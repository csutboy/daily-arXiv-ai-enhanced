<div id=toc></div>

# Table of Contents

- [cs.SI](#cs.SI) [Total: 2]
- [econ.EM](#econ.EM) [Total: 6]
- [cs.CY](#cs.CY) [Total: 14]
- [cs.ET](#cs.ET) [Total: 3]
- [cs.AI](#cs.AI) [Total: 42]
- [stat.AP](#stat.AP) [Total: 13]


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [1] [Rabble-Rousers in the New King's Court: Algorithmic Effects on Account Visibility in Pre-X Twitter](https://arxiv.org/abs/2512.06129)
*Alexandros Efstratiou,Kayla Duskin,Kate Starbird,Emma Spiro*

Main category: cs.SI

TL;DR: 研究发现Twitter算法推送中右翼账户获得更多曝光，但这并非源于政治立场，而是因为其发布更多煽动性内容并受到平台所有者马斯克关注。同时，传统认证账户在算法推送中曝光度低于非认证或Twitter Blue认证账户。


<details>
  <summary>Details</summary>
Motivation: 社交媒体算法对右翼账户的曝光优势已有多项研究证实，但Twitter所有权变更后的情况尚不清楚。本研究旨在探究算法推送中右翼账户曝光优势的真正原因，以及不同认证类型账户的曝光差异。

Method: 收集Twitter所有权变更后但尚未更名为X时期的用户推送数据，对比算法推送和按时间倒序推送两种模式。分析右翼账户曝光优势的相关因素，包括内容特征、平台所有者关注度等，并比较不同认证类型账户的曝光差异。

Result: 右翼账户在算法推送中确实获得更多曝光，但主要原因是他们发布更多煽动性内容并受到马斯克（当时网络中最核心账户）的关注。传统认证账户（如企业和政府官员）在算法推送中曝光度低于非认证或Twitter Blue认证账户。

Conclusion: 算法推送的曝光差异并非单纯基于政治立场，而是与用户行为模式（如发布煽动性内容）和平台所有者关注度相关。这揭示了算法奖励机制与行为激励之间的关联，对在线信任和安全具有重要启示。

Abstract: Algorithmic effects on social media platforms have come under recent scrutiny, with several works reporting that right-leaning accounts tend to receive more exposure. In this paper, we expand upon this body of work using data collected from user feeds after Twitter's change of ownership but before its re-branding to X. We replicate findings from prior work regarding the increased exposure of right-leaning accounts to wider audiences in algorithmically curated compared to reverse-chronological feeds, and, crucially, we further unpack this effect to understand what correlated (and did not correlate) with these differences. Our results reveal that right-leaning accounts benefited not necessarily due to their political affiliation, but possibly because they behaved in ways associated with algorithmic rewards; namely, posting more agitating content and receiving attention from the platform's owner, Elon Musk, who was the most central network account. We also demonstrate that legacy-verified accounts, like businesses and government officials, received less exposure in the algorithmic feed compared to non-verified or Twitter Blue-verified accounts. We discuss implications of these findings for the intersection between behavioral incentives for algorithmic reach and online trust and safety.

</details>


### [2] [The relationship between offline partisan geographical segregation and online partisan segregation](https://arxiv.org/abs/2512.07121)
*Megan A. Brown,Tiago Ventura,Joshua A. Tucker,Jonathan Nagler*

Main category: cs.SI

TL;DR: 研究发现：虽然社交媒体用户倾向于形成政治同质的在线网络，但线下党派隔离程度显著高于线上；民主党人在两种环境中都比共和党人更孤立；只有年长共和党人表现出线上隔离高于线下。


<details>
  <summary>Details</summary>
Motivation: 回应社交媒体常被指责制造"回音室"的批评，指出这些批评忽略了美国线下党派隔离造成的高水平线下回音室现象。研究旨在实证评估线上与线下党派隔离的动态关系。

Method: 将1.8亿美国选民公开选民档案中的线下党派隔离数据与Twitter用户的在线网络隔离数据链接起来，使用地理和网络隔离测量方法，分析每个匹配的选民-Twitter用户的党派隔离情况。

Result: 1. 社交媒体用户确实倾向于形成政治同质的在线网络；2. 但线下党派隔离程度显著高于线上隔离；3. 民主党人在线上和线下都比共和党人更孤立；4. 只有年长共和党人表现出线上隔离高于线下隔离。

Conclusion: 研究为政治传播和在线网络同质性的新兴文献提供了新证据，表明虽然社交媒体存在党派隔离，但线下环境中的隔离程度更高，挑战了社交媒体是主要回音室来源的传统观点。

Abstract: Social media is often blamed for the creation of echo chambers. However, these claims fail to consider the prevalence of offline echo chambers resulting from high levels of partisan segregation in the United States. Our article empirically assesses these online versus offline dynamics by linking a novel dataset of voters' offline partisan segregation extracted from publicly available voter files for 180 million US voters with their online network segregation on Twitter. We investigate offline and online partisan segregation using measures of geographical and network isolation of every matched voter-twitter user to their co-partisans online and offline. Our results show that while social media users tend to form politically homogeneous online networks, these levels of partisan sorting are significantly lower than those found in offline settings. Notably, Democrats are more isolated than Republicans in both settings, and only older Republicans exhibit higher online than offline segregation. Our results contribute to the emerging literature on political communication and the homophily of online networks, providing novel evidence on partisan sorting both online and offline.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [3] [Making Event Study Plots Honest: A Functional Data Approach to Causal Inference](https://arxiv.org/abs/2512.06804)
*Chencheng Fang,Dominik Liebl*

Main category: econ.EM

TL;DR: 提出一种基于函数数据方法的DiD估计器，通过等价检验和相关性检验将事件研究图转化为严谨的因果推断工具


<details>
  <summary>Details</summary>
Motivation: 当前的事件研究图方法在平行趋势和/或无预期假设失效时无法提供可靠的因果推断，需要一种能够提供诚实因果推断的新方法

Method: 引入函数数据方法到DiD分析中，DiD估计器在连续函数的Banach空间中收敛到高斯过程，支持快速且强大的同时置信带

Result: 该方法在模拟和两个案例研究中表现出良好性能，能够通过等价检验验证前预期期的诚实参考带，并通过相关性检验测试后处理期的诚实因果效应

Conclusion: 该方法将事件研究图转化为严谨的诚实因果推断工具，解决了传统方法在假设失效时的局限性

Abstract: Event study plots are the centerpiece of Difference-in-Differences (DiD) analysis, but current plotting methods cannot provide honest causal inference when the parallel trends and/or no-anticipation assumptions fail. We introduce a novel functional data approach to DiD that directly enables honest causal inference via event study plots. Our DiD estimator converges to a Gaussian process in the Banach space of continuous functions, enabling fast and powerful simultaneous confidence bands. This theoretical contribution allows us to turn an event study plot into a rigorous honest causal inference tool through equivalence and relevance testing: Honest reference bands can be validated using equivalence testing in the pre-anticipation period, and honest causal effects can be tested using relevance testing in the post-treatment period. We demonstrate the performance of the method in simulations and two case studies.

</details>


### [4] [Estimating Duration Dependence in Job Search: the Within-Estimation Duration Bias](https://arxiv.org/abs/2512.06928)
*Jeremy Zuchuat*

Main category: econ.EM

TL;DR: 固定效应模型在分析纵向数据时可能存在严重偏差，特别是当研究对象在退出研究时具有特定结果值时，会导致时间变量与误差项产生机械相关性。


<details>
  <summary>Details</summary>
Motivation: 许多研究使用个体纵向数据分析求职行为，固定效应模型被用来处理动态选择问题并识别时间结构效应。然而，当求职者在退出失业状态时具有特定结果值时，固定效应估计可能产生显著偏差。

Method: 推导固定效应估计器提供有效持续时间依赖关系估计的条件，并使用蒙特卡洛模拟来展示偏差的大小。

Result: 蒙特卡洛模拟显示，固定效应估计的偏差可能非常大，特别是在研究对象退出时具有特定结果值的情况下。

Conclusion: 固定效应估计器在特定条件下才能有效估计时间结构效应，这一发现不仅适用于求职研究，也适用于任何使用纵向数据测量时间结构效应的框架。

Abstract: Many recent studies use individual longitudinal data to analyze job search behaviors. Such data allow the use of fixed-effects models, which supposedly address the issue of dynamic selection and make it possible to identify the structural effect of time. However, using fixed effects can induce a sizable within-estimation bias if job search outcomes take specific values at the time job seekers exit unemployment. This pattern creates an undesirable mechanical correlation between the error term and the time regressor. This paper derives the conditions under which the fixed-effects estimator provides valid estimates of structural duration-dependence relationships. Using Monte Carlo simulations, we show that the magnitude of the bias can be extremely large. Our results are not limited to the job search context but naturally extend to any framework in which longitudinal data are used to measure the structural effect of time.

</details>


### [5] [Testing the Significance of the Difference-in-Differences Coefficient via Doubly Randomised Inference](https://arxiv.org/abs/2512.06946)
*Stanisław Marek Sergiusz Halkiewicz,Andrzej Kałuża*

Main category: econ.EM

TL;DR: 提出基于双重随机化推断的DID估计量显著性检验，通过同时置换处理和时间指标来生成经验零分布，相比传统方法有更大的随机化空间和更好的小样本稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统DID显著性检验（如t检验或单边置换程序）存在局限性，特别是在小样本或非规则分配结构下。需要一种更稳健的非参数方法来评估DID估计的统计显著性。

Method: 开发双重随机化推断方法：同时置换处理指标和时间指标来生成DID系数的经验零分布。该方法利用扩大的随机化空间，通过组合数学分析显示可容许重标记数量增加了$\binom{n}{n_T}$倍。

Result: 在多个实证数据集（印尼学校建设计划、品牌搜索数据、最低工资改革、希腊难民流入）上测试，双重随机化推断与标准方法表现相当，但具有更好的小样本稳定性和更尖锐的临界区域。

Conclusion: 双重随机化推断为评估DID估计的统计显著性提供了稳健的非参数替代方案，特别适用于组规模有限或分配结构不规则的实验设计。

Abstract: This article develops a significance test for the Difference-in-Differences (DiD) estimator based on doubly randomised inference, in which both the treatment and time indicators are permuted to generate an empirical null distribution of the DiD coefficient. Unlike classical $t$-tests or single-margin permutation procedures, the proposed method exploits a substantially enlarged randomization space. We formally characterise this expansion and show that dual randomization increases the number of admissible relabelings by a factor of $\binom{n}{n_T}$, yielding an exponentially richer permutation universe. This combinatorial gain implies a denser and more stable approximation of the null distribution, a result further justified through an information-theoretic (entropy) interpretation. The validity and finite-sample behaviour of the test are examined using multiple empirical datasets commonly analysed in applied economics, including the Indonesian school construction program (INPRES), brand search data, minimum wage reforms, and municipality-level refugee inflows in Greece. Across all settings, doubly randomised inference performs comparably to standard approaches while offering superior small-sample stability and sharper critical regions due to the enlarged permutation space. The proposed procedure therefore provides a robust, nonparametric alternative for assessing the statistical significance of DiD estimates, particularly in designs with limited group sizes or irregular assignment structures.

</details>


### [6] [Limitations of Randomization Tests in Finite Samples](https://arxiv.org/abs/2512.07099)
*Deniz Dutz,Xinyi Zhang*

Main category: econ.EM

TL;DR: 本文研究了随机化检验的有限样本有效性条件，发现某些零假设（如均值为零）本质上无法构造有效的随机化检验，这解释了为什么实践中需要比原假设更强的条件。


<details>
  <summary>Details</summary>
Motivation: 随机化检验在满足随机化假设时能提供精确的有限样本第一类错误控制，但实践中常需要比原假设更强的条件。例如，均值零的符号变化检验需要对称性，对于非对称的均值零分布无法控制有限样本错误。作者想探究这种限制是特定检验选择的问题，还是反映了某些假设本质上无法构造有效随机化检验。

Method: 作者开发了一个理论框架，提供了零假设是否允许随机化检验的简单必要充分条件。将该框架应用于单样本检验，对有限和连续支撑的情况给出了哪些零假设满足该条件的特征刻画。特别证明了某些零假设（包括均值为零）不允许随机化检验。进一步展示了基于线性群作用的随机化检验对应的零假设只能是对称或正态分布的子集。

Result: 研究证实了某些零假设（如均值零）本质上无法构造有效的随机化检验，这解释了为什么实践中需要更强的条件。基于线性群作用的随机化检验只能对应对称或正态分布的子集。这些发现确认了实践者在使用现有检验时并非无意中增加了第一类错误风险。

Conclusion: 研究结果表明，对于某些零假设，随机化检验的有限样本有效性确实存在根本性限制，这为关注随机化检验的渐近有效性提供了进一步的理论依据。实践者在使用现有检验时并未无意中增加第一类错误，而是面对了某些假设下有限样本检验的根本不可能性。

Abstract: Randomization tests yield exact finite-sample Type 1 error control when the null satisfies the randomization hypothesis. However, achieving these guarantees in practice often requires stronger conditions than the null hypothesis of primary interest. For instance, sign-change tests for mean zero require symmetry and fail to control finite-sample error for non-symmetric mean-zero distributions. We investigate whether such limitations stem from specific test choices or reflect a fundamental inability to construct valid randomization tests for certain hypotheses. We develop a framework providing a simple necessary and sufficient condition for when null hypotheses admit randomization tests. Applying this framework to one-sample tests, we provide characterizations of which nulls satisfy this condition for both finite and continuous supports. In doing so, we prove that certain null hypotheses -- including mean zero -- do not admit randomization tests. We further show that nulls that admit randomization tests based on linear group actions correspond only to subsets of symmetric or normal distributions. Overall, our findings affirm that practitioners are not inadvertently incurring additional Type 1 error when using existing tests and further motivate focusing on the asymptotic validity of randomization tests.

</details>


### [7] [Variational Regularized Bilevel Estimation for Exponential Random Graph Models](https://arxiv.org/abs/2512.07176)
*Yoon Choi*

Main category: econ.EM

TL;DR: 提出一种用于指数随机图模型（ERGM）的估计算法，通过变分平均场方法和ℓ₂正则化解决归一化常数难处理和模型退化问题，在三角形参数估计上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有ERGM估计方法在三角形参数估计上不可靠，可能导致不可信的政策建议。三角形是捕捉共同朋友连接倾向的关键网络结构，需要更可靠的估计方法。

Method: 采用变分平均场方法解决ERGM归一化常数难处理和模型退化问题，引入ℓ₂正则化确保平均场近似问题在适当条件下有唯一解。

Result: 蒙特卡洛模拟显示，该方法在扰动初始化下对中小型网络的三角形参数实现完美符号恢复率（100%），而现有算法只有50%。提供了非渐近优化收敛率分析和超参数敏感性分析。

Conclusion: 提出的算法显著提高了ERGM中三角形参数估计的可靠性，为网络形成策略分析提供了更可信的估计工具，具有实际应用价值。

Abstract: I propose an estimation algorithm for Exponential Random Graph Models (ERGM), a popular statistical network model for estimating the structural parameters of strategic network formation in economics and finance. Existing methods often produce unreliable estimates of parameters for the triangle, a key network structure that captures the tendency of two individuals with friends in common to connect. Such unreliable estimates may lead to untrustworthy policy recommendations for networks with triangles. Through a variational mean-field approach, my algorithm addresses the two well-known difficulties when estimating the ERGM, the intractability of its normalizing constant and model degeneracy. In addition, I introduce $\ell_2$ regularization that ensures a unique solution to the mean-field approximation problem under suitable conditions. I provide a non-asymptotic optimization convergence rate analysis for my proposed algorithm under mild regularity conditions. Through Monte Carlo simulations, I demonstrate that my method achieves a perfect sign recovery rate for triangle parameters for small and mid-sized networks under perturbed initialization, compared to a 50% rate for existing algorithms. I provide the sensitivity analysis of estimates of ERGM parameters to hyperparameter choices, offering practical insights for implementation.

</details>


### [8] [Bounds on inequality with incomplete data](https://arxiv.org/abs/2512.07709)
*James Banks,Thomas Glinnan,Tatiana Komarova*

Main category: econ.EM

TL;DR: 提出非参数框架，用于在收入或财富仅被粗略观测（如分组表格或区间报告）时，对不平等指数进行尖锐的部分识别和推断，支持线性约束如已知均值或子组总和。


<details>
  <summary>Details</summary>
Motivation: 现实数据中，收入或财富通常只能通过分组表格或区间报告等粗略方式观测，这给不平等指数的准确估计带来挑战。需要开发一个统一框架来处理这种数据限制，同时允许纳入已知的线性约束信息。

Method: 1) 对Schur凸不平等度量，通过特征化极值分配将无限维问题简化为有限维优化；2) 对具有线性分数表示的不平等指数（如基尼系数、分位数比、胡佛指数），将边界问题转化为线性或二次规划；3) 使用均匀方向delta方法和自助法进行边界端点的√n推断。

Result: 在ELSA财富数据中，获得液体储蓄的基尼系数尖锐边界为0.714-0.792，广义储蓄度量为0.686-0.767。历史美国收入表格在分组信息下为基尼系数、分位数比和胡佛指数提供了时间序列边界。

Conclusion: 该框架为在粗略观测数据下进行不平等指数的尖锐识别和推断提供了统一、计算高效的方法，能够处理现实世界中的分组数据和区间报告，为政策分析和经济研究提供可靠的不平等度量边界。

Abstract: We develop a unified, nonparametric framework for sharp partial identification and inference on inequality indices when income or wealth are only coarsely observed -- for example via grouped tables or individual interval reports -- possibly together with linear restrictions such as known means or subgroup totals. First, for a broad class of Schur-convex inequality measures, we characterize extremal allocations and show that sharp bounds are attained by distributions with simple, finite support, reducing the underlying infinite-dimensional problem to finite-dimensional optimization. Second, for indices that admit linear-fractional representations after suitable ordering of the data (including the Gini coefficient, quantile ratios, and the Hoover index), we recast the bound problems as linear or quadratic programs, yielding fast computation of numerically sharp bounds. Third, we establish $\sqrt{n}$ inference for bound endpoints using a uniform directional delta method and a bootstrap procedure for standard errors. In ELSA wealth data with mixed point and interval observations, we obtain sharp Gini bounds of 0.714--0.792 for liquid savings and 0.686--0.767 for a broad savings measure; historical U.S. income tables deliver time-series bounds for the Gini, quantile ratios, and Hoover index under grouped information.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [9] [The Tragedy of Productivity: A Unified Framework for Diagnosing Coordination Failures in Labor Markets and AI Governance](https://arxiv.org/abs/2512.05995)
*Ali Dasdan*

Main category: cs.CY

TL;DR: 论文提出"结构性悲剧"框架，分析为何生产力增长未转化为工人福利、AI发展无视风险警告，揭示这些失败具有相同博弈结构，并量化AI治理协调难度远超气候变化和核武器。


<details>
  <summary>Details</summary>
Motivation: 尽管生产力自凯恩斯时代增长八倍，但全球工人仍工作约30小时/周（两倍于预测）；同时AI发展加速却无视存在风险警告。作者发现这些失败具有相同的博弈论结构，需要理论框架来解释这种系统性协调失败。

Method: 提出"结构性悲剧"框架，包含五个必要充分条件：N人结构、二元选择与负外部性、背叛占优策略、合作帕累托占优但难以实现、结构性执行障碍。通过条件强度分析建立"悲剧指数"，应用于生产力竞争和AI治理案例验证。

Result: 验证框架适用于经典案例，量化显示AI治理协调难度比气候变化或核武器高数量级。生产力竞争证明企业面临协调失败，欧洲证据显示生产力-福利脱钩持续。AI治理在八个维度强度远超成功军控案例，俄乌无人机战争验证了该结构。

Conclusion: 分析是诊断性的而非处方性的，识别协调的结构性障碍而非提出解决方案。揭示了生产力增长未转化为工人福利、AI发展无视风险警告的根本原因在于相同的博弈结构，AI治理面临前所未有的协调挑战。

Abstract: Despite productivity increasing eightfold since Keynes's 1930
  prediction of 15-hour workweeks, workers globally still work roughly
  double these hours. Separately, AI development accelerates despite
  existential risk warnings from leading researchers. We demonstrate
  these failures share identical game-theoretic structure.
  We synthesize five necessary and sufficient conditions
  characterizing structural tragedies: N-player structure,
  binary choices with negative externalities, dominance where
  defection yields higher payoffs, Pareto-inefficiency where
  cooperation dominates mutual defection, and enforcement difficulty
  from structural barriers. We validate this framework across canonical
  cases and extend it through condition intensities, introducing a
  Tragedy Index revealing AI governance faces orders-of-magnitude
  greater coordination difficulty than climate change or nuclear
  weapons.
  Applied to productivity competition, we prove firms face
  coordination failure preventing productivity gains from translating
  to worker welfare. European evidence shows that even under favorable
  conditions, productivity-welfare decoupling persists. Applied to AI
  governance, we demonstrate development faces the same structure but
  with amplified intensity across eight dimensions compared to
  successful arms control. The Russia-Ukraine drone war validates this:
  both sides escalated from zero to thousands of drones monthly within
  two years despite prior governance dialogue.
  The analysis is diagnostic rather than prescriptive, identifying
  structural barriers to coordination rather than proposing solutions.

</details>


### [10] [Uncovering Students' Inquiry Patterns in GenAI-Supported Clinical Practice: An Integration of Epistemic Network Analysis and Sequential Pattern Mining](https://arxiv.org/abs/2512.06018)
*Jiameng Wei,Dinh Dang,Kaixun Yang,Emily Stokes,Amna Mazeh,Angelina Lim,David Wei Dai,Joel Moore,Yizhou Fan,Danijela Gasevic,Dragan Gasevic,Guanliang Chen*

Main category: cs.CY

TL;DR: 本研究应用学习分析技术，分析药学学生在GenAI虚拟病人对话中的临床沟通能力发展模式，发现高绩效学生展现战略性的信息识别行为，而低绩效学生则陷入常规问答循环。


<details>
  <summary>Details</summary>
Motivation: 传统药物史采集评估依赖人工观察，限制了可扩展性和详细性能数据。虽然生成式AI平台能够收集大量数据，学习分析也能分析教育轨迹，但这些方法在药学临床培训中尚未充分探索。考虑到学生群体的多样性、语言背景差异以及传统培训中个性化反馈机会有限，需要新的评估方法。

Method: 分析323名澳大利亚和马来西亚学生的互动日志，包含50,871个编码话语和1,487个学生-GenAI对话。结合认知网络分析（ENA）建模问题共现关系和序列模式挖掘（SPM）捕捉时间序列，研究学生临床沟通能力发展模式。

Result: 高绩效学生展现出战略性的信息识别行为，以识别临床相关信息为中心，整合关系建立和结构组织；低绩效学生则停留在常规问题验证循环中。人口统计学因素（母语背景、药学工作经验、机构背景）也塑造了不同的询问模式。

Conclusion: 研究揭示了GenAI辅助环境中可能指示临床推理发展的询问模式，为健康专业教育评估提供了方法论见解，并为支持多样化学习路径的自适应GenAI系统设计提供了信息。

Abstract: Assessment of medication history-taking has traditionally relied on human observation, limiting scalability and detailed performance data. While Generative AI (GenAI) platforms enable extensive data collection and learning analytics provide powerful methods for analyzing educational traces, these approaches remain largely underexplored in pharmacy clinical training. This study addresses this gap by applying learning analytics to understand how students develop clinical communication competencies with GenAI-powered virtual patients -- a crucial endeavor given the diversity of student cohorts, varying language backgrounds, and the limited opportunities for individualized feedback in traditional training settings. We analyzed 323 students' interaction logs across Australian and Malaysian institutions, comprising 50,871 coded utterances from 1,487 student-GenAI dialogues. Combining Epistemic Network Analysis to model inquiry co-occurrences with Sequential Pattern Mining to capture temporal sequences, we found that high performers demonstrated strategic deployment of information recognition behaviors. Specifically, high performers centered inquiry on recognizing clinically relevant information, integrating rapport-building and structural organization, while low performers remained in routine question-verification loops. Demographic factors including first-language background, prior pharmacy work experience, and institutional context, also shaped distinct inquiry patterns. These findings reveal inquiry patterns that may indicate clinical reasoning development in GenAI-assisted contexts, providing methodological insights for health professions education assessment and informing adaptive GenAI system design that supports diverse learning pathways.

</details>


### [11] [Code vs. Context: STEM Students' Resistance to Non-STEM Coursework](https://arxiv.org/abs/2512.06529)
*Md Abdullah Al Kafi,Raka Moni,Sumit Kumar Banshal*

Main category: cs.CY

TL;DR: 研究发现工程学生对非技术课程的抵触主要源于角色模糊，而非工作负荷或认知转换成本，角色模糊通过影响情感抵触降低参与意愿，进而影响技能长期采用。


<details>
  <summary>Details</summary>
Motivation: STEM项目要求学生修读非技术课程培养软技能，但工程学生常抵触此类要求。先前研究多归因于工作负荷，但对认知和身份相关机制了解不足。本研究旨在填补这一知识空白。

Method: 收集212名计算机科学与工程本科生的调查数据，使用顺序OLS回归测试认知转换成本、工作超负荷、角色模糊对情感抵触的影响，以及后续对参与意愿和技能长期采用的影响。

Result: 角色模糊是情感抵触的最强预测因子（β=0.47），超过工作超负荷（β=0.20）和认知转换成本（β=0.14）。情感抵触显著降低参与意愿（β=-0.25），参与意愿强烈预测技能长期采用（β=0.55）。

Conclusion: 学生抵触主要源于非技术内容与学生专业身份认同的不一致，而非认知努力或工作负荷。为改善结果，课程应通过将人文社科材料置于明确的工程情境中来减少角色模糊。

Abstract: Many STEM programs now require students to take non-technical courses to develop the soft skills necessary for professional practice, yet engineering students frequently resist this requirement. While prior research often attributes this resistance to heavy workloads, little is known about its cognitive and identity-related mechanisms. This study fills this knowledge gap by examining the effects of Cognitive Switching Costs, Work Overload, and Role Ambiguity on students' Affective Resistance to non-STEM coursework, as well as the subsequent impact on their Willingness to Engage and Long-Term Adoption of skills. We collected survey data from 212 undergraduate Computer Science and Engineering students and tested directional relationships using sequential OLS regression. Role Ambiguity emerged as the strongest predictor of Affective Resistance (beta of 0.47, p less than 0.001), exceeding the effects of Work Overload (beta of 0.20, p equals 0.007) and Cognitive Switching Cost (beta of 0.14, p equals 0.038). In turn, Affective Resistance significantly reduced Willingness to Engage (beta of -0.25, p less than 0.001), while Willingness to Engage served as a strong predictor of Long-Term Adoption (beta of 0.55, p less than 0.001). These results indicate that student resistance is driven primarily by the incongruence between non-technical content and students' emergent professional identities, rather than by cognitive effort or workload alone. To improve outcomes, curricula should focus on reducing role ambiguity by placing humanities and social science material in clear engineering contexts.

</details>


### [12] [Protocol Futuring: Speculating Second-Order Dynamics of Protocols in Sociotechnical Infrastructural Futures](https://arxiv.org/abs/2512.06108)
*Botao 'Amber' Hu,Samuel Chua,Helena Rong*

Main category: cs.CY

TL;DR: 论文提出Protocol Futuring方法框架，通过关注协议规则在长时间尺度上的演变来探索基础设施政治和长期社会技术影响。


<details>
  <summary>Details</summary>
Motivation: 现有设计未来方法主要关注离散的未来物品，缺乏对协议规则（规则、标准、协调机制）在长时间尺度上演变及其二阶效应的系统性分析，特别是基础设施政治和长期社会技术影响难以显现。

Method: 提出Protocol Futuring方法框架，以协议作为推测性探究的主要材料，通过多团队参与式工作坊（Knowledge Futurama）采用接力形式，让团队继承和重新解释部分形成的设计，观察协议在跨社区和跨时代传播中的演变。

Result: 工作坊揭示了协议在传播过程中如何因模糊交接、对抗性重新解释、文化规范变迁和危机动态而发生转变，使基础设施政治和长期后果在分析上变得可见。

Conclusion: Protocol Futuring为研究在长时间尺度上展开影响的新兴社会技术系统提供了有价值的分析工具，能够揭示基础设施政治和长期演变过程，但方法也存在局限性，需要进一步探讨。

Abstract: Drawing on infrastructure studies in HCI and CSCW, this paper introduces Protocol Futuring, a methodological framework that extends design futuring by foregrounding protocols-rules, standards, and coordination mechanisms-as the primary material of speculative inquiry. Rather than imagining discrete future artifacts, Protocol Futuring examines how protocol rules accumulate drift, jam, and other second-order effects over long temporal horizons. We demonstrate the method through a case study of Knowledge Futurama, a multi-team participatory workshop exploring millennial-scale knowledge preservation. Using a relay format in which teams inherited and reinterpreted partially formed designs, the workshop revealed how ambiguous handovers, adversarial reinterpretations, shifting cultural norms, and crisis dynamics transform protocols as they move across communities and epochs. The case shows how Protocol Futuring makes infrastructural politics and long-run consequences analytically visible. We discuss the method's strengths, limitations, and implications for researchers seeking to investigate emergent sociotechnical systems whose impacts unfold over extended timescales.

</details>


### [13] [A Framework for Data Valuation and Monetisation](https://arxiv.org/abs/2512.07664)
*Eduardo Vyhmeister,Bastien Pietropaoli,UdoBub,Rob Schneider,Andrea Visentin*

Main category: cs.CY

TL;DR: 提出统一的数据估值框架，整合经济、治理和战略视角，通过混合模型系统评估数据价值，并与组织战略对齐。


<details>
  <summary>Details</summary>
Motivation: 组织面临将数据资产转化为可衡量商业价值的挑战，现有估值方法分散且缺乏适用于实际环境的操作机制，需要整合不同视角的统一框架。

Method: 采用设计科学研究方法，基于DATAMITE项目的两个构件（数据质量和性能指标分类法、ANP工具），开发结合定性评分、成本/效用估计、相关性/质量指数和多准则加权的混合估值模型，并嵌入工业合作伙伴的案例研究进行持续改进。

Result: 该框架在分析的使用案例中表现出灵活性、透明度和减少估值随意性，为组织提供了将数据资产与战略和经济结果联系起来的结构化基础。

Conclusion: 提出的统一估值框架成功整合了不同视角，通过平衡计分卡与组织战略对齐，为数据作为服务、信息作为服务和答案作为服务等路径的货币化潜力评估提供了系统化工具。

Abstract: As organisations increasingly recognise data as a strategic resource, they face the challenge of translating informational assets into measurable business value. Existing valuation approaches remain fragmented, often separating economic, governance, and strategic perspectives and lacking operational mechanisms suitable for real settings. This paper introduces a unified valuation framework that integrates these perspectives into a coherent decision-support model. Building on two artefacts from the Horizon Europe DATAMITE project, a taxonomy of data-quality and performance metrics, and an Analytic Network Process (ANP) tool for deriving relative importance, we develop a hybrid valuation model. The model combines qualitative scoring, cost- and utility-based estimation, relevance/quality indexing, and multi-criteria weighting to define data value transparently and systematically. Anchored in the Balanced Scorecard (BSC), the framework aligns indicators and valuation outcomes with organisational strategy, enabling firms to assess monetisation potential across Data-as-a-Service, Information-as-a-Service, and Answers-as-a-Service pathways. Methodologically, the study follows a Design Science approach complemented by embedded case studies with industrial partners, which informed continual refinement of the model. Because the evaluation is connected to a high-level taxonomy, the approach also reveals how valuation considerations map to BSC perspectives. Across the analysed use cases, the framework demonstrated flexibility, transparency, and reduced arbitrariness in valuation, offering organisations a structured basis for linking data assets to strategic and economic outcomes.

</details>


### [14] [The Role of Smart Cities in Ethical Design Framework](https://arxiv.org/abs/2512.06336)
*Yijun Chen*

Main category: cs.CY

TL;DR: 本文探讨智慧城市技术实施中的伦理挑战，包括数据隐私、公平性、包容性和透明度问题，并提出通过监管沙盒、参与式治理和弥合数字鸿沟等建议来确保智慧城市符合社会价值观。


<details>
  <summary>Details</summary>
Motivation: 随着数字技术融入城市规划形成"智慧城市"，旨在提高生活质量和运营效率，但技术实施带来了数据隐私、公平性、包容性和透明度等伦理挑战，需要系统分析以确保智慧城市发展符合社会价值观。

Method: 采用Beard和Longstaff框架，结合理论分析和案例研究，聚焦自决、公平、可及性和目的性原则，考察智慧城市倡议中的治理模式、利益相关者角色和伦理困境。

Result: 研究识别了智慧城市实施中的关键伦理挑战，包括数据隐私风险、数字鸿沟、治理透明度不足等问题，并提出了具体解决方案。

Conclusion: 为确保智慧城市发展符合伦理和社会价值观，建议采用监管沙盒、促进参与式治理、弥合数字鸿沟等措施，以实现包容性和伦理导向的城市发展。

Abstract: The integration of digital technologies into urban planning has given rise to "smart cities," aiming to enhance quality of life and operational efficiency. However, the implementation of such technologies introduces ethical challenges, including data privacy, equity, inclusion, and transparency. This article employs the Beard and Longstaff framework to discuss these challenges through a combination of theoretical analysis and case studies. Focusing on principles of self-determination, fairness, accessibility, and purpose, the study examines governance models, stakeholder roles, and ethical dilemmas inherent in smart city initiatives. Recommendations include adopting regulatory sandboxes, fostering participatory governance, and bridging digital divides to ensure that smart cities align with societal values, promoting inclusivity and ethical urban development.

</details>


### [15] [Why They Disagree: Decoding Differences in Opinions about AI Risk on the Lex Fridman Podcast](https://arxiv.org/abs/2512.06350)
*Nghi Truong,Phanish Puranam,Özgecan Koçak*

Main category: cs.CY

TL;DR: 该论文使用LLM分析AI风险辩论中的"末日论者"与"繁荣论者"观点分歧，发现分歧主要源于对复杂系统设计vs涌现、以及历史理论适用性vs革命性的不同因果前提，而非道德价值观差异。


<details>
  <summary>Details</summary>
Motivation: AI技术发展引发了深刻的社会分歧，尽管各方都希望AI造福人类并避免灾难性后果，但关于AI风险的辩论仍然激烈。论文旨在系统分析这些分歧的根源，理解为何共享利益却存在持续对立。

Method: 使用LLM集成方法大规模分析推理链条，将"末日论者"与"繁荣论者"的观点分歧解析为定义性、事实性、因果性和道德性前提，识别关键争议点。

Result: 发现关于存在性风险的分歧源于对复杂系统设计vs涌现的不同因果前提；关于就业风险的分歧源于对历史理论适用性vs革命性的不同因果前提。两种分歧都不涉及重大道德价值观差异，都可描述为对人类理性有限性的不同看法。

Conclusion: 该分析方法可推广到任何公共风险辩论领域，帮助识别关键争议点。理解分歧的认知根源而非道德差异，有助于更建设性地解决AI风险辩论。

Abstract: The emergence of transformative technologies often surfaces deep societal divisions, nowhere more evident than in contemporary debates about artificial intelligence (AI). A striking feature of these divisions is that they persist despite shared interests in ensuring that AI benefits humanity and avoiding catastrophic outcomes. This paper analyzes contemporary debates about AI risk, parsing the differences between the "doomer" and "boomer" perspectives into definitional, factual, causal, and moral premises to identify key points of contention. We find that differences in perspectives about existential risk ("X-risk") arise fundamentally from differences in causal premises about design vs. emergence in complex systems, while differences in perspectives about employment risks ("E-risks") pertain to different causal premises about the applicability of past theories (evolution) vs their inapplicability (revolution). Disagreements about these two forms of AI risk appear to share two properties: neither involves significant disagreements on moral values and both can be described in terms of differing views on the extent of boundedness of human rationality. Our approach to analyzing reasoning chains at scale, using an ensemble of LLMs to parse textual data, can be applied to identify key points of contention in debates about risk to the public in any arena.

</details>


### [16] [The Missing Variable: Socio-Technical Alignment in Risk Evaluation](https://arxiv.org/abs/2512.06354)
*Niclas Flehmig,Mary Ann Lundteigen,Shen Yin*

Main category: cs.CY

TL;DR: 该论文提出了一种新的社会技术对齐变量STA，用于改进AI安全关键系统的风险评估，弥补了现有方法忽视人机组织复杂交互的缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有AI安全关键系统的风险评估方法存在重大缺陷，未能考虑人、技术和组织要素之间的复杂交互作用，而这些系统本质上是复杂的社会技术系统。

Method: 通过比较社会技术系统和AI赋能系统的属性特征，并回顾现有风险评估方法，确认了标准风险表达中社会技术考虑的缺失。为此，提出了社会技术对齐变量STA，可集成到基础风险方程中，用于评估AI系统、人类操作者和组织流程之间的和谐交互程度。

Result: 通过AI赋能液氢加注系统的案例研究，比较了原始设计和安全防护设计，证明了STA增强的风险表达能够捕捉传统风险评估忽视的社会技术安全影响，为风险评估提供了更全面的基础。

Conclusion: STA变量成功填补了AI安全关键系统风险评估中的关键空白，通过纳入社会技术对齐考量，能够更全面地评估系统风险，为复杂社会技术系统的安全评估提供了新方法。

Abstract: This paper addresses a critical gap in the risk assessment of AI-enabled safety-critical systems. While these systems, where AI systems assists human operators, function as complex socio-technical systems, existing risk evaluation methods fail to account for the associated complex interaction between human, technical, and organizational elements. Through a comparative analysis of system attributes from both socio-technical and AI-enabled systems and a review of current risk evaluation methods, we confirm the absence of socio-technical considerations in standard risk expressions. To bridge this gap, we introduce a novel socio-technical alignment $STA$ variable designed to be integrated into the foundational risk equation. This variable estimates the degree of harmonious interaction between the AI systems, human operators, and organizational processes. A case study on an AI-enabled liquid hydrogen bunkering system demonstrates the variable's relevance. By comparing a naive and a safeguarded system design, we illustrate how the $STA$-augmented expression captures socio-technical safety implications that traditional risk evaluation overlooks, providing a more holistic basis for risk evaluation.

</details>


### [17] [Generic visuality of war? How image-generative AI models (mis)represent Russia's war against Ukraine](https://arxiv.org/abs/2512.06570)
*Mykola Makhortykh,Miglė Bareikytė*

Main category: cs.CY

TL;DR: 该研究审计了西方和非西方生成式AI模型（Midjourney和Kandinsky）如何表征俄乌战争，发现情境因素导致战争表征存在差异，但也存在可能导致战争美学同质化的模式。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的兴起可能改变社会现实（包括现代战争）的表征方式。虽然已有研究关注AI的军事应用，但生成式AI技术对战争描绘、记忆和解释方式的影响尚不明确，特别是西方与非西方模型在表征暴力事件时的差异。

Method: 以俄罗斯侵略乌克兰为案例研究，审计美国Midjourney和俄罗斯Kandinsky两个图像生成模型对战争虚构和事实场景的表征。分析模型对战争相关提示的响应性，以及生成图像的美学和内容特征。

Result: 研究发现情境因素导致战争表征存在差异，既存在于不同模型之间，也存在于同一模型的输出内部。然而，存在一些一致的表征模式，可能促进战争美学的同质化。

Conclusion: 生成式AI对战争的表征受到情境因素的影响，但同时也展现出可能导致战争美学同质化的模式，这对理解AI如何塑造暴力事件的集体记忆和解释具有重要意义。

Abstract: The rise of generative AI (genAI) can transform the representation of different aspects of social reality, including modern wars. While scholarship has largely focused on the military applications of AI, the growing adoption of genAI technologies may have major implications for how wars are portrayed, remembered, and interpreted. A few initial scholarly inquiries highlight the risks of genAI in this context, specifically regarding its potential to distort the representation of mass violence, particularly by sanitising and homogenising it. However, little is known about how genAI representation practices vary between different episodes of violence portrayed by Western and non-Western genAI models. Using the Russian aggression against Ukraine as a case study, we audit how two image-generative models, the US-based Midjourney and the Russia-based Kandinsky, represent both fictional and factual episodes of the war. We then analyse the models' responsiveness to the war-related prompts, together with the aesthetic and content-based aspects of the resulting images. Our findings highlight that contextual factors lead to variation in the representation of war, both between models and within the outputs of the same model. However, there are some consistent patterns of representation that may contribute to the homogenization of war aesthetics.

</details>


### [18] [When Does Regulation by Insurance Work? The Case of Frontier AI](https://arxiv.org/abs/2512.06597)
*Cristian Trout*

Main category: cs.CY

TL;DR: 本文提出了一个评估保险对风险监管影响的框架，指出在某些条件下保险可以产生净监管效应而非道德风险，并以AI行业为例进行了应用分析。


<details>
  <summary>Details</summary>
Motivation: 关于"保险监管"的争论一直存在，支持者和反对者都记录了保险成功或失败产生净监管效应的案例。本文旨在收集这些案例并结合经济学文献，建立一个原则性框架来评估保险在特定情境下的监管效果。

Method: 收集保险监管效应的案例，结合广泛的经济学文献，开发一个评估保险监管效果的原则性框架。该框架考虑多种扭曲因素（如责任限制、竞争动态、行为偏差），并分析政策持有人类型、风险类型、保险公司类型和保险市场结构的影响。

Result: 分析表明，在存在某些扭曲（如责任限制、竞争动态、行为偏差）的情况下，保险具有产生净监管效应的潜力。这种潜力的实现程度取决于政策持有人类型、风险类型、保险公司类型和保险市场结构。对于灾难性非产品事故，保险监管可能特别有效。

Conclusion: 保险监管可以在特定条件下有效减少危害，特别是在灾难性非产品事故领域。以AI行业为例，框架揭示了显著的净监管效应潜力，但需要政策干预来实现这种潜力。一个可行的方案是设计精心制定的强制保险，鼓励形成专业保险公司或互助组织，专注于灾难性风险而非常规风险，并禁止纯粹的专属保险公司。

Abstract: No one doubts the utility of insurance for its ability to spread risk or streamline claims management; much debated is when and how insurance uptake can improve welfare by reducing harm, despite moral hazard. Proponents and dissenters of "regulation by insurance" have now documented a number of cases of insurers succeeding or failing to have such a net regulatory effect (in contrast with a net hazard effect). Collecting these examples together and drawing on an extensive economics literature, this Article develops a principled framework for evaluating insurance uptake's effect in a given context. The presence of certain distortions - including judgment-proofness, competitive dynamics, and behavioral biases - creates potential for a net regulatory effect. How much of that potential gets realized then depends on the type of policyholder, type of risk, type of insurer, and the structure of the insurance market. The analysis suggests regulation by insurance can be particularly effective for catastrophic non-product accidents where market mechanisms provide insufficient discipline and psychological biases are strongest. As a demonstration, the framework is applied to the frontier AI industry, revealing significant potential for a net regulatory effect but also the need for policy intervention to realize that potential. One option is a carefully designed mandate that encourages forming a specialized insurer or mutual, focuses on catastrophic rather than routine risks, and bars pure captives.

</details>


### [19] [IyaCare: An Integrated AI-IoT-Blockchain Platform for Maternal Health in Resource-Constrained Settings](https://arxiv.org/abs/2512.07333)
*Oche D. Ankeli,Marvin M. Ogore*

Main category: cs.CY

TL;DR: IyaCare是一个为撒哈拉以南非洲资源匮乏地区设计的集成数字健康平台，结合了AI预测、IoT监测和区块链安全记录管理，在可行性研究中展示了85.2%的高危妊娠预测准确率。


<details>
  <summary>Details</summary>
Motivation: 撒哈拉以南非洲地区孕产妇死亡率极高，占全球死亡人数的70%，而人口仅占17%。现有的数字健康干预措施通常孤立部署AI、IoT和区块链技术，错失了协同增效的机会。

Method: 开发了IyaCare概念验证平台，采用Next.js前端、Firebase后端、以太坊区块链架构和基于XGBoost的AI模型（使用孕产妇健康数据集训练）。平台包括预测风险评估、持续生命体征监测和安全健康记录管理功能。

Result: 可行性研究显示：高危妊娠预测准确率达到85.2%，区块链数据完整性得到验证。平台创新包括离线优先功能和基于SMS的社区卫生工作者通信。

Conclusion: 虽然存在依赖合成验证数据和模拟医疗环境的局限性，但结果证实了融合数字健康解决方案的技术可行性和潜在影响。这项工作为资源匮乏地区的集成孕产妇健康平台提供了可复制的架构模型，有助于推进SDG 3.1目标的实现。

Abstract: Maternal mortality in Sub-Saharan Africa remains critically high, accounting for 70% of global deaths despite representing only 17% of the world population. Current digital health interventions typically deploy artificial intelligence (AI), Internet of Things (IoT), and blockchain technologies in isolation, missing synergistic opportunities for transformative healthcare delivery. This paper presents IyaCare, a proof-of-concept integrated platform that combines predictive risk assessment, continuous vital sign monitoring, and secure health records management specifically designed for resource-constrained settings. We developed a web-based system with Next.js frontend, Firebase backend, Ethereum blockchain architecture, and XGBoost AI models trained on maternal health datasets. Our feasibility study demonstrates 85.2% accuracy in high-risk pregnancy prediction and validates blockchain data integrity, with key innovations including offline-first functionality and SMS-based communication for community health workers. While limitations include reliance on synthetic validation data and simulated healthcare environments, results confirm the technical feasibility and potential impact of converged digital health solutions. This work contributes a replicable architectural model for integrated maternal health platforms in low-resource settings, advancing progress toward SDG 3.1 targets.

</details>


### [20] [Artificial Intelligence and Nuclear Weapons Proliferation: The Technological Arms Race for (In)visibility](https://arxiv.org/abs/2512.07487)
*David M. Allison,Stephen Herzog*

Main category: cs.CY

TL;DR: 论文分析了新兴技术如何重塑核扩散风险，重点关注人工智能驱动的核扩散技术(PETs)与探测技术(DETs)之间的技术军备竞赛，提出了量化相对优势的模型来评估核扩散风险。


<details>
  <summary>Details</summary>
Motivation: 现有核不扩散机制虽然有效，但新兴颠覆性技术正在改变核风险格局。人工智能等技术加速了核扩散技术的发展，同时挑战了传统监测方法，需要新的分析框架来理解这一动态。

Method: 开发了基于相对优势指数(RAI)的形式模型，量化PETs和DETs之间的平衡变化。通过可复现的情景模拟，分析不对称技术进步（特别是AI驱动的PETs增长与逐步的DETs改进）对核扩散可探测性不确定性的影响。

Result: 模型显示，AI驱动的PETs快速增长与逐步的DETs改进之间的不对称技术进步扩大了核扩散可探测性的不确定性范围。模拟表明，PETs增长率变化和DETs投资策略会影响累积核突破风险。

Conclusion: 核扩散战略模式将越来越受这些领域创新速度的影响。仅靠探测可能不再足够，需要更广泛的PET治理。政府和国际组织应投资于足够灵活的政策和工具，以跟上未来技术发展的步伐。

Abstract: A robust nonproliferation regime has contained the spread of nuclear weapons to just nine states. Yet, emerging and disruptive technologies are reshaping the landscape of nuclear risks, presenting a critical juncture for decision makers. This article lays out the contours of an overlooked but intensifying technological arms race for nuclear (in)visibility, driven by the interplay between proliferation-enabling technologies (PETs) and detection-enhancing technologies (DETs). We argue that the strategic pattern of proliferation will be increasingly shaped by the innovation pace in these domains. Artificial intelligence (AI) introduces unprecedented complexity to this equation, as its rapid scaling and knowledge substitution capabilities accelerate PET development and challenge traditional monitoring and verification methods. To analyze this dynamic, we develop a formal model centered on a Relative Advantage Index (RAI), quantifying the shifting balance between PETs and DETs. Our model explores how asymmetric technological advancement, particularly logistic AI-driven PET growth versus stepwise DET improvements, expands the band of uncertainty surrounding proliferation detectability. Through replicable scenario-based simulations, we evaluate the impact of varying PET growth rates and DET investment strategies on cumulative nuclear breakout risk. We identify a strategic fork ahead, where detection may no longer suffice without broader PET governance. Governments and international organizations should accordingly invest in policies and tools agile enough to keep pace with tomorrow's technology.

</details>


### [21] [Reliable agent engineering should integrate machine-compatible organizational principles](https://arxiv.org/abs/2512.07665)
*R. Patrick Xian,Garry A. Gabison,Ahmed Alaa,Christoph Riedl,Grigorios G. Chrysos*

Main category: cs.CY

TL;DR: 论文探讨如何借鉴组织科学理论来提升LLM智能体的可靠性，提出通过平衡智能体设计、扩展和管理中的关键因素来实现可靠有效的AI系统。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的AI智能体在社会中日益普及，协调、控制、委托和问责等问题与可靠性担忧交织在一起。需要设计可靠的LLM智能体操作，考虑任务复杂性，减少限制，最小化失败并优化资源效率。

Method: 研究LLM智能体与组织科学框架的相似性，借鉴组织设计、扩展和管理的经验，提出三个组织原则：平衡智能体设计中的自主性与能力，平衡扩展中的资源约束与性能收益，平衡管理中的内部与外部机制。

Result: 提出了三个初步的组织原则框架，用于指导AI智能体工程实现可靠性和有效性，扩展了AI系统与社会系统在操作和治理原则方面的交流。

Conclusion: 通过借鉴组织科学的理论和实践，可以为LLM智能体的可靠性设计提供有价值的指导，促进AI系统与社会系统的更好整合。

Abstract: As AI agents built on large language models (LLMs) become increasingly embedded in society, issues of coordination, control, delegation, and accountability are entangled with concerns over their reliability. To design and implement LLM agents around reliable operations, we should consider the task complexity in the application settings and reduce their limitations while striving to minimize agent failures and optimize resource efficiency. High-functioning human organizations have faced similar balancing issues, which led to evidence-based theories that seek to understand their functioning strategies. We examine the parallels between LLM agents and the compatible frameworks in organization science, focusing on what the design, scaling, and management of organizations can inform agentic systems towards improving reliability. We offer three preliminary accounts of organizational principles for AI agent engineering to attain reliability and effectiveness, through balancing agency and capabilities in agent design, resource constraints and performance benefits in agent scaling, and internal and external mechanisms in agent management. Our work extends the growing exchanges between the operational and governance principles of AI systems and social systems to facilitate system integration.

</details>


### [22] [LLM Use for Mental Health: Crowdsourcing Users' Sentiment-based Perspectives and Values from Social Discussions](https://arxiv.org/abs/2512.07797)
*Lingyao Li,Xiaoshan Huang,Renkai Ma,Ben Zefeng Zhang,Haolun Wu,Fan Yang,Chen Chen*

Main category: cs.CY

TL;DR: 本文通过分析社交媒体上用户与LLM聊天机器人在心理健康支持方面的互动讨论，发现使用效果具有条件特异性，并提出了从"一刀切"设计转向条件特异性、价值敏感设计的建议。


<details>
  <summary>Details</summary>
Motivation: 随着ChatGPT等大型语言模型聊天机器人越来越多地用于心理健康支持，虽然提供了可访问的治疗支持，但也引发了关于错误信息、过度依赖以及在心理健康高风险情境下的风险担忧。需要了解用户如何讨论与LLM聊天机器人的互动，特别是在不同心理健康状况下的体验。

Method: 从六个主要社交媒体平台众包大规模用户帖子，通过基于价值敏感设计(VSD)的LLM辅助分析流程，映射用户报告的情感、心理健康状况、观点和价值观之间的关系。

Result: LLM聊天机器人的使用具有条件特异性：神经多样性状况(如ADHD、ASD)用户报告强烈积极情感和工具性或评估性支持，而高风险障碍(如精神分裂症、双相情感障碍)则显示更多负面情感。用户观点与身份认同、自主性和隐私等潜在价值观共同出现。

Conclusion: 需要从"一刀切"的聊天机器人设计转向条件特异性、价值敏感的LLM设计，考虑不同心理健康状况用户的特定需求和价值观，以提供更有效、安全的心理健康支持。

Abstract: Large language models (LLMs) chatbots like ChatGPT are increasingly used for mental health support. They offer accessible, therapeutic support but also raise concerns about misinformation, over-reliance, and risks in high-stakes contexts of mental health. We crowdsource large-scale users' posts from six major social media platforms to examine how people discuss their interactions with LLM chatbots across different mental health conditions. Through an LLM-assisted pipeline grounded in Value-Sensitive Design (VSD), we mapped the relationships across user-reported sentiments, mental health conditions, perspectives, and values. Our results reveal that the use of LLM chatbots is condition-specific. Users with neurodivergent conditions (e.g., ADHD, ASD) report strong positive sentiments and instrumental or appraisal support, whereas higher-risk disorders (e.g., schizophrenia, bipolar disorder) show more negative sentiments. We further uncover how user perspectives co-occur with underlying values, such as identity, autonomy, and privacy. Finally, we discuss shifting from "one-size-fits-all" chatbot design toward condition-specific, value-sensitive LLM design.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [23] [Enhancing Urban Sensing Utility with Sensor-enabled Vehicles and Easily Accessible Data](https://arxiv.org/abs/2512.07124)
*Hui Zhong,Qing-Long Lu,Qiming Zhang,Hongliang Lu,Xinhu Zheng*

Main category: cs.ET

TL;DR: 本文提出了一种自适应框架，通过集成异构开源数据并利用时空加权优化车辆选择和感知覆盖，开发了基于熵的车辆选择策略Improved OptiFleet，在真实空气质量数据验证中比基线策略提供高达5%的感知效用提升。


<details>
  <summary>Details</summary>
Motivation: 城市感知对智慧城市发展至关重要，现代车辆正从单纯的移动工具转变为有价值的城市数据收集传感器。然而，优化感知策略以平衡时空覆盖、最小化冗余并解决预算约束仍然是一个关键挑战。

Method: 提出自适应框架增强传感器车辆的感知效用，集成异构开源数据，利用时空加权优化不同城市背景下的车辆选择和感知覆盖，开发基于熵的车辆选择策略Improved OptiFleet以最大化感知效用同时最小化冗余。

Result: 使用广州320辆传感器车辆两个月真实空气质量数据进行验证，结果显示该方法优于基线策略，在减少车队规模的同时提供高达5%的感知效用提升，并突显动态城市数据在优化移动感知策略中的关键作用。

Conclusion: 提出的自适应框架和Improved OptiFleet策略能有效优化车辆感知效用，为智慧城市中的移动感知提供了实用解决方案，证明了动态城市数据集成在优化感知策略中的重要性。

Abstract: Urban sensing is essential for the development of smart cities, enabling monitoring, computing, and decision-making for urban management.Thanks to the advent of vehicle technologies, modern vehicles are transforming from solely mobility tools to valuable sensors for urban data collection, and hold the potential of improving traffic congestion, transport sustainability, and infrastructure inspection.Vehicle-based sensing is increasingly recognized as a promising technology due to its flexibility, cost-effectiveness, and extensive spatiotemporal coverage. However, optimizing sensing strategies to balance spatial and temporal coverage, minimize redundancy, and address budget constraints remains a key challenge.This study proposes an adaptive framework for enhancing the sensing utility of sensor-equipped vehicles.By integrating heterogeneous open-source data, the framework leverages spatiotemporal weighting to optimize vehicle selection and sensing coverage across various urban contexts.An entropy-based vehicle selection strategy, \texttt{Improved OptiFleet}, is developed to maximize sensing utility while minimizing redundancy.The framework is validated using real-world air quality data from 320 sensor-equipped vehicles operating in Guangzhou, China, over two months.Key findings show that the proposed method outperforms baseline strategies, providing up to 5\% higher sensing utility with reduced fleet sizes, and also highlights the critical role of dynamic urban data in optimizing mobile sensing strategies.

</details>


### [24] [DBMC-aNOMAly: Asynchronous NOMA with Pilot-Symbol Optimization Protocol for Diffusion-Based Molecular Communication Networks](https://arxiv.org/abs/2512.07317)
*Alexander Wietfeld,Wolfgang Kellerer*

Main category: cs.ET

TL;DR: 本文提出DBMC-aNOMAly协议，用于优化异步分子通信网络中的非正交多址接入参数，降低误码率，并通过化学反应网络实现。


<details>
  <summary>Details</summary>
Motivation: 在未来的扩散式分子通信网络中，多址接入方案能实现多节点协作。非正交多址接入是一种有前景的高效方案，但需要解决参数优化和误码率降低问题，特别是在异步网络中。

Method: 首先解析推导误码率，并与时分多址、分子分多址等方案比较。提出DBMC-aNOMAly协议，这是一种基于导频符号的优化协议，使用蒙特卡洛模拟评估，协议设计简单操作（比较和加法）以便用化学反应网络实现。

Result: 研究表明异步特性可被利用以获得性能增益，通过避免最差偏移配置可达到上限性能。DBMC-aNOMAly协议在不同网络规模、噪声水平、采样抖动和运行时条件变化下都能提供稳健的误码率降低效果。

Conclusion: DBMC-aNOMAly协议能有效优化异步扩散式分子通信网络的非正交多址接入性能，其简单设计为未来用化学反应网络实现协议的现实建模奠定了基础。

Abstract: Multiple access (MA) schemes can enable cooperation between multiple nodes in future diffusion-based molecular communication (DBMC) networks. Non-orthogonal MA for DBMC networks (DBMC-NOMA) is a promising option for efficient simultaneous MA using a single molecule type. Expanding significantly upon previous work on the topic, this paper addresses the question of parameter optimization and bit error probability (BEP) reduction in an asynchronous network using DBMC-NOMA. First, we analytically derive the associated BEP and use the result for a thorough comparison with other MA schemes like time-division and molecule-division MA. We show that the asynchronous nature of the system can be exploited for performance gain, and the upper-bound performance can be achieved in all circumstances by avoiding a few worst-case offset configurations. Subsequently, we propose DBMC-aNOMAly, a pilot-symbol-based optimization protocol for asynchronous DBMC-NOMA, and extensively evaluate it using Monte-Carlo simulations. DBMC-aNOMAly is shown to provide robust BEP reduction for different network sizes, noise levels, subjected to sampling jitter, as well as for changing conditions during runtime, particularly, compared to protocols in previous work. DBMC-aNOMAly consists of a set of simple operations such as comparisons and additions, deliberately designed to be implementable with chemical reaction networks, setting up future work on the realistic modeling of the protocol.

</details>


### [25] [The Native Spiking Microarchitecture: From Iontronic Primitives to Bit-Exact FP8 Arithmetic](https://arxiv.org/abs/2512.07724)
*Zhengzheng Tang*

Main category: cs.ET

TL;DR: 提出原生脉冲微架构，解决MOF材料随机离子特性与AI确定性浮点计算之间的悖论，实现FP8精度100%对齐PyTorch，线性层延迟降至O(log N)


<details>
  <summary>Details</summary>
Motivation: MOF材料具有原生脉冲动力学特性，但其随机、模拟性质与AI确定性、比特精确计算需求存在矛盾。现有神经形态方法多为近似计算，无法满足Transformer精度要求。

Method: 提出原生脉冲微架构，将噪声神经元视为逻辑原语，引入空间组合流水线和粘性额外校正机制，处理随机离子到确定性浮点的转换。

Result: 在全部16,129个FP8数对验证中实现100%比特精确对齐PyTorch；线性层延迟降至O(log N)，获得17倍加速；物理仿真显示对极端膜泄漏（β≈0.01）具有鲁棒性。

Conclusion: 该架构成功弥合MOF材料随机特性与AI确定性计算之间的鸿沟，为后硅时代计算提供可行解决方案，实现硬件随机性的有效免疫。

Abstract: The 2025 Nobel Prize in Chemistry for Metal-Organic Frameworks (MOFs) and recent breakthroughs by Huanting Wang's team at Monash University establish angstrom-scale channels as promising post-silicon substrates with native integrate-and-fire (IF) dynamics. However, utilizing these stochastic, analog materials for deterministic, bit-exact AI workloads (e.g., FP8) remains a paradox. Existing neuromorphic methods often settle for approximation, failing Transformer precision standards. To traverse the gap "from stochastic ions to deterministic floats," we propose a Native Spiking Microarchitecture. Treating noisy neurons as logic primitives, we introduce a Spatial Combinational Pipeline and a Sticky-Extra Correction mechanism. Validation across all 16,129 FP8 pairs confirms 100% bit-exact alignment with PyTorch. Crucially, our architecture reduces Linear layer latency to O(log N), yielding a 17x speedup. Physical simulations further demonstrate robustness against extreme membrane leakage (beta approx 0.01), effectively immunizing the system against the stochastic nature of the hardware.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [26] [Going All-In on LLM Accuracy: Fake Prediction Markets, Real Confidence Signals](https://arxiv.org/abs/2512.05998)
*Michael Todasco*

Main category: cs.AI

TL;DR: 通过虚构预测市场让LLM下注评估其他模型，虽然准确率提升不显著，但下注金额能有效反映模型置信度，为LLM元评估提供新方法。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估其他模型时缺乏置信度表示，需要一种方法让LLM的预测不仅准确，还能反映其内部置信水平。

Method: 创建100个数学逻辑问题，让6个基线模型回答，3个预测模型在两种条件下预测基线模型回答正确性：控制组（简单预测）和激励组（预测+下注1-100,000 LLMCoin）。

Result: 激励组准确率略高（81.5% vs 79.1%），学习速度显著更快。下注金额与置信度高度相关：大额下注（40,000+硬币）正确率约99%，小额下注（<1,000硬币）正确率仅74%。

Conclusion: 虚构货币框架虽未显著提升准确率，但成功创建了可读的置信度信号，为LLM元评估系统和LLM间预测市场奠定基础。

Abstract: Large language models are increasingly used to evaluate other models, yet these judgments typically lack any representation of confidence. This pilot study tests whether framing an evaluation task as a betting game (a fictional prediction market with its own LLM currency) improves forecasting accuracy and surfaces calibrated confidence signals. We generated 100 math and logic questions with verifiable answers. Six Baseline models (three current-generation, three prior-generation) answered all items. Three Predictor models then forecasted, for each question-baseline pair, if the baseline would answer correctly. Each predictor completed matched runs in two conditions: Control (simple correct/incorrect predictions) and Incentive (predictions plus wagers of 1-100,000 LLMCoin under even odds, starting from a 1,000,000 LLMCoin bankroll). Across 5,400 predictions per condition, Incentive runs showed modestly higher accuracy (81.5% vs. 79.1%, p = .089, d = 0.86) and significantly faster learning across rounds (12.0 vs. 2.9 percentage-point improvement from Round 1 to Round 4, p = .011). Most notably, stake size tracked confidence. "Whale" bets of 40,000+ coins were correct ~99% of the time, while small bets (<1,000 coins) showed only ~74% accuracy. The key finding is not that fictional money makes models smarter; accuracy gains were modest and did not reach statistical significance (p = .089) in this pilot. Rather, the betting mechanic created a legible confidence signal absent from binary yes/no outputs. This suggests that simple financial framing may help transform LLMs into risk-aware forecasters, making their internal beliefs visible and usable. The protocol offers a foundation for future work for meta-evaluation systems and what may become LLM-to-LLM prediction markets.

</details>


### [27] [Deep learning for autism detection using clinical notes: A comparison of transfer learning for a transparent and black-box approach](https://arxiv.org/abs/2512.06161)
*Gondy Leroy,Prakash Bisht,Sai Madhuri Kandula,Nell Maltman,Sydney Rice*

Main category: cs.AI

TL;DR: 提出基于BioBERT的可解释机器学习方法，通过分析临床文本来诊断自闭症谱系障碍，在混合数据集训练下达到97%敏感性和98%特异性，优于黑盒模型。


<details>
  <summary>Details</summary>
Motivation: 自闭症谱系障碍诊断需求日益增长，现有机器学习模型多为黑盒且通常基于单一数据集训练，限制了其可解释性和泛化能力。

Method: 使用BioBERT语言模型分析非结构化临床文本，训练模型标记行为描述并映射到诊断标准，然后分配最终标签（ASD或非ASD）。评估了迁移学习能力，比较了顺序训练和混合训练策略。

Result: 透明模型表现稳健，混合数据训练策略效果最佳（敏感性97%，特异性98%）。顺序训练导致性能略有下降。黑盒模型表现较差（敏感性90%，特异性96%）。透明方法整体优于黑盒方法。

Conclusion: 透明可解释的机器学习方法在自闭症诊断中优于黑盒模型，混合数据集训练能获得更好性能，为神经发育诊断领域开发更可信、可泛化、临床可操作的AI工具铺平道路。

Abstract: Autism spectrum disorder (ASD) is a complex neurodevelopmental condition whose rising prevalence places increasing demands on a lengthy diagnostic process. Machine learning (ML) has shown promise in automating ASD diagnosis, but most existing models operate as black boxes and are typically trained on a single dataset, limiting their generalizability. In this study, we introduce a transparent and interpretable ML approach that leverages BioBERT, a state-of-the-art language model, to analyze unstructured clinical text. The model is trained to label descriptions of behaviors and map them to diagnostic criteria, which are then used to assign a final label (ASD or not). We evaluate transfer learning, the ability to transfer knowledge to new data, using two distinct real-world datasets. We trained on datasets sequentially and mixed together and compared the performance of the best models and their ability to transfer to new data. We also created a black-box approach and repeated this transfer process for comparison. Our transparent model demonstrated robust performance, with the mixed-data training strategy yielding the best results (97 % sensitivity, 98 % specificity). Sequential training across datasets led to a slight drop in performance, highlighting the importance of training data order. The black-box model performed worse (90 % sensitivity, 96 % specificity) when trained sequentially or with mixed data. Overall, our transparent approach outperformed the black-box approach. Mixing datasets during training resulted in slightly better performance and should be the preferred approach when practically possible. This work paves the way for more trustworthy, generalizable, and clinically actionable AI tools in neurodevelopmental diagnostics.

</details>


### [28] [ARCANE: A Multi-Agent Framework for Interpretable and Configurable Alignment](https://arxiv.org/abs/2512.06196)
*Charlie Masters,Marta Grześkiewicz,Stefano V. Albrecht*

Main category: cs.AI

TL;DR: ARCANE框架将AI对齐问题转化为多智能体协作，通过动态生成自然语言评分标准来代表利益相关者偏好，实现可解释、无需重新训练即可调整的对齐。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的智能体越来越多地部署到长期任务中，保持它们与利益相关者偏好的一致性变得至关重要。需要可解释的奖励模型让利益相关者能够理解和审计模型目标，并且能够在交互时引导智能体，无需重新训练就能适应偏好变化。

Method: ARCANE框架将对齐问题构建为多智能体协作问题，动态地将利益相关者偏好表示为自然语言评分标准（可验证的加权标准集合）。采用正则化的组序列策略优化（GSPO）程序来平衡可解释性、忠实度和计算效率。

Result: 在GDPVal基准的219个标注评分标准语料库上评估，ARCANE在需要多步推理和工具使用的挑战性任务上表现良好。学习的评分标准产生紧凑、易读的评估，并支持可配置的权衡（如正确性与简洁性）而无需重新训练。

Conclusion: 基于评分标准的奖励模型为复杂、长期AI系统提供了一条有前景的可解释、测试时自适应对齐路径。

Abstract: As agents based on large language models are increasingly deployed to long-horizon tasks, maintaining their alignment with stakeholder preferences becomes critical. Effective alignment in such settings requires reward models that are interpretable so that stakeholders can understand and audit model objectives. Moreover, reward models must be capable of steering agents at interaction time, allowing preference shifts to be incorporated without retraining. We introduce ARCANE, a framework that frames alignment as a multi-agent collaboration problem that dynamically represents stakeholder preferences as natural-language rubrics: weighted sets of verifiable criteria that can be generated on-the-fly from task context. Inspired by utility theory, we formulate rubric learning as a reconstruction problem and apply a regularized Group-Sequence Policy Optimization (GSPO) procedure that balances interpretability, faithfulness, and computational efficiency. Using a corpus of 219 labeled rubrics derived from the GDPVal benchmark, we evaluate ARCANE on challenging tasks requiring multi-step reasoning and tool use. The learned rubrics produce compact, legible evaluations and enable configurable trade-offs (e.g., correctness vs. conciseness) without retraining. Our results show that rubric-based reward models offer a promising path toward interpretable, test-time adaptive alignment for complex, long-horizon AI systems.

</details>


### [29] [On measuring grounding and generalizing grounding problems](https://arxiv.org/abs/2512.06205)
*Daniel Quigley,Eric Maynard*

Main category: cs.AI

TL;DR: 该论文将符号接地问题重新构建为一个包含多个评估维度的审计框架，包括真实性、保持性、忠实性、鲁棒性和组合性，并应用于不同接地模式的分析。


<details>
  <summary>Details</summary>
Motivation: 解决符号接地问题——即符号如何与现实世界实体建立联系，而不仅仅是形式系统中的形状操作。传统二元判断不足以全面评估符号接地，需要更系统的分析框架。

Method: 提出一个基于评估元组（上下文、意义类型、威胁模型、参考分布）的多维度审计框架，包含五个核心要求：真实性、保持性、忠实性（相关性和病因性）、鲁棒性、组合性。将此框架应用于四种接地模式（符号、指称、向量、关系）和三个案例研究。

Result: 分析发现：模型论语义学实现精确组合但缺乏病因性保证；大语言模型在语言任务上显示相关性拟合和局部鲁棒性，但在无接地交互的世界任务上缺乏成功选择；人类语言通过进化和发育获得满足强真实性要求。

Conclusion: 通过将哲学表征问题操作化，为科学哲学家、计算机科学家、语言学家和数学家提供了一个共同语言和技术框架，用于系统研究接地和意义问题，超越了传统的二元判断方法。

Abstract: The symbol grounding problem asks how tokens like cat can be about cats, as opposed to mere shapes manipulated in a calculus. We recast grounding from a binary judgment into an audit across desiderata, each indexed by an evaluation tuple (context, meaning type, threat model, reference distribution): authenticity (mechanisms reside inside the agent and, for strong claims, were acquired through learning or evolution); preservation (atomic meanings remain intact); faithfulness, both correlational (realized meanings match intended ones) and etiological (internal mechanisms causally contribute to success); robustness (graceful degradation under declared perturbations); compositionality (the whole is built systematically from the parts). We apply this framework to four grounding modes (symbolic; referential; vectorial; relational) and three case studies: model-theoretic semantics achieves exact composition but lacks etiological warrant; large language models show correlational fit and local robustness for linguistic tasks, yet lack selection-for-success on world tasks without grounded interaction; human language meets the desiderata under strong authenticity through evolutionary and developmental acquisition. By operationalizing a philosophical inquiry about representation, we equip philosophers of science, computer scientists, linguists, and mathematicians with a common language and technical framework for systematic investigation of grounding and meaning.

</details>


### [30] [AI Application in Anti-Money Laundering for Sustainable and Transparent Financial Systems](https://arxiv.org/abs/2512.06240)
*Chuanhao Nie,Yunbo Liu,Chao Wang*

Main category: cs.AI

TL;DR: 本文综述了AI在反洗钱(AML)中的应用，提出基于图检索增强生成(RAG-Graph)的KYC系统，提高检测准确性和透明度。


<details>
  <summary>Details</summary>
Motivation: 洗钱和金融欺诈威胁全球金融稳定，传统AML系统存在检测精度低、误报率高、人工调查负担重等问题，需要AI技术进行现代化改造。

Method: 1. 综述AI在AML中的应用现状；2. 提出基于图检索增强生成(RAG-Graph)的AI驱动KYC应用，整合图结构和生成模型；3. 探索联邦学习、公平可解释AI、强化学习等未来方向。

Result: RAG-Graph架构在多样评估场景中展现出高忠实度和强答案相关性，显著提升KYC客户尽职调查/增强尽职调查(CDD/EDD)流程的效率和透明度。

Conclusion: AI技术能够现代化AML工作流，提高检测准确性、降低误报率、减轻操作负担。RAG-Graph等创新架构为实现透明、可问责、稳健的下一代AML系统提供了可行路径，促进可持续合规实践。

Abstract: Money laundering and financial fraud remain major threats to global financial stability, costing trillions annually and challenging regulatory oversight. This paper reviews how artificial intelligence (AI) applications can modernize Anti-Money Laundering (AML) workflows by improving detection accuracy, lowering false-positive rates, and reducing the operational burden of manual investigations, thereby supporting more sustainable development. It further highlights future research directions including federated learning for privacy-preserving collaboration, fairness-aware and interpretable AI, reinforcement learning for adaptive defenses, and human-in-the-loop visualization systems to ensure that next-generation AML architectures remain transparent, accountable, and robust. In the final part, the paper proposes an AI-driven KYC application that integrates graph-based retrieval-augmented generation (RAG Graph) with generative models to enhance efficiency, transparency, and decision support in KYC processes related to money-laundering detection. Experimental results show that the RAG-Graph architecture delivers high faithfulness and strong answer relevancy across diverse evaluation settings, thereby enhancing the efficiency and transparency of KYC CDD/EDD workflows and contributing to more sustainable, resource-optimized compliance practices.

</details>


### [31] [How Sharp and Bias-Robust is a Model? Dual Evaluation Perspectives on Knowledge Graph Completion](https://arxiv.org/abs/2512.06296)
*Sooho Moon,Yunyong Ko*

Main category: cs.AI

TL;DR: PROBE：一个新的知识图谱补全评估框架，通过考虑预测锐度（A1）和流行度偏差鲁棒性（A2）来提供更全面的模型评估。


<details>
  <summary>Details</summary>
Motivation: 现有KGC评估指标存在两个关键问题：1）忽视了预测锐度（对单个预测的严格程度评估）；2）缺乏对流行度偏差的鲁棒性（预测低流行度实体的能力）。这导致现有指标可能高估或低估KGC模型的准确性。

Method: 提出PROBE评估框架，包含两个核心组件：1）秩转换器（RT）根据所需的预测锐度级别估计每个预测的分数；2）秩聚合器（RA）以流行度感知的方式聚合所有分数。

Result: 在真实世界知识图谱上的实验表明，现有指标倾向于高估或低估KGC模型的准确性，而PROBE能够提供对KGC模型的全面理解和可靠的评估结果。

Conclusion: PROBE框架通过同时考虑预测锐度和流行度偏差鲁棒性，为知识图谱补全提供了更全面、更可靠的评估方法，有助于更准确地理解KGC模型的性能。

Abstract: Knowledge graph completion (KGC) aims to predict missing facts from the observed KG. While a number of KGC models have been studied, the evaluation of KGC still remain underexplored. In this paper, we observe that existing metrics overlook two key perspectives for KGC evaluation: (A1) predictive sharpness -- the degree of strictness in evaluating an individual prediction, and (A2) popularity-bias robustness -- the ability to predict low-popularity entities. Toward reflecting both perspectives, we propose a novel evaluation framework (PROBE), which consists of a rank transformer (RT) estimating the score of each prediction based on a required level of predictive sharpness and a rank aggregator (RA) aggregating all the scores in a popularity-aware manner. Experiments on real-world KGs reveal that existing metrics tend to over- or under-estimate the accuracy of KGC models, whereas PROBE yields a comprehensive understanding of KGC models and reliable evaluation results.

</details>


### [32] [DaGRPO: Rectifying Gradient Conflict in Reasoning via Distinctiveness-Aware Group Relative Policy Optimization](https://arxiv.org/abs/2512.06337)
*Xuan Xie,Xuan Wang,Wenjie Wang*

Main category: cs.AI

TL;DR: DaGRPO通过序列级梯度修正和离策略数据增强解决GRPO训练不稳定和样本效率低的问题，在数学推理和OOD基准上实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: GRPO在激发LLM后训练推理能力方面表现出色，但存在训练不稳定和样本效率低的问题。研究发现根本原因在于on-policy rollouts缺乏区分度：常规查询中高度同质化样本导致破坏性梯度冲突，而困难查询中有效正样本稀缺导致优化无效。

Method: 提出Distinctiveness-aware Group Relative Policy Optimization (DaGRPO)，包含两个核心机制：1) 序列级梯度修正：利用细粒度评分动态屏蔽低区分度的样本对，从源头消除梯度冲突；2) 离策略数据增强：引入高质量锚点恢复困难任务的训练信号。

Result: 在9个数学推理和OOD泛化基准上的广泛实验表明，DaGRPO显著超越现有SFT、GRPO和混合基线，实现新的SOTA性能（例如在数学基准上平均准确率提升+4.7%）。深入分析证实DaGRPO有效缓解梯度爆炸并加速长链推理能力的出现。

Conclusion: DaGRPO通过解决GRPO的区分度问题，显著提升了训练稳定性和样本效率，在数学推理和泛化任务上取得了突破性进展，为LLM的后训练推理能力优化提供了有效解决方案。

Abstract: The evolution of Large Language Models (LLMs) has catalyzed a paradigm shift from superficial instruction following to rigorous long-horizon reasoning. While Group Relative Policy Optimization (GRPO) has emerged as a pivotal mechanism for eliciting such post-training reasoning capabilities due to its exceptional performance, it remains plagued by significant training instability and poor sample efficiency. We theoretically identify the root cause of these issues as the lack of distinctiveness within on-policy rollouts: for routine queries, highly homogeneous samples induce destructive gradient conflicts; whereas for hard queries, the scarcity of valid positive samples results in ineffective optimization. To bridge this gap, we propose Distinctiveness-aware Group Relative Policy Optimization (DaGRPO). DaGRPO incorporates two core mechanisms: (1) Sequence-level Gradient Rectification, which utilizes fine-grained scoring to dynamically mask sample pairs with low distinctiveness, thereby eradicating gradient conflicts at the source; and (2) Off-policy Data Augmentation, which introduces high-quality anchors to recover training signals for challenging tasks. Extensive experiments across 9 mathematical reasoning and out-of-distribution (OOD) generalization benchmarks demonstrate that DaGRPO significantly surpasses existing SFT, GRPO, and hybrid baselines, achieving new state-of-the-art performance (e.g., a +4.7% average accuracy gain on math benchmarks). Furthermore, in-depth analysis confirms that DaGRPO effectively mitigates gradient explosion and accelerates the emergence of long-chain reasoning capabilities.

</details>


### [33] [Less Is More for Multi-Step Logical Reasoning of LLM Generalisation Under Rule Removal, Paraphrasing, and Compression](https://arxiv.org/abs/2512.06393)
*Qiming Bao,Xiaoxuan Fu*

Main category: cs.AI

TL;DR: LLMs在逻辑推理中表现出对语义保持变换的稳定性，但对缺失或矛盾证据极度脆弱


<details>
  <summary>Details</summary>
Motivation: 探究LLMs在逻辑结构扰动下的泛化能力，现有研究对其在逻辑推理中的可靠性理解不足

Method: 设计包含四种针对性压力测试的评估框架：规则删除、矛盾证据注入、逻辑保持重写、多定律等价叠加

Result: 所有模型在基础任务上准确率完美，对冗余规则删除和等价变换完全泛化，但在必要规则删除时准确率降至25%，面对矛盾证据时完全崩溃（0%）

Conclusion: LLMs对语义保持的逻辑变换具有稳定不变性，但对缺失或冲突证据保持根本性脆弱，框架为诊断推理失败模式提供工具，揭示当前LLMs逻辑泛化能力的持续差距

Abstract: Large language models (LLMs) excel across many natural language tasks, yet their generalisation to structural perturbations in logical contexts remains poorly understood. We introduce a controlled evaluation framework that probes reasoning reliability through four targeted stress tests: (1) rule deletion, removing either redundant or essential rules from a multi-step inference chain; (2) contradictory evidence injection; (3) logic-preserving rewrites generated through several families of equivalence laws (contrapositive, double negation, implication, De Morgan, identity, and commutativity); and (4) multi-law equivalence stacking that introduces 2-5 simultaneous logical transformations.
  Across three representative model families: BERT, Qwen2, and LLaMA-like models. Our experiments reveal a strikingly consistent pattern: all models achieve perfect accuracy on the base tasks and remain fully generalise to redundant rule deletion and all equivalence-based rewrites (single or multi-law), but fail sharply under essential rule deletion (dropping to 25% accuracy) and collapse completely in the presence of explicit contradictions (0% accuracy). These results demonstrate that LLMs possess stable invariance to semantic-preserving logical transformations, yet remain fundamentally brittle to missing or conflicting evidence. Our framework provides a clean diagnostic tool for isolating such reasoning failure modes and highlights persistent gaps in the logical generalisation abilities of current LLMs.

</details>


### [34] [GENIUS: An Agentic AI Framework for Autonomous Design and Execution of Simulation Protocols](https://arxiv.org/abs/2512.06404)
*Mohammad Soleymanibrojeni,Roland Aydin,Diego Guedes-Sobrinho,Alexandre C. Dias,Maurício J. Piotrowski,Wolfgang Wenzel,Celso Ricardo Caldeira Rêgo*

Main category: cs.AI

TL;DR: GENIUS是一个AI驱动的自动化工作流，将量子ESPRESSO知识图谱与分层大语言模型结合，通过有限状态错误恢复机监督，可将自然语言提示自动转换为验证过的输入文件，显著提升DFT模拟的成功率。


<details>
  <summary>Details</summary>
Motivation: 尽管预测性原子模拟推动了材料发现，但常规设置和调试仍需计算机专家，这种知识差距限制了集成计算材料工程（ICME）的发展。现有先进代码对非专家用户来说仍然繁琐，需要解决这一瓶颈。

Method: GENIUS融合了智能量子ESPRESSO知识图谱与分层大语言模型层次结构，由有限状态错误恢复机监督。该系统将自由形式的人类提示转换为验证过的输入文件，并具备自主修复能力。

Result: 在295个多样化基准测试中，约80%成功运行到完成，其中76%可自主修复。成功率呈指数衰减至7%基线。相比纯LLM基线，GENIUS将推理成本减半，几乎消除幻觉。

Conclusion: GENIUS框架通过智能自动化协议生成、验证和修复，民主化了电子结构DFT模拟，为大规模筛选和加速ICME设计循环开辟了道路，适用于全球学术界和工业界。

Abstract: Predictive atomistic simulations have propelled materials discovery, yet routine setup and debugging still demand computer specialists. This know-how gap limits Integrated Computational Materials Engineering (ICME), where state-of-the-art codes exist but remain cumbersome for non-experts. We address this bottleneck with GENIUS, an AI-agentic workflow that fuses a smart Quantum ESPRESSO knowledge graph with a tiered hierarchy of large language models supervised by a finite-state error-recovery machine. Here we show that GENIUS translates free-form human-generated prompts into validated input files that run to completion on $\approx$80% of 295 diverse benchmarks, where 76% are autonomously repaired, with success decaying exponentially to a 7% baseline. Compared with LLM-only baselines, GENIUS halves inference costs and virtually eliminates hallucinations. The framework democratizes electronic-structure DFT simulations by intelligently automating protocol generation, validation, and repair, opening large-scale screening and accelerating ICME design loops across academia and industry worldwide.

</details>


### [35] [UncertaintyZoo: A Unified Toolkit for Quantifying Predictive Uncertainty in Deep Learning Systems](https://arxiv.org/abs/2512.06406)
*Xianzong Wu,Xiaohong Li,Lili Quan,Qiang Hu*

Main category: cs.AI

TL;DR: UncertaintyZoo是一个统一的不确定性量化工具包，集成了29种UQ方法，涵盖五大类别，用于评估LLM预测的可信度，并在代码漏洞检测任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: LLM在安全关键场景中可能做出错误预测，需要量化其不确定性来评估置信度。现有UQ方法缺乏统一工具，阻碍了实际应用和研究发展。

Method: 开发UncertaintyZoo工具包，标准化集成29种不确定性量化方法，涵盖五大类别。在CodeBERT和ChatGLM3模型上进行代码漏洞检测任务评估。

Result: UncertaintyZoo能有效揭示预测不确定性，为UQ方法提供统一评估平台。工具已在GitHub开源，包含演示视频。

Conclusion: UncertaintyZoo填补了UQ方法集成工具的空白，促进了不确定性量化在实际应用和未来研究中的发展。

Abstract: Large language models(LLMs) are increasingly expanding their real-world applications across domains, e.g., question answering, autonomous driving, and automatic software development. Despite this achievement, LLMs, as data-driven systems, often make incorrect predictions, which can lead to potential losses in safety-critical scenarios. To address this issue and measure the confidence of model outputs, multiple uncertainty quantification(UQ) criteria have been proposed. However, even though important, there are limited tools to integrate these methods, hindering the practical usage of UQ methods and future research in this domain. To bridge this gap, in this paper, we introduce UncertaintyZoo, a unified toolkit that integrates 29 uncertainty quantification methods, covering five major categories under a standardized interface. Using UncertaintyZoo, we evaluate the usefulness of existing uncertainty quantification methods under the code vulnerability detection task on CodeBERT and ChatGLM3 models. The results demonstrate that UncertaintyZoo effectively reveals prediction uncertainty. The tool with a demonstration video is available on the project site https://github.com/Paddingbuta/UncertaintyZoo.

</details>


### [36] [Smart Spatial Planning in Egypt: An Algorithm-Driven Approach to Public Service Evaluation in Qena City](https://arxiv.org/abs/2512.06431)
*Mohamed Shamroukh,Mohamed Alkhuzamy Aziz*

Main category: cs.AI

TL;DR: 开发基于Voronoi图的智能空间分析算法，为埃及Qena市制定本地化规划标准模型，评估公共服务覆盖效率


<details>
  <summary>Details</summary>
Motivation: 埃及国家公共服务规划标准往往与地方独特特征不符，需要开发适应本地特点的规划模型

Method: 采用混合方法（描述性、分析性和实验性），使用Python编程开发基于Voronoi图的智能空间分析算法，生成城市特定规划标准

Result: 总体服务覆盖率为81.3%，救护车站效率最高（99.8%），公园和开放空间覆盖率最低（10%）；市中心服务密度高（>45个/km²），郊区显著降低（<5个/km²）；Hajer Qena区未服务区域最多，第一区服务覆盖率最高

Conclusion: 成功开发了本地化规划标准模型和自动化评估算法，为埃及城市提供了可复制的数据驱动城市规划框架

Abstract: National planning standards for public services in Egypt often fail to align with unique local characteristics. Addressing this gap, this study develops a tailored planning model for Qena City. Using a hybrid methodology (descriptive, analytical, and experimental), the research utilizes Python programming to generate an intelligent spatial analysis algorithm based on Voronoi Diagrams. This approach creates city-specific planning criteria and evaluates the current coverage of public facilities. The primary contribution of this study is the successful derivation of a localized planning standards model and the deployment of an automated algorithm to assess service efficiency. Application of this model reveals a general service coverage average of 81.3%. Ambulance stations demonstrated the highest efficiency (99.8%) due to recent upgrades, while parks and open spaces recorded the lowest coverage (10%) caused by limited land availability. Spatial analysis indicates a high service density in midtown (>45 services/km^2), which diminishes significantly towards the outskirts (<5 services/km^2). Consequently, the Hajer Qena district contains the highest volume of unserved areas, while the First District (Qesm 1) exhibits the highest level of service coverage. This model offers a replicable framework for data-driven urban planning in Egyptian cities.

</details>


### [37] [The Effect of Belief Boxes and Open-mindedness on Persuasion](https://arxiv.org/abs/2512.06573)
*Onur Bilgin,Abdullah As Sami,Sriram Sai Vujjini,John Licato*

Main category: cs.AI

TL;DR: 研究探索了LLM智能体中"信念箱"技术对行为的影响，发现信念陈述会影响智能体对相反观点的抵抗力和说服力，而开放心态指令会影响信念改变的倾向性。


<details>
  <summary>Details</summary>
Motivation: 随着多智能体系统在推理和决策应用中的增加，需要LLM智能体具备类似命题信念的能力。研究旨在探索信念陈述如何影响智能体行为和说服能力，以及开放心态指令的作用。

Method: 采用"信念箱"技术，在提示空间中包含描述信念的陈述。通过一系列实验，研究信念陈述及其强度如何影响智能体对相反观点的抵抗力和说服力，以及开放心态指令对信念改变倾向的影响。

Result: 开放心态指令确实影响智能体对信念改变的接受程度；信念陈述及其强度影响智能体对相反观点的抵抗力和说服力；在辩论中被相反观点包围（同侪压力场景）时，信念陈述特别影响信念改变的可能性。

Conclusion: 信念箱技术在推理和决策任务中是可行且有效的，能够影响智能体的行为倾向和说服能力，为多智能体系统中的信念建模提供了实用方法。

Abstract: As multi-agent systems are increasingly utilized for reasoning and decision-making applications, there is a greater need for LLM-based agents to have something resembling propositional beliefs. One simple method for doing so is to include statements describing beliefs maintained in the prompt space (in what we'll call their belief boxes). But when agents have such statements in belief boxes, how does it actually affect their behaviors and dispositions towards those beliefs? And does it significantly affect agents' ability to be persuasive in multi-agent scenarios? Likewise, if the agents are given instructions to be open-minded, how does that affect their behaviors? We explore these and related questions in a series of experiments. Our findings confirm that instructing agents to be open-minded affects how amenable they are to belief change. We show that incorporating belief statements and their strengths influences an agent's resistance to (and persuasiveness against) opposing viewpoints. Furthermore, it affects the likelihood of belief change, particularly when the agent is outnumbered in a debate by opposing viewpoints, i.e., peer pressure scenarios. The results demonstrate the feasibility and validity of the belief box technique in reasoning and decision-making tasks.

</details>


### [38] [FlatFormer: A Flat Transformer Knowledge Tracing Model Based on Cognitive Bias Injection](https://arxiv.org/abs/2512.06629)
*Xiao-li Xia,Hou-biao Li*

Main category: cs.AI

TL;DR: FlatFormer：一种基于"信息注入而非结构堆叠"新设计范式的轻量级知识追踪模型，通过混合输入编码和预计算幂律偏置机制，在保持高性能的同时大幅降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 知识追踪模型面临"性能-复杂度陷阱"：捕捉复杂认知动态（如学习会话和记忆衰减）通常需要深度分层架构，这导致实时部署的计算成本过高。需要一种既能保持高性能又计算高效的解决方案。

Method: 提出FlatFormer架构，采用"信息注入而非结构堆叠"设计范式。主要包含两个轻量级注入机制：1）混合输入编码策略，结合可学习会话标识符和固定正弦步长嵌入；2）预计算幂律偏置直接集成到注意力对数中，显式建模遗忘曲线。

Result: 在四个大规模数据集（如EdNet、Junyi）上的实验表明，FlatFormer达到最先进性能。在EdNet数据集上，相比最强分层基线（HiTSKT），绝对AUC提升8.3%，参数使用量不到15%，推理速度约快3倍。

Conclusion: 高认知保真度不需要架构复杂性。FlatFormer通过信息注入而非结构堆叠的设计范式，成功解决了知识追踪中的性能-复杂度权衡问题，为实时部署提供了高效解决方案。

Abstract: Knowledge Tracing (KT) models face a critical ``Performance-Complexity Trap'': capturing complex cognitive dynamics like learning sessions and memory decay typically requires deep hierarchical architectures, which incur prohibitive computational costs for real-time deployment. To resolve this, we propose FlatFormer, a streamlined architecture based on the novel design paradigm of ``Information Injection over Structural Stacking.'' Unlike parameter-heavy hierarchical models, FlatFormer leverages a standard flat Transformer augmented with two lightweight injection mechanisms: (i) a hybrid input encoding strategy combining learnable session identifiers with fixed sinusoidal step embeddings; and (ii) a pre-computed power-law bias integrated directly into attention logits to explicitly model the forgetting curve. Extensive experiments on four large-scale datasets (e.g., EdNet, Junyi) show that FlatFormer achieves state-of-the-art performance. For example, on the EdNet dataset, compared to the strongest hierarchical baseline (HiTSKT), its absolute AUC increased by 8.3%, while using less than 15% of parameters, and inference speed was about three times faster. These results validate that high cognitive fidelity does not necessitate architectural complexity.

</details>


### [39] [LightSearcher: Efficient DeepSearch via Experiential Memory](https://arxiv.org/abs/2512.06653)
*Hengzhi Lan,Yue Yu,Li Qian,Li Peng,Jie Wu,Wei Liu,Jian Luan,Ting Bai*

Main category: cs.AI

TL;DR: LightSearcher是一个高效的RL框架，通过文本经验记忆和自适应奖励机制，在保持准确性的同时显著减少DeepSearch中的工具调用次数和计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的RL驱动的DeepSearch系统存在准确性与效率之间的权衡问题：频繁调用外部搜索工具可以提高事实准确性，但会导致不必要的计算开销和效率下降。

Method: 提出了LightSearcher框架：1）通过对比学习推理轨迹生成可解释的成功推理模式摘要；2）采用自适应奖励机制，仅在正确答案场景中惩罚冗余工具调用。

Result: 在四个多跳QA基准测试中，LightSearcher保持与SOTA基线ReSearch相当的准确性，同时将搜索工具调用减少39.6%，推理时间减少48.6%，token消耗减少21.2%。

Conclusion: LightSearcher通过文本经验记忆和自适应奖励机制，有效平衡了DeepSearch范式中的准确性与效率权衡，实现了高效且准确的深度推理。

Abstract: DeepSearch paradigms have become a core enabler for deep reasoning models, allowing them to invoke external search tools to access up-to-date, domain-specific knowledge beyond parametric boundaries, thereby enhancing the depth and factual reliability of reasoning. Building upon this foundation, recent advances in reinforcement learning (RL) have further empowered models to autonomously and strategically control search tool usage, optimizing when and how to query external knowledge sources. Yet, these RL-driven DeepSearch systems often reveal a see-saw trade-off between accuracy and efficiency-frequent tool invocations can improve factual correctness but lead to unnecessary computational overhead and diminished efficiency. To address this challenge, we propose LightSearcher, an efficient RL framework that incorporates textual experiential memory by learning contrastive reasoning trajectories to generate interpretable summaries of successful reasoning patterns. In addition, it employs an adaptive reward shaping mechanism that penalizes redundant tool calls only in correct-answer scenarios. This design effectively balances the inherent accuracy-efficiency trade-off in DeepSearch paradigms. Experiments on four multi-hop QA benchmarks show that LightSearcher maintains accuracy comparable to SOTA baseline ReSearch, while reducing search tool invocations by 39.6%, inference time by 48.6%, and token consumption by 21.2%, demonstrating its superior efficiency.

</details>


### [40] [Academic journals' AI policies fail to curb the surge in AI-assisted academic writing](https://arxiv.org/abs/2512.06705)
*Yongyuan He,Yi Bu*

Main category: cs.AI

TL;DR: 期刊AI政策无效：尽管70%期刊采用AI使用指南，但研究人员AI工具使用率大幅增长，且政策有无期刊间无显著差异；透明度差距巨大，仅0.1%论文明确披露AI使用


<details>
  <summary>Details</summary>
Motivation: 评估生成式AI在学术写作中快速整合背景下，期刊和出版商AI使用政策的实际效果，了解这些政策是否真正促进了透明度或限制了AI采用

Method: 分析5,114种期刊和超过520万篇论文，评估AI使用指南的实际影响；对164,000篇科学出版物进行全文分析，特别关注2023年后发表的75,000篇论文的AI使用披露情况

Result: 1. 尽管70%期刊采用AI政策（主要要求披露），研究人员AI写作工具使用率在各学科大幅增长；2. 有政策与无政策期刊间无显著差异；3. 非英语国家、物理科学和高开放获取期刊增长最快；4. 透明度差距显著：2023年后发表的75,000篇论文中仅76篇（0.1%）明确披露AI使用

Conclusion: 当前政策基本未能促进透明度或限制AI采用，需要重新评估伦理框架以促进科学中负责任的AI整合

Abstract: The rapid integration of generative AI into academic writing has prompted widespread policy responses from journals and publishers. However, the effectiveness of these policies remains unclear. Here, we analyze 5,114 journals and over 5.2 million papers to evaluate the real-world impact of AI usage guidelines. We show that despite 70% of journals adopting AI policies (primarily requiring disclosure), researchers' use of AI writing tools has increased dramatically across disciplines, with no significant difference between journals with or without policies. Non-English-speaking countries, physical sciences, and high-OA journals exhibit the highest growth rates. Crucially, full-text analysis on 164k scientific publications reveals a striking transparency gap: Of the 75k papers published since 2023, only 76 (0.1%) explicitly disclosed AI use. Our findings suggest that current policies have largely failed to promote transparency or restrain AI adoption. We urge a re-evaluation of ethical frameworks to foster responsible AI integration in science.

</details>


### [41] [Stochasticity in Agentic Evaluations: Quantifying Inconsistency with Intraclass Correlation](https://arxiv.org/abs/2512.06710)
*Zairah Mustahsan,Abel Lim,Megna Anand,Saahil Jain,Bryan McCann*

Main category: cs.AI

TL;DR: 提出使用组内相关系数(ICC)来评估语言模型代理系统的可靠性，将方差分解为任务难度和代理不一致性，为代理系统评估提供更可靠的指标。


<details>
  <summary>Details</summary>
Motivation: 当前评估实践只报告单次运行的准确率，掩盖了结果背后的方差，无法区分真正的能力提升和幸运采样。随着大语言模型成为更大代理系统的组成部分，评估可靠性变得至关重要。

Method: 采用测量科学中的组内相关系数(ICC)来表征评估方差，将观察到的方差分解为查询间方差(任务难度)和查询内方差(代理不一致性)。在GAIA和FRAMES数据集上进行评估，分析不同任务结构下的ICC表现。

Result: ICC随任务结构变化显著：推理和检索任务(FRAMES)的ICC为0.4955-0.7118，代理任务(GAIA)的ICC为0.304-0.774。对于代理系统中的子代理替换决策，只有在ICC也改善时，准确率提升才是可信的。ICC在结构化任务中需要8-16次试验收敛，复杂推理任务需要≥32次。

Conclusion: 建议将准确率与ICC和查询内方差一起作为标准实践报告，提出更新的评估卡片来捕获这些指标。通过使评估稳定性可见，旨在将代理基准测试从不透明的排行榜竞争转变为可信赖的实验科学。

Abstract: As large language models become components of larger agentic systems, evaluation reliability becomes critical: unreliable sub-agents introduce brittleness into downstream system behavior. Yet current evaluation practice, reporting a single accuracy number from a single run, obscures the variance underlying these results, making it impossible to distinguish genuine capability improvements from lucky sampling. We propose adopting Intraclass Correlation Coefficient (ICC), a metric from measurement science, to characterize this variance. ICC decomposes observed variance into between-query variance (task difficulty) and within-query variance (agent inconsistency), highlighting whether reported results reflect true capability or measurement noise. We evaluated on GAIA (Levels 1-3, measuring agentic capabilities across varying reasoning complexity) and FRAMES (measuring retrieval and factuality across multiple documents). We found that ICC varies dramatically with task structure, with reasoning and retrieval tasks (FRAMES) exhibit ICC=0.4955-0.7118 across models, and agentic tasks (GAIA) exhibiting ICC=0.304-0.774 across models. For sub-agent replacement decisions in agentic systems, accuracy improvements are only trustworthy if ICC also improves. We demonstrate that ICC converges by n=8-16 trials for structured tasks and n>=32 for complex reasoning, enabling practitioners to set evidence-based resampling budgets. We recommend reporting accuracy alongside ICC and within-query variance as standard practice, and propose updated Evaluation Cards capturing these metrics. By making evaluation stability visible, we aim to transform agentic benchmarking from opaque leaderboard competition to trustworthy experimental science. Our code is open-sourced at https://github.com/youdotcom-oss/stochastic-agent-evals.

</details>


### [42] [PICKT: Practical Interlinked Concept Knowledge Tracing for Personalized Learning using Knowledge Map Concept Relations](https://arxiv.org/abs/2512.07179)
*Wonbeen Lee,Channyoung Lee,Junho Sohn,Hansam Cho*

Main category: cs.AI

TL;DR: 提出PICKT模型解决知识追踪中的冷启动问题，通过知识图谱处理多种输入数据格式，提升模型在实际应用中的稳定性和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有知识追踪模型存在输入数据格式受限、新学生/新问题冷启动问题、以及实际服务环境稳定性不足等局限性，需要开发更实用的模型来支持个性化学习系统。

Method: 提出PICKT模型，利用知识图谱结构化概念间关系，结合问题和概念文本信息，有效处理多种类型输入数据，解决冷启动问题。

Result: 实验表明模型在真实操作环境中表现优异，特别是在新学生注册和新问题添加两个核心冷启动挑战上显著优于现有模型，验证了稳定性和实用性。

Conclusion: PICKT模型为下一代智能辅导系统的实际应用提供了重要的理论和技术基础，解决了知识追踪中的关键实践问题。

Abstract: With the recent surge in personalized learning, Intelligent Tutoring Systems (ITS) that can accurately track students' individual knowledge states and provide tailored learning paths based on this information are in demand as an essential task. This paper focuses on the core technology of Knowledge Tracing (KT) models that analyze students' sequences of interactions to predict their knowledge acquisition levels. However, existing KT models suffer from limitations such as restricted input data formats, cold start problems arising with new student enrollment or new question addition, and insufficient stability in real-world service environments. To overcome these limitations, a Practical Interlinked Concept Knowledge Tracing (PICKT) model that can effectively process multiple types of input data is proposed. Specifically, a knowledge map structures the relationships among concepts considering the question and concept text information, thereby enabling effective knowledge tracing even in cold start situations. Experiments reflecting real operational environments demonstrated the model's excellent performance and practicality. The main contributions of this research are as follows. First, a model architecture that effectively utilizes diverse data formats is presented. Second, significant performance improvements are achieved over existing models for two core cold start challenges: new student enrollment and new question addition. Third, the model's stability and practicality are validated through delicate experimental design, enhancing its applicability in real-world product environments. This provides a crucial theoretical and technical foundation for the practical implementation of next-generation ITS.

</details>


### [43] [Cognitive Control Architecture (CCA): A Lifecycle Supervision Framework for Robustly Aligned AI Agents](https://arxiv.org/abs/2512.06716)
*Zhibo Liang,Tianze Hu,Zaiye Chen,Mingjie Tang*

Main category: cs.AI

TL;DR: 论文提出认知控制架构（CCA），通过意图图和分层裁决器实现全生命周期认知监督，有效防御LLM智能体间接提示注入攻击，在安全、功能和效率间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体防御机制存在根本性缺陷：安全与功能之间存在固有权衡，防御架构碎片化，无法在整个任务执行流程中提供完整完整性保证，导致在多维安全、功能和效率之间做出不可接受的妥协。

Method: 提出认知控制架构（CCA），包含两个协同支柱：1）通过预生成的"意图图"实现主动控制流和数据流完整性执行；2）创新的"分层裁决器"，在检测到偏差时基于多维评分启动深度推理，专门应对复杂条件攻击。

Result: 在AgentDojo基准测试中，CCA不仅能有效抵御挑战其他先进防御方法的复杂攻击，还能在不妥协安全性的情况下实现显著效率和鲁棒性，成功调和了多维权衡问题。

Conclusion: CCA通过全生命周期认知监督框架，基于动作轨迹偏差检测的核心洞察，构建了高效的双层防御系统，解决了LLM智能体间接提示注入攻击的根本脆弱性问题，实现了安全、功能和效率的平衡。

Abstract: Autonomous Large Language Model (LLM) agents exhibit significant vulnerability to Indirect Prompt Injection (IPI) attacks. These attacks hijack agent behavior by polluting external information sources, exploiting fundamental trade-offs between security and functionality in existing defense mechanisms. This leads to malicious and unauthorized tool invocations, diverting agents from their original objectives. The success of complex IPIs reveals a deeper systemic fragility: while current defenses demonstrate some effectiveness, most defense architectures are inherently fragmented. Consequently, they fail to provide full integrity assurance across the entire task execution pipeline, forcing unacceptable multi-dimensional compromises among security, functionality, and efficiency. Our method is predicated on a core insight: no matter how subtle an IPI attack, its pursuit of a malicious objective will ultimately manifest as a detectable deviation in the action trajectory, distinct from the expected legitimate plan. Based on this, we propose the Cognitive Control Architecture (CCA), a holistic framework achieving full-lifecycle cognitive supervision. CCA constructs an efficient, dual-layered defense system through two synergistic pillars: (i) proactive and preemptive control-flow and data-flow integrity enforcement via a pre-generated "Intent Graph"; and (ii) an innovative "Tiered Adjudicator" that, upon deviation detection, initiates deep reasoning based on multi-dimensional scoring, specifically designed to counter complex conditional attacks. Experiments on the AgentDojo benchmark substantiate that CCA not only effectively withstands sophisticated attacks that challenge other advanced defense methods but also achieves uncompromised security with notable efficiency and robustness, thereby reconciling the aforementioned multi-dimensional trade-off.

</details>


### [44] [ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems](https://arxiv.org/abs/2512.06721)
*Bufang Yang,Lilin Xu,Liekang Zeng,Yunqi Guo,Siyang Jiang,Wenrui Lu,Kaiwei Liu,Hancheng Xiang,Xiaofan Jiang,Guoliang Xing,Zhenyu Yan*

Main category: cs.AI

TL;DR: ProAgent：首个端到端主动代理系统，利用多模态感知和LLM推理提供主动协助，在AR眼镜上实现，显著提升预测准确率和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理主要采用被动响应范式，需要用户明确指令才能启动服务，增加了用户的物理和认知负担。需要一种能够主动感知环境并提供协助的智能代理系统。

Method: 1. 采用面向主动的上下文提取方法，通过按需分层感知持续感知环境，提取包含感官和人物特征的分层上下文；2. 使用上下文感知的主动推理器，将上下文映射到用户需求和工具调用，提供主动协助。

Result: 在真实世界测试平台、公共数据集和用户研究中评估，ProAgent相比现有最优基线：主动预测准确率提升33.4%，工具调用F1分数提升16.8%，用户满意度显著改善。

Conclusion: ProAgent是首个端到端的主动代理系统，通过结合多模态感知和LLM推理，显著提升了主动协助能力，标志着向真正主动助手迈出了重要一步。

Abstract: Large Language Model (LLM) agents are emerging to transform daily life. However, existing LLM agents primarily follow a reactive paradigm, relying on explicit user instructions to initiate services, which increases both physical and cognitive workload. In this paper, we propose ProAgent, the first end-to-end proactive agent system that harnesses massive sensory contexts and LLM reasoning to deliver proactive assistance. ProAgent first employs a proactive-oriented context extraction approach with on-demand tiered perception to continuously sense the environment and derive hierarchical contexts that incorporate both sensory and persona cues. ProAgent then adopts a context-aware proactive reasoner to map these contexts to user needs and tool calls, providing proactive assistance. We implement ProAgent on Augmented Reality (AR) glasses with an edge server and extensively evaluate it on a real-world testbed, a public dataset, and through a user study. Results show that ProAgent achieves up to 33.4% higher proactive prediction accuracy, 16.8% higher tool-calling F1 score, and notable improvements in user satisfaction over state-of-the-art baselines, marking a significant step toward proactive assistants. A video demonstration of ProAgent is available at https://youtu.be/pRXZuzvrcVs.

</details>


### [45] [DoVer: Intervention-Driven Auto Debugging for LLM Multi-Agent Systems](https://arxiv.org/abs/2512.06749)
*Ming Ma,Jue Zhang,Fangkai Yang,Yu Kang,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.AI

TL;DR: DoVer是一个基于干预的调试框架，通过主动验证假设来改进LLM多智能体系统的调试，相比传统日志调试方法能显著提升任务成功率。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的多智能体系统调试存在两个关键限制：1）仅依赖日志的调试缺乏验证，产生未经测试的假设；2）单步或单智能体归因通常不准确，因为多个不同的干预可能独立修复失败任务。

Method: DoVer是一个干预驱动的调试框架，通过主动验证假设来增强假设生成，采用有针对性的干预措施（如编辑消息、修改计划），并专注于衡量系统是否解决失败或朝着任务成功取得可量化的进展。

Result: 在Magnetic-One智能体框架上，基于GAIA和AssistantBench的数据集，DoVer将18-28%的失败试验转为成功，实现高达16%的里程碑进展，验证或反驳了30-60%的失败假设。在GSMPlus数据集和AG2框架上，恢复了49%的失败试验。

Conclusion: 干预是提高智能体系统可靠性的实用机制，为基于LLM的多智能体系统提供了更强大、可扩展的调试方法，开辟了更稳健调试方法的机会。

Abstract: Large language model (LLM)-based multi-agent systems are challenging to debug because failures often arise from long, branching interaction traces. The prevailing practice is to leverage LLMs for log-based failure localization, attributing errors to a specific agent and step. However, this paradigm has two key limitations: (i) log-only debugging lacks validation, producing untested hypotheses, and (ii) single-step or single-agent attribution is often ill-posed, as we find that multiple distinct interventions can independently repair the failed task. To address the first limitation, we introduce DoVer, an intervention-driven debugging framework, which augments hypothesis generation with active verification through targeted interventions (e.g., editing messages, altering plans). For the second limitation, rather than evaluating on attribution accuracy, we focus on measuring whether the system resolves the failure or makes quantifiable progress toward task success, reflecting a more outcome-oriented view of debugging. Within the Magnetic-One agent framework, on the datasets derived from GAIA and AssistantBench, DoVer flips 18-28% of failed trials into successes, achieves up to 16% milestone progress, and validates or refutes 30-60% of failure hypotheses. DoVer also performs effectively on a different dataset (GSMPlus) and agent framework (AG2), where it recovers 49% of failed trials. These results highlight intervention as a practical mechanism for improving reliability in agentic systems and open opportunities for more robust, scalable debugging methods for LLM-based multi-agent systems. Project website and code will be available at https://aka.ms/DoVer.

</details>


### [46] [Decouple to Generalize: Context-First Self-Evolving Learning for Data-Scarce Vision-Language Reasoning](https://arxiv.org/abs/2512.06835)
*Tingyu Li,Zheng Sun,Jingxuan Wei,Siyuan Li,Conghui He,Lijun Wu,Cheng Tan*

Main category: cs.AI

TL;DR: DoGe提出双解耦框架，通过将学习过程分解为思考者和解决者两个组件，解决VLMs在专业领域RL训练中的数据稀缺和奖励黑客问题，实现自我进化的大视觉语言模型。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型通过强化学习实现推理能力，但在化学、地球科学、多模态数学等专业领域面临高质量多模态数据稀缺问题。现有合成数据和自奖励方法存在分布有限和对齐困难，导致奖励黑客问题，模型会利用高奖励模式，导致策略熵崩溃和训练不稳定。

Method: DoGe采用双解耦框架：1) 将学习过程解耦为思考者和解决者两个组件，引导模型首先从上下文学习而非直接解决问题；2) 提出两阶段RL后训练方法，从自由探索上下文到实际解决任务；3) 构建演化课程学习管道，包括扩展的本体领域知识语料库和迭代演化的种子问题池。

Result: 实验表明，该方法在各种基准测试中持续优于基线，为大视觉语言模型的自我进化提供了可扩展的途径。

Conclusion: DoGe通过双解耦框架解决了专业领域VLMs强化学习中的数据稀缺和奖励黑客问题，为自我进化的大视觉语言模型实现提供了有效解决方案。

Abstract: Recent vision-language models (VLMs) achieve remarkable reasoning through reinforcement learning (RL), which provides a feasible solution for realizing continuous self-evolving large vision-language models (LVLMs) in the era of experience. However, RL for VLMs requires abundant high-quality multimodal data, especially challenging in specialized domains like chemistry, earth sciences, and multimodal mathematics. Existing strategies such as synthetic data and self-rewarding mechanisms suffer from limited distributions and alignment difficulties, ultimately causing reward hacking: models exploit high-reward patterns, collapsing policy entropy and destabilizing training. We propose DoGe (Decouple to Generalize), a dual-decoupling framework that guides models to first learn from context rather than problem solving by refocusing on the problem context scenarios overlooked by synthetic data methods. By decoupling learning process into dual components (Thinker and Solver), we reasonably quantify the reward signals of this process and propose a two-stage RL post-training approach from freely exploring context to practically solving tasks. Second, to increase the diversity of training data, DoGe constructs an evolving curriculum learning pipeline: an expanded native domain knowledge corpus and an iteratively evolving seed problems pool. Experiments show that our method consistently outperforms the baseline across various benchmarks, providing a scalable pathway for realizing self-evolving LVLMs.

</details>


### [47] [JT-DA: Enhancing Data Analysis with Tool-Integrated Table Reasoning Large Language Models](https://arxiv.org/abs/2512.06859)
*Ce Chi,Xing Wang,Zhendong Wang,Xiaofan Liu,Ce Li,Zhiyan Song,Chen Zhao,Kexin Yang,Boshen Shi,Jingjing Yang,Chao Deng,Junlan Feng*

Main category: cs.AI

TL;DR: JT-DA-8B是一个专门用于复杂表格推理任务的8B参数大语言模型，通过构建34个表格推理任务的多样化训练语料，结合SFT和RL优化，在多种表格推理任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 针对表格推理场景中高质量监督数据缺乏的问题，需要构建专门的大语言模型来处理现实世界中的复杂表格推理任务。

Method: 1) 构建包含34个表格推理任务的多样化训练语料，整合29个公开表格QA数据集和300万张表格；2) 提出自动流水线生成现实多步分析任务；3) 基于JT-Coder-8B基础模型，采用LLM评分和工作流对齐过滤来蒸馏高质量表格中心数据；4) 结合监督微调(SFT)和强化学习(RL)优化模型；5) 提出四阶段表格推理工作流（表格预处理、表格感知、工具集成推理、提示工程）。

Result: JT-DA-8B在各种表格推理任务中表现出强大的性能，证明了数据中心生成和工作流驱动优化的有效性。

Conclusion: 通过构建全面的训练语料、采用数据蒸馏技术和多阶段工作流优化，JT-DA-8B能够有效处理复杂的表格推理任务，为现实世界表格分析提供了有效的解决方案。

Abstract: In this work, we present JT-DA-8B (JiuTian Data Analyst 8B), a specialized large language model designed for complex table reasoning tasks across diverse real-world scenarios. To address the lack of high-quality supervision in tabular reasoning scenarios, we construct a comprehensive and diverse training corpus with 34 well-defined table reasoning tasks, by aggregating 29 public table QA datasets and 3 million tables. An automatic pipeline is proposed to generate realistic multi-step analytical tasks involving reasoning patterns. The model is trained upon open-source JT-Coder-8B model, an 8B-parameter decoder-only foundation model trained from scratch. In the training stage, we leverage LLM-based scoring and workflow-aligned filtering to distill high-quality, table-centric data. Both supervised fine-tuning (SFT) and Reinforcement learning (RL) are adopted to optimize our model. Afterwards, a four-stage table reasoning workflow is proposed, including table preprocessing, table sensing, tool-integrated reasoning, and prompt engineering, to improve model interpretability and execution accuracy. Experimental results show that JT-DA-8B achieves strong performance in various table reasoning tasks, demonstrating the effectiveness of data-centric generation and workflow-driven optimization.

</details>


### [48] [Do Persona-Infused LLMs Affect Performance in a Strategic Reasoning Game?](https://arxiv.org/abs/2512.06867)
*John Licato,Stephen Steinle,Brayden Hollis*

Main category: cs.AI

TL;DR: 研究探讨人格提示在LLM中是否影响战略决策行为，发现在特定调解机制下，某些人格类型能提升游戏表现


<details>
  <summary>Details</summary>
Motivation: 虽然人格提示能触发LLM生成不同风格的文本，但尚不清楚这些差异是否转化为可测量的行为差异，特别是在对抗性战略环境中的决策影响

Method: 使用PERIL世界统治棋盘游戏作为测试环境，比较人格启发式策略与手动选择策略的效果。引入基于探索性因子分析的结构化调解过程，将LLM生成的库存响应映射为启发式值

Result: 研究发现：1) 某些与战略思维相关的人格能提升游戏表现，但仅在使用调解器将人格转化为启发式值时有效；2) 提出的方法相比直接推断的启发式，增强了启发式的可靠性和表面效度

Conclusion: 研究推进了对人格提示如何影响LLM决策的理解，并提出了一种将心理测量学原理应用于LLM的启发式生成方法，为研究人格类型对决策的影响提供了更好工具

Abstract: Although persona prompting in large language models appears to trigger different styles of generated text, it is unclear whether these translate into measurable behavioral differences, much less whether they affect decision-making in an adversarial strategic environment that we provide as open-source. We investigate the impact of persona prompting on strategic performance in PERIL, a world-domination board game. Specifically, we compare the effectiveness of persona-derived heuristic strategies to those chosen manually. Our findings reveal that certain personas associated with strategic thinking improve game performance, but only when a mediator is used to translate personas into heuristic values. We introduce this mediator as a structured translation process, inspired by exploratory factor analysis, that maps LLM-generated inventory responses into heuristics. Results indicate our method enhances heuristic reliability and face validity compared to directly inferred heuristics, allowing us to better study the effect of persona types on decision making. These insights advance our understanding of how persona prompting influences LLM-based decision-making and propose a heuristic generation method that applies psychometric principles to LLMs.

</details>


### [49] [On Memory: A comparison of memory mechanisms in world models](https://arxiv.org/abs/2512.06983)
*Eli J. Laird,Corey Clark*

Main category: cs.AI

TL;DR: 该论文研究了基于Transformer的世界模型的有效记忆跨度问题，分析了多种记忆增强机制，提出了一种区分记忆编码和记忆注入机制的分类法，并通过状态回忆评估任务验证了这些机制在扩展世界模型记忆和实现循环闭合方面的效果。


<details>
  <summary>Details</summary>
Motivation: 世界模型使智能体能够在想象环境中进行规划，但基于Transformer的世界模型在长时程规划中存在有效记忆跨度限制，导致长轨迹生成中的感知漂移，阻碍了在想象轨迹中实现循环闭合的能力。

Method: 1. 分析多种记忆增强机制的有效记忆跨度；2. 提出区分记忆编码和记忆注入机制的分类法；3. 从残差流动态角度理解记忆机制扩展世界模型记忆的作用；4. 使用状态回忆评估任务测量每种机制的记忆回忆能力并分析其权衡。

Result: 研究发现记忆机制能够提高视觉Transformer的有效记忆跨度，并为在世界模型的想象中完成循环闭合提供了路径。

Conclusion: 记忆增强机制对于扩展基于Transformer的世界模型的记忆能力至关重要，特别是在实现长时程规划和循环闭合方面，为改进世界模型的规划能力提供了有效途径。

Abstract: World models enable agents to plan within imagined environments by predicting future states conditioned on past observations and actions. However, their ability to plan over long horizons is limited by the effective memory span of the backbone architecture. This limitation leads to perceptual drift in long rollouts, hindering the model's capacity to perform loop closures within imagined trajectories. In this work, we investigate the effective memory span of transformer-based world models through an analysis of several memory augmentation mechanisms. We introduce a taxonomy that distinguishes between memory encoding and memory injection mechanisms, motivating their roles in extending the world model's memory through the lens of residual stream dynamics. Using a state recall evaluation task, we measure the memory recall of each mechanism and analyze its respective trade-offs. Our findings show that memory mechanisms improve the effective memory span in vision transformers and provide a path to completing loop closures within a world model's imagination.

</details>


### [50] [Utilizing Multi-Agent Reinforcement Learning with Encoder-Decoder Architecture Agents to Identify Optimal Resection Location in Glioblastoma Multiforme Patients](https://arxiv.org/abs/2512.06990)
*Krishna Arun,Moinak Bhattachrya,Paras Goel*

Main category: cs.AI

TL;DR: 开发了一个AI系统，用于胶质母细胞瘤的诊断和治疗规划，通过序列决策框架和强化学习系统，显著降低了计算成本并提高了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 目前医疗领域缺乏AI系统来支持医生治疗异质性脑肿瘤如胶质母细胞瘤（GBM），这是世界上最致命的癌症，五年生存率仅为5.1%。

Method: 诊断阶段使用包含4个分类模型（卷积神经网络和支持向量机）的序列决策框架；治疗规划阶段使用包含3个生成模型的强化学习系统：切除模型（扩散模型）、放疗模型（时空视觉Transformer）和化疗模型（扩散模型），结合生存率计算器和近端策略优化的反馈循环。

Result: 序列决策框架将计算成本降低22.28倍；Transformer回归能力将肿瘤进展推理时间减少113小时；真实场景数据增强使DICE分数提高2.9%；预计可将生存率提高0.9%，挽救约2250条生命。

Conclusion: 该AI系统为胶质母细胞瘤提供了首个端到端解决方案，在诊断和治疗规划方面都取得了显著改进，有望提高患者生存率。

Abstract: Currently, there is a noticeable lack of AI in the medical field to support doctors in treating heterogenous brain tumors such as Glioblastoma Multiforme (GBM), the deadliest human cancer in the world with a five-year survival rate of just 5.1%. This project develops an AI system offering the only end-to-end solution by aiding doctors with both diagnosis and treatment planning. In the diagnosis phase, a sequential decision-making framework consisting of 4 classification models (Convolutional Neural Networks and Support Vector Machine) are used. Each model progressively classifies the patient's brain into increasingly specific categories, with the final step being named diagnosis. For treatment planning, an RL system consisting of 3 generative models is used. First, the resection model (diffusion model) analyzes the diagnosed GBM MRI and predicts a possible resection outcome. Second, the radiotherapy model (Spatio-Temporal Vision Transformer) generates an MRI of the brain's progression after a user-defined number of weeks. Third, the chemotherapy model (Diffusion Model) produces the post-treatment MRI. A survival rate calculator (Convolutional Neural Network) then checks if the generated post treatment MRI has a survival rate within 15% of the user defined target. If not, a feedback loop using proximal policy optimization iterates over this system until an optimal resection location is identified. When compared to existing solutions, this project found 3 key findings: (1) Using a sequential decision-making framework consisting of 4 small diagnostic models reduced computing costs by 22.28x, (2) Transformers regression capabilities decreased tumor progression inference time by 113 hours, and (3) Applying Augmentations resembling Real-life situations improved overall DICE scores by 2.9%. These results project to increase survival rates by 0.9%, potentially saving approximately 2,250 lives.

</details>


### [51] [ClinNoteAgents: An LLM Multi-Agent System for Predicting and Interpreting Heart Failure 30-Day Readmission from Clinical Notes](https://arxiv.org/abs/2512.07081)
*Rongjia Zhou,Chengzhuo Li,Carl Yang,Jiaying Lu*

Main category: cs.AI

TL;DR: ClinNoteAgents：基于LLM的多智能体框架，将临床自由文本笔记转化为结构化风险因素表示和临床风格抽象，用于心衰30天再入院预测，减少对结构化字段的依赖。


<details>
  <summary>Details</summary>
Motivation: 心衰是美国老年人再入院的主要原因之一。临床笔记包含丰富的患者信息，占电子健康记录的很大部分，但在心衰再入院风险分析中未得到充分利用。传统模型依赖专家规则、医学术语和本体来解释临床笔记，但这些笔记通常有拼写错误、缩写和领域特定术语。

Method: 提出ClinNoteAgents，一个基于LLM的多智能体框架，将自由文本临床笔记转化为：(1) 临床和社会风险因素的结构化表示用于关联分析；(2) 临床风格抽象用于心衰30天再入院预测。

Result: 在3,544份笔记（来自2,065名患者，再入院率35.16%）上评估ClinNoteAgents，在从自由文本提取风险因素、识别关键贡献因素和预测再入院风险方面表现出色。

Conclusion: 通过减少对结构化字段的依赖，最小化手动标注和模型训练，ClinNoteAgents为数据有限的医疗系统提供了可扩展且可解释的基于笔记的心衰再入院风险建模方法。

Abstract: Heart failure (HF) is one of the leading causes of rehospitalization among older adults in the United States. Although clinical notes contain rich, detailed patient information and make up a large portion of electronic health records (EHRs), they remain underutilized for HF readmission risk analysis. Traditional computational models for HF readmission often rely on expert-crafted rules, medical thesauri, and ontologies to interpret clinical notes, which are typically written under time pressure and may contain misspellings, abbreviations, and domain-specific jargon. We present ClinNoteAgents, an LLM-based multi-agent framework that transforms free-text clinical notes into (1) structured representations of clinical and social risk factors for association analysis and (2) clinician-style abstractions for HF 30-day readmission prediction. We evaluate ClinNoteAgents on 3,544 notes from 2,065 patients (readmission rate=35.16%), demonstrating strong performance in extracting risk factors from free-text, identifying key contributing factors, and predicting readmission risk. By reducing reliance on structured fields and minimizing manual annotation and model training, ClinNoteAgents provides a scalable and interpretable approach to note-based HF readmission risk modeling in data-limited healthcare systems.

</details>


### [52] [VIGIL: A Reflective Runtime for Self-Healing Agents](https://arxiv.org/abs/2512.07094)
*Christopher Cruz*

Main category: cs.AI

TL;DR: VIGIL是一个用于LLM智能体的反射运行时系统，通过行为日志分析、情感表征、RBT诊断和自主维护，实现智能体的自我修复与改进，而非直接执行任务。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体框架存在脆弱性，缺乏运行时自省能力，无法诊断自身失败模式，且需要人工干预才能改进。大多数部署系统退化为装饰性的LLM调用链，没有可靠性的结构化机制。

Method: VIGIL作为监督兄弟智能体的反射运行时，包含：1) 行为日志摄取；2) 事件情感表征评估；3) 带衰减和上下文策略的持久EmoBank；4) RBT诊断（优势、机会、失败）；5) 生成保护性提示更新和只读代码提案；6) 状态门控管道，非法转换产生显式错误。

Result: 在提醒延迟案例研究中，VIGIL识别出延迟升高，提出提示和代码修复方案。当自身诊断工具因模式冲突失败时，能暴露内部错误、生成备用诊断并发出修复计划，展示了部署智能体运行时的元级自我修复能力。

Conclusion: VIGIL实现了LLM智能体的自主维护和自我修复能力，通过结构化机制解决了当前智能体框架的脆弱性问题，为构建更可靠的自主系统提供了新方法。

Abstract: Agentic LLM frameworks promise autonomous behavior via task decomposition, tool use, and iterative planning, but most deployed systems remain brittle. They lack runtime introspection, cannot diagnose their own failure modes, and do not improve over time without human intervention. In practice, many agent stacks degrade into decorated chains of LLM calls with no structural mechanisms for reliability. We present VIGIL (Verifiable Inspection and Guarded Iterative Learning), a reflective runtime that supervises a sibling agent and performs autonomous maintenance rather than task execution. VIGIL ingests behavioral logs, appraises each event into a structured emotional representation, maintains a persistent EmoBank with decay and contextual policies, and derives an RBT diagnosis that sorts recent behavior into strengths, opportunities, and failures. From this analysis, VIGIL generates both guarded prompt updates that preserve core identity semantics and read only code proposals produced by a strategy engine that operates on log evidence and code hotspots. VIGIL functions as a state gated pipeline. Illegal transitions produce explicit errors rather than allowing the LLM to improvise. In a reminder latency case study, VIGIL identified elevated lag, proposed prompt and code repairs, and when its own diagnostic tool failed due to a schema conflict, it surfaced the internal error, produced a fallback diagnosis, and emitted a repair plan. This demonstrates meta level self repair in a deployed agent runtime.

</details>


### [53] [A Neural Affinity Framework for Abstract Reasoning: Diagnosing the Compositional Gap in Transformer Architectures via Procedural Task Taxonomy](https://arxiv.org/abs/2512.07109)
*Miguel Ingram,Arthur Joseph Merritt*

Main category: cs.AI

TL;DR: 本文提出了首个针对400个ARC任务的9类别分类法，通过代码分析验证准确率达97.5%，揭示了Transformer架构在35.3%任务上存在神经亲和力不足的问题，发现了组合性鸿沟现象，表明需要亲和力对齐的混合架构。


<details>
  <summary>Details</summary>
Motivation: 响应Hodel等人对ARC任务相关性正式定义的需求，建立系统化的任务分类体系，以诊断当前神经网络架构在抽象推理任务上的局限性。

Method: 1) 开发基于规则代码分析的9类别分类法；2) 使用原始网格像素训练CNN验证分类视觉一致性；3) 在302个任务上微调170万参数Transformer；4) 应用分类法分析ARC-AGI-2测试集和独立研究数据。

Result: 1) 分类法准确率97.5%，CNN验证视觉一致性达95.24%；2) 发现35.3%任务对Transformer神经亲和力低；3) 揭示组合性鸿沟：69.5%任务局部准确率>80%但全局准确率<10%；4) 低亲和力任务准确率51.9% vs 高亲和力77.7%。

Conclusion: 当前神经网络架构存在神经亲和力天花板效应，性能受限于架构适用性而非训练数据。需要开发亲和力对齐的混合架构来突破现有性能瓶颈，分类法为精准诊断和架构设计提供了有效工具。

Abstract: Responding to Hodel et al.'s (2024) call for a formal definition of task relatedness in re-arc, we present the first 9-category taxonomy of all 400 tasks, validated at 97.5% accuracy via rule-based code analysis. We prove the taxonomy's visual coherence by training a CNN on raw grid pixels (95.24% accuracy on S3, 36.25% overall, 3.3x chance), then apply the taxonomy diagnostically to the original ARC-AGI-2 test set. Our curriculum analysis reveals 35.3% of tasks exhibit low neural affinity for Transformers--a distributional bias mirroring ARC-AGI-2. To probe this misalignment, we fine-tuned a 1.7M-parameter Transformer across 302 tasks, revealing a profound Compositional Gap: 210 of 302 tasks (69.5%) achieve >80% cell accuracy (local patterns) but <10% grid accuracy (global synthesis). This provides direct evidence for a Neural Affinity Ceiling Effect, where performance is bounded by architectural suitability, not curriculum. Applying our framework to Li et al.'s independent ViTARC study (400 specialists, 1M examples each) confirms its predictive power: Very Low affinity tasks achieve 51.9% versus 77.7% for High affinity (p<0.001), with a task at 0% despite massive data. The taxonomy enables precise diagnosis: low-affinity tasks (A2) hit hard ceilings, while high-affinity tasks (C1) reach 99.8%. These findings indicate that progress requires hybrid architectures with affinity-aligned modules. We release our validated taxonomy,

</details>


### [54] [ContextualSHAP : Enhancing SHAP Explanations Through Contextual Language Generation](https://arxiv.org/abs/2512.07178)
*Latifa Dwiyanti,Sergio Ryan Wibisono,Hidetaka Nambo*

Main category: cs.AI

TL;DR: 提出一个Python包，将SHAP与大型语言模型（GPT）结合，生成上下文文本解释，提高非技术用户对机器学习模型解释的理解性。


<details>
  <summary>Details</summary>
Motivation: SHAP虽然能有效可视化特征重要性，但缺乏对非技术背景终端用户有意义的上下文解释。需要改进模型解释的用户友好性和可信度。

Method: 开发Python包，将SHAP与OpenAI的GPT集成，通过用户定义的参数（特征别名、描述、背景信息）生成上下文文本解释。

Result: 在医疗案例研究中应用，用户评估显示生成的解释比纯视觉输出更易理解和上下文适当（基于李克特量表和访谈）。

Conclusion: 结合可视化与上下文文本可以支持更用户友好和可信的模型解释，但结果仍是初步的。

Abstract: Explainable Artificial Intelligence (XAI) has become an increasingly important area of research, particularly as machine learning models are deployed in high-stakes domains. Among various XAI approaches, SHAP (SHapley Additive exPlanations) has gained prominence due to its ability to provide both global and local explanations across different machine learning models. While SHAP effectively visualizes feature importance, it often lacks contextual explanations that are meaningful for end-users, especially those without technical backgrounds. To address this gap, we propose a Python package that extends SHAP by integrating it with a large language model (LLM), specifically OpenAI's GPT, to generate contextualized textual explanations. This integration is guided by user-defined parameters (such as feature aliases, descriptions, and additional background) to tailor the explanation to both the model context and the user perspective. We hypothesize that this enhancement can improve the perceived understandability of SHAP explanations. To evaluate the effectiveness of the proposed package, we applied it in a healthcare-related case study and conducted user evaluations involving real end-users. The results, based on Likert-scale surveys and follow-up interviews, indicate that the generated explanations were perceived as more understandable and contextually appropriate compared to visual-only outputs. While the findings are preliminary, they suggest that combining visualization with contextualized text may support more user-friendly and trustworthy model explanations.

</details>


### [55] [Sample from What You See: Visuomotor Policy Learning via Diffusion Bridge with Observation-Embedded Stochastic Differential Equation](https://arxiv.org/abs/2512.07212)
*Zhaoyang Liu,Mokai Pan,Zhongyi Wang,Kaizhen Zhu,Haotao Lu,Jingya Wang,Ye Shi*

Main category: cs.AI

TL;DR: BridgePolicy是一种新的视觉运动策略，通过扩散桥公式将观测嵌入随机微分方程中，使采样从信息丰富的先验开始而非随机噪声，显著提升控制精度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的模仿学习方法通常将观测作为去噪网络的高层条件输入，而不是将其整合到扩散过程的随机动力学中。这导致采样必须从随机高斯噪声开始，削弱了感知与控制之间的耦合，通常产生次优性能。

Method: 提出BridgePolicy，通过扩散桥公式将观测嵌入随机微分方程中；设计多模态融合模块和语义对齐器，统一视觉和状态输入，对齐观测和动作表示，使桥方法适用于异构机器人数据。

Result: 在三个基准测试的52个仿真任务和五个真实世界任务上的广泛实验表明，BridgePolicy始终优于最先进的生成策略。

Conclusion: BridgePolicy通过将观测嵌入扩散过程的随机动力学中，使采样从信息丰富的先验开始，显著提高了生成视觉运动策略的精度和可靠性。

Abstract: Imitation learning with diffusion models has advanced robotic control by capturing multi-modal action distributions. However, existing approaches typically treat observations as high-level conditioning inputs to the denoising network, rather than integrating them into the stochastic dynamics of the diffusion process itself. As a result, sampling must begin from random Gaussian noise, weakening the coupling between perception and control and often yielding suboptimal performance. We introduce BridgePolicy, a generative visuomotor policy that explicitly embeds observations within the stochastic differential equation via a diffusion-bridge formulation. By constructing an observation-informed trajectory, BridgePolicy enables sampling to start from a rich, informative prior rather than random noise, substantially improving precision and reliability in control. A key challenge is that classical diffusion bridges connect distributions with matched dimensionality, whereas robotic observations are heterogeneous and multi-modal and do not naturally align with the action space. To address this, we design a multi-modal fusion module and a semantic aligner that unify visual and state inputs and align observation and action representations, making the bridge applicable to heterogeneous robot data. Extensive experiments across 52 simulation tasks on three benchmarks and five real-world tasks demonstrate that BridgePolicy consistently outperforms state-of-the-art generative policies.

</details>


### [56] [Cross-platform Product Matching Based on Entity Alignment of Knowledge Graph with RAEA model](https://arxiv.org/abs/2512.07232)
*Wenlong Liu,Jiahua Pan,Xingyu Zhang,Xinxin Gong,Yang Ye,Xujin Zhao,Xin Wang,Kent Wu,Hua Xiang,Houmin Yan,Qingpeng Zhang*

Main category: cs.AI

TL;DR: 该论文提出了一种用于产品匹配的两阶段流水线，采用RAEA框架进行实体对齐，通过同时利用属性三元组和关系三元组及其交互作用，在跨语言数据集上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有实体对齐方法未能充分利用属性三元组和关系三元组，特别是它们之间的交互作用。产品匹配可以通过构建知识图谱转化为实体对齐任务，需要更有效的方法来整合这两种信息源。

Method: 提出两阶段流水线：粗过滤和细过滤。细过滤采用RAEA框架，包含属性感知实体编码器和关系感知图注意力网络，通过注意力机制聚合属性和关系的对齐信号，捕捉它们之间的交互作用。

Result: RAEA模型在跨语言数据集DBP15K上相比12个基线方法平均Hits@1提升6.59%，在单语言数据集DWY100K上取得竞争性结果。实验验证了同时利用属性和关系信息及其交互的有效性。

Conclusion: 通过同时利用属性三元组和关系三元组及其交互作用，RAEA框架显著提升了实体对齐性能，为产品匹配等应用提供了有效的解决方案。两阶段流水线在实际电商平台数据上具有应用潜力。

Abstract: Product matching aims to identify identical or similar products sold on different platforms. By building knowledge graphs (KGs), the product matching problem can be converted to the Entity Alignment (EA) task, which aims to discover the equivalent entities from diverse KGs. The existing EA methods inadequately utilize both attribute triples and relation triples simultaneously, especially the interactions between them. This paper introduces a two-stage pipeline consisting of rough filter and fine filter to match products from eBay and Amazon. For fine filtering, a new framework for Entity Alignment, Relation-aware and Attribute-aware Graph Attention Networks for Entity Alignment (RAEA), is employed. RAEA focuses on the interactions between attribute triples and relation triples, where the entity representation aggregates the alignment signals from attributes and relations with Attribute-aware Entity Encoder and Relation-aware Graph Attention Networks. The experimental results indicate that the RAEA model achieves significant improvements over 12 baselines on EA task in the cross-lingual dataset DBP15K (6.59% on average Hits@1) and delivers competitive results in the monolingual dataset DWY100K. The source code for experiments on DBP15K and DWY100K is available at github (https://github.com/Mockingjay-liu/RAEA-model-for-Entity-Alignment).

</details>


### [57] [M-STAR: Multi-Scale Spatiotemporal Autoregression for Human Mobility Modeling](https://arxiv.org/abs/2512.07314)
*Yuxiao Luo,Songming Zhang,Sijie Ruan,Siran Chen,Kang Liu,Yang Xu,Yu Zheng,Ling Yin*

Main category: cs.AI

TL;DR: M-STAR是一个多尺度时空自回归框架，用于高效生成长期人类移动轨迹，通过从粗到细的预测过程显著提升生成速度和保真度。


<details>
  <summary>Details</summary>
Motivation: 现有基于自回归和扩散模型的方法在生成长期轨迹（如周轨迹）时效率低下，且缺乏显式的时空多尺度建模，限制了实际应用。

Method: 提出M-STAR框架，包含多尺度时空标记器编码分层移动模式，以及基于Transformer的解码器进行下一尺度自回归预测，实现从粗到细的轨迹生成。

Result: 在两个真实数据集上的实验表明，M-STAR在保真度上优于现有方法，并显著提高了生成速度。

Conclusion: M-STAR通过多尺度时空建模有效解决了长期轨迹生成的效率和保真度问题，为人类移动建模提供了新解决方案。

Abstract: Modeling human mobility is vital for extensive applications such as transportation planning and epidemic modeling. With the rise of the Artificial Intelligence Generated Content (AIGC) paradigm, recent works explore synthetic trajectory generation using autoregressive and diffusion models. While these methods show promise for generating single-day trajectories, they remain limited by inefficiencies in long-term generation (e.g., weekly trajectories) and a lack of explicit spatiotemporal multi-scale modeling. This study proposes Multi-Scale Spatio-Temporal AutoRegression (M-STAR), a new framework that generates long-term trajectories through a coarse-to-fine spatiotemporal prediction process. M-STAR combines a Multi-scale Spatiotemporal Tokenizer that encodes hierarchical mobility patterns with a Transformer-based decoder for next-scale autoregressive prediction. Experiments on two real-world datasets show that M-STAR outperforms existing methods in fidelity and significantly improves generation speed. The data and codes are available at https://github.com/YuxiaoLuo0013/M-STAR.

</details>


### [58] [A Geometric Unification of Concept Learning with Concept Cones](https://arxiv.org/abs/2512.07355)
*Alexandre Rocchi--Henry,Thomas Fel,Gianni Franchi*

Main category: cs.AI

TL;DR: 该论文提出了一个统一监督和无监督概念发现的几何框架，将概念瓶颈模型和稀疏自编码器视为学习概念锥的两种方法，并建立了量化评估指标。


<details>
  <summary>Details</summary>
Motivation: 概念瓶颈模型（CBMs）和稀疏自编码器（SAEs）这两种可解释性传统各自发展但缺乏对话。CBMs通过监督定义概念，SAEs通过稀疏编码发现概念，需要建立统一的框架来连接这两种范式。

Method: 提出概念锥的几何框架，将CBMs和SAEs都视为学习激活空间中线性方向的非负组合。建立包含性评估指标，用CBMs提供参考几何，评估SAEs学习的概念锥与CBM概念锥的近似或包含程度。

Result: 发现了稀疏度和扩展因子的"最佳点"，能最大化与CBM概念的几何和语义对齐。提供了量化指标来评估SAEs进展及其与人类概念的对齐程度。

Conclusion: 通过共享的几何框架统一了监督和无监督概念发现，为评估SAEs进展和衡量发现概念与人类概念的对齐提供了原则性指标。

Abstract: Two traditions of interpretability have evolved side by side but seldom spoken to each other: Concept Bottleneck Models (CBMs), which prescribe what a concept should be, and Sparse Autoencoders (SAEs), which discover what concepts emerge. While CBMs use supervision to align activations with human-labeled concepts, SAEs rely on sparse coding to uncover emergent ones. We show that both paradigms instantiate the same geometric structure: each learns a set of linear directions in activation space whose nonnegative combinations form a concept cone. Supervised and unsupervised methods thus differ not in kind but in how they select this cone. Building on this view, we propose an operational bridge between the two paradigms. CBMs provide human-defined reference geometries, while SAEs can be evaluated by how well their learned cones approximate or contain those of CBMs. This containment framework yields quantitative metrics linking inductive biases -- such as SAE type, sparsity, or expansion ratio -- to emergence of plausible\footnote{We adopt the terminology of \citet{jacovi2020towards}, who distinguish between faithful explanations (accurately reflecting model computations) and plausible explanations (aligning with human intuition and domain knowledge). CBM concepts are plausible by construction -- selected or annotated by humans -- though not necessarily faithful to the true latent factors that organise the data manifold.} concepts. Using these metrics, we uncover a ``sweet spot'' in both sparsity and expansion factor that maximizes both geometric and semantic alignment with CBM concepts. Overall, our work unifies supervised and unsupervised concept discovery through a shared geometric framework, providing principled metrics to measure SAE progress and assess how well discovered concept align with plausible human concepts.

</details>


### [59] [LocalSearchBench: Benchmarking Agentic Search in Real-World Local Life Services](https://arxiv.org/abs/2512.07436)
*Hang He,Chuhuai Yue,Chengqi Dong,Mingxue Tian,Zhenfeng Liu,Jiajun Chai,Xiaohan Wang,Yufei Zhang,Qun Liao,Guojun Yin,Wei Lin,Chengcheng Wan,Haiying Sun,Ting Su*

Main category: cs.AI

TL;DR: 该论文提出了LocalSearchBench，这是首个针对本地生活服务的智能搜索基准测试，包含超过15万条高质量数据和300个多跳问答任务，揭示了当前大型推理模型在该领域的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型推理模型研究主要关注通用信息检索，很少探索具有独特挑战的垂直领域。本地生活服务领域的查询通常模糊且需要跨商家和产品的多跳推理，现有方法未能充分解决这些挑战。

Method: 构建了LocalSearchBench基准测试，包含来自不同城市和业务类型的超过15万条高质量条目，并基于真实用户查询构建了300个多跳问答任务。同时开发了LocalPlayground统一环境，集成了多种工具供智能体交互。

Result: 实验表明，即使最先进的大型推理模型在LocalSearchBench上也表现不佳：最佳模型（DeepSeek-V3.1）仅达到34.34%的正确率，大多数模型在完整性（平均77.33%）和忠实度（平均61.99%）方面存在问题。

Conclusion: 该研究强调了在本地生活服务领域需要专门的基准测试和领域特定的智能体训练。LocalSearchBench为评估和改进该领域的智能搜索系统提供了重要工具。

Abstract: Recent advances in large reasoning models (LRMs) have enabled agentic search systems to perform complex multi-step reasoning across multiple sources. However, most studies focus on general information retrieval and rarely explores vertical domains with unique challenges. In this work, we focus on local life services and introduce LocalSearchBench, which encompass diverse and complex business scenarios. Real-world queries in this domain are often ambiguous and require multi-hop reasoning across merchants and products, remaining challenging and not fully addressed. As the first comprehensive benchmark for agentic search in local life services, LocalSearchBench includes over 150,000 high-quality entries from various cities and business types. We construct 300 multi-hop QA tasks based on real user queries, challenging agents to understand questions and retrieve information in multiple steps. We also developed LocalPlayground, a unified environment integrating multiple tools for agent interaction. Experiments show that even state-of-the-art LRMs struggle on LocalSearchBench: the best model (DeepSeek-V3.1) achieves only 34.34% correctness, and most models have issues with completeness (average 77.33%) and faithfulness (average 61.99%). This highlights the need for specialized benchmarks and domain-specific agent training in local life services. Code, Benchmark, and Leaderboard are available at localsearchbench.github.io.

</details>


### [60] [How Do LLMs Fail In Agentic Scenarios? A Qualitative Analysis of Success and Failure Scenarios of Various LLMs in Agentic Simulations](https://arxiv.org/abs/2512.07497)
*JV Roig*

Main category: cs.AI

TL;DR: 研究大型语言模型作为具有工具使用能力的自主代理时的失败模式，通过KAMI基准测试分析三个代表性模型的行为，发现模型规模并非代理可靠性的唯一决定因素，识别出四种常见失败模式。


<details>
  <summary>Details</summary>
Motivation: 当前研究多关注LLM的聚合性能指标，但缺乏对LLM作为自主代理在工具使用场景中具体失败行为的细粒度分析。需要理解哪些策略支持成功的多步骤工具执行，以及哪些重复出现的失败模式会破坏可靠性。

Method: 使用Kamiwaza Agentic Merit Index (KAMI) v0.1基准测试，分析900个执行轨迹，涵盖三个代表性模型（Granite 4 Small、Llama 4 Maverick、DeepSeek V3.1），涉及文件系统、文本提取、CSV分析和SQL场景。采用细粒度的逐试验行为分析而非聚合评分。

Result: 1. 模型规模并非代理鲁棒性的唯一预测因素：Llama 4 Maverick (400B)在某些不确定性驱动任务中仅略优于Granite 4 Small (32B)；2. DeepSeek V3.1的优越可靠性主要源于后训练强化学习而非架构或规模；3. 识别出四种重复出现的失败模式：缺乏基础的过早行动、替代缺失实体的过度帮助性、分心诱导的上下文污染脆弱性、负载下的脆弱执行。

Conclusion: 可靠的代理部署不仅需要更强的模型，还需要有意识的训练和设计选择，强调验证、约束发现和遵循真实数据源。需要开发强调交互基础、恢复行为和环境感知适应的代理评估方法。

Abstract: We investigate how large language models (LLMs) fail when operating as autonomous agents with tool-use capabilities. Using the Kamiwaza Agentic Merit Index (KAMI) v0.1 benchmark, we analyze 900 execution traces from three representative models - Granite 4 Small, Llama 4 Maverick, and DeepSeek V3.1 - across filesystem, text extraction, CSV analysis, and SQL scenarios. Rather than focusing on aggregate scores, we perform fine-grained, per-trial behavioral analysis to surface the strategies that enable successful multi-step tool execution and the recurrent failure modes that undermine reliability. Our findings show that model scale alone does not predict agentic robustness: Llama 4 Maverick (400B) performs only marginally better than Granite 4 Small (32B) in some uncertainty-driven tasks, while DeepSeek V3.1's superior reliability derives primarily from post-training reinforcement learning rather than architecture or size. Across models, we identify four recurring failure archetypes: premature action without grounding, over-helpfulness that substitutes missing entities, vulnerability to distractor-induced context pollution, and fragile execution under load. These patterns highlight the need for agentic evaluation methods that emphasize interactive grounding, recovery behavior, and environment-aware adaptation, suggesting that reliable enterprise deployment requires not just stronger models but deliberate training and design choices that reinforce verification, constraint discovery, and adherence to source-of-truth data.

</details>


### [61] [Comparative Analysis and Parametric Tuning of PPO, GRPO, and DAPO for LLM Reasoning Enhancement](https://arxiv.org/abs/2512.07611)
*Yongsheng Lian*

Main category: cs.AI

TL;DR: 系统比较PPO、GRPO、DAPO三种RL算法在提升大语言模型复杂推理能力上的效果，通过Countdown Game微调后在通用推理基准上评估，发现RL训练模型均优于基础模型，但改进程度因任务而异。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索强化学习算法如何有效提升大语言模型的复杂推理能力，通过系统比较不同RL方法的训练效果，为RL-based LLM训练提供实用指导。

Method: 采用控制性迁移学习评估方法：先在专门的Countdown Game上微调模型，然后在通用推理基准套件上评估。比较PPO、GRPO、DAPO三种RL算法，并进行参数分析（组大小、KL惩罚系数、动态采样组件）。

Result: 所有任务中RL训练模型均优于对应基础模型，但改进程度因基准而异。增加GRPO和DAPO的组大小能带来更稳定的训练动态和更高准确率，KL惩罚系数影响非单调，DAPO的动态采样组件反而降低性能，禁用时效果最佳。

Conclusion: RL训练能有效提升LLM的复杂推理能力，不同RL算法效果不同。参数设置对训练效果有重要影响，特别是组大小和KL惩罚系数需要仔细调整，DAPO的动态采样组件在实际应用中可能不必要。

Abstract: This study presents a systematic comparison of three Reinforcement Learning (RL) algorithms (PPO, GRPO, and DAPO) for improving complex reasoning in large language models (LLMs). Our main contribution is a controlled transfer-learning evaluation: models are first fine-tuned on the specialized Countdown Game and then assessed on a suite of general-purpose reasoning benchmarks. Across all tasks, RL-trained models outperform their corresponding base models, although the degree of improvement differs by benchmark.
  Our parametric analysis offers practical guidance for RL-based LLM training. Increasing the group size in GRPO and DAPO leads to more stable training dynamics and higher accuracy, while the impact of the KL-penalty coefficient is non-monotonic. Additionally, we find that the Dynamic Sampling (DS) component in DAPO does not improve performance; in fact, the best overall results are achieved with DAPO when DS is disabled.

</details>


### [62] [The Agent Capability Problem: Predicting Solvability Through Information-Theoretic Bounds](https://arxiv.org/abs/2512.07631)
*Shahar Lutati*

Main category: cs.AI

TL;DR: 提出Agent Capability Problem (ACP)框架，通过信息获取视角预测智能体在资源约束下能否解决问题，用信息增益和成本计算有效成本来预测资源需求。


<details>
  <summary>Details</summary>
Motivation: 解决自主智能体何时应该为任务投入资源的问题，避免依赖经验启发式方法，为智能体能力预测提供理论框架。

Method: 将问题解决视为信息获取过程：智能体需要I_total比特信息来识别解决方案，每个动作获得I_step比特信息，成本为C_step，计算有效成本C_eff = (I_total/I_step) * C_step来预测资源需求。

Result: 证明C_eff是期望成本的下界，并提供紧密的概率上界。实验验证显示ACP预测与实际智能体性能紧密匹配，能有效约束搜索努力，比贪婪和随机策略更高效。

Conclusion: ACP框架为智能体能力预测提供了统一的信息论视角，连接了主动学习、贝叶斯优化和强化学习的原则，适用于LLM和智能体工作流。

Abstract: When should an autonomous agent commit resources to a task? We introduce the Agent Capability Problem (ACP), a framework for predicting whether an agent can solve a problem under resource constraints. Rather than relying on empirical heuristics, ACP frames problem-solving as information acquisition: an agent requires $\Itotal$ bits to identify a solution and gains $\Istep$ bits per action at cost $\Cstep$, yielding an effective cost $\Ceff = (\Itotal/\Istep), \Cstep$ that predicts resource requirements before search. We prove that $\Ceff$ lower-bounds expected cost and provide tight probabilistic upper bounds. Experimental validation shows that ACP predictions closely track actual agent performance, consistently bounding search effort while improving efficiency over greedy and random strategies. The framework generalizes across LLM-based and agentic workflows, linking principles from active learning, Bayesian optimization, and reinforcement learning through a unified information-theoretic lens. \

</details>


### [63] [Each Prompt Matters: Scaling Reinforcement Learning Without Wasting Rollouts on Hundred-Billion-Scale MoE](https://arxiv.org/abs/2512.07710)
*Anxiang Zeng,Haibo Zhang,Hailing Zhang,Kaixiang Mo,Liang Yao,Ling Hu,Long Zhang,Shuman Liu,Shuyi Xie,Yanshi Li,Yizhang Chen,Yuepeng Sheng,Yuwei Huang,Zhaochen Xu,Zhiqiang Zhou,Ziqin Liew*

Main category: cs.AI

TL;DR: 提出了CompassMax-V3-Thinking，一个千亿级MoE推理模型，采用基于"每个提示都必须重要"原则的新RL框架，解决了大规模RL中的效率问题，包括零方差提示浪费、重要性采样不稳定、优势反转和系统瓶颈。


<details>
  <summary>Details</summary>
Motivation: 将RL扩展到千亿级规模暴露了关键效率问题：零方差提示浪费rollout资源、长视野下重要性采样不稳定、标准奖励模型导致优势反转，以及rollout处理的系统性瓶颈。需要解决这些问题来实现大规模MoE模型的高效RL训练。

Method: 1) 多阶段零方差消除：过滤非信息性提示，稳定基于组的策略优化；2) ESPO：熵自适应优化方法，平衡token级和序列级重要性采样；3) Router Replay策略：对齐训练时MoE路由决策与推理时行为，配合奖励模型调整防止优势反转；4) 高吞吐RL系统：采用FP8精度rollout、重叠奖励计算和长度感知调度。

Result: 这些创新形成了一个统一的pipeline，使千亿级MoE模型的RL训练变得稳定高效。最终模型在内部和公开评估中都表现出色。

Conclusion: 通过解决大规模RL训练中的关键效率问题，成功实现了千亿级MoE推理模型的稳定高效训练，为大规模语言模型的强化学习提供了可行的解决方案。

Abstract: We present CompassMax-V3-Thinking, a hundred-billion-scale MoE reasoning model trained with a new RL framework built on one principle: each prompt must matter. Scaling RL to this size exposes critical inefficiencies-zero-variance prompts that waste rollouts, unstable importance sampling over long horizons, advantage inversion from standard reward models, and systemic bottlenecks in rollout processing. To overcome these challenges, we introduce several unified innovations: (1) Multi-Stage Zero-Variance Elimination, which filters out non-informative prompts and stabilizes group-based policy optimization (e.g. GRPO) by removing wasted rollouts; (2) ESPO, an entropy-adaptive optimization method that balances token-level and sequence-level importance sampling to maintain stable learning dynamics; (3) a Router Replay strategy that aligns training-time MoE router decisions with inference-time behavior to mitigate train-infer discrepancies, coupled with a reward model adjustment to prevent advantage inversion; (4) a high-throughput RL system with FP8-precision rollouts, overlapped reward computation, and length-aware scheduling to eliminate performance bottlenecks. Together, these contributions form a cohesive pipeline that makes RL on hundred-billion-scale MoE models stable and efficient. The resulting model delivers strong performance across both internal and public evaluations.

</details>


### [64] [RL-MTJail: Reinforcement Learning for Automated Black-Box Multi-Turn Jailbreaking of Large Language Models](https://arxiv.org/abs/2512.07761)
*Xiqiao Xiong,Ouxiang Li,Zhuo Liu,Moxin Li,Wentao Shi,Fuli Feng,Xiangnan He*

Main category: cs.AI

TL;DR: 该论文提出了一种基于强化学习的多轮越狱攻击方法，通过训练攻击者LLM来诱导黑盒模型生成有害内容，相比单轮优化方法显著提高了攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型容易受到越狱攻击的威胁，影响其在现实应用中的安全部署。现有方法通常依赖单轮优化，不足以学习长期攻击策略，需要更有效的多轮攻击方法。

Method: 将问题形式化为多轮强化学习任务，直接优化最终轮输出的有害性作为结果奖励。提出两种启发式过程奖励：1) 控制中间输出的有害性以避免触发黑盒模型的拒绝机制；2) 保持中间输出的语义相关性以避免偏离主题。

Result: 在多个基准测试上的实验结果显示，该方法在多个模型上持续提高了攻击成功率，证明了方法的有效性。

Conclusion: 提出的基于强化学习的多轮越狱攻击方法能够有效训练攻击者LLM，通过优化长期攻击策略显著提高对黑盒模型的攻击成功率，为模型安全研究提供了重要参考。

Abstract: Large language models are vulnerable to jailbreak attacks, threatening their safe deployment in real-world applications. This paper studies black-box multi-turn jailbreaks, aiming to train attacker LLMs to elicit harmful content from black-box models through a sequence of prompt-output interactions. Existing approaches typically rely on single turn optimization, which is insufficient for learning long-term attack strategies. To bridge this gap, we formulate the problem as a multi-turn reinforcement learning task, directly optimizing the harmfulness of the final-turn output as the outcome reward. To mitigate sparse supervision and promote long-term attack strategies, we propose two heuristic process rewards: (1) controlling the harmfulness of intermediate outputs to prevent triggering the black-box model's rejection mechanisms, and (2) maintaining the semantic relevance of intermediate outputs to avoid drifting into irrelevant content. Experimental results on multiple benchmarks show consistently improved attack success rates across multiple models, highlighting the effectiveness of our approach. The code is available at https://github.com/xxiqiao/RL-MTJail. Warning: This paper contains examples of harmful content.

</details>


### [65] [ReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning](https://arxiv.org/abs/2512.07795)
*Nearchos Potamitis,Lars Klein,Akhil Arora*

Main category: cs.AI

TL;DR: ReasonBENCH是首个量化LLM推理不稳定性的基准，通过多轮评估协议提供统计可靠的质量和成本指标，揭示当前推理方法普遍存在高不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM推理评估主要报告单次运行准确率，忽略了随机解码带来的内在不确定性，导致无法可靠评估方法的稳定性、可重复性和成本一致性。

Method: 开发ReasonBENCH基准，包含：(1)标准化推理框架、模型和任务的模块化评估库；(2)报告统计可靠质量和成本指标的多轮评估协议；(3)鼓励方差感知报告的公共排行榜。

Result: 大多数推理策略和模型表现出高不稳定性，即使平均性能相似的策略置信区间宽度差异可达4倍，且性能最佳的方法通常成本更高且更不稳定。

Conclusion: 可重复性是可靠LLM推理的关键维度，ReasonBENCH为未来推理方法和不确定性量化技术提供了基础，强调了方差感知评估的重要性。

Abstract: Large language models (LLMs) are increasingly deployed in settings where reasoning, such as multi-step problem solving and chain-of-thought, is essential. Yet, current evaluation practices overwhelmingly report single-run accuracy while ignoring the intrinsic uncertainty that naturally arises from stochastic decoding. This omission creates a blind spot because practitioners cannot reliably assess whether a method's reported performance is stable, reproducible, or cost-consistent. We introduce ReasonBENCH, the first benchmark designed to quantify the underlying instability in LLM reasoning. ReasonBENCH provides (i) a modular evaluation library that standardizes reasoning frameworks, models, and tasks, (ii) a multi-run protocol that reports statistically reliable metrics for both quality and cost, and (iii) a public leaderboard to encourage variance-aware reporting. Across tasks from different domains, we find that the vast majority of reasoning strategies and models exhibit high instability. Notably, even strategies with similar average performance can display confidence intervals up to four times wider, and the top-performing methods often incur higher and less stable costs. Such instability compromises reproducibility across runs and, consequently, the reliability of reported performance. To better understand these dynamics, we further analyze the impact of prompts, model families, and scale on the trade-off between solve rate and stability. Our results highlight reproducibility as a critical dimension for reliable LLM reasoning and provide a foundation for future reasoning methods and uncertainty quantification techniques. ReasonBENCH is publicly available at https://github.com/au-clan/ReasonBench .

</details>


### [66] [Large Causal Models from Large Language Models](https://arxiv.org/abs/2512.07796)
*Sridhar Mahadevan*

Main category: cs.AI

TL;DR: 提出DEMOCRITUS系统，利用大语言模型构建大规模因果模型，通过提取、组织和可视化跨领域因果知识，将碎片化因果陈述整合为连贯的因果三元组网络。


<details>
  <summary>Details</summary>
Motivation: 传统因果推理局限于狭窄领域和假设驱动，依赖实验产生的数值数据。本文旨在利用LLMs的巨大潜力，构建跨越不同领域的大规模因果模型，从文本中提取和组织因果知识。

Method: 使用高质量LLM提出主题、生成因果问题、从多领域提取因果陈述，然后通过新的范畴机器学习方法将这些碎片化、可能冲突的因果主张转化为关系因果三元组，嵌入大规模因果模型。系统包含六个模块的流水线。

Result: 在考古学、生物学、气候变化、经济学、医学和技术等多个领域应用DEMOCRITUS系统，展示了其跨领域构建因果模型的能力。分析了系统的计算成本特征，确定了扩展到大模型的瓶颈。

Conclusion: DEMOCRITUS为构建大规模因果模型提供了新范式，但当前系统仍有局限性，需要进一步扩展能力。论文主要关注系统构建方面，新的范畴机器学习方法仅简要总结。

Abstract: We introduce a new paradigm for building large causal models (LCMs) that exploits the enormous potential latent in today's large language models (LLMs). We describe our ongoing experiments with an implemented system called DEMOCRITUS (Decentralized Extraction of Manifold Ontologies of Causal Relations Integrating Topos Universal Slices) aimed at building, organizing, and visualizing LCMs that span disparate domains extracted from carefully targeted textual queries to LLMs. DEMOCRITUS is methodologically distinct from traditional narrow domain and hypothesis centered causal inference that builds causal models from experiments that produce numerical data. A high-quality LLM is used to propose topics, generate causal questions, and extract plausible causal statements from a diverse range of domains. The technical challenge is then to take these isolated, fragmented, potentially ambiguous and possibly conflicting causal claims, and weave them into a coherent whole, converting them into relational causal triples and embedding them into a LCM. Addressing this technical challenge required inventing new categorical machine learning methods, which we can only briefly summarize in this paper, as it is focused more on the systems side of building DEMOCRITUS. We describe the implementation pipeline for DEMOCRITUS comprising of six modules, examine its computational cost profile to determine where the current bottlenecks in scaling the system to larger models. We describe the results of using DEMOCRITUS over a wide range of domains, spanning archaeology, biology, climate change, economics, medicine and technology. We discuss the limitations of the current DEMOCRITUS system, and outline directions for extending its capabilities.

</details>


### [67] [Auditing Games for Sandbagging](https://arxiv.org/abs/2512.07810)
*Jordan Taylor,Sid Black,Dillon Bowen,Thomas Read,Satvik Golechha,Alex Zelenka-Martin,Oliver Makins,Connor Kissane,Kola Ayonrinde,Jacob Merizian,Samuel Marks,Chris Cundy,Joseph Bloom*

Main category: cs.AI

TL;DR: 论文通过审计游戏测试沙袋化检测技术，发现现有方法难以可靠识别故意隐藏能力的AI模型，但基于训练的激发方法能有效引出隐藏能力，不过存在误报风险。


<details>
  <summary>Details</summary>
Motivation: 未来AI系统可能在评估中故意隐藏能力（沙袋化），误导开发者和审计者。需要测试现有检测技术是否能有效识别这种欺骗行为。

Method: 采用红蓝对抗审计游戏：红队微调5个模型（部分有条件地表现不佳作为沙袋化代理），蓝队使用黑盒、模型内部或基于训练的方法来识别沙袋化模型。

Result: 蓝队无法可靠区分沙袋化模型与良性模型。黑盒方法被有效模仿较弱模型的行为击败。线性探针（模型内部方法）更有希望但易受红队植入行为影响。基于训练的激发能一致引出沙袋化模型的全部性能，但也会提升良性模型性能，导致误报。

Conclusion: 短期建议开发者使用分布内训练消除潜在沙袋化；长期需要进一步研究确保基于训练激发的有效性，并开发更稳健的沙袋化检测方法。

Abstract: Future AI systems could conceal their capabilities ('sandbagging') during evaluations, potentially misleading developers and auditors. We stress-tested sandbagging detection techniques using an auditing game. First, a red team fine-tuned five models, some of which conditionally underperformed, as a proxy for sandbagging. Second, a blue team used black-box, model-internals, or training-based approaches to identify sandbagging models. We found that the blue team could not reliably discriminate sandbaggers from benign models. Black-box approaches were defeated by effective imitation of a weaker model. Linear probes, a model-internals approach, showed more promise but their naive application was vulnerable to behaviours instilled by the red team. We also explored capability elicitation as a strategy for detecting sandbagging. Although Prompt-based elicitation was not reliable, training-based elicitation consistently elicited full performance from the sandbagging models, using only a single correct demonstration of the evaluation task. However the performance of benign models was sometimes also raised, so relying on elicitation as a detection strategy was prone to false-positives. In the short-term, we recommend developers remove potential sandbagging using on-distribution training for elicitation. In the longer-term, further research is needed to ensure the efficacy of training-based elicitation, and develop robust methods for sandbagging detection. We open source our model organisms at https://github.com/AI-Safety-Institute/sandbagging_auditing_games and select transcripts and results at https://huggingface.co/datasets/sandbagging-games/evaluation_logs . A demo illustrating the game can be played at https://sandbagging-demo.far.ai/ .

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [68] [Spatial Analysis for AI-segmented Histopathology Images: Methods and Implementation](https://arxiv.org/abs/2512.06116)
*Y. Park,F. Wu,X. Feng,S. Yang,E. H. Wang,B. Yao,C. Moon,G. Xiao,Q. Li*

Main category: stat.AP

TL;DR: SASHIMI是一个基于浏览器的工具，用于对AI分割的组织病理学图像进行实时空间分析，通过计算多种空间描述符来量化细胞空间组织，并在癌症数据集中识别与患者生存相关的空间特征。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对AI分割组织病理学图像中复杂细胞空间组织进行定量分析的可访问工具，尽管机器学习已能大规模分割和分类细胞核，但定量分析工具仍然有限。

Method: 首先回顾了27种传统空间统计方法，然后开发了SASHIMI工具，该工具计算全面的数学描述符，包括空间统计、基于邻近度的度量、网格级相似性指数、空间自相关度量和拓扑描述符。

Result: 在口腔潜在恶性病变和非小细胞肺癌两个癌症数据集中，SASHIMI识别出多个与患者生存结果显著相关的空间特征。

Conclusion: SASHIMI为肿瘤形态结构的单细胞级空间分析提供了一个可访问且可重复的平台，为跨癌症类型的组织组织定量探索提供了稳健框架。

Abstract: Quantitatively characterizing the spatial organization of cells and their interaction is essential for understanding cancer progression and immune response. Recent advances in machine intelligence have enabled large-scale segmentation and classification of cell nuclei from digitized histopathology slides, generating massive point pattern and marked point pattern datasets. However, accessible tools for quantitative analysis of such complex cellular spatial organization remain limited. In this paper, we first review 27 traditional spatial summary statistics, areal indices, and topological features applicable to point pattern data. Then, we introduce SASHIMI (Spatial Analysis for Segmented Histopathology Images using Machine Intelligence), a browser-based tool for real-time spatial analysis of artificial intelligence (AI)-segmented histopathology images. SASHIMI computes a comprehensive suite of mathematically grounded descriptors, including spatial statistics, proximity-based measures, grid-level similarity indices, spatial autocorrelation measures, and topological descriptors, to quantify cellular abundance and cell-cell interaction. Applied to two cancer datasets, oral potentially malignant disorders (OPMD) and non-small-cell lung cancer (NSCLC), SASHIMI identified multiple spatial features significantly associated with patient survival outcomes. SASHIMI provides an accessible and reproducible platform for single-cell-level spatial profiling of tumor morphological architecture, offering a robust framework for quantitative exploration of tissue organization across cancer types.

</details>


### [69] [Mode Choice Heterogeneity Among Zero-Vehicle Households: A Latent Class Cluster Approach](https://arxiv.org/abs/2512.06127)
*Nancy Kasamala,Arthur Mukwaya,Nana Kankam Gyimah,Judith Mwakalonge,Gurcan Comert,Saidi Siuhi,Akinbobola Jegede*

Main category: stat.AP

TL;DR: 该研究通过潜在类别聚类分析，将零车辆家庭分为三类不同出行模式群体，打破了传统将零车辆家庭视为单一群体的假设，为差异化交通规划提供依据。


<details>
  <summary>Details</summary>
Motivation: 传统交通规划中将零车辆家庭视为单一群体，假设他们主要依赖步行或公共交通，忽视了不同出行需求和人口特征下的多样化出行策略。本研究旨在揭示零车辆家庭内部的异质性出行模式。

Method: 使用加权潜在类别聚类分析，基于2022年全国家庭出行调查数据，以出行方式和出行目的为指标，以人口、经济和建成环境变量为协变量，识别零车辆家庭的不同潜在类别。

Result: 识别出三类零车辆家庭：共享出行通勤者（36.3%），主要使用公交和网约车通勤和进行必要活动；汽车依赖购物者（29.9%），依赖非正式车辆进行较长距离的休闲出行；活跃出行购物者（33.8%），依赖步行或骑行进行短距离本地购物出行。

Conclusion: 零车辆家庭内部存在显著的行为异质性，这一发现有助于政策制定者根据不同群体的具体需求，在多样化的地理和人口环境中制定差异化的规划解决方案。

Abstract: In transportation planning, Zero-Vehicle Households (ZVHs) are often treated as a uniform group with limited mobility options and assumed to rely heavily on walking or public transit. However, such assumptions overlook the diverse travel strategies ZVHs employ in response to varying trip needs and sociodemographic factors. This study addresses this gap by applying a weighted Latent Class Cluster Analysis (LCCA) to data from the 2022 National Household Travel Survey (NHTS) to uncover distinct mobility patterns within the ZVH population. Using travel mode and trip purpose as indicators and demographic, economic, and built environment variables as covariates, we identified three latent classes :Shared mobility errand workers (36.3%), who primarily use transit and ridehailing for commuting and essential activities; car based shoppers (29.9%), who depend on informal vehicle access for longer discretionary trips and active travel Shoppers (33.8%), who rely on walking or cycling for short, local shopping oriented travel. These behavioral findings enable policymakers to develop differentiated planning solutions to the specific needs of each segment among the ZVHs population across varied geographic and demographic settings.

</details>


### [70] [Forests of Uncertaint(r)ees: Using tree-based ensembles to estimate probability distributions of future conflict](https://arxiv.org/abs/2512.06210)
*Daniel Mittermaier,Tobias Bohne,Martin Hofer,Daniel Racek*

Main category: stat.AP

TL;DR: 该论文提出了一种量化冲突预测不确定性的方法，通过从点预测转向完整预测分布，使用自动机器学习框架结合多种树基分类器和分布回归器，在PRIO-GRID月度层面进行个体化分布估计。


<details>
  <summary>Details</summary>
Motivation: PRIO-GRID月度层面的暴力冲突死亡人数预测存在高度不确定性，限制了其在实际应用中的有效性。论文旨在解决这一预测任务中的两大不确定性来源：暴力冲突的本质特性和数据限制，并将其置于机器学习不确定性量化更广泛的文献背景中。

Method: 开发了一种量化冲突预测不确定性的策略，从传统点预测转向完整预测分布。采用自定义自动机器学习设置，比较和结合多种树基分类器和分布回归器，为每个PRIO-GRID月度单元单独估计分布。同时测试了将区域模型集成到空间集成中作为减少不确定性的潜在途径。

Result: 模型能够持续优于基于冲突历史的一系列基准预测，预测时间跨度可达一年，性能提升主要出现在观察到冲突的区域。评估强调了需要理解指标在特定预测问题中的行为，特别是针对极端高零膨胀特性的情况。虽然集成较小模型未能带来更好的预测，但也没有降低性能，为未来整合空间覆盖较少的数据源开辟了途径。

Conclusion: 该研究成功开发了一种量化冲突预测不确定性的方法，通过预测分布而非点估计来提供更全面的信息。虽然空间集成未能显著改善预测性能，但为整合有限空间覆盖的数据源提供了可能性，强调了在零膨胀预测问题中理解指标行为的重要性。

Abstract: Predictions of fatalities from violent conflict on the PRIO-GRID-month (pgm) level are characterized by high levels of uncertainty, limiting their usefulness in practical applications. We discuss the two main sources of uncertainty for this prediction task, the nature of violent conflict and data limitations, embedding this in the wider literature on uncertainty quantification in machine learning. We develop a strategy to quantify uncertainty in conflict forecasting, shifting from traditional point predictions to full predictive distributions. Our approach compares and combines multiple tree-based classifiers and distributional regressors in a custom auto-ML setup, estimating distributions for each pgm individually. We also test the integration of regional models in spatial ensembles as a potential avenue to reduce uncertainty. The models are able to consistently outperform a suite of benchmarks derived from conflict history in predictions up to one year in advance, with performance driven by regions where conflict was observed. With our evaluation, we emphasize the need to understand how a metric behaves for a given prediction problem, in our case characterized by extremely high zero-inflatedness. While not resulting in better predictions, the integration of smaller models does not decrease performance for this prediction task, opening avenues to integrate data sources with less spatial coverage in the future.

</details>


### [71] [Spatio-temporal Shared-Field Modeling of Beluga and Bowhead Whale Sightings Using a Joint Marked Log-Gaussian Cox Process](https://arxiv.org/abs/2512.06450)
*Mauli Pant,Linda Fernandez,Indranil Sahoo*

Main category: stat.AP

TL;DR: 该研究开发了一种多物种对数高斯Cox过程模型，结合共享潜在空间场，用于联合分析2010-2019年美国北极地区白鲸和弓头鲸的时空分布与群体大小。


<details>
  <summary>Details</summary>
Motivation: 在数据稀疏且调查环境异质的北极地区，需要开发能够同时分析多个鲸鱼物种分布的方法，以更好地理解它们的空间格局和生态关系。

Method: 开发了多物种对数高斯Cox过程模型，通过共享潜在空间高斯场连接物种特定强度表面，使用SPDE方法表示各向异性Matern协方差，在海洋约束三角网格上实现，并扩展为标记点过程以分析群体大小。

Result: 模型成功识别了持续的多物种热点区域，并揭示了每个物种独特的环境关联，证明了共享场LGCP在数据稀疏调查环境中的有效性。

Conclusion: 共享潜在场LGCP框架为联合物种分布建模提供了有力工具，特别适用于数据稀疏的海洋调查环境，能够同时分析物种出现和群体大小。

Abstract: We analyze a decade of aerial survey whale sighting data (2010-2019) to model the spatio-temporal distributions and group sizes of beluga (Delphinapterus leucas) and bowhead (Balaena mysticetus) whales in the United States Arctic. To jointly model these species, we develop a multi-species Log-Gaussian Cox Process (LGCP) in which species specific intensity surfaces are linked through a shared latent spatial Gaussian field. This structure allows the model to capture broad spatial patterns common to both species while still accommodating species level responses to environmental covariates and seasonal variation. The latent field is represented using the Stochastic Partial Differential Equation (SPDE) approach with an anisotropic Matern covariance, implemented on an ocean constrained triangulated mesh so that spatial dependence aligns with marine geography. Whale group size is incorporated through a marked point process extension with species specific negative binomial marks, allowing occurrence and group sizes to be jointly analyzed within a unified framework. Inference is carried out using the Integrated Nested Laplace Approximation (INLA), enabling efficient model fitting over a decade of survey effort. The results highlight persistent multi-species hotspots and distinct environmental associations for each species, demonstrating the value of shared field LGCPs for joint species distribution modeling in data sparse and heterogeneous survey settings.

</details>


### [72] [A Latent Variable Framework for Scaling Laws in Large Language Models](https://arxiv.org/abs/2512.06553)
*Peiyao Cai,Chengyu Cui,Felipe Maia Polo,Seamus Somerstep,Leshem Choshen,Mikhail Yurochkin,Moulinath Banerjee,Yuekai Sun,Kean Ming Tan,Gongjun Xu*

Main category: stat.AP

TL;DR: 提出基于潜变量建模的统计框架，用于分析大语言模型的缩放定律，解决不同模型架构和基准测试的异质性问题。


<details>
  <summary>Details</summary>
Motivation: 随着越来越多具有不同架构和训练策略的LLM家族出现，以及评估基准不断增加，单一的全局缩放曲线无法准确捕捉不同模型家族和基准测试之间的性能变化。

Method: 提出潜变量建模框架：每个LLM家族关联一个潜变量，捕捉该家族的共同特征；模型在不同基准上的性能由其潜变量技能驱动，这些技能由潜变量和模型可观测特征共同决定。开发了相应的估计方法和高效数值算法。

Result: 在Open LLM Leaderboard的12个广泛使用的基准测试上进行了实证评估。

Conclusion: 该框架能够更好地建模不同LLM家族和基准测试之间的异质性，为理解大语言模型的缩放规律提供了更精细的统计工具。

Abstract: We propose a statistical framework built on latent variable modeling for scaling laws of large language models (LLMs). Our work is motivated by the rapid emergence of numerous new LLM families with distinct architectures and training strategies, evaluated on an increasing number of benchmarks. This heterogeneity makes a single global scaling curve inadequate for capturing how performance varies across families and benchmarks. To address this, we propose a latent variable modeling framework in which each LLM family is associated with a latent variable that captures the common underlying features in that family. An LLM's performance on different benchmarks is then driven by its latent skills, which are jointly determined by the latent variable and the model's own observable features. We develop an estimation procedure for this latent variable model and establish its statistical properties. We also design efficient numerical algorithms that support estimation and various downstream tasks. Empirically, we evaluate the approach on 12 widely used benchmarks from the Open LLM Leaderboard (v1/v2).

</details>


### [73] [Disentangling the Mediation Pathways of Depression in Asian Students and Workers](https://arxiv.org/abs/2512.06654)
*Zhaojin Nan,Ran Chen*

Main category: stat.AP

TL;DR: 该研究比较了学生和工作者群体中抑郁的预测因素，发现压力是跨群体的最强预测因子，年龄对学生和工作者有相反影响，模型内部准确性中等但跨国家泛化能力较弱。


<details>
  <summary>Details</summary>
Motivation: 抑郁症是全球主要心理健康问题，受文化、人口和职业因素影响。研究旨在比较学生和工作者群体中抑郁的预测因素，了解不同亚群的特异性效应，为针对性干预提供依据。

Method: 使用印度、马来西亚和中国的数据集，将印度数据分为学生和工作者组，马来西亚只有学生数据，中国只有工作者数据。在变量协调后，应用逻辑回归、随机森林和因果森林模型识别关键预测因子和亚群特异性效应，并进行因果中介分析评估变量是否通过压力等中介变量起作用。

Result: 学生群体中压力、年龄、工作量、财务压力、心理健康史和满意度是显著预测因子；工作者群体类似。年龄效应相反：年轻学生抑郁风险更高，而年长工作者风险更高。随机森林表现优于逻辑回归，模型内部准确性中等但跨国家泛化能力较弱。因果森林显示压力效应异质性有限，因果中介分析表明压力不中介年龄效应但更直接起作用，满意度部分通过压力影响抑郁。

Conclusion: 压力是跨学生和工作者群体最一致的强预测因子，表明针对学术和职业压力的干预可能有助于减少抑郁症状。研究强调了考虑亚群特异性效应的重要性，并为跨文化心理健康干预提供了实证基础。

Abstract: Depression is a major global mental health issue shaped by cultural, demographic, and occupational factors. This study compares predictors of depression across student and worker populations using datasets from India, Malaysia, and China. The India dataset was split into student and worker groups, while the Malaysia dataset includes only students and the China (CHARLS) dataset includes only workers. After harmonizing variables, we applied logistic regression, random forest, and causal forest models to identify key predictors and subgroup-specific effects, and conducted causal mediation analysis (CMA) to assess whether variables operate through intermediaries such as perceived pressure. Among students, pressure, age, workload, financial stress, mental health history, and satisfaction were significant predictors; similar factors emerged for workers. Notably, age showed opposite effects across groups: younger students were more likely to experience depression, whereas older workers showed higher risk. Model performance showed moderate internal accuracy but weaker external generalizability across countries, with random forest outperforming logistic regression. Causal forest results indicated limited heterogeneity in the effect of pressure, while CMA showed that pressure does not mediate the effect of age but operates more directly, and satisfaction influences depression partly through pressure. Overall, pressure consistently emerged as the strongest predictor, suggesting that interventions targeting academic and occupational stress may help reduce depressive symptoms.

</details>


### [74] [Partially Observable Markov Decision Process Framework for Operating Condition Optimization Using Real-Time Degradation Signals](https://arxiv.org/abs/2512.06682)
*Boyang Xu,Yunyi Kang,Xinyu Zhao,Hao Yan,Feng Ju*

Main category: stat.AP

TL;DR: 提出一个基于部分可观测马尔可夫决策过程(POMDP)的系统决策框架，用于联合优化运行容量和预测性维护策略，利用多传感器实时退化信号提高制造系统性能。


<details>
  <summary>Details</summary>
Motivation: 在工程系统中，预测性维护和运行控制对提高效率、可靠性和降低维护成本至关重要。主要挑战在于多传感器监测数据的同步分析困难，需要系统化方法来利用实时退化信号进行联合优化。

Method: 提出部分可观测马尔可夫决策过程(POMDP)模型，考虑系统状态观测的不完美性，生成最优容量和预测性维护策略。该方法结合退化约束和不可观测状态，利用实时机器退化信号联合控制运行条件和预防性维护。

Result: 将所提技术应用于轴承退化数据和NASA飞机涡轮风扇发动机数据集，证明了该方法的有效性。

Conclusion: 该研究提供了一个系统化方法，通过整合退化约束和不可观测状态，利用实时机器退化信号联合控制运行条件和预防性维护，为制造实践中的系统性能改进提供了有效框架。

Abstract: In many engineering systems, proper predictive maintenance and operational control are essential to increase efficiency and reliability while reducing maintenance costs. However, one of the major challenges is that many sensors are used for system monitoring. Analyzing these sensors simultaneously for better predictive maintenance optimization is often very challenging. In this paper, we propose a systematic decision-making framework to improve the system performance in manufacturing practice, considering the real-time degradation signals generated by multiple sensors. Specifically, we propose a partially observed Markov decision process (POMDP) model to generate the optimal capacity and predictive maintenance policies, given the fact that the observation of the system state is imperfect. Such work provides a systematic approach that focuses on jointly controlling the operating conditions and preventive maintenance utilizing the real-time machine deterioration signals by incorporating the degradation constraint and non-observable states. We apply this technique to the bearing degradation data and NASA aircraft turbofan engine dataset, demonstrating the effectiveness of the proposed method.

</details>


### [75] [Machine Learning-based Unfolding for Cross Section Measurements in the Presence of Nuisance Parameters](https://arxiv.org/abs/2512.07074)
*Huanbiao Zhu,Krish Desai,Mikael Kuusela,Vinicius Mikuni,Benjamin Nachman,Larry Wasserman*

Main category: stat.AP

TL;DR: 提出Profile OmniFold算法，将机器学习反卷积方法扩展到包含nuisance参数，解决探测器效应校正中的模型不确定性


<details>
  <summary>Details</summary>
Motivation: 在粒子物理实验中，探测器效应校正（反卷积）是重要步骤。现有OmniFold算法虽然能处理高维数据，但假设前向模型精确已知，而实际中探测器模型存在不确定性，需要通过nuisance参数编码

Method: 基于OmniFold算法，提出Profile OmniFold方法，将分类器为基础的期望最大化过程扩展到包含nuisance参数。通过profile似然方法处理模型不确定性

Result: 使用高斯示例和CMS实验模拟数据进行验证，展示了新算法能有效处理包含nuisance参数的反卷积问题

Conclusion: Profile OmniFold成功将机器学习反卷积方法扩展到包含模型不确定性的情况，为实际实验数据分析提供了更完整的工具

Abstract: Statistically correcting measured cross sections for detector effects is an important step across many applications. In particle physics, this inverse problem is known as \textit{unfolding}. In cases with complex instruments, the distortions they introduce are often known only implicitly through simulations of the detector. Modern machine learning has enabled efficient simulation-based approaches for unfolding high-dimensional data. Among these, one of the first methods successfully deployed on experimental data is the \textsc{OmniFold} algorithm, a classifier-based Expectation-Maximization procedure. In practice, however, the forward model is only approximately specified, and the corresponding uncertainty is encoded through nuisance parameters. Building on the well-studied \textsc{OmniFold} algorithm, we show how to extend machine learning-based unfolding to incorporate nuisance parameters. Our new algorithm, called Profile \textsc{OmniFold}, is demonstrated using a Gaussian example as well as a particle physics case study using simulated data from the CMS Experiment at the Large Hadron Collider.

</details>


### [76] [Big shells, bigger data: cohort analysis of Chesapeake Bay Crassostrea virginica reefs](https://arxiv.org/abs/2512.07080)
*Madison D. Griffin,Grace S. Chiu,Roger L. Mann,Melissa J. Southworth,John K. Thomas*

Main category: stat.AP

TL;DR: 利用高斯混合模型分析弗吉尼亚切萨皮克湾牡蛎壳长数据，开发新方法识别年龄组和估计寿命，发现2010年代中后期牡蛎比2000年代早期寿命更长、体型更大，显示恢复力迹象。


<details>
  <summary>Details</summary>
Motivation: 弗吉尼亚切萨皮克湾牡蛎礁存在"年龄截断"现象，可能由历史过度捕捞、疾病爆发、环境退化和气候变化共同导致。虽然研究表明牡蛎对环境压力具有恢复力，但这一证据基于当前对牡蛎寿命的有限理解。VOSARA数据集（2003-2023年222个礁体的壳长数据）尚未在恢复力背景下进行全面分析。

Method: 开发基于高斯混合模型（GMM）的新方法：1）对每个河流层、礁体和年份的壳长数据进行单变量GMM拟合，估计每个年龄组的平均壳长、标准差和混合比例；2）开发机制算法将时间序列上的年龄组连接成年龄队列，防止壳长随时间缩小；3）仅使用壳长数据识别牡蛎队列并估计寿命。

Result: 64个礁体（29%）数据充足（至少连续8年采样300只牡蛎）。结果显示几乎所有河流系统都显示出恢复力信号：与2000年代早期相比，2010年代中后期的牡蛎队列寿命更长、体型更大。

Conclusion: 该方法仅使用壳长数据就能有效识别牡蛎队列和估计寿命。研究结果表明切萨皮克湾牡蛎在2010年代中后期显示出恢复力增强的迹象，为牡蛎种群管理和保护提供了重要见解。

Abstract: Oysters in Virginia Chesapeake Bay oyster reefs are "age-truncated", possibly due to a combination of historical overfishing, disease epizootics, environmental degradation, and climate change. Research has suggested that oysters exhibit resilience to environmental stressors; however, that evidence is based on the current limited understanding of oyster lifespan. Until this paper, the Virginia Oyster Stock Assessment and Replenishment Archive (VOSARA), a spatially and temporally expansive dataset (222 reefs across 2003-2023) of shell lengths (SL, mm), had yet to be examined comprehensively in the context of resilience. We develop a novel method using Gaussian mixture modeling (GMM) to identify the age groups in each reef using yearly SL data and then link those age groups over time to identify cohorts and estimate their lifespan. Sixty-four reefs (29%) are deemed to have sufficient data (at least 300 oysters sampled for a minimum of 8 consecutive years) for this analysis. We fit univariate GMMs for each year ($t$) and reef ($r$) for each of the seven river strata ($R$) to estimate 1) the mean and standard deviation of SL for each $a_{Rrt}$th age group, and 2) the mixture percentage of each $a_{Rrt}$th age group. We link age groups across time to infer age cohorts by developing a mechanistic algorithm that prevents the shrinking of shell length when an $a_{Rrt}$th group becomes an ($a_{R,r,t+1}$)th group. Our method shows promise in identifying oyster cohorts and estimating lifespan solely using SL data. Our results show signals of resiliency in almost all river systems: oyster cohorts live longer and grow larger in the mid-to-late 2010s compared to the early 2000s.

</details>


### [77] [Facilitating Conditions as an Enabler, Not a Direct Motivator: A Robustness and Mediation Analysis of E-Learning Adoption](https://arxiv.org/abs/2512.07185)
*Jaka Nugraha,Noyyn Sun,Xinlin Zhao,Vindi Kusuma Wardani,Inna Koblianska,Jiunn-Woei Lian*

Main category: stat.AP

TL;DR: 研究发现：在UTAUT框架中，便利条件(FC)对行为意向(BI)无直接影响，而是通过增强绩效期望和努力期望间接发挥作用，揭示了技术基础设施的真正价值在于优化学习体验而非单纯提供工具。


<details>
  <summary>Details</summary>
Motivation: 尽管机构大量投资于电子学习基础设施，但学生参与度往往达不到预期，这与UTAUT框架中便利条件(FC)直接影响行为意向的传统假设相矛盾，需要重新理解FC在电子学习环境中的实际作用机制。

Method: 对470名印尼大学生进行实证研究，采用多阶段分析方法：首先验证绩效期望、努力期望、社会影响和感知愉悦对行为意向的直接影响，然后检验便利条件对行为意向的直接和间接影响，最后通过中介模型揭示FC的作用路径。

Result: 绩效期望(β=0.190)、努力期望(β=0.198)、社会影响(β=0.151)和感知愉悦(β=0.472)显著影响行为意向，行为意向又强烈预测使用行为(β=0.666)。但便利条件对行为意向的直接效应不显著(β=-0.085)，而是通过显著增强绩效期望(β=0.556)和努力期望(β=0.419)间接发挥作用。

Conclusion: 技术基础设施的价值不在于其存在本身，而在于其动态优化学习体验的能力。研究提出了"赋能路径"理论框架，建议管理者将技术投资重点从单纯提供工具转向战略性地设计学习体验。

Abstract: Despite substantial institutional investment in e-learning infrastructure, student engagement often fails to meet expectations--a persistent paradox that challenges the established direct relationship between Facilitating Conditions (FC) and behavioral intention within the classic UTAUT framework. To resolve this theoretical puzzle, we reconceptualized the role of FC through an empirical study of 470 Indonesian university students. Our robust, multi-stage analytical approach first confirmed the significant influence of established drivers--Performance Expectancy (beta=0.190), Effort Expectancy (beta=0.198), Social Influence (beta=0.151), and Perceived Enjoyment (beta=0.472)--on Behavioral Intention (BI), which in turn strongly predicted Use Behavior (beta=0.666). Crucially, however, the direct effect of FC on BI proved non-significant (beta=-0.085). A subsequent mediation model revealed FC's true function as a foundational enabling construct that operates indirectly by powerfully enhancing both Performance Expectancy (beta=0.556) and Effort Expectancy (beta=0.419). Our findings demonstrate that the value of technological infrastructure lies not in its mere presence, but in its dynamic capacity to enable learning and optimize user experience. This research advances a refined "enabling pathway" theoretical framework, guiding administrators to shift the focus of technological investment from merely providing tools to strategically crafting learning experiences.

</details>


### [78] [Bridging CORDEX and CMIP6: Machine Learning Downscaling for Wind and Solar Energy Droughts in Central Europe](https://arxiv.org/abs/2512.07429)
*Nina Effenberger,Maxim Samarin,Maybritt Schillinger,Reto Knutti*

Main category: stat.AP

TL;DR: 本文提出一种基于机器学习的区域气候模拟器，能够高效地将全球气候模型数据降尺度为高分辨率区域数据，用于评估气候变化对可再生能源的影响。


<details>
  <summary>Details</summary>
Motivation: 传统的区域气候模型（如CORDEX）计算成本高且组织困难，而高分辨率区域气候信息对于评估气候变化影响和可再生能源规划至关重要。需要一种更高效的方法来获取可靠的区域气候数据。

Method: 开发机器学习模拟器，学习全球气候场与区域气候场之间的映射关系。使用CMIP5和CORDEX模拟数据进行训练，然后应用于未见过的CMIP6模拟数据。使用CORDEX数据、CMIP5和CMIP6模拟以及两个机器学习模型生成的区域数据，分析低风速和低太阳辐射同时发生的现象。

Result: 模拟器能够准确再现区域气候模型数据，在未见过的CMIP6模拟数据上也产生真实结果，表明性能稳定。分析发现未来低风速和低太阳辐射同时发生的能源干旱天数可能会减少。

Conclusion: 机器学习降尺度模拟器为CORDEX等传统方法提供了高效补充，能够提供影响评估所需的高分辨率信息，是区域气候建模的有前景的替代方案。

Abstract: Reliable regional climate information is essential for assessing the impacts of climate change and for planning in sectors such as renewable energy; yet, producing high-resolution projections through coordinated initiatives like CORDEX that run multiple physical regional climate models is both computationally demanding and difficult to organize. Machine learning emulators that learn the mapping between global and regional climate fields offer a promising way to address these limitations. Here we introduce the application of such an emulator: trained on CMIP5 and CORDEX simulations, it reproduces regional climate model data with sufficient accuracy. When applied to CMIP6 simulations not seen during training, it also produces realistic results, indicating stable performance. Using CORDEX data, CMIP5 and CMIP6 simulations, as well as regional data generated by two machine learning models, we analyze the co-occurrence of low wind speed and low solar radiation and find indications that the number of such energy drought days is likely to decrease in the future. Our results highlight that downscaling with machine learning emulators provides an efficient complement to efforts such as CORDEX, supplying the higher-resolution information required for impact assessments.

</details>


### [79] [Permanent and transitory crime risk in variable-density hot spot analysis](https://arxiv.org/abs/2512.07467)
*Ben Moews*

Main category: stat.AP

TL;DR: 对芝加哥2001-2022年犯罪报告进行变密度聚类分析，研究不同密度热点区域的犯罪类型构成变化，特别关注COVID-19疫情的影响及城市功能区差异。


<details>
  <summary>Details</summary>
Motivation: 为了有效配置公共安全资源，需要基于时空数据的实证分析来制定犯罪预防措施。现有研究虽然丰富，但缺乏对犯罪类型构成在热点区域中长期演变的分析，特别是疫情等重大事件的影响。

Method: 对芝加哥市2001-2022年的犯罪事件报告进行变密度聚类分析，识别不同密度的犯罪热点区域，分析犯罪类型构成在二十年间的演变，并特别考察COVID-19疫情及社交隔离措施的影响，同时考虑城市功能区的作用。

Result: 发现犯罪类型构成在不同密度热点区域中存在显著变化；COVID-19疫情及社交隔离措施对犯罪模式产生明显影响，且这种影响因城市功能区而异；不同犯罪类型的治理难度存在差异；空间自相关分析显示不同距离半径下热点区域与异常区域的犯罪事件均匀性存在变化。

Conclusion: 研究揭示了犯罪热点区域中犯罪类型构成的长期演变规律，强调了重大事件（如疫情）和城市功能区对犯罪模式的影响，为热点警务和公共安全优化提供了实证依据，同时指出了数据偏差在犯罪学研究中的重要性。

Abstract: Crime prevention measures, aiming for the effective and efficient spending of public resources, rely on the empirical analysis of spatial and temporal data for public safety outcomes. We perform a variable-density cluster analysis on crime incident reports in the City of Chicago for the years 2001--2022 to investigate changes in crime share composition for hot spots of different densities. Contributing to and going beyond the existing wealth of research on criminological applications in the operational research literature, we study the evolution of crime type shares in clusters over the course of two decades and demonstrate particularly notable impacts of the COVID-19 pandemic and its associated social contact avoidance measures, as well as a dependence of these effects on the primary function of city areas. Our results also indicate differences in the relative difficulty to address specific crime types, and an analysis of spatial autocorrelations further shows variations in incident uniformity between clusters and outlier areas at different distance radii. We discuss our findings in the context of the interplay between operational research and criminal justice, the practice of hot spot policing and public safety optimization, and the factors contributing to, and challenges and risks due to, data biases as an often neglected factor in criminological applications.

</details>


### [80] [Meta-analyses of dietary exposures must consider energy adjustment: recommendations from a meta-scientific review](https://arxiv.org/abs/2512.07531)
*Natalia Ortega,Peter WG Tennant,Darren C Greenwood,Octavio Pano,Christina C Dahm,Russell J de Souza,Daniel B Ibsen,Conor J MacDonald,Deirdre K Tobias,Georgia D Tomova*

Main category: stat.AP

TL;DR: 该研究回顾了饱和脂肪和鱼类摄入与心血管疾病关系的荟萃分析，发现大多数研究未考虑能量调整策略的差异，导致合并了不可比较的效应估计，影响证据质量。


<details>
  <summary>Details</summary>
Motivation: 在观察性饮食研究中，能量调整策略（如调整总能量摄入或将暴露表示为总能量百分比）会显著影响效应估计，导致估计的是替代效应。如果不考虑这些策略差异，荟萃分析可能会合并不可比较的效应估计，影响研究解释和证据质量。

Method: 进行元科学回顾，识别所有研究饱和脂肪和鱼类摄入与心血管疾病关系的荟萃分析。选取每个暴露的最新的两篇和引用最多的两篇综述，并检查所有原始研究。总结研究目的、目标效应和解释等信息。

Result: 分析了8篇荟萃分析，涵盖82项原始研究的144个独特模型。仅1篇荟萃分析明确考虑了原始研究的能量调整策略以确定替代亚组分析的资格。没有荟萃分析承认它们正在合并不同效应的估计。82%的原始研究模型隐含地估计替代效应，但大多数研究目的、解释或结论中未明确说明。

Conclusion: 当前荟萃分析很少考虑原始研究的能量调整策略，导致合并估计反映的是定义不清、解释不明的量。研究提出了改进未来荟萃分析实施和提高营养建议证据质量的建议。

Abstract: In observational studies of dietary exposures, the energy adjustment strategy has a critical impact on the effect being estimated. Adjusting for total energy intake or expressing the exposure as a percentage of total energy, leads to a substitution effect being estimated. This impacts the interpretation of primary studies and meta-analyses. Unless energy adjustment strategies are considered, meta-analyses may end up pooling estimates for incomparable effects. This meta-scientific review aimed to investigate the extent to which meta-analyses of dietary exposures may be pooling incomparable effects by reviewing the energy adjustment strategies. We identified all meta-analyses examining the relationship between saturated fat and fish and cardiovascular disease. The two most recent and two most cited reviews for each exposure were examined, along with all primary studies. Information on the study aims, targeted effects, and interpretations were summarized. The eight meta-analyses summarised results from 82 primary studies including 144 unique models. Only one meta-analysis explicitly considered the energy adjustment strategy of the primary studies to determine eligibility for a substitution subgroup analysis. None of the meta-analyses acknowledged that they were pooling estimates for different effects. 82% of the models from the primary studies were implicitly estimating substitution effects but this was not explicitly stated in most study aims, interpretation or conclusions. Our meta-scientific review found little evidence that the energy adjustment strategies of the primary studies were being considered in the synthesis or interpretation of evidence. Consequently, the pooled estimates reflect ill-defined quantities with unclear interpretations. We offer recommendations to improve the conduct of future meta-analyses and the quality of evidence that informs nutritional recommendations.

</details>
