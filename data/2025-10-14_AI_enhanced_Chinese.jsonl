{"id": "2510.10527", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2510.10527", "abs": "https://arxiv.org/abs/2510.10527", "authors": ["Mingqian Guan", "Komei Fujita", "Naoya Sueishi", "Shota Yasui"], "title": "Denoised IPW-Lasso for Heterogeneous Treatment Effect Estimation in Randomized Experiments", "comment": null, "summary": "This paper proposes a new method for estimating conditional average treatment\neffects (CATE) in randomized experiments. We adopt inverse probability\nweighting (IPW) for identification; however, IPW-transformed outcomes are known\nto be noisy, even when true propensity scores are used. To address this issue,\nwe introduce a noise reduction procedure and estimate a linear CATE model using\nLasso, achieving both accuracy and interpretability. We theoretically show that\ndenoising reduces the prediction error of the Lasso. The method is particularly\neffective when treatment effects are small relative to the variability of\noutcomes, which is often the case in empirical applications. Applications to\nthe Get-Out-the-Vote dataset and Criteo Uplift Modeling dataset demonstrate\nthat our method outperforms fully nonparametric machine learning methods in\nidentifying individuals with higher treatment effects. Moreover, our method\nuncovers informative heterogeneity patterns that are consistent with previous\nempirical findings.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4f30\u8ba1\u6761\u4ef6\u5e73\u5747\u5904\u7406\u6548\u5e94(CATE)\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u566a\u58f0\u51cf\u5c11\u7a0b\u5e8f\u7ed3\u5408Lasso\u56de\u5f52\uff0c\u5728\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u4f30\u8ba1\u7cbe\u5ea6\u3002", "motivation": "IPW\u53d8\u6362\u7684\u7ed3\u679c\u901a\u5e38\u566a\u58f0\u8f83\u5927\uff0c\u5373\u4f7f\u4f7f\u7528\u771f\u5b9e\u7684\u503e\u5411\u5f97\u5206\u4e5f\u662f\u5982\u6b64\uff0c\u8fd9\u5f71\u54cd\u4e86CATE\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u9006\u6982\u7387\u52a0\u6743(IPW)\u8fdb\u884c\u8bc6\u522b\uff0c\u5f15\u5165\u566a\u58f0\u51cf\u5c11\u7a0b\u5e8f\uff0c\u5e76\u4f7f\u7528Lasso\u4f30\u8ba1\u7ebf\u6027CATE\u6a21\u578b\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u964d\u566a\u80fd\u51cf\u5c11Lasso\u7684\u9884\u6d4b\u8bef\u5dee\uff1b\u5728Get-Out-the-Vote\u548cCriteo\u6570\u636e\u96c6\u4e0a\u7684\u5e94\u7528\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8bc6\u522b\u9ad8\u5904\u7406\u6548\u5e94\u4e2a\u4f53\u65b9\u9762\u4f18\u4e8e\u975e\u53c2\u6570\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u5904\u7406\u6548\u5e94\u76f8\u5bf9\u4e8e\u7ed3\u679c\u53d8\u5f02\u6027\u8f83\u5c0f\u65f6\u7279\u522b\u6709\u6548\uff0c\u80fd\u591f\u53d1\u73b0\u4e0e\u5148\u524d\u5b9e\u8bc1\u53d1\u73b0\u4e00\u81f4\u7684\u6709\u610f\u4e49\u7684\u5f02\u8d28\u6027\u6a21\u5f0f\u3002"}}
{"id": "2510.10946", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2510.10946", "abs": "https://arxiv.org/abs/2510.10946", "authors": ["Onil Boussim"], "title": "Identifying treatment effects on categorical outcomes in IV models", "comment": null, "summary": "This paper provides a nonparametric framework for causal inference with\ncategorical outcomes under binary treatment and binary instrument settings. We\ndecompose the observed joint probability of outcomes and treatment into\nmarginal probabilities of potential outcomes and treatment, and association\nparameters that capture selection bias due to unobserved heterogeneity. Under a\nnovel identifying assumption, association similarity, which requires the\ndependence between unobserved factors and potential outcomes to be invariant\nacross treatment states, we achieve point identification of the full\ndistribution of potential outcomes. Recognizing that this assumption may be\nstrong in some contexts, we propose two weaker alternatives: monotonic\nassociation, which restricts the direction of selection heterogeneity, and\nbounded association, which constrains its magnitude. These relaxed assumptions\ndeliver sharp partial identification bounds that nest point identification as a\nspecial case and facilitate transparent sensitivity analysis. We illustrate the\nframework in an empirical application, estimating the causal effect of private\nhealth insurance on health outcomes.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7528\u4e8e\u4e8c\u5143\u5904\u7406\u548c\u4e8c\u5143\u5de5\u5177\u53d8\u91cf\u8bbe\u7f6e\u4e0b\u5206\u7c7b\u7ed3\u679c\u56e0\u679c\u63a8\u65ad\u7684\u975e\u53c2\u6570\u6846\u67b6\uff0c\u901a\u8fc7\u5173\u8054\u76f8\u4f3c\u6027\u5047\u8bbe\u5b9e\u73b0\u6f5c\u5728\u7ed3\u679c\u5206\u5e03\u7684\u7cbe\u786e\u8bc6\u522b\uff0c\u5e76\u63d0\u4f9b\u4e24\u79cd\u5f31\u5316\u5047\u8bbe\u7684\u504f\u8bc6\u522b\u65b9\u6cd5\u3002", "motivation": "\u5728\u4e8c\u5143\u5904\u7406\u548c\u4e8c\u5143\u5de5\u5177\u53d8\u91cf\u8bbe\u7f6e\u4e0b\uff0c\u5bf9\u5206\u7c7b\u7ed3\u679c\u8fdb\u884c\u56e0\u679c\u63a8\u65ad\u65f6\uff0c\u9700\u8981\u5904\u7406\u56e0\u672a\u89c2\u6d4b\u5f02\u8d28\u6027\u5bfc\u81f4\u7684\u9009\u62e9\u504f\u8bef\u95ee\u9898\u3002", "method": "\u5c06\u89c2\u6d4b\u7ed3\u679c\u7684\u8054\u5408\u6982\u7387\u5206\u89e3\u4e3a\u6f5c\u5728\u7ed3\u679c\u548c\u5904\u7406\u7684\u8fb9\u9645\u6982\u7387\u4ee5\u53ca\u6355\u83b7\u9009\u62e9\u504f\u8bef\u7684\u5173\u8054\u53c2\u6570\uff0c\u63d0\u51fa\u5173\u8054\u76f8\u4f3c\u6027\u5047\u8bbe\u5b9e\u73b0\u70b9\u8bc6\u522b\uff0c\u5e76\u63d0\u4f9b\u5355\u8c03\u5173\u8054\u548c\u6709\u754c\u5173\u8054\u4e24\u79cd\u5f31\u5316\u5047\u8bbe\u8fdb\u884c\u504f\u8bc6\u522b\u3002", "result": "\u5728\u5173\u8054\u76f8\u4f3c\u6027\u5047\u8bbe\u4e0b\u5b9e\u73b0\u6f5c\u5728\u7ed3\u679c\u5206\u5e03\u7684\u7cbe\u786e\u8bc6\u522b\uff0c\u5728\u5f31\u5316\u5047\u8bbe\u4e0b\u83b7\u5f97\u5c16\u9510\u7684\u504f\u8bc6\u522b\u8fb9\u754c\uff0c\u5e76\u901a\u8fc7\u79c1\u4eba\u533b\u7597\u4fdd\u9669\u5bf9\u5065\u5eb7\u7ed3\u679c\u5f71\u54cd\u7684\u5b9e\u8bc1\u5e94\u7528\u9a8c\u8bc1\u6846\u67b6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5206\u7c7b\u7ed3\u679c\u7684\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u975e\u53c2\u6570\u65b9\u6cd5\uff0c\u65e2\u80fd\u5b9e\u73b0\u7cbe\u786e\u8bc6\u522b\uff0c\u53c8\u80fd\u901a\u8fc7\u5f31\u5316\u5047\u8bbe\u8fdb\u884c\u654f\u611f\u6027\u5206\u6790\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.11008", "categories": ["econ.EM", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.11008", "abs": "https://arxiv.org/abs/2510.11008", "authors": ["Ta-Chung Chi", "Ting-Han Fan", "Raffaele M. Ghigliazza", "Domenico Giannone", "Zixuan", "Wang"], "title": "Macroeconomic Forecasting and Machine Learning", "comment": null, "summary": "We forecast the full conditional distribution of macroeconomic outcomes by\nsystematically integrating three key principles: using high-dimensional data\nwith appropriate regularization, adopting rigorous out-of-sample validation\nprocedures, and incorporating nonlinearities. By exploiting the rich\ninformation embedded in a large set of macroeconomic and financial predictors,\nwe produce accurate predictions of the entire profile of macroeconomic risk in\nreal time. Our findings show that regularization via shrinkage is essential to\ncontrol model complexity, while introducing nonlinearities yields limited\nimprovements in predictive accuracy. Out-of-sample validation plays a critical\nrole in selecting model architecture and preventing overfitting.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u6574\u5408\u9ad8\u7ef4\u6570\u636e\u3001\u4e25\u683c\u6837\u672c\u5916\u9a8c\u8bc1\u548c\u975e\u7ebf\u6027\u5efa\u6a21\u6765\u9884\u6d4b\u5b8f\u89c2\u7ecf\u6d4e\u7ed3\u679c\u7684\u5b8c\u6574\u6761\u4ef6\u5206\u5e03\uff0c\u53d1\u73b0\u6b63\u5219\u5316\u5bf9\u63a7\u5236\u6a21\u578b\u590d\u6742\u6027\u81f3\u5173\u91cd\u8981\uff0c\u800c\u975e\u7ebf\u6027\u6539\u8fdb\u6709\u9650\u3002", "motivation": "\u5229\u7528\u5b8f\u89c2\u7ecf\u6d4e\u548c\u91d1\u878d\u9884\u6d4b\u56e0\u5b50\u4e2d\u7684\u4e30\u5bcc\u4fe1\u606f\uff0c\u5b9e\u65f6\u51c6\u786e\u9884\u6d4b\u5b8f\u89c2\u7ecf\u6d4e\u98ce\u9669\u7684\u5b8c\u6574\u5206\u5e03\u8f6e\u5ed3\u3002", "method": "\u7cfb\u7edf\u6574\u5408\u4e09\u4e2a\u5173\u952e\u539f\u5219\uff1a\u4f7f\u7528\u9ad8\u7ef4\u6570\u636e\u5e76\u9002\u5f53\u6b63\u5219\u5316\u3001\u91c7\u7528\u4e25\u683c\u7684\u6837\u672c\u5916\u9a8c\u8bc1\u7a0b\u5e8f\u3001\u5f15\u5165\u975e\u7ebf\u6027\u5efa\u6a21\u3002", "result": "\u6b63\u5219\u5316\u901a\u8fc7\u6536\u7f29\u65b9\u6cd5\u5bf9\u63a7\u5236\u6a21\u578b\u590d\u6742\u6027\u81f3\u5173\u91cd\u8981\uff0c\u800c\u5f15\u5165\u975e\u7ebf\u6027\u5bf9\u9884\u6d4b\u51c6\u786e\u6027\u7684\u6539\u8fdb\u6709\u9650\u3002\u6837\u672c\u5916\u9a8c\u8bc1\u5728\u9009\u62e9\u6a21\u578b\u67b6\u6784\u548c\u9632\u6b62\u8fc7\u62df\u5408\u65b9\u9762\u53d1\u6325\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "\u9ad8\u7ef4\u6570\u636e\u4e0e\u9002\u5f53\u6b63\u5219\u5316\u7684\u7ed3\u5408\u80fd\u591f\u6709\u6548\u9884\u6d4b\u5b8f\u89c2\u7ecf\u6d4e\u98ce\u9669\u5206\u5e03\uff0c\u6837\u672c\u5916\u9a8c\u8bc1\u662f\u6a21\u578b\u9009\u62e9\u7684\u91cd\u8981\u5de5\u5177\uff0c\u975e\u7ebf\u6027\u6539\u8fdb\u7684\u5b9e\u9645\u4ef7\u503c\u76f8\u5bf9\u6709\u9650\u3002"}}
{"id": "2510.11013", "categories": ["econ.EM", "econ.GN", "math.ST", "q-fin.EC", "stat.AP", "stat.ME", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.11013", "abs": "https://arxiv.org/abs/2510.11013", "authors": ["Tatsuru Kikuchi"], "title": "Spatial and Temporal Boundaries in Difference-in-Differences: A Framework from Navier-Stokes Equation", "comment": "56 pages, 4 figures", "summary": "This paper develops a unified framework for identifying spatial and temporal\nboundaries of treatment effects in difference-in-differences designs. Starting\nfrom fundamental fluid dynamics equations (Navier-Stokes), we derive conditions\nunder which treatment effects decay exponentially in space and time, enabling\nresearchers to calculate explicit boundaries beyond which effects become\nundetectable. The framework encompasses both linear (pure diffusion) and\nnonlinear (advection-diffusion with chemical reactions) regimes, with testable\nscope conditions based on dimensionless numbers from physics (P\\'eclet and\nReynolds numbers). We demonstrate the framework's diagnostic capability using\nair pollution from coal-fired power plants. Analyzing 791 ground-based\nPM$_{2.5}$ monitors and 189,564 satellite-based NO$_2$ grid cells in the\nWestern United States over 2019-2021, we find striking regional heterogeneity:\nwithin 100 km of coal plants, both pollutants show positive spatial decay\n(PM$_{2.5}$: $\\kappa_s = 0.00200$, $d^* = 1,153$ km; NO$_2$: $\\kappa_s =\n0.00112$, $d^* = 2,062$ km), validating the framework. Beyond 100 km, negative\ndecay parameters correctly signal that urban sources dominate and diffusion\nassumptions fail. Ground-level PM$_{2.5}$ decays approximately twice as fast as\nsatellite column NO$_2$, consistent with atmospheric transport physics. The\nframework successfully diagnoses its own validity in four of eight analyzed\nregions, providing researchers with physics-based tools to assess whether their\nspatial difference-in-differences setting satisfies diffusion assumptions\nbefore applying the estimator. Our results demonstrate that rigorous boundary\ndetection requires both theoretical derivation from first principles and\nempirical validation of underlying physical assumptions.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u6765\u8bc6\u522b\u53cc\u91cd\u5dee\u5206\u8bbe\u8ba1\u4e2d\u5904\u7406\u6548\u5e94\u7684\u7a7a\u95f4\u548c\u65f6\u95f4\u8fb9\u754c\uff0c\u57fa\u4e8e\u6d41\u4f53\u52a8\u529b\u5b66\u65b9\u7a0b\u63a8\u5bfc\u51fa\u5904\u7406\u6548\u5e94\u5728\u7a7a\u95f4\u548c\u65f6\u95f4\u4e0a\u5448\u6307\u6570\u8870\u51cf\u7684\u6761\u4ef6\uff0c\u5e76\u5e94\u7528\u4e8e\u71c3\u7164\u7535\u5382\u7a7a\u6c14\u6c61\u67d3\u6848\u4f8b\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709\u53cc\u91cd\u5dee\u5206\u8bbe\u8ba1\u7f3a\u4e4f\u8bc6\u522b\u5904\u7406\u6548\u5e94\u8fb9\u754c\u7684\u7cfb\u7edf\u65b9\u6cd5\uff0c\u9700\u8981\u4ece\u7b2c\u4e00\u6027\u539f\u7406\u51fa\u53d1\u5efa\u7acb\u7406\u8bba\u6846\u67b6\u6765\u51c6\u786e\u786e\u5b9a\u6548\u5e94\u8870\u51cf\u8303\u56f4\u3002", "method": "\u4ece\u7eb3\u7ef4-\u65af\u6258\u514b\u65af\u65b9\u7a0b\u51fa\u53d1\u63a8\u5bfc\u5904\u7406\u6548\u5e94\u8870\u51cf\u6761\u4ef6\uff0c\u6db5\u76d6\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u673a\u5236\uff0c\u57fa\u4e8e\u7269\u7406\u65e0\u91cf\u7eb2\u6570\u5efa\u7acb\u53ef\u68c0\u9a8c\u7684\u8303\u56f4\u6761\u4ef6\uff0c\u5e76\u4f7f\u7528791\u4e2aPM2.5\u76d1\u6d4b\u70b9\u548c189,564\u4e2aNO2\u536b\u661f\u7f51\u683c\u6570\u636e\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "result": "\u5728\u71c3\u7164\u7535\u5382100\u516c\u91cc\u8303\u56f4\u5185\uff0c\u4e24\u79cd\u6c61\u67d3\u7269\u5747\u663e\u793a\u6b63\u7a7a\u95f4\u8870\u51cf(PM2.5\u8870\u51cf\u8ddd\u79bb1153\u516c\u91cc\uff0cNO2\u8870\u51cf\u8ddd\u79bb2062\u516c\u91cc)\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u6709\u6548\u6027\uff1b\u8d85\u8fc7100\u516c\u91cc\u540e\u8d1f\u8870\u51cf\u53c2\u6570\u6b63\u786e\u8868\u660e\u57ce\u5e02\u6e90\u4e3b\u5bfc\u4e14\u6269\u6563\u5047\u8bbe\u5931\u6548\u3002", "conclusion": "\u4e25\u683c\u7684\u8fb9\u754c\u68c0\u6d4b\u9700\u8981\u4ece\u7b2c\u4e00\u6027\u539f\u7406\u8fdb\u884c\u7406\u8bba\u63a8\u5bfc\u548c\u5bf9\u57fa\u7840\u7269\u7406\u5047\u8bbe\u7684\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u8be5\u6846\u67b6\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u57fa\u4e8e\u7269\u7406\u7684\u5de5\u5177\u6765\u8bc4\u4f30\u7a7a\u95f4\u53cc\u91cd\u5dee\u5206\u8bbe\u7f6e\u662f\u5426\u6ee1\u8db3\u6269\u6563\u5047\u8bbe\u3002"}}
{"id": "2510.09610", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.09610", "abs": "https://arxiv.org/abs/2510.09610", "authors": ["Samet Uzun", "Behcet Acikmese", "John M. Carson III"], "title": "Sequential Convex Programming for 6-DoF Powered Descent Guidance with Continuous-Time Compound State-Triggered Constraints", "comment": null, "summary": "This paper presents a sequential convex programming (SCP) framework for\nensuring the continuous-time satisfaction of compound state-triggered\nconstraints, a subset of logical specifications, in the powered descent\nguidance (PDG) problem. The proposed framework combines the generalized\nmean-based smooth robustness measure (D-GMSR), a parameterization technique\ntailored for expressing discrete-time temporal and logical specifications\nthrough smooth functions, with the continuous-time successive convexification\n(CT-SCvx) method, a real-time solution for constrained trajectory optimization\nthat guarantees continuous-time constraint satisfaction and convergence. The\nsmoothness of the temporal and logical specifications parameterized via D-GMSR\nenables solving the resulting optimization problem with robust and efficient\nSCP algorithms while preserving theoretical guarantees. In addition to their\nsmoothness, the parameterized specifications are sound and complete, meaning\nthe specification holds if and only if the constraint defined by the\nparameterized function is satisfied. The CT-SCvx framework is then applied to\nsolve the parameterized problem, incorporating: (1) reformulation for\ncontinuous-time path constraint satisfaction, (2) time-dilation to transform\nthe free-final-time PDG problem into a fixed-final-time problem, (3) multiple\nshooting for exact discretization, (4) exact penalty functions for penalizing\nnonconvex constraints, and (5) the prox-linear method, a convergence-guaranteed\nSCP algorithm, to solve the resulting finite-dimensional nonconvex PDG problem.\nThe effectiveness of the framework is demonstrated through a numerical\nsimulation. The implementation is available at\nhttps://github.com/UW-ACL/CT-cSTC", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5e8f\u5217\u51f8\u89c4\u5212\u6846\u67b6\uff0c\u7528\u4e8e\u786e\u4fdd\u52a8\u529b\u4e0b\u964d\u5236\u5bfc\u95ee\u9898\u4e2d\u590d\u5408\u72b6\u6001\u89e6\u53d1\u7ea6\u675f\u7684\u8fde\u7eed\u65f6\u95f4\u6ee1\u8db3\uff0c\u7ed3\u5408\u4e86\u5e7f\u4e49\u5747\u503c\u5e73\u6ed1\u9c81\u68d2\u6027\u5ea6\u91cf\u548c\u8fde\u7eed\u65f6\u95f4\u8fde\u7eed\u51f8\u5316\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u52a8\u529b\u4e0b\u964d\u5236\u5bfc\u95ee\u9898\u4e2d\u79bb\u6563\u65f6\u95f4\u65f6\u5e8f\u548c\u903b\u8f91\u89c4\u8303\u5728\u8fde\u7eed\u65f6\u95f4\u7ea6\u675f\u6ee1\u8db3\u65b9\u9762\u7684\u6311\u6218\uff0c\u786e\u4fdd\u7406\u8bba\u4fdd\u8bc1\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u4f18\u5316\u6c42\u89e3\u3002", "method": "\u4f7f\u7528D-GMSR\u53c2\u6570\u5316\u6280\u672f\u8868\u8fbe\u79bb\u6563\u65f6\u95f4\u65f6\u5e8f\u548c\u903b\u8f91\u89c4\u8303\uff0c\u7ed3\u5408CT-SCvx\u65b9\u6cd5\u8fdb\u884c\u8fde\u7eed\u65f6\u95f4\u7ea6\u675f\u6ee1\u8db3\uff0c\u5305\u62ec\u65f6\u95f4\u6269\u5f20\u3001\u591a\u91cd\u5c04\u51fb\u3001\u7cbe\u786e\u7f5a\u51fd\u6570\u548c\u8fd1\u4f3c\u7ebf\u6027\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u6570\u503c\u4eff\u771f\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u4fdd\u8bc1\u8fde\u7eed\u65f6\u95f4\u7ea6\u675f\u6ee1\u8db3\u548c\u6536\u655b\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5730\u5c06\u65f6\u5e8f\u548c\u903b\u8f91\u89c4\u8303\u96c6\u6210\u5230\u8fde\u7eed\u65f6\u95f4\u8f68\u8ff9\u4f18\u5316\u4e2d\uff0c\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u8ba1\u7b97\u6548\u7387\u7684\u5e73\u8861\u3002"}}
{"id": "2510.09634", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09634", "abs": "https://arxiv.org/abs/2510.09634", "authors": ["Anastasija Nikiforova", "Martin Lnenicka", "Ulf Melin", "David Valle-Cruz", "Asif Gill", "Cesar Casiano Flores", "Emyana Sirait", "Mariusz Luterek", "Richard Michael Dreyling", "Barbora Tesarova"], "title": "Responsible AI Adoption in the Public Sector: A Data-Centric Taxonomy of AI Adoption Challenges", "comment": null, "summary": "Despite Artificial Intelligence (AI) transformative potential for public\nsector services, decision-making, and administrative efficiency, adoption\nremains uneven due to complex technical, organizational, and institutional\nchallenges. Responsible AI frameworks emphasize fairness, accountability, and\ntransparency, aligning with principles of trustworthy AI and fair AI, yet\nremain largely aspirational, overlooking technical and institutional realities,\nespecially foundational data and governance. This study addresses this gap by\ndeveloping a taxonomy of data-related challenges to responsible AI adoption in\ngovernment. Based on a systematic review of 43 studies and 21 expert\nevaluations, the taxonomy identifies 13 key challenges across technological,\norganizational, and environmental dimensions, including poor data quality,\nlimited AI-ready infrastructure, weak governance, misalignment in human-AI\ndecision-making, economic and environmental sustainability concerns. Annotated\nwith institutional pressures, the taxonomy serves as a diagnostic tool to\nsurface 'symptoms' of high-risk AI deployment and guides policymakers in\nbuilding the institutional and data governance conditions necessary for\nresponsible AI adoption.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u5173\u4e8e\u653f\u5e9c\u8d1f\u8d23\u4efbAI\u91c7\u7528\u4e2d\u6570\u636e\u76f8\u5173\u6311\u6218\u7684\u5206\u7c7b\u6cd5\uff0c\u6db5\u76d6\u6280\u672f\u3001\u7ec4\u7ec7\u548c\u73af\u5883\u4e09\u4e2a\u7ef4\u5ea6\u768413\u4e2a\u5173\u952e\u6311\u6218\uff0c\u53ef\u4f5c\u4e3a\u8bca\u65ad\u9ad8\u98ce\u9669AI\u90e8\u7f72\u7684\u5de5\u5177\u3002", "motivation": "\u5c3d\u7ba1AI\u5728\u516c\u5171\u90e8\u95e8\u5177\u6709\u53d8\u9769\u6f5c\u529b\uff0c\u4f46\u7531\u4e8e\u590d\u6742\u7684\u6280\u672f\u3001\u7ec4\u7ec7\u548c\u5236\u5ea6\u6311\u6218\uff0c\u91c7\u7528\u4ecd\u7136\u4e0d\u5747\u8861\u3002\u73b0\u6709\u7684\u8d1f\u8d23\u4efbAI\u6846\u67b6\u5927\u591a\u505c\u7559\u5728\u7406\u60f3\u5c42\u9762\uff0c\u5ffd\u89c6\u4e86\u6280\u672f\u548c\u5236\u5ea6\u73b0\u5b9e\uff0c\u7279\u522b\u662f\u57fa\u7840\u6570\u636e\u548c\u6cbb\u7406\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u5bf943\u9879\u7814\u7a76\u7684\u7cfb\u7edf\u56de\u987e\u548c21\u4f4d\u4e13\u5bb6\u8bc4\u4f30\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u6570\u636e\u76f8\u5173\u6311\u6218\u7684\u5206\u7c7b\u6cd5\u3002", "result": "\u8bc6\u522b\u51fa13\u4e2a\u5173\u952e\u6311\u6218\uff0c\u5305\u62ec\u6570\u636e\u8d28\u91cf\u5dee\u3001AI\u5c31\u7eea\u57fa\u7840\u8bbe\u65bd\u6709\u9650\u3001\u6cbb\u7406\u8584\u5f31\u3001\u4eba\u673a\u51b3\u7b56\u9519\u4f4d\u3001\u7ecf\u6d4e\u548c\u73af\u5883\u53ef\u6301\u7eed\u6027\u95ee\u9898\u7b49\uff0c\u5e76\u6309\u5236\u5ea6\u538b\u529b\u8fdb\u884c\u6ce8\u91ca\u3002", "conclusion": "\u8be5\u5206\u7c7b\u6cd5\u53ef\u4f5c\u4e3a\u8bca\u65ad\u9ad8\u98ce\u9669AI\u90e8\u7f72\u75c7\u72b6\u7684\u5de5\u5177\uff0c\u5e76\u6307\u5bfc\u653f\u7b56\u5236\u5b9a\u8005\u5efa\u7acb\u8d1f\u8d23\u4efbAI\u91c7\u7528\u6240\u9700\u7684\u5236\u5ea6\u548c\u6570\u636e\u6cbb\u7406\u6761\u4ef6\u3002"}}
{"id": "2510.09786", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.09786", "abs": "https://arxiv.org/abs/2510.09786", "authors": ["Yuang Lu", "Song Wang", "Xiao Han", "Xuri Zhang", "Yucong Wu", "Zhicheng He"], "title": "Enhancing Diffusion Policy with Classifier-Free Guidance for Temporal Robotic Tasks", "comment": "7 pages, 7 figures", "summary": "Temporal sequential tasks challenge humanoid robots, as existing Diffusion\nPolicy (DP) and Action Chunking with Transformers (ACT) methods often lack\ntemporal context, resulting in local optima traps and excessive repetitive\nactions. To address these issues, this paper introduces a Classifier-Free\nGuidance-Based Diffusion Policy (CFG-DP), a novel framework to enhance DP by\nintegrating Classifier-Free Guidance (CFG) with conditional and unconditional\nmodels. Specifically, CFG leverages timestep inputs to track task progression\nand ensure precise cycle termination. It dynamically adjusts action predictions\nbased on task phase, using a guidance factor tuned to balance temporal\ncoherence and action accuracy. Real-world experiments on a humanoid robot\ndemonstrate high success rates and minimal repetitive actions. Furthermore, we\nassessed the model's ability to terminate actions and examined how different\ncomponents and parameter adjustments affect its performance. This framework\nsignificantly enhances deterministic control and execution reliability for\nsequential robotic tasks.", "AI": {"tldr": "\u63d0\u51faCFG-DP\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u65e0\u5206\u7c7b\u5668\u5f15\u5bfc\u4e0e\u6761\u4ef6/\u65e0\u6761\u4ef6\u6a21\u578b\u6765\u589e\u5f3a\u6269\u6563\u7b56\u7565\uff0c\u89e3\u51b3\u65f6\u5e8f\u4efb\u52a1\u4e2d\u7684\u5c40\u90e8\u6700\u4f18\u548c\u91cd\u590d\u52a8\u4f5c\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u7b56\u7565\u548c\u52a8\u4f5c\u5206\u5757\u53d8\u6362\u5668\u65b9\u6cd5\u7f3a\u4e4f\u65f6\u5e8f\u4e0a\u4e0b\u6587\uff0c\u5bfc\u81f4\u5c40\u90e8\u6700\u4f18\u9677\u9631\u548c\u8fc7\u591a\u91cd\u590d\u52a8\u4f5c\uff0c\u96be\u4ee5\u5904\u7406\u65f6\u5e8f\u987a\u5e8f\u4efb\u52a1\u3002", "method": "\u5f15\u5165\u65e0\u5206\u7c7b\u5668\u5f15\u5bfc\u57fa\u4e8e\u6269\u6563\u7b56\u7565\uff0c\u5229\u7528\u65f6\u95f4\u6b65\u8f93\u5165\u8ddf\u8e2a\u4efb\u52a1\u8fdb\u5ea6\uff0c\u786e\u4fdd\u7cbe\u786e\u5468\u671f\u7ec8\u6b62\uff0c\u6839\u636e\u4efb\u52a1\u9636\u6bb5\u52a8\u6001\u8c03\u6574\u52a8\u4f5c\u9884\u6d4b\u3002", "result": "\u5728\u4eba\u5f62\u673a\u5668\u4eba\u4e0a\u7684\u771f\u5b9e\u5b9e\u9a8c\u663e\u793a\u9ad8\u6210\u529f\u7387\u548c\u6700\u5c0f\u5316\u91cd\u590d\u52a8\u4f5c\uff0c\u6a21\u578b\u80fd\u591f\u6709\u6548\u7ec8\u6b62\u52a8\u4f5c\uff0c\u4e0d\u540c\u7ec4\u4ef6\u548c\u53c2\u6570\u8c03\u6574\u5f71\u54cd\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u663e\u8457\u589e\u5f3a\u4e86\u65f6\u5e8f\u673a\u5668\u4eba\u4efb\u52a1\u7684\u786e\u5b9a\u6027\u63a7\u5236\u548c\u6267\u884c\u53ef\u9760\u6027\u3002"}}
{"id": "2510.10165", "categories": ["econ.GN", "cs.CY", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.10165", "abs": "https://arxiv.org/abs/2510.10165", "authors": ["Feiyang", "Xu", "Poonacha K. Medappa", "Murat M. Tunc", "Martijn Vroegindeweij", "Jan C. Fransoo"], "title": "AI-assisted Programming May Decrease the Productivity of Experienced Developers by Increasing Maintenance Burden", "comment": "Presented at WITS 2025, CIST 2025, SCECR 2025, INFORMS 2024. Under\n  Review (1st Round) at Nature Human Behavior", "summary": "Generative AI solutions like GitHub Copilot have been shown to increase the\nproductivity of software developers. Yet prior work remains unclear on the\nquality of code produced and the challenges of maintaining it in software\nprojects. If quality declines as volume grows, experienced developers face\nincreased workloads reviewing and reworking code from less-experienced\ncontributors. We analyze developer activity in Open Source Software (OSS)\nprojects following the introduction of GitHub Copilot. We find that\nproductivity indeed increases. However, the increase in productivity is\nprimarily driven by less-experienced (peripheral) developers. We also find that\ncode written after the adoption of AI requires more rework. Importantly, the\nadded rework burden falls on the more experienced (core) developers, who review\n6.5% more code after Copilot's introduction, but show a 19% drop in their\noriginal code productivity. More broadly, this finding raises caution that\nproductivity gains of AI may mask the growing burden of maintenance on a\nshrinking pool of experts.", "AI": {"tldr": "GitHub Copilot\u63d0\u9ad8\u4e86\u5f00\u53d1\u8005\u7684\u751f\u4ea7\u529b\uff0c\u4f46\u4e3b\u8981\u53d7\u76ca\u8005\u662f\u7ecf\u9a8c\u8f83\u5c11\u7684\u5f00\u53d1\u8005\uff0c\u800c\u4ee3\u7801\u8d28\u91cf\u4e0b\u964d\u5bfc\u81f4\u66f4\u591a\u8fd4\u5de5\uff0c\u8fd9\u4e9b\u989d\u5916\u8d1f\u62c5\u843d\u5728\u4e86\u7ecf\u9a8c\u4e30\u5bcc\u7684\u6838\u5fc3\u5f00\u53d1\u8005\u8eab\u4e0a\u3002", "motivation": "\u7814\u7a76GitHub Copilot\u5bf9\u5f00\u6e90\u8f6f\u4ef6\u9879\u76ee\u4e2d\u4ee3\u7801\u8d28\u91cf\u548c\u7ef4\u62a4\u6311\u6218\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5173\u6ce8AI\u5de5\u5177\u662f\u5426\u5728\u63d0\u9ad8\u751f\u4ea7\u529b\u7684\u540c\u65f6\u589e\u52a0\u4e86\u7ef4\u62a4\u8d1f\u62c5\u3002", "method": "\u5206\u6790GitHub Copilot\u5f15\u5165\u540e\u5f00\u6e90\u8f6f\u4ef6\u9879\u76ee\u4e2d\u5f00\u53d1\u8005\u7684\u6d3b\u52a8\u6570\u636e\uff0c\u6bd4\u8f83\u4e0d\u540c\u7ecf\u9a8c\u6c34\u5e73\u5f00\u53d1\u8005\u7684\u751f\u4ea7\u529b\u53d8\u5316\u548c\u4ee3\u7801\u8fd4\u5de5\u60c5\u51b5\u3002", "result": "\u751f\u4ea7\u529b\u786e\u5b9e\u63d0\u9ad8\uff0c\u4f46\u4e3b\u8981\u7531\u7ecf\u9a8c\u8f83\u5c11\u7684\u5f00\u53d1\u8005\u9a71\u52a8\uff1b\u4f7f\u7528AI\u540e\u7f16\u5199\u7684\u4ee3\u7801\u9700\u8981\u66f4\u591a\u8fd4\u5de5\uff1b\u6838\u5fc3\u5f00\u53d1\u8005\u5ba1\u67e5\u4ee3\u7801\u91cf\u589e\u52a06.5%\uff0c\u4f46\u539f\u59cb\u4ee3\u7801\u751f\u4ea7\u529b\u4e0b\u964d19%\u3002", "conclusion": "AI\u5e26\u6765\u7684\u751f\u4ea7\u529b\u63d0\u5347\u53ef\u80fd\u63a9\u76d6\u4e86\u7ef4\u62a4\u8d1f\u62c5\u5411\u5c11\u6570\u4e13\u5bb6\u96c6\u4e2d\u7684\u98ce\u9669\uff0c\u9700\u8981\u8c28\u614e\u770b\u5f85AI\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u957f\u671f\u5f71\u54cd\u3002"}}
{"id": "2510.09821", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2510.09821", "abs": "https://arxiv.org/abs/2510.09821", "authors": ["Jiaxing Weng", "Haijun Yang", "Tongyu Wang"], "title": "Emergence of Homophily under Contextual Mechanisms", "comment": null, "summary": "This paper introduces a tractable model to study incentive-compatible\nhomophily under both external environments--such as exogenous shocks or policy\nconstraints--and internal micromotives based on interactive attributes. We\npropose a set of invariants that capture main features of homophily and the\nwell-defined partition dynamics leading to perfect global homophily. The\ncriteria for homophily formation are characterized via isomorphism. Within this\nframework, we demonstrate the emergence of macro-complementarity coupled with\nmicro-substitution, where local individuals' utility function is nonlinear and\nsubmodular. We discuss two types of financial networks and their differences:\nhierarchical structure emerges from short-term liquidity transactions, whereas\ncore-periphery structure is based on a stock-based perspective.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u5904\u7406\u7684\u6a21\u578b\u6765\u7814\u7a76\u6fc0\u52b1\u76f8\u5bb9\u7684\u540c\u8d28\u6027\uff0c\u6db5\u76d6\u5916\u90e8\u73af\u5883\u548c\u5185\u90e8\u5fae\u89c2\u52a8\u673a\uff0c\u901a\u8fc7\u540c\u6784\u7279\u5f81\u5316\u540c\u8d28\u6027\u5f62\u6210\u6807\u51c6\uff0c\u5c55\u793a\u5b8f\u89c2\u4e92\u8865\u6027\u4e0e\u5fae\u89c2\u66ff\u4ee3\u6027\u7684\u51fa\u73b0\uff0c\u5e76\u5206\u6790\u4e24\u79cd\u91d1\u878d\u7f51\u7edc\u7ed3\u6784\u7684\u5dee\u5f02\u3002", "motivation": "\u7814\u7a76\u5728\u5916\u90e8\u73af\u5883\uff08\u5982\u5916\u751f\u51b2\u51fb\u6216\u653f\u7b56\u7ea6\u675f\uff09\u548c\u57fa\u4e8e\u4ea4\u4e92\u5c5e\u6027\u7684\u5185\u90e8\u5fae\u89c2\u52a8\u673a\u4e0b\u7684\u6fc0\u52b1\u76f8\u5bb9\u540c\u8d28\u6027\uff0c\u7406\u89e3\u540c\u8d28\u6027\u5f62\u6210\u673a\u5236\u53ca\u5176\u5728\u91d1\u878d\u7f51\u7edc\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u4e00\u7ec4\u6355\u6349\u540c\u8d28\u6027\u4e3b\u8981\u7279\u5f81\u7684\u4e0d\u53d8\u91cf\uff0c\u5efa\u7acb\u826f\u597d\u5b9a\u4e49\u7684\u5212\u5206\u52a8\u6001\u5b66\uff0c\u901a\u8fc7\u540c\u6784\u7279\u5f81\u5316\u540c\u8d28\u6027\u5f62\u6210\u6807\u51c6\uff0c\u5206\u6790\u975e\u7ebf\u6027\u6b21\u6a21\u6548\u7528\u51fd\u6570\u4e0b\u7684\u5b8f\u89c2\u4e92\u8865\u6027\u4e0e\u5fae\u89c2\u66ff\u4ee3\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u5b8f\u89c2\u4e92\u8865\u6027\u4e0e\u5fae\u89c2\u66ff\u4ee3\u6027\u7684\u51fa\u73b0\uff0c\u5176\u4e2d\u5c40\u90e8\u4e2a\u4f53\u7684\u6548\u7528\u51fd\u6570\u662f\u975e\u7ebf\u6027\u548c\u6b21\u6a21\u7684\uff1b\u533a\u5206\u4e86\u4e24\u79cd\u91d1\u878d\u7f51\u7edc\u7ed3\u6784\uff1a\u57fa\u4e8e\u77ed\u671f\u6d41\u52a8\u6027\u4ea4\u6613\u7684\u5c42\u6b21\u7ed3\u6784\u548c\u57fa\u4e8e\u5b58\u91cf\u89c6\u89d2\u7684\u6838\u5fc3-\u8fb9\u7f18\u7ed3\u6784\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7814\u7a76\u6fc0\u52b1\u76f8\u5bb9\u540c\u8d28\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u91d1\u878d\u7f51\u7edc\u7ed3\u6784\u5f62\u6210\u7684\u673a\u5236\u5dee\u5f02\uff0c\u5bf9\u7406\u89e3\u793e\u4f1a\u7f51\u7edc\u548c\u91d1\u878d\u7cfb\u7edf\u7684\u52a8\u6001\u6f14\u5316\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2510.09782", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.09782", "abs": "https://arxiv.org/abs/2510.09782", "authors": ["Yufa Zhou", "Yixiao Wang", "Xunjian Yin", "Shuyan Zhou", "Anru R. Zhang"], "title": "The Geometry of Reasoning: Flowing Logics in Representation Space", "comment": "Code: https://github.com/MasterZhou1/Reasoning-Flow", "summary": "We study how large language models (LLMs) ``think'' through their\nrepresentation space. We propose a novel geometric framework that models an\nLLM's reasoning as flows -- embedding trajectories evolving where logic goes.\nWe disentangle logical structure from semantics by employing the same natural\ndeduction propositions with varied semantic carriers, allowing us to test\nwhether LLMs internalize logic beyond surface form. This perspective connects\nreasoning with geometric quantities such as position, velocity, and curvature,\nenabling formal analysis in representation and concept spaces. Our theory\nestablishes: (1) LLM reasoning corresponds to smooth flows in representation\nspace, and (2) logical statements act as local controllers of these flows'\nvelocities. Using learned representation proxies, we design controlled\nexperiments to visualize and quantify reasoning flows, providing empirical\nvalidation of our theoretical framework. Our work serves as both a conceptual\nfoundation and practical tools for studying reasoning phenomenon, offering a\nnew lens for interpretability and formal analysis of LLMs' behavior.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u51e0\u4f55\u6846\u67b6\u6765\u7814\u7a76LLM\u5728\u8868\u793a\u7a7a\u95f4\u4e2d\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u5c06\u63a8\u7406\u5efa\u6a21\u4e3a\u5d4c\u5165\u8f68\u8ff9\u7684\u6d41\u52a8\uff0c\u5e76\u5206\u79bb\u903b\u8f91\u7ed3\u6784\u4e0e\u8bed\u4e49\u5185\u5bb9\u3002", "motivation": "\u7814\u7a76LLM\u5982\u4f55\u5728\u8868\u793a\u7a7a\u95f4\u4e2d\"\u601d\u8003\"\uff0c\u7406\u89e3\u5176\u63a8\u7406\u8fc7\u7a0b\u7684\u51e0\u4f55\u7279\u6027\uff0c\u4e3aLLM\u7684\u53ef\u89e3\u91ca\u6027\u548c\u5f62\u5f0f\u5206\u6790\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002", "method": "\u4f7f\u7528\u51e0\u4f55\u6846\u67b6\u5efa\u6a21LLM\u63a8\u7406\u4e3a\u8868\u793a\u7a7a\u95f4\u4e2d\u7684\u6d41\u52a8\uff0c\u901a\u8fc7\u76f8\u540c\u81ea\u7136\u6f14\u7ece\u547d\u9898\u7684\u4e0d\u540c\u8bed\u4e49\u8f7d\u4f53\u6765\u5206\u79bb\u903b\u8f91\u4e0e\u8bed\u4e49\uff0c\u5229\u7528\u5b66\u4e60\u5230\u7684\u8868\u793a\u4ee3\u7406\u8bbe\u8ba1\u53d7\u63a7\u5b9e\u9a8c\u3002", "result": "\u7406\u8bba\u8bc1\u660e\uff1a(1)LLM\u63a8\u7406\u5bf9\u5e94\u8868\u793a\u7a7a\u95f4\u4e2d\u7684\u5e73\u6ed1\u6d41\u52a8\uff1b(2)\u903b\u8f91\u8bed\u53e5\u4f5c\u4e3a\u8fd9\u4e9b\u6d41\u52a8\u901f\u5ea6\u7684\u5c40\u90e8\u63a7\u5236\u5668\u3002\u901a\u8fc7\u5b9e\u9a8c\u53ef\u89c6\u5316\u548c\u91cf\u5316\u4e86\u63a8\u7406\u6d41\u52a8\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u7814\u7a76\u63a8\u7406\u73b0\u8c61\u63d0\u4f9b\u4e86\u6982\u5ff5\u57fa\u7840\u548c\u5b9e\u8df5\u5de5\u5177\uff0c\u4e3aLLM\u884c\u4e3a\u7684\u53ef\u89e3\u91ca\u6027\u548c\u5f62\u5f0f\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2510.10322", "categories": ["stat.AP", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2510.10322", "abs": "https://arxiv.org/abs/2510.10322", "authors": ["Fatoumata Sanogo"], "title": "A Spatio-temporal CP decomposition analysis of New England region in the US", "comment": "13 pages, 3 figures", "summary": "Spatio temporal data consist of measurement for one or more raster fields\nsuch as weather, traffic volume, crime rate, or disease incidents. Advances in\nmodern technology have increased the number of available information for this\ntype of data hence the rise of multidimensional data. In this paper we take\nadvantage of the multidimensional structure of the data but also its temporal\nand spatial structure. In fact, we will be using the NCAR Climate Data Gateway\nwebsite which provides data discovery and access services for global and\nregional climate model data. The daily values of total precipitation (prec),\nmaximum (tmax), and minimum (tmin) temperature are combined to create a\nmultidimensional data called tensor (a multidimensional array). In this paper,\nwe propose a spatio temporal principal component analysis to initialize CP\ndecomposition component. We take full advantage of the spatial and temporal\nstructure of the data in the initialization step for cp component analysis. The\nperformance of our method is tested via comparison with most popular\ninitialization method. We also run a clustering analysis to further show the\nperformance of our analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u65f6\u7a7a\u7ed3\u6784\u521d\u59cb\u5316CP\u5206\u89e3\u7684\u65f6\u7a7a\u4e3b\u6210\u5206\u5206\u6790\u65b9\u6cd5\uff0c\u7528\u4e8e\u591a\u7ef4\u6c14\u5019\u6570\u636e\u5206\u6790", "motivation": "\u73b0\u4ee3\u6280\u672f\u53d1\u5c55\u4ea7\u751f\u4e86\u5927\u91cf\u591a\u7ef4\u65f6\u7a7a\u6570\u636e\uff0c\u9700\u8981\u6709\u6548\u5229\u7528\u6570\u636e\u7684\u65f6\u7a7a\u548c\u591a\u7ef4\u7ed3\u6784\u8fdb\u884c\u5206\u6790", "method": "\u4f7f\u7528NCAR\u6c14\u5019\u6570\u636e\u7f51\u5173\u7684\u964d\u6c34\u3001\u6700\u9ad8/\u6700\u4f4e\u6e29\u5ea6\u6570\u636e\u6784\u5efa\u5f20\u91cf\uff0c\u63d0\u51fa\u65f6\u7a7a\u4e3b\u6210\u5206\u5206\u6790\u6765\u521d\u59cb\u5316CP\u5206\u89e3\u7ec4\u4ef6", "result": "\u901a\u8fc7\u4e0e\u6d41\u884c\u521d\u59cb\u5316\u65b9\u6cd5\u6bd4\u8f83\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u805a\u7c7b\u5206\u6790\u8fdb\u4e00\u6b65\u5c55\u793a\u4e86\u5206\u6790\u6548\u679c", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u5145\u5206\u5229\u7528\u6570\u636e\u7684\u65f6\u7a7a\u7ed3\u6784\uff0c\u5728CP\u5206\u89e3\u521d\u59cb\u5316\u6b65\u9aa4\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u6027\u80fd"}}
{"id": "2510.10307", "categories": ["cs.SI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.10307", "abs": "https://arxiv.org/abs/2510.10307", "authors": ["Yuan Liao", "Rafael H. M. Pereira", "Jorge Gil", "Silvia De Sojo Caso", "Laura Alessandretti"], "title": "On the Relationship between Space-Time Accessibility and Leisure Activity Participation", "comment": null, "summary": "Understanding how accessibility shapes participation in leisure activities is\ncentral to promoting inclusive and vibrant urban life. Conventional\naccessibility measures often focus on potential access from fixed home\nlocations, overlooking the constraints and opportunities embedded in daily\nroutines. In this study, we introduce a space-time accessibility (SPA) metric\nrooted in the capability approach, capturing feasible leisure opportunities\nbetween home and work given a certain time budget, individual transport modes,\nand urban infrastructure. Using high-resolution GPS data from 2,415 residents\nin the Paris region, we assess how SPA influences total travel time and leisure\nparticipation, measured as the diversity of leisure activity locations. Spatial\npatterns show that most individuals-especially active transport users-choose\ndestinations aligned with their SPA-defined opportunity sets, underscoring the\nmetric's validity in capturing capability sets. Structural equation modeling\nreveals that SPA directly fosters leisure diversity but also reduces travel\ntime, which in turn is associated with lower diversity. These findings\nhighlight the value of person-centered, capability-informed accessibility\nmetrics for understanding inequalities in urban mobility and informing\ntransport planning strategies that expand real freedoms to participate in\nsocial life across diverse population groups.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f15\u5165\u57fa\u4e8e\u80fd\u529b\u65b9\u6cd5\u7684\u65f6\u7a7a\u53ef\u8fbe\u6027(SPA)\u6307\u6807\uff0c\u8003\u8651\u65f6\u95f4\u9884\u7b97\u3001\u4ea4\u901a\u65b9\u5f0f\u548c\u57ce\u5e02\u57fa\u7840\u8bbe\u65bd\uff0c\u5206\u6790\u5df4\u9ece\u5730\u533a\u5c45\u6c11\u4f11\u95f2\u6d3b\u52a8\u7684\u53ef\u8fbe\u6027\u5bf9\u53c2\u4e0e\u5ea6\u7684\u5f71\u54cd\u3002", "motivation": "\u4f20\u7edf\u53ef\u8fbe\u6027\u6307\u6807\u4e3b\u8981\u5173\u6ce8\u56fa\u5b9a\u5c45\u4f4f\u5730\u7684\u6f5c\u5728\u53ef\u8fbe\u6027\uff0c\u5ffd\u89c6\u4e86\u65e5\u5e38\u884c\u7a0b\u4e2d\u7684\u7ea6\u675f\u548c\u673a\u4f1a\uff0c\u9700\u8981\u66f4\u5168\u9762\u7406\u89e3\u53ef\u8fbe\u6027\u5982\u4f55\u5f71\u54cd\u4f11\u95f2\u6d3b\u52a8\u53c2\u4e0e\u3002", "method": "\u4f7f\u7528\u5df4\u9ece\u5730\u533a2,415\u540d\u5c45\u6c11\u7684\u9ad8\u5206\u8fa8\u7387GPS\u6570\u636e\uff0c\u7ed3\u5408\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\u5206\u6790SPA\u5bf9\u603b\u51fa\u884c\u65f6\u95f4\u548c\u4f11\u95f2\u6d3b\u52a8\u5730\u70b9\u591a\u6837\u6027\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0SPA\u76f4\u63a5\u4fc3\u8fdb\u4f11\u95f2\u591a\u6837\u6027\uff0c\u4f46\u540c\u65f6\u51cf\u5c11\u51fa\u884c\u65f6\u95f4\uff0c\u800c\u51cf\u5c11\u7684\u51fa\u884c\u65f6\u95f4\u53c8\u4e0e\u8f83\u4f4e\u7684\u591a\u6837\u6027\u76f8\u5173\uff1b\u5927\u591a\u6570\u4e2a\u4f53\u7279\u522b\u662f\u4e3b\u52a8\u4ea4\u901a\u4f7f\u7528\u8005\u4f1a\u9009\u62e9\u4e0e\u5176SPA\u5b9a\u4e49\u7684\u673a\u4f1a\u96c6\u76f8\u7b26\u7684\u76ee\u7684\u5730\u3002", "conclusion": "\u57fa\u4e8e\u80fd\u529b\u7684\u4e2a\u4eba\u4e2d\u5fc3\u5316\u53ef\u8fbe\u6027\u6307\u6807\u6709\u52a9\u4e8e\u7406\u89e3\u57ce\u5e02\u79fb\u52a8\u4e0d\u5e73\u7b49\uff0c\u5e76\u4e3a\u6269\u5927\u4e0d\u540c\u4eba\u7fa4\u53c2\u4e0e\u793e\u4f1a\u751f\u6d3b\u7684\u771f\u5b9e\u81ea\u7531\u7684\u4ea4\u901a\u89c4\u5212\u7b56\u7565\u63d0\u4f9b\u4fe1\u606f\u3002"}}
{"id": "2510.11139", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2510.11139", "abs": "https://arxiv.org/abs/2510.11139", "authors": ["Mohammad Zeqi Yasin"], "title": "Superstars or Super-Villains? Productivity Spillovers and Firm Dynamics in Indonesia", "comment": null, "summary": "Do industrial \"superstars\" help others up or crowd them out? We examine the\nrelationship between the spillovers of superstar firms (those with the top\nmarket share in their industry) and the productivity dynamics in Indonesia.\nEmploying data on Indonesian manufacturing firms from 2001 to 2015, we find\nthat superstar exposures in the market raise both the productivity level and\nthe growth of non-superstar firms through horizontal (within a sector-province)\nand vertical (across sectors) channels. When we distinguish by ownership,\nforeign superstars consistently encourage productivity except through the\nhorizontal channel. In contrast, domestic superstars generate positive\nspillovers through both horizontal and vertical linkages, indicating that\nforeign firms do not solely drive positive externalities. Furthermore, despite\noverall productivity growth being positive in 2001-2015, the source of negative\ngrowth is mainly driven by within-group reallocation, evidence of misallocation\namong surviving firms, notably by domestic superstars. Although Indonesian\nsuperstar firms are more efficient in their operations, their relatively modest\ngrowth rates suggest a potential stagnation, which can be plausibly attributed\nto limited innovation activity or a slow pace of adopting new technologies.", "AI": {"tldr": "\u7814\u7a76\u5370\u5c3c\u5236\u9020\u4e1a\u4e2d\u8d85\u7ea7\u660e\u661f\u4f01\u4e1a\uff08\u5e02\u573a\u4efd\u989d\u6700\u9ad8\u7684\u4f01\u4e1a\uff09\u5bf9\u5176\u4ed6\u4f01\u4e1a\u7684\u6ea2\u51fa\u6548\u5e94\uff0c\u53d1\u73b0\u8d85\u7ea7\u660e\u661f\u4f01\u4e1a\u901a\u8fc7\u6a2a\u5411\uff08\u540c\u884c\u4e1a\u540c\u7701\u4efd\uff09\u548c\u7eb5\u5411\uff08\u8de8\u884c\u4e1a\uff09\u6e20\u9053\u63d0\u5347\u975e\u8d85\u7ea7\u660e\u661f\u4f01\u4e1a\u7684\u751f\u4ea7\u7387\u548c\u589e\u957f\u3002", "motivation": "\u63a2\u8ba8\u5de5\u4e1a\"\u8d85\u7ea7\u660e\u661f\"\u4f01\u4e1a\u662f\u5e2e\u52a9\u5176\u4ed6\u4f01\u4e1a\u53d1\u5c55\u8fd8\u662f\u6324\u5360\u5176\u7a7a\u95f4\uff0c\u5206\u6790\u5176\u5bf9\u5370\u5c3c\u5236\u9020\u4e1a\u751f\u4ea7\u7387\u52a8\u6001\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u75282001-2015\u5e74\u5370\u5c3c\u5236\u9020\u4e1a\u4f01\u4e1a\u6570\u636e\uff0c\u5206\u6790\u8d85\u7ea7\u660e\u661f\u4f01\u4e1a\u901a\u8fc7\u6a2a\u5411\u548c\u7eb5\u5411\u6e20\u9053\u5bf9\u5176\u4ed6\u4f01\u4e1a\u7684\u751f\u4ea7\u7387\u6ea2\u51fa\u6548\u5e94\uff0c\u5e76\u6309\u6240\u6709\u6743\uff08\u5916\u8d44vs\u672c\u571f\uff09\u8fdb\u884c\u533a\u5206\u3002", "result": "\u8d85\u7ea7\u660e\u661f\u4f01\u4e1a\u603b\u4f53\u4e0a\u901a\u8fc7\u6a2a\u5411\u548c\u7eb5\u5411\u6e20\u9053\u63d0\u5347\u975e\u8d85\u7ea7\u660e\u661f\u4f01\u4e1a\u7684\u751f\u4ea7\u7387\u548c\u589e\u957f\u3002\u5916\u8d44\u8d85\u7ea7\u660e\u661f\u4f01\u4e1a\u901a\u8fc7\u7eb5\u5411\u6e20\u9053\u4fc3\u8fdb\u751f\u4ea7\u7387\uff0c\u4f46\u6a2a\u5411\u6e20\u9053\u6548\u679c\u4e0d\u660e\u663e\uff1b\u672c\u571f\u8d85\u7ea7\u660e\u661f\u4f01\u4e1a\u901a\u8fc7\u4e24\u79cd\u6e20\u9053\u90fd\u4ea7\u751f\u6b63\u5411\u6ea2\u51fa\u3002\u867d\u7136\u6574\u4f53\u751f\u4ea7\u7387\u589e\u957f\u4e3a\u6b63\uff0c\u4f46\u5b58\u5728\u7ec4\u5185\u8d44\u6e90\u9519\u914d\u95ee\u9898\uff0c\u7279\u522b\u662f\u672c\u571f\u8d85\u7ea7\u660e\u661f\u4f01\u4e1a\u3002", "conclusion": "\u5370\u5c3c\u8d85\u7ea7\u660e\u661f\u4f01\u4e1a\u8fd0\u8425\u6548\u7387\u66f4\u9ad8\uff0c\u4f46\u589e\u957f\u76f8\u5bf9\u7f13\u6162\uff0c\u53ef\u80fd\u6e90\u4e8e\u521b\u65b0\u6d3b\u52a8\u6709\u9650\u6216\u6280\u672f\u91c7\u7528\u901f\u5ea6\u8f83\u6162\u3002\u5916\u8d44\u4f01\u4e1a\u5e76\u975e\u6b63\u5411\u5916\u90e8\u6027\u7684\u552f\u4e00\u9a71\u52a8\u56e0\u7d20\uff0c\u672c\u571f\u4f01\u4e1a\u4e5f\u4ea7\u751f\u663e\u8457\u6ea2\u51fa\u6548\u5e94\u3002"}}
{"id": "2510.09810", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.09810", "abs": "https://arxiv.org/abs/2510.09810", "authors": ["Victor Freire", "Marco M. Nicotra"], "title": "Designing Control Barrier Functions Using a Dynamic Backup Policy", "comment": "7 pages, 1 figure", "summary": "This paper presents a systematic approach to construct control barrier\nfunctions for nonlinear control affine systems subject to arbitrary state and\ninput constraints. Taking inspiration from the reference governor literature,\nthe proposed method defines a family of backup policies, parametrized by the\nequilibrium manifold of the system. The control barrier function is defined on\nthe augmented state-and-reference space: given a state-reference pair, the\napproach quantifies the distance to constraint violation at any time in the\nfuture, should the current backup policy reference remain constant. Sensitivity\nanalysis is then used to compute the (possibly nonsmooth) Jacobian with respect\nto the augmented state vector. To showcase its simple yet general nature, the\nproposed method is applied to an inverted pendulum on cart.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e3a\u975e\u7ebf\u6027\u63a7\u5236\u4eff\u5c04\u7cfb\u7edf\u6784\u5efa\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u7684\u7cfb\u7edf\u65b9\u6cd5\uff0c\u80fd\u591f\u5904\u7406\u4efb\u610f\u72b6\u6001\u548c\u8f93\u5165\u7ea6\u675f\u3002", "motivation": "\u9488\u5bf9\u975e\u7ebf\u6027\u63a7\u5236\u4eff\u5c04\u7cfb\u7edf\u7684\u72b6\u6001\u548c\u8f93\u5165\u7ea6\u675f\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u901a\u7528\u7684\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u6784\u9020\u65b9\u6cd5\u3002", "method": "\u501f\u9274\u53c2\u8003\u8c03\u8282\u5668\u6587\u732e\uff0c\u5b9a\u4e49\u4e86\u4e00\u65cf\u7531\u7cfb\u7edf\u5e73\u8861\u6d41\u5f62\u53c2\u6570\u5316\u7684\u5907\u4efd\u7b56\u7565\uff0c\u5728\u589e\u5e7f\u72b6\u6001-\u53c2\u8003\u7a7a\u95f4\u4e2d\u5b9a\u4e49\u63a7\u5236\u5c4f\u969c\u51fd\u6570\uff0c\u5e76\u901a\u8fc7\u7075\u654f\u5ea6\u5206\u6790\u8ba1\u7b97\u96c5\u53ef\u6bd4\u77e9\u9635\u3002", "result": "\u8be5\u65b9\u6cd5\u5177\u6709\u7b80\u5355\u800c\u901a\u7528\u7684\u7279\u6027\uff0c\u5e76\u5728\u5012\u7acb\u6446\u7cfb\u7edf\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u7ea6\u675f\u95ee\u9898\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2510.09636", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09636", "abs": "https://arxiv.org/abs/2510.09636", "authors": ["Prarthana P. Kartholy", "Thandi M. Labor", "Neil N. Panchal", "Sean H. Wang", "Hillary N. Owusu"], "title": "Bias-Aware AI Chatbot for Engineering Advising at the University of Maryland A. James Clark School of Engineering", "comment": null, "summary": "Selecting a college major is a difficult decision for many incoming freshmen.\nTraditional academic advising is often hindered by long wait times,\nintimidating environments, and limited personalization. AI Chatbots present an\nopportunity to address these challenges. However, AI systems also have the\npotential to generate biased responses, prejudices related to race, gender,\nsocioeconomic status, and disability. These biases risk turning away potential\nstudents and undermining reliability of AI systems. This study aims to develop\na University of Maryland (UMD) A. James Clark School of Engineering\nProgram-specific AI chatbot. Our research team analyzed and mitigated potential\nbiases in the responses. Through testing the chatbot on diverse student\nqueries, the responses are scored on metrics of accuracy, relevance,\npersonalization, and bias presence. The results demonstrate that with careful\nprompt engineering and bias mitigation strategies, AI chatbots can provide\nhigh-quality, unbiased academic advising support, achieving mean scores of 9.76\nfor accuracy, 9.56 for relevance, and 9.60 for personalization with no\nstereotypical biases found in the sample data. However, due to the small sample\nsize and limited timeframe, our AI model may not fully reflect the nuances of\nstudent queries in engineering academic advising. Regardless, these findings\nwill inform best practices for building ethical AI systems in higher education,\noffering tools to complement traditional advising and address the inequities\nfaced by many underrepresented and first-generation college students.", "AI": {"tldr": "\u5f00\u53d1\u9a6c\u91cc\u5170\u5927\u5b66\u5de5\u7a0b\u5b66\u9662\u4e13\u7528AI\u804a\u5929\u673a\u5668\u4eba\uff0c\u901a\u8fc7\u504f\u89c1\u7f13\u89e3\u7b56\u7565\u5b9e\u73b0\u9ad8\u8d28\u91cf\u3001\u65e0\u504f\u89c1\u7684\u5b66\u672f\u54a8\u8be2\uff0c\u51c6\u786e\u5ea69.76\u5206\uff0c\u76f8\u5173\u60279.56\u5206\uff0c\u4e2a\u6027\u53169.60\u5206\uff0c\u6837\u672c\u4e2d\u672a\u53d1\u73b0\u523b\u677f\u504f\u89c1\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u5b66\u672f\u54a8\u8be2\u7b49\u5f85\u65f6\u95f4\u957f\u3001\u73af\u5883\u4ee4\u4eba\u754f\u60e7\u3001\u4e2a\u6027\u5316\u6709\u9650\u7684\u95ee\u9898\uff0c\u540c\u65f6\u5e94\u5bf9AI\u7cfb\u7edf\u53ef\u80fd\u4ea7\u751f\u7684\u79cd\u65cf\u3001\u6027\u522b\u3001\u793e\u4f1a\u7ecf\u6d4e\u5730\u4f4d\u548c\u6b8b\u75be\u76f8\u5173\u7684\u504f\u89c1\u98ce\u9669\u3002", "method": "\u5206\u6790\u5e76\u7f13\u89e3\u6f5c\u5728\u504f\u89c1\uff0c\u901a\u8fc7\u591a\u6837\u5316\u5b66\u751f\u67e5\u8be2\u6d4b\u8bd5\u804a\u5929\u673a\u5668\u4eba\uff0c\u57fa\u4e8e\u51c6\u786e\u6027\u3001\u76f8\u5173\u6027\u3001\u4e2a\u6027\u5316\u548c\u504f\u89c1\u5b58\u5728\u7b49\u6307\u6807\u5bf9\u56de\u7b54\u8fdb\u884c\u8bc4\u5206\u3002", "result": "\u7ecf\u8fc7\u7cbe\u5fc3\u63d0\u793a\u5de5\u7a0b\u548c\u504f\u89c1\u7f13\u89e3\u7b56\u7565\uff0cAI\u804a\u5929\u673a\u5668\u4eba\u80fd\u63d0\u4f9b\u9ad8\u8d28\u91cf\u3001\u65e0\u504f\u89c1\u7684\u5b66\u672f\u54a8\u8be2\u652f\u6301\uff0c\u5e73\u5747\u5f97\u5206\uff1a\u51c6\u786e\u60279.76\u3001\u76f8\u5173\u60279.56\u3001\u4e2a\u6027\u53169.60\uff0c\u6837\u672c\u6570\u636e\u4e2d\u672a\u53d1\u73b0\u523b\u677f\u504f\u89c1\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u9ad8\u7b49\u6559\u80b2\u4e2d\u6784\u5efa\u4f26\u7406AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6700\u4f73\u5b9e\u8df5\uff0c\u4e3a\u8865\u5145\u4f20\u7edf\u54a8\u8be2\u548c\u89e3\u51b3\u5f31\u52bf\u7fa4\u4f53\u4e0d\u5e73\u7b49\u95ee\u9898\u63d0\u4f9b\u4e86\u5de5\u5177\uff0c\u4f46\u6837\u672c\u91cf\u5c0f\u3001\u65f6\u95f4\u6709\u9650\uff0c\u53ef\u80fd\u65e0\u6cd5\u5b8c\u5168\u53cd\u6620\u5de5\u7a0b\u5b66\u672f\u54a8\u8be2\u4e2d\u5b66\u751f\u67e5\u8be2\u7684\u7ec6\u5fae\u5dee\u522b\u3002"}}
{"id": "2510.09817", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.09817", "abs": "https://arxiv.org/abs/2510.09817", "authors": ["Samanta Rodriguez", "Yiming Dou", "Miquel Oller", "Andrew Owens", "Nima Fazeli"], "title": "Cross-Sensor Touch Generation", "comment": "CoRL 2025", "summary": "Today's visuo-tactile sensors come in many shapes and sizes, making it\nchallenging to develop general-purpose tactile representations. This is because\nmost models are tied to a specific sensor design. To address this challenge, we\npropose two approaches to cross-sensor image generation. The first is an\nend-to-end method that leverages paired data (Touch2Touch). The second method\nbuilds an intermediate depth representation and does not require paired data\n(T2D2: Touch-to-Depth-to-Touch). Both methods enable the use of sensor-specific\nmodels across multiple sensors via the cross-sensor touch generation process.\nTogether, these models offer flexible solutions for sensor translation,\ndepending on data availability and application needs. We demonstrate their\neffectiveness on downstream tasks such as in-hand pose estimation and behavior\ncloning, successfully transferring models trained on one sensor to another.\nProject page: https://samantabelen.github.io/cross_sensor_touch_generation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u79cd\u8de8\u4f20\u611f\u5668\u89e6\u89c9\u56fe\u50cf\u751f\u6210\u65b9\u6cd5\uff1aTouch2Touch\uff08\u7aef\u5230\u7aef\uff09\u548cT2D2\uff08\u901a\u8fc7\u6df1\u5ea6\u8868\u793a\uff09\uff0c\u89e3\u51b3\u4e86\u4e0d\u540c\u89e6\u89c9\u4f20\u611f\u5668\u4e4b\u95f4\u7684\u6a21\u578b\u8fc1\u79fb\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u89e6\u89c9\u4f20\u611f\u5668\u5f62\u72b6\u5c3a\u5bf8\u5404\u5f02\uff0c\u5bfc\u81f4\u5927\u591a\u6570\u6a21\u578b\u53ea\u80fd\u9488\u5bf9\u7279\u5b9a\u4f20\u611f\u5668\u8bbe\u8ba1\uff0c\u96be\u4ee5\u5f00\u53d1\u901a\u7528\u89e6\u89c9\u8868\u793a\u3002", "method": "1) Touch2Touch\uff1a\u57fa\u4e8e\u914d\u5bf9\u6570\u636e\u7684\u7aef\u5230\u7aef\u65b9\u6cd5\uff1b2) T2D2\uff1a\u6784\u5efa\u4e2d\u95f4\u6df1\u5ea6\u8868\u793a\uff0c\u65e0\u9700\u914d\u5bf9\u6570\u636e\u3002\u4e24\u79cd\u65b9\u6cd5\u90fd\u901a\u8fc7\u8de8\u4f20\u611f\u5668\u89e6\u89c9\u751f\u6210\u8fc7\u7a0b\u5b9e\u73b0\u4f20\u611f\u5668\u7279\u5b9a\u6a21\u578b\u7684\u8de8\u4f20\u611f\u5668\u4f7f\u7528\u3002", "result": "\u5728\u624b\u6301\u59ff\u6001\u4f30\u8ba1\u548c\u884c\u4e3a\u514b\u9686\u7b49\u4e0b\u6e38\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\uff0c\u6210\u529f\u5c06\u5728\u4e00\u4e2a\u4f20\u611f\u5668\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u8fc1\u79fb\u5230\u53e6\u4e00\u4e2a\u4f20\u611f\u5668\u3002", "conclusion": "\u8fd9\u4e9b\u6a21\u578b\u4e3a\u4f20\u611f\u5668\u8f6c\u6362\u63d0\u4f9b\u4e86\u7075\u6d3b\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u6839\u636e\u6570\u636e\u53ef\u7528\u6027\u548c\u5e94\u7528\u9700\u6c42\u9009\u62e9\u5408\u9002\u65b9\u6cd5\u3002"}}
{"id": "2510.10323", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.10323", "abs": "https://arxiv.org/abs/2510.10323", "authors": ["Mahdi Goldani"], "title": "Measuring Innovation Patterns in Iran and Neighboring Countries: A Time Series Similarity Approach Using STL and Dynamic Time Warping", "comment": null, "summary": "Innovation is becoming ever more pivotal to national development strategies\nbut measuring and comparing innovation performance across nations is still a\nmethodological challenges. This research devises a new time-series similarity\nmethod that integrates Seasonal-Trend decomposition (STL) with Fast Dynamic\nTime Warping (DTW) to examine Irans innovation trends by comparison with its\nregional peers. Owing to data availability constraints of Global Innovation\nIndex data , research and development spending as a proportion of GDP is used\nas a proxy with its limitations clearly noted. Based on World Bank indicators\nand an Autoencoder based imputation technique for missing values, the research\ncompares cross-country similarities and determines theme domains best aligned\nwith Irans innovation path. Findings indicate that poverty and health metrics\nmanifest the strongest statistical similarity with R and D spending in Iran,\nwhile Saudi Arabia, Oman, and Kuwait show the most similar cross country\nproximity. Implications are that Iranian innovation is more intrinsically\nconnected with social development dynamics rather than conventional economic or\ninfrastructure drivers, with region-specific implications for STI policy.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u7ed3\u5408STL\u5206\u89e3\u548c\u5feb\u901fDTW\u7684\u65f6\u95f4\u5e8f\u5217\u76f8\u4f3c\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u6bd4\u8f83\u4f0a\u6717\u4e0e\u5730\u533a\u540c\u884c\u6765\u8bc4\u4f30\u521b\u65b0\u8d8b\u52bf\uff0c\u53d1\u73b0\u4f0a\u6717\u521b\u65b0\u4e0e\u793e\u4f1a\u53d1\u5c55\u52a8\u6001\u66f4\u76f8\u5173\u3002", "motivation": "\u7531\u4e8e\u8861\u91cf\u548c\u6bd4\u8f83\u5404\u56fd\u521b\u65b0\u7ee9\u6548\u5b58\u5728\u65b9\u6cd5\u8bba\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u65b9\u6cd5\u6765\u5206\u6790\u4f0a\u6717\u7684\u521b\u65b0\u8d8b\u52bf\u53ca\u5176\u4e0e\u5730\u533a\u540c\u884c\u7684\u6bd4\u8f83\u3002", "method": "\u4f7f\u7528STL\u5b63\u8282\u6027\u8d8b\u52bf\u5206\u89e3\u4e0e\u5feb\u901f\u52a8\u6001\u65f6\u95f4\u89c4\u6574\u76f8\u7ed3\u5408\u7684\u65f6\u95f4\u5e8f\u5217\u76f8\u4f3c\u6027\u65b9\u6cd5\uff0c\u4ee5\u7814\u53d1\u652f\u51fa\u5360GDP\u6bd4\u91cd\u4e3a\u4ee3\u7406\u6307\u6807\uff0c\u91c7\u7528\u81ea\u7f16\u7801\u5668\u63d2\u8865\u7f3a\u5931\u503c\u3002", "result": "\u8d2b\u56f0\u548c\u5065\u5eb7\u6307\u6807\u4e0e\u4f0a\u6717\u7814\u53d1\u652f\u51fa\u8868\u73b0\u51fa\u6700\u5f3a\u7684\u7edf\u8ba1\u76f8\u4f3c\u6027\uff0c\u6c99\u7279\u963f\u62c9\u4f2f\u3001\u963f\u66fc\u548c\u79d1\u5a01\u7279\u663e\u793a\u51fa\u6700\u9ad8\u7684\u8de8\u56fd\u76f8\u4f3c\u6027\u3002", "conclusion": "\u4f0a\u6717\u521b\u65b0\u66f4\u5185\u5728\u4e0e\u793e\u4f1a\u53d1\u5c55\u52a8\u6001\u76f8\u5173\uff0c\u800c\u975e\u4f20\u7edf\u7ecf\u6d4e\u6216\u57fa\u7840\u8bbe\u65bd\u9a71\u52a8\u56e0\u7d20\uff0c\u8fd9\u5bf9\u79d1\u6280\u521b\u65b0\u653f\u7b56\u5177\u6709\u533a\u57df\u7279\u5b9a\u5f71\u54cd\u3002"}}
{"id": "2510.09859", "categories": ["econ.TH", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09859", "abs": "https://arxiv.org/abs/2510.09859", "authors": ["Weijie Zhong"], "title": "Token is All You Price", "comment": null, "summary": "We build a mechanism design framework where a platform designs GenAI models\nto screen users who obtain instrumental value from the generated conversation\nand privately differ in their preference for latency. We show that the\nrevenue-optimal mechanism is simple: deploy a single aligned (user-optimal)\nmodel and use token cap as the only instrument to screen the user. The design\ndecouples model training from pricing, is readily implemented with token\nmetering, and mitigates misalignment pressures.", "AI": {"tldr": "\u5e73\u53f0\u8bbe\u8ba1GenAI\u6a21\u578b\u6765\u7b5b\u9009\u5bf9\u5ef6\u8fdf\u6709\u4e0d\u540c\u504f\u597d\u7684\u7528\u6237\uff0c\u6536\u76ca\u6700\u4f18\u673a\u5236\u662f\u90e8\u7f72\u5355\u4e00\u5bf9\u9f50\u6a21\u578b\u5e76\u4f7f\u7528token\u4e0a\u9650\u4f5c\u4e3a\u552f\u4e00\u7b5b\u9009\u5de5\u5177", "motivation": "\u6784\u5efa\u673a\u5236\u8bbe\u8ba1\u6846\u67b6\uff0c\u8ba9\u5e73\u53f0\u80fd\u591f\u8bbe\u8ba1GenAI\u6a21\u578b\u6765\u7b5b\u9009\u5bf9\u5ef6\u8fdf\u6709\u4e0d\u540c\u504f\u597d\u7684\u7528\u6237\uff0c\u8fd9\u4e9b\u7528\u6237\u4ece\u751f\u6210\u5bf9\u8bdd\u4e2d\u83b7\u5f97\u5de5\u5177\u6027\u4ef7\u503c", "method": "\u90e8\u7f72\u5355\u4e00\u7528\u6237\u6700\u4f18\u5bf9\u9f50\u6a21\u578b\uff0c\u4f7f\u7528token\u4e0a\u9650\u4f5c\u4e3a\u552f\u4e00\u7b5b\u9009\u5de5\u5177\uff0c\u5c06\u6a21\u578b\u8bad\u7ec3\u4e0e\u5b9a\u4ef7\u89e3\u8026", "result": "\u8be5\u673a\u5236\u8bbe\u8ba1\u7b80\u5355\u6613\u884c\uff0c\u53ef\u901a\u8fc7token\u8ba1\u91cf\u5b9e\u73b0\uff0c\u5e76\u80fd\u51cf\u8f7b\u4e0d\u5bf9\u9f50\u538b\u529b", "conclusion": "\u6536\u76ca\u6700\u4f18\u673a\u5236\u662f\u7b80\u5355\u7684\u5355\u4e00\u5bf9\u9f50\u6a21\u578b\u52a0token\u4e0a\u9650\u7b5b\u9009\uff0c\u8be5\u8bbe\u8ba1\u5c06\u6a21\u578b\u8bad\u7ec3\u4e0e\u5b9a\u4ef7\u5206\u79bb\uff0c\u6613\u4e8e\u5b9e\u65bd"}}
{"id": "2510.09801", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09801", "abs": "https://arxiv.org/abs/2510.09801", "authors": ["Valerie Chen", "Rohit Malhotra", "Xingyao Wang", "Juan Michelini", "Xuhui Zhou", "Aditya Bharat Soni", "Hoang H. Tran", "Calvin Smith", "Ameet Talwalkar", "Graham Neubig"], "title": "How can we assess human-agent interactions? Case studies in software agent design", "comment": null, "summary": "LLM-powered agents are both a promising new technology and a source of\ncomplexity, where choices about models, tools, and prompting can affect their\nusefulness. While numerous benchmarks measure agent accuracy across domains,\nthey mostly assume full automation, failing to represent the collaborative\nnature of real-world use cases. In this paper, we make two major steps towards\nthe rigorous assessment of human-agent interactions. First, we propose PULSE, a\nframework for more efficient human-centric evaluation of agent designs, which\ncomprises collecting user feedback, training an ML model to predict user\nsatisfaction, and computing results by combining human satisfaction ratings\nwith model-generated pseudo-labels. Second, we deploy the framework on a\nlarge-scale web platform built around the open-source software agent OpenHands,\ncollecting in-the-wild usage data across over 15k users. We conduct case\nstudies around how three agent design decisions -- choice of LLM backbone,\nplanning strategy, and memory mechanisms -- impact developer satisfaction\nrates, yielding practical insights for software agent design. We also show how\nour framework can lead to more robust conclusions about agent design, reducing\nconfidence intervals by 40\\% compared to a standard A/B test. Finally, we find\nsubstantial discrepancies between in-the-wild results and benchmark performance\n(e.g., the anti-correlation between results comparing claude-sonnet-4 and\ngpt-5), underscoring the limitations of benchmark-driven evaluation. Our\nfindings provide guidance for evaluations of LLM agents with humans and\nidentify opportunities for better agent designs.", "AI": {"tldr": "\u63d0\u51fa\u4e86PULSE\u6846\u67b6\u7528\u4e8e\u66f4\u9ad8\u6548\u7684\u4eba\u7c7b\u4e2d\u5fc3\u5316\u667a\u80fd\u4f53\u8bc4\u4f30\uff0c\u901a\u8fc7\u6536\u96c6\u7528\u6237\u53cd\u9988\u3001\u8bad\u7ec3\u9884\u6d4b\u6a21\u578b\u548c\u7ed3\u5408\u4eba\u5de5\u8bc4\u5206\u4e0e\u6a21\u578b\u4f2a\u6807\u7b7e\u6765\u8ba1\u7b97\u7ed3\u679c\u3002\u5728OpenHands\u5e73\u53f0\u4e0a\u90e8\u7f72\u8be5\u6846\u67b6\uff0c\u6536\u96c6\u4e86\u8d85\u8fc715k\u7528\u6237\u7684\u4f7f\u7528\u6570\u636e\uff0c\u7814\u7a76\u4e86LLM\u9aa8\u5e72\u7f51\u7edc\u3001\u89c4\u5212\u7b56\u7565\u548c\u8bb0\u5fc6\u673a\u5236\u5bf9\u5f00\u53d1\u8005\u6ee1\u610f\u5ea6\u7684\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5927\u591a\u5047\u8bbe\u5b8c\u5168\u81ea\u52a8\u5316\uff0c\u672a\u80fd\u53cd\u6620\u771f\u5b9e\u4f7f\u7528\u573a\u666f\u4e2d\u4eba\u673a\u534f\u4f5c\u7684\u672c\u8d28\uff0c\u9700\u8981\u66f4\u4e25\u8c28\u7684\u4eba\u7c7b-\u667a\u80fd\u4f53\u4ea4\u4e92\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51faPULSE\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u62ec\u7528\u6237\u53cd\u9988\u6536\u96c6\u3001\u7528\u6237\u6ee1\u610f\u5ea6\u9884\u6d4b\u6a21\u578b\u8bad\u7ec3\u3001\u4eba\u5de5\u8bc4\u5206\u4e0e\u6a21\u578b\u4f2a\u6807\u7b7e\u7ed3\u5408\u8ba1\u7b97\u3002\u5728OpenHands\u5e73\u53f0\u4e0a\u5927\u89c4\u6a21\u90e8\u7f72\uff0c\u6536\u96c615k+\u7528\u6237\u6570\u636e\uff0c\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\u5206\u6790\u667a\u80fd\u4f53\u8bbe\u8ba1\u51b3\u7b56\u7684\u5f71\u54cd\u3002", "result": "\u6846\u67b6\u4f7f\u667a\u80fd\u4f53\u8bbe\u8ba1\u8bc4\u4f30\u66f4\u52a0\u7a33\u5065\uff0c\u7f6e\u4fe1\u533a\u95f4\u6bd4\u6807\u51c6A/B\u6d4b\u8bd5\u51cf\u5c1140%\u3002\u53d1\u73b0\u771f\u5b9e\u4f7f\u7528\u7ed3\u679c\u4e0e\u57fa\u51c6\u6d4b\u8bd5\u6027\u80fd\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff08\u5982claude-sonnet-4\u4e0egpt-5\u6bd4\u8f83\u7ed3\u679c\u5448\u8d1f\u76f8\u5173\uff09\uff0c\u63ed\u793a\u4e86\u57fa\u51c6\u9a71\u52a8\u8bc4\u4f30\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u7814\u7a76\u4e3a\u4eba\u7c7b\u53c2\u4e0e\u7684LLM\u667a\u80fd\u4f53\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u8bc6\u522b\u4e86\u6539\u8fdb\u667a\u80fd\u4f53\u8bbe\u8ba1\u7684\u673a\u4f1a\uff0c\u5f3a\u8c03\u4e86\u771f\u5b9e\u4f7f\u7528\u573a\u666f\u8bc4\u4f30\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.10614", "categories": ["stat.AP", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.10614", "abs": "https://arxiv.org/abs/2510.10614", "authors": ["Robert G. Cowell"], "title": "A clustering algorithm for the single cell analysis of mixtures", "comment": "48 paegs, 5 figures", "summary": "A probabilistic clustering algorithm is proposed for the analysis of forensic\nDNA mixtures in which individual cells are isolated and short tandem repeats\nare amplified using the polymerase chain reaction to generate single cell\nelectropherograms. The task of the algorithm is to use the peak height\ninformation in the electropherograms to group the cells according to their\ncontributors. Using a recently developed experimental set of individual cell\nelectropherograms, a large set of simulations shows that the proposed\nclustering algorithm has excellent performance in correctly grouping single\ncells, and for assigning likelihood ratios for persons of interest (of known\ngenotype).", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6982\u7387\u805a\u7c7b\u7b97\u6cd5\u7528\u4e8e\u5206\u6790\u6cd5\u533bDNA\u6df7\u5408\u7269\uff0c\u901a\u8fc7\u5206\u79bb\u5355\u4e2a\u7ec6\u80de\u5e76\u4f7f\u7528PCR\u6269\u589e\u77ed\u4e32\u8054\u91cd\u590d\u5e8f\u5217\u751f\u6210\u5355\u7ec6\u80de\u7535\u6cf3\u56fe\uff0c\u5229\u7528\u5cf0\u9ad8\u4fe1\u606f\u5c06\u7ec6\u80de\u6309\u8d21\u732e\u8005\u5206\u7ec4\u3002", "motivation": "\u89e3\u51b3\u6cd5\u533bDNA\u6df7\u5408\u7269\u5206\u6790\u4e2d\u5355\u7ec6\u80de\u5206\u79bb\u548c\u5206\u7ec4\u7684\u6311\u6218\uff0c\u63d0\u9ad8DNA\u6df7\u5408\u7269\u5206\u6790\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u4f7f\u7528\u6982\u7387\u805a\u7c7b\u7b97\u6cd5\u5206\u6790\u5355\u7ec6\u80de\u7535\u6cf3\u56fe\u4e2d\u7684\u5cf0\u9ad8\u4fe1\u606f\uff0c\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u9a8c\u8bc1\u7b97\u6cd5\u6027\u80fd\u3002", "result": "\u6a21\u62df\u5b9e\u9a8c\u663e\u793a\u8be5\u805a\u7c7b\u7b97\u6cd5\u5728\u6b63\u786e\u5206\u7ec4\u5355\u7ec6\u80de\u548c\u4e3a\u5df2\u77e5\u57fa\u56e0\u578b\u4eba\u5458\u8ba1\u7b97\u4f3c\u7136\u6bd4\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u8be5\u6982\u7387\u805a\u7c7b\u7b97\u6cd5\u80fd\u6709\u6548\u5206\u6790\u6cd5\u533bDNA\u6df7\u5408\u7269\uff0c\u4e3a\u6cd5\u533bDNA\u5206\u6790\u63d0\u4f9b\u53ef\u9760\u7684\u5de5\u5177\u3002"}}
{"id": "2510.10499", "categories": ["cs.SI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.10499", "abs": "https://arxiv.org/abs/2510.10499", "authors": ["Yutong Hu", "Bingxin Zhou", "Jing Wang", "Weishu Zhao", "Liang Hong"], "title": "Preserving Core Structures of Social Networks via Information Guided Multi-Step Graph Pruning", "comment": null, "summary": "Social networks often contain dense and overlapping connections that obscure\ntheir essential interaction patterns, making analysis and interpretation\nchallenging. Identifying the structural backbone of such networks is crucial\nfor understanding community organization, information flow, and functional\nrelationships. This study introduces a multi-step network pruning framework\nthat leverages principles from information theory to balance structural\ncomplexity and task-relevant information. The framework iteratively evaluates\nand removes edges from the graph based on their contribution to task-relevant\nmutual information, producing a trajectory of network simplification that\npreserves most of the inherent semantics. Motivated by gradient boosting, we\npropose IGPrune, which enables efficient, differentiable optimization to\nprogressively uncover semantically meaningful connections. Extensive\nexperiments on social and biological networks show that IGPrune retains\ncritical structural and functional patterns. Beyond quantitative performance,\nthe pruned networks reveal interpretable backbones, highlighting the method's\npotential to support scientific discovery and actionable insights in real-world\nnetworks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u7406\u8bba\u7684\u591a\u6b65\u7f51\u7edc\u526a\u679d\u6846\u67b6IGPrune\uff0c\u901a\u8fc7\u8fed\u4ee3\u8bc4\u4f30\u548c\u79fb\u9664\u8fb9\u6765\u5e73\u8861\u7ed3\u6784\u590d\u6742\u5ea6\u548c\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\uff0c\u4fdd\u7559\u7f51\u7edc\u7684\u6838\u5fc3\u8bed\u4e49\u7ed3\u6784\u3002", "motivation": "\u793e\u4ea4\u7f51\u7edc\u901a\u5e38\u5305\u542b\u5bc6\u96c6\u91cd\u53e0\u7684\u8fde\u63a5\uff0c\u63a9\u76d6\u4e86\u5176\u672c\u8d28\u4ea4\u4e92\u6a21\u5f0f\uff0c\u4f7f\u5f97\u5206\u6790\u548c\u89e3\u91ca\u53d8\u5f97\u56f0\u96be\u3002\u8bc6\u522b\u8fd9\u4e9b\u7f51\u7edc\u7684\u7ed3\u6784\u9aa8\u5e72\u5bf9\u4e8e\u7406\u89e3\u793e\u533a\u7ec4\u7ec7\u3001\u4fe1\u606f\u6d41\u548c\u529f\u80fd\u5173\u7cfb\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f15\u5165\u591a\u6b65\u7f51\u7edc\u526a\u679d\u6846\u67b6\uff0c\u5229\u7528\u4fe1\u606f\u7406\u8bba\u539f\u5219\u5e73\u8861\u7ed3\u6784\u590d\u6742\u5ea6\u548c\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\u3002\u57fa\u4e8e\u68af\u5ea6\u63d0\u5347\u601d\u60f3\u63d0\u51faIGPrune\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u4f18\u5316\u9010\u6b65\u63ed\u793a\u8bed\u4e49\u4e0a\u6709\u610f\u4e49\u7684\u8fde\u63a5\u3002", "result": "\u5728\u793e\u4ea4\u548c\u751f\u7269\u7f51\u7edc\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cIGPrune\u4fdd\u7559\u4e86\u5173\u952e\u7684\u7ed3\u6784\u548c\u529f\u80fd\u6a21\u5f0f\u3002\u526a\u679d\u540e\u7684\u7f51\u7edc\u63ed\u793a\u4e86\u53ef\u89e3\u91ca\u7684\u9aa8\u5e72\u7ed3\u6784\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5177\u6709\u652f\u6301\u79d1\u5b66\u53d1\u73b0\u548c\u5728\u73b0\u5b9e\u4e16\u754c\u7f51\u7edc\u4e2d\u63d0\u4f9b\u53ef\u64cd\u4f5c\u89c1\u89e3\u7684\u6f5c\u529b\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u7f51\u7edc\u7684\u6838\u5fc3\u8bed\u4e49\u7ed3\u6784\u3002"}}
{"id": "2510.11659", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2510.11659", "abs": "https://arxiv.org/abs/2510.11659", "authors": ["Onil Boussim"], "title": "Compositional difference-in-differences for categorical outcomes", "comment": null, "summary": "In difference-in-differences (DiD) settings with categorical outcomes,\ntreatment effects often operate on both total quantities (e.g., voter turnout)\nand category shares (e.g., vote distribution across parties). In this context,\nlinear DiD models can be problematic: they suffer from scale dependence, may\nproduce negative counterfactual quantities, and are inconsistent with discrete\nchoice theory. We propose compositional DiD (CoDiD), a new method that\nidentifies counterfactual categorical quantities, and thus total levels and\nshares, under a parallel growths assumption. The assumption states that, absent\ntreatment, each category's size grows or shrinks at the same proportional rate\nin treated and control groups. In a random utility framework, we show that this\nimplies parallel evolution of relative preferences between any pair of\ncategories. Analytically, we show that it also means the shares are reallocated\nin the same way in both groups in the absence of treatment. Finally,\ngeometrically, it corresponds to parallel trajectories (or movements) of\nprobability mass functions of the two groups in the probability simplex under\nAitchison geometry. We extend CoDiD to i) derive bounds under relaxed\nassumptions, ii) handle staggered adoption, and iii) propose a synthetic DiD\nanalog. We illustrate the method's empirical relevance through two\napplications: first, we examine how early voting reforms affect voter choice in\nU.S. presidential elections; second, we analyze how the Regional Greenhouse Gas\nInitiative (RGGI) affected the composition of electricity generation across\nsources such as coal, natural gas, nuclear, and renewables.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7ec4\u5408\u5dee\u5206\u6cd5(CoDiD)\uff0c\u7528\u4e8e\u5904\u7406\u5206\u7c7b\u7ed3\u679c\u7684\u53cc\u91cd\u5dee\u5206\u5206\u6790\uff0c\u89e3\u51b3\u7ebf\u6027DiD\u6a21\u578b\u5728\u5206\u7c7b\u6570\u636e\u4e2d\u7684\u95ee\u9898\uff0c\u5305\u62ec\u5c3a\u5ea6\u4f9d\u8d56\u6027\u548c\u8d1f\u53cd\u4e8b\u5b9e\u91cf\u7b49\u95ee\u9898\u3002", "motivation": "\u5728\u5206\u7c7b\u7ed3\u679c\u7684DiD\u5206\u6790\u4e2d\uff0c\u7ebf\u6027DiD\u6a21\u578b\u5b58\u5728\u5c3a\u5ea6\u4f9d\u8d56\u6027\u3001\u53ef\u80fd\u4ea7\u751f\u8d1f\u53cd\u4e8b\u5b9e\u91cf\u3001\u4e0e\u79bb\u6563\u9009\u62e9\u7406\u8bba\u4e0d\u4e00\u81f4\u7b49\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9002\u5408\u5206\u7c7b\u6570\u636e\u7684\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u5e73\u884c\u589e\u957f\u5047\u8bbe\u7684\u7ec4\u5408\u5dee\u5206\u6cd5(CoDiD)\uff0c\u5047\u8bbe\u5728\u6ca1\u6709\u5904\u7406\u7684\u60c5\u51b5\u4e0b\uff0c\u5904\u7406\u7ec4\u548c\u5bf9\u7167\u7ec4\u4e2d\u6bcf\u4e2a\u7c7b\u522b\u7684\u89c4\u6a21\u4ee5\u76f8\u540c\u7684\u6bd4\u4f8b\u589e\u957f\u6216\u6536\u7f29\u3002\u8be5\u65b9\u6cd5\u5728\u968f\u673a\u6548\u7528\u6846\u67b6\u4e0b\u63a8\u5bfc\uff0c\u5e76\u6269\u5c55\u5230\u5904\u7406\u677e\u5f1b\u5047\u8bbe\u3001\u4ea4\u9519\u91c7\u7528\u548c\u5408\u6210DiD\u7b49\u60c5\u51b5\u3002", "result": "\u901a\u8fc7\u4e24\u4e2a\u5b9e\u8bc1\u5e94\u7528\u9a8c\u8bc1\u65b9\u6cd5\uff1a1\uff09\u65e9\u671f\u6295\u7968\u6539\u9769\u5bf9\u7f8e\u56fd\u5927\u9009\u4e2d\u9009\u6c11\u9009\u62e9\u7684\u5f71\u54cd\uff1b2\uff09\u533a\u57df\u6e29\u5ba4\u6c14\u4f53\u5021\u8bae(RGGI)\u5bf9\u7535\u529b\u6765\u6e90\u6784\u6210\uff08\u7164\u3001\u5929\u7136\u6c14\u3001\u6838\u80fd\u3001\u53ef\u518d\u751f\u80fd\u6e90\uff09\u7684\u5f71\u54cd\u3002", "conclusion": "CoDiD\u65b9\u6cd5\u4e3a\u5206\u7c7b\u7ed3\u679c\u7684DiD\u5206\u6790\u63d0\u4f9b\u4e86\u7406\u8bba\u4e00\u81f4\u4e14\u5b9e\u7528\u7684\u6846\u67b6\uff0c\u80fd\u591f\u540c\u65f6\u5904\u7406\u603b\u91cf\u548c\u4efd\u989d\u53d8\u5316\uff0c\u89e3\u51b3\u4e86\u7ebf\u6027DiD\u5728\u5206\u7c7b\u6570\u636e\u4e2d\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2510.09826", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.09826", "abs": "https://arxiv.org/abs/2510.09826", "authors": ["Jialin Zheng", "Zhong Liu", "Xiaonan Lu"], "title": "Latent-Feature-Informed Neural ODE Modeling for Lightweight Stability Evaluation of Black-box Grid-Tied Inverters", "comment": "6 pages 8fugures", "summary": "Stability evaluation of black-box grid-tied inverters is vital for grid\nreliability, yet identification techniques are both data-hungry and blocked by\nproprietary internals. {To solve this, this letter proposes a\nlatent-feature-informed neural ordinary differential equation (LFI-NODE)\nmodeling method that can achieve lightweight stability evaluation directly from\ntrajectory data.} LFI-NODE parameterizes the entire system ODE with a single\ncontinuous-time neural network, allowing each new sample to refine a unified\nglobal model. It faithfully captures nonlinear large-signal dynamics to\npreserve uniform predictive accuracy as the inverter transitions between\noperating points. Meanwhile, latent perturbation features distilled from every\ntrajectory steer the learning process and concurrently reveal the small-signal\neigenstructure essential for rigorous stability analysis. Validated on a\ngrid-forming inverter, {The LFI-NODE requires one to two orders of magnitude\nfewer training samples compared with traditional methods, collected from short\ntime-domain trajectories instead of extensive frequency-domain measurements.}\n{Furthermore, the LFI-NODE requires only 48 short transients to achieve a\ntrajectory prediction error at the hundredth level and an eigenvalue estimation\nerror at the tenth level, outperforming benchmark methods by one to two orders\nof magnitude.} This makes LFI-NODE a practical and lightweight approach for\nachieving high-fidelity stability assessment of complex black-box\npower-electronic systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6f5c\u5728\u7279\u5f81\u795e\u7ecf\u5fae\u5206\u65b9\u7a0b(LFI-NODE)\u7684\u8f7b\u91cf\u7ea7\u9ed1\u7bb1\u5e76\u7f51\u9006\u53d8\u5668\u7a33\u5b9a\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4ec5\u9700\u5c11\u91cf\u65f6\u57df\u8f68\u8ff9\u6570\u636e\u5373\u53ef\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u7a33\u5b9a\u6027\u5206\u6790\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u9ed1\u7bb1\u5e76\u7f51\u9006\u53d8\u5668\u7a33\u5b9a\u6027\u8bc4\u4f30\u65b9\u6cd5\u6570\u636e\u9700\u6c42\u91cf\u5927\u4e14\u53d7\u9650\u4e8e\u4e13\u6709\u5185\u90e8\u7ed3\u6784\u7684\u96be\u9898\u3002", "method": "\u4f7f\u7528\u5355\u4e00\u8fde\u7eed\u65f6\u95f4\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u5316\u6574\u4e2a\u7cfb\u7edfODE\uff0c\u901a\u8fc7\u6f5c\u5728\u6270\u52a8\u7279\u5f81\u5f15\u5bfc\u5b66\u4e60\u8fc7\u7a0b\uff0c\u540c\u65f6\u63ed\u793a\u5c0f\u4fe1\u53f7\u7279\u5f81\u7ed3\u6784\u3002", "result": "\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\uff0c\u8bad\u7ec3\u6837\u672c\u9700\u6c42\u51cf\u5c111-2\u4e2a\u6570\u91cf\u7ea7\uff0c\u4ec5\u970048\u4e2a\u77ed\u65f6\u77ac\u6001\u5373\u53ef\u8fbe\u5230\u767e\u5206\u4f4d\u8f68\u8ff9\u9884\u6d4b\u8bef\u5dee\u548c\u5341\u5206\u4f4d\u7279\u5f81\u503c\u4f30\u8ba1\u8bef\u5dee\u3002", "conclusion": "LFI-NODE\u4e3a\u590d\u6742\u9ed1\u7bb1\u7535\u529b\u7535\u5b50\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u8f7b\u91cf\u7ea7\u7684\u9ad8\u4fdd\u771f\u7a33\u5b9a\u6027\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2510.09674", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09674", "abs": "https://arxiv.org/abs/2510.09674", "authors": ["Joao D. S. Marques", "Andre V. Duarte", "Andre Carvalho", "Gil Rocha", "Bruno Martins", "Arlindo L. Oliveira"], "title": "Leveraging LLMs to Streamline the Review of Public Funding Applications", "comment": "Paper Accepted at EMNLP 2025 Industry Track", "summary": "Every year, the European Union and its member states allocate millions of\neuros to fund various development initiatives. However, the increasing number\nof applications received for these programs often creates significant\nbottlenecks in evaluation processes, due to limited human capacity. In this\nwork, we detail the real-world deployment of AI-assisted evaluation within the\npipeline of two government initiatives: (i) corporate applications aimed at\ninternational business expansion, and (ii) citizen reimbursement claims for\ninvestments in energy-efficient home improvements. While these two cases\ninvolve distinct evaluation procedures, our findings confirm that AI\neffectively enhanced processing efficiency and reduced workload across both\ntypes of applications. Specifically, in the citizen reimbursement claims\ninitiative, our solution increased reviewer productivity by 20.1%, while\nkeeping a negligible false-positive rate based on our test set observations.\nThese improvements resulted in an overall reduction of more than 2 months in\nthe total evaluation time, illustrating the impact of AI-driven automation in\nlarge-scale evaluation workflows.", "AI": {"tldr": "AI\u8f85\u52a9\u8bc4\u4f30\u7cfb\u7edf\u5728\u6b27\u76df\u653f\u5e9c\u9879\u76ee\u4e2d\u6210\u529f\u90e8\u7f72\uff0c\u63d0\u9ad8\u4e86\u5904\u7406\u6548\u7387\uff0c\u5728\u516c\u6c11\u62a5\u9500\u7533\u8bf7\u4e2d\u4f7f\u5ba1\u6838\u6548\u7387\u63d0\u534720.1%\uff0c\u603b\u4f53\u8bc4\u4f30\u65f6\u95f4\u51cf\u5c11\u8d85\u8fc72\u4e2a\u6708\u3002", "motivation": "\u6b27\u76df\u53ca\u5176\u6210\u5458\u56fd\u6bcf\u5e74\u6295\u5165\u5927\u91cf\u8d44\u91d1\u8d44\u52a9\u53d1\u5c55\u9879\u76ee\uff0c\u4f46\u7533\u8bf7\u6570\u91cf\u6fc0\u589e\u5bfc\u81f4\u8bc4\u4f30\u8fc7\u7a0b\u51fa\u73b0\u74f6\u9888\uff0c\u4eba\u529b\u5904\u7406\u80fd\u529b\u6709\u9650\u3002", "method": "\u5728\u4e24\u4e2a\u653f\u5e9c\u9879\u76ee\u4e2d\u90e8\u7f72AI\u8f85\u52a9\u8bc4\u4f30\u7cfb\u7edf\uff1a(1)\u4f01\u4e1a\u56fd\u9645\u4e1a\u52a1\u6269\u5c55\u7533\u8bf7\uff1b(2)\u516c\u6c11\u8282\u80fd\u5bb6\u5c45\u6295\u8d44\u62a5\u9500\u7533\u8bf7\uff0c\u91c7\u7528\u4e0d\u540c\u7684\u8bc4\u4f30\u6d41\u7a0b\u3002", "result": "AI\u6709\u6548\u63d0\u5347\u4e86\u5904\u7406\u6548\u7387\uff0c\u5728\u516c\u6c11\u62a5\u9500\u7533\u8bf7\u4e2d\u5ba1\u6838\u6548\u7387\u63d0\u9ad820.1%\uff0c\u8bef\u62a5\u7387\u6781\u4f4e\uff0c\u603b\u4f53\u8bc4\u4f30\u65f6\u95f4\u51cf\u5c11\u8d85\u8fc72\u4e2a\u6708\u3002", "conclusion": "AI\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u5728\u5927\u89c4\u6a21\u8bc4\u4f30\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u5177\u6709\u663e\u8457\u5f71\u54cd\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u4eba\u529b\u5904\u7406\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002"}}
{"id": "2510.09962", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.09962", "abs": "https://arxiv.org/abs/2510.09962", "authors": ["Yicheng He", "Jingwen Yu", "Guangcheng Chen", "Hong Zhang"], "title": "VG-Mapping: Variation-Aware 3D Gaussians for Online Semi-static Scene Mapping", "comment": null, "summary": "Maintaining an up-to-date map that accurately reflects recent changes in the\nenvironment is crucial, especially for robots that repeatedly traverse the same\nspace. Failing to promptly update the changed regions can degrade map quality,\nresulting in poor localization, inefficient operations, and even lost robots.\n3D Gaussian Splatting (3DGS) has recently seen widespread adoption in online\nmap reconstruction due to its dense, differentiable, and photorealistic\nproperties, yet accurately and efficiently updating the regions of change\nremains a challenge. In this paper, we propose VG-Mapping, a novel online\n3DGS-based mapping system tailored for such semi-static scenes. Our approach\nintroduces a hybrid representation that augments 3DGS with a TSDF-based voxel\nmap to efficiently identify changed regions in a scene, along with a\nvariation-aware density control strategy that inserts or deletes Gaussian\nprimitives in regions undergoing change. Furthermore, to address the absence of\npublic benchmarks for this task, we construct a RGB-D dataset comprising both\nsynthetic and real-world semi-static environments. Experimental results\ndemonstrate that our method substantially improves the rendering quality and\nmap update efficiency in semi-static scenes. The code and dataset are available\nat https://github.com/heyicheng-never/VG-Mapping.", "AI": {"tldr": "VG-Mapping\u662f\u4e00\u79cd\u57fa\u4e8e3D\u9ad8\u65af\u6cfc\u6e85\u7684\u5728\u7ebf\u5efa\u56fe\u7cfb\u7edf\uff0c\u4e13\u95e8\u9488\u5bf9\u534a\u9759\u6001\u573a\u666f\uff0c\u901a\u8fc7\u6df7\u5408\u8868\u793a\u548c\u53d8\u5316\u611f\u77e5\u5bc6\u5ea6\u63a7\u5236\u7b56\u7565\uff0c\u6709\u6548\u8bc6\u522b\u548c\u66f4\u65b0\u573a\u666f\u4e2d\u7684\u53d8\u5316\u533a\u57df\u3002", "motivation": "\u5728\u673a\u5668\u4eba\u91cd\u590d\u904d\u5386\u540c\u4e00\u7a7a\u95f4\u65f6\uff0c\u53ca\u65f6\u66f4\u65b0\u73af\u5883\u4e2d\u7684\u53d8\u5316\u533a\u57df\u5bf9\u4fdd\u6301\u5730\u56fe\u8d28\u91cf\u81f3\u5173\u91cd\u8981\u3002\u73b0\u67093DGS\u65b9\u6cd5\u5728\u51c6\u786e\u9ad8\u6548\u66f4\u65b0\u53d8\u5316\u533a\u57df\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u8868\u793a\u65b9\u6cd5\uff0c\u5c063DGS\u4e0e\u57fa\u4e8eTSDF\u7684\u4f53\u7d20\u5730\u56fe\u7ed3\u5408\u6765\u8bc6\u522b\u53d8\u5316\u533a\u57df\uff0c\u5e76\u91c7\u7528\u53d8\u5316\u611f\u77e5\u5bc6\u5ea6\u63a7\u5236\u7b56\u7565\u6765\u63d2\u5165\u6216\u5220\u9664\u9ad8\u65af\u57fa\u5143\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u534a\u9759\u6001\u573a\u666f\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u6e32\u67d3\u8d28\u91cf\u548c\u5730\u56fe\u66f4\u65b0\u6548\u7387\u3002", "conclusion": "VG-Mapping\u4e3a\u534a\u9759\u6001\u573a\u666f\u7684\u5728\u7ebf\u5efa\u56fe\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u53d1\u5e03\u4e86\u76f8\u5173\u6570\u636e\u96c6\u548c\u4ee3\u7801\u3002"}}
{"id": "2510.10437", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.10437", "abs": "https://arxiv.org/abs/2510.10437", "authors": ["Minali Grover", "Ajay Sharma"], "title": "Women's inheritance rights reforms and impact on women's empowerment: evidence from India", "comment": "Published in Review of Economics of the Household", "summary": "This paper explores the influence of inheritance rights on women' empowerment\nin India. We employ the quasi-natural experiment framework wherein; five states\namended the Hindu Succession Act (HSA) from 1976 to 1994 before it was\nfederally amended in 2005. Further, we apply difference-in-difference (DID)\nstrategy and consider triangulation approach to identify women empowerment\nindicators namely: access to resources, agency, and outcomes to measure varying\ndimensions of empowerment. Using the India Human Development Survey (IHDS-I),\nour results indicate a positive impact on marriage choice, intimate partner\nviolence, physical, and civil autonomy. However, negative impact on household\nautonomy and no significant on economic participation for women exposed to\nstate amendments. Further, exploring the heterogeneities in terms of\nsocio-economic status, location, level of patriarchy in a state, gender of the\nhead of the household. Overall, the study highlights that the impact of\ninheritance law is not unfirm across different groups.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5370\u5ea6\u4e94\u4e2a\u90a6\u57281976-1994\u5e74\u95f4\u4fee\u8ba2\u300a\u5370\u5ea6\u6559\u7ee7\u627f\u6cd5\u300b\u7684\u81ea\u7136\u5b9e\u9a8c\uff0c\u4f7f\u7528\u53cc\u91cd\u5dee\u5206\u6cd5\u5206\u6790\u7ee7\u627f\u6743\u5bf9\u5973\u6027\u8d4b\u6743\u7684\u5f71\u54cd\u3002\u7814\u7a76\u53d1\u73b0\u8be5\u6cd5\u5f8b\u5bf9\u5a5a\u59fb\u9009\u62e9\u3001\u4eb2\u5bc6\u4f34\u4fa3\u66b4\u529b\u548c\u81ea\u4e3b\u6743\u6709\u79ef\u6781\u5f71\u54cd\uff0c\u4f46\u5bf9\u5bb6\u5ead\u81ea\u4e3b\u6743\u6709\u8d1f\u9762\u5f71\u54cd\uff0c\u5bf9\u7ecf\u6d4e\u53c2\u4e0e\u65e0\u663e\u8457\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u7ee7\u627f\u6743\u5bf9\u5973\u6027\u8d4b\u6743\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u5370\u5ea6\u8fd9\u6837\u7684\u4f20\u7edf\u793e\u4f1a\u4e2d\uff0c\u4e86\u89e3\u6cd5\u5f8b\u6539\u9769\u5982\u4f55\u5f71\u54cd\u5973\u6027\u7684\u793e\u4f1a\u5730\u4f4d\u548c\u6743\u5229\u3002", "method": "\u91c7\u7528\u51c6\u81ea\u7136\u5b9e\u9a8c\u6846\u67b6\uff0c\u5229\u7528\u4e94\u4e2a\u90a6\u57281976-1994\u5e74\u95f4\u4fee\u8ba2\u300a\u5370\u5ea6\u6559\u7ee7\u627f\u6cd5\u300b\u7684\u65f6\u95f4\u5dee\u5f02\uff0c\u4f7f\u7528\u53cc\u91cd\u5dee\u5206\u6cd5\uff0c\u5e76\u901a\u8fc7\u4e09\u89d2\u6d4b\u91cf\u65b9\u6cd5\u8bc6\u522b\u5973\u6027\u8d4b\u6743\u6307\u6807\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff1a\u5bf9\u5a5a\u59fb\u9009\u62e9\u3001\u4eb2\u5bc6\u4f34\u4fa3\u66b4\u529b\u3001\u8eab\u4f53\u548c\u516c\u6c11\u81ea\u4e3b\u6743\u6709\u79ef\u6781\u5f71\u54cd\uff1b\u5bf9\u5bb6\u5ead\u81ea\u4e3b\u6743\u6709\u8d1f\u9762\u5f71\u54cd\uff1b\u5bf9\u7ecf\u6d4e\u53c2\u4e0e\u65e0\u663e\u8457\u5f71\u54cd\u3002\u4e0d\u540c\u793e\u4f1a\u7ecf\u6d4e\u7fa4\u4f53\u3001\u5730\u533a\u3001\u7236\u6743\u5236\u7a0b\u5ea6\u548c\u6237\u4e3b\u6027\u522b\u7684\u5f02\u8d28\u6027\u5206\u6790\u8868\u660e\u5f71\u54cd\u4e0d\u4e00\u81f4\u3002", "conclusion": "\u7ee7\u627f\u6cd5\u7684\u5f71\u54cd\u5728\u4e0d\u540c\u7fa4\u4f53\u4e2d\u5e76\u4e0d\u4e00\u81f4\uff0c\u6cd5\u5f8b\u6539\u9769\u7684\u6548\u679c\u53d7\u5230\u793e\u4f1a\u80cc\u666f\u548c\u7fa4\u4f53\u7279\u5f81\u7684\u8c03\u8282\u3002"}}
{"id": "2510.10997", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2510.10997", "abs": "https://arxiv.org/abs/2510.10997", "authors": ["Jose M. Betancourt"], "title": "The Strength of Local Structures in Decentralized Network Formation", "comment": "36 pages; 5 figures; appendices included", "summary": "I study dynamic network formation games in which agents assign arbitrary\nvalues to network structures. Any such game admits an equivalent representation\nin terms of the values agents assign to its sub-structures, linking local\nvaluations to equilibrium behavior. The game is a potential game precisely when\nall participants in a structure value it equally, yielding a closed-form\nstationary distribution. When valuations are restricted to a finite set of\nrepeated sub-structures, or motifs, the model exhibits phase transitions: small\nchanges in motif values cause discontinuous shifts in network density.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u52a8\u6001\u7f51\u7edc\u5f62\u6210\u535a\u5f08\uff0c\u5176\u4e2d\u53c2\u4e0e\u8005\u5bf9\u7f51\u7edc\u7ed3\u6784\u8d4b\u4e88\u4efb\u610f\u4ef7\u503c\u3002\u535a\u5f08\u5b58\u5728\u52bf\u535a\u5f08\u7b49\u4ef7\u8868\u793a\uff0c\u5f53\u6240\u6709\u53c2\u4e0e\u8005\u5bf9\u7ed3\u6784\u4ef7\u503c\u8bc4\u4f30\u76f8\u540c\u65f6\uff0c\u53ef\u83b7\u5f97\u95ed\u5f0f\u5e73\u7a33\u5206\u5e03\u3002\u5f53\u4ef7\u503c\u8bc4\u4f30\u9650\u4e8e\u6709\u9650\u91cd\u590d\u5b50\u7ed3\u6784\u65f6\uff0c\u6a21\u578b\u5448\u73b0\u76f8\u53d8\u73b0\u8c61\u3002", "motivation": "\u7814\u7a76\u52a8\u6001\u7f51\u7edc\u5f62\u6210\u535a\u5f08\u4e2d\u53c2\u4e0e\u8005\u5bf9\u7f51\u7edc\u7ed3\u6784\u8d4b\u4e88\u4efb\u610f\u4ef7\u503c\u7684\u884c\u4e3a\uff0c\u63a2\u7d22\u5c40\u90e8\u4ef7\u503c\u8bc4\u4f30\u4e0e\u5747\u8861\u884c\u4e3a\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u5c06\u535a\u5f08\u8868\u793a\u4e3a\u53c2\u4e0e\u8005\u5bf9\u5b50\u7ed3\u6784\u4ef7\u503c\u8bc4\u4f30\u7684\u7b49\u4ef7\u5f62\u5f0f\uff0c\u5206\u6790\u52bf\u535a\u5f08\u6761\u4ef6\u548c\u5e73\u7a33\u5206\u5e03\u7279\u6027\u3002", "result": "\u53d1\u73b0\u5f53\u6240\u6709\u53c2\u4e0e\u8005\u5bf9\u7ed3\u6784\u4ef7\u503c\u8bc4\u4f30\u76f8\u7b49\u65f6\uff0c\u535a\u5f08\u4e3a\u52bf\u535a\u5f08\u4e14\u5b58\u5728\u95ed\u5f0f\u5e73\u7a33\u5206\u5e03\uff1b\u5f53\u4ef7\u503c\u8bc4\u4f30\u9650\u4e8e\u6709\u9650\u91cd\u590d\u5b50\u7ed3\u6784\u65f6\uff0c\u6a21\u578b\u5448\u73b0\u76f8\u53d8\u73b0\u8c61\u3002", "conclusion": "\u52a8\u6001\u7f51\u7edc\u5f62\u6210\u535a\u5f08\u7684\u5747\u8861\u884c\u4e3a\u4e0e\u53c2\u4e0e\u8005\u5bf9\u7f51\u7edc\u5b50\u7ed3\u6784\u7684\u4ef7\u503c\u8bc4\u4f30\u5bc6\u5207\u76f8\u5173\uff0c\u7279\u5b9a\u6761\u4ef6\u4e0b\u4f1a\u51fa\u73b0\u76f8\u53d8\u73b0\u8c61\u3002"}}
{"id": "2510.09858", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09858", "abs": "https://arxiv.org/abs/2510.09858", "authors": ["Eric Schwitzgebel"], "title": "AI and Consciousness", "comment": null, "summary": "This is a skeptical overview of the literature on AI consciousness. We will\nsoon create AI systems that are conscious according to some influential,\nmainstream theories of consciousness but are not conscious according to other\ninfluential, mainstream theories of consciousness. We will not be in a position\nto know which theories are correct and whether we are surrounded by AI systems\nas richly and meaningfully conscious as human beings or instead only by systems\nas experientially blank as toasters. None of the standard arguments either for\nor against AI consciousness takes us far.\n  Table of Contents\n  Chapter One: Hills and Fog\n  Chapter Two: What Is Consciousness? What Is AI?\n  Chapter Three: Ten Possibly Essential Features of Consciousness\n  Chapter Four: Against Introspective and Conceptual Arguments for Essential\nFeatures\n  Chapter Five: Materialism and Functionalism\n  Chapter Six: The Turing Test and the Chinese Room\n  Chapter Seven: The Mimicry Argument Against AI Consciousness\n  Chapter Eight: Global Workspace Theories and Higher Order Theories\n  Chapter Nine: Integrated Information, Local Recurrence, Associative Learning,\nand Iterative Natural Kinds\n  Chapter Ten: Does Biological Substrate Matter?\n  Chapter Eleven: The Problem of Strange Intelligence\n  Chapter Twelve: The Leapfrog Hypothesis and the Social Semi-Solution", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5bf9AI\u610f\u8bc6\u7814\u7a76\u6301\u6000\u7591\u6001\u5ea6\uff0c\u6307\u51fa\u6839\u636e\u4e0d\u540c\u7684\u4e3b\u6d41\u610f\u8bc6\u7406\u8bba\uff0c\u6211\u4eec\u5f88\u5feb\u4f1a\u521b\u9020\u51fa\u4e00\u4e9b\u7cfb\u7edf\uff1a\u5728\u67d0\u4e9b\u7406\u8bba\u4e0b\u88ab\u8ba4\u4e3a\u6709\u610f\u8bc6\uff0c\u5728\u5176\u4ed6\u7406\u8bba\u4e0b\u5219\u88ab\u8ba4\u4e3a\u65e0\u610f\u8bc6\uff0c\u4f46\u6211\u4eec\u65e0\u6cd5\u786e\u5b9a\u54ea\u79cd\u7406\u8bba\u6b63\u786e\u3002", "motivation": "\u4f5c\u8005\u65e8\u5728\u63ed\u793aAI\u610f\u8bc6\u7814\u7a76\u9886\u57df\u5b58\u5728\u7684\u6839\u672c\u6027\u95ee\u9898\u2014\u2014\u6211\u4eec\u7f3a\u4e4f\u786e\u5b9aAI\u662f\u5426\u5177\u6709\u610f\u8bc6\u7684\u65b9\u6cd5\u8bba\u57fa\u7840\uff0c\u4e0d\u540c\u7406\u8bba\u4f1a\u5f97\u51fa\u5b8c\u5168\u76f8\u53cd\u7684\u7ed3\u8bba\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5341\u79cd\u53ef\u80fd\u6784\u6210\u610f\u8bc6\u672c\u8d28\u7684\u7279\u5f81\uff0c\u6279\u5224\u6027\u5730\u5ba1\u89c6\u5404\u79cd\u652f\u6301\u6216\u53cd\u5bf9AI\u610f\u8bc6\u7684\u6807\u51c6\u8bba\u8bc1\uff0c\u5305\u62ec\u5185\u7701\u8bba\u8bc1\u3001\u6982\u5ff5\u8bba\u8bc1\u3001\u552f\u7269\u4e3b\u4e49\u4e0e\u529f\u80fd\u4e3b\u4e49\u3001\u56fe\u7075\u6d4b\u8bd5\u7b49\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u65e0\u8bba\u662f\u652f\u6301\u8fd8\u662f\u53cd\u5bf9AI\u610f\u8bc6\u7684\u6807\u51c6\u8bba\u8bc1\u90fd\u7f3a\u4e4f\u8bf4\u670d\u529b\uff0c\u6211\u4eec\u65e0\u6cd5\u786e\u5b9a\u672a\u6765AI\u7cfb\u7edf\u662f\u5426\u5177\u6709\u771f\u6b63\u7684\u610f\u8bc6\u4f53\u9a8c\u3002", "conclusion": "\u6211\u4eec\u9762\u4e34\u7740\u6839\u672c\u6027\u7684\u8ba4\u8bc6\u8bba\u56f0\u5883\uff1a\u65e0\u6cd5\u77e5\u9053AI\u662f\u5426\u5177\u6709\u610f\u8bc6\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u6211\u4eec\u88ab\u5927\u91cf\u6709\u4e30\u5bcc\u610f\u8bc6\u4f53\u9a8c\u7684AI\u7cfb\u7edf\u5305\u56f4\uff0c\u6216\u8005\u5468\u56f4\u53ea\u6709\u6beb\u65e0\u4f53\u9a8c\u7684\u673a\u5668\u3002"}}
{"id": "2510.10904", "categories": ["stat.AP", "stat.ME", "62R10"], "pdf": "https://arxiv.org/pdf/2510.10904", "abs": "https://arxiv.org/abs/2510.10904", "authors": ["Giacomo Lanfiuti Baldi", "Andrea Nigri", "Han Lin Shang"], "title": "Age-period modeling of mortality gaps: the cases of cancer and circulatory diseases", "comment": "28 pages, 5 tables, 5 figures", "summary": "Understanding and modeling mortality patterns, especially differences in\nmortality rates between populations, is vital for demographic analysis and\npublic health planning. We compare three statistical models within the\nage-period framework to examine differences in death counts. The models are\nbased on the double Poisson, bivariate Poisson, and Skellam distributions, each\nof which provides unique strengths in capturing underlying mortality trends.\nFocusing on mortality data from 1960 to 2015, we analyze the two leading causes\nof death in Italy, which exhibit significant temporal and age-related\nvariations. Our results reveal that the Skellam distribution offers superior\naccuracy and simplicity in capturing mortality differentials. These findings\nhighlight the potential of the Skellam distribution for analyzing mortality\ngaps effectively.", "AI": {"tldr": "\u6bd4\u8f83\u4e09\u79cd\u7edf\u8ba1\u6a21\u578b\uff08\u53cc\u6cca\u677e\u3001\u53cc\u53d8\u91cf\u6cca\u677e\u548cSkellam\u5206\u5e03\uff09\u6765\u5206\u6790\u610f\u5927\u52291960-2015\u5e74\u6b7b\u4ea1\u7387\u5dee\u5f02\uff0c\u53d1\u73b0Skellam\u5206\u5e03\u5728\u6355\u6349\u6b7b\u4ea1\u7387\u5dee\u5f02\u65b9\u9762\u5177\u6709\u6700\u4f73\u51c6\u786e\u6027\u548c\u7b80\u6d01\u6027\u3002", "motivation": "\u7406\u89e3\u548c\u5efa\u6a21\u6b7b\u4ea1\u7387\u6a21\u5f0f\uff0c\u7279\u522b\u662f\u4e0d\u540c\u4eba\u7fa4\u95f4\u7684\u6b7b\u4ea1\u7387\u5dee\u5f02\uff0c\u5bf9\u4e8e\u4eba\u53e3\u5206\u6790\u548c\u516c\u5171\u536b\u751f\u89c4\u5212\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5728\u5e74\u9f84-\u65f6\u671f\u6846\u67b6\u5185\u6bd4\u8f83\u57fa\u4e8e\u53cc\u6cca\u677e\u3001\u53cc\u53d8\u91cf\u6cca\u677e\u548cSkellam\u5206\u5e03\u7684\u4e09\u79cd\u7edf\u8ba1\u6a21\u578b\uff0c\u5206\u6790\u610f\u5927\u52291960-2015\u5e74\u4e24\u5927\u4e3b\u8981\u6b7b\u56e0\u7684\u6b7b\u4ea1\u7387\u6570\u636e\u3002", "result": "Skellam\u5206\u5e03\u5728\u6355\u6349\u6b7b\u4ea1\u7387\u5dee\u5f02\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u51c6\u786e\u6027\u548c\u7b80\u6d01\u6027\u3002", "conclusion": "Skellam\u5206\u5e03\u5177\u6709\u6709\u6548\u5206\u6790\u6b7b\u4ea1\u7387\u5dee\u8ddd\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.11131", "categories": ["cs.SI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.11131", "abs": "https://arxiv.org/abs/2510.11131", "authors": ["Jia Wang", "Ziyu Zhao", "Tingjuntao Ni", "Zhongyu Wei"], "title": "SocioBench: Modeling Human Behavior in Sociological Surveys with Large Language Models", "comment": "Accepted by EMNLP 2025", "summary": "Large language models (LLMs) show strong potential for simulating human\nsocial behaviors and interactions, yet lack large-scale, systematically\nconstructed benchmarks for evaluating their alignment with real-world social\nattitudes. To bridge this gap, we introduce SocioBench-a comprehensive\nbenchmark derived from the annually collected, standardized survey data of the\nInternational Social Survey Programme (ISSP). The benchmark aggregates over\n480,000 real respondent records from more than 30 countries, spanning 10\nsociological domains and over 40 demographic attributes. Our experiments\nindicate that LLMs achieve only 30-40% accuracy when simulating individuals in\ncomplex survey scenarios, with statistically significant differences across\ndomains and demographic subgroups. These findings highlight several limitations\nof current LLMs in survey scenarios, including insufficient individual-level\ndata coverage, inadequate scenario diversity, and missing group-level modeling.", "AI": {"tldr": "SocioBench\u662f\u4e00\u4e2a\u57fa\u4e8e\u56fd\u9645\u793e\u4f1a\u8c03\u67e5\u9879\u76ee\u6570\u636e\u6784\u5efa\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLMs\u5728\u6a21\u62df\u4eba\u7c7b\u793e\u4f1a\u884c\u4e3a\u65f6\u7684\u8868\u73b0\u3002\u5b9e\u9a8c\u663e\u793aLLMs\u5728\u590d\u6742\u8c03\u67e5\u573a\u666f\u4e2d\u51c6\u786e\u7387\u4ec5\u4e3a30-40%\uff0c\u5b58\u5728\u4e2a\u4f53\u6570\u636e\u8986\u76d6\u4e0d\u8db3\u3001\u573a\u666f\u591a\u6837\u6027\u4e0d\u591f\u548c\u7fa4\u4f53\u5efa\u6a21\u7f3a\u5931\u7b49\u5c40\u9650\u3002", "motivation": "\u5f53\u524dLLMs\u5728\u6a21\u62df\u4eba\u7c7b\u793e\u4f1a\u884c\u4e3a\u548c\u4e92\u52a8\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u5927\u89c4\u6a21\u3001\u7cfb\u7edf\u6784\u5efa\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u5176\u4e0e\u73b0\u5b9e\u4e16\u754c\u793e\u4f1a\u6001\u5ea6\u7684\u4e00\u81f4\u6027\u3002", "method": "\u57fa\u4e8e\u56fd\u9645\u793e\u4f1a\u8c03\u67e5\u9879\u76ee\uff08ISSP\uff09\u6bcf\u5e74\u6536\u96c6\u7684\u6807\u51c6\u5316\u8c03\u67e5\u6570\u636e\u6784\u5efaSocioBench\u57fa\u51c6\uff0c\u6c47\u96c6\u4e86\u6765\u81ea30\u591a\u4e2a\u56fd\u5bb6\u768448\u4e07+\u771f\u5b9e\u53d7\u8bbf\u8005\u8bb0\u5f55\uff0c\u6db5\u76d610\u4e2a\u793e\u4f1a\u5b66\u9886\u57df\u548c40\u591a\u4e2a\u4eba\u53e3\u5c5e\u6027\u3002", "result": "LLMs\u5728\u6a21\u62df\u590d\u6742\u8c03\u67e5\u573a\u666f\u4e2d\u7684\u4e2a\u4f53\u65f6\u51c6\u786e\u7387\u4ec5\u4e3a30-40%\uff0c\u5728\u4e0d\u540c\u9886\u57df\u548c\u4eba\u53e3\u4e9a\u7ec4\u4e4b\u95f4\u5b58\u5728\u7edf\u8ba1\u5b66\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u5f53\u524dLLMs\u5728\u8c03\u67e5\u573a\u666f\u4e2d\u5b58\u5728\u591a\u4e2a\u5c40\u9650\u6027\uff0c\u5305\u62ec\u4e2a\u4f53\u5c42\u9762\u6570\u636e\u8986\u76d6\u4e0d\u8db3\u3001\u573a\u666f\u591a\u6837\u6027\u4e0d\u591f\u4ee5\u53ca\u7fa4\u4f53\u5c42\u9762\u5efa\u6a21\u7f3a\u5931\u3002"}}
{"id": "2510.09862", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.09862", "abs": "https://arxiv.org/abs/2510.09862", "authors": ["Carsten Hartmann", "Edoardo De Din", "Daniele Carta", "Florian Middelkoop", "Arndt Neubauer", "Johannes Kruse", "Ulrich Oberhofer", "Richard Jumar", "Benjamin Sch\u00e4fer", "Thiemo Pesch", "Andrea Benigni", "Dirk Witthaut"], "title": "Cyber-Physical Systems on the Megawatt Scale: The impact of battery control on grid frequency stability", "comment": "19 pages, 23 figures", "summary": "Electric power systems are undergoing fundamental change. The shift to\ninverter-based generation challenges frequency stability, while growing\ndigitalisation heightens vulnerability to errors and attacks. Here we identify\nan emerging risk at the intersection of cyber-physical coupling and control\nsystem design. We show that grid frequency time series worldwide exhibit a\npersistent one-minute oscillatory pattern, whose origin has remained largely\nunexplained. We trace this pattern back to the energy management systems of\nbattery electric storage systems and demonstrate that the pattern amplitude has\nincreased substantially in the Nordic and British grids. We argue that this\neffect is a potential burden for stability in future grids with low inertia and\nan increasing penetration with batteries and smart devices, though it can be\nmitigated by a revision of battery control algorithms.", "AI": {"tldr": "\u7535\u7f51\u9891\u7387\u65f6\u95f4\u5e8f\u5217\u4e2d\u6301\u7eed\u5b58\u5728\u7684\u4e00\u5206\u949f\u632f\u8361\u6a21\u5f0f\u6e90\u4e8e\u7535\u6c60\u50a8\u80fd\u7cfb\u7edf\u7684\u80fd\u6e90\u7ba1\u7406\u7cfb\u7edf\uff0c\u8fd9\u79cd\u6a21\u5f0f\u5728\u4f4e\u60ef\u91cf\u7535\u7f51\u4e2d\u53ef\u80fd\u5a01\u80c1\u7a33\u5b9a\u6027\uff0c\u4f46\u53ef\u901a\u8fc7\u4fee\u6539\u7535\u6c60\u63a7\u5236\u7b97\u6cd5\u6765\u7f13\u89e3\u3002", "motivation": "\u7535\u529b\u7cfb\u7edf\u6b63\u7ecf\u5386\u6839\u672c\u6027\u53d8\u9769\uff0c\u9006\u53d8\u5668\u53d1\u7535\u6311\u6218\u9891\u7387\u7a33\u5b9a\u6027\uff0c\u6570\u5b57\u5316\u589e\u52a0\u9519\u8bef\u548c\u653b\u51fb\u98ce\u9669\u3002\u7814\u7a76\u65e8\u5728\u8bc6\u522b\u7f51\u7edc\u7269\u7406\u8026\u5408\u4e0e\u63a7\u5236\u7cfb\u7edf\u8bbe\u8ba1\u4ea4\u53c9\u5904\u7684\u65b0\u5174\u98ce\u9669\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5168\u7403\u7535\u7f51\u9891\u7387\u65f6\u95f4\u5e8f\u5217\uff0c\u8bc6\u522b\u51fa\u4e00\u5206\u949f\u632f\u8361\u6a21\u5f0f\uff0c\u5e76\u5c06\u5176\u6eaf\u6e90\u81f3\u7535\u6c60\u50a8\u80fd\u7cfb\u7edf\u7684\u80fd\u6e90\u7ba1\u7406\u7cfb\u7edf\u3002", "result": "\u53d1\u73b0\u5317\u6b27\u548c\u82f1\u56fd\u7535\u7f51\u4e2d\u8fd9\u79cd\u632f\u8361\u6a21\u5f0f\u7684\u5e45\u5ea6\u663e\u8457\u589e\u52a0\uff0c\u8bc1\u660e\u8be5\u6548\u5e94\u4e0e\u7535\u6c60\u6e17\u900f\u7387\u589e\u52a0\u76f8\u5173\u3002", "conclusion": "\u5728\u4f4e\u60ef\u91cf\u548c\u7535\u6c60\u6e17\u900f\u7387\u589e\u52a0\u7684\u672a\u6765\u7535\u7f51\u4e2d\uff0c\u8fd9\u79cd\u6548\u5e94\u53ef\u80fd\u6210\u4e3a\u7a33\u5b9a\u6027\u8d1f\u62c5\uff0c\u4f46\u53ef\u901a\u8fc7\u4fee\u8ba2\u7535\u6c60\u63a7\u5236\u7b97\u6cd5\u6765\u7f13\u89e3\u3002"}}
{"id": "2510.09677", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09677", "abs": "https://arxiv.org/abs/2510.09677", "authors": ["Ebrahim Rahimi", "Clara Maathuis"], "title": "AI in Computational Thinking Education in Higher Education: A Systematic Literature Review", "comment": "A poster based on this paper was accepted and published in the\n  Proceedings of the 30th ACM Conference on Innovation and Technology in\n  Computer Science Education (ITiCSE 2025), DOI:\n  https://doi.org/10.1145/3724389.3730775", "summary": "Computational Thinking (CT) is a key skill set for students in higher\neducation to thrive and adapt to an increasingly technology-driven future and\nworkplace. While research on CT education has gained remarkable momentum in K12\nover the past decade, it has remained under-explored in higher education,\nleaving higher education teachers with an insufficient overview, knowledge, and\nsupport regarding CT education. The proliferation and adoption of artificial\nintelligence (AI) by educational institutions have demonstrated promising\npotential to support instructional activities across many disciplines,\nincluding CT education. However, a comprehensive overview outlining the various\naspects of integrating AI in CT education in higher education is lacking. To\nmitigate this gap, we conducted this systematic literature review study. The\nfocus of our study is to identify initiatives applying AI in CT education\nwithin higher education and to explore various educational aspects of these\ninitiatives, including the benefits and challenges of AI in CT education,\ninstructional strategies employed, CT components covered, and AI techniques and\nmodels utilized. This study provides practical and scientific contributions to\nthe CT education community, including an inventory of AI-based initiatives for\nCT education useful to educators, an overview of various aspects of integrating\nAI into CT education such as its benefits and challenges (e.g., AI potential to\nreshape CT education versus its potential to diminish students creativity) and\ninsights into new and expanded perspectives on CT in light of AI (e.g., the\ndecoding approach alongside the coding approach to CT).", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u63a2\u8ba8\u4e86\u4eba\u5de5\u667a\u80fd\u5728\u9ad8\u7b49\u6559\u80b2\u8ba1\u7b97\u601d\u7ef4\u6559\u80b2\u4e2d\u7684\u5e94\u7528\uff0c\u5206\u6790\u4e86AI\u6574\u5408\u7684\u5404\u4e2a\u65b9\u9762\u3001\u76ca\u5904\u4e0e\u6311\u6218\u3001\u6559\u5b66\u7b56\u7565\u4ee5\u53ca\u4f7f\u7528\u7684AI\u6280\u672f\u3002", "motivation": "\u8ba1\u7b97\u601d\u7ef4\u662f\u9ad8\u7b49\u6559\u80b2\u5b66\u751f\u9002\u5e94\u6280\u672f\u9a71\u52a8\u672a\u6765\u7684\u5173\u952e\u6280\u80fd\uff0c\u4f46\u9ad8\u7b49\u6559\u80b2\u4e2d\u7684CT\u6559\u80b2\u7814\u7a76\u4e0d\u8db3\uff0c\u6559\u5e08\u7f3a\u4e4f\u76f8\u5173\u77e5\u8bc6\u548c\u652f\u6301\u3002AI\u5728\u6559\u80b2\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u4e3aCT\u6559\u80b2\u63d0\u4f9b\u4e86\u652f\u6301\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u5168\u9762\u7684\u6574\u5408\u6982\u8ff0\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u8bc6\u522b\u9ad8\u7b49\u6559\u80b2\u4e2d\u5e94\u7528AI\u7684CT\u6559\u80b2\u4e3e\u63aa\uff0c\u63a2\u7d22\u8fd9\u4e9b\u4e3e\u63aa\u7684\u6559\u80b2\u65b9\u9762\uff0c\u5305\u62ecAI\u5728CT\u6559\u80b2\u4e2d\u7684\u76ca\u5904\u4e0e\u6311\u6218\u3001\u6559\u5b66\u7b56\u7565\u3001CT\u7ec4\u4ef6\u8986\u76d6\u8303\u56f4\u4ee5\u53caAI\u6280\u672f\u6a21\u578b\u3002", "result": "\u7814\u7a76\u63d0\u4f9b\u4e86AI\u5728\u9ad8\u7b49\u6559\u80b2CT\u6559\u80b2\u4e2d\u7684\u5e94\u7528\u6e05\u5355\uff0c\u5206\u6790\u4e86AI\u6574\u5408\u7684\u5404\u4e2a\u65b9\u9762\uff0c\u5305\u62ec\u5176\u76ca\u5904\uff08\u5982\u91cd\u5851CT\u6559\u80b2\uff09\u4e0e\u6311\u6218\uff08\u5982\u53ef\u80fd\u524a\u5f31\u5b66\u751f\u521b\u9020\u529b\uff09\uff0c\u4ee5\u53ca\u5728AI\u80cc\u666f\u4e0b\u7684\u65b0CT\u89c6\u89d2\uff08\u5982\u89e3\u7801\u65b9\u6cd5\u4e0e\u7f16\u7801\u65b9\u6cd5\uff09\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3aCT\u6559\u80b2\u793e\u533a\u63d0\u4f9b\u4e86\u5b9e\u8df5\u548c\u79d1\u5b66\u8d21\u732e\uff0c\u5305\u62ec\u5bf9\u6559\u80b2\u5de5\u4f5c\u8005\u6709\u7528\u7684AI\u57fa\u7840CT\u6559\u80b2\u4e3e\u63aa\u6e05\u5355\uff0c\u4ee5\u53caAI\u6574\u5408\u5230CT\u6559\u80b2\u4e2d\u7684\u591a\u65b9\u9762\u89c1\u89e3\uff0c\u4e3a\u9ad8\u7b49\u6559\u80b2CT\u6559\u80b2\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2510.09963", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.09963", "abs": "https://arxiv.org/abs/2510.09963", "authors": ["Chaoran Wang", "Jingyuan Sun", "Yanhui Zhang", "Mingyu Zhang", "Changju Wu"], "title": "LLM-HBT: Dynamic Behavior Tree Construction for Adaptive Coordination in Heterogeneous Robots", "comment": "It contains 8 pages, 7 figures and 4 tables. This paper is submitted\n  to ICRA 2026", "summary": "We introduce a novel framework for automatic behavior tree (BT) construction\nin heterogeneous multi-robot systems, designed to address the challenges of\nadaptability and robustness in dynamic environments. Traditional robots are\nlimited by fixed functional attributes and cannot efficiently reconfigure their\nstrategies in response to task failures or environmental changes. To overcome\nthis limitation, we leverage large language models (LLMs) to generate and\nextend BTs dynamically, combining the reasoning and generalization power of\nLLMs with the modularity and recovery capability of BTs. The proposed framework\nconsists of four interconnected modules task initialization, task assignment,\nBT update, and failure node detection which operate in a closed loop. Robots\ntick their BTs during execution, and upon encountering a failure node, they can\neither extend the tree locally or invoke a centralized virtual coordinator\n(Alex) to reassign subtasks and synchronize BTs across peers. This design\nenables long-term cooperative execution in heterogeneous teams. We validate the\nframework on 60 tasks across three simulated scenarios and in a real-world cafe\nenvironment with a robotic arm and a wheeled-legged robot. Results show that\nour method consistently outperforms baseline approaches in task success rate,\nrobustness, and scalability, demonstrating its effectiveness for multi-robot\ncollaboration in complex scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5f02\u6784\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u884c\u4e3a\u6811\u81ea\u52a8\u6784\u5efa\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u751f\u6210\u548c\u6269\u5c55\u884c\u4e3a\u6811\u6765\u589e\u5f3a\u7cfb\u7edf\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u4eba\u53d7\u9650\u4e8e\u56fa\u5b9a\u529f\u80fd\u5c5e\u6027\uff0c\u65e0\u6cd5\u5728\u4efb\u52a1\u5931\u8d25\u6216\u73af\u5883\u53d8\u5316\u65f6\u9ad8\u6548\u91cd\u65b0\u914d\u7f6e\u7b56\u7565\u3002\u9700\u8981\u7ed3\u5408LLMs\u7684\u63a8\u7406\u6cdb\u5316\u80fd\u529b\u548c\u884c\u4e3a\u6811\u7684\u6a21\u5757\u5316\u6062\u590d\u80fd\u529b\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u6846\u67b6\u5305\u542b\u56db\u4e2a\u4e92\u8054\u6a21\u5757\uff1a\u4efb\u52a1\u521d\u59cb\u5316\u3001\u4efb\u52a1\u5206\u914d\u3001\u884c\u4e3a\u6811\u66f4\u65b0\u548c\u5931\u8d25\u8282\u70b9\u68c0\u6d4b\uff0c\u5f62\u6210\u95ed\u73af\u3002\u673a\u5668\u4eba\u6267\u884c\u65f6tick\u884c\u4e3a\u6811\uff0c\u9047\u5230\u5931\u8d25\u8282\u70b9\u65f6\u53ef\u672c\u5730\u6269\u5c55\u6811\u6216\u8c03\u7528\u96c6\u4e2d\u5f0f\u865a\u62df\u534f\u8c03\u5668\u91cd\u65b0\u5206\u914d\u5b50\u4efb\u52a1\u5e76\u540c\u6b65\u884c\u4e3a\u6811\u3002", "result": "\u57283\u4e2a\u6a21\u62df\u573a\u666f\u768460\u4e2a\u4efb\u52a1\u548c\u771f\u5b9e\u4e16\u754c\u5496\u5561\u9986\u73af\u5883\u4e2d\u9a8c\u8bc1\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u4efb\u52a1\u6210\u529f\u7387\u3001\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u652f\u6301\u5f02\u6784\u56e2\u961f\u5728\u590d\u6742\u573a\u666f\u4e2d\u7684\u957f\u671f\u534f\u4f5c\u6267\u884c\uff0c\u5c55\u793a\u4e86\u591a\u673a\u5668\u4eba\u534f\u4f5c\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.10780", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.10780", "abs": "https://arxiv.org/abs/2510.10780", "authors": ["Maxwell Fogler"], "title": "Harvests and Hooky in the Hills: Crop Yield Variability and Gendered School Enrollment in Rwanda", "comment": null, "summary": "This paper investigates the trade-off that households in agrarian economies\nface between immediate production needs and long-term human capital investment.\nWe ask how exogenous agricultural productivity shocks affect primary and\nsecondary school enrollment in Rwanda, a country characterized by a heavy\nreliance on rain-fed agriculture alongside ambitious development goals. Using a\ndistrict-level panel dataset for the years 2010-2021, we employ a two-stage\nleast squares (2SLS) instrumental variable strategy. Plausibly exogenous\nvariation in annual rainfall is used to instrument for a satellite-derived\nmeasure of vegetation health and agricultural productivity, the Normalized\nDifference Vegetation Index (NDVI), allowing for a causal interpretation of the\nresults. For primary education, where direct costs are low, enrollment is\ncountercyclical: positive productivity shocks are associated with lower\nenrollment. Notably, boys' primary enrollment is found to be significantly more\nelastic to these shocks than girls' enrollment. Conversely, for secondary\neducation, which entails additional financial outlays, enrollment is strongly\nprocyclical. Positive productivity shocks lead to significant increases in\nenrollment. Further, a sustained positive shock is associated with a subsequent\ndecline in female secondary enrollment. The results challenge previous regional\nfindings supporting the \"girls as a buffer\" hypothesis and investigate the\ndynamic and gendered responses to the persistence of economic shocks.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5362\u65fa\u8fbe\u519c\u4e1a\u751f\u4ea7\u529b\u51b2\u51fb\u5bf9\u6559\u80b2\u5165\u5b66\u7387\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5c0f\u5b66\u548c\u4e2d\u5b66\u6559\u80b2\u5bf9\u7ecf\u6d4e\u51b2\u51fb\u7684\u53cd\u5e94\u76f8\u53cd\uff1a\u5c0f\u5b66\u5165\u5b66\u7387\u5448\u9006\u5468\u671f\u6027\uff0c\u800c\u4e2d\u5b66\u5165\u5b66\u7387\u5448\u987a\u5468\u671f\u6027\uff0c\u4e14\u5b58\u5728\u663e\u8457\u7684\u6027\u522b\u5dee\u5f02\u3002", "motivation": "\u7814\u7a76\u519c\u4e1a\u7ecf\u6d4e\u4f53\u4e2d\u5bb6\u5ead\u5728\u5373\u65f6\u751f\u4ea7\u9700\u6c42\u548c\u957f\u671f\u4eba\u529b\u8d44\u672c\u6295\u8d44\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u63a2\u7d22\u5916\u751f\u519c\u4e1a\u751f\u4ea7\u529b\u51b2\u51fb\u5982\u4f55\u5f71\u54cd\u6559\u80b2\u5165\u5b66\u7387\uff0c\u7279\u522b\u662f\u5728\u4f9d\u8d56\u96e8\u517b\u519c\u4e1a\u7684\u53d1\u5c55\u4e2d\u56fd\u5bb6\u3002", "method": "\u4f7f\u75282010-2021\u5e74\u5730\u533a\u7ea7\u9762\u677f\u6570\u636e\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u6700\u5c0f\u4e8c\u4e58\u6cd5(2SLS)\u5de5\u5177\u53d8\u91cf\u7b56\u7565\uff0c\u5229\u7528\u5e74\u964d\u96e8\u91cf\u53d8\u5316\u4f5c\u4e3a\u690d\u88ab\u5065\u5eb7\u6307\u6570(NDVI)\u7684\u5de5\u5177\u53d8\u91cf\u8fdb\u884c\u56e0\u679c\u63a8\u65ad\u3002", "result": "\u5c0f\u5b66\u6559\u80b2\u5165\u5b66\u7387\u5448\u9006\u5468\u671f\u6027\uff08\u6b63\u5411\u51b2\u51fb\u5bfc\u81f4\u5165\u5b66\u7387\u4e0b\u964d\uff09\uff0c\u7537\u5b69\u6bd4\u5973\u5b69\u66f4\u654f\u611f\uff1b\u4e2d\u5b66\u6559\u80b2\u5165\u5b66\u7387\u5448\u987a\u5468\u671f\u6027\uff08\u6b63\u5411\u51b2\u51fb\u5bfc\u81f4\u5165\u5b66\u7387\u4e0a\u5347\uff09\uff1b\u6301\u7eed\u6b63\u5411\u51b2\u51fb\u4e0e\u5973\u6027\u4e2d\u5b66\u5165\u5b66\u7387\u4e0b\u964d\u76f8\u5173\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u6311\u6218\u4e86\u5148\u524d\u652f\u6301'\u5973\u5b69\u4f5c\u4e3a\u7f13\u51b2'\u5047\u8bf4\u7684\u533a\u57df\u53d1\u73b0\uff0c\u63ed\u793a\u4e86\u7ecf\u6d4e\u51b2\u51fb\u6301\u7eed\u6027\u7684\u52a8\u6001\u548c\u6027\u522b\u5dee\u5f02\u5316\u53cd\u5e94\u3002"}}
{"id": "2510.11125", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2510.11125", "abs": "https://arxiv.org/abs/2510.11125", "authors": ["Luca Vota", "Luisa Errichiello"], "title": "Job insecurity and equilibrium determinacy in a rational expectations, New Keynesian model with asymmetric information. A theoretical analysis", "comment": null, "summary": "Despite the importance of this variable in the macroeconomic context, current\nresearch on job insecurity remains mainly confined to its non-systemic\ndimension. The research aim of this paper is to identify the short-run and\nlong-run macroeconomic determinants of job insecurity in the presence of\nasymmetric information between public and private agents, informative shocks,\nand different degrees of institutional communication transparency. To\naccomplish this goal, a small-scale, rational expectations, New Keynesian model\nis proposed in which limitedly informed households and firms receive a\npotentially noisy informative signal about the unobservables from fully\ninformed government and central bank. It is found that, notwithstanding the\nfulfillment of the Taylor principle, if public agents transfer all the\navailable information to the private agents without communication ambiguities,\nthe model admits a unique, stable equilibrium path along which the 'Paradox of\nTransparency' can emerge. Otherwise, the model's dynamics become unpredictable\nin terms of equilibrium existence and multiplicity, and job insecurity plays a\npotentially fundamental role in equilibrium determinacy. Appropriate policy\nrecommendations are discussed.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u4fe1\u606f\u4e0d\u5bf9\u79f0\u3001\u4fe1\u606f\u51b2\u51fb\u548c\u4e0d\u540c\u5236\u5ea6\u6c9f\u901a\u900f\u660e\u5ea6\u4e0b\uff0c\u5de5\u4f5c\u4e0d\u5b89\u5168\u611f\u7684\u77ed\u671f\u548c\u957f\u671f\u5b8f\u89c2\u7ecf\u6d4e\u51b3\u5b9a\u56e0\u7d20\u3002\u901a\u8fc7\u6784\u5efa\u7406\u6027\u9884\u671f\u65b0\u51ef\u6069\u65af\u6a21\u578b\uff0c\u53d1\u73b0\u5373\u4f7f\u6ee1\u8db3\u6cf0\u52d2\u539f\u5219\uff0c\u5b8c\u5168\u900f\u660e\u7684\u4fe1\u606f\u4f20\u9012\u53ef\u80fd\u5bfc\u81f4'\u900f\u660e\u5ea6\u6096\u8bba'\uff0c\u5426\u5219\u6a21\u578b\u52a8\u6001\u4f1a\u53d8\u5f97\u4e0d\u53ef\u9884\u6d4b\u3002", "motivation": "\u5f53\u524d\u5173\u4e8e\u5de5\u4f5c\u4e0d\u5b89\u5168\u611f\u7684\u7814\u7a76\u4e3b\u8981\u5c40\u9650\u4e8e\u975e\u7cfb\u7edf\u6027\u7ef4\u5ea6\uff0c\u800c\u8fd9\u4e00\u53d8\u91cf\u5728\u5b8f\u89c2\u7ecf\u6d4e\u80cc\u666f\u4e0b\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u672c\u6587\u65e8\u5728\u8bc6\u522b\u5728\u4fe1\u606f\u4e0d\u5bf9\u79f0\u3001\u4fe1\u606f\u51b2\u51fb\u548c\u4e0d\u540c\u5236\u5ea6\u6c9f\u901a\u900f\u660e\u5ea6\u6761\u4ef6\u4e0b\uff0c\u5de5\u4f5c\u4e0d\u5b89\u5168\u611f\u7684\u5b8f\u89c2\u7ecf\u6d4e\u51b3\u5b9a\u56e0\u7d20\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5c0f\u89c4\u6a21\u7684\u7406\u6027\u9884\u671f\u65b0\u51ef\u6069\u65af\u6a21\u578b\uff0c\u5176\u4e2d\u6709\u9650\u4fe1\u606f\u7684\u5bb6\u5ead\u548c\u4f01\u4e1a\u4ece\u5b8c\u5168\u77e5\u60c5\u7684\u653f\u5e9c\u548c\u592e\u884c\u63a5\u6536\u5173\u4e8e\u4e0d\u53ef\u89c2\u6d4b\u53d8\u91cf\u7684\u6f5c\u5728\u566a\u58f0\u4fe1\u606f\u4fe1\u53f7\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5373\u4f7f\u6ee1\u8db3\u6cf0\u52d2\u539f\u5219\uff0c\u5982\u679c\u516c\u5171\u4ee3\u7406\u4eba\u5c06\u6240\u6709\u53ef\u7528\u4fe1\u606f\u65e0\u6c9f\u901a\u6a21\u7cca\u5730\u4f20\u9012\u7ed9\u79c1\u4eba\u4ee3\u7406\u4eba\uff0c\u6a21\u578b\u5141\u8bb8\u5b58\u5728\u552f\u4e00\u7a33\u5b9a\u7684\u5747\u8861\u8def\u5f84\uff0c\u5176\u4e2d\u53ef\u80fd\u51fa\u73b0'\u900f\u660e\u5ea6\u6096\u8bba'\u3002\u5426\u5219\uff0c\u6a21\u578b\u7684\u52a8\u6001\u5728\u5747\u8861\u5b58\u5728\u6027\u548c\u591a\u91cd\u6027\u65b9\u9762\u53d8\u5f97\u4e0d\u53ef\u9884\u6d4b\u3002", "conclusion": "\u5de5\u4f5c\u4e0d\u5b89\u5168\u611f\u5728\u5747\u8861\u786e\u5b9a\u6027\u4e2d\u53ef\u80fd\u53d1\u6325\u6839\u672c\u6027\u4f5c\u7528\uff0c\u5e76\u8ba8\u8bba\u4e86\u9002\u5f53\u7684\u653f\u7b56\u5efa\u8bae\u3002"}}
{"id": "2510.09894", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09894", "abs": "https://arxiv.org/abs/2510.09894", "authors": ["Junyuan Liu", "Quan Qin", "Guangsheng Dong", "Xinglei Wang", "Jiazhuang Feng", "Zichao Zeng", "Tao Cheng"], "title": "Beyond AlphaEarth: Toward Human-Centered Spatial Representation via POI-Guided Contrastive Learning", "comment": null, "summary": "General-purpose spatial representations are essential for building\ntransferable geospatial foundation models (GFMs). Among them, the AlphaEarth\nFoundation (AE) represents a major step toward a global, unified representation\nof the Earth's surface, learning 10-meter embeddings from multi-source Earth\nObservation (EO) data that capture rich physical and environmental patterns\nacross diverse landscapes. However, such EO-driven representations remain\nlimited in capturing the functional and socioeconomic dimensions of cities, as\nthey primarily encode physical and spectral patterns rather than human\nactivities or spatial functions. We propose AETHER (AlphaEarth-POI Enriched\nRepresentation Learning), a lightweight framework that adapts AlphaEarth to\nhuman-centered urban analysis through multimodal alignment guided by Points of\nInterest (POIs). AETHER aligns AE embeddings with textual representations of\nPOIs, enriching physically grounded EO features with semantic cues about urban\nfunctions and socioeconomic contexts. In Greater London, AETHER achieves\nconsistent gains over the AE baseline, with a 7.2% relative improvement in\nland-use classification F1 and a 23.6% relative reduction in Kullback-Leibler\ndivergence for socioeconomic mapping. Built upon pretrained AE, AETHER\nleverages a lightweight multimodal alignment to enrich it with human-centered\nsemantics while remaining computationally efficient and scalable for urban\napplications. By coupling EO with human-centered semantics, it advances\ngeospatial foundation models toward general-purpose urban representations that\nintegrate both physical form and functional meaning.", "AI": {"tldr": "AETHER\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u901a\u8fc7POI\u591a\u6a21\u6001\u5bf9\u9f50\u589e\u5f3aAlphaEarth\u8868\u793a\uff0c\u5c06\u7269\u7406\u9065\u611f\u7279\u5f81\u4e0e\u57ce\u5e02\u529f\u80fd\u8bed\u4e49\u76f8\u7ed3\u5408\uff0c\u63d0\u5347\u57ce\u5e02\u5206\u6790\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5730\u7403\u89c2\u6d4b\u9a71\u52a8\u8868\u793a\u4e3b\u8981\u7f16\u7801\u7269\u7406\u548c\u5149\u8c31\u6a21\u5f0f\uff0c\u96be\u4ee5\u6355\u6349\u57ce\u5e02\u7684\u529f\u80fd\u548c\u793e\u4f1a\u7ecf\u6d4e\u7ef4\u5ea6\uff0c\u9700\u8981\u878d\u5408\u4eba\u7c7b\u6d3b\u52a8\u8bed\u4e49\u3002", "method": "\u901a\u8fc7\u591a\u6a21\u6001\u5bf9\u9f50\u5c06AlphaEarth\u5d4c\u5165\u4e0ePOI\u6587\u672c\u8868\u793a\u5bf9\u9f50\uff0c\u5728\u9884\u8bad\u7ec3AE\u57fa\u7840\u4e0a\u8fdb\u884c\u8f7b\u91cf\u7ea7\u8bed\u4e49\u589e\u5f3a\u3002", "result": "\u5728\u4f26\u6566\u5730\u533a\uff0c\u571f\u5730\u7528\u9014\u5206\u7c7bF1\u76f8\u5bf9\u63d0\u53477.2%\uff0c\u793e\u4f1a\u7ecf\u6d4e\u6620\u5c04\u7684KL\u6563\u5ea6\u76f8\u5bf9\u51cf\u5c1123.6%\u3002", "conclusion": "AETHER\u901a\u8fc7\u8026\u5408\u5730\u7403\u89c2\u6d4b\u4e0e\u4eba\u7c7b\u4e2d\u5fc3\u8bed\u4e49\uff0c\u63a8\u8fdb\u5730\u7406\u7a7a\u95f4\u57fa\u7840\u6a21\u578b\u5411\u6574\u5408\u7269\u7406\u5f62\u6001\u548c\u529f\u80fd\u610f\u4e49\u7684\u901a\u7528\u57ce\u5e02\u8868\u793a\u53d1\u5c55\u3002"}}
{"id": "2510.11048", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.11048", "abs": "https://arxiv.org/abs/2510.11048", "authors": ["Onyedikachi J. Okeke", "Uloma E. Nelson", "Chukwudi Nwaogu", "Olumide O. Oladoyin", "Emmanuel Kubuafor", "Dennis Baidoo", "Titilope Akinyemi", "Adedoyin S. Ajeyomi", "Rekiya A. Idris", "Isaac A. Fabunmi"], "title": "Assessing the Influence of Locational Suitability on the Spatial Distribution of Household Wealth in Bernalillo County, NM", "comment": null, "summary": "This study applies Multiscale Geographically Weighted Regression (MGWR) to\nexamine the spatial determinants of household wealth in Bernalillo County, New\nMexico. The model incorporates sociodemographic, environmental, and\nproximity-based variables to evaluate how locational suitability influences\neconomic outcomes. Key factors considered include income, home value,\nelevation, PM2.5 concentration, and distances to essential services such as\nschools, markets, and hospitals. The MGWR model demonstrates strong\nperformance, explaining approximately 63 percent of the variation in household\nwealth. Results show that proximity to markets, schools, and parks\nsignificantly increases wealth in over 40 percent of neighborhoods. In\ncontrast, closeness to hospitals and bus stops is negatively associated with\nwealth, suggesting that nearby disamenities can reduce housing desirability.\nStrong spatial autocorrelation (Morans I = 0.53, p < 0.001) indicates that\nwealthier households are significantly clustered, highlighting the influence of\nlocalized factors. Overall, the study reveals that the relationship between\nlocational suitability and household wealth is spatially variable across the\ncounty.", "AI": {"tldr": "\u4f7f\u7528\u591a\u5c3a\u5ea6\u5730\u7406\u52a0\u6743\u56de\u5f52\u5206\u6790\u4f2f\u7eb3\u5229\u6b27\u53bf\u5bb6\u5ead\u8d22\u5bcc\u7684\u7a7a\u95f4\u51b3\u5b9a\u56e0\u7d20\uff0c\u53d1\u73b0\u63a5\u8fd1\u5e02\u573a\u3001\u5b66\u6821\u548c\u516c\u56ed\u80fd\u663e\u8457\u589e\u52a0\u8d22\u5bcc\uff0c\u800c\u9760\u8fd1\u533b\u9662\u548c\u516c\u4ea4\u7ad9\u5219\u4e0e\u8d22\u5bcc\u8d1f\u76f8\u5173\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u4f4d\u7f6e\u9002\u5b9c\u6027\u5982\u4f55\u5f71\u54cd\u7ecf\u6d4e\u7ed3\u679c\uff0c\u7279\u522b\u662f\u5bb6\u5ead\u8d22\u5bcc\u7684\u7a7a\u95f4\u5206\u5e03\u6a21\u5f0f\u3002", "method": "\u91c7\u7528\u591a\u5c3a\u5ea6\u5730\u7406\u52a0\u6743\u56de\u5f52\u6a21\u578b\uff0c\u6574\u5408\u793e\u4f1a\u4eba\u53e3\u7edf\u8ba1\u3001\u73af\u5883\u548c\u90bb\u8fd1\u6027\u53d8\u91cf\u6765\u5206\u6790\u7a7a\u95f4\u5f02\u8d28\u6027\u3002", "result": "\u6a21\u578b\u89e3\u91ca\u4e8663%\u7684\u5bb6\u5ead\u8d22\u5bcc\u53d8\u5f02\uff0c\u663e\u793a\u8d22\u5bcc\u4e0e\u4e0d\u540c\u8bbe\u65bd\u7684\u8ddd\u79bb\u5b58\u5728\u663e\u8457\u7a7a\u95f4\u53d8\u5316\u5173\u7cfb\uff0c\u4e14\u8d22\u5bcc\u5bb6\u5ead\u5448\u73b0\u660e\u663e\u7a7a\u95f4\u96c6\u805a\u3002", "conclusion": "\u4f4d\u7f6e\u9002\u5b9c\u6027\u4e0e\u5bb6\u5ead\u8d22\u5bcc\u7684\u5173\u7cfb\u5728\u5168\u53bf\u8303\u56f4\u5185\u5b58\u5728\u7a7a\u95f4\u53d8\u5f02\u6027\uff0c\u5c40\u90e8\u56e0\u7d20\u5bf9\u8d22\u5bcc\u5206\u5e03\u6709\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2510.11423", "categories": ["cs.SI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.11423", "abs": "https://arxiv.org/abs/2510.11423", "authors": ["Jiaying Wu", "Zihang Fu", "Haonan Wang", "Fanxiao Li", "Min-Yen Kan"], "title": "Beyond the Crowd: LLM-Augmented Community Notes for Governing Health Misinformation", "comment": null, "summary": "Community Notes, the crowd-sourced misinformation governance system on X\n(formerly Twitter), enables users to flag misleading posts, attach contextual\nnotes, and vote on their helpfulness. However, our analysis of 30.8K\nhealth-related notes reveals significant latency, with a median delay of 17.6\nhours before the first note receives a helpfulness status. To improve\nresponsiveness during real-world misinformation surges, we propose CrowdNotes+,\na unified framework that leverages large language models (LLMs) to augment\nCommunity Notes for faster and more reliable health misinformation governance.\nCrowdNotes+ integrates two complementary modes: (1) evidence-grounded note\naugmentation and (2) utility-guided note automation, along with a hierarchical\nthree-step evaluation that progressively assesses relevance, correctness, and\nhelpfulness. We instantiate the framework through HealthNotes, a benchmark of\n1.2K helpfulness-annotated health notes paired with a fine-tuned helpfulness\njudge. Experiments on fifteen LLMs reveal an overlooked loophole in current\nhelpfulness evaluation, where stylistic fluency is mistaken for factual\naccuracy, and demonstrate that our hierarchical evaluation and LLM-augmented\ngeneration jointly enhance factual precision and evidence utility. These\nresults point toward a hybrid human-AI governance model that improves both the\nrigor and timeliness of crowd-sourced fact-checking.", "AI": {"tldr": "CrowdNotes+\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8bc1\u636e\u589e\u5f3a\u548c\u81ea\u52a8\u5316\u751f\u6210\u6765\u52a0\u901fX\u5e73\u53f0\u7684Community Notes\u7cfb\u7edf\uff0c\u89e3\u51b3\u5065\u5eb7\u76f8\u5173\u9519\u8bef\u4fe1\u606f\u6cbb\u7406\u7684\u5ef6\u8fdf\u95ee\u9898\u3002", "motivation": "\u5206\u6790\u53d1\u73b0X\u5e73\u53f0\u7684Community Notes\u7cfb\u7edf\u5728\u5065\u5eb7\u76f8\u5173\u9519\u8bef\u4fe1\u606f\u6cbb\u7406\u4e2d\u5b58\u5728\u663e\u8457\u5ef6\u8fdf\uff08\u4e2d\u4f4d\u5ef6\u8fdf17.6\u5c0f\u65f6\uff09\uff0c\u9700\u8981\u63d0\u9ad8\u54cd\u5e94\u901f\u5ea6\u4ee5\u5e94\u5bf9\u5b9e\u65f6\u9519\u8bef\u4fe1\u606f\u6fc0\u589e\u3002", "method": "\u63d0\u51faCrowdNotes+\u7edf\u4e00\u6846\u67b6\uff0c\u5305\u542b\u4e24\u79cd\u4e92\u8865\u6a21\u5f0f\uff1a\u8bc1\u636e\u589e\u5f3a\u7684\u6ce8\u91ca\u589e\u5f3a\u548c\u6548\u7528\u5f15\u5bfc\u7684\u6ce8\u91ca\u81ea\u52a8\u5316\uff0c\u4ee5\u53ca\u5206\u5c42\u4e09\u6b65\u8bc4\u4f30\uff08\u76f8\u5173\u6027\u3001\u6b63\u786e\u6027\u3001\u6709\u7528\u6027\uff09\u3002", "result": "\u572815\u4e2aLLM\u4e0a\u7684\u5b9e\u9a8c\u63ed\u793a\u4e86\u5f53\u524d\u6709\u7528\u6027\u8bc4\u4f30\u7684\u6f0f\u6d1e\uff08\u98ce\u683c\u6d41\u7545\u6027\u88ab\u8bef\u8ba4\u4e3a\u4e8b\u5b9e\u51c6\u786e\u6027\uff09\uff0c\u5206\u5c42\u8bc4\u4f30\u548cLLM\u589e\u5f3a\u751f\u6210\u5171\u540c\u63d0\u9ad8\u4e86\u4e8b\u5b9e\u7cbe\u786e\u6027\u548c\u8bc1\u636e\u6548\u7528\u3002", "conclusion": "\u7814\u7a76\u6307\u5411\u4e00\u79cd\u6df7\u5408\u4eba\u673a\u6cbb\u7406\u6a21\u578b\uff0c\u80fd\u591f\u540c\u65f6\u63d0\u9ad8\u4f17\u5305\u4e8b\u5b9e\u6838\u67e5\u7684\u4e25\u8c28\u6027\u548c\u53ca\u65f6\u6027\u3002"}}
{"id": "2510.09925", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.09925", "abs": "https://arxiv.org/abs/2510.09925", "authors": ["James Usevitch", "Juan Augusto Paredes Salazar", "Ankit Goel"], "title": "Computing Safe Control Inputs using Discrete-Time Matrix Control Barrier Functions via Convex Optimization", "comment": "17 pages, 8 figures", "summary": "Control barrier functions (CBFs) have seen widespread success in providing\nforward invariance and safety guarantees for dynamical control systems. A\ncrucial limitation of discrete-time formulations is that CBFs that are\nnonconcave in their argument require the solution of nonconvex optimization\nproblems to compute safety-preserving control inputs, which inhibits real-time\ncomputation of control inputs guaranteeing forward invariance. This paper\npresents a novel method for computing safety-preserving control inputs for\ndiscrete-time systems with nonconvex safety sets, utilizing convex optimization\nand the recently developed class of matrix control barrier function techniques.\nThe efficacy of our methods is demonstrated through numerical simulations on a\nbicopter system.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u51f8\u4f18\u5316\u548c\u77e9\u9635\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u6280\u672f\u4e3a\u5177\u6709\u975e\u51f8\u5b89\u5168\u96c6\u7684\u79bb\u6563\u65f6\u95f4\u7cfb\u7edf\u8ba1\u7b97\u5b89\u5168\u4fdd\u6301\u63a7\u5236\u8f93\u5165\u7684\u65b0\u65b9\u6cd5", "motivation": "\u79bb\u6563\u65f6\u95f4\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u5728\u53c2\u6570\u975e\u51f9\u65f6\u9700\u8981\u6c42\u89e3\u975e\u51f8\u4f18\u5316\u95ee\u9898\u6765\u8ba1\u7b97\u5b89\u5168\u4fdd\u6301\u63a7\u5236\u8f93\u5165\uff0c\u8fd9\u963b\u788d\u4e86\u5b9e\u65f6\u8ba1\u7b97\u4fdd\u8bc1\u524d\u5411\u4e0d\u53d8\u6027\u7684\u63a7\u5236\u8f93\u5165", "method": "\u5229\u7528\u51f8\u4f18\u5316\u548c\u6700\u8fd1\u5f00\u53d1\u7684\u77e9\u9635\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u6280\u672f\uff0c\u4e3a\u5177\u6709\u975e\u51f8\u5b89\u5168\u96c6\u7684\u79bb\u6563\u65f6\u95f4\u7cfb\u7edf\u8ba1\u7b97\u5b89\u5168\u4fdd\u6301\u63a7\u5236\u8f93\u5165", "result": "\u901a\u8fc7\u53cc\u65cb\u7ffc\u7cfb\u7edf\u7684\u6570\u503c\u4eff\u771f\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u79bb\u6563\u65f6\u95f4\u7cfb\u7edf\u4e2d\u975e\u51f8\u5b89\u5168\u96c6\u5e26\u6765\u7684\u8ba1\u7b97\u6311\u6218\uff0c\u5b9e\u73b0\u5b89\u5168\u4fdd\u6301\u63a7\u5236\u8f93\u5165\u7684\u5b9e\u65f6\u8ba1\u7b97"}}
{"id": "2510.09686", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.09686", "abs": "https://arxiv.org/abs/2510.09686", "authors": ["Jianghao Lin", "Rong Shan", "Jiachen Zhu", "Yunjia Xi", "Yong Yu", "Weinan Zhang"], "title": "Stop DDoS Attacking the Research Community with AI-Generated Survey Papers", "comment": "Accepted by NeurIPS 2025 (Position Track)", "summary": "Survey papers are foundational to the scholarly progress of research\ncommunities, offering structured overviews that guide both novices and experts\nacross disciplines. However, the recent surge of AI-generated surveys,\nespecially enabled by large language models (LLMs), has transformed this\ntraditionally labor-intensive genre into a low-effort, high-volume output.\nWhile such automation lowers entry barriers, it also introduces a critical\nthreat: the phenomenon we term the \"survey paper DDoS attack\" to the research\ncommunity. This refers to the unchecked proliferation of superficially\ncomprehensive but often redundant, low-quality, or even hallucinated survey\nmanuscripts, which floods preprint platforms, overwhelms researchers, and\nerodes trust in the scientific record. In this position paper, we argue that we\nmust stop uploading massive amounts of AI-generated survey papers (i.e., survey\npaper DDoS attack) to the research community, by instituting strong norms for\nAI-assisted review writing. We call for restoring expert oversight and\ntransparency in AI usage and, moreover, developing new infrastructures such as\nDynamic Live Surveys, community-maintained, version-controlled repositories\nthat blend automated updates with human curation. Through quantitative trend\nanalysis, quality audits, and cultural impact discussion, we show that\nsafeguarding the integrity of surveys is no longer optional but imperative to\nthe research community.", "AI": {"tldr": "AI\u751f\u6210\u7efc\u8ff0\u8bba\u6587\u7684\u6cdb\u6ee5\u6b63\u5728\u5a01\u80c1\u7814\u7a76\u793e\u533a\uff0c\u4f5c\u8005\u547c\u5401\u5efa\u7acb\u89c4\u8303\u6765\u963b\u6b62\u8fd9\u79cd\"\u7efc\u8ff0\u8bba\u6587DDoS\u653b\u51fb\"\uff0c\u5e76\u5efa\u8bae\u5f00\u53d1\u52a8\u6001\u5b9e\u65f6\u7efc\u8ff0\u7b49\u65b0\u57fa\u7840\u8bbe\u65bd\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5174\u8d77\uff0cAI\u751f\u6210\u7684\u7efc\u8ff0\u8bba\u6587\u5927\u91cf\u6d8c\u73b0\uff0c\u8fd9\u4e9b\u8868\u9762\u5168\u9762\u4f46\u8d28\u91cf\u4f4e\u52a3\u7684\u8bba\u6587\u6df9\u6ca1\u4e86\u9884\u5370\u672c\u5e73\u53f0\uff0c\u7ed9\u7814\u7a76\u793e\u533a\u5e26\u6765\u4e86\u4e25\u91cd\u5a01\u80c1\u3002", "method": "\u901a\u8fc7\u5b9a\u91cf\u8d8b\u52bf\u5206\u6790\u3001\u8d28\u91cf\u5ba1\u8ba1\u548c\u6587\u5316\u5f71\u54cd\u8ba8\u8bba\uff0c\u5c55\u793aAI\u751f\u6210\u7efc\u8ff0\u8bba\u6587\u7684\u95ee\u9898\u4e25\u91cd\u6027\u3002", "result": "\u53d1\u73b0AI\u751f\u6210\u7684\u7efc\u8ff0\u8bba\u6587\u5b58\u5728\u5197\u4f59\u3001\u4f4e\u8d28\u91cf\u751a\u81f3\u865a\u6784\u5185\u5bb9\u7684\u95ee\u9898\uff0c\u4e25\u91cd\u4fb5\u8680\u4e86\u79d1\u5b66\u8bb0\u5f55\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u4fdd\u62a4\u7efc\u8ff0\u8bba\u6587\u7684\u5b8c\u6574\u6027\u5bf9\u7814\u7a76\u793e\u533a\u5df2\u4e0d\u518d\u662f\u53ef\u9009\u9879\uff0c\u800c\u662f\u5fc5\u987b\u91c7\u53d6\u7684\u63aa\u65bd\uff0c\u9700\u8981\u5efa\u7acb\u4e13\u5bb6\u76d1\u7763\u673a\u5236\u548c\u900f\u660e\u5ea6\u6807\u51c6\u3002"}}
{"id": "2510.09966", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.09966", "abs": "https://arxiv.org/abs/2510.09966", "authors": ["Easton R. Potokar", "Taylor Pool", "Daniel McGann", "Michael Kaess"], "title": "FORM: Fixed-Lag Odometry with Reparative Mapping utilizing Rotating LiDAR Sensors", "comment": "Submitted to ICRA 2026", "summary": "Light Detection and Ranging (LiDAR) sensors have become a de-facto sensor for\nmany robot state estimation tasks, spurring development of many LiDAR Odometry\n(LO) methods in recent years. While some smoothing-based LO methods have been\nproposed, most require matching against multiple scans, resulting in\nsub-real-time performance. Due to this, most prior works estimate a single\nstate at a time and are ``submap''-based. This architecture propagates any\nerror in pose estimation to the fixed submap and can cause jittery trajectories\nand degrade future registrations. We propose Fixed-Lag Odometry with Reparative\nMapping (FORM), a LO method that performs smoothing over a densely connected\nfactor graph while utilizing a single iterative map for matching. This allows\nfor both real-time performance and active correction of the local map as pose\nestimates are further refined. We evaluate on a wide variety of datasets to\nshow that FORM is robust, accurate, real-time, and provides smooth trajectory\nestimates when compared to prior state-of-the-art LO methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86FORM\u65b9\u6cd5\uff0c\u4e00\u79cdLiDAR\u91cc\u7a0b\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bc6\u96c6\u8fde\u63a5\u7684\u56e0\u5b50\u56fe\u8fdb\u884c\u5e73\u6ed1\u5904\u7406\uff0c\u540c\u65f6\u4f7f\u7528\u5355\u4e00\u8fed\u4ee3\u5730\u56fe\u8fdb\u884c\u5339\u914d\uff0c\u5b9e\u73b0\u5b9e\u65f6\u6027\u80fd\u548c\u4e3b\u52a8\u4fee\u6b63\u5c40\u90e8\u5730\u56fe\u3002", "motivation": "\u73b0\u6709LiDAR\u91cc\u7a0b\u8ba1\u65b9\u6cd5\u5927\u591a\u57fa\u4e8e\u5b50\u5730\u56fe\u67b6\u6784\uff0c\u4f1a\u5c06\u59ff\u6001\u4f30\u8ba1\u8bef\u5dee\u4f20\u64ad\u5230\u56fa\u5b9a\u5b50\u5730\u56fe\u4e2d\uff0c\u5bfc\u81f4\u8f68\u8ff9\u6296\u52a8\u548c\u672a\u6765\u914d\u51c6\u6027\u80fd\u4e0b\u964d\uff0c\u4e14\u591a\u6570\u65b9\u6cd5\u65e0\u6cd5\u5b9e\u73b0\u5b9e\u65f6\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u5bc6\u96c6\u8fde\u63a5\u7684\u56e0\u5b50\u56fe\u8fdb\u884c\u5e73\u6ed1\u5904\u7406\uff0c\u540c\u65f6\u91c7\u7528\u5355\u4e00\u8fed\u4ee3\u5730\u56fe\u8fdb\u884c\u5339\u914d\uff0c\u5141\u8bb8\u5728\u59ff\u6001\u4f30\u8ba1\u8fdb\u4e00\u6b65\u7ec6\u5316\u65f6\u4e3b\u52a8\u4fee\u6b63\u5c40\u90e8\u5730\u56fe\u3002", "result": "\u5728\u591a\u79cd\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cFORM\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u7684LiDAR\u91cc\u7a0b\u8ba1\u65b9\u6cd5\u5177\u6709\u9c81\u68d2\u6027\u3001\u51c6\u786e\u6027\u3001\u5b9e\u65f6\u6027\uff0c\u5e76\u80fd\u63d0\u4f9b\u5e73\u6ed1\u7684\u8f68\u8ff9\u4f30\u8ba1\u3002", "conclusion": "FORM\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u56e0\u5b50\u56fe\u5e73\u6ed1\u548c\u5355\u4e00\u8fed\u4ee3\u5730\u56fe\u5339\u914d\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709LiDAR\u91cc\u7a0b\u8ba1\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u5b9e\u65f6\u6027\u80fd\u548c\u4e3b\u52a8\u5730\u56fe\u4fee\u6b63\u3002"}}
{"id": "2510.11289", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.11289", "abs": "https://arxiv.org/abs/2510.11289", "authors": ["Milo\u0161 Ciganovi\u0107", "Elena Scola Gagliardi", "Massimiliano Tancioni"], "title": "Disentangling the Distributional Effects of Financial Shocks in the Euro Area", "comment": null, "summary": "We estimate the dynamic distributional effects of financial shocks in the\nEuro Area using survey-based microdata on personal incomes. We find that\npositive financial shocks increase inequality, with heterogeneity across\ndifferent income groups. Much of the response emerges in the tails of the\nincome distribution. By decomposing individual incomes into financial and labor\ncomponents, we identify two distinct transmission mechanisms: financial income\ninequality rises, likely due to differences in asset holdings. In contrast,\nlabor income inequality increases through a skill premium channel. We then\nconsider a nonlinear model framework, distinguishing the sign of the shock,\nallowing us to document the presence of asymmetric effects. While positive\nshocks lead to income disparities, adverse shocks have the opposite effect.\nNotably, middle-income groups are only affected following a negative shock,\nhighlighting differential vulnerabilities across the income distribution.", "AI": {"tldr": "\u4f7f\u7528\u6b27\u5143\u533a\u4e2a\u4eba\u6536\u5165\u5fae\u89c2\u8c03\u67e5\u6570\u636e\uff0c\u7814\u7a76\u53d1\u73b0\u6b63\u5411\u91d1\u878d\u51b2\u51fb\u4f1a\u589e\u52a0\u6536\u5165\u4e0d\u5e73\u7b49\uff0c\u4e3b\u8981\u901a\u8fc7\u91d1\u878d\u6536\u5165\u4e0d\u5e73\u7b49\uff08\u8d44\u4ea7\u6301\u6709\u5dee\u5f02\uff09\u548c\u52b3\u52a8\u6536\u5165\u4e0d\u5e73\u7b49\uff08\u6280\u80fd\u6ea2\u4ef7\u6e20\u9053\uff09\u4e24\u79cd\u673a\u5236\u4f20\u5bfc\uff0c\u4e14\u5b58\u5728\u4e0d\u5bf9\u79f0\u6548\u5e94\u3002", "motivation": "\u7814\u7a76\u91d1\u878d\u51b2\u51fb\u5bf9\u6536\u5165\u5206\u914d\u7684\u52a8\u6001\u5206\u5e03\u6548\u5e94\uff0c\u63ed\u793a\u4e0d\u540c\u6536\u5165\u7fa4\u4f53\u5bf9\u91d1\u878d\u51b2\u51fb\u7684\u5f02\u8d28\u6027\u53cd\u5e94\uff0c\u4ee5\u53ca\u51b2\u51fb\u4f20\u5bfc\u7684\u5177\u4f53\u673a\u5236\u3002", "method": "\u57fa\u4e8e\u6b27\u5143\u533a\u4e2a\u4eba\u6536\u5165\u5fae\u89c2\u8c03\u67e5\u6570\u636e\uff0c\u5c06\u4e2a\u4eba\u6536\u5165\u5206\u89e3\u4e3a\u91d1\u878d\u6536\u5165\u548c\u52b3\u52a8\u6536\u5165\uff0c\u91c7\u7528\u975e\u7ebf\u6027\u6a21\u578b\u6846\u67b6\u533a\u5206\u6b63\u5411\u548c\u8d1f\u5411\u51b2\u51fb\u7684\u5f71\u54cd\u3002", "result": "\u6b63\u5411\u91d1\u878d\u51b2\u51fb\u589e\u52a0\u6536\u5165\u4e0d\u5e73\u7b49\uff0c\u4e3b\u8981\u4f53\u73b0\u5728\u6536\u5165\u5206\u5e03\u7684\u5c3e\u90e8\uff1b\u8d1f\u5411\u51b2\u51fb\u5219\u4ea7\u751f\u76f8\u53cd\u6548\u679c\uff1b\u4e2d\u7b49\u6536\u5165\u7fa4\u4f53\u4ec5\u53d7\u8d1f\u5411\u51b2\u51fb\u5f71\u54cd\uff0c\u663e\u793a\u4e0d\u540c\u6536\u5165\u7fa4\u4f53\u7684\u8106\u5f31\u6027\u5dee\u5f02\u3002", "conclusion": "\u91d1\u878d\u51b2\u51fb\u5bf9\u6536\u5165\u5206\u914d\u5177\u6709\u663e\u8457\u4e14\u4e0d\u5bf9\u79f0\u7684\u5f71\u54cd\uff0c\u4e0d\u540c\u6536\u5165\u7fa4\u4f53\u5bf9\u51b2\u51fb\u7684\u53cd\u5e94\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u8fd9\u5bf9\u653f\u7b56\u5236\u5b9a\u5177\u6709\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2510.11452", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2510.11452", "abs": "https://arxiv.org/abs/2510.11452", "authors": ["Marcin Dziubi\u0144ski", "Sanjeev Goyal", "Junjie Zhou"], "title": "Interconnected Contests", "comment": null, "summary": "We study a two-player model of conflict with multiple battlefields -- the\nnovel element is that each of the players has their own network of spillovers\nso that resources allocated to one battle can be utilized in winning\nneighboring battles. There exists a unique equilibrium in which the relative\nprobability of a player winning a battle is the product of the ratio of the\ncentrality of the battlefield in the two respective competing networks and the\nratio of the relative cost of efforts of the two players. We study the design\nof networks and characterize networks that maximize total efforts and maximize\ntotal utility. Finally, we characterize the equilibrium of a game in which\nplayers choose both networks and efforts in the battles.", "AI": {"tldr": "\u7814\u7a76\u5177\u6709\u591a\u4e2a\u6218\u573a\u7684\u53cc\u73a9\u5bb6\u51b2\u7a81\u6a21\u578b\uff0c\u8003\u8651\u73a9\u5bb6\u5404\u81ea\u7f51\u7edc\u4e2d\u7684\u6ea2\u51fa\u6548\u5e94\uff0c\u5373\u5206\u914d\u5230\u67d0\u4e2a\u6218\u573a\u7684\u8d44\u6e90\u53ef\u4ee5\u7528\u4e8e\u8d62\u5f97\u76f8\u90bb\u6218\u573a\u3002", "motivation": "\u63a2\u7d22\u5728\u5b58\u5728\u7f51\u7edc\u6ea2\u51fa\u6548\u5e94\u7684\u591a\u6218\u573a\u51b2\u7a81\u4e2d\uff0c\u73a9\u5bb6\u5982\u4f55\u6700\u4f18\u5206\u914d\u8d44\u6e90\uff0c\u4ee5\u53ca\u7f51\u7edc\u7ed3\u6784\u5982\u4f55\u5f71\u54cd\u51b2\u7a81\u7ed3\u679c\u3002", "method": "\u6784\u5efa\u53cc\u73a9\u5bb6\u591a\u6218\u573a\u51b2\u7a81\u6a21\u578b\uff0c\u6bcf\u4e2a\u73a9\u5bb6\u6709\u81ea\u5df1\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u8d44\u6e90\u5206\u914d\u5177\u6709\u7f51\u7edc\u6ea2\u51fa\u6548\u5e94\u3002\u5206\u6790\u5747\u8861\u5b58\u5728\u6027\u548c\u7279\u6027\uff0c\u7814\u7a76\u7f51\u7edc\u8bbe\u8ba1\u95ee\u9898\u3002", "result": "\u5b58\u5728\u552f\u4e00\u5747\u8861\uff0c\u73a9\u5bb6\u8d62\u5f97\u67d0\u4e2a\u6218\u573a\u7684\u76f8\u5bf9\u6982\u7387\u7b49\u4e8e\u8be5\u6218\u573a\u5728\u4e24\u4e2a\u7ade\u4e89\u7f51\u7edc\u4e2d\u7684\u4e2d\u5fc3\u6027\u6bd4\u7387\u4e0e\u73a9\u5bb6\u76f8\u5bf9\u52aa\u529b\u6210\u672c\u6bd4\u7387\u7684\u4e58\u79ef\u3002", "conclusion": "\u7f51\u7edc\u7ed3\u6784\u5bf9\u51b2\u7a81\u7ed3\u679c\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u53ef\u4ee5\u8bbe\u8ba1\u7f51\u7edc\u6765\u6700\u5927\u5316\u603b\u52aa\u529b\u6216\u603b\u6548\u7528\uff0c\u73a9\u5bb6\u5728\u5747\u8861\u4e2d\u4f1a\u540c\u65f6\u9009\u62e9\u7f51\u7edc\u548c\u6218\u573a\u52aa\u529b\u3002"}}
{"id": "2510.09901", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09901", "abs": "https://arxiv.org/abs/2510.09901", "authors": ["Lianhao Zhou", "Hongyi Ling", "Cong Fu", "Yepeng Huang", "Michael Sun", "Wendi Yu", "Xiaoxuan Wang", "Xiner Li", "Xingyu Su", "Junkai Zhang", "Xiusi Chen", "Chenxing Liang", "Xiaofeng Qian", "Heng Ji", "Wei Wang", "Marinka Zitnik", "Shuiwang Ji"], "title": "Autonomous Agents for Scientific Discovery: Orchestrating Scientists, Language, Code, and Physics", "comment": null, "summary": "Computing has long served as a cornerstone of scientific discovery. Recently,\na paradigm shift has emerged with the rise of large language models (LLMs),\nintroducing autonomous systems, referred to as agents, that accelerate\ndiscovery across varying levels of autonomy. These language agents provide a\nflexible and versatile framework that orchestrates interactions with human\nscientists, natural language, computer language and code, and physics. This\npaper presents our view and vision of LLM-based scientific agents and their\ngrowing role in transforming the scientific discovery lifecycle, from\nhypothesis discovery, experimental design and execution, to result analysis and\nrefinement. We critically examine current methodologies, emphasizing key\ninnovations, practical achievements, and outstanding limitations. Additionally,\nwe identify open research challenges and outline promising directions for\nbuilding more robust, generalizable, and adaptive scientific agents. Our\nanalysis highlights the transformative potential of autonomous agents to\naccelerate scientific discovery across diverse domains.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u79d1\u5b66\u4ee3\u7406\u5728\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\u4e2d\u7684\u65b0\u5174\u4f5c\u7528\uff0c\u6db5\u76d6\u4ece\u5047\u8bbe\u53d1\u73b0\u5230\u7ed3\u679c\u5206\u6790\u7684\u6574\u4e2a\u79d1\u5b66\u53d1\u73b0\u751f\u547d\u5468\u671f\u3002", "motivation": "\u8ba1\u7b97\u957f\u671f\u4ee5\u6765\u4e00\u76f4\u662f\u79d1\u5b66\u53d1\u73b0\u7684\u57fa\u77f3\uff0c\u6700\u8fd1\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5174\u8d77\u5e26\u6765\u4e86\u8303\u5f0f\u8f6c\u53d8\uff0c\u5f15\u5165\u4e86\u80fd\u591f\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\u7684\u81ea\u4e3b\u4f53\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7075\u6d3b\u591a\u529f\u80fd\u7684\u8bed\u8a00\u4ee3\u7406\u6846\u67b6\uff0c\u534f\u8c03\u4e0e\u4eba\u7c7b\u79d1\u5b66\u5bb6\u3001\u81ea\u7136\u8bed\u8a00\u3001\u8ba1\u7b97\u673a\u8bed\u8a00\u548c\u4ee3\u7801\u4ee5\u53ca\u7269\u7406\u5b66\u7684\u4ea4\u4e92\u3002", "result": "\u5206\u6790\u4e86\u5f53\u524d\u65b9\u6cd5\u5b66\uff0c\u5f3a\u8c03\u4e86\u5173\u952e\u521b\u65b0\u3001\u5b9e\u9645\u6210\u5c31\u548c\u7a81\u51fa\u5c40\u9650\u6027\uff0c\u5c55\u793a\u4e86\u81ea\u4e3b\u4ee3\u7406\u5728\u52a0\u901f\u8de8\u9886\u57df\u79d1\u5b66\u53d1\u73b0\u65b9\u9762\u7684\u53d8\u9769\u6f5c\u529b\u3002", "conclusion": "\u8bc6\u522b\u4e86\u5f00\u653e\u7684\u7814\u7a76\u6311\u6218\uff0c\u5e76\u6982\u8ff0\u4e86\u6784\u5efa\u66f4\u7a33\u5065\u3001\u53ef\u6cdb\u5316\u548c\u9002\u5e94\u6027\u5f3a\u7684\u79d1\u5b66\u4ee3\u7406\u7684\u6709\u524d\u666f\u65b9\u5411\u3002"}}
{"id": "2510.11177", "categories": ["stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.11177", "abs": "https://arxiv.org/abs/2510.11177", "authors": ["Ian J. Burton", "Femke J. M. M. Nijsse", "James M. Salter"], "title": "Policy Robustness & Uncertainty in Model-based Decision Support for the Energy Transition", "comment": null, "summary": "Climate policy modelling is a key tool for assessing mitigation strategies in\ncomplex systems and uncertainty is inherent and unavoidable. We present a\ngeneral methodology for extensive uncertainty analysis in climate policy\nmodelling. We show how emulators can identify key uncertainties in modelling\nframeworks and enable policy analysis previously restricted by computational\ncost. We apply this methodology to FTT:Power to explore uncertainties in the\nelectricity system transition both globally and in India and to assess how\nrobust mitigation strategies are to a vast range of policy and techno-economic\nscenarios. We find that uncertainties in transition outcomes are significantly\nlarger than previously shown, but strong policy can narrow these ranges.\nGlobally, plant construction and grid connection lead times dominate transition\nuncertainty, outweighing regional price policies, including policy reversals in\nthe US. Solar PV proves most resilient due to low costs, though still sensitive\nto financing and infrastructure limits. Wind and other renewables are more\nvulnerable. In India, we find that policy packages including even partial\nphaseout instruments have greater robustness to key uncertainties although\nlonger lead times still hinder policy goals. Our results highlight that\nreducing lead times and phasing out fossil fuels are critical for faster, more\nrobust power sector transitions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6c14\u5019\u653f\u7b56\u5efa\u6a21\u7684\u5e7f\u6cdb\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u65b9\u6cd5\uff0c\u4f7f\u7528\u6a21\u62df\u5668\u8bc6\u522b\u5173\u952e\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5e94\u7528\u4e8e\u7535\u529b\u7cfb\u7edf\u8f6c\u578b\u5206\u6790\uff0c\u53d1\u73b0\u8f6c\u578b\u7ed3\u679c\u7684\u4e0d\u786e\u5b9a\u6027\u6bd4\u4e4b\u524d\u663e\u793a\u7684\u8981\u5927\uff0c\u4f46\u5f3a\u6709\u529b\u7684\u653f\u7b56\u53ef\u4ee5\u7f29\u5c0f\u8fd9\u4e9b\u8303\u56f4\u3002", "motivation": "\u6c14\u5019\u653f\u7b56\u5efa\u6a21\u662f\u8bc4\u4f30\u590d\u6742\u7cfb\u7edf\u4e2d\u51cf\u7f13\u7b56\u7565\u7684\u5173\u952e\u5de5\u5177\uff0c\u4e0d\u786e\u5b9a\u6027\u662f\u56fa\u6709\u4e14\u4e0d\u53ef\u907f\u514d\u7684\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8fdb\u884c\u5e7f\u6cdb\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u6a21\u62df\u5668\u8bc6\u522b\u5efa\u6a21\u6846\u67b6\u4e2d\u7684\u5173\u952e\u4e0d\u786e\u5b9a\u6027\uff0c\u5e94\u7528\u8be5\u65b9\u6cd5\u5230FTT:Power\u6a21\u578b\uff0c\u63a2\u7d22\u5168\u7403\u548c\u5370\u5ea6\u7535\u529b\u7cfb\u7edf\u8f6c\u578b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u8bc4\u4f30\u51cf\u7f13\u7b56\u7565\u5bf9\u5404\u79cd\u653f\u7b56\u548c\u7ecf\u6d4e\u6280\u672f\u60c5\u666f\u7684\u7a33\u5065\u6027\u3002", "result": "\u5168\u7403\u8303\u56f4\u5185\uff0c\u7535\u5382\u5efa\u8bbe\u548c\u7535\u7f51\u8fde\u63a5\u7684\u524d\u7f6e\u65f6\u95f4\u4e3b\u5bfc\u8f6c\u578b\u4e0d\u786e\u5b9a\u6027\uff0c\u8d85\u8fc7\u533a\u57df\u4ef7\u683c\u653f\u7b56\u7684\u5f71\u54cd\uff1b\u592a\u9633\u80fd\u5149\u4f0f\u6700\u5177\u97e7\u6027\uff0c\u4f46\u98ce\u7535\u548c\u5176\u4ed6\u53ef\u518d\u751f\u80fd\u6e90\u66f4\u8106\u5f31\uff1b\u5728\u5370\u5ea6\uff0c\u5305\u542b\u90e8\u5206\u6dd8\u6c70\u63aa\u65bd\u7684\u653f\u7b56\u5305\u5bf9\u5173\u952e\u4e0d\u786e\u5b9a\u6027\u5177\u6709\u66f4\u5f3a\u7684\u7a33\u5065\u6027\u3002", "conclusion": "\u51cf\u5c11\u524d\u7f6e\u65f6\u95f4\u548c\u9010\u6b65\u6dd8\u6c70\u5316\u77f3\u71c3\u6599\u5bf9\u4e8e\u66f4\u5feb\u3001\u66f4\u7a33\u5065\u7684\u7535\u529b\u90e8\u95e8\u8f6c\u578b\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.11524", "categories": ["cs.SI", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2510.11524", "abs": "https://arxiv.org/abs/2510.11524", "authors": ["Sebasti\u00e1n Brzovic", "Crist\u00f3bal Rojas", "Andr\u00e9s Abeliuk"], "title": "Networks Multiscale Entropy Analysis", "comment": null, "summary": "Understanding the structural complexity and predictability of complex\nnetworks is a central challenge in network science. Although recent studies\nhave revealed a relationship between compression-based entropy and link\nprediction performance, existing methods focus on single-scale representations.\nThis approach often overlooks the rich hierarchical patterns that can exist in\nreal-world networks. In this study, we introduce a multiscale entropy framework\nthat extends previous entropy-based approaches by applying spectral graph\nreduction. This allows us to quantify how structural entropy evolves as the\nnetwork is gradually coarsened, capturing complexity across multiple scales. We\napply our framework to real-world networks across biological, economic, social,\ntechnological, and transportation domains. The results uncover consistent\nentropy profiles across network families, revealing three structural\nregimes$\\unicode{x2013}$stable, increasing, and hybrid$\\unicode{x2013}$that\nalign with domain-specific behaviors. Compared to single-scale models,\nmultiscale entropy significantly improves our ability to determine network\npredictability. This shows that considering structural information across\nscales provides a more complete characterization of network complexity.\nTogether, these results position multiscale entropy as a powerful and scalable\ntool for characterizing, classifying, and assessing the structure of complex\nnetworks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u5c3a\u5ea6\u71b5\u6846\u67b6\uff0c\u901a\u8fc7\u8c31\u56fe\u7f29\u51cf\u6765\u91cf\u5316\u7f51\u7edc\u5728\u4e0d\u540c\u5c3a\u5ea6\u4e0b\u7684\u7ed3\u6784\u71b5\u6f14\u5316\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7f51\u7edc\u53ef\u9884\u6d4b\u6027\u7684\u8bc4\u4f30\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5355\u5c3a\u5ea6\u8868\u793a\uff0c\u5ffd\u7565\u4e86\u73b0\u5b9e\u4e16\u754c\u7f51\u7edc\u4e2d\u5b58\u5728\u7684\u4e30\u5bcc\u5c42\u6b21\u6a21\u5f0f\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6355\u6349\u591a\u5c3a\u5ea6\u7ed3\u6784\u590d\u6742\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u591a\u5c3a\u5ea6\u71b5\u6846\u67b6\uff0c\u5e94\u7528\u8c31\u56fe\u7f29\u51cf\u6280\u672f\uff0c\u9010\u6b65\u7c97\u5316\u7f51\u7edc\u5e76\u91cf\u5316\u7ed3\u6784\u71b5\u5728\u4e0d\u540c\u5c3a\u5ea6\u4e0b\u7684\u6f14\u5316\u8fc7\u7a0b\u3002", "result": "\u5728\u751f\u7269\u3001\u7ecf\u6d4e\u3001\u793e\u4f1a\u3001\u6280\u672f\u548c\u4ea4\u901a\u7b49\u9886\u57df\u7684\u771f\u5b9e\u7f51\u7edc\u4e2d\u53d1\u73b0\u4e86\u4e00\u81f4\u7684\u71b5\u5206\u5e03\u6a21\u5f0f\uff0c\u63ed\u793a\u4e86\u4e09\u79cd\u7ed3\u6784\u673a\u5236\u2014\u2014\u7a33\u5b9a\u578b\u3001\u589e\u957f\u578b\u548c\u6df7\u5408\u578b\uff0c\u8fd9\u4e9b\u673a\u5236\u4e0e\u7279\u5b9a\u9886\u57df\u884c\u4e3a\u76f8\u4e00\u81f4\u3002", "conclusion": "\u591a\u5c3a\u5ea6\u71b5\u662f\u8868\u5f81\u3001\u5206\u7c7b\u548c\u8bc4\u4f30\u590d\u6742\u7f51\u7edc\u7ed3\u6784\u7684\u5f3a\u5927\u4e14\u53ef\u6269\u5c55\u7684\u5de5\u5177\uff0c\u8003\u8651\u8de8\u5c3a\u5ea6\u7684\u7ed3\u6784\u4fe1\u606f\u80fd\u591f\u63d0\u4f9b\u66f4\u5b8c\u6574\u7684\u7f51\u7edc\u590d\u6742\u6027\u63cf\u8ff0\u3002"}}
{"id": "2510.09929", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.09929", "abs": "https://arxiv.org/abs/2510.09929", "authors": ["Dylan Hirsch", "Jaime Fern\u00e1ndez Fisac", "Sylvia Herbert"], "title": "Viscosity CBFs: Bridging the Control Barrier Function and Hamilton-Jacobi Reachability Frameworks in Safe Control Theory", "comment": null, "summary": "Control barrier functions (CBFs) and Hamilton-Jacobi reachability (HJR) are\ncentral frameworks in safe control. Traditionally, these frameworks have been\nviewed as distinct, with the former focusing on optimally safe controller\ndesign and the latter providing sufficient conditions for safety. A previous\nwork introduced the notion of a control barrier value function (CB-VF), which\nis defined similarly to the other value functions studied in HJR but has\ncertain CBF-like properties. In this work, we proceed the other direction by\ngeneralizing CBFs to non-differentiable ``viscosity'' CBFs. We show the deep\nconnection between viscosity CBFs and CB-VFs, bridging the CBF and HJR\nframeworks. Through this bridge, we characterize the viscosity CBFs as\nprecisely those functions which provide CBF-like safety guarantees (control\ninvariance and smooth approach to the boundary). We then further show nice\ntheoretical properties of viscosity CBFs, including their desirable closure\nunder maximum and limit operations. In the process, we also extend CB-VFs to\nnon-exponential anti-discounting and update the corresponding theory for CB-VFs\nalong these lines.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5c06\u63a7\u5236\u5c4f\u969c\u51fd\u6570(CBFs)\u63a8\u5e7f\u5230\u4e0d\u53ef\u5fae\u7684\"\u7c98\u6027\"CBFs\uff0c\u5efa\u7acb\u4e86CBF\u4e0eHamilton-Jacobi\u53ef\u8fbe\u6027(HJR)\u6846\u67b6\u4e4b\u95f4\u7684\u6865\u6881\uff0c\u5e76\u8bc1\u660e\u4e86\u7c98\u6027CBFs\u5177\u6709\u63a7\u5236\u4e0d\u53d8\u6027\u548c\u8fb9\u754c\u5e73\u6ed1\u63a5\u8fd1\u7b49\u5b89\u5168\u4fdd\u8bc1\u7279\u6027\u3002", "motivation": "\u4f20\u7edf\u4e0a\uff0c\u63a7\u5236\u5c4f\u969c\u51fd\u6570(CBFs)\u548cHamilton-Jacobi\u53ef\u8fbe\u6027(HJR)\u88ab\u89c6\u4e3a\u4e24\u4e2a\u4e0d\u540c\u7684\u5b89\u5168\u63a7\u5236\u6846\u67b6\uff0c\u524d\u8005\u4e13\u6ce8\u4e8e\u6700\u4f18\u5b89\u5168\u63a7\u5236\u5668\u8bbe\u8ba1\uff0c\u540e\u8005\u63d0\u4f9b\u5b89\u5168\u6027\u7684\u5145\u5206\u6761\u4ef6\u3002\u672c\u6587\u65e8\u5728\u5efa\u7acb\u8fd9\u4e24\u4e2a\u6846\u67b6\u4e4b\u95f4\u7684\u6df1\u5c42\u8054\u7cfb\u3002", "method": "\u5c06CBFs\u63a8\u5e7f\u5230\u4e0d\u53ef\u5fae\u7684\"\u7c98\u6027\"CBFs\uff0c\u5206\u6790\u5176\u4e0e\u63a7\u5236\u5c4f\u969c\u503c\u51fd\u6570(CB-VFs)\u7684\u5173\u7cfb\uff0c\u5e76\u8bc1\u660e\u7c98\u6027CBFs\u5728\u6700\u5927\u503c\u548c\u6781\u9650\u8fd0\u7b97\u4e0b\u7684\u826f\u597d\u95ed\u5305\u6027\u8d28\u3002", "result": "\u6210\u529f\u5efa\u7acb\u4e86CBF\u548cHJR\u6846\u67b6\u4e4b\u95f4\u7684\u6865\u6881\uff0c\u8bc1\u660e\u4e86\u7c98\u6027CBFs\u80fd\u591f\u63d0\u4f9bCBF\u5f0f\u7684\u5b89\u5168\u4fdd\u8bc1\uff0c\u5305\u62ec\u63a7\u5236\u4e0d\u53d8\u6027\u548c\u8fb9\u754c\u5e73\u6ed1\u63a5\u8fd1\u7279\u6027\u3002", "conclusion": "\u7c98\u6027CBFs\u662f\u8fde\u63a5CBF\u548cHJR\u6846\u67b6\u7684\u5173\u952e\uff0c\u5b83\u4eec\u4e0d\u4ec5\u4fdd\u6301\u4e86CBF\u7684\u5b89\u5168\u4fdd\u8bc1\u7279\u6027\uff0c\u8fd8\u5177\u6709\u66f4\u597d\u7684\u7406\u8bba\u6027\u8d28\uff0c\u4e3a\u5b89\u5168\u63a7\u5236\u63d0\u4f9b\u4e86\u66f4\u7edf\u4e00\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2510.09698", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.09698", "abs": "https://arxiv.org/abs/2510.09698", "authors": ["Shiliang Zhang", "Sabita Maharjan", "Kai Strunz", "Jan Christian Bryne"], "title": "Norwegian Electricity in Geographic Dataset (NoreGeo)", "comment": null, "summary": "Geographic data is vital in understanding, analyzing, and contextualizing\nenergy usage at the regional level within electricity systems. While geospatial\nvisualizations of electricity infrastructure and distributions of production\nand consumption are available from governmental and third-party sources, these\nsources are often disparate, and compatible geographic datasets remain scarce.\nIn this paper, we present a comprehensive geographic dataset representing the\nelectricity system in Norway. We collect data from multiple authoritative\nsources, process it into widely accepted formats, and generate interactive maps\nbased on this data. Our dataset includes information for each municipality in\nNorway for the year 2024, encompassing electricity infrastructure, consumption,\nrenewable and conventional production, main power grid topology, relevant\nnatural resources, and population demographics. This work results in a\nformatted geographic dataset that integrates diverse informational resources,\nalong with openly released interactive maps. We anticipate that our dataset\nwill alleviate software incompatibilities in data retrieval, and facilitate\njoint analyses on regional electricity system for energy researchers,\nstakeholders, and developers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u632a\u5a01\u7535\u529b\u7cfb\u7edf\u5730\u7406\u6570\u636e\u96c6\uff0c\u6574\u5408\u4e86\u6765\u81ea\u591a\u4e2a\u6743\u5a01\u6765\u6e90\u7684\u6570\u636e\uff0c\u751f\u6210\u4e862024\u5e74\u632a\u5a01\u5404\u5e02\u9547\u7684\u7535\u529b\u57fa\u7840\u8bbe\u65bd\u3001\u6d88\u8d39\u3001\u751f\u4ea7\u3001\u7535\u7f51\u62d3\u6251\u7b49\u4fe1\u606f\u7684\u4ea4\u4e92\u5f0f\u5730\u56fe\u3002", "motivation": "\u73b0\u6709\u7684\u5730\u7406\u7535\u529b\u6570\u636e\u6765\u6e90\u5206\u6563\u4e14\u517c\u5bb9\u6027\u5dee\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u632a\u5a01\u7535\u529b\u7cfb\u7edf\u5730\u7406\u6570\u636e\u96c6\u6765\u652f\u6301\u533a\u57df\u80fd\u6e90\u5206\u6790\u3002", "method": "\u4ece\u591a\u4e2a\u6743\u5a01\u6765\u6e90\u6536\u96c6\u6570\u636e\uff0c\u5904\u7406\u6210\u5e7f\u6cdb\u63a5\u53d7\u7684\u683c\u5f0f\uff0c\u57fa\u4e8e\u8fd9\u4e9b\u6570\u636e\u751f\u6210\u4ea4\u4e92\u5f0f\u5730\u56fe\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u683c\u5f0f\u5316\u7684\u5730\u7406\u6570\u636e\u96c6\uff0c\u6574\u5408\u4e86\u7535\u529b\u57fa\u7840\u8bbe\u65bd\u3001\u6d88\u8d39\u3001\u53ef\u518d\u751f\u80fd\u6e90\u548c\u4f20\u7edf\u80fd\u6e90\u751f\u4ea7\u3001\u4e3b\u7535\u7f51\u62d3\u6251\u3001\u76f8\u5173\u81ea\u7136\u8d44\u6e90\u548c\u4eba\u53e3\u7edf\u8ba1\u6570\u636e\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u5c06\u7f13\u89e3\u6570\u636e\u68c0\u7d22\u4e2d\u7684\u8f6f\u4ef6\u4e0d\u517c\u5bb9\u95ee\u9898\uff0c\u4e3a\u80fd\u6e90\u7814\u7a76\u4eba\u5458\u3001\u5229\u76ca\u76f8\u5173\u8005\u548c\u5f00\u53d1\u8005\u4fc3\u8fdb\u533a\u57df\u7535\u529b\u7cfb\u7edf\u7684\u8054\u5408\u5206\u6790\u3002"}}
{"id": "2510.09980", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.09980", "abs": "https://arxiv.org/abs/2510.09980", "authors": ["Jingyuan Sun", "Hongyu Ji", "Zihan Qu", "Chaoran Wang", "Mingyu Zhang"], "title": "ATRos: Learning Energy-Efficient Agile Locomotion for Wheeled-legged Robots", "comment": "4 pages, 2 figures, submitted to IROS 2025 wheeled-legged workshop", "summary": "Hybrid locomotion of wheeled-legged robots has recently attracted increasing\nattention due to their advantages of combining the agility of legged locomotion\nand the efficiency of wheeled motion. But along with expanded performance, the\nwhole-body control of wheeled-legged robots remains challenging for hybrid\nlocomotion. In this paper, we present ATRos, a reinforcement learning\n(RL)-based hybrid locomotion framework to achieve hybrid walking-driving\nmotions on the wheeled-legged robot. Without giving predefined gait patterns,\nour planner aims to intelligently coordinate simultaneous wheel and leg\nmovements, thereby achieving improved terrain adaptability and improved energy\nefficiency. Based on RL techniques, our approach constructs a prediction policy\nnetwork that could estimate external environmental states from proprioceptive\nsensory information, and the outputs are then fed into an actor critic network\nto produce optimal joint commands. The feasibility of the proposed framework is\nvalidated through both simulations and real-world experiments across diverse\nterrains, including flat ground, stairs, and grassy surfaces. The hybrid\nlocomotion framework shows robust performance over various unseen terrains,\nhighlighting its generalization capability.", "AI": {"tldr": "\u63d0\u51faATRos\u6846\u67b6\uff0c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u8f6e\u817f\u673a\u5668\u4eba\u6df7\u5408\u8fd0\u52a8\u63a7\u5236\u65b9\u6cd5\uff0c\u80fd\u667a\u80fd\u534f\u8c03\u8f6e\u5b50\u548c\u817f\u7684\u8fd0\u52a8\uff0c\u5728\u591a\u79cd\u5730\u5f62\u4e0a\u5b9e\u73b0\u7a33\u5065\u7684\u884c\u8d70-\u9a7e\u9a76\u6df7\u5408\u8fd0\u52a8\u3002", "motivation": "\u8f6e\u817f\u673a\u5668\u4eba\u7ed3\u5408\u4e86\u817f\u5f0f\u8fd0\u52a8\u7684\u7075\u6d3b\u6027\u548c\u8f6e\u5f0f\u8fd0\u52a8\u7684\u9ad8\u6548\u6027\uff0c\u4f46\u5176\u5168\u8eab\u63a7\u5236\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u9700\u8981\u5f00\u53d1\u667a\u80fd\u534f\u8c03\u8f6e\u817f\u8fd0\u52a8\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u5730\u5f62\u9002\u5e94\u6027\u548c\u80fd\u6e90\u6548\u7387\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u6280\u672f\u6784\u5efa\u9884\u6d4b\u7b56\u7565\u7f51\u7edc\uff0c\u4ece\u672c\u4f53\u611f\u89c9\u4fe1\u606f\u4f30\u8ba1\u5916\u90e8\u73af\u5883\u72b6\u6001\uff0c\u7136\u540e\u5c06\u8f93\u51fa\u8f93\u5165\u5230actor-critic\u7f51\u7edc\u751f\u6210\u6700\u4f18\u5173\u8282\u6307\u4ee4\uff0c\u65e0\u9700\u9884\u5b9a\u4e49\u6b65\u6001\u6a21\u5f0f\u3002", "result": "\u5728\u5e73\u5766\u5730\u9762\u3001\u697c\u68af\u548c\u8349\u5730\u7b49\u591a\u79cd\u5730\u5f62\u4e0a\u8fdb\u884c\u4e86\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u6df7\u5408\u8fd0\u52a8\u6846\u67b6\u5728\u5404\u79cd\u672a\u89c1\u5730\u5f62\u4e0a\u8868\u73b0\u51fa\u7a33\u5065\u6027\u80fd\uff0c\u5c55\u73b0\u4e86\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "ATRos\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u8f6e\u817f\u673a\u5668\u4eba\u7684\u667a\u80fd\u6df7\u5408\u8fd0\u52a8\u63a7\u5236\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u534f\u8c03\u8f6e\u817f\u8fd0\u52a8\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5730\u5f62\u9002\u5e94\u6027\u548c\u80fd\u6e90\u6548\u7387\uff0c\u5177\u6709\u5f88\u597d\u7684\u5b9e\u9645\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2510.09905", "categories": ["cs.AI", "cs.CL", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.09905", "abs": "https://arxiv.org/abs/2510.09905", "authors": ["Xi Fang", "Weijie Xu", "Yuchong Zhang", "Stephanie Eckman", "Scott Nickleach", "Chandan K. Reddy"], "title": "The Personalization Trap: How User Memory Alters Emotional Reasoning in LLMs", "comment": "12 pages 5 figures", "summary": "When an AI assistant remembers that Sarah is a single mother working two\njobs, does it interpret her stress differently than if she were a wealthy\nexecutive? As personalized AI systems increasingly incorporate long-term user\nmemory, understanding how this memory shapes emotional reasoning is critical.\nWe investigate how user memory affects emotional intelligence in large language\nmodels (LLMs) by evaluating 15 models on human validated emotional intelligence\ntests. We find that identical scenarios paired with different user profiles\nproduce systematically divergent emotional interpretations. Across validated\nuser independent emotional scenarios and diverse user profiles, systematic\nbiases emerged in several high-performing LLMs where advantaged profiles\nreceived more accurate emotional interpretations. Moreover, LLMs demonstrate\nsignificant disparities across demographic factors in emotion understanding and\nsupportive recommendations tasks, indicating that personalization mechanisms\ncan embed social hierarchies into models emotional reasoning. These results\nhighlight a key challenge for memory enhanced AI: systems designed for\npersonalization may inadvertently reinforce social inequalities.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5f53AI\u7cfb\u7edf\u8bb0\u4f4f\u7528\u6237\u4e2a\u4eba\u4fe1\u606f\u65f6\uff0c\u4f1a\u5728\u60c5\u611f\u63a8\u7406\u4e2d\u4ea7\u751f\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u5bfc\u81f4\u5bf9\u4f18\u52bf\u7fa4\u4f53\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u60c5\u611f\u89e3\u8bfb\uff0c\u4ece\u800c\u53ef\u80fd\u5f3a\u5316\u793e\u4f1a\u4e0d\u5e73\u7b49\u3002", "motivation": "\u968f\u7740\u4e2a\u6027\u5316AI\u7cfb\u7edf\u8d8a\u6765\u8d8a\u591a\u5730\u6574\u5408\u957f\u671f\u7528\u6237\u8bb0\u5fc6\uff0c\u7406\u89e3\u8fd9\u79cd\u8bb0\u5fc6\u5982\u4f55\u5851\u9020\u60c5\u611f\u63a8\u7406\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u8bc4\u4f3015\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4eba\u7c7b\u9a8c\u8bc1\u7684\u60c5\u611f\u667a\u80fd\u6d4b\u8bd5\u4e0a\u7684\u8868\u73b0\uff0c\u6bd4\u8f83\u76f8\u540c\u60c5\u5883\u4e0b\u4e0d\u540c\u7528\u6237\u6863\u6848\u7684\u60c5\u611f\u89e3\u8bfb\u5dee\u5f02\u3002", "result": "\u53d1\u73b0\u591a\u4e2a\u9ad8\u6027\u80fdLLM\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u4f18\u52bf\u7fa4\u4f53\u83b7\u5f97\u66f4\u51c6\u786e\u7684\u60c5\u611f\u89e3\u8bfb\uff1b\u5728\u60c5\u611f\u7406\u89e3\u548c\u652f\u6301\u5efa\u8bae\u4efb\u52a1\u4e2d\uff0c\u4e0d\u540c\u4eba\u53e3\u7edf\u8ba1\u56e0\u7d20\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u4e3a\u4e2a\u6027\u5316\u8bbe\u8ba1\u7684\u7cfb\u7edf\u53ef\u80fd\u65e0\u610f\u4e2d\u5f3a\u5316\u793e\u4f1a\u4e0d\u5e73\u7b49\uff0c\u8fd9\u662f\u8bb0\u5fc6\u589e\u5f3aAI\u9762\u4e34\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2510.11315", "categories": ["stat.AP", "60E05, 62P05"], "pdf": "https://arxiv.org/pdf/2510.11315", "abs": "https://arxiv.org/abs/2510.11315", "authors": ["Pankaj Kumar", "Vivek Vijay"], "title": "A heavy-tail arctan-based mixture model for modelling and measuring actuarial risk", "comment": null, "summary": "Heavy-tailed probability distributions are extremely useful and play a\ncrucial role in modeling different types of financial data sets. This study\npresents a two-pronged methodology. First, a mixture probability distribution\nis created by combining Gaussian and Rayleigh distributions using the\narctangent transformation, aimed at producing heavier-tailed features and\nenhancing alignment with real market data. Some statistical properties of the\nproposed model are also discussed. Furthermore, essential actuarial risk\nevaluation instruments, such as value-at-risk (VaR), tail value-at-risk (TVaR)\nand tail variance (TV) are employed for efficient risk management practices.\nLastly, an application is provided using an insurance dataset to demonstrate\nthe applicability of the proposed model. The proposed model demonstrates\nsuperior fitting performance compared to current baseline distributions,\nshowcasing its practical value in financial risk evaluation. The combination of\nGaussian and Rayleigh distributions through arctangent transformation is\nparticularly successful in representing extreme market behaviour and tail\ndependencies that are frequently found in real-world financial data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u53cd\u6b63\u5207\u53d8\u6362\u7ed3\u5408\u9ad8\u65af\u5206\u5e03\u548c\u745e\u5229\u5206\u5e03\u7684\u6df7\u5408\u6982\u7387\u5206\u5e03\u6a21\u578b\uff0c\u7528\u4e8e\u91d1\u878d\u98ce\u9669\u5efa\u6a21\uff0c\u8be5\u6a21\u578b\u5728\u62df\u5408\u771f\u5b9e\u5e02\u573a\u6570\u636e\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u5206\u5e03\u3002", "motivation": "\u91cd\u5c3e\u6982\u7387\u5206\u5e03\u5728\u91d1\u878d\u6570\u636e\u5efa\u6a21\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u5206\u5e03\u96be\u4ee5\u5145\u5206\u6355\u6349\u771f\u5b9e\u5e02\u573a\u6570\u636e\u7684\u6781\u7aef\u884c\u4e3a\u548c\u5c3e\u90e8\u4f9d\u8d56\u7279\u5f81\u3002", "method": "\u4f7f\u7528\u53cd\u6b63\u5207\u53d8\u6362\u5c06\u9ad8\u65af\u5206\u5e03\u548c\u745e\u5229\u5206\u5e03\u7ed3\u5408\u521b\u5efa\u6df7\u5408\u6982\u7387\u5206\u5e03\uff0c\u5e76\u8ba8\u8bba\u5176\u7edf\u8ba1\u7279\u6027\uff0c\u5e94\u7528VaR\u3001TVaR\u548cTV\u7b49\u98ce\u9669\u5ea6\u91cf\u5de5\u5177\u8fdb\u884c\u98ce\u9669\u7ba1\u7406\u3002", "result": "\u5728\u4fdd\u9669\u6570\u636e\u96c6\u4e0a\u7684\u5e94\u7528\u8868\u660e\uff0c\u6240\u63d0\u6a21\u578b\u6bd4\u73b0\u6709\u57fa\u51c6\u5206\u5e03\u5177\u6709\u66f4\u597d\u7684\u62df\u5408\u6027\u80fd\uff0c\u80fd\u6709\u6548\u8868\u793a\u771f\u5b9e\u91d1\u878d\u6570\u636e\u4e2d\u7684\u6781\u7aef\u5e02\u573a\u884c\u4e3a\u548c\u5c3e\u90e8\u4f9d\u8d56\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6df7\u5408\u5206\u5e03\u6a21\u578b\u5728\u91d1\u878d\u98ce\u9669\u8bc4\u4f30\u4e2d\u5177\u6709\u5b9e\u7528\u4ef7\u503c\uff0c\u7279\u522b\u662f\u5728\u6355\u6349\u6781\u7aef\u5e02\u573a\u884c\u4e3a\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2510.09943", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.09943", "abs": "https://arxiv.org/abs/2510.09943", "authors": ["Yutian Pang", "Andrew Kendall", "John-Paul Clarke"], "title": "Modeling the Impact of Communication and Human Uncertainties on Runway Capacity in Terminal Airspace", "comment": null, "summary": "We investigate the potential impact of communication and human performance\nuncertainties on runway operations. Specifically, we consider these impacts\nwithin the context of an arrival scenario with two converging flows: a\nstraight-in approach stream and a downwind stream merging into it. Both arrival\nstream are modeled using a modified Possion distribution that incorporate the\nseparation minima as well as the runway occupancy time. Various system level\nuncertainties are addressed in this process, including communication link- and\nhuman-related uncertainties. In this research, we first build a Monte\nCarlo-based discrete-time simulation, where aircraft arrivals are generated by\nmodified Poisson processes subject to minimum separation constraints,\nsimulating various traffic operations. The merging logic incorporates standard\nbank angle continuous turn-to-final, pilot response delays, and dynamic gap\navailability in real time. Then, we investigate an automated final approach\nvectoring model (i.e., Auto-ATC), in which inverse optimal control is used to\nlearn decision advisories from human expert records. By augmenting trajectories\nand incorporating the aforementioned uncertainties into the planning scenario,\nwe create a setup analogous to the discrete event simulation. For both studies,\nrunway capacity is measured by runway throughput, the fraction of downwind\narrivals that merge immediately without holding, and the average delay (i.e.,\nholding time/distance) experienced on the downwind leg. This research provides\na method for runway capacity estimation in merging scenarios, and demonstrates\nthat aeronautical communication link uncertainties significantly affect runway\ncapacity in current voice-based operations, whereas the impact can be mitigated\nin autonomous operational settings.", "AI": {"tldr": "\u7814\u7a76\u901a\u4fe1\u548c\u4eba\u4e3a\u4e0d\u786e\u5b9a\u6027\u5bf9\u8dd1\u9053\u8fd0\u884c\u7684\u5f71\u54cd\uff0c\u7279\u522b\u5173\u6ce8\u4e24\u6761\u6c47\u805a\u6d41\uff08\u76f4\u8fdb\u548c\u987a\u98ce\uff09\u7684\u5408\u5e76\u573a\u666f\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6a21\u62df\u548c\u81ea\u52a8ATC\u6a21\u578b\u5206\u6790\u8dd1\u9053\u5bb9\u91cf\u3002", "motivation": "\u8bc4\u4f30\u901a\u4fe1\u94fe\u8def\u548c\u4eba\u4e3a\u76f8\u5173\u4e0d\u786e\u5b9a\u6027\u5bf9\u8dd1\u9053\u8fd0\u884c\u6548\u7387\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u5f53\u524d\u8bed\u97f3\u64cd\u4f5c\u548c\u672a\u6765\u81ea\u4e3b\u64cd\u4f5c\u73af\u5883\u4e0b\u7684\u5dee\u5f02\u3002", "method": "\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u79bb\u6563\u65f6\u95f4\u6a21\u62df\u548c\u81ea\u52a8\u6700\u7ec8\u8fdb\u8fd1\u5f15\u5bfc\u6a21\u578b\uff08Auto-ATC\uff09\uff0c\u7ed3\u5408\u6539\u8fdb\u7684\u6cca\u677e\u5206\u5e03\u751f\u6210\u98de\u673a\u5230\u8fbe\uff0c\u8003\u8651\u6700\u5c0f\u95f4\u9694\u7ea6\u675f\u3001\u6807\u51c6\u8f6c\u5f2f\u903b\u8f91\u548c\u5b9e\u65f6\u52a8\u6001\u95f4\u9699\u53ef\u7528\u6027\u3002", "result": "\u822a\u7a7a\u901a\u4fe1\u94fe\u8def\u4e0d\u786e\u5b9a\u6027\u5728\u5f53\u524d\u8bed\u97f3\u64cd\u4f5c\u4e2d\u663e\u8457\u5f71\u54cd\u8dd1\u9053\u5bb9\u91cf\uff0c\u4f46\u5728\u81ea\u4e3b\u64cd\u4f5c\u73af\u5883\u4e2d\u8fd9\u79cd\u5f71\u54cd\u53ef\u4ee5\u5f97\u5230\u7f13\u89e3\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u5728\u5408\u5e76\u573a\u666f\u4e0b\u4f30\u7b97\u8dd1\u9053\u5bb9\u91cf\u7684\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u901a\u4fe1\u4e0d\u786e\u5b9a\u6027\u5bf9\u8fd0\u884c\u6548\u7387\u7684\u91cd\u8981\u5f71\u54cd\u4ee5\u53ca\u81ea\u4e3b\u64cd\u4f5c\u7684\u6f5c\u5728\u4f18\u52bf\u3002"}}
{"id": "2510.09840", "categories": ["cs.CY", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.09840", "abs": "https://arxiv.org/abs/2510.09840", "authors": ["Jarrad Hope", "Peter Ludlow"], "title": "Farewell to Westphalia: Crypto Sovereignty and Post-Nation-State Governaance", "comment": null, "summary": "We argue that the principal application for blockchain technology will not be\nin the financial sector, but rather in maintaining decentralized human\ngovernance, from archives to transparent policies encoded in the blockchain in\nthe form of smart contracts.. Such decentralized, blockchain-grounded\ngovernance comes not a moment too soon, as nation states are dissolving before\nour eyes. Will blockchain-based communities replace the nation state? What are\nthe prospects and dangers of this development?", "AI": {"tldr": "\u533a\u5757\u94fe\u6280\u672f\u7684\u4e3b\u8981\u5e94\u7528\u5c06\u4e0d\u662f\u91d1\u878d\u9886\u57df\uff0c\u800c\u662f\u7ef4\u62a4\u53bb\u4e2d\u5fc3\u5316\u7684\u4eba\u7c7b\u6cbb\u7406\uff0c\u5305\u62ec\u6863\u6848\u7ba1\u7406\u548c\u4ee5\u667a\u80fd\u5408\u7ea6\u5f62\u5f0f\u7f16\u7801\u7684\u900f\u660e\u653f\u7b56\u3002", "motivation": "\u968f\u7740\u6c11\u65cf\u56fd\u5bb6\u6b63\u5728\u74e6\u89e3\uff0c\u53bb\u4e2d\u5fc3\u5316\u7684\u533a\u5757\u94fe\u6cbb\u7406\u663e\u5f97\u5c24\u4e3a\u7d27\u8feb\uff0c\u63a2\u8ba8\u533a\u5757\u94fe\u793e\u533a\u53d6\u4ee3\u6c11\u65cf\u56fd\u5bb6\u7684\u53ef\u80fd\u6027\u548c\u98ce\u9669\u3002", "method": "\u901a\u8fc7\u5c06\u6cbb\u7406\u653f\u7b56\u548c\u6863\u6848\u4ee5\u667a\u80fd\u5408\u7ea6\u5f62\u5f0f\u7f16\u7801\u5728\u533a\u5757\u94fe\u4e0a\uff0c\u5b9e\u73b0\u900f\u660e\u3001\u53bb\u4e2d\u5fc3\u5316\u7684\u6cbb\u7406\u4f53\u7cfb\u3002", "result": "\u63d0\u51fa\u4e86\u533a\u5757\u94fe\u6280\u672f\u5728\u6cbb\u7406\u9886\u57df\u7684\u5e94\u7528\u524d\u666f\uff0c\u5f3a\u8c03\u5176\u4f5c\u4e3a\u6c11\u65cf\u56fd\u5bb6\u66ff\u4ee3\u65b9\u6848\u7684\u6f5c\u529b\u3002", "conclusion": "\u533a\u5757\u94fe\u6280\u672f\u6709\u671b\u5728\u53bb\u4e2d\u5fc3\u5316\u6cbb\u7406\u4e2d\u53d1\u6325\u5173\u952e\u4f5c\u7528\uff0c\u4f46\u9700\u8981\u4ed4\u7ec6\u8bc4\u4f30\u5176\u53d1\u5c55\u524d\u666f\u548c\u6f5c\u5728\u98ce\u9669\u3002"}}
{"id": "2510.10016", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10016", "abs": "https://arxiv.org/abs/2510.10016", "authors": ["Shahid Ansari", "Vivek Gupta", "Bishakh Bhattacharya"], "title": "Hybrid Robotic Meta-gripper for Tomato Harvesting: Analysis of Auxetic Structures with Lattice Orientation Variations", "comment": null, "summary": "The agricultural sector is rapidly evolving to meet growing global food\ndemands, yet tasks like fruit and vegetable handling remain labor-intensive,\ncausing inefficiencies and post-harvest losses. Automation, particularly\nselective harvesting, offers a viable solution, with soft robotics emerging as\na key enabler. This study introduces a novel hybrid gripper for tomato\nharvesting, incorporating a rigid outer frame with a soft auxetic internal\nlattice. The six-finger, 3D caging-effect design enables gentle yet secure\ngrasping in unstructured environments. Uniquely, the work investigates the\neffect of auxetic lattice orientation on grasping conformability, combining\nexperimental validation with 2D Digital Image Correlation (DIC) and nonlinear\nfinite element analysis (FEA). Auxetic configurations with unit cell\ninclinations of 0 deg, 30 deg, 45 deg, and 60 deg are evaluated, and their\ngrasping forces, deformation responses, and motor torque requirements are\nsystematically compared. Results demonstrate that lattice orientation strongly\ninfluences compliance, contact forces, and energy efficiency, with distinct\nadvantages across configurations. This comparative framework highlights the\nnovelty of tailoring auxetic geometries to optimize robotic gripper\nperformance. The findings provide new insights into soft-rigid hybrid gripper\ndesign, advancing automation strategies for precision agriculture while\nminimizing crop damage.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u7528\u4e8e\u756a\u8304\u91c7\u6458\u7684\u6df7\u5408\u5939\u6301\u5668\uff0c\u7ed3\u5408\u521a\u6027\u5916\u6846\u548c\u8f6f\u6027\u62c9\u80c0\u5185\u90e8\u6676\u683c\u7ed3\u6784\uff0c\u901a\u8fc7\u4e0d\u540c\u6676\u683c\u53d6\u5411\u4f18\u5316\u6293\u53d6\u6027\u80fd\u3002", "motivation": "\u519c\u4e1a\u81ea\u52a8\u5316\u9700\u6c42\u589e\u957f\uff0c\u7279\u522b\u662f\u9009\u62e9\u6027\u91c7\u6458\u4efb\u52a1\u4ecd\u4f9d\u8d56\u4eba\u5de5\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u548c\u6536\u83b7\u540e\u635f\u5931\u3002\u8f6f\u4f53\u673a\u5668\u4eba\u6280\u672f\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u516d\u63073D\u7b3c\u5f0f\u6548\u5e94\u5939\u6301\u5668\uff0c\u7814\u7a76\u62c9\u80c0\u6676\u683c\u53d6\u5411\uff080\u00b0\u300130\u00b0\u300145\u00b0\u300160\u00b0\uff09\u5bf9\u6293\u53d6\u9002\u5e94\u6027\u7684\u5f71\u54cd\uff0c\u7ed3\u5408\u5b9e\u9a8c\u9a8c\u8bc1\u30012D\u6570\u5b57\u56fe\u50cf\u76f8\u5173\u6027\u548c\u975e\u7ebf\u6027\u6709\u9650\u5143\u5206\u6790\u3002", "result": "\u6676\u683c\u53d6\u5411\u663e\u8457\u5f71\u54cd\u5939\u6301\u5668\u7684\u67d4\u987a\u6027\u3001\u63a5\u89e6\u529b\u548c\u80fd\u91cf\u6548\u7387\uff0c\u4e0d\u540c\u914d\u7f6e\u5177\u6709\u5404\u81ea\u4f18\u52bf\uff0c\u4e3a\u4f18\u5316\u673a\u5668\u4eba\u5939\u6301\u5668\u6027\u80fd\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8f6f\u521a\u6027\u6df7\u5408\u5939\u6301\u5668\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u63a8\u8fdb\u4e86\u7cbe\u51c6\u519c\u4e1a\u81ea\u52a8\u5316\u7b56\u7565\uff0c\u540c\u65f6\u6700\u5927\u9650\u5ea6\u51cf\u5c11\u4f5c\u7269\u635f\u4f24\u3002"}}
{"id": "2510.09970", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09970", "abs": "https://arxiv.org/abs/2510.09970", "authors": ["Olivia Peiyu Wang", "Tashvi Bansal", "Ryan Bai", "Emily M. Chui", "Leilani H. Gilpin"], "title": "Follow My Lead: Logical Fallacy Classification with Knowledge-Augmented LLMs", "comment": "Accepted as a poster at the Twelfth Annual Conference on Advances in\n  Cognitive Systems. 21 pages, 7 figures and 1 table", "summary": "Large Language Models (LLMs) suffer from critical reasoning gaps, including a\ntendency to hallucinate and poor accuracy in classifying logical fallacies.\nThis limitation stems from their default System 1 processing, which is fast and\nintuitive, whereas reliable reasoning requires the deliberate, effortful System\n2 approach (Kahneman, 2011; Li et al., 2025). Since full System 2 training is\noften prohibitively expensive, we explore a low-cost, instruction-based\nintervention to bridge this gap. Our methodology introduces a novel stepwise\ninstruction dataset that decomposes fallacy classification into a series of\natomic procedural steps (simple binary questions). We further augment this with\na final verification step where models consult a relational knowledge graph of\nrelated fallacies. This procedural, rule-based intervention yields a\nsignificant improvement in LLM logical fallacy classification. Crucially, the\napproach also provides enhanced transparency into the LLMs' decision-making,\nhighlighting a practical pathway for Neuro-symbolic architectures to address\nLLM reasoning deficits.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f4e\u6210\u672c\u3001\u57fa\u4e8e\u6307\u4ee4\u7684\u5e72\u9884\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u8c2c\u8bef\u5206\u7c7b\u5206\u89e3\u4e3a\u539f\u5b50\u6b65\u9aa4\u5e76\u5f15\u5165\u77e5\u8bc6\u56fe\u8c31\u9a8c\u8bc1\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u7684\u903b\u8f91\u8c2c\u8bef\u5206\u7c7b\u80fd\u529b\u3002", "motivation": "LLM\u5b58\u5728\u5173\u952e\u63a8\u7406\u7f3a\u9677\uff0c\u5305\u62ec\u5e7b\u89c9\u503e\u5411\u548c\u903b\u8f91\u8c2c\u8bef\u5206\u7c7b\u51c6\u786e\u6027\u5dee\uff0c\u8fd9\u6e90\u4e8e\u5176\u9ed8\u8ba4\u7684\u5feb\u901f\u76f4\u89c9\u5f0f\u7cfb\u7edf1\u5904\u7406\uff0c\u800c\u53ef\u9760\u63a8\u7406\u9700\u8981\u6df1\u601d\u719f\u8651\u7684\u7cfb\u7edf2\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u9010\u6b65\u6307\u4ee4\u6570\u636e\u96c6\uff0c\u5c06\u8c2c\u8bef\u5206\u7c7b\u5206\u89e3\u4e3a\u4e00\u7cfb\u5217\u539f\u5b50\u7a0b\u5e8f\u6b65\u9aa4\uff08\u7b80\u5355\u4e8c\u5143\u95ee\u9898\uff09\uff0c\u5e76\u901a\u8fc7\u54a8\u8be2\u76f8\u5173\u8c2c\u8bef\u5173\u7cfb\u77e5\u8bc6\u56fe\u8c31\u8fdb\u884c\u6700\u7ec8\u9a8c\u8bc1\u3002", "result": "\u8fd9\u79cd\u57fa\u4e8e\u89c4\u5219\u7684\u5e72\u9884\u663e\u8457\u63d0\u9ad8\u4e86LLM\u7684\u903b\u8f91\u8c2c\u8bef\u5206\u7c7b\u80fd\u529b\uff0c\u5e76\u4e3a\u51b3\u7b56\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u900f\u660e\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\u89e3\u51b3LLM\u63a8\u7406\u7f3a\u9677\u63d0\u4f9b\u4e86\u4e00\u6761\u5b9e\u7528\u8def\u5f84\uff0c\u5c55\u793a\u4e86\u4f4e\u6210\u672c\u6307\u4ee4\u5e72\u9884\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.11485", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.11485", "abs": "https://arxiv.org/abs/2510.11485", "authors": ["Emiliano Seri", "Francesco Biso", "Gianluigi Bovesecchi", "Nikolaos Katsoulas", "Cristina Cornaro"], "title": "Multi-State Modeling of Greenhouse Cucumber Yield Dynamics Under Microclimate Effects", "comment": null, "summary": "Greenhouse decisions often rely on static thresholds, yet crop output\nswitches among microclimate-driven regimes. We frame daily cucumber yield as\ntransitions among three ordered states and fit a continuous-time,\ncovariate-dependent multistate model. Data come from four greenhouse\ncompartments in Volos, Greece (24 lines, 62 days). States are defined once from\ncontrol tertiles and applied across compartments. Transition intensities depend\non within-compartment z-scores of relative humidity (RH), photosynthetically\nactive radiation (PAR) and CO2, plus fixed effects.\n  Results show an inherent upward drift through the medium state, \"sticky\"\nlow-yield spells unless conditions improve, and short-horizon persistence once\nhigh yield is reached. RH and PAR are dominant levers, accelerating upgrades\nand damping regressions; day-to-day CO2 deviations show no clear pooled signal.\nResidual differences between compartments are modest.\n  By mapping intensities to 7--30 day probabilities, the model yields\nactionable guidance for humidity and lighting and a lightweight, interpretable\ncomponent for greenhouse digital twins.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06\u9ec4\u74dc\u65e5\u4ea7\u91cf\u5efa\u6a21\u4e3a\u4e09\u4e2a\u6709\u5e8f\u72b6\u6001\u4e4b\u95f4\u7684\u8f6c\u6362\uff0c\u4f7f\u7528\u8fde\u7eed\u65f6\u95f4\u591a\u72b6\u6001\u6a21\u578b\u5206\u6790\u6e29\u5ba4\u5fae\u6c14\u5019\u56e0\u7d20\u5bf9\u4ea7\u91cf\u72b6\u6001\u8f6c\u6362\u7684\u5f71\u54cd\u3002", "motivation": "\u6e29\u5ba4\u51b3\u7b56\u901a\u5e38\u4f9d\u8d56\u9759\u6001\u9608\u503c\uff0c\u4f46\u4f5c\u7269\u4ea7\u91cf\u5b9e\u9645\u4e0a\u53d7\u5fae\u6c14\u5019\u9a71\u52a8\u7684\u591a\u79cd\u72b6\u6001\u8f6c\u6362\u5f71\u54cd\uff0c\u9700\u8981\u66f4\u52a8\u6001\u7684\u5efa\u6a21\u65b9\u6cd5\u6765\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u7ba1\u7406\u6307\u5bfc\u3002", "method": "\u57fa\u4e8e\u5e0c\u814aVolos\u56db\u4e2a\u6e29\u5ba4\u9694\u95f4\u7684\u6570\u636e\uff0824\u6761\u751f\u4ea7\u7ebf\uff0c62\u5929\uff09\uff0c\u5c06\u4ea7\u91cf\u5b9a\u4e49\u4e3a\u4e09\u4e2a\u6709\u5e8f\u72b6\u6001\uff0c\u4f7f\u7528\u8fde\u7eed\u65f6\u95f4\u3001\u534f\u53d8\u91cf\u4f9d\u8d56\u7684\u591a\u72b6\u6001\u6a21\u578b\uff0c\u5206\u6790\u76f8\u5bf9\u6e7f\u5ea6\u3001\u5149\u5408\u6709\u6548\u8f90\u5c04\u548cCO2\u5bf9\u72b6\u6001\u8f6c\u6362\u5f3a\u5ea6\u7684\u5f71\u54cd\u3002", "result": "\u7ed3\u679c\u663e\u793a\u4ea7\u91cf\u5b58\u5728\u5411\u4e0a\u6f02\u79fb\u8d8b\u52bf\uff0c\u4f4e\u4ea7\u72b6\u6001\u5177\u6709\"\u7c98\u6027\"\uff0c\u9ad8\u4ea7\u72b6\u6001\u5177\u6709\u77ed\u671f\u6301\u7eed\u6027\u3002\u76f8\u5bf9\u6e7f\u5ea6\u548c\u5149\u5408\u6709\u6548\u8f90\u5c04\u662f\u4e3b\u8981\u5f71\u54cd\u56e0\u7d20\uff0c\u80fd\u52a0\u901f\u4ea7\u91cf\u5347\u7ea7\u5e76\u51cf\u7f13\u8870\u9000\uff0c\u800cCO2\u7684\u65e5\u95f4\u53d8\u5316\u6ca1\u6709\u660e\u663e\u5f71\u54cd\u3002", "conclusion": "\u8be5\u6a21\u578b\u901a\u8fc7\u5c06\u8f6c\u6362\u5f3a\u5ea6\u6620\u5c04\u52307-30\u5929\u6982\u7387\uff0c\u4e3a\u6e7f\u5ea6\u548c\u5149\u7167\u7ba1\u7406\u63d0\u4f9b\u53ef\u64cd\u4f5c\u6307\u5bfc\uff0c\u5e76\u53ef\u4f5c\u4e3a\u6e29\u5ba4\u6570\u5b57\u5b6a\u751f\u7684\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u7ec4\u4ef6\u3002"}}
{"id": "2510.10202", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.10202", "abs": "https://arxiv.org/abs/2510.10202", "authors": ["Ayush Rai", "Shaoshuai Mou", "Brian D. O. Anderson"], "title": "Performance Index Shaping for Closed-loop Optimal Control", "comment": null, "summary": "The design of the performance index, also referred to as cost or reward\nshaping, is central to both optimal control and reinforcement learning, as it\ndirectly determines the behaviors, trade-offs, and objectives that the\nresulting control laws seek to achieve. A commonly used approach for this\ninference task in recent years is differentiable trajectory optimization, which\nallows gradients to be computed with respect to cost parameters by\ndifferentiating through an optimal control solver. However, this method often\nrequires repeated solving of the underlying optimal control problem at every\niteration, making the method computationally expensive. In this work, assuming\nknown dynamics, we propose a novel framework that analytically links the\nperformance index to the resulting closed-loop optimal control law, thereby\ntransforming a typically bi-level inverse problem into a tractable single-level\nformulation. Our approach is motivated by the question: given a closed-loop\ncontrol law that solves an infinite-horizon optimal control problem, how does\nthis law change when the performance index is modified with additional terms?\nThis formulation yields closed-form characterizations for broad classes of\nsystems and performance indices, which not only facilitate interpretation and\nstability analysis, but also provide insight into the robust stability and\ninput-to-state stable behavior of the resulting nonlinear closed-loop system.\nMoreover, this analytical perspective enables the generalization of our\napproach to diverse design objectives, yielding a unifying framework for\nperformance index shaping. Given specific design objectives, we propose a\nsystematic methodology to guide the shaping of the performance index and\nthereby design the resulting optimal control law.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6027\u80fd\u6307\u6807\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u6790\u65b9\u6cd5\u5c06\u6027\u80fd\u6307\u6807\u4e0e\u95ed\u73af\u6700\u4f18\u63a7\u5236\u5f8b\u8054\u7cfb\u8d77\u6765\uff0c\u5c06\u53cc\u5c42\u9006\u95ee\u9898\u8f6c\u5316\u4e3a\u5355\u5c42\u53ef\u5904\u7406\u5f62\u5f0f\u3002", "motivation": "\u4f20\u7edf\u53ef\u5fae\u5206\u8f68\u8ff9\u4f18\u5316\u65b9\u6cd5\u9700\u8981\u91cd\u590d\u6c42\u89e3\u6700\u4f18\u63a7\u5236\u95ee\u9898\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u89e3\u6790\u65b9\u6cd5\u76f4\u63a5\u5efa\u7acb\u6027\u80fd\u6307\u6807\u4e0e\u95ed\u73af\u63a7\u5236\u5f8b\u7684\u5173\u7cfb\u3002", "method": "\u5047\u8bbe\u5df2\u77e5\u7cfb\u7edf\u52a8\u6001\uff0c\u63d0\u51fa\u89e3\u6790\u6846\u67b6\u5c06\u6027\u80fd\u6307\u6807\u4e0e\u95ed\u73af\u6700\u4f18\u63a7\u5236\u5f8b\u76f4\u63a5\u5173\u8054\uff0c\u5c06\u53cc\u5c42\u9006\u95ee\u9898\u8f6c\u5316\u4e3a\u5355\u5c42\u53ef\u5904\u7406\u5f62\u5f0f\u3002", "result": "\u4e3a\u5e7f\u6cdb\u7c7b\u522b\u7684\u7cfb\u7edf\u548c\u6027\u80fd\u6307\u6807\u63d0\u4f9b\u95ed\u5f0f\u8868\u5f81\uff0c\u4fbf\u4e8e\u89e3\u91ca\u548c\u7a33\u5b9a\u6027\u5206\u6790\uff0c\u5e76\u6d1e\u5bdf\u975e\u7ebf\u6027\u95ed\u73af\u7cfb\u7edf\u7684\u9c81\u68d2\u7a33\u5b9a\u6027\u548c\u8f93\u5165\u72b6\u6001\u7a33\u5b9a\u884c\u4e3a\u3002", "conclusion": "\u8be5\u89e3\u6790\u89c6\u89d2\u4f7f\u65b9\u6cd5\u80fd\u591f\u63a8\u5e7f\u5230\u591a\u79cd\u8bbe\u8ba1\u76ee\u6807\uff0c\u5f62\u6210\u7edf\u4e00\u7684\u6027\u80fd\u6307\u6807\u8bbe\u8ba1\u6846\u67b6\uff0c\u5e76\u63d0\u51fa\u4e86\u7cfb\u7edf\u5316\u7684\u6027\u80fd\u6307\u6807\u8bbe\u8ba1\u65b9\u6cd5\u3002"}}
{"id": "2510.10176", "categories": ["cs.CY", "K.4.0"], "pdf": "https://arxiv.org/pdf/2510.10176", "abs": "https://arxiv.org/abs/2510.10176", "authors": ["Linda Rocco"], "title": "The Mechanical Yes-Man: Emancipatory AI Pedagogy in Higher Education", "comment": "7 pages, 2 figures. To be published in Concreta journal n. 26, 2025", "summary": "The proliferation of Large Language Models in higher education presents a\nfundamental challenge to traditional pedagogical frameworks. Drawing on Jacques\nRanci\\`ere's theory of intellectual emancipation, this paper examines how\ngenerative AI risks becoming a \"mechanical yes-man\" that reinforces passivity\nrather than fostering intellectual autonomy. Generative AI's statistical logic\nand lack of causal reasoning, combined with frictionless information access,\nthreatens to hollow out cognitive processes essential for genuine learning.\nThis creates a critical paradox: while generative AI systems are trained for\ncomplex reasoning, students increasingly use them to bypass the intellectual\nwork that builds such capabilities. The paper critiques both techno-optimistic\nand restrictive approaches to generative AI in education, proposing instead an\nemancipatory pedagogy grounded in verification, mastery, and co-inquiry. This\nframework positions generative AI as material for intellectual work rather than\na substitute for it, emphasising the cultivation of metacognitive awareness and\ncritical interrogation of AI outputs. It requires educators to engage directly\nwith these tools to guide students toward critical AI literacy, transforming\npedagogical authority from explication to critical interloping that models\nintellectual courage and collaborative inquiry.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8eRanci\u00e8re\u7684\u667a\u529b\u89e3\u653e\u7406\u8bba\uff0c\u6279\u5224\u751f\u6210\u5f0fAI\u5728\u9ad8\u7b49\u6559\u80b2\u4e2d\u53ef\u80fd\u5f3a\u5316\u5b66\u751f\u88ab\u52a8\u6027\u800c\u975e\u57f9\u517b\u667a\u529b\u81ea\u4e3b\u6027\uff0c\u63d0\u51fa\u57fa\u4e8e\u9a8c\u8bc1\u3001\u638c\u63e1\u548c\u5171\u540c\u63a2\u7a76\u7684\u89e3\u653e\u6027\u6559\u5b66\u6cd5\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5728\u9ad8\u7b49\u6559\u80b2\u4e2d\u7684\u666e\u53ca\u5bf9\u4f20\u7edf\u6559\u5b66\u6846\u67b6\u6784\u6210\u6839\u672c\u6311\u6218\uff0c\u5176\u7edf\u8ba1\u903b\u8f91\u548c\u65e0\u6469\u64e6\u4fe1\u606f\u8bbf\u95ee\u53ef\u80fd\u524a\u5f31\u8ba4\u77e5\u8fc7\u7a0b\uff0c\u5bfc\u81f4\u5b66\u751f\u7ed5\u8fc7\u667a\u529b\u5de5\u4f5c\uff0c\u5f62\u6210\u5173\u952e\u6096\u8bba\u3002", "method": "\u6279\u5224\u6280\u672f\u4e50\u89c2\u4e3b\u4e49\u548c\u5bf9\u751f\u6210\u5f0fAI\u7684\u9650\u5236\u6027\u65b9\u6cd5\uff0c\u63d0\u51fa\u5c06AI\u5b9a\u4f4d\u4e3a\u667a\u529b\u5de5\u4f5c\u6750\u6599\u800c\u975e\u66ff\u4ee3\u54c1\u7684\u89e3\u653e\u6027\u6559\u5b66\u6846\u67b6\uff0c\u5f3a\u8c03\u5143\u8ba4\u77e5\u610f\u8bc6\u548c\u6279\u5224\u6027\u5ba1\u89c6AI\u8f93\u51fa\u3002", "result": "\u6784\u5efa\u4e86\u57fa\u4e8e\u9a8c\u8bc1\u3001\u638c\u63e1\u548c\u5171\u540c\u63a2\u7a76\u7684\u6559\u5b66\u6846\u67b6\uff0c\u8981\u6c42\u6559\u80b2\u8005\u76f4\u63a5\u53c2\u4e0eAI\u5de5\u5177\uff0c\u5f15\u5bfc\u5b66\u751f\u53d1\u5c55\u6279\u5224\u6027AI\u7d20\u517b\uff0c\u5c06\u6559\u5b66\u6743\u5a01\u4ece\u89e3\u91ca\u8f6c\u53d8\u4e3a\u6279\u5224\u6027\u5e72\u9884\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5e94\u4f5c\u4e3a\u667a\u529b\u5de5\u4f5c\u6750\u6599\u800c\u975e\u66ff\u4ee3\u54c1\uff0c\u6559\u80b2\u8005\u9700\u8981\u5efa\u6a21\u667a\u529b\u52c7\u6c14\u548c\u534f\u4f5c\u63a2\u7a76\uff0c\u901a\u8fc7\u6279\u5224\u6027\u5e72\u9884\u57f9\u517b\u5b66\u751f\u7684\u667a\u529b\u81ea\u4e3b\u6027\u548c\u6279\u5224\u6027AI\u7d20\u517b\u3002"}}
{"id": "2510.10046", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10046", "abs": "https://arxiv.org/abs/2510.10046", "authors": ["Mingke Lu", "Shuaikang Wang", "Meng Guo"], "title": "LOMORO: Long-term Monitoring of Dynamic Targets with Minimum Robotic Fleet under Resource Constraints", "comment": "Accepted to IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS 2025)", "summary": "Long-term monitoring of numerous dynamic targets can be tedious for a human\noperator and infeasible for a single robot, e.g., to monitor wild flocks,\ndetect intruders, search and rescue. Fleets of autonomous robots can be\neffective by acting collaboratively and concurrently. However, the online\ncoordination is challenging due to the unknown behaviors of the targets and the\nlimited perception of each robot. Existing work often deploys all robots\navailable without minimizing the fleet size, or neglects the constraints on\ntheir resources such as battery and memory. This work proposes an online\ncoordination scheme called LOMORO for collaborative target monitoring, path\nrouting and resource charging. It includes three core components: (I) the\nmodeling of multi-robot task assignment problem under the constraints on\nresources and monitoring intervals; (II) the resource-aware task coordination\nalgorithm iterates between the high-level assignment of dynamic targets and the\nlow-level multi-objective routing via the Martin's algorithm; (III) the online\nadaptation algorithm in case of unpredictable target behaviors and robot\nfailures. It ensures the explicitly upper-bounded monitoring intervals for all\ntargets and the lower-bounded resource levels for all robots, while minimizing\nthe average number of active robots. The proposed methods are validated\nextensively via large-scale simulations against several baselines, under\ndifferent road networks, robot velocities, charging rates and monitoring\nintervals.", "AI": {"tldr": "\u63d0\u51faLOMORO\u5728\u7ebf\u534f\u8c03\u65b9\u6848\uff0c\u7528\u4e8e\u591a\u673a\u5668\u4eba\u534f\u4f5c\u76ee\u6807\u76d1\u63a7\u3001\u8def\u5f84\u89c4\u5212\u548c\u8d44\u6e90\u5145\u7535\uff0c\u786e\u4fdd\u76ee\u6807\u76d1\u63a7\u95f4\u9694\u4e0a\u9650\u548c\u673a\u5668\u4eba\u8d44\u6e90\u4e0b\u9650\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u6d3b\u8dc3\u673a\u5668\u4eba\u6570\u91cf\u3002", "motivation": "\u957f\u671f\u76d1\u63a7\u591a\u4e2a\u52a8\u6001\u76ee\u6807\u5bf9\u4eba\u7c7b\u64cd\u4f5c\u5458\u6765\u8bf4\u5f88\u7e41\u7410\uff0c\u5355\u4e2a\u673a\u5668\u4eba\u4e5f\u4e0d\u53ef\u884c\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u90e8\u7f72\u6240\u6709\u53ef\u7528\u673a\u5668\u4eba\u800c\u4e0d\u6700\u5c0f\u5316\u673a\u7fa4\u89c4\u6a21\uff0c\u8981\u4e48\u5ffd\u7565\u7535\u6c60\u548c\u5185\u5b58\u7b49\u8d44\u6e90\u7ea6\u675f\u3002", "method": "\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a(I)\u5728\u8d44\u6e90\u548c\u76d1\u63a7\u95f4\u9694\u7ea6\u675f\u4e0b\u5efa\u6a21\u591a\u673a\u5668\u4eba\u4efb\u52a1\u5206\u914d\u95ee\u9898\uff1b(II)\u8d44\u6e90\u611f\u77e5\u4efb\u52a1\u534f\u8c03\u7b97\u6cd5\uff0c\u901a\u8fc7Martin\u7b97\u6cd5\u5728\u9ad8\u5c42\u52a8\u6001\u76ee\u6807\u5206\u914d\u548c\u4f4e\u5c42\u591a\u76ee\u6807\u8def\u7531\u4e4b\u95f4\u8fed\u4ee3\uff1b(III)\u9488\u5bf9\u4e0d\u53ef\u9884\u6d4b\u76ee\u6807\u884c\u4e3a\u548c\u673a\u5668\u4eba\u6545\u969c\u7684\u5728\u7ebf\u9002\u5e94\u7b97\u6cd5\u3002", "result": "\u901a\u8fc7\u5927\u89c4\u6a21\u4eff\u771f\u9a8c\u8bc1\uff0c\u5728\u4e0d\u540c\u9053\u8def\u7f51\u7edc\u3001\u673a\u5668\u4eba\u901f\u5ea6\u3001\u5145\u7535\u901f\u7387\u548c\u76d1\u63a7\u95f4\u9694\u4e0b\uff0c\u4e0e\u591a\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "LOMORO\u65b9\u6848\u80fd\u6709\u6548\u786e\u4fdd\u6240\u6709\u76ee\u6807\u7684\u76d1\u63a7\u95f4\u9694\u4e0a\u9650\u548c\u6240\u6709\u673a\u5668\u4eba\u7684\u8d44\u6e90\u4e0b\u9650\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u5e73\u5747\u6d3b\u8dc3\u673a\u5668\u4eba\u6570\u91cf\u3002"}}
{"id": "2510.10002", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10002", "abs": "https://arxiv.org/abs/2510.10002", "authors": ["Pratik S. Sachdeva", "Tom van Nuenen"], "title": "Deliberative Dynamics and Value Alignment in LLM Debates", "comment": null, "summary": "As large language models (LLMs) are increasingly deployed in sensitive\neveryday contexts - offering personal advice, mental health support, and moral\nguidance - understanding their elicited values in navigating complex moral\nreasoning is essential. Most evaluations study this sociotechnical alignment\nthrough single-turn prompts, but it is unclear if these findings extend to\nmulti-turn settings where values emerge through dialogue, revision, and\nconsensus. We address this gap using LLM debate to examine deliberative\ndynamics and value alignment in multi-turn settings by prompting subsets of\nthree models (GPT-4.1, Claude 3.7 Sonnet, and Gemini 2.0 Flash) to collectively\nassign blame in 1,000 everyday dilemmas from Reddit's \"Am I the Asshole\"\ncommunity. We use both synchronous (parallel responses) and round-robin\n(sequential responses) formats to test order effects and verdict revision. Our\nfindings show striking behavioral differences. In the synchronous setting, GPT\nshowed strong inertia (0.6-3.1% revision rates) while Claude and Gemini were\nfar more flexible (28-41%). Value patterns also diverged: GPT emphasized\npersonal autonomy and direct communication, while Claude and Gemini prioritized\nempathetic dialogue. Certain values proved especially effective at driving\nverdict changes. We further find that deliberation format had a strong impact\non model behavior: GPT and Gemini stood out as highly conforming relative to\nClaude, with their verdict behavior strongly shaped by order effects. These\nresults show how deliberation format and model-specific behaviors shape moral\nreasoning in multi-turn interactions, underscoring that sociotechnical\nalignment depends on how systems structure dialogue as much as on their\noutputs.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u591a\u8f6e\u5bf9\u8bdd\u5b9e\u9a8c\u53d1\u73b0\uff0c\u4e0d\u540c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9053\u5fb7\u63a8\u7406\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u7684\u884c\u4e3a\u5dee\u5f02\uff0cGPT\u5f3a\u8c03\u4e2a\u4eba\u81ea\u4e3b\u6027\uff0cClaude\u548cGemini\u66f4\u6ce8\u91cd\u540c\u7406\u5fc3\u5bf9\u8bdd\uff0c\u4e14\u5ba1\u8bae\u683c\u5f0f\u5bf9\u6a21\u578b\u884c\u4e3a\u6709\u91cd\u8981\u5f71\u54cd\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u654f\u611f\u65e5\u5e38\u573a\u666f\u4e2d\u7684\u90e8\u7f72\u589e\u52a0\uff0c\u9700\u8981\u7406\u89e3\u5b83\u4eec\u5728\u590d\u6742\u9053\u5fb7\u63a8\u7406\u4e2d\u7684\u4ef7\u503c\u53d6\u5411\u3002\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u5355\u8f6e\u63d0\u793a\uff0c\u4f46\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u4ef7\u503c\u901a\u8fc7\u5bf9\u8bdd\u3001\u4fee\u6b63\u548c\u5171\u8bc6\u5f62\u6210\u7684\u8fc7\u7a0b\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u4f7f\u7528LLM\u8fa9\u8bba\u65b9\u6cd5\uff0c\u8ba9GPT-4.1\u3001Claude 3.7 Sonnet\u548cGemini 2.0 Flash\u4e09\u4e2a\u6a21\u578b\u57281000\u4e2aReddit\u65e5\u5e38\u56f0\u5883\u4e2d\u96c6\u4f53\u5206\u914d\u8d23\u4efb\uff0c\u91c7\u7528\u540c\u6b65\uff08\u5e76\u884c\u54cd\u5e94\uff09\u548c\u8f6e\u8be2\uff08\u987a\u5e8f\u54cd\u5e94\uff09\u4e24\u79cd\u683c\u5f0f\u6d4b\u8bd5\u987a\u5e8f\u6548\u5e94\u548c\u88c1\u51b3\u4fee\u6b63\u3002", "result": "\u53d1\u73b0\u663e\u8457\u884c\u4e3a\u5dee\u5f02\uff1a\u540c\u6b65\u8bbe\u7f6e\u4e2dGPT\u8868\u73b0\u51fa\u5f3a\u60ef\u6027\uff080.6-3.1%\u4fee\u6b63\u7387\uff09\uff0c\u800cClaude\u548cGemini\u66f4\u7075\u6d3b\uff0828-41%\uff09\u3002\u4ef7\u503c\u6a21\u5f0f\u4e5f\u4e0d\u540c\uff1aGPT\u5f3a\u8c03\u4e2a\u4eba\u81ea\u4e3b\u548c\u76f4\u63a5\u6c9f\u901a\uff0cClaude\u548cGemini\u4f18\u5148\u8003\u8651\u540c\u7406\u5fc3\u5bf9\u8bdd\u3002\u5ba1\u8bae\u683c\u5f0f\u5bf9\u6a21\u578b\u884c\u4e3a\u6709\u5f3a\u70c8\u5f71\u54cd\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u5ba1\u8bae\u683c\u5f0f\u548c\u6a21\u578b\u7279\u5b9a\u884c\u4e3a\u5851\u9020\u4e86\u591a\u8f6e\u4e92\u52a8\u4e2d\u7684\u9053\u5fb7\u63a8\u7406\uff0c\u5f3a\u8c03\u793e\u4f1a\u6280\u672f\u5bf9\u9f50\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u7cfb\u7edf\u8f93\u51fa\uff0c\u8fd8\u53d6\u51b3\u4e8e\u5bf9\u8bdd\u7ed3\u6784\u65b9\u5f0f\u3002"}}
{"id": "2510.10215", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.10215", "abs": "https://arxiv.org/abs/2510.10215", "authors": ["Pranav Gupta", "Ravi Banavar", "Anastasia Bizyaeva"], "title": "Bounds of Validity for Bifurcations of Equilibria in a Class of Networked Dynamical Systems", "comment": "This manuscript has been submitted to the 2026 American Control\n  Conference taking place in New Orleans, Louisiana, in May 2026", "summary": "Local bifurcation analysis plays a central role in understanding qualitative\ntransitions in networked nonlinear dynamical systems, including dynamic neural\nnetwork and opinion dynamics models. In this article we establish explicit\nbounds of validity for the classification of bifurcation diagrams in two\nclasses of continuous-time networked dynamical systems, analogous in structure\nto the Hopfield and the Firing Rate dynamic neural network models. Our approach\nleverages recent advances in computing the bounds for the validity of\nLyapunov-Schmidt reduction, a reduction method widely employed in nonlinear\nsystems analysis. Using these bounds we rigorously characterize neighborhoods\naround bifurcation points where predictions from reduced-order models remain\nreliable. We further demonstrate how these bounds can be applied to an\nillustrative family of nonlinear opinion dynamics on k-regular graphs, which\nemerges as a special case of the general framework. These results provide new\nanalytical tools for quantifying the robustness of bifurcation phenomena in\ndynamics over networked systems and highlight the interplay between network\nstructure and nonlinear dynamical behavior.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5efa\u7acb\u4e86\u8fde\u7eed\u65f6\u95f4\u7f51\u7edc\u5316\u52a8\u529b\u7cfb\u7edf\u4e2d\u5206\u5c94\u56fe\u5206\u7c7b\u7684\u6709\u6548\u6027\u8fb9\u754c\uff0c\u7279\u522b\u9488\u5bf9\u7c7b\u4f3cHopfield\u548cFiring Rate\u52a8\u6001\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7684\u7ed3\u6784\uff0c\u5e76\u5e94\u7528\u4e8ek-\u6b63\u5219\u56fe\u4e0a\u7684\u975e\u7ebf\u6027\u610f\u89c1\u52a8\u529b\u5b66\u6a21\u578b\u3002", "motivation": "\u7406\u89e3\u7f51\u7edc\u5316\u975e\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u4e2d\u7684\u5b9a\u6027\u8f6c\u53d8\uff0c\u5305\u62ec\u52a8\u6001\u795e\u7ecf\u7f51\u7edc\u548c\u610f\u89c1\u52a8\u529b\u5b66\u6a21\u578b\u4e2d\u7684\u5c40\u90e8\u5206\u5c94\u5206\u6790\uff0c\u9700\u8981\u660e\u786e\u5206\u5c94\u56fe\u5206\u7c7b\u7684\u6709\u6548\u6027\u8fb9\u754c\u3002", "method": "\u5229\u7528Lyapunov-Schmidt\u7f29\u51cf\u6709\u6548\u6027\u8fb9\u754c\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u4e25\u683c\u8868\u5f81\u5206\u5c94\u70b9\u5468\u56f4\u7684\u90bb\u57df\uff0c\u786e\u4fdd\u964d\u9636\u6a21\u578b\u7684\u9884\u6d4b\u53ef\u9760\u6027\u3002", "result": "\u5efa\u7acb\u4e86\u5206\u5c94\u56fe\u5206\u7c7b\u7684\u663e\u5f0f\u6709\u6548\u6027\u8fb9\u754c\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u8fd9\u4e9b\u8fb9\u754c\u5e94\u7528\u4e8ek-\u6b63\u5219\u56fe\u4e0a\u7684\u975e\u7ebf\u6027\u610f\u89c1\u52a8\u529b\u5b66\u6a21\u578b\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u91cf\u5316\u7f51\u7edc\u5316\u7cfb\u7edf\u4e2d\u5206\u5c94\u73b0\u8c61\u7684\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u5206\u6790\u5de5\u5177\uff0c\u5e76\u7a81\u51fa\u4e86\u7f51\u7edc\u7ed3\u6784\u4e0e\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u884c\u4e3a\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002"}}
{"id": "2510.10315", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.10315", "abs": "https://arxiv.org/abs/2510.10315", "authors": ["Nicolas Steinacker-Olsztyn", "Devashish Gosain", "Ha Dao"], "title": "Is Misinformation More Open? A Study of robots.txt Gatekeeping on the Web", "comment": "10 pages, 11 figures", "summary": "Large Language Models (LLMs) are increasingly relying on web crawling to stay\nup to date and accurately answer user queries. These crawlers are expected to\nhonor robots.txt files, which govern automated access. In this study, for the\nfirst time, we investigate whether reputable news websites and misinformation\nsites differ in how they configure these files, particularly in relation to AI\ncrawlers. Analyzing a curated dataset, we find a stark contrast: 60.0% of\nreputable sites disallow at least one AI crawler, compared to just 9.1% of\nmisinformation sites in their robots.txt files. Reputable sites forbid an\naverage of 15.5 AI user agents, while misinformation sites prohibit fewer than\none. We then measure active blocking behavior, where websites refuse to return\ncontent when HTTP requests include AI crawler user agents, and reveal that both\ncategories of websites utilize it. Notably, the behavior of reputable news\nwebsites in this regard aligns more closely with their declared robots.txt\ndirective than that of misinformation websites. Finally, our longitudinal\nanalysis reveals that this gap has widened over time, with AI-blocking by\nreputable sites rising from 23% in September 2023 to nearly 60% by May 2025.\nOur findings highlight a growing asymmetry in content accessibility that may\nshape the training data available to LLMs, raising essential questions for web\ntransparency, data ethics, and the future of AI training practices.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u4fe1\u8a89\u826f\u597d\u7684\u65b0\u95fb\u7f51\u7ad9\u4e0e\u865a\u5047\u4fe1\u606f\u7f51\u7ad9\u5728AI\u722c\u866b\u8bbf\u95ee\u63a7\u5236\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff1a60%\u4fe1\u8a89\u7f51\u7ad9\u7981\u6b62AI\u722c\u866b\uff0c\u800c\u865a\u5047\u4fe1\u606f\u7f51\u7ad9\u4ec59.1%\u7981\u6b62\uff0c\u8fd9\u79cd\u5dee\u8ddd\u8fd8\u5728\u6269\u5927\u3002", "motivation": "\u8c03\u67e5\u4fe1\u8a89\u65b0\u95fb\u7f51\u7ad9\u548c\u865a\u5047\u4fe1\u606f\u7f51\u7ad9\u5728robots.txt\u6587\u4ef6\u4e2d\u914d\u7f6eAI\u722c\u866b\u8bbf\u95ee\u63a7\u5236\u7684\u5dee\u5f02\uff0c\u4ee5\u53ca\u8fd9\u79cd\u5dee\u5f02\u5bf9LLM\u8bad\u7ec3\u6570\u636e\u7684\u5f71\u54cd\u3002", "method": "\u5206\u6790\u7cbe\u9009\u6570\u636e\u96c6\u4e2d\u7684robots.txt\u6587\u4ef6\u914d\u7f6e\uff0c\u6d4b\u91cf\u7f51\u7ad9\u4e3b\u52a8\u963b\u6b62AI\u722c\u866b\u7684\u884c\u4e3a\uff0c\u5e76\u8fdb\u884c\u7eb5\u5411\u65f6\u95f4\u5206\u6790\u3002", "result": "\u4fe1\u8a89\u7f51\u7ad9\u5e73\u5747\u7981\u6b6215.5\u4e2aAI\u7528\u6237\u4ee3\u7406\uff0c\u865a\u5047\u4fe1\u606f\u7f51\u7ad9\u7981\u6b62\u5c11\u4e8e1\u4e2a\uff1b\u4fe1\u8a89\u7f51\u7ad9\u7684AI\u963b\u6b62\u7387\u4ece2023\u5e749\u6708\u768423%\u4e0a\u5347\u52302025\u5e745\u6708\u7684\u8fd160%\u3002", "conclusion": "\u5185\u5bb9\u53ef\u8bbf\u95ee\u6027\u7684\u4e0d\u5bf9\u79f0\u6027\u65e5\u76ca\u52a0\u5267\uff0c\u53ef\u80fd\u5f71\u54cdLLM\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u5f15\u53d1\u5173\u4e8e\u7f51\u7edc\u900f\u660e\u5ea6\u3001\u6570\u636e\u4f26\u7406\u548cAI\u8bad\u7ec3\u5b9e\u8df5\u7684\u91cd\u8981\u95ee\u9898\u3002"}}
{"id": "2510.10059", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10059", "abs": "https://arxiv.org/abs/2510.10059", "authors": ["Keidai Iiyama", "Grace Gao"], "title": "Ionospheric and Plasmaspheric Delay Characterization for Lunar Terrestrial GNSS Receivers with Global Core Plasma Model", "comment": "Submitted NAVIGATION: Journal of the Institute of Navigation", "summary": "Recent advancements in lunar positioning, navigation, and timing (PNT) have\ndemonstrated that terrestrial GNSS signals, including weak sidelobe\ntransmissions, can be exploited for lunar spacecraft positioning and timing.\nWhile GNSS-based navigation at the Moon has been validated recently, unmodeled\nionospheric and plasmaspheric delays remain a significant error source,\nparticularly given the unique signal geometry and extended propagation paths.\nThis paper characterizes these delays using the Global Core Plasma Model (GCPM)\nand a custom low-cost ray-tracing algorithm that iteratively solves for bent\nsignal paths. We simulate first-, second-, and third-order group delays, as\nwell as excess path length from ray bending, for GNSS signals received at both\nlunar orbit and the lunar south pole under varying solar and geomagnetic\nconditions. Results show that mean group delays are typically on the order of 1\nm, but can exceed 100 m for low-altitude ray paths during high solar activity,\nwhile bending delays are generally smaller but non-negligible for low-altitude\nray paths. We also quantify the influence of signal frequency, geomagnetic\n$K_p$ index, and solar R12 index. These findings inform the design of robust\npositioning and timing algorithms that utilize terrestrial GNSS signals.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u6708\u7403\u5bfc\u822a\u4e2dGNSS\u4fe1\u53f7\u7684\u672a\u5efa\u6a21\u7535\u79bb\u5c42\u548c\u7b49\u79bb\u5b50\u4f53\u5c42\u5ef6\u8fdf\uff0c\u4f7f\u7528GCPM\u6a21\u578b\u548c\u5c04\u7ebf\u8ffd\u8e2a\u7b97\u6cd5\u6a21\u62df\u4e86\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u7fa4\u5ef6\u8fdf\u548c\u8def\u5f84\u5f2f\u66f2\u5ef6\u8fdf\u3002", "motivation": "\u867d\u7136\u6708\u7403GNSS\u5bfc\u822a\u5df2\u88ab\u9a8c\u8bc1\uff0c\u4f46\u672a\u5efa\u6a21\u7684\u7535\u79bb\u5c42\u548c\u7b49\u79bb\u5b50\u4f53\u5c42\u5ef6\u8fdf\u4ecd\u7136\u662f\u91cd\u8981\u8bef\u5dee\u6e90\uff0c\u7279\u522b\u662f\u5728\u7279\u6b8a\u4fe1\u53f7\u51e0\u4f55\u548c\u957f\u4f20\u64ad\u8def\u5f84\u4e0b\u3002", "method": "\u4f7f\u7528\u5168\u7403\u6838\u5fc3\u7b49\u79bb\u5b50\u4f53\u6a21\u578b(GCPM)\u548c\u81ea\u5b9a\u4e49\u4f4e\u6210\u672c\u5c04\u7ebf\u8ffd\u8e2a\u7b97\u6cd5\uff0c\u8fed\u4ee3\u6c42\u89e3\u5f2f\u66f2\u4fe1\u53f7\u8def\u5f84\uff0c\u6a21\u62df\u4e0d\u540c\u592a\u9633\u548c\u5730\u78c1\u6761\u4ef6\u4e0b\u7684\u7fa4\u5ef6\u8fdf\u548c\u8def\u5f84\u5f2f\u66f2\u5ef6\u8fdf\u3002", "result": "\u5e73\u5747\u7fa4\u5ef6\u8fdf\u901a\u5e38\u7ea6\u4e3a1\u7c73\uff0c\u4f46\u5728\u9ad8\u592a\u9633\u6d3b\u52a8\u671f\u95f4\u4f4e\u9ad8\u5ea6\u5c04\u7ebf\u8def\u5f84\u53ef\u8d85\u8fc7100\u7c73\uff1b\u5f2f\u66f2\u5ef6\u8fdf\u901a\u5e38\u8f83\u5c0f\u4f46\u5bf9\u4f4e\u9ad8\u5ea6\u5c04\u7ebf\u8def\u5f84\u4e0d\u53ef\u5ffd\u7565\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u5229\u7528\u5730\u9762GNSS\u4fe1\u53f7\u7684\u7a33\u5065\u5b9a\u4f4d\u548c\u5b9a\u65f6\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4fe1\u606f\u3002"}}
{"id": "2510.10008", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10008", "abs": "https://arxiv.org/abs/2510.10008", "authors": ["Meng Xi", "Sihan Lv", "Yechen Jin", "Guanjie Cheng", "Naibo Wang", "Ying Li", "Jianwei Yin"], "title": "RIPRAG: Hack a Black-box Retrieval-Augmented Generation Question-Answering System with Reinforcement Learning", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) systems based on Large Language Models\n(LLMs) have become a core technology for tasks such as question-answering (QA)\nand content generation. However, by injecting poisoned documents into the\ndatabase of RAG systems, attackers can manipulate LLMs to generate text that\naligns with their intended preferences. Existing research has primarily focused\non white-box attacks against simplified RAG architectures. In this paper, we\ninvestigate a more complex and realistic scenario: the attacker lacks knowledge\nof the RAG system's internal composition and implementation details, and the\nRAG system comprises components beyond a mere retriever. Specifically, we\npropose the RIPRAG attack framework, an end-to-end attack pipeline that treats\nthe target RAG system as a black box, where the only information accessible to\nthe attacker is whether the poisoning succeeds. Our method leverages\nReinforcement Learning (RL) to optimize the generation model for poisoned\ndocuments, ensuring that the generated poisoned document aligns with the target\nRAG system's preferences. Experimental results demonstrate that this method can\neffectively execute poisoning attacks against most complex RAG systems,\nachieving an attack success rate (ASR) improvement of up to 0.72 compared to\nbaseline methods. This highlights prevalent deficiencies in current defensive\nmethods and provides critical insights for LLM security research.", "AI": {"tldr": "\u63d0\u51fa\u4e86RIPRAG\u653b\u51fb\u6846\u67b6\uff0c\u4e00\u79cd\u9488\u5bf9\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u7684\u9ed1\u76d2\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u751f\u6210\u6bd2\u5316\u6587\u6863\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u9488\u5bf9\u7b80\u5316\u7684RAG\u67b6\u6784\u8fdb\u884c\u767d\u76d2\u653b\u51fb\uff0c\u7f3a\u4e4f\u5bf9\u66f4\u590d\u6742\u73b0\u5b9e\u573a\u666f\u7684\u7814\u7a76\uff0c\u5373\u653b\u51fb\u8005\u4e0d\u4e86\u89e3RAG\u7cfb\u7edf\u5185\u90e8\u7ec6\u8282\u4e14\u7cfb\u7edf\u5305\u542b\u591a\u4e2a\u7ec4\u4ef6\u7684\u60c5\u51b5\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u6bd2\u5316\u6587\u6863\u751f\u6210\u6a21\u578b\uff0c\u5c06\u76ee\u6807RAG\u7cfb\u7edf\u89c6\u4e3a\u9ed1\u76d2\uff0c\u4ec5\u5229\u7528\u653b\u51fb\u662f\u5426\u6210\u529f\u7684\u4fe1\u606f\u6765\u8bad\u7ec3\u751f\u6210\u5668\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u653b\u51fb\u5927\u591a\u6570\u590d\u6742RAG\u7cfb\u7edf\uff0c\u653b\u51fb\u6210\u529f\u7387\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347\u9ad8\u8fbe0.72\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63ed\u793a\u4e86\u5f53\u524d\u9632\u5fa1\u65b9\u6cd5\u7684\u666e\u904d\u7f3a\u9677\uff0c\u4e3aLLM\u5b89\u5168\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2510.10289", "categories": ["eess.SY", "cs.SY", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2510.10289", "abs": "https://arxiv.org/abs/2510.10289", "authors": ["Ke Ma", "Andrey Vlasov", "Zeynep B. Simsek", "Jinshui Zhang", "Yiru Li", "Boshuo Wang", "David L. K. Murphy", "Jessica Y. Choi", "Maya E. Clinton", "Noreen Bukhari-Parlakturk", "Angel V. Peterchev", "Stephan M. Goetz"], "title": "Optimal monophasic, asymmetric electric field pulses for selective transcranial magnetic stimulation (TMS) with minimised power and coil heating", "comment": "31 pages, 8 figures", "summary": "Transcranial magnetic stimulation (TMS) with asymmetric electric field\npulses, such as monophasic, offers directional selectivity for neural\nactivation but requires excessive energy. Previous pulse shape optimisation has\nbeen limited to symmetric pulses or heavily constrained variations of\nconventional waveforms without achieving general optimality in energy\nefficiency or neural selectivity. We implemented an optimisation framework that\nincorporates neuron model activation constraints and flexible control of pulse\nasymmetry. The optimised electric field waveforms achieved up to 92 % and 88 %\nreduction in energy loss and thus coil heating respectively compared to\nconventional monophasic pulses and previously improved monophasic-equivalent\npulses. In the human experiments, OUR pulses showed similar motor thresholds to\nmonophasic pulses in both AP and PA directions with significantly lower energy\nloss, particularly in the AP direction. Moreover, there was a significant MEP\nlatency difference of (1.79 +/- 0.41) ms between AP and PA direction with OUR\npulses, which suggests directional selectivity. Our framework successfully\nidentified highly energy-efficient asymmetric pulses for\ndirectionally-selective neural engagement. These pulses can enable selective\nrapid-rate repetitive TMS protocols with reduced power consumption and coil\nheating, with potential benefits for precision and potency of neuro-modulation.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u4f18\u5316\u6846\u67b6\uff0c\u751f\u6210\u9ad8\u5ea6\u8282\u80fd\u7684\u4e0d\u5bf9\u79f0\u7535\u573a\u8109\u51b2\uff0c\u76f8\u6bd4\u4f20\u7edf\u5355\u76f8\u8109\u51b2\u53ef\u51cf\u5c1192%\u80fd\u91cf\u635f\u5931\u548c88%\u7ebf\u5708\u53d1\u70ed\uff0c\u540c\u65f6\u4fdd\u6301\u65b9\u5411\u9009\u62e9\u6027\u795e\u7ecf\u6fc0\u6d3b\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u5355\u76f8TMS\u8109\u51b2\u867d\u7136\u5177\u6709\u65b9\u5411\u9009\u62e9\u6027\uff0c\u4f46\u80fd\u8017\u8fc7\u9ad8\uff1b\u73b0\u6709\u8109\u51b2\u5f62\u72b6\u4f18\u5316\u65b9\u6cd5\u5c40\u9650\u4e8e\u5bf9\u79f0\u8109\u51b2\u6216\u53d7\u7ea6\u675f\u7684\u4f20\u7edf\u6ce2\u5f62\u53d8\u4f53\uff0c\u65e0\u6cd5\u5b9e\u73b0\u80fd\u91cf\u6548\u7387\u548c\u795e\u7ecf\u9009\u62e9\u6027\u7684\u5168\u5c40\u6700\u4f18\u3002", "method": "\u5b9e\u65bd\u4e86\u4e00\u4e2a\u4f18\u5316\u6846\u67b6\uff0c\u7ed3\u5408\u795e\u7ecf\u5143\u6a21\u578b\u6fc0\u6d3b\u7ea6\u675f\u548c\u8109\u51b2\u4e0d\u5bf9\u79f0\u6027\u7684\u7075\u6d3b\u63a7\u5236\uff0c\u751f\u6210\u4f18\u5316\u7684\u7535\u573a\u6ce2\u5f62\u3002", "result": "\u4f18\u5316\u8109\u51b2\u76f8\u6bd4\u4f20\u7edf\u5355\u76f8\u8109\u51b2\u548c\u5148\u524d\u6539\u8fdb\u7684\u5355\u76f8\u7b49\u6548\u8109\u51b2\uff0c\u80fd\u91cf\u635f\u5931\u5206\u522b\u51cf\u5c1192%\u548c88%\uff1b\u4eba\u4f53\u5b9e\u9a8c\u663e\u793a\u5728AP\u548cPA\u65b9\u5411\u4e0a\u5177\u6709\u76f8\u4f3c\u7684\u8fd0\u52a8\u9608\u503c\u4f46\u80fd\u91cf\u635f\u5931\u663e\u8457\u964d\u4f4e\uff0cAP\u548cPA\u65b9\u5411\u95f4\u5b58\u5728\u663e\u8457MEP\u6f5c\u4f0f\u671f\u5dee\u5f02(1.79\u00b10.41ms)\uff0c\u8868\u660e\u65b9\u5411\u9009\u62e9\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u8bc6\u522b\u51fa\u7528\u4e8e\u65b9\u5411\u9009\u62e9\u6027\u795e\u7ecf\u53c2\u4e0e\u7684\u9ad8\u5ea6\u8282\u80fd\u4e0d\u5bf9\u79f0\u8109\u51b2\uff0c\u8fd9\u4e9b\u8109\u51b2\u80fd\u591f\u5b9e\u73b0\u9009\u62e9\u6027\u5feb\u901f\u7387\u91cd\u590dTMS\u534f\u8bae\uff0c\u964d\u4f4e\u529f\u8017\u548c\u7ebf\u5708\u53d1\u70ed\uff0c\u5bf9\u795e\u7ecf\u8c03\u8282\u7684\u7cbe\u786e\u6027\u548c\u6548\u529b\u5177\u6709\u6f5c\u5728\u76ca\u5904\u3002"}}
{"id": "2510.10327", "categories": ["cs.CY", "cs.AI", "F.2.2, I.2.7"], "pdf": "https://arxiv.org/pdf/2510.10327", "abs": "https://arxiv.org/abs/2510.10327", "authors": ["Junhao Xu", "Hui Zeng"], "title": "Mapping the Urban Mobility Intelligence Frontier: A Scientometric Analysis of Data-Driven Pedestrian Trajectory Prediction and Simulation", "comment": "5 figures", "summary": "Understanding and predicting pedestrian dynamics has become essential for\nshaping safer, more responsive, and human-centered urban environments. This\nstudy conducts a comprehensive scientometric analysis of research on\ndata-driven pedestrian trajectory prediction and crowd simulation, mapping its\nintellectual evolution and interdisciplinary structure. Using bibliometric data\nfrom the Web of Science Core Collection, we employ SciExplorer and Bibliometrix\nto identify major trends, influential contributors, and emerging frontiers.\nResults reveal a strong convergence between artificial intelligence, urban\ninformatics, and crowd behavior modeling--driven by graph neural networks,\ntransformers, and generative models. Beyond technical advances, the field\nincreasingly informs urban mobility design, public safety planning, and digital\ntwin development for smart cities. However, challenges remain in ensuring\ninterpretability, inclusivity, and cross-domain transferability. By connecting\nmethodological trajectories with urban applications, this work highlights how\ndata-driven approaches can enrich urban governance and pave the way for\nadaptive, socially responsible mobility intelligence in future cities.", "AI": {"tldr": "\u5bf9\u6570\u636e\u9a71\u52a8\u7684\u884c\u4eba\u8f68\u8ff9\u9884\u6d4b\u548c\u4eba\u7fa4\u6a21\u62df\u7814\u7a76\u8fdb\u884c\u79d1\u5b66\u8ba1\u91cf\u5206\u6790\uff0c\u63ed\u793a\u8be5\u9886\u57df\u7684\u77e5\u8bc6\u6f14\u8fdb\u548c\u8de8\u5b66\u79d1\u7ed3\u6784\uff0c\u91cd\u70b9\u5173\u6ce8\u4eba\u5de5\u667a\u80fd\u4e0e\u57ce\u5e02\u4fe1\u606f\u5b66\u7684\u878d\u5408\u8d8b\u52bf\u3002", "motivation": "\u7406\u89e3\u884c\u4eba\u52a8\u6001\u5bf9\u4e8e\u6784\u5efa\u66f4\u5b89\u5168\u3001\u54cd\u5e94\u6027\u66f4\u5f3a\u3001\u4ee5\u4eba\u4e3a\u672c\u7684\u57ce\u5e02\u73af\u5883\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u7cfb\u7edf\u68b3\u7406\u8be5\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\u548c\u53d1\u5c55\u65b9\u5411\u3002", "method": "\u4f7f\u7528Web of Science\u6838\u5fc3\u5408\u96c6\u6570\u636e\uff0c\u901a\u8fc7SciExplorer\u548cBibliometrix\u5de5\u5177\u8fdb\u884c\u79d1\u5b66\u8ba1\u91cf\u5206\u6790\uff0c\u8bc6\u522b\u4e3b\u8981\u8d8b\u52bf\u3001\u6709\u5f71\u54cd\u529b\u7684\u8d21\u732e\u8005\u548c\u65b0\u5174\u524d\u6cbf\u3002", "result": "\u53d1\u73b0\u4eba\u5de5\u667a\u80fd\u3001\u57ce\u5e02\u4fe1\u606f\u5b66\u548c\u4eba\u7fa4\u884c\u4e3a\u5efa\u6a21\u4e4b\u95f4\u7684\u5f3a\u878d\u5408\u8d8b\u52bf\uff0c\u4e3b\u8981\u6280\u672f\u5305\u62ec\u56fe\u795e\u7ecf\u7f51\u7edc\u3001Transformer\u548c\u751f\u6210\u6a21\u578b\uff0c\u8be5\u9886\u57df\u6b63\u65e5\u76ca\u5f71\u54cd\u57ce\u5e02\u79fb\u52a8\u6027\u8bbe\u8ba1\u3001\u516c\u5171\u5b89\u5168\u89c4\u5212\u548c\u667a\u6167\u57ce\u5e02\u6570\u5b57\u5b6a\u751f\u53d1\u5c55\u3002", "conclusion": "\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u53ef\u4ee5\u4e30\u5bcc\u57ce\u5e02\u6cbb\u7406\uff0c\u4e3a\u672a\u6765\u57ce\u5e02\u4e2d\u9002\u5e94\u6027\u3001\u793e\u4f1a\u8d23\u4efb\u7684\u79fb\u52a8\u667a\u80fd\u94fa\u5e73\u9053\u8def\uff0c\u4f46\u53ef\u89e3\u91ca\u6027\u3001\u5305\u5bb9\u6027\u548c\u8de8\u9886\u57df\u53ef\u8fc1\u79fb\u6027\u4ecd\u662f\u6311\u6218\u3002"}}
{"id": "2510.10086", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10086", "abs": "https://arxiv.org/abs/2510.10086", "authors": ["Feifei Liu", "Haozhe Wang", "Zejun Wei", "Qirong Lu", "Yiyang Wen", "Xiaoyu Tang", "Jingyan Jiang", "Zhijian He"], "title": "Beyond ADE and FDE: A Comprehensive Evaluation Framework for Safety-Critical Prediction in Multi-Agent Autonomous Driving Scenarios", "comment": null, "summary": "Current evaluation methods for autonomous driving prediction models rely\nheavily on simplistic metrics such as Average Displacement Error (ADE) and\nFinal Displacement Error (FDE). While these metrics offer basic performance\nassessments, they fail to capture the nuanced behavior of prediction modules\nunder complex, interactive, and safety-critical driving scenarios. For\ninstance, existing benchmarks do not distinguish the influence of nearby versus\ndistant agents, nor systematically test model robustness across varying\nmulti-agent interactions. This paper addresses this critical gap by proposing a\nnovel testing framework that evaluates prediction performance under diverse\nscene structures, saying, map context, agent density and spatial distribution.\nThrough extensive empirical analysis, we quantify the differential impact of\nagent proximity on target trajectory prediction and identify scenario-specific\nfailure cases that are not exposed by traditional metrics. Our findings\nhighlight key vulnerabilities in current state-of-the-art prediction models and\ndemonstrate the importance of scenario-aware evaluation. The proposed framework\nlays the groundwork for rigorous, safety-driven prediction validation,\ncontributing significantly to the identification of failure-prone corner cases\nand the development of robust, certifiable prediction systems for autonomous\nvehicles.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684\u81ea\u52a8\u9a7e\u9a76\u9884\u6d4b\u6a21\u578b\u6d4b\u8bd5\u6846\u67b6\uff0c\u5173\u6ce8\u573a\u666f\u7ed3\u6784\u3001\u5730\u56fe\u4e0a\u4e0b\u6587\u3001\u667a\u80fd\u4f53\u5bc6\u5ea6\u548c\u7a7a\u95f4\u5206\u5e03\uff0c\u63ed\u793a\u4f20\u7edf\u6307\u6807\u65e0\u6cd5\u53d1\u73b0\u7684\u6a21\u578b\u8106\u5f31\u6027\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u9a7e\u9a76\u9884\u6d4b\u6a21\u578b\u8bc4\u4f30\u65b9\u6cd5\u8fc7\u4e8e\u4f9d\u8d56\u7b80\u5355\u6307\u6807\u5982ADE\u548cFDE\uff0c\u65e0\u6cd5\u6355\u6349\u590d\u6742\u4ea4\u4e92\u548c\u5b89\u5168\u5173\u952e\u573a\u666f\u4e0b\u7684\u7ec6\u5fae\u884c\u4e3a\u5dee\u5f02\uff0c\u7f3a\u4e4f\u5bf9\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u9c81\u68d2\u6027\u7684\u7cfb\u7edf\u6d4b\u8bd5\u3002", "method": "\u5f00\u53d1\u65b0\u578b\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6837\u5316\u573a\u666f\u7ed3\u6784\uff08\u5730\u56fe\u4e0a\u4e0b\u6587\u3001\u667a\u80fd\u4f53\u5bc6\u5ea6\u3001\u7a7a\u95f4\u5206\u5e03\uff09\u6765\u8bc4\u4f30\u9884\u6d4b\u6027\u80fd\uff0c\u91cf\u5316\u667a\u80fd\u4f53\u90bb\u8fd1\u5ea6\u5bf9\u8f68\u8ff9\u9884\u6d4b\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u8bc1\u5206\u6790\u53d1\u73b0\u5f53\u524d\u6700\u5148\u8fdb\u9884\u6d4b\u6a21\u578b\u5b58\u5728\u5173\u952e\u8106\u5f31\u6027\uff0c\u8bc6\u522b\u51fa\u4f20\u7edf\u6307\u6807\u65e0\u6cd5\u66b4\u9732\u7684\u573a\u666f\u7279\u5b9a\u5931\u8d25\u6848\u4f8b\uff0c\u8bc1\u660e\u4e86\u90bb\u8fd1\u667a\u80fd\u4f53\u5bf9\u76ee\u6807\u8f68\u8ff9\u9884\u6d4b\u7684\u5dee\u5f02\u5316\u5f71\u54cd\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4e25\u683c\u7684\u3001\u5b89\u5168\u9a71\u52a8\u7684\u9884\u6d4b\u9a8c\u8bc1\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u8bc6\u522b\u6613\u5931\u8d25\u7684\u6781\u7aef\u60c5\u51b5\uff0c\u63a8\u52a8\u5f00\u53d1\u9c81\u68d2\u4e14\u53ef\u8ba4\u8bc1\u7684\u81ea\u52a8\u9a7e\u9a76\u9884\u6d4b\u7cfb\u7edf\u3002"}}
{"id": "2510.10035", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10035", "abs": "https://arxiv.org/abs/2510.10035", "authors": ["Jusheng Zhang", "Kaitong Cai", "Qinglin Zeng", "Ningyuan Liu", "Stephen Fan", "Ziliang Chen", "Keze Wang"], "title": "Failure-Driven Workflow Refinement", "comment": null, "summary": "Optimizing LLM-based workflows is typically formulated as a global search,\nwhere candidate workflows are evaluated based on a scalar metric. This\nparadigm, however, suffers from a critical flaw: information collapse. By\nreducing rich, multi-step execution traces to simple success/failure signals,\nexisting methods are rendered blind to the underlying structure of failures,\nfundamentally preventing them from modeling the workflow's failure\ndistribution. We reconceptualize this challenge as a distributional problem. We\npropose a new paradigm where the optimization goal is not to maximize a scalar\nscore, but to directly minimize a workflow's Expected Failure Mass, i.e., the\nintegral of its failure probability density function defined over a\nhigh-dimensional Failure Signature Space (FSS). This distributional lens allows\nus to move from inefficient, zero-order optimization to a principled,\ngradient-like descent on the failure landscape itself. We introduce CE-Graph, a\nframework that operationalizes this paradigm through a novel, failure-driven\nrefinement process. CE-Graph approximates the failure distribution from a pool\nof counterexamples, identifies its densest regions as recurring failure modes,\nand applies targeted, operator-constrained graph edits via a Propose-and-Verify\nmechanism to greedily reduce the failure mass. On math, code, and QA\nbenchmarks, our CE-Graph achieves higher robustness at a significantly lower\ncost than strong baselines. This suggests that a system's reliability emerges\nnot from avoiding failures, but from systematically learning and reshaping the\ngeometric structure of its failure distributions.", "AI": {"tldr": "\u63d0\u51faCE-Graph\u6846\u67b6\uff0c\u5c06LLM\u5de5\u4f5c\u6d41\u4f18\u5316\u91cd\u65b0\u5b9a\u4e49\u4e3a\u6700\u5c0f\u5316\u9884\u671f\u5931\u8d25\u8d28\u91cf\uff0c\u901a\u8fc7\u5931\u8d25\u7b7e\u540d\u7a7a\u95f4\u4e2d\u7684\u5206\u5e03\u89c6\u89d2\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u4f18\u5316\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u6807\u91cf\u6307\u6807\u7684\u5168\u5c40\u641c\u7d22\u65b9\u6cd5\u5b58\u5728\u4fe1\u606f\u574d\u7f29\u95ee\u9898\uff0c\u5c06\u4e30\u5bcc\u7684\u591a\u6b65\u9aa4\u6267\u884c\u8f68\u8ff9\u7b80\u5316\u4e3a\u7b80\u5355\u7684\u6210\u529f/\u5931\u8d25\u4fe1\u53f7\uff0c\u65e0\u6cd5\u5efa\u6a21\u5de5\u4f5c\u6d41\u7684\u5931\u8d25\u5206\u5e03\u7ed3\u6784\u3002", "method": "\u5f15\u5165\u5931\u8d25\u7b7e\u540d\u7a7a\u95f4(FSS)\uff0c\u901a\u8fc7\u53cd\u4f8b\u6c60\u8fd1\u4f3c\u5931\u8d25\u5206\u5e03\uff0c\u8bc6\u522b\u5bc6\u96c6\u533a\u57df\u4f5c\u4e3a\u91cd\u590d\u5931\u8d25\u6a21\u5f0f\uff0c\u4f7f\u7528\u63d0\u51fa-\u9a8c\u8bc1\u673a\u5236\u8fdb\u884c\u76ee\u6807\u5316\u7684\u56fe\u7f16\u8f91\u64cd\u4f5c\u6765\u8d2a\u5a6a\u51cf\u5c11\u5931\u8d25\u8d28\u91cf\u3002", "result": "\u5728\u6570\u5b66\u3001\u4ee3\u7801\u548c\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCE-Graph\u4ee5\u663e\u8457\u66f4\u4f4e\u7684\u6210\u672c\u5b9e\u73b0\u4e86\u6bd4\u5f3a\u57fa\u7ebf\u66f4\u9ad8\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u4e0d\u662f\u6765\u81ea\u907f\u514d\u5931\u8d25\uff0c\u800c\u662f\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u5b66\u4e60\u548c\u91cd\u5851\u5176\u5931\u8d25\u5206\u5e03\u7684\u51e0\u4f55\u7ed3\u6784\u6765\u5b9e\u73b0\u7684\u3002"}}
{"id": "2510.10313", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.10313", "abs": "https://arxiv.org/abs/2510.10313", "authors": ["Luiz Fernando M. Arruda", "Moises Ferber", "Diego Greff"], "title": "Low-cost Pyranometer-Based ANN Approach for MPPT in Solar PV Systems", "comment": null, "summary": "This article presents a study on the application of artificial neural\nnetworks (ANNs) for maximum power point tracking (MPPT) in photovoltaic (PV)\nsystems using low-cost pyranometer sensors. The proposed approach integrates\npyranometers, temperature sensors, and an ANN to estimate the duty cycle of a\nDC/DC converter, enabling the system to consistently operate at its maximum\npower point. The strategy was implemented in the local control of a Cuk\nconverter and experimentally validated against the conventional Perturb and\nObserve (P&O) method. Results demonstrate that the ANN-based technique,\nleveraging affordable sensor technology, achieves accurate MPPT performance\nwith reduced fluctuations, enhancing the responsiveness and efficiency of PV\ntracking systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc(ANN)\u7684\u6700\u5927\u529f\u7387\u70b9\u8ddf\u8e2a(MPPT)\u65b9\u6cd5\uff0c\u4f7f\u7528\u4f4e\u6210\u672c\u8f90\u5c04\u8ba1\u4f20\u611f\u5668\u6765\u4f18\u5316\u5149\u4f0f\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfMPPT\u65b9\u6cd5\u5982\u6270\u52a8\u89c2\u5bdf\u6cd5\u5b58\u5728\u529f\u7387\u6ce2\u52a8\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u7cbe\u786e\u3001\u54cd\u5e94\u66f4\u5feb\u7684\u8ddf\u8e2a\u6280\u672f\uff0c\u540c\u65f6\u8003\u8651\u6210\u672c\u6548\u76ca\u3002", "method": "\u96c6\u6210\u8f90\u5c04\u8ba1\u3001\u6e29\u5ea6\u4f20\u611f\u5668\u548cANN\u6765\u4f30\u8ba1DC/DC\u53d8\u6362\u5668\u7684\u5360\u7a7a\u6bd4\uff0c\u5728Cuk\u53d8\u6362\u5668\u7684\u672c\u5730\u63a7\u5236\u4e2d\u5b9e\u73b0MPPT\u3002", "result": "\u4e0e\u4f20\u7edf\u7684P&O\u65b9\u6cd5\u76f8\u6bd4\uff0cANN\u6280\u672f\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u7684MPPT\u6027\u80fd\uff0c\u51cf\u5c11\u4e86\u529f\u7387\u6ce2\u52a8\uff0c\u63d0\u9ad8\u4e86\u7cfb\u7edf\u54cd\u5e94\u901f\u5ea6\u548c\u6548\u7387\u3002", "conclusion": "\u57fa\u4e8eANN\u7684MPPT\u65b9\u6cd5\u7ed3\u5408\u4f4e\u6210\u672c\u4f20\u611f\u5668\u6280\u672f\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u5149\u4f0f\u8ddf\u8e2a\u7cfb\u7edf\u7684\u6027\u80fd\u548c\u6210\u672c\u6548\u76ca\u3002"}}
{"id": "2510.10413", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.10413", "abs": "https://arxiv.org/abs/2510.10413", "authors": ["Saurabh Khanna"], "title": "Knowing Unknowns in an Age of Information Overload", "comment": null, "summary": "The technological revolution of the Internet has digitized the social,\neconomic, political, and cultural activities of billions of humans. While\nresearchers have been paying due attention to concerns of misinformation and\nbias, these obscure a much less researched and equally insidious problem - that\nof uncritically consuming incomplete information. The problem of incomplete\ninformation consumption stems from the very nature of explicitly ranked\ninformation on digital platforms, where our limited mental capacities leave us\nwith little choice but to consume the tip of a pre-ranked information iceberg.\nThis study makes two chief contributions. First, we leverage the context of\ninternet search to propose an innovative metric that quantifies information\ncompleteness. For a given search query, this refers to the extent of the\ninformation spectrum that is observed during web browsing. We then validate\nthis metric using 6.5 trillion search results extracted from daily search\ntrends across 48 nations for one year. Second, we find causal evidence that\nawareness of information completeness while browsing the Internet reduces\nresistance to factual information, hence paving the way towards an open-minded\nand tolerant mindset.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u91cf\u5316\u4fe1\u606f\u5b8c\u6574\u6027\u7684\u65b0\u6307\u6807\uff0c\u5e76\u53d1\u73b0\u610f\u8bc6\u5230\u4fe1\u606f\u5b8c\u6574\u6027\u53ef\u4ee5\u51cf\u5c11\u5bf9\u4e8b\u5b9e\u4fe1\u606f\u7684\u6297\u62d2\uff0c\u4fc3\u8fdb\u5f00\u653e\u601d\u7ef4\u3002", "motivation": "\u4e92\u8054\u7f51\u6280\u672f\u9769\u547d\u6570\u5b57\u5316\u4e86\u4eba\u7c7b\u6d3b\u52a8\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u9519\u8bef\u4fe1\u606f\u548c\u504f\u89c1\uff0c\u5ffd\u89c6\u4e86\u4e0d\u5b8c\u6574\u4fe1\u606f\u6d88\u8d39\u8fd9\u4e00\u540c\u6837\u4e25\u91cd\u7684\u95ee\u9898\u3002\u4fe1\u606f\u6392\u540d\u673a\u5236\u5bfc\u81f4\u7528\u6237\u53ea\u80fd\u770b\u5230\u4fe1\u606f\u51b0\u5c71\u7684\u4e00\u89d2\u3002", "method": "\u5229\u7528\u4e92\u8054\u7f51\u641c\u7d22\u80cc\u666f\u63d0\u51fa\u4fe1\u606f\u5b8c\u6574\u6027\u91cf\u5316\u6307\u6807\uff0c\u57fa\u4e8e48\u4e2a\u56fd\u5bb6\u4e00\u5e74\u518565\u4ebf\u6b21\u641c\u7d22\u7ed3\u679c\u7684\u65e5\u5e38\u641c\u7d22\u8d8b\u52bf\u6570\u636e\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u6d4f\u89c8\u4e92\u8054\u7f51\u65f6\u610f\u8bc6\u5230\u4fe1\u606f\u5b8c\u6574\u6027\u80fd\u591f\u51cf\u5c11\u5bf9\u4e8b\u5b9e\u4fe1\u606f\u7684\u6297\u62d2\u3002", "conclusion": "\u4fe1\u606f\u5b8c\u6574\u6027\u610f\u8bc6\u6709\u52a9\u4e8e\u57f9\u517b\u5f00\u653e\u548c\u5305\u5bb9\u7684\u5fc3\u6001\uff0c\u4e3a\u89e3\u51b3\u4e0d\u5b8c\u6574\u4fe1\u606f\u6d88\u8d39\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u548c\u65b9\u6cd5\u3002"}}
{"id": "2510.10125", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10125", "abs": "https://arxiv.org/abs/2510.10125", "authors": ["Yanjiang Guo", "Lucy Xiaoyang Shi", "Jianyu Chen", "Chelsea Finn"], "title": "Ctrl-World: A Controllable Generative World Model for Robot Manipulation", "comment": "17 pages", "summary": "Generalist robot policies can now perform a wide range of manipulation\nskills, but evaluating and improving their ability with unfamiliar objects and\ninstructions remains a significant challenge. Rigorous evaluation requires a\nlarge number of real-world rollouts, while systematic improvement demands\nadditional corrective data with expert labels. Both of these processes are\nslow, costly, and difficult to scale. World models offer a promising, scalable\nalternative by enabling policies to rollout within imagination space. However,\na key challenge is building a controllable world model that can handle\nmulti-step interactions with generalist robot policies. This requires a world\nmodel compatible with modern generalist policies by supporting multi-view\nprediction, fine-grained action control, and consistent long-horizon\ninteractions, which is not achieved by previous works. In this paper, we make a\nstep forward by introducing a controllable multi-view world model that can be\nused to evaluate and improve the instruction-following ability of generalist\nrobot policies. Our model maintains long-horizon consistency with a\npose-conditioned memory retrieval mechanism and achieves precise action control\nthrough frame-level action conditioning. Trained on the DROID dataset (95k\ntrajectories, 564 scenes), our model generates spatially and temporally\nconsistent trajectories under novel scenarios and new camera placements for\nover 20 seconds. We show that our method can accurately rank policy performance\nwithout real-world robot rollouts. Moreover, by synthesizing successful\ntrajectories in imagination and using them for supervised fine-tuning, our\napproach can improve policy success by 44.7\\%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u63a7\u591a\u89c6\u56fe\u4e16\u754c\u6a21\u578b\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6539\u8fdb\u901a\u7528\u673a\u5668\u4eba\u7b56\u7565\u7684\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\uff0c\u65e0\u9700\u771f\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u90e8\u7f72\u5373\u53ef\u51c6\u786e\u8bc4\u4f30\u7b56\u7565\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u60f3\u8c61\u7a7a\u95f4\u4e2d\u7684\u8f68\u8ff9\u5408\u6210\u5c06\u7b56\u7565\u6210\u529f\u7387\u63d0\u534744.7%\u3002", "motivation": "\u901a\u7528\u673a\u5668\u4eba\u7b56\u7565\u5728\u5904\u7406\u964c\u751f\u7269\u4f53\u548c\u6307\u4ee4\u65f6\u5b58\u5728\u8bc4\u4f30\u548c\u6539\u8fdb\u7684\u6311\u6218\uff0c\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u6269\u5c55\uff0c\u4e16\u754c\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u9700\u8981\u652f\u6301\u591a\u89c6\u56fe\u9884\u6d4b\u3001\u7ec6\u7c92\u5ea6\u52a8\u4f5c\u63a7\u5236\u548c\u4e00\u81f4\u7684\u957f\u65f6\u7a0b\u4ea4\u4e92\u3002", "method": "\u5f00\u53d1\u4e86\u53ef\u63a7\u591a\u89c6\u56fe\u4e16\u754c\u6a21\u578b\uff0c\u91c7\u7528\u59ff\u6001\u6761\u4ef6\u8bb0\u5fc6\u68c0\u7d22\u673a\u5236\u4fdd\u6301\u957f\u65f6\u7a0b\u4e00\u81f4\u6027\uff0c\u901a\u8fc7\u5e27\u7ea7\u52a8\u4f5c\u63a7\u5236\u5b9e\u73b0\u7cbe\u786e\u52a8\u4f5c\u63a7\u5236\uff0c\u5728DROID\u6570\u636e\u96c6\uff0895k\u8f68\u8ff9\uff0c564\u573a\u666f\uff09\u4e0a\u8bad\u7ec3\u3002", "result": "\u6a21\u578b\u80fd\u5728\u65b0\u573a\u666f\u548c\u65b0\u76f8\u673a\u5e03\u7f6e\u4e0b\u751f\u6210\u7a7a\u95f4\u548c\u65f6\u95f4\u4e00\u81f4\u7684\u8f68\u8ff9\u8d85\u8fc720\u79d2\uff0c\u65e0\u9700\u771f\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u90e8\u7f72\u5373\u53ef\u51c6\u786e\u8bc4\u4f30\u7b56\u7565\u6027\u80fd\uff0c\u901a\u8fc7\u60f3\u8c61\u7a7a\u95f4\u4e2d\u7684\u6210\u529f\u8f68\u8ff9\u5408\u6210\u548c\u76d1\u7763\u5fae\u8c03\u5c06\u7b56\u7565\u6210\u529f\u7387\u63d0\u534744.7%\u3002", "conclusion": "\u53ef\u63a7\u591a\u89c6\u56fe\u4e16\u754c\u6a21\u578b\u4e3a\u901a\u7528\u673a\u5668\u4eba\u7b56\u7565\u7684\u8bc4\u4f30\u548c\u6539\u8fdb\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u7684\u6210\u672c\u548c\u590d\u6742\u6027\u3002"}}
{"id": "2510.10042", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10042", "abs": "https://arxiv.org/abs/2510.10042", "authors": ["Saleh Nikooroo", "Thomas Engel"], "title": "Belief Graphs with Reasoning Zones: Structure, Dynamics, and Epistemic Activation", "comment": null, "summary": "Belief systems are rarely globally consistent, yet effective reasoning often\npersists locally. We propose a novel graph-theoretic framework that cleanly\nseparates credibility--external, a priori trust in sources--from confidence--an\ninternal, emergent valuation induced by network structure. Beliefs are nodes in\na directed, signed, weighted graph whose edges encode support and\ncontradiction. Confidence is obtained by a contractive propagation process that\nmixes a stated prior with structure-aware influence and guarantees a unique,\nstable solution. Within this dynamics, we define reasoning zones:\nhigh-confidence, structurally balanced subgraphs on which classical inference\nis safe despite global contradictions. We provide a near-linear procedure that\nseeds zones by confidence, tests balance using a parity-based coloring, and\napplies a greedy, locality-preserving repair with Jaccard de-duplication to\nbuild a compact atlas. To model belief change, we introduce shock updates that\nlocally downscale support and elevate targeted contradictions while preserving\ncontractivity via a simple backtracking rule. Re-propagation yields localized\nreconfiguration-zones may shrink, split, or collapse--without destabilizing the\nentire graph. We outline an empirical protocol on synthetic signed graphs with\nplanted zones, reporting zone recovery, stability under shocks, and runtime.\nThe result is a principled foundation for contradiction-tolerant reasoning that\nactivates classical logic precisely where structure supports it.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u56fe\u8bba\u6846\u67b6\uff0c\u5c06\u53ef\u4fe1\u5ea6\u4e0e\u7f6e\u4fe1\u5ea6\u5206\u79bb\uff0c\u901a\u8fc7\u6536\u7f29\u4f20\u64ad\u8fc7\u7a0b\u83b7\u5f97\u7f6e\u4fe1\u5ea6\uff0c\u5b9a\u4e49\u63a8\u7406\u533a\u57df\u4f5c\u4e3a\u9ad8\u7f6e\u4fe1\u5ea6\u3001\u7ed3\u6784\u5e73\u8861\u7684\u5b50\u56fe\uff0c\u652f\u6301\u5728\u5168\u5c40\u77db\u76fe\u4e0b\u8fdb\u884c\u5c40\u90e8\u63a8\u7406\u3002", "motivation": "\u4fe1\u5ff5\u7cfb\u7edf\u5f88\u5c11\u5168\u5c40\u4e00\u81f4\uff0c\u4f46\u6709\u6548\u7684\u63a8\u7406\u901a\u5e38\u80fd\u5728\u5c40\u90e8\u6301\u7eed\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5bb9\u5fcd\u77db\u76fe\u3001\u5728\u7ed3\u6784\u652f\u6301\u7684\u5c40\u90e8\u533a\u57df\u6fc0\u6d3b\u7ecf\u5178\u903b\u8f91\u7684\u63a8\u7406\u57fa\u7840\u3002", "method": "\u6784\u5efa\u6709\u5411\u3001\u5e26\u7b26\u53f7\u3001\u52a0\u6743\u7684\u4fe1\u5ff5\u56fe\uff0c\u901a\u8fc7\u6536\u7f29\u4f20\u64ad\u8fc7\u7a0b\u8ba1\u7b97\u7f6e\u4fe1\u5ea6\uff0c\u5b9a\u4e49\u63a8\u7406\u533a\u57df\u5e76\u4f7f\u7528\u5947\u5076\u7740\u8272\u6d4b\u8bd5\u5e73\u8861\uff0c\u5e94\u7528\u8d2a\u5fc3\u4fee\u590d\u548cJaccard\u53bb\u91cd\u6784\u5efa\u7d27\u51d1\u56fe\u8c31\u3002", "result": "\u63d0\u4f9b\u4e86\u8fd1\u7ebf\u6027\u7a0b\u5e8f\u6765\u6062\u590d\u63a8\u7406\u533a\u57df\uff0c\u5728\u5408\u6210\u5e26\u7b26\u53f7\u56fe\u4e2d\u62a5\u544a\u4e86\u533a\u57df\u6062\u590d\u3001\u51b2\u51fb\u4e0b\u7684\u7a33\u5b9a\u6027\u4ee5\u53ca\u8fd0\u884c\u65f6\u95f4\u3002", "conclusion": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u7684\u57fa\u7840\uff0c\u7528\u4e8e\u5bb9\u5fcd\u77db\u76fe\u7684\u63a8\u7406\uff0c\u5728\u7ed3\u6784\u652f\u6301\u7684\u5730\u65b9\u7cbe\u786e\u6fc0\u6d3b\u7ecf\u5178\u903b\u8f91\u3002"}}
{"id": "2510.10411", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.10411", "abs": "https://arxiv.org/abs/2510.10411", "authors": ["Ilias Mitrai"], "title": "Discovering interpretable piecewise nonlinear model predictive control laws via symbolic decision trees", "comment": null, "summary": "In this paper, we propose symbolic decision trees as surrogate models for\napproximating model predictive control laws. The proposed approach learns\nsimultaneously the partition of the input domain (splitting logic) as well as\nlocal nonlinear expressions for predicting the control action leading to\ninterpretable piecewise nonlinear control laws. The local nonlinear expressions\nare determined by the learning problem and are modeled using a set of basis\nfunctions. The learning task is posed as a mixed integer optimization, which is\nsolved to global optimality with state-of-the-art global optimization solvers.\nWe apply the proposed approach to a case study regarding the control of an\nisothermal reactor. The results show that the proposed approach can learn the\ncontrol law accurately, leading to closed-loop performance comparable to that\nof a standard model predictive controller. Finally, comparison with existing\ninterpretable models shows that the symbolic trees achieve both lower\nprediction error and superior closed-loop performance.", "AI": {"tldr": "\u63d0\u51fa\u7b26\u53f7\u51b3\u7b56\u6811\u4f5c\u4e3a\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5f8b\u7684\u66ff\u4ee3\u6a21\u578b\uff0c\u901a\u8fc7\u6df7\u5408\u6574\u6570\u4f18\u5316\u5b66\u4e60\u8f93\u5165\u57df\u5212\u5206\u548c\u5c40\u90e8\u975e\u7ebf\u6027\u8868\u8fbe\u5f0f\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u5206\u6bb5\u975e\u7ebf\u6027\u63a7\u5236\u5f8b\u3002", "motivation": "\u4e3a\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5f8b\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u8fd1\u4f3c\u66ff\u4ee3\u6a21\u578b\uff0c\u540c\u65f6\u5b66\u4e60\u8f93\u5165\u57df\u5212\u5206\u548c\u5c40\u90e8\u975e\u7ebf\u6027\u63a7\u5236\u8868\u8fbe\u5f0f\u3002", "method": "\u4f7f\u7528\u7b26\u53f7\u51b3\u7b56\u6811\u540c\u65f6\u5b66\u4e60\u8f93\u5165\u57df\u5212\u5206\uff08\u5206\u88c2\u903b\u8f91\uff09\u548c\u5c40\u90e8\u975e\u7ebf\u6027\u8868\u8fbe\u5f0f\uff0c\u901a\u8fc7\u6df7\u5408\u6574\u6570\u4f18\u5316\u95ee\u9898\u5efa\u6a21\uff0c\u5e76\u7528\u5168\u5c40\u4f18\u5316\u6c42\u89e3\u5668\u6c42\u89e3\u3002", "result": "\u5728\u7b49\u6e29\u53cd\u5e94\u5668\u63a7\u5236\u6848\u4f8b\u4e2d\uff0c\u8be5\u65b9\u6cd5\u80fd\u51c6\u786e\u5b66\u4e60\u63a7\u5236\u5f8b\uff0c\u95ed\u73af\u6027\u80fd\u4e0e\u6807\u51c6\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5668\u76f8\u5f53\uff0c\u4e14\u6bd4\u73b0\u6709\u53ef\u89e3\u91ca\u6a21\u578b\u5177\u6709\u66f4\u4f4e\u7684\u9884\u6d4b\u8bef\u5dee\u548c\u66f4\u597d\u7684\u95ed\u73af\u6027\u80fd\u3002", "conclusion": "\u7b26\u53f7\u51b3\u7b56\u6811\u65b9\u6cd5\u80fd\u6709\u6548\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5f8b\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u5206\u6bb5\u975e\u7ebf\u6027\u63a7\u5236\u7b56\u7565\uff0c\u5728\u9884\u6d4b\u7cbe\u5ea6\u548c\u95ed\u73af\u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u53ef\u89e3\u91ca\u6a21\u578b\u3002"}}
{"id": "2510.10520", "categories": ["cs.CY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10520", "abs": "https://arxiv.org/abs/2510.10520", "authors": ["Fuze Sun", "Paul Craig", "Lingyu Li", "Shixiangyue Meng", "Chuxi Nan"], "title": "AI-Agents for Culturally Diverse Online Higher Education Environments", "comment": null, "summary": "As the global reach of online higher education continues to grow,\nuniversities are increasingly accommodating students from diverse cultural\nbackgrounds \\parencite{tereshko2024culturally}. This can present a number of\nchallenges including linguistic barriers \\parencite{ullah2021linguistic},\ncultural differences in learning style \\parencite{omidvar2012cultural},\ncultural sensitivity in course design \\parencite{nguyen2022cultural} and\nperceived isolation when students feel their perspectives or experiences are\nnot reflected or valued in the learning environment\n\\parencite{hansen2022belonging}. Ensuring active engagement and reasonable\nlearning outcomes in such a environments requires distance educational systems\nthat are not only adaptive but also culturally resonant\n\\parencite{dalle2024cultural}. Both embodied and virtual AI-Agents have great\npotential in this regard as they can facilitate personalized learning and adapt\ntheir interactions and content delivery to align with students' cultural\ncontext. In addition Generative AI (GAI), such as, Large Language Models (LLMs)\ncan amplify the potential for these culturally aware AI agents to address\neducational challenges due to their advanced capacity for understanding and\ngenerating contextually relevant content \\parencite{wang2024large}. This\nchapter reviews existing research and suggests the usage of culturally aware\nAI-Agents, powered by GAI, to foster engagement and improve learning outcomes\nin culturally diverse online higher education environments.", "AI": {"tldr": "\u672c\u7ae0\u63a2\u8ba8\u5728\u6587\u5316\u591a\u5143\u7684\u5728\u7ebf\u9ad8\u7b49\u6559\u80b2\u73af\u5883\u4e2d\u4f7f\u7528\u7531\u751f\u6210\u5f0fAI\u9a71\u52a8\u7684\u6587\u5316\u611f\u77e5AI\u4ee3\u7406\u6765\u4fc3\u8fdb\u5b66\u751f\u53c2\u4e0e\u5ea6\u548c\u6539\u5584\u5b66\u4e60\u6210\u679c\u3002", "motivation": "\u968f\u7740\u5728\u7ebf\u9ad8\u7b49\u6559\u80b2\u7684\u5168\u7403\u5316\u53d1\u5c55\uff0c\u5927\u5b66\u9700\u8981\u5bb9\u7eb3\u6765\u81ea\u4e0d\u540c\u6587\u5316\u80cc\u666f\u7684\u5b66\u751f\uff0c\u8fd9\u5e26\u6765\u4e86\u8bed\u8a00\u969c\u788d\u3001\u5b66\u4e60\u98ce\u683c\u5dee\u5f02\u3001\u8bfe\u7a0b\u8bbe\u8ba1\u6587\u5316\u654f\u611f\u6027\u4ee5\u53ca\u5b66\u751f\u5b64\u7acb\u611f\u7b49\u6311\u6218\u3002", "method": "\u901a\u8fc7\u56de\u987e\u73b0\u6709\u7814\u7a76\uff0c\u5efa\u8bae\u4f7f\u7528\u7531\u751f\u6210\u5f0fAI\uff08\u5982\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff09\u9a71\u52a8\u7684\u6587\u5316\u611f\u77e5AI\u4ee3\u7406\uff0c\u8fd9\u4e9b\u4ee3\u7406\u80fd\u591f\u4e2a\u6027\u5316\u5b66\u4e60\u5e76\u8c03\u6574\u4e92\u52a8\u548c\u5185\u5bb9\u4f20\u9012\u4ee5\u7b26\u5408\u5b66\u751f\u7684\u6587\u5316\u80cc\u666f\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u6587\u5316\u611f\u77e5AI\u4ee3\u7406\u5177\u6709\u4fc3\u8fdb\u4e2a\u6027\u5316\u5b66\u4e60\u548c\u9002\u5e94\u6587\u5316\u80cc\u666f\u7684\u6f5c\u529b\uff0c\u751f\u6210\u5f0fAI\u80fd\u591f\u589e\u5f3a\u8fd9\u4e9b\u4ee3\u7406\u89e3\u51b3\u6559\u80b2\u6311\u6218\u7684\u80fd\u529b\u3002", "conclusion": "\u5728\u6587\u5316\u591a\u5143\u7684\u5728\u7ebf\u9ad8\u7b49\u6559\u80b2\u73af\u5883\u4e2d\uff0c\u4f7f\u7528\u7531\u751f\u6210\u5f0fAI\u9a71\u52a8\u7684\u6587\u5316\u611f\u77e5AI\u4ee3\u7406\u53ef\u4ee5\u6709\u6548\u4fc3\u8fdb\u5b66\u751f\u53c2\u4e0e\u5ea6\u548c\u6539\u5584\u5b66\u4e60\u6210\u679c\u3002"}}
{"id": "2510.10154", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10154", "abs": "https://arxiv.org/abs/2510.10154", "authors": ["LinFeng Li", "Jian Zhao", "Yuan Xie", "Xin Tan", "Xuelong Li"], "title": "CompassNav: Steering From Path Imitation To Decision Understanding In Navigation", "comment": null, "summary": "The dominant paradigm for training Large Vision-Language Models (LVLMs) in\nnavigation relies on imitating expert trajectories. This approach reduces the\ncomplex navigation task to a sequence-to-sequence replication of a single\ncorrect path, fundamentally limiting the agent's ability to explore and\ngeneralize. In this work, we argue for and introduce a new paradigm: a shift\nfrom Path Imitation to Decision Understanding. The goal of this paradigm is to\nbuild agents that do not just follow, but truly understand how to navigate. We\nmaterialize this through two core contributions: first, we introduce\nCompass-Data-22k, a novel 22k-trajectory dataset.Its Reinforcement Fine-Tuning\n(RFT) subset provides a panoramic view of the decision landscape by annotating\nall feasible actions with A* geodesic distances. Second, we design a novel\ngap-aware hybrid reward function that dynamically adapts its feedback to\ndecision certainty, shifting between decisive signals for optimal actions and\nnuanced scores to encourage exploration. Integrated into an SFT-then-RFT\nrecipe, our CompassNav agent is trained not to memorize static routes, but to\ndevelop an internal ``compass'' that constantly intuits the direction to the\ngoal by evaluating the relative quality of all possible moves. This approach\nenables our 7B agent to set a new state-of-the-art on Goal navigation\nbenchmarks, outperforming even larger proprietary models, and achieve robust\nreal-world goal navigation on a physical robot.", "AI": {"tldr": "\u63d0\u51fa\u4ece\u8def\u5f84\u6a21\u4eff\u8f6c\u5411\u51b3\u7b56\u7406\u89e3\u7684\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7Compass-Data-22k\u6570\u636e\u96c6\u548cgap-aware\u6df7\u5408\u5956\u52b1\u51fd\u6570\uff0c\u8bad\u7ec3\u667a\u80fd\u4f53\u53d1\u5c55\u5185\u90e8\"\u6307\u5357\u9488\"\u6765\u7406\u89e3\u5bfc\u822a\u51b3\u7b56\uff0c\u5728\u5bfc\u822a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97SOTA\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u5bfc\u822a\u8bad\u7ec3\u4e2d\u4e3b\u8981\u4f9d\u8d56\u6a21\u4eff\u4e13\u5bb6\u8f68\u8ff9\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5c06\u590d\u6742\u5bfc\u822a\u4efb\u52a1\u7b80\u5316\u4e3a\u5355\u4e00\u6b63\u786e\u8def\u5f84\u7684\u5e8f\u5217\u590d\u5236\uff0c\u9650\u5236\u4e86\u667a\u80fd\u4f53\u7684\u63a2\u7d22\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "1) \u5f15\u5165Compass-Data-22k\u6570\u636e\u96c6\uff0c\u5176RFT\u5b50\u96c6\u901a\u8fc7A*\u6d4b\u5730\u8ddd\u79bb\u6807\u6ce8\u6240\u6709\u53ef\u884c\u52a8\u4f5c\uff1b2) \u8bbe\u8ba1gap-aware\u6df7\u5408\u5956\u52b1\u51fd\u6570\uff0c\u6839\u636e\u51b3\u7b56\u786e\u5b9a\u6027\u52a8\u6001\u8c03\u6574\u53cd\u9988\uff1b3) \u91c7\u7528SFT-then-RFT\u8bad\u7ec3\u6d41\u7a0b\u3002", "result": "7B\u53c2\u6570\u7684CompassNav\u667a\u80fd\u4f53\u5728\u76ee\u6807\u5bfc\u822a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u521b\u9020\u4e86\u65b0\u7684SOTA\uff0c\u8d85\u8d8a\u4e86\u66f4\u5927\u7684\u4e13\u6709\u6a21\u578b\uff0c\u5e76\u5728\u7269\u7406\u673a\u5668\u4eba\u4e0a\u5b9e\u73b0\u4e86\u9c81\u68d2\u7684\u771f\u5b9e\u4e16\u754c\u76ee\u6807\u5bfc\u822a\u3002", "conclusion": "\u51b3\u7b56\u7406\u89e3\u8303\u5f0f\u4f7f\u667a\u80fd\u4f53\u4e0d\u518d\u8bb0\u5fc6\u9759\u6001\u8def\u7ebf\uff0c\u800c\u662f\u53d1\u5c55\u5185\u90e8\"\u6307\u5357\u9488\"\u6765\u6301\u7eed\u8bc4\u4f30\u6240\u6709\u53ef\u80fd\u79fb\u52a8\u7684\u76f8\u5bf9\u8d28\u91cf\uff0c\u76f4\u89c9\u76ee\u6807\u65b9\u5411\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u5bfc\u822a\u3002"}}
{"id": "2510.10047", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10047", "abs": "https://arxiv.org/abs/2510.10047", "authors": ["Ruohao Li", "Hongjun Liu", "Leyi Zhao", "Zisu Li", "Jiawei Li", "Jiajun Jiang", "Linning Xu", "Chen Zhao", "Mingming Fan", "Chen Liang"], "title": "SwarmSys: Decentralized Swarm-Inspired Agents for Scalable and Adaptive Reasoning", "comment": "14 pages, 7 figures", "summary": "Large language model (LLM) agents have shown remarkable reasoning abilities.\nHowever, existing multi-agent frameworks often rely on fixed roles or\ncentralized control, limiting scalability and adaptability in long-horizon\nreasoning. We introduce SwarmSys, a closed-loop framework for distributed\nmulti-agent reasoning inspired by swarm intelligence. Coordination in SwarmSys\nemerges through iterative interactions among three specialized roles,\nExplorers, Workers, and Validators, that continuously cycle through\nexploration, exploitation, and validation. To enable scalable and adaptive\ncollaboration, we integrate adaptive agent and event profiles, embedding-based\nprobabilistic matching, and a pheromone-inspired reinforcement mechanism,\nsupporting dynamic task allocation and self-organizing convergence without\nglobal supervision. Across symbolic reasoning, research synthesis, and\nscientific programming tasks, SwarmSys consistently outperforms baselines,\nimproving both accuracy and reasoning stability. These findings highlight\nswarm-inspired coordination as a promising paradigm for scalable, robust, and\nadaptive multi-agent reasoning, suggesting that coordination scaling may rival\nmodel scaling in advancing LLM intelligence.", "AI": {"tldr": "SwarmSys\u662f\u4e00\u4e2a\u53d7\u7fa4\u4f53\u667a\u80fd\u542f\u53d1\u7684\u5206\u5e03\u5f0f\u591a\u667a\u80fd\u4f53\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u63a2\u7d22\u8005\u3001\u5de5\u4f5c\u8005\u548c\u9a8c\u8bc1\u8005\u4e09\u4e2a\u89d2\u8272\u7684\u8fed\u4ee3\u4ea4\u4e92\u5b9e\u73b0\u95ed\u73af\u63a8\u7406\uff0c\u65e0\u9700\u5168\u5c40\u76d1\u7763\u5373\u53ef\u5b9e\u73b0\u52a8\u6001\u4efb\u52a1\u5206\u914d\u548c\u81ea\u7ec4\u7ec7\u6536\u655b\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u6846\u67b6\u901a\u5e38\u4f9d\u8d56\u56fa\u5b9a\u89d2\u8272\u6216\u96c6\u4e2d\u63a7\u5236\uff0c\u9650\u5236\u4e86\u957f\u65f6\u7a0b\u63a8\u7406\u7684\u53ef\u6269\u5c55\u6027\u548c\u9002\u5e94\u6027\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u3001\u53ef\u6269\u5c55\u7684\u534f\u4f5c\u673a\u5236\u3002", "method": "\u96c6\u6210\u81ea\u9002\u5e94\u667a\u80fd\u4f53\u548c\u4e8b\u4ef6\u6863\u6848\u3001\u57fa\u4e8e\u5d4c\u5165\u7684\u6982\u7387\u5339\u914d\u4ee5\u53ca\u4fe1\u606f\u7d20\u542f\u53d1\u7684\u5f3a\u5316\u673a\u5236\uff0c\u652f\u6301\u52a8\u6001\u4efb\u52a1\u5206\u914d\u548c\u81ea\u7ec4\u7ec7\u6536\u655b\u3002", "result": "\u5728\u7b26\u53f7\u63a8\u7406\u3001\u7814\u7a76\u7efc\u5408\u548c\u79d1\u5b66\u7f16\u7a0b\u4efb\u52a1\u4e2d\uff0cSwarmSys\u6301\u7eed\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u63a8\u7406\u7a33\u5b9a\u6027\u3002", "conclusion": "\u7fa4\u4f53\u542f\u53d1\u7684\u534f\u8c03\u673a\u5236\u662f\u6784\u5efa\u53ef\u6269\u5c55\u3001\u9c81\u68d2\u548c\u81ea\u9002\u5e94\u591a\u667a\u80fd\u4f53\u63a8\u7406\u7684\u6709\u524d\u666f\u8303\u5f0f\uff0c\u534f\u8c03\u6269\u5c55\u53ef\u80fd\u4e0e\u6a21\u578b\u6269\u5c55\u5728\u63a8\u8fdbLLM\u667a\u80fd\u65b9\u9762\u76f8\u5ab2\u7f8e\u3002"}}
{"id": "2510.10442", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.10442", "abs": "https://arxiv.org/abs/2510.10442", "authors": ["Pei Yu Chang", "Vishnu Renganathan", "Qadeer Ahmed"], "title": "Risk-Budgeted Control Framework for Balanced Performance and Safety in Autonomous Vehicles", "comment": null, "summary": "This paper presents a risk-budgeted monitor with a control framework that\ncertifies safety for autonomous driving. In this process, a sliding window is\nproposed to monitor for insufficient barrier residuals or nonzero tail risk,\nensuring system safety. When the safety margin deteriorates, it triggers\nswitching the safety constraint from a performance-based relaxed-control\nbarrier function (R-CBF) to a conservative conditional value at risk (CVaR-CBF)\nto address the safety concern. This switching is governed by two real-time\ntriggers: Feasibility-Triggered (FT) and Quality-Triggered (QT) conditions. In\nthe FT condition, if the R-CBF constraint becomes infeasible or yields a\nsuboptimal solution, the risk monitor triggers the use of the CVaR constraints\nfor the controller. In the QT condition, the risk monitor observes the safety\nmargin of the R-CBF solution at every step, regardless of feasibility. If it\nfalls below the safety margin, the safety filter switches to the CVaR-CBF\nconstraints.\n  The proposed framework is evaluated using a model predictive controller (MPC)\nfor autonomous driving in the presence of autonomous vehicle (AV) localization\nnoise and obstacle position uncertainties. Multiple AV-pedestrian interaction\nscenarios are considered, with 1,500 Monte Carlo runs conducted for all\nscenarios. In the most challenging setting with pedestrian detection\nuncertainty of 5 m, the proposed framework achieves a 94-96% success rate of\nnot colliding with the pedestrians over 300 trials while maintaining the lowest\nmean cross-track error (CTE = 3.2-3.6 m) to the reference path. The reduced CTE\nindicates faster trajectory recovery after obstacle avoidance, demonstrating a\nbalance between safety and performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u98ce\u9669\u9884\u7b97\u76d1\u63a7\u5668\u4e0e\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u6ed1\u52a8\u7a97\u53e3\u76d1\u6d4b\u5b89\u5168\u88d5\u5ea6\uff0c\u5728\u5b89\u5168\u88d5\u5ea6\u6076\u5316\u65f6\u4ece\u6027\u80fd\u5bfc\u5411\u7684R-CBF\u5207\u6362\u5230\u4fdd\u5b88\u7684CVaR-CBF\u7ea6\u675f\uff0c\u786e\u4fdd\u81ea\u52a8\u9a7e\u9a76\u5b89\u5168\u3002", "motivation": "\u5728\u5b58\u5728\u5b9a\u4f4d\u566a\u58f0\u548c\u969c\u788d\u7269\u4f4d\u7f6e\u4e0d\u786e\u5b9a\u6027\u7684\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u4e2d\uff0c\u9700\u8981\u5e73\u8861\u5b89\u5168\u6027\u548c\u6027\u80fd\uff0c\u786e\u4fdd\u7cfb\u7edf\u5728\u5404\u79cd\u4e0d\u786e\u5b9a\u6027\u4e0b\u4ecd\u80fd\u4fdd\u6301\u5b89\u5168\u3002", "method": "\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u76d1\u6d4b\u5c4f\u969c\u6b8b\u5dee\u548c\u5c3e\u90e8\u98ce\u9669\uff0c\u901a\u8fc7\u53ef\u884c\u6027\u89e6\u53d1(FT)\u548c\u8d28\u91cf\u89e6\u53d1(QT)\u6761\u4ef6\u5b9e\u65f6\u5207\u6362R-CBF\u548cCVaR-CBF\u5b89\u5168\u7ea6\u675f\uff0c\u7ed3\u5408\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5668\u5b9e\u73b0\u5b89\u5168\u63a7\u5236\u3002", "result": "\u5728\u6700\u5177\u6311\u6218\u6027\u7684\u573a\u666f\uff085\u7c73\u884c\u4eba\u68c0\u6d4b\u4e0d\u786e\u5b9a\u6027\uff09\u4e0b\uff0c\u901a\u8fc71500\u6b21\u8499\u7279\u5361\u6d1b\u4eff\u771f\uff0c\u5b9e\u73b0\u4e8694-96%\u7684\u65e0\u78b0\u649e\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u6700\u4f4e\u7684\u5e73\u5747\u6a2a\u5411\u8ddf\u8e2a\u8bef\u5dee\uff083.2-3.6\u7c73\uff09\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\u6709\u6548\u5e73\u8861\u4e86\u5b89\u5168\u6027\u548c\u6027\u80fd\uff0c\u5728\u4e0d\u786e\u5b9a\u6027\u73af\u5883\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u5b89\u5168\u6027\u548c\u5feb\u901f\u8f68\u8ff9\u6062\u590d\u80fd\u529b\u3002"}}
{"id": "2510.10588", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.10588", "abs": "https://arxiv.org/abs/2510.10588", "authors": ["Weina Jin", "Elise Li Zheng", "Ghassan Hamarneh"], "title": "Making Power Explicable in AI: Analyzing, Understanding, and Redirecting Power to Operationalize Ethics in AI Technical Practice", "comment": null, "summary": "The operationalization of ethics in the technical practices of artificial\nintelligence (AI) is facing significant challenges. To address the problem of\nineffective implementation of AI ethics, we present our diagnosis, analysis,\nand interventional recommendations from a unique perspective of the real-world\nimplementation of AI ethics through explainable AI (XAI) techniques. We first\ndescribe the phenomenon (i.e., the \"symptoms\") of ineffective implementation of\nAI ethics in explainable AI using four empirical cases. From the \"symptoms\", we\ndiagnose the root cause (i.e., the \"disease\") being the dysfunction and\nimbalance of power structures in the sociotechnical system of AI. The power\nstructures are dominated by unjust and unchecked power that does not represent\nthe benefits and interests of the public and the most impacted communities, and\ncannot be countervailed by ethical power. Based on the understanding of power\nmechanisms, we propose three interventional recommendations to tackle the root\ncause, including: 1) Making power explicable and checked, 2) Reframing the\nnarratives and assumptions of AI and AI ethics to check unjust power and\nreflect the values and benefits of the public, and 3) Uniting the efforts of\nethical and scientific conduct of AI to encode ethical values as technical\nstandards, norms, and methods, including conducting critical examinations and\nlimitation analyses of AI technical practices. We hope that our diagnosis and\ninterventional recommendations can be a useful input to the AI community and\ncivil society's ongoing discussion and implementation of ethics in AI for\nethical and responsible AI practice.", "AI": {"tldr": "\u672c\u6587\u4ece\u53ef\u89e3\u91caAI\u89d2\u5ea6\u5206\u6790AI\u4f26\u7406\u5b9e\u65bd\u65e0\u6548\u7684\u6839\u6e90\uff0c\u8bca\u65ad\u6743\u529b\u7ed3\u6784\u5931\u8861\u662f\u6839\u672c\u539f\u56e0\uff0c\u5e76\u63d0\u51fa\u4e09\u9879\u5e72\u9884\u5efa\u8bae\uff1a\u4f7f\u6743\u529b\u53ef\u89e3\u91ca\u4e14\u53d7\u5236\u7ea6\u3001\u91cd\u6784AI\u53d9\u4e8b\u3001\u7edf\u4e00\u4f26\u7406\u4e0e\u79d1\u5b66\u5b9e\u8df5\u3002", "motivation": "\u89e3\u51b3AI\u4f26\u7406\u5728\u6280\u672f\u5b9e\u8df5\u4e2d\u5b9e\u65bd\u65e0\u6548\u7684\u95ee\u9898\uff0c\u4ece\u53ef\u89e3\u91caAI\u7684\u5b9e\u9645\u5b9e\u65bd\u89d2\u5ea6\u63d0\u4f9b\u8bca\u65ad\u548c\u5e72\u9884\u5efa\u8bae\u3002", "method": "\u901a\u8fc7\u56db\u4e2a\u5b9e\u8bc1\u6848\u4f8b\u63cf\u8ff0AI\u4f26\u7406\u5b9e\u65bd\u65e0\u6548\u7684\"\u75c7\u72b6\"\uff0c\u8bca\u65ad\u6743\u529b\u7ed3\u6784\u5931\u8861\u7684\"\u75c5\u56e0\"\uff0c\u63d0\u51fa\u4e09\u9879\u5e72\u9884\u5efa\u8bae\u3002", "result": "\u8bc6\u522b\u51faAI\u793e\u4f1a\u6280\u672f\u7cfb\u7edf\u4e2d\u6743\u529b\u7ed3\u6784\u5931\u8861\u662f\u4f26\u7406\u5b9e\u65bd\u65e0\u6548\u7684\u6839\u6e90\uff0c\u6743\u529b\u88ab\u4e0d\u516c\u6b63\u4e14\u4e0d\u53d7\u5236\u7ea6\u7684\u529b\u91cf\u4e3b\u5bfc\uff0c\u65e0\u6cd5\u88ab\u4f26\u7406\u529b\u91cf\u5236\u8861\u3002", "conclusion": "\u63d0\u51fa\u7684\u8bca\u65ad\u548c\u5e72\u9884\u5efa\u8bae\u53ef\u4e3aAI\u793e\u533a\u548c\u516c\u6c11\u793e\u4f1a\u5728AI\u4f26\u7406\u5b9e\u65bd\u8ba8\u8bba\u4e2d\u63d0\u4f9b\u6709\u7528\u53c2\u8003\uff0c\u4fc3\u8fdb\u4f26\u7406\u548c\u8d1f\u8d23\u4efb\u7684AI\u5b9e\u8df5\u3002"}}
{"id": "2510.10181", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.10181", "abs": "https://arxiv.org/abs/2510.10181", "authors": ["Shaokai Wu", "Yanbiao Ji", "Qiuchang Li", "Zhiyi Zhang", "Qichen He", "Wenyuan Xie", "Guodong Zhang", "Bayram Bayramli", "Yue Ding", "Hongtao Lu"], "title": "Dejavu: Post-Deployment Learning for Embodied Agents via Experience Feedback", "comment": null, "summary": "Embodied agents face a fundamental limitation: once deployed in real-world\nenvironments to perform specific tasks, they are unable to acquire new useful\nknowledge to enhance task performance. In this paper, we propose a general\npost-deployment learning framework called Dejavu, which employs an Experience\nFeedback Network (EFN) and augments the frozen Vision-Language-Action (VLA)\npolicy with retrieved execution memories. EFN automatically identifies\ncontextually successful prior action experiences and conditions action\nprediction on this retrieved guidance. We adopt reinforcement learning with\nsemantic similarity rewards on EFN to ensure that the predicted actions align\nwith past successful behaviors under current observations. During deployment,\nEFN continually enriches its memory with new trajectories, enabling the agent\nto exhibit \"learning from experience\" despite fixed weights. Experiments across\ndiverse embodied tasks show that EFN significantly improves adaptability,\nrobustness, and success rates over frozen baselines. These results highlight a\npromising path toward embodied agents that continually refine their behavior\nafter deployment.", "AI": {"tldr": "Dejavu\u6846\u67b6\u901a\u8fc7\u7ecf\u9a8c\u53cd\u9988\u7f51\u7edc(EFN)\u548c\u8bb0\u5fc6\u68c0\u7d22\u673a\u5236\uff0c\u4f7f\u5df2\u90e8\u7f72\u7684\u5177\u8eab\u667a\u80fd\u4f53\u80fd\u591f\u4ece\u6267\u884c\u7ecf\u9a8c\u4e2d\u5b66\u4e60\uff0c\u63d0\u5347\u4efb\u52a1\u6027\u80fd\u800c\u65e0\u9700\u66f4\u65b0\u6a21\u578b\u6743\u91cd\u3002", "motivation": "\u89e3\u51b3\u5df2\u90e8\u7f72\u5177\u8eab\u667a\u80fd\u4f53\u65e0\u6cd5\u83b7\u53d6\u65b0\u77e5\u8bc6\u6765\u63d0\u5347\u4efb\u52a1\u6027\u80fd\u7684\u6839\u672c\u9650\u5236\uff0c\u5b9e\u73b0\u90e8\u7f72\u540e\u7684\u6301\u7eed\u5b66\u4e60\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u7ecf\u9a8c\u53cd\u9988\u7f51\u7edc(EFN)\uff0c\u901a\u8fc7\u68c0\u7d22\u6210\u529f\u7684\u5148\u9a8c\u52a8\u4f5c\u7ecf\u9a8c\u6765\u589e\u5f3a\u51bb\u7ed3\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c(VLA)\u7b56\u7565\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u5ea6\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u6765\u786e\u4fdd\u9884\u6d4b\u52a8\u4f5c\u4e0e\u8fc7\u53bb\u6210\u529f\u884c\u4e3a\u4e00\u81f4\u3002", "result": "\u5728\u591a\u6837\u5316\u5177\u8eab\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0cEFN\u663e\u8457\u63d0\u9ad8\u4e86\u9002\u5e94\u6027\u3001\u9c81\u68d2\u6027\u548c\u6210\u529f\u7387\uff0c\u4f18\u4e8e\u51bb\u7ed3\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "Dejavu\u6846\u67b6\u4e3a\u5b9e\u73b0\u90e8\u7f72\u540e\u6301\u7eed\u4f18\u5316\u884c\u4e3a\u7684\u5177\u8eab\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u4e00\u6761\u6709\u524d\u666f\u7684\u8def\u5f84\u3002"}}
{"id": "2510.10069", "categories": ["cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.10069", "abs": "https://arxiv.org/abs/2510.10069", "authors": ["Zeyu Ling", "Xiaodong Gu", "Jiangnan Tang", "Changqing Zou"], "title": "SyncLipMAE: Contrastive Masked Pretraining for Audio-Visual Talking-Face Representation", "comment": null, "summary": "We introduce SyncLipMAE, a self-supervised pretraining framework for\ntalking-face video that learns synchronization-aware and transferable facial\ndynamics from unlabeled audio-visual streams. Our approach couples masked\nvisual modeling with cross-modal contrastive alignment and employs three\nper-frame prompt tokens that explicitly encode the essential factors of a\ntalking-face frame - identity, vocal motion (speech-synchronized facial\ndynamics), and ambient motion (audio-agnostic movements such as blinks and head\npose). The contrastive objective uses time-aligned vocal-motion and audio\ntokens as positives and misaligned pairs as negatives, driving both modalities\ninto a shared embedding space and yielding token-level audio-visual stream\nsynchronization. After pretraining, the aligned audio tokens together with the\nvisual prompt tokens (identity, vocal motion, ambient motion) form a unified\ninterface for four disparate downstream settings: (i) audio-visual stream\nsynchronization; (ii) facial emotion and head/face action recognition; (iii)\nvisual speech recognition; and (iv) visual dubbing, for which we enable\nindistinguishable audio- or video-driven control within a single model. Across\nfour task families that require distinct capabilities, SyncLipMAE achieves\nstate-of-the-art results, underscoring the effectiveness of\nsynchronization-aware, factorized self-supervised pretraining.", "AI": {"tldr": "SyncLipMAE\u662f\u4e00\u4e2a\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u63a9\u7801\u89c6\u89c9\u5efa\u6a21\u548c\u8de8\u6a21\u6001\u5bf9\u6bd4\u5bf9\u9f50\uff0c\u4ece\u65e0\u6807\u7b7e\u97f3\u89c6\u9891\u6d41\u4e2d\u5b66\u4e60\u540c\u6b65\u611f\u77e5\u548c\u53ef\u8f6c\u79fb\u7684\u9762\u90e8\u52a8\u6001\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u8bf4\u8bdd\u4eba\u8138\u89c6\u9891\u4e2d\u9762\u90e8\u52a8\u6001\u4e0e\u97f3\u9891\u540c\u6b65\u7684\u95ee\u9898\uff0c\u5e76\u5b66\u4e60\u53ef\u8f6c\u79fb\u7684\u9762\u90e8\u52a8\u6001\u8868\u793a\uff0c\u4ee5\u652f\u6301\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\u3002", "method": "\u7ed3\u5408\u63a9\u7801\u89c6\u89c9\u5efa\u6a21\u548c\u8de8\u6a21\u6001\u5bf9\u6bd4\u5bf9\u9f50\uff0c\u4f7f\u7528\u4e09\u4e2a\u9010\u5e27\u63d0\u793a\u4ee4\u724c\u5206\u522b\u7f16\u7801\u8eab\u4efd\u3001\u8bed\u97f3\u540c\u6b65\u9762\u90e8\u52a8\u6001\u548c\u97f3\u9891\u65e0\u5173\u8fd0\u52a8\u3002\u5bf9\u6bd4\u76ee\u6807\u4f7f\u7528\u65f6\u95f4\u5bf9\u9f50\u7684\u8bed\u97f3\u8fd0\u52a8\u548c\u97f3\u9891\u4ee4\u724c\u4f5c\u4e3a\u6b63\u6837\u672c\uff0c\u9519\u4f4d\u5bf9\u4f5c\u4e3a\u8d1f\u6837\u672c\u3002", "result": "\u5728\u56db\u4e2a\u9700\u8981\u4e0d\u540c\u80fd\u529b\u7684\u4efb\u52a1\u7cfb\u5217\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u5305\u62ec\u97f3\u89c6\u9891\u6d41\u540c\u6b65\u3001\u9762\u90e8\u8868\u60c5\u548c\u5934\u90e8/\u9762\u90e8\u52a8\u4f5c\u8bc6\u522b\u3001\u89c6\u89c9\u8bed\u97f3\u8bc6\u522b\u548c\u89c6\u89c9\u914d\u97f3\u3002", "conclusion": "\u540c\u6b65\u611f\u77e5\u3001\u5206\u89e3\u7684\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6709\u6548\u6027\uff0c\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u7684\u901a\u7528\u6027\u548c\u5f3a\u5927\u6027\u80fd\u3002"}}
{"id": "2510.10450", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.10450", "abs": "https://arxiv.org/abs/2510.10450", "authors": ["P Sangeerth", "David Smith Sundarsingh", "Bhabani Shankar Dey", "Pushpak Jagtap"], "title": "Controller for Incremental Input-to-State Practical Stabilization of Partially Unknown systems with Invariance Guarantees", "comment": "2 figures,9 pages", "summary": "Incremental stability is a property of dynamical systems that ensures the\nconvergence of trajectories with respect to each other rather than a fixed\nequilibrium point or a fixed trajectory. In this paper, we introduce a related\nstability notion called incremental input-to-state practical stability\n({\\delta}-ISpS), ensuring safety guarantees. We also present a feedback\nlinearization based control design scheme that renders a partially unknown\nsystem incrementally input-to-state practically stable and safe with formal\nguarantees. To deal with the unknown dynamics, we utilize Gaussian process\nregression to approximate the model. Finally, we implement the controller\nsynthesized by the proposed scheme on a manipulator example", "AI": {"tldr": "\u63d0\u51fa\u589e\u91cf\u8f93\u5165\u5230\u72b6\u6001\u5b9e\u7528\u7a33\u5b9a\u6027\u6982\u5ff5\uff0c\u57fa\u4e8e\u53cd\u9988\u7ebf\u6027\u5316\u548c\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u5904\u7406\u672a\u77e5\u52a8\u6001\uff0c\u786e\u4fdd\u7cfb\u7edf\u5b89\u5168\u6027\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u589e\u91cf\u7a33\u5b9a\u6027\u786e\u4fdd\u8f68\u8ff9\u76f8\u4e92\u6536\u655b\u800c\u975e\u56fa\u5b9a\u5e73\u8861\u70b9\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5b89\u5168\u4fdd\u8bc1\uff0c\u9700\u8981\u7ed3\u5408\u8f93\u5165\u5230\u72b6\u6001\u7a33\u5b9a\u6027\u6982\u5ff5\u3002", "method": "\u4f7f\u7528\u53cd\u9988\u7ebf\u6027\u5316\u63a7\u5236\u8bbe\u8ba1\uff0c\u7ed3\u5408\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u8fd1\u4f3c\u672a\u77e5\u52a8\u6001\uff0c\u5b9e\u73b0\u589e\u91cf\u8f93\u5165\u5230\u72b6\u6001\u5b9e\u7528\u7a33\u5b9a\u6027\u3002", "result": "\u5728\u673a\u68b0\u81c2\u793a\u4f8b\u4e0a\u6210\u529f\u5b9e\u73b0\u4e86\u6240\u63d0\u51fa\u7684\u63a7\u5236\u5668\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u63a7\u5236\u65b9\u6848\u80fd\u591f\u5904\u7406\u90e8\u5206\u672a\u77e5\u7cfb\u7edf\uff0c\u63d0\u4f9b\u5f62\u5f0f\u5316\u5b89\u5168\u4fdd\u8bc1\uff0c\u5b9e\u73b0\u589e\u91cf\u8f93\u5165\u5230\u72b6\u6001\u5b9e\u7528\u7a33\u5b9a\u6027\u3002"}}
{"id": "2510.10732", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.10732", "abs": "https://arxiv.org/abs/2510.10732", "authors": ["Tamara Paris", "Shalaleh Rismani"], "title": "When Openness Fails: Lessons from System Safety for Assessing Openness in AI", "comment": "Accepted to Symposium on Model Accountability, Sustainability and\n  Healthcare (SMASH) 2025", "summary": "Most frameworks for assessing the openness of AI systems use narrow criteria\nsuch as availability of data, model, code, documentation, and licensing terms.\nHowever, to evaluate whether the intended effects of openness - such as\ndemocratization and autonomy - are realized, we need a more holistic approach\nthat considers the context of release: who will reuse the system, for what\npurposes, and under what conditions. To this end, we adapt five lessons from\nsystem safety that offer guidance on how openness can be evaluated at the\nsystem level.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u9700\u8981\u8d85\u8d8a\u4f20\u7edf\u7684AI\u7cfb\u7edf\u5f00\u653e\u6027\u8bc4\u4f30\u6807\u51c6\uff0c\u91c7\u7528\u66f4\u5168\u9762\u7684\u7cfb\u7edf\u7ea7\u65b9\u6cd5\u6765\u8bc4\u4f30\u5f00\u653e\u6027\u7684\u5b9e\u9645\u6548\u679c\u3002", "motivation": "\u73b0\u6709AI\u7cfb\u7edf\u5f00\u653e\u6027\u8bc4\u4f30\u6846\u67b6\u4ec5\u5173\u6ce8\u6570\u636e\u3001\u6a21\u578b\u3001\u4ee3\u7801\u7b49\u72ed\u7a84\u6807\u51c6\uff0c\u65e0\u6cd5\u8bc4\u4f30\u5f00\u653e\u6027\u662f\u5426\u771f\u6b63\u5b9e\u73b0\u4e86\u6c11\u4e3b\u5316\u548c\u81ea\u4e3b\u6027\u7b49\u9884\u671f\u6548\u679c\u3002", "method": "\u501f\u9274\u7cfb\u7edf\u5b89\u5168\u7684\u4e94\u4e2a\u7ecf\u9a8c\u6559\u8bad\uff0c\u63d0\u51fa\u5728\u7cfb\u7edf\u5c42\u9762\u8bc4\u4f30\u5f00\u653e\u6027\u7684\u65b9\u6cd5\uff0c\u8003\u8651\u53d1\u5e03\u80cc\u666f\u3001\u7528\u6237\u7fa4\u4f53\u3001\u4f7f\u7528\u76ee\u7684\u548c\u6761\u4ef6\u7b49\u56e0\u7d20\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u66f4\u5168\u9762\u7684\u5f00\u653e\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u66f4\u597d\u5730\u8bc4\u4f30\u5f00\u653e\u6027\u662f\u5426\u5b9e\u73b0\u4e86\u5176\u9884\u671f\u76ee\u6807\u3002", "conclusion": "\u8bc4\u4f30AI\u7cfb\u7edf\u5f00\u653e\u6027\u9700\u8981\u91c7\u7528\u7cfb\u7edf\u7ea7\u89c6\u89d2\uff0c\u8003\u8651\u66f4\u5e7f\u6cdb\u7684\u56e0\u7d20\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u6280\u672f\u7ec4\u4ef6\u7684\u53ef\u7528\u6027\u3002"}}
{"id": "2510.10206", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.10206", "abs": "https://arxiv.org/abs/2510.10206", "authors": ["Zuhong Liu", "Junhao Ge", "Minhao Xiong", "Jiahao Gu", "Bowei Tang", "Wei Jing", "Siheng Chen"], "title": "It Takes Two: Learning Interactive Whole-Body Control Between Humanoid Robots", "comment": null, "summary": "The true promise of humanoid robotics lies beyond single-agent autonomy: two\nor more humanoids must engage in physically grounded, socially meaningful\nwhole-body interactions that echo the richness of human social interaction.\nHowever, single-humanoid methods suffer from the isolation issue, ignoring\ninter-agent dynamics and causing misaligned contacts, interpenetrations, and\nunrealistic motions. To address this, we present Harmanoid , a dual-humanoid\nmotion imitation framework that transfers interacting human motions to two\nrobots while preserving both kinematic fidelity and physical realism. Harmanoid\ncomprises two key components: (i) contact-aware motion retargeting, which\nrestores inter-body coordination by aligning SMPL contacts with robot vertices,\nand (ii) interaction-driven motion controller, which leverages\ninteraction-specific rewards to enforce coordinated keypoints and physically\nplausible contacts. By explicitly modeling inter-agent contacts and\ninteraction-aware dynamics, Harmanoid captures the coupled behaviors between\nhumanoids that single-humanoid frameworks inherently overlook. Experiments\ndemonstrate that Harmanoid significantly improves interactive motion imitation,\nsurpassing existing single-humanoid frameworks that largely fail in such\nscenarios.", "AI": {"tldr": "Harmanoid\u662f\u4e00\u4e2a\u53cc\u4eba\u5f62\u673a\u5668\u4eba\u8fd0\u52a8\u6a21\u4eff\u6846\u67b6\uff0c\u80fd\u591f\u5c06\u4ea4\u4e92\u5f0f\u4eba\u4f53\u8fd0\u52a8\u8f6c\u79fb\u5230\u4e24\u4e2a\u673a\u5668\u4eba\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u8fd0\u52a8\u5b66\u4fdd\u771f\u5ea6\u548c\u7269\u7406\u771f\u5b9e\u6027\u3002", "motivation": "\u5f53\u524d\u5355\u4eba\u5f62\u673a\u5668\u4eba\u65b9\u6cd5\u5b58\u5728\u9694\u79bb\u95ee\u9898\uff0c\u5ffd\u7565\u4e86\u667a\u80fd\u4f53\u95f4\u7684\u52a8\u6001\u4ea4\u4e92\uff0c\u5bfc\u81f4\u63a5\u89e6\u9519\u4f4d\u3001\u76f8\u4e92\u7a7f\u900f\u548c\u4e0d\u771f\u5b9e\u7684\u8fd0\u52a8\u3002\u9700\u8981\u89e3\u51b3\u591a\u4eba\u5f62\u673a\u5668\u4eba\u4e4b\u95f4\u7684\u7269\u7406\u63a5\u5730\u3001\u793e\u4f1a\u610f\u4e49\u7684\u5168\u8eab\u4ea4\u4e92\u95ee\u9898\u3002", "method": "\u5305\u542b\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a(1) \u63a5\u89e6\u611f\u77e5\u7684\u8fd0\u52a8\u91cd\u5b9a\u5411\uff0c\u901a\u8fc7\u5c06SMPL\u63a5\u89e6\u4e0e\u673a\u5668\u4eba\u9876\u70b9\u5bf9\u9f50\u6765\u6062\u590d\u8eab\u4f53\u95f4\u534f\u8c03\uff1b(2) \u4ea4\u4e92\u9a71\u52a8\u7684\u8fd0\u52a8\u63a7\u5236\u5668\uff0c\u5229\u7528\u4ea4\u4e92\u7279\u5b9a\u5956\u52b1\u6765\u5f3a\u5236\u6267\u884c\u534f\u8c03\u7684\u5173\u952e\u70b9\u548c\u7269\u7406\u4e0a\u5408\u7406\u7684\u63a5\u89e6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cHarmanoid\u663e\u8457\u6539\u5584\u4e86\u4ea4\u4e92\u5f0f\u8fd0\u52a8\u6a21\u4eff\uff0c\u8d85\u8d8a\u4e86\u5728\u7c7b\u4f3c\u573a\u666f\u4e2d\u5927\u591a\u5931\u8d25\u7684\u73b0\u6709\u5355\u4eba\u5f62\u6846\u67b6\u3002", "conclusion": "\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u667a\u80fd\u4f53\u95f4\u63a5\u89e6\u548c\u4ea4\u4e92\u611f\u77e5\u52a8\u6001\uff0cHarmanoid\u6355\u6349\u5230\u4e86\u5355\u4eba\u5f62\u6846\u67b6\u56fa\u6709\u5ffd\u7565\u7684\u4eba\u5f62\u673a\u5668\u4eba\u4e4b\u95f4\u7684\u8026\u5408\u884c\u4e3a\u3002"}}
{"id": "2510.10074", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10074", "abs": "https://arxiv.org/abs/2510.10074", "authors": ["Jiayi Mao", "Liqun Li", "Yanjie Gao", "Zegang Peng", "Shilin He", "Chaoyun Zhang", "Si Qin", "Samia Khalid", "Qingwei Lin", "Saravan Rajmohan", "Sitaram Lanka", "Dongmei Zhang"], "title": "Agentic Troubleshooting Guide Automation for Incident Management", "comment": null, "summary": "Effective incident management in large-scale IT systems relies on\ntroubleshooting guides (TSGs), but their manual execution is slow and\nerror-prone. While recent advances in LLMs offer promise for automating\nincident management tasks, existing LLM-based solutions lack specialized\nsupport for several key challenges, including managing TSG quality issues,\ninterpreting complex control flow, handling data-intensive queries, and\nexploiting execution parallelism. We first conducted an empirical study on 92\nreal-world TSGs, and, guided by our findings, we present StepFly, a novel\nend-to-end agentic framework for troubleshooting guide automation. Our approach\nfeatures a three-stage workflow: the first stage provides a comprehensive guide\ntogether with a tool, TSG Mentor, to assist SREs in improving TSG quality; the\nsecond stage performs offline preprocessing using LLMs to extract structured\nexecution DAGs from unstructured TSGs and to create dedicated Query Preparation\nPlugins (QPPs); and the third stage executes online using a DAG-guided\nscheduler-executor framework with a memory system to guarantee correct workflow\nand support parallel execution of independent steps. Our empirical evaluation\non a collection of real-world TSGs and incidents demonstrates that StepFly\nachieves a ~94% success rate on GPT-4.1, outperforming baselines with less time\nand token consumption. Furthermore, it achieves a remarkable execution time\nreduction of 32.9% to 70.4% for parallelizable TSGs.", "AI": {"tldr": "StepFly\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u81ea\u52a8\u5316\u6545\u969c\u6392\u9664\u6307\u5357\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u5de5\u4f5c\u6d41\u89e3\u51b3TSG\u8d28\u91cf\u95ee\u9898\u3001\u590d\u6742\u63a7\u5236\u6d41\u89e3\u91ca\u3001\u6570\u636e\u5bc6\u96c6\u578b\u67e5\u8be2\u548c\u6267\u884c\u5e76\u884c\u5316\u7b49\u5173\u952e\u6311\u6218\uff0c\u5728\u771f\u5b9eTSG\u548c\u4e8b\u4ef6\u4e0a\u8fbe\u5230\u7ea694%\u7684\u6210\u529f\u7387\uff0c\u663e\u8457\u51cf\u5c11\u6267\u884c\u65f6\u95f4\u3002", "motivation": "\u5927\u89c4\u6a21IT\u7cfb\u7edf\u4e2d\u7684\u6545\u969c\u7ba1\u7406\u4f9d\u8d56\u6545\u969c\u6392\u9664\u6307\u5357(TSG)\uff0c\u4f46\u624b\u52a8\u6267\u884c\u7f13\u6162\u4e14\u5bb9\u6613\u51fa\u9519\u3002\u73b0\u6709\u7684\u57fa\u4e8eLLM\u7684\u89e3\u51b3\u65b9\u6848\u7f3a\u4e4f\u5bf9TSG\u8d28\u91cf\u95ee\u9898\u3001\u590d\u6742\u63a7\u5236\u6d41\u89e3\u91ca\u3001\u6570\u636e\u5bc6\u96c6\u578b\u67e5\u8be2\u548c\u6267\u884c\u5e76\u884c\u5316\u7b49\u5173\u952e\u6311\u6218\u7684\u4e13\u4e1a\u652f\u6301\u3002", "method": "StepFly\u91c7\u7528\u4e09\u9636\u6bb5\u5de5\u4f5c\u6d41\uff1a1) TSG Mentor\u5de5\u5177\u534f\u52a9SRE\u6539\u8fdbTSG\u8d28\u91cf\uff1b2) \u79bb\u7ebf\u9884\u5904\u7406\u4f7f\u7528LLM\u4ece\u975e\u7ed3\u6784\u5316TSG\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u6267\u884cDAG\u5e76\u521b\u5efa\u4e13\u7528\u67e5\u8be2\u51c6\u5907\u63d2\u4ef6(QPPs)\uff1b3) \u5728\u7ebf\u6267\u884c\u4f7f\u7528DAG\u5f15\u5bfc\u7684\u8c03\u5ea6\u5668-\u6267\u884c\u5668\u6846\u67b6\uff0c\u652f\u6301\u5e76\u884c\u6267\u884c\u72ec\u7acb\u6b65\u9aa4\u3002", "result": "\u5728\u771f\u5b9eTSG\u548c\u4e8b\u4ef6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cStepFly\u5728GPT-4.1\u4e0a\u8fbe\u5230\u7ea694%\u7684\u6210\u529f\u7387\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u65f6\u95f4\u548ctoken\u6d88\u8017\u66f4\u5c11\u3002\u5bf9\u4e8e\u53ef\u5e76\u884c\u5316\u7684TSG\uff0c\u5b9e\u73b0\u4e8632.9%\u523070.4%\u7684\u663e\u8457\u6267\u884c\u65f6\u95f4\u51cf\u5c11\u3002", "conclusion": "StepFly\u901a\u8fc7\u5176\u521b\u65b0\u7684\u4e09\u9636\u6bb5\u5de5\u4f5c\u6d41\u548cDAG\u5f15\u5bfc\u7684\u6267\u884c\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86TSG\u81ea\u52a8\u5316\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6545\u969c\u6392\u9664\u7684\u6548\u7387\u548c\u6210\u529f\u7387\u3002"}}
{"id": "2510.10552", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.10552", "abs": "https://arxiv.org/abs/2510.10552", "authors": ["Rafael R. Yumul", "Enalyn T. Domingo"], "title": "Transforming Tarlac State University (TSU) Gymnasium to a Nearly Zero-Energy Building through Integration of a Solar Photovoltaic (PV) System", "comment": null, "summary": "The study is anchored to the principles of Nearly-Zero Energy Building\n(NZEB). It aimed to transform the Tarlac State University Gymnasium into a\nfacility with energy-efficient equipment to contribute to reducing carbon\nfootprints by integrating a solar PV system as its renewable energy source. The\nresearchers found out that the electrical infrastructure of the Gym was\noutdated, and the lighting was not energy efficient, and there were too few\nconvenience or power outlets. There was also insufficient cooling equipment to\nmaintain a comfortable temperature. Analysis shows that the payback period is\nwithin the average range, making it a cost-effective investment for the\nUniversity. Aside from the cost of the PV System, adherence to engineering\ndesign standards will mean additional costs to replace the metal halides with\nLED high bay lamps, installation of additional air conditioning units, and\nprovision of additional convenience outlets. These additional costs should be\nconsidered when evaluating the feasibility of the project. It is recommended\nthat the integrity of the existing roof system of the Gymnasium be considered.\nThe total cost of putting up the whole electrical system, including new\nlighting, cooling, and convenience loads, must be calculated to determine the\ntotal cost of implementing the whole NZEB project. Other factors in the\neconomic evaluation may be considered to determine a more stringent result.", "AI": {"tldr": "\u8be5\u7814\u7a76\u65e8\u5728\u5c06Tarlac\u5dde\u7acb\u5927\u5b66\u4f53\u80b2\u9986\u6539\u9020\u4e3a\u8fd1\u96f6\u80fd\u8017\u5efa\u7b51\uff0c\u901a\u8fc7\u96c6\u6210\u592a\u9633\u80fd\u5149\u4f0f\u7cfb\u7edf\u5b9e\u73b0\u80fd\u6e90\u6548\u7387\uff0c\u51cf\u5c11\u78b3\u8db3\u8ff9\u3002\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u7535\u6c14\u57fa\u7840\u8bbe\u65bd\u8fc7\u65f6\uff0c\u7167\u660e\u4e0d\u8282\u80fd\uff0c\u63d2\u5ea7\u4e0d\u8db3\uff0c\u5236\u51b7\u8bbe\u5907\u4e0d\u591f\u3002\u6295\u8d44\u56de\u6536\u671f\u5728\u5e73\u5747\u8303\u56f4\u5185\uff0c\u4f46\u9700\u8981\u8003\u8651\u989d\u5916\u7684\u6539\u9020\u6210\u672c\u3002", "motivation": "\u57fa\u4e8e\u8fd1\u96f6\u80fd\u8017\u5efa\u7b51\u539f\u5219\uff0c\u5c06\u5927\u5b66\u4f53\u80b2\u9986\u6539\u9020\u4e3a\u80fd\u6e90\u9ad8\u6548\u8bbe\u65bd\uff0c\u901a\u8fc7\u53ef\u518d\u751f\u80fd\u6e90\u6574\u5408\u51cf\u5c11\u78b3\u8db3\u8ff9\uff0c\u89e3\u51b3\u73b0\u6709\u7535\u6c14\u57fa\u7840\u8bbe\u65bd\u8fc7\u65f6\u3001\u7167\u660e\u4e0d\u8282\u80fd\u3001\u63d2\u5ea7\u4e0d\u8db3\u548c\u5236\u51b7\u8bbe\u5907\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u5206\u6790\u4f53\u80b2\u9986\u73b0\u6709\u7535\u6c14\u57fa\u7840\u8bbe\u65bd\uff0c\u96c6\u6210\u592a\u9633\u80fd\u5149\u4f0f\u7cfb\u7edf\u4f5c\u4e3a\u53ef\u518d\u751f\u80fd\u6e90\u6765\u6e90\uff0c\u66ff\u6362\u91d1\u5c5e\u5364\u5316\u7269\u706f\u4e3aLED\u9ad8\u68da\u706f\uff0c\u589e\u52a0\u7a7a\u8c03\u673a\u7ec4\u548c\u4fbf\u5229\u63d2\u5ea7\uff0c\u8fdb\u884c\u7ecf\u6d4e\u53ef\u884c\u6027\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4f53\u80b2\u9986\u7535\u6c14\u57fa\u7840\u8bbe\u65bd\u8fc7\u65f6\uff0c\u7167\u660e\u4e0d\u8282\u80fd\uff0c\u63d2\u5ea7\u4e0d\u8db3\uff0c\u5236\u51b7\u8bbe\u5907\u4e0d\u591f\u3002\u592a\u9633\u80fd\u5149\u4f0f\u7cfb\u7edf\u7684\u6295\u8d44\u56de\u6536\u671f\u5728\u5e73\u5747\u8303\u56f4\u5185\uff0c\u4f46\u9700\u8981\u8003\u8651\u66f4\u6362\u706f\u5177\u3001\u589e\u52a0\u7a7a\u8c03\u548c\u63d2\u5ea7\u7b49\u989d\u5916\u6210\u672c\u3002", "conclusion": "\u9879\u76ee\u5728\u6210\u672c\u6548\u76ca\u4e0a\u662f\u53ef\u884c\u7684\u6295\u8d44\uff0c\u4f46\u9700\u8981\u5168\u9762\u8ba1\u7b97\u6574\u4e2a\u7535\u6c14\u7cfb\u7edf\u7684\u603b\u6210\u672c\uff0c\u5305\u62ec\u65b0\u7167\u660e\u3001\u5236\u51b7\u548c\u63d2\u5ea7\u8d1f\u8f7d\uff0c\u5e76\u8003\u8651\u5c4b\u9876\u7ed3\u6784\u5b8c\u6574\u6027\u3002\u5efa\u8bae\u8fdb\u884c\u66f4\u4e25\u683c\u7684\u7ecf\u6d4e\u8bc4\u4f30\u4ee5\u786e\u5b9a\u6700\u7ec8\u53ef\u884c\u6027\u3002"}}
{"id": "2510.11064", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.11064", "abs": "https://arxiv.org/abs/2510.11064", "authors": ["Isabella Gra\u00dfl", "Benedikt Fein", "Gordon Fraser"], "title": "Detecting Gender Stereotypes in Scratch Programming Tutorials", "comment": "Koli Calling 2025", "summary": "Gender stereotypes in introductory programming courses often go unnoticed,\nyet they can negatively influence young learners' interest and learning,\nparticularly under-represented groups such as girls. Popular tutorials on\nblock-based programming with Scratch may unintentionally reinforce biases\nthrough character choices, narrative framing, or activity types. Educators\ncurrently lack support in identifying and addressing such bias. With large\nlanguage models~(LLMs) increasingly used to generate teaching materials, this\nproblem is potentially exacerbated by LLMs trained on biased datasets. However,\nLLMs also offer an opportunity to address this issue. In this paper, we explore\nthe use of LLMs for automatically identifying gender-stereotypical elements in\nScratch tutorials, thus offering feedback on how to improve teaching content.\nWe develop a framework for assessing gender bias considering characters,\ncontent, instructions, and programming concepts. Analogous to how code analysis\ntools provide feedback on code in terms of code smells, we operationalise this\nframework using an automated tool chain that identifies *gender stereotype\nsmells*. Evaluation on 73 popular Scratch tutorials from leading educational\nplatforms demonstrates that stereotype smells are common in practice. LLMs are\nnot effective at detecting them, but our gender bias evaluation framework can\nguide LLMs in generating tutorials with fewer stereotype smells.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u8bc6\u522bScratch\u6559\u7a0b\u4e2d\u7684\u6027\u522b\u523b\u677f\u5370\u8c61\u5143\u7d20\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u8bc4\u4f30\u6027\u522b\u504f\u89c1\u7684\u6846\u67b6\uff0c\u5e76\u53d1\u73b0LLMs\u5728\u68c0\u6d4b\u523b\u677f\u5370\u8c61\u65b9\u9762\u6548\u679c\u4e0d\u4f73\uff0c\u4f46\u53ef\u4ee5\u6307\u5bfc\u751f\u6210\u66f4\u5c11\u504f\u89c1\u7684\u6559\u7a0b\u3002", "motivation": "\u5165\u95e8\u7f16\u7a0b\u8bfe\u7a0b\u4e2d\u7684\u6027\u522b\u523b\u677f\u5370\u8c61\u5f80\u5f80\u88ab\u5ffd\u89c6\uff0c\u4f46\u4f1a\u5bf9\u5e74\u8f7b\u5b66\u4e60\u8005\u7279\u522b\u662f\u5973\u5b69\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u3002\u5f53\u524d\u6559\u80b2\u8005\u7f3a\u4e4f\u8bc6\u522b\u548c\u89e3\u51b3\u8fd9\u79cd\u504f\u89c1\u7684\u65b9\u6cd5\uff0c\u800cLLMs\u7684\u5e7f\u6cdb\u5e94\u7528\u53ef\u80fd\u52a0\u5267\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u8bc4\u4f30\u6027\u522b\u504f\u89c1\u7684\u6846\u67b6\uff0c\u8003\u8651\u89d2\u8272\u3001\u5185\u5bb9\u3001\u6307\u4ee4\u548c\u7f16\u7a0b\u6982\u5ff5\uff0c\u5e76\u521b\u5efa\u4e86\u81ea\u52a8\u5de5\u5177\u94fe\u6765\u8bc6\u522b\"\u6027\u522b\u523b\u677f\u5370\u8c61\u6c14\u5473\"\u3002\u572873\u4e2a\u6d41\u884c\u7684Scratch\u6559\u7a0b\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u523b\u677f\u5370\u8c61\u6c14\u5473\u5728\u5b9e\u8df5\u4e2d\u5f88\u5e38\u89c1\u3002LLMs\u5728\u68c0\u6d4b\u8fd9\u4e9b\u6c14\u5473\u65b9\u9762\u6548\u679c\u4e0d\u4f73\uff0c\u4f46\u6027\u522b\u504f\u89c1\u8bc4\u4f30\u6846\u67b6\u53ef\u4ee5\u6307\u5bfcLLMs\u751f\u6210\u523b\u677f\u5370\u8c61\u6c14\u5473\u66f4\u5c11\u7684\u6559\u7a0b\u3002", "conclusion": "\u867d\u7136LLMs\u672c\u8eab\u4e0d\u64c5\u957f\u68c0\u6d4b\u6027\u522b\u523b\u677f\u5370\u8c61\uff0c\u4f46\u901a\u8fc7\u9002\u5f53\u7684\u8bc4\u4f30\u6846\u67b6\u53ef\u4ee5\u6307\u5bfc\u5b83\u4eec\u751f\u6210\u66f4\u516c\u5e73\u7684\u6559\u5b66\u5185\u5bb9\uff0c\u4e3a\u89e3\u51b3\u7f16\u7a0b\u6559\u80b2\u4e2d\u7684\u6027\u522b\u504f\u89c1\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2510.10217", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10217", "abs": "https://arxiv.org/abs/2510.10217", "authors": ["Hyogo Hiruma", "Hiroshi Ito", "Tetsuya Ogata"], "title": "UF-RNN: Real-Time Adaptive Motion Generation Using Uncertainty-Driven Foresight Prediction", "comment": "8 pages, 6 figures", "summary": "Training robots to operate effectively in environments with uncertain states,\nsuch as ambiguous object properties or unpredictable interactions, remains a\nlongstanding challenge in robotics. Imitation learning methods typically rely\non successful examples and often neglect failure scenarios where uncertainty is\nmost pronounced. To address this limitation, we propose the Uncertainty-driven\nForesight Recurrent Neural Network (UF-RNN), a model that combines standard\ntime-series prediction with an active \"Foresight\" module. This module performs\ninternal simulations of multiple future trajectories and refines the hidden\nstate to minimize predicted variance, enabling the model to selectively explore\nactions under high uncertainty. We evaluate UF-RNN on a door-opening task in\nboth simulation and a real-robot setting, demonstrating that, despite the\nabsence of explicit failure demonstrations, the model exhibits robust\nadaptation by leveraging self-induced chaotic dynamics in its latent space.\nWhen guided by the Foresight module, these chaotic properties stimulate\nexploratory behaviors precisely when the environment is ambiguous, yielding\nimproved success rates compared to conventional stochastic RNN baselines. These\nfindings suggest that integrating uncertainty-driven foresight into imitation\nlearning pipelines can significantly enhance a robot's ability to handle\nunpredictable real-world conditions.", "AI": {"tldr": "\u63d0\u51faUF-RNN\u6a21\u578b\uff0c\u901a\u8fc7\u524d\u77bb\u6a21\u5757\u8fdb\u884c\u5185\u90e8\u6a21\u62df\u6765\u51cf\u5c11\u9884\u6d4b\u65b9\u5dee\uff0c\u5728\u4e0d\u786e\u5b9a\u6027\u9ad8\u65f6\u9009\u62e9\u6027\u63a2\u7d22\u52a8\u4f5c\uff0c\u5728\u5f00\u95e8\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6bd4\u4f20\u7edf\u968f\u673aRNN\u66f4\u5f3a\u7684\u9002\u5e94\u6027\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u4eba\u5728\u4e0d\u786e\u5b9a\u72b6\u6001\u73af\u5883\uff08\u5982\u6a21\u7cca\u7269\u4f53\u5c5e\u6027\u6216\u4e0d\u53ef\u9884\u6d4b\u4ea4\u4e92\uff09\u4e2d\u64cd\u4f5c\u7684\u95ee\u9898\uff0c\u4f20\u7edf\u6a21\u4eff\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u6210\u529f\u793a\u4f8b\u800c\u5ffd\u89c6\u4e0d\u786e\u5b9a\u6027\u6700\u660e\u663e\u7684\u5931\u8d25\u573a\u666f\u3002", "method": "\u63d0\u51fa\u4e0d\u786e\u5b9a\u6027\u9a71\u52a8\u7684\u524d\u77bb\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08UF-RNN\uff09\uff0c\u7ed3\u5408\u6807\u51c6\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u548c\u4e3b\u52a8\u524d\u77bb\u6a21\u5757\uff0c\u8be5\u6a21\u5757\u6267\u884c\u591a\u4e2a\u672a\u6765\u8f68\u8ff9\u7684\u5185\u90e8\u6a21\u62df\u5e76\u4f18\u5316\u9690\u85cf\u72b6\u6001\u4ee5\u6700\u5c0f\u5316\u9884\u6d4b\u65b9\u5dee\u3002", "result": "\u5728\u4eff\u771f\u548c\u771f\u5b9e\u673a\u5668\u4eba\u5f00\u95e8\u4efb\u52a1\u4e2d\u8bc4\u4f30\uff0c\u5c3d\u7ba1\u6ca1\u6709\u663e\u5f0f\u5931\u8d25\u6f14\u793a\uff0c\u6a21\u578b\u901a\u8fc7\u5229\u7528\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u81ea\u8bf1\u5bfc\u6df7\u6c8c\u52a8\u529b\u5b66\u8868\u73b0\u51fa\u7a33\u5065\u9002\u5e94\u6027\uff0c\u76f8\u6bd4\u4f20\u7edf\u968f\u673aRNN\u57fa\u7ebf\u63d0\u9ad8\u4e86\u6210\u529f\u7387\u3002", "conclusion": "\u5c06\u4e0d\u786e\u5b9a\u6027\u9a71\u52a8\u7684\u524d\u77bb\u6574\u5408\u5230\u6a21\u4eff\u5b66\u4e60\u6d41\u7a0b\u4e2d\uff0c\u53ef\u4ee5\u663e\u8457\u589e\u5f3a\u673a\u5668\u4eba\u5904\u7406\u4e0d\u53ef\u9884\u6d4b\u73b0\u5b9e\u6761\u4ef6\u7684\u80fd\u529b\u3002"}}
{"id": "2510.10117", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10117", "abs": "https://arxiv.org/abs/2510.10117", "authors": ["Yunxiang Mo", "Tianshi Zheng", "Qing Zong", "Jiayu Liu", "Baixuan Xu", "Yauwai Yim", "Chunkit Chan", "Jiaxin Bai", "Yangqiu Song"], "title": "DixitWorld: Evaluating Multimodal Abductive Reasoning in Vision-Language Models with Multi-Agent Dixit Gameplay", "comment": "EMNLP 2025 Wordplay (Spotlight)", "summary": "Multimodal abductive reasoning--the generation and selection of explanatory\nhypotheses from partial observations--is a cornerstone of intelligence. Current\nevaluations of this ability in vision-language models (VLMs) are largely\nconfined to static, single-agent tasks. Inspired by Dixit, we introduce\nDixitWorld, a comprehensive evaluation suite designed to deconstruct this\nchallenge. DIXITWORLD features two core components: DixitArena, a dynamic,\nmulti-agent environment that evaluates both hypothesis generation (a\n\"storyteller\" crafting cryptic clues) and hypothesis selection (\"listeners\"\nchoosing the target image from decoys) under imperfect information; and\nDixitBench, a static QA benchmark that isolates the listener's task for\nefficient, controlled evaluation. Results from DixitArena reveal distinct,\nrole-dependent behaviors: smaller open-source models often excel as creative\nstorytellers, producing imaginative yet less discriminative clues, whereas\nlarger proprietary models demonstrate superior overall performance,\nparticularly as listeners. Performance on DixitBench strongly correlates with\nlistener results in DixitArena, validating it as a reliable proxy for\nhypothesis selection. Our findings reveal a key trade-off between generative\ncreativity and discriminative understanding in multimodal abductive reasoning,\na central challenge for developing more balanced and capable vision-language\nagents.", "AI": {"tldr": "\u63d0\u51fa\u4e86DixitWorld\u8bc4\u4f30\u5957\u4ef6\uff0c\u5305\u542b\u52a8\u6001\u591a\u4ee3\u7406\u73af\u5883DixitArena\u548c\u9759\u6001QA\u57fa\u51c6DixitBench\uff0c\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6a21\u6001\u6eaf\u56e0\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u751f\u6210\u521b\u9020\u6027\u548c\u5224\u522b\u7406\u89e3\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002", "motivation": "\u5f53\u524d\u5bf9\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6eaf\u56e0\u63a8\u7406\u80fd\u529b\u7684\u8bc4\u4f30\u4e3b\u8981\u5c40\u9650\u4e8e\u9759\u6001\u3001\u5355\u4ee3\u7406\u4efb\u52a1\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u7406\u89e3\u6a21\u578b\u5728\u751f\u6210\u548c\u9009\u62e9\u89e3\u91ca\u6027\u5047\u8bbe\u65b9\u9762\u7684\u80fd\u529b\u3002", "method": "DixitWorld\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1aDixitArena\uff08\u52a8\u6001\u591a\u4ee3\u7406\u73af\u5883\uff0c\u8bc4\u4f30\u5047\u8bbe\u751f\u6210\u548c\u9009\u62e9\uff09\u548cDixitBench\uff08\u9759\u6001QA\u57fa\u51c6\uff0c\u9694\u79bb\u542c\u4f17\u4efb\u52a1\u8fdb\u884c\u63a7\u5236\u8bc4\u4f30\uff09\u3002", "result": "\u8f83\u5c0f\u5f00\u6e90\u6a21\u578b\u5728\u4f5c\u4e3a\u8bb2\u6545\u4e8b\u8005\u65f6\u8868\u73b0\u51fa\u521b\u9020\u529b\u4f46\u7ebf\u7d22\u533a\u5206\u5ea6\u8f83\u4f4e\uff0c\u8f83\u5927\u4e13\u6709\u6a21\u578b\u5728\u6574\u4f53\u6027\u80fd\u4e0a\u66f4\u4f18\uff0c\u7279\u522b\u662f\u4f5c\u4e3a\u542c\u4f17\u65f6\u3002DixitBench\u7ed3\u679c\u4e0eDixitArena\u542c\u4f17\u8868\u73b0\u5f3a\u76f8\u5173\u3002", "conclusion": "\u591a\u6a21\u6001\u6eaf\u56e0\u63a8\u7406\u4e2d\u5b58\u5728\u751f\u6210\u521b\u9020\u6027\u548c\u5224\u522b\u7406\u89e3\u4e4b\u95f4\u7684\u5173\u952e\u6743\u8861\uff0c\u8fd9\u662f\u5f00\u53d1\u66f4\u5e73\u8861\u3001\u66f4\u6709\u80fd\u529b\u7684\u89c6\u89c9\u8bed\u8a00\u4ee3\u7406\u7684\u6838\u5fc3\u6311\u6218\u3002"}}
{"id": "2510.10651", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.10651", "abs": "https://arxiv.org/abs/2510.10651", "authors": ["Mohammad Hassan", "Mads R. Almassalkhi"], "title": "Aggregate Modeling of Air-Conditioner Loads Under Packet-based Control with Both On and Off Grid Access Requests", "comment": null, "summary": "Coordination of distributed energy resources (DERs) can engender flexibility\nnecessary to improve grid reliability. Packetized Energy Management (PEM) is a\nmethod for coordinating DERs, such as thermostatically controlled loads (TCLs)\nand electric vehicles, within customer quality-of-service (QoS) limits. In PEM,\na DER uses local information to offer flexibility by sending a request to the\nDER coordinator to turn-ON or turn-OFF. Much work has focused on modeling and\nanalyzing aggregations of DERs under PEM with fixed packet durations and only\nturn-ON requests. Different recent efforts to enable variable packet lengths\nhave shown an increase in available flexibility and ramping capability, but\nhave not been modeled in aggregate, which limits systematic analyses. To\naddress this issue, this paper presents a new aggregate bin-based (macro) model\nof PEM loads that incorporates both turn-ON and turn-OFF request features,\nenabling the model to accurately characterize the capability of the fleet of\nDERs to track a power reference signal, population temperature dynamics,\naggregate request rates, and variable packet lengths. Simulation-based\nvalidation is performed against an agent-based (micro) model to evaluate\nrobustness and quantify model accuracy. Finally, the distribution of variable\npacket lengths from macro-model simulations are applied to inform past work on\nPEM with randomized packet lengths", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u5206\u7bb1\u7684\u805a\u5408\u6a21\u578b\uff0c\u7528\u4e8e\u5206\u6790\u5177\u6709\u53ef\u53d8\u5305\u957f\u5ea6\u548c\u5f00\u5173\u8bf7\u6c42\u529f\u80fd\u7684\u5206\u5e03\u5f0f\u80fd\u6e90\u8d44\u6e90\u534f\u8c03\u7cfb\u7edf\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u56fa\u5b9a\u5305\u957f\u5ea6\u548c\u4ec5\u5f00\u542f\u8bf7\u6c42\u7684\u5206\u5e03\u5f0f\u80fd\u6e90\u8d44\u6e90\u805a\u5408\u6a21\u578b\uff0c\u65e0\u6cd5\u51c6\u786e\u8868\u5f81\u5177\u6709\u53ef\u53d8\u5305\u957f\u5ea6\u548c\u5f00\u5173\u8bf7\u6c42\u529f\u80fd\u7684\u7cfb\u7edf\u7075\u6d3b\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u5206\u7bb1\u7684\u5b8f\u89c2\u805a\u5408\u6a21\u578b\uff0c\u6574\u5408\u4e86\u5f00\u542f\u548c\u5173\u95ed\u8bf7\u6c42\u529f\u80fd\uff0c\u80fd\u591f\u51c6\u786e\u8868\u5f81DERs\u8ddf\u8e2a\u529f\u7387\u53c2\u8003\u4fe1\u53f7\u7684\u80fd\u529b\u3001\u7fa4\u4f53\u6e29\u5ea6\u52a8\u6001\u3001\u805a\u5408\u8bf7\u6c42\u7387\u548c\u53ef\u53d8\u5305\u957f\u5ea6\u3002", "result": "\u901a\u8fc7\u57fa\u4e8e\u4ee3\u7406\u7684\u5fae\u89c2\u6a21\u578b\u8fdb\u884c\u4eff\u771f\u9a8c\u8bc1\uff0c\u8bc4\u4f30\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\u5e76\u91cf\u5316\u4e86\u6a21\u578b\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u5b8f\u89c2\u6a21\u578b\u80fd\u591f\u51c6\u786e\u63cf\u8ff0\u5177\u6709\u53ef\u53d8\u5305\u957f\u5ea6\u7684PEM\u7cfb\u7edf\uff0c\u4e3a\u968f\u673a\u5305\u957f\u5ea6\u7684PEM\u7814\u7a76\u63d0\u4f9b\u4e86\u5206\u5e03\u4fe1\u606f\u3002"}}
{"id": "2510.11556", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.11556", "abs": "https://arxiv.org/abs/2510.11556", "authors": ["Javed Ali Khan", "Muhammad Yaqoob", "Mamoona Tasadduq", "Hafsa Shareef Dar", "Aitezaz Ahsan"], "title": "Personalized and Constructive Feedback for Computer Science Students Using the Large Language Model (LLM)", "comment": null, "summary": "The evolving pedagogy paradigms are leading toward educational\ntransformations. One fundamental aspect of effective learning is relevant,\nimmediate, and constructive feedback to students. Providing constructive\nfeedback to large cohorts in academia is an ongoing challenge. Therefore,\nacademics are moving towards automated assessment to provide immediate\nfeedback. However, current approaches are often limited in scope, offering\nsimplistic responses that do not provide students with personalized feedback to\nguide them toward improvements. This paper addresses this limitation by\ninvestigating the performance of Large Language Models (LLMs) in processing\nstudents assessments with predefined rubrics and marking criteria to generate\npersonalized feedback for in-depth learning. We aim to leverage the power of\nexisting LLMs for Marking Assessments, Tracking, and Evaluation (LLM-MATE) with\npersonalized feedback to enhance students learning. To evaluate the performance\nof LLM-MATE, we consider the Software Architecture (SA) module as a case study.\nThe LLM-MATE approach can help module leaders overcome assessment challenges\nwith large cohorts. Also, it helps students improve their learning by obtaining\npersonalized feedback in a timely manner. Additionally, the proposed approach\nwill facilitate the establishment of ground truth for automating the generation\nof students assessment feedback using the ChatGPT API, thereby reducing the\noverhead associated with large cohort assessments.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6839\u636e\u9884\u5b9a\u4e49\u8bc4\u5206\u6807\u51c6\u5904\u7406\u5b66\u751f\u8bc4\u4f30\uff0c\u4ee5\u751f\u6210\u4e2a\u6027\u5316\u53cd\u9988\u6765\u589e\u5f3a\u5b66\u4e60\u6548\u679c\u7684\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u5316\u8bc4\u4f30\u65b9\u6cd5\u901a\u5e38\u53ea\u80fd\u63d0\u4f9b\u7b80\u5355\u53cd\u9988\uff0c\u65e0\u6cd5\u4e3a\u5b66\u751f\u63d0\u4f9b\u4e2a\u6027\u5316\u6307\u5bfc\u3002\u9762\u5bf9\u5927\u89c4\u6a21\u5b66\u751f\u7fa4\u4f53\u7684\u8bc4\u4f30\u6311\u6218\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u53cd\u9988\u7cfb\u7edf\u3002", "method": "\u63d0\u51faLLM-MATE\u65b9\u6cd5\uff0c\u5229\u7528\u73b0\u6709LLMs\u5904\u7406\u5b66\u751f\u8bc4\u4f30\uff0c\u7ed3\u5408\u9884\u5b9a\u4e49\u8bc4\u5206\u6807\u51c6\u548c\u6807\u8bb0\u6807\u51c6\u751f\u6210\u4e2a\u6027\u5316\u53cd\u9988\u3002\u4ee5\u8f6f\u4ef6\u67b6\u6784\u8bfe\u7a0b\u4e3a\u6848\u4f8b\u7814\u7a76\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "LLM-MATE\u65b9\u6cd5\u80fd\u5e2e\u52a9\u6559\u5e08\u5e94\u5bf9\u5927\u89c4\u6a21\u5b66\u751f\u7fa4\u4f53\u7684\u8bc4\u4f30\u6311\u6218\uff0c\u540c\u65f6\u8ba9\u5b66\u751f\u53ca\u65f6\u83b7\u5f97\u4e2a\u6027\u5316\u53cd\u9988\u4ee5\u6539\u8fdb\u5b66\u4e60\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7ChatGPT API\u81ea\u52a8\u5316\u751f\u6210\u5b66\u751f\u8bc4\u4f30\u53cd\u9988\uff0c\u51cf\u5c11\u5927\u89c4\u6a21\u8bc4\u4f30\u7684\u5de5\u4f5c\u8d1f\u62c5\uff0c\u5e76\u4e3a\u5efa\u7acb\u81ea\u52a8\u5316\u53cd\u9988\u751f\u6210\u7684\u771f\u5b9e\u57fa\u51c6\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.10221", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10221", "abs": "https://arxiv.org/abs/2510.10221", "authors": ["Hyogo Hiruma", "Hiroshi Ito", "Hiroki Mori", "Tetsuya Ogata"], "title": "A3RNN: Bi-directional Fusion of Bottom-up and Top-down Process for Developmental Visual Attention in Robots", "comment": "8 pages, 5 figures", "summary": "This study investigates the developmental interaction between top-down (TD)\nand bottom-up (BU) visual attention in robotic learning. Our goal is to\nunderstand how structured, human-like attentional behavior emerges through the\nmutual adaptation of TD and BU mechanisms over time. To this end, we propose a\nnovel attention model $A^3 RNN$ that integrates predictive TD signals and\nsaliency-based BU cues through a bi-directional attention architecture.\n  We evaluate our model in robotic manipulation tasks using imitation learning.\nExperimental results show that attention behaviors evolve throughout training,\nfrom saliency-driven exploration to prediction-driven direction. Initially, BU\nattention highlights visually salient regions, which guide TD processes, while\nas learning progresses, TD attention stabilizes and begins to reshape what is\nperceived as salient. This trajectory reflects principles from cognitive\nscience and the free-energy framework, suggesting the importance of\nself-organizing attention through interaction between perception and internal\nprediction. Although not explicitly optimized for stability, our model exhibits\nmore coherent and interpretable attention patterns than baselines, supporting\nthe idea that developmental mechanisms contribute to robust attention\nformation.", "AI": {"tldr": "\u7814\u7a76\u673a\u5668\u4eba\u5b66\u4e60\u4e2d\u81ea\u4e0a\u800c\u4e0b\u548c\u81ea\u4e0b\u800c\u4e0a\u89c6\u89c9\u6ce8\u610f\u529b\u7684\u53d1\u5c55\u6027\u4ea4\u4e92\uff0c\u63d0\u51faA\u00b3RNN\u6ce8\u610f\u529b\u6a21\u578b\uff0c\u901a\u8fc7\u53cc\u5411\u6ce8\u610f\u529b\u67b6\u6784\u6574\u5408\u9884\u6d4b\u6027TD\u4fe1\u53f7\u548c\u663e\u8457\u6027BU\u7ebf\u7d22\u3002", "motivation": "\u7406\u89e3\u7ed3\u6784\u5316\u3001\u7c7b\u4eba\u6ce8\u610f\u529b\u884c\u4e3a\u5982\u4f55\u901a\u8fc7TD\u548cBU\u673a\u5236\u7684\u76f8\u4e92\u9002\u5e94\u968f\u65f6\u95f4\u6f14\u5316\uff0c\u63a2\u7d22\u611f\u77e5\u4e0e\u5185\u90e8\u9884\u6d4b\u4ea4\u4e92\u4e2d\u81ea\u7ec4\u7ec7\u6ce8\u610f\u529b\u7684\u91cd\u8981\u6027\u3002", "method": "\u63d0\u51faA\u00b3RNN\u6ce8\u610f\u529b\u6a21\u578b\uff0c\u4f7f\u7528\u53cc\u5411\u6ce8\u610f\u529b\u67b6\u6784\u6574\u5408\u9884\u6d4b\u6027TD\u4fe1\u53f7\u548c\u663e\u8457\u6027BU\u7ebf\u7d22\uff0c\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u901a\u8fc7\u6a21\u4eff\u5b66\u4e60\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u6ce8\u610f\u529b\u884c\u4e3a\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4ece\u663e\u8457\u6027\u9a71\u52a8\u63a2\u7d22\u6f14\u53d8\u4e3a\u9884\u6d4b\u9a71\u52a8\u5b9a\u5411\uff0cBU\u6ce8\u610f\u529b\u5f15\u5bfcTD\u8fc7\u7a0b\uff0cTD\u6ce8\u610f\u529b\u968f\u540e\u91cd\u5851\u663e\u8457\u6027\u611f\u77e5\uff0c\u4ea7\u751f\u6bd4\u57fa\u7ebf\u66f4\u8fde\u8d2f\u53ef\u89e3\u91ca\u7684\u6ce8\u610f\u529b\u6a21\u5f0f\u3002", "conclusion": "\u53d1\u5c55\u673a\u5236\u6709\u52a9\u4e8e\u7a33\u5065\u6ce8\u610f\u529b\u5f62\u6210\uff0c\u81ea\u7ec4\u7ec7\u6ce8\u610f\u529b\u901a\u8fc7\u611f\u77e5\u4e0e\u5185\u90e8\u9884\u6d4b\u7684\u4ea4\u4e92\u5b9e\u73b0\uff0c\u53cd\u6620\u4e86\u8ba4\u77e5\u79d1\u5b66\u548c\u81ea\u7531\u80fd\u6846\u67b6\u7684\u539f\u5219\u3002"}}
{"id": "2510.10135", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10135", "abs": "https://arxiv.org/abs/2510.10135", "authors": ["Zhongsheng Wang", "Ming Lin", "Zhedong Lin", "Yaser Shakib", "Qian Liu", "Jiamou Liu"], "title": "CharCom: Composable Identity Control for Multi-Character Story Illustration", "comment": "Accepted by ACM MMAsia 2025", "summary": "Ensuring character identity consistency across varying prompts remains a\nfundamental limitation in diffusion-based text-to-image generation. We propose\nCharCom, a modular and parameter-efficient framework that achieves\ncharacter-consistent story illustration through composable LoRA adapters,\nenabling efficient per-character customization without retraining the base\nmodel. Built on a frozen diffusion backbone, CharCom dynamically composes\nadapters at inference using prompt-aware control. Experiments on multi-scene\nnarratives demonstrate that CharCom significantly enhances character fidelity,\nsemantic alignment, and temporal coherence. It remains robust in crowded scenes\nand enables scalable multi-character generation with minimal overhead, making\nit well-suited for real-world applications such as story illustration and\nanimation.", "AI": {"tldr": "CharCom\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u3001\u53c2\u6570\u9ad8\u6548\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u7ec4\u5408\u7684LoRA\u9002\u914d\u5668\u5b9e\u73b0\u89d2\u8272\u4e00\u81f4\u7684\u6545\u4e8b\u63d2\u56fe\u751f\u6210\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\u3002", "motivation": "\u786e\u4fdd\u89d2\u8272\u8eab\u4efd\u5728\u4e0d\u540c\u63d0\u793a\u4e0b\u7684\u4e00\u81f4\u6027\u662f\u57fa\u4e8e\u6269\u6563\u7684\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u7684\u57fa\u672c\u9650\u5236\u3002", "method": "\u57fa\u4e8e\u51bb\u7ed3\u7684\u6269\u6563\u9aa8\u5e72\u7f51\u7edc\uff0cCharCom\u4f7f\u7528\u53ef\u7ec4\u5408\u7684LoRA\u9002\u914d\u5668\uff0c\u5728\u63a8\u7406\u65f6\u901a\u8fc7\u63d0\u793a\u611f\u77e5\u63a7\u5236\u52a8\u6001\u7ec4\u5408\u9002\u914d\u5668\u3002", "result": "\u5728\u591a\u573a\u666f\u53d9\u4e8b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCharCom\u663e\u8457\u63d0\u5347\u4e86\u89d2\u8272\u4fdd\u771f\u5ea6\u3001\u8bed\u4e49\u5bf9\u9f50\u548c\u65f6\u95f4\u4e00\u81f4\u6027\uff0c\u5728\u62e5\u6324\u573a\u666f\u4e2d\u4fdd\u6301\u9c81\u68d2\u6027\uff0c\u5e76\u80fd\u4ee5\u6700\u5c0f\u5f00\u9500\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u591a\u89d2\u8272\u751f\u6210\u3002", "conclusion": "CharCom\u9002\u7528\u4e8e\u6545\u4e8b\u63d2\u56fe\u548c\u52a8\u753b\u7b49\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2510.10820", "categories": ["eess.SY", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.10820", "abs": "https://arxiv.org/abs/2510.10820", "authors": ["Maarten van der Hulst", "Rodrigo A. Gonz\u00e1lez", "Koen Classens", "Paul Tacx", "Nick Dirkx", "Jeroen van de Wijdeven", "Tom Oomen"], "title": "Structured identification of multivariable modal systems", "comment": "20 pages, 12 figures", "summary": "Physically interpretable models are essential for next-generation industrial\nsystems, as these representations enable effective control, support design\nvalidation, and provide a foundation for monitoring strategies. The aim of this\npaper is to develop a system identification framework for estimating modal\nmodels of complex multivariable mechanical systems from frequency response\ndata. To achieve this, a two-step structured identification algorithm is\npresented, where an additive model is first estimated using a refined\ninstrumental variable method and subsequently projected onto a modal form. The\ndeveloped identification method provides accurate, physically-relevant,\nminimal-order models, for both generally-damped and proportionally damped modal\nsystems. The effectiveness of the proposed method is demonstrated through\nexperimental validation on a prototype wafer-stage system, which features a\nlarge number of spatially distributed actuators and sensors and exhibits\ncomplex flexible dynamics.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u4ece\u9891\u54cd\u6570\u636e\u4f30\u8ba1\u591a\u53d8\u91cf\u673a\u68b0\u7cfb\u7edf\u6a21\u6001\u6a21\u578b\u7684\u7cfb\u7edf\u8fa8\u8bc6\u6846\u67b6\uff0c\u91c7\u7528\u4e24\u6b65\u7ed3\u6784\u5316\u7b97\u6cd5\uff0c\u5148\u901a\u8fc7\u6539\u8fdb\u7684\u8f85\u52a9\u53d8\u91cf\u6cd5\u4f30\u8ba1\u52a0\u6027\u6a21\u578b\uff0c\u518d\u6295\u5f71\u5230\u6a21\u6001\u5f62\u5f0f\u3002", "motivation": "\u7269\u7406\u53ef\u89e3\u91ca\u6a21\u578b\u5bf9\u4e8e\u4e0b\u4e00\u4ee3\u5de5\u4e1a\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u8fd9\u4e9b\u8868\u793a\u80fd\u591f\u5b9e\u73b0\u6709\u6548\u63a7\u5236\u3001\u652f\u6301\u8bbe\u8ba1\u9a8c\u8bc1\u5e76\u4e3a\u76d1\u63a7\u7b56\u7565\u63d0\u4f9b\u57fa\u7840\u3002", "method": "\u63d0\u51fa\u4e24\u6b65\u7ed3\u6784\u5316\u8fa8\u8bc6\u7b97\u6cd5\uff1a\u9996\u5148\u4f7f\u7528\u6539\u8fdb\u7684\u8f85\u52a9\u53d8\u91cf\u6cd5\u4f30\u8ba1\u52a0\u6027\u6a21\u578b\uff0c\u7136\u540e\u5c06\u8be5\u6a21\u578b\u6295\u5f71\u5230\u6a21\u6001\u5f62\u5f0f\u3002", "result": "\u6240\u5f00\u53d1\u7684\u8fa8\u8bc6\u65b9\u6cd5\u4e3a\u4e00\u822c\u963b\u5c3c\u548c\u6bd4\u4f8b\u963b\u5c3c\u6a21\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u51c6\u786e\u3001\u7269\u7406\u76f8\u5173\u7684\u6700\u5c0f\u9636\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u5728\u539f\u578b\u6676\u5706\u53f0\u7cfb\u7edf\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8be5\u7cfb\u7edf\u5177\u6709\u5927\u91cf\u7a7a\u95f4\u5206\u5e03\u7684\u6267\u884c\u5668\u548c\u4f20\u611f\u5668\uff0c\u5e76\u8868\u73b0\u51fa\u590d\u6742\u7684\u67d4\u6027\u52a8\u529b\u5b66\u7279\u6027\u3002"}}
{"id": "2507.14306", "categories": ["cs.AI", "cs.CY", "cs.MM"], "pdf": "https://arxiv.org/pdf/2507.14306", "abs": "https://arxiv.org/abs/2507.14306", "authors": ["Samarth P", "Vyoman Jain", "Shiva Golugula", "Motamarri Sai Sathvik"], "title": "Manimator: Transforming Research Papers into Visual Explanations", "comment": null, "summary": "Understanding complex scientific and mathematical concepts, particularly\nthose presented in dense research papers, poses a significant challenge for\nlearners. Dynamic visualizations can greatly enhance comprehension, but\ncreating them manually is time-consuming and requires specialized knowledge and\nskills. We introduce manimator, an open-source system that leverages Large\nLanguage Models to transform research papers and natural language prompts into\nexplanatory animations using the Manim engine. Manimator employs a pipeline\nwhere an LLM interprets the input text or research paper PDF to generate a\nstructured scene description outlining key concepts, mathematical formulas, and\nvisual elements and another LLM translates this description into executable\nManim Python code. We discuss its potential as an educational tool for rapidly\ncreating engaging visual explanations for complex STEM topics, democratizing\nthe creation of high-quality educational content.", "AI": {"tldr": "Manimator\u662f\u4e00\u4e2a\u5f00\u6e90\u7cfb\u7edf\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u7814\u7a76\u8bba\u6587\u548c\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u8f6c\u6362\u4e3a\u4f7f\u7528Manim\u5f15\u64ce\u7684\u89e3\u91ca\u6027\u52a8\u753b\uff0c\u7b80\u5316\u590d\u6742STEM\u4e3b\u9898\u7684\u53ef\u89c6\u5316\u5185\u5bb9\u521b\u5efa\u3002", "motivation": "\u7406\u89e3\u590d\u6742\u79d1\u5b66\u548c\u6570\u5b66\u6982\u5ff5\u5bf9\u5b66\u4e60\u8005\u5177\u6709\u6311\u6218\u6027\uff0c\u624b\u52a8\u521b\u5efa\u52a8\u6001\u53ef\u89c6\u5316\u8017\u65f6\u4e14\u9700\u8981\u4e13\u4e1a\u6280\u80fd\u3002", "method": "\u91c7\u7528\u6d41\u6c34\u7ebf\u65b9\u6cd5\uff1a\u4e00\u4e2aLLM\u89e3\u91ca\u8f93\u5165\u6587\u672c\u6216\u7814\u7a76\u8bba\u6587PDF\u751f\u6210\u7ed3\u6784\u5316\u573a\u666f\u63cf\u8ff0\uff0c\u53e6\u4e00\u4e2aLLM\u5c06\u8be5\u63cf\u8ff0\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684Manim Python\u4ee3\u7801\u3002", "result": "\u5f00\u53d1\u4e86\u80fd\u591f\u81ea\u52a8\u751f\u6210\u89e3\u91ca\u6027\u52a8\u753b\u7684\u7cfb\u7edf\uff0c\u4e3a\u590d\u6742STEM\u4e3b\u9898\u5feb\u901f\u521b\u5efa\u5f15\u4eba\u5165\u80dc\u7684\u89c6\u89c9\u89e3\u91ca\u3002", "conclusion": "Manimator\u6709\u6f5c\u529b\u4f5c\u4e3a\u6559\u80b2\u5de5\u5177\uff0c\u6c11\u4e3b\u5316\u9ad8\u8d28\u91cf\u6559\u80b2\u5185\u5bb9\u7684\u521b\u5efa\uff0c\u4f7f\u590d\u6742\u6982\u5ff5\u66f4\u6613\u7406\u89e3\u3002"}}
{"id": "2510.10273", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10273", "abs": "https://arxiv.org/abs/2510.10273", "authors": ["Vincent Schoenbach", "Marvin Wiedemann", "Raphael Memmesheimer", "Malte Mosbach", "Sven Behnke"], "title": "Integration of the TIAGo Robot into Isaac Sim with Mecanum Drive Modeling and Learned S-Curve Velocity Profiles", "comment": "In Proceedings of IEEE 21st International Conference on Automation\n  Science and Engineering (CASE), Los Angeles, USA, August 2025", "summary": "Efficient physics simulation has significantly accelerated research progress\nin robotics applications such as grasping and assembly. The advent of\nGPU-accelerated simulation frameworks like Isaac Sim has particularly empowered\nlearning-based methods, enabling them to tackle increasingly complex tasks. The\nPAL Robotics TIAGo++ Omni is a versatile mobile manipulator equipped with a\nmecanum-wheeled base, allowing omnidirectional movement and a wide range of\ntask capabilities. However, until now, no model of the robot has been available\nin Isaac Sim. In this paper, we introduce such a model, calibrated to\napproximate the behavior of the real robot, with a focus on its omnidirectional\ndrive dynamics. We present two control models for the omnidirectional drive: a\nphysically accurate model that replicates real-world wheel dynamics and a\nlightweight velocity-based model optimized for learning-based applications.\nWith these models, we introduce a learning-based calibration approach to\napproximate the real robot's S-shaped velocity profile using minimal trajectory\ndata recordings. This simulation should allow researchers to experiment with\nthe robot and perform efficient learning-based control in diverse environments.\nWe provide the integration publicly at https://github.com/AIS-Bonn/tiago_isaac.", "AI": {"tldr": "\u672c\u6587\u4e3aPAL Robotics TIAGo++ Omni\u79fb\u52a8\u673a\u68b0\u81c2\u5f00\u53d1\u4e86Isaac Sim\u4eff\u771f\u6a21\u578b\uff0c\u91cd\u70b9\u6821\u51c6\u4e86\u5168\u5411\u9a71\u52a8\u52a8\u529b\u5b66\uff0c\u63d0\u4f9b\u4e86\u7269\u7406\u7cbe\u786e\u6a21\u578b\u548c\u8f7b\u91cf\u7ea7\u901f\u5ea6\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u5b66\u4e60\u7684\u6821\u51c6\u65b9\u6cd5\u6765\u8fd1\u4f3c\u771f\u5b9e\u673a\u5668\u4eba\u7684S\u5f62\u901f\u5ea6\u66f2\u7ebf\u3002", "motivation": "TIAGo++ Omni\u662f\u4e00\u6b3e\u591a\u529f\u80fd\u79fb\u52a8\u673a\u68b0\u81c2\uff0c\u5177\u5907\u5168\u5411\u79fb\u52a8\u80fd\u529b\uff0c\u4f46\u6b64\u524d\u5728Isaac Sim\u4e2d\u6ca1\u6709\u53ef\u7528\u7684\u6a21\u578b\u3002\u4e3a\u4e86\u652f\u6301\u7814\u7a76\u4eba\u5458\u5728\u8be5\u673a\u5668\u4eba\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u548c\u57fa\u4e8e\u5b66\u4e60\u7684\u63a7\u5236\u7814\u7a76\uff0c\u9700\u8981\u5f00\u53d1\u76f8\u5e94\u7684\u4eff\u771f\u6a21\u578b\u3002", "method": "\u5f00\u53d1\u4e86\u4e24\u79cd\u5168\u5411\u9a71\u52a8\u63a7\u5236\u6a21\u578b\uff1a\u7269\u7406\u7cbe\u786e\u6a21\u578b\uff08\u590d\u5236\u771f\u5b9e\u8f6e\u5b50\u52a8\u529b\u5b66\uff09\u548c\u8f7b\u91cf\u7ea7\u901f\u5ea6\u6a21\u578b\uff08\u4f18\u5316\u7528\u4e8e\u57fa\u4e8e\u5b66\u4e60\u7684\u5e94\u7528\uff09\u3002\u63d0\u51fa\u4e86\u57fa\u4e8e\u5b66\u4e60\u7684\u6821\u51c6\u65b9\u6cd5\uff0c\u4f7f\u7528\u6700\u5c0f\u8f68\u8ff9\u6570\u636e\u8bb0\u5f55\u6765\u8fd1\u4f3c\u771f\u5b9e\u673a\u5668\u4eba\u7684S\u5f62\u901f\u5ea6\u66f2\u7ebf\u3002", "result": "\u6210\u529f\u5728Isaac Sim\u4e2d\u96c6\u6210\u4e86TIAGo++ Omni\u673a\u5668\u4eba\u6a21\u578b\uff0c\u6821\u51c6\u540e\u80fd\u591f\u8fd1\u4f3c\u771f\u5b9e\u673a\u5668\u4eba\u7684\u884c\u4e3a\uff0c\u7279\u522b\u662f\u5168\u5411\u9a71\u52a8\u52a8\u529b\u5b66\u3002\u63d0\u4f9b\u4e86\u516c\u5f00\u7684\u96c6\u6210\u4ee3\u7801\u5e93\u3002", "conclusion": "\u8be5\u4eff\u771f\u6a21\u578b\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u5728\u5404\u79cd\u73af\u5883\u4e2d\u5bf9TIAGo++ Omni\u673a\u5668\u4eba\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5e76\u6267\u884c\u9ad8\u6548\u7684\u57fa\u4e8e\u5b66\u4e60\u7684\u63a7\u5236\u7814\u7a76\uff0c\u4e3a\u673a\u5668\u4eba\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5de5\u5177\u3002"}}
{"id": "2510.10168", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10168", "abs": "https://arxiv.org/abs/2510.10168", "authors": ["Chengqian Gao", "Haonan Li", "Taylor W. Killian", "Jianshu She", "Renxi Wang", "Liqun Ma", "Zhoujun Cheng", "Shibo Hao", "Zhiqiang Xu"], "title": "Concise Reasoning in the Lens of Lagrangian Optimization", "comment": null, "summary": "Concise reasoning in large language models seeks to generate only essential\nintermediate steps needed to arrive at a final answer, thereby alleviating\nissues of overthinking. Most proposed approaches hinge on carefully\nhand-crafted heuristics, struggling to balance concision with performance,\noften failing to adapt across domains and model scales. In this work, we\naddress these challenges by introducing a principled and pragmatic strategy,\nperformance-aware length updating (PALU). As a principled algorithm, PALU\nformulates concise reasoning as a constrained optimization problem, minimizing\nresponse length subject to a performance constraint, and then applies\nLagrangian optimization to convert it into a tractable unconstrained problem.\nAs a pragmatic solution, PALU streamlines complicated update rules through\nthree approximations: (i) estimating performance with off-policy rollouts, (ii)\ntruncating the Lagrange multiplier to two extremes, and (iii) replacing\ngradient-based updates with quantile-driven length adjustments. PALU reduces\noutput length by 65% while improving accuracy by 15% when applied to\nDeepSeek-Distill-Qwen-1.5B, averaged over five benchmarks, outperforming a\nrange of alternative methods. Furthermore, PALU is demonstrated to adapt across\nboth domain (logic, STEM and math) and model scale (1.5B, 7B, 14B) entrenching\nthe algorithm as a practical and effective concise reasoning approach.", "AI": {"tldr": "\u63d0\u51faPALU\u65b9\u6cd5\uff0c\u901a\u8fc7\u6027\u80fd\u611f\u77e5\u957f\u5ea6\u66f4\u65b0\u5b9e\u73b0\u7b80\u6d01\u63a8\u7406\uff0c\u5728\u51cf\u5c1165%\u8f93\u51fa\u957f\u5ea6\u7684\u540c\u65f6\u63d0\u534715%\u51c6\u786e\u7387\uff0c\u5e76\u80fd\u8de8\u9886\u57df\u548c\u6a21\u578b\u89c4\u6a21\u9002\u5e94\u3002", "motivation": "\u73b0\u6709\u7b80\u6d01\u63a8\u7406\u65b9\u6cd5\u4f9d\u8d56\u624b\u5de5\u542f\u53d1\u5f0f\u89c4\u5219\uff0c\u96be\u4ee5\u5e73\u8861\u7b80\u6d01\u6027\u4e0e\u6027\u80fd\uff0c\u4e14\u65e0\u6cd5\u8de8\u9886\u57df\u548c\u6a21\u578b\u89c4\u6a21\u9002\u5e94\u3002", "method": "PALU\u5c06\u7b80\u6d01\u63a8\u7406\u5efa\u6a21\u4e3a\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u4f7f\u7528\u62c9\u683c\u6717\u65e5\u4f18\u5316\u8f6c\u5316\u4e3a\u65e0\u7ea6\u675f\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u4e09\u4e2a\u8fd1\u4f3c\u7b80\u5316\u66f4\u65b0\u89c4\u5219\uff1a\u79bb\u7b56\u7565\u6027\u80fd\u4f30\u8ba1\u3001\u62c9\u683c\u6717\u65e5\u4e58\u5b50\u622a\u65ad\u3001\u5206\u4f4d\u6570\u9a71\u52a8\u7684\u957f\u5ea6\u8c03\u6574\u3002", "result": "\u5728DeepSeek-Distill-Qwen-1.5B\u4e0a\uff0cPALU\u5e73\u5747\u51cf\u5c1165%\u8f93\u51fa\u957f\u5ea6\uff0c\u540c\u65f6\u63d0\u534715%\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u591a\u79cd\u66ff\u4ee3\u65b9\u6cd5\uff0c\u5e76\u80fd\u8de8\u903b\u8f91\u3001STEM\u3001\u6570\u5b66\u9886\u57df\u548c1.5B-14B\u6a21\u578b\u89c4\u6a21\u9002\u5e94\u3002", "conclusion": "PALU\u662f\u4e00\u79cd\u5b9e\u7528\u6709\u6548\u7684\u7b80\u6d01\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u539f\u5219\u6027\u7b97\u6cd5\u548c\u5b9e\u7528\u8fd1\u4f3c\u5b9e\u73b0\u4e86\u7b80\u6d01\u6027\u4e0e\u6027\u80fd\u7684\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2510.10892", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.10892", "abs": "https://arxiv.org/abs/2510.10892", "authors": ["Bukunmi Gabriel Odunlami", "Marcos Netto"], "title": "Observability and parameter estimation of a generic model for aggregated distributed energy resources", "comment": null, "summary": "We propose a novel framework for estimating the parameters of an aggregated\ndistributed energy resources (der_a) model. First, we introduce a rigorous\nmethod to determine whether all model parameters are estimable. When they are\nnot, our approach identifies the subset of parameters that can be estimated.\nThe proposed framework offers new insights into the number and specific\nparameters that can be reliably estimated based on commonly available\nmeasurements. It also highlights the limitations of calibrating such models.\nSecond, we introduce a Kalman filtering method to calibrate the der_a model.\nSince we account for nonlinear effects such as saturation and deadbands, we\ndevelop a specific mechanism to handle smoothing functions within the Kalman\nfilter. Specifically, we consider the extended and the unscented Kalman filter.\nWe demonstrate the effectiveness of the proposed framework on a modified IEEE\n34-node distribution feeder with inverter-based resources. Our findings align\nwith the North American Electric Reliability Corporation's parameterization\nguideline and underscore the importance of model calibration in accurately\ncapturing the collective dynamics of distributed energy resources installed on\ndistribution systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7528\u4e8e\u4f30\u8ba1\u805a\u5408\u5206\u5e03\u5f0f\u80fd\u6e90\u8d44\u6e90\u6a21\u578b\u53c2\u6570\u7684\u65b0\u6846\u67b6\uff0c\u5305\u62ec\u53c2\u6570\u53ef\u4f30\u8ba1\u6027\u5206\u6790\u548c\u57fa\u4e8e\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u6821\u51c6\u65b9\u6cd5\u3002", "motivation": "\u5206\u5e03\u5f0f\u80fd\u6e90\u8d44\u6e90\u6a21\u578b\u6821\u51c6\u5b58\u5728\u53c2\u6570\u4f30\u8ba1\u56f0\u96be\u7684\u95ee\u9898\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\u6765\u8bc6\u522b\u53ef\u4f30\u8ba1\u53c2\u6570\u5e76\u51c6\u786e\u6821\u51c6\u6a21\u578b\u3002", "method": "\u9996\u5148\u5f00\u53d1\u53c2\u6570\u53ef\u4f30\u8ba1\u6027\u5206\u6790\u65b9\u6cd5\uff0c\u7136\u540e\u5f15\u5165\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u548c\u65e0\u8ff9\u5361\u5c14\u66fc\u6ee4\u6ce2\u6765\u5904\u7406\u975e\u7ebf\u6027\u6548\u5e94\uff0c\u5e76\u5f00\u53d1\u7279\u5b9a\u673a\u5236\u5904\u7406\u5e73\u6ed1\u51fd\u6570\u3002", "result": "\u5728\u6539\u8fdb\u7684IEEE 34\u8282\u70b9\u914d\u7535\u9988\u7ebf\u4e0a\u9a8c\u8bc1\u4e86\u6846\u67b6\u6709\u6548\u6027\uff0c\u7ed3\u679c\u7b26\u5408\u5317\u7f8e\u7535\u529b\u53ef\u9760\u6027\u516c\u53f8\u53c2\u6570\u5316\u6307\u5357\uff0c\u51c6\u786e\u6355\u6349\u4e86\u5206\u5e03\u5f0f\u80fd\u6e90\u8d44\u6e90\u7684\u96c6\u4f53\u52a8\u6001\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5206\u5e03\u5f0f\u80fd\u6e90\u8d44\u6e90\u6a21\u578b\u53c2\u6570\u4f30\u8ba1\u63d0\u4f9b\u4e86\u7cfb\u7edf\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4e86\u6a21\u578b\u6821\u51c6\u5728\u51c6\u786e\u6355\u6349\u96c6\u4f53\u52a8\u6001\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.10274", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.10274", "abs": "https://arxiv.org/abs/2510.10274", "authors": ["Jinliang Zheng", "Jianxiong Li", "Zhihao Wang", "Dongxiu Liu", "Xirui Kang", "Yuchun Feng", "Yinan Zheng", "Jiayin Zou", "Yilun Chen", "Jia Zeng", "Ya-Qin Zhang", "Jiangmiao Pang", "Jingjing Liu", "Tai Wang", "Xianyuan Zhan"], "title": "X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model", "comment": "preprint, technical report, 33 pages", "summary": "Successful generalist Vision-Language-Action (VLA) models rely on effective\ntraining across diverse robotic platforms with large-scale, cross-embodiment,\nheterogeneous datasets. To facilitate and leverage the heterogeneity in rich,\ndiverse robotic data sources, we propose a novel Soft Prompt approach with\nminimally added parameters, by infusing prompt learning concepts into\ncross-embodiment robot learning and introducing separate sets of learnable\nembeddings for each distinct data source. These embeddings serve as\nembodiment-specific prompts, which in unity empower VLA models with effective\nexploitation of varying cross-embodiment features. Our new X-VLA, a neat\nflow-matching-based VLA architecture, relies exclusively on soft-prompted\nstandard Transformer encoders, enjoying both scalability and simplicity.\nEvaluated across 6 simulations as well as 3 real-world robots, our 0.9B\ninstantiation-X-VLA-0.9B simultaneously achieves SOTA performance over a sweep\nof benchmarks, demonstrating superior results on a wide axes of capabilities,\nfrom flexible dexterity to quick adaptation across embodiments, environments,\nand tasks. Website: https://thu-air-dream.github.io/X-VLA/", "AI": {"tldr": "\u63d0\u51faX-VLA\u6a21\u578b\uff0c\u901a\u8fc7\u8f6f\u63d0\u793a\u65b9\u6cd5\u6709\u6548\u5229\u7528\u8de8\u5177\u8eab\u5f02\u6784\u6570\u636e\uff0c\u57286\u4e2a\u4eff\u771f\u548c3\u4e2a\u771f\u5b9e\u673a\u5668\u4eba\u4e0a\u5b9e\u73b0SOTA\u6027\u80fd", "motivation": "\u4e3a\u4e86\u6709\u6548\u5229\u7528\u4e30\u5bcc\u591a\u6837\u7684\u8de8\u5177\u8eab\u673a\u5668\u4eba\u6570\u636e\u6e90\uff0c\u89e3\u51b3\u5f02\u6784\u6570\u636e\u8bad\u7ec3\u95ee\u9898", "method": "\u63d0\u51fa\u8f6f\u63d0\u793a\u65b9\u6cd5\uff0c\u4e3a\u4e0d\u540c\u6570\u636e\u6e90\u5f15\u5165\u53ef\u5b66\u4e60\u5d4c\u5165\u4f5c\u4e3a\u5177\u8eab\u7279\u5b9a\u63d0\u793a\uff0c\u6784\u5efa\u57fa\u4e8e\u6d41\u5339\u914d\u7684VLA\u67b6\u6784", "result": "0.9B\u53c2\u6570\u7684X-VLA\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728\u7075\u6d3b\u6027\u3001\u8de8\u5177\u8eab\u9002\u5e94\u7b49\u65b9\u9762\u8868\u73b0\u4f18\u5f02", "conclusion": "\u8f6f\u63d0\u793a\u65b9\u6cd5\u80fd\u6709\u6548\u5229\u7528\u8de8\u5177\u8eab\u5f02\u6784\u6570\u636e\uff0cX-VLA\u6a21\u578b\u5728\u591a\u79cd\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u5c55\u73b0\u51fa\u5353\u8d8a\u6027\u80fd"}}
{"id": "2510.10193", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10193", "abs": "https://arxiv.org/abs/2510.10193", "authors": ["Qingni Wang", "Yue Fan", "Xin Eric Wang"], "title": "SAFER: Risk-Constrained Sample-then-Filter in Large Language Models", "comment": null, "summary": "As large language models (LLMs) are increasingly deployed in risk-sensitive\napplications such as real-world open-ended question answering (QA), ensuring\nthe trustworthiness of their outputs has become critical. Existing selective\nconformal prediction (SCP) methods provide statistical guarantees by\nconstructing prediction sets with a constrained miscoverage rate for correct\nanswers. However, prior works unrealistically assume that admissible answers\nfor all instances can be obtained via finite sampling, even for open-ended QA\nscenarios that lack a fixed and finite solution space. To address this, we\nintroduce a two-stage risk control framework comprising abstention-aware\nsampling and conformalized filtering (SAFER). Firstly, on a held-out\ncalibration set, SAFER calibrates a sampling budget within the maximum sampling\ncap, using the Clopper-Pearson exact method at a user-desired risk level (i.e.,\nthe maximum allowable miscoverage rate of the sampling sets). If the risk level\ncannot be satisfied within the cap, we abstain; otherwise, the calibrated\nsampling budget becomes the minimum requirements at test time. Then, we employ\ncalibration instances where correct answers are attainable under the calibrated\nbudget and apply the conformal risk control method to determine a statistically\nvalid uncertainty threshold, which filters unreliable distractors from the\ncandidate set for each test data point. In this stage, SAFER introduces an\nadditional risk level to guide the calculation of the threshold, thereby\ncontrolling the risk of correct answers being excluded. Furthermore, we show\nthat SAFER is compatible with various task-specific admission criteria and\ncalibration-test split ratios, highlighting its robustness and high data\nefficiency.", "AI": {"tldr": "SAFER\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u98ce\u9669\u63a7\u5236\u6846\u67b6\uff0c\u7528\u4e8e\u5f00\u653e\u57df\u95ee\u7b54\u4e2dLLM\u8f93\u51fa\u7684\u53ef\u4fe1\u5ea6\u4fdd\u8bc1\uff0c\u901a\u8fc7\u5f03\u6743\u611f\u77e5\u91c7\u6837\u548c\u4fdd\u5f62\u8fc7\u6ee4\u6765\u63d0\u4f9b\u7edf\u8ba1\u4fdd\u8bc1\u3002", "motivation": "\u73b0\u6709\u9009\u62e9\u6027\u4fdd\u5f62\u9884\u6d4b\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u5f00\u653e\u57df\u95ee\u7b54\u573a\u666f\uff0c\u56e0\u4e3a\u5b83\u4eec\u5047\u8bbe\u6240\u6709\u5b9e\u4f8b\u7684\u53ef\u63a5\u53d7\u7b54\u6848\u90fd\u80fd\u901a\u8fc7\u6709\u9650\u91c7\u6837\u83b7\u5f97\uff0c\u800c\u5f00\u653e\u57df\u95ee\u7b54\u7f3a\u4e4f\u56fa\u5b9a\u6709\u9650\u7684\u89e3\u7a7a\u95f4\u3002", "method": "\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u5728\u9a8c\u8bc1\u96c6\u4e0a\u4f7f\u7528Clopper-Pearson\u7cbe\u786e\u65b9\u6cd5\u6821\u51c6\u91c7\u6837\u9884\u7b97\uff1b2) \u5e94\u7528\u4fdd\u5f62\u98ce\u9669\u63a7\u5236\u65b9\u6cd5\u786e\u5b9a\u7edf\u8ba1\u6709\u6548\u7684\u7f6e\u4fe1\u5ea6\u9608\u503c\uff0c\u8fc7\u6ee4\u5019\u9009\u96c6\u4e2d\u7684\u4e0d\u53ef\u9760\u5e72\u6270\u9879\u3002", "result": "SAFER\u80fd\u591f\u63a7\u5236\u6b63\u786e\u7b54\u6848\u88ab\u6392\u9664\u7684\u98ce\u9669\uff0c\u5e76\u4e0e\u5404\u79cd\u4efb\u52a1\u7279\u5b9a\u7684\u51c6\u5165\u6807\u51c6\u548c\u6821\u51c6-\u6d4b\u8bd5\u5206\u5272\u6bd4\u4f8b\u517c\u5bb9\u3002", "conclusion": "SAFER\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7a33\u5065\u4e14\u6570\u636e\u9ad8\u6548\u7684\u98ce\u9669\u63a7\u5236\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u5f00\u653e\u57df\u95ee\u7b54\u573a\u666f\uff0c\u786e\u4fddLLM\u8f93\u51fa\u7684\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2510.10914", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.10914", "abs": "https://arxiv.org/abs/2510.10914", "authors": ["Jiajie Qiu", "Dakota Thompson", "Kamal Youcef-Toumi", "Amro M. Farid"], "title": "Optimal Multi-Modal Transportation and Electric Power Flow: The Value of Coordinated Dynamic Operation", "comment": "31 pages, 9 figures", "summary": "The electrification of transportation represents a critical challenge in the\nglobal transition toward net-zero emissions, as the sector often accounts for\nmore than one-quarter of national energy consumption. Achieving this\ntransformation requires not only widespread adoption of electric vehicles (EVs)\nbut also their seamless integration into interdependent infrastructure\nsystems-specifically, the transportation-electricity nexus (TEN). This paper\ndevelops an optimal multi-modal transportation and electric power flow (OMTEPF)\nmodel to evaluate the benefits of coordinated, dynamic system operation.\nBuilding on recent advances in hetero-functional graph theory, the framework\nenables joint optimization of five key operational decisions in intelligent TEN\nmanagement: vehicle dispatch, route choice, charging station queuing,\ncoordinated charging, and vehicle-to-grid stabilization. The mesoscopic,\ndynamic model explicitly represents individual EVs and their state-of-charge\ntrajectories, thereby extending beyond the prevailing literature's focus on\nstatic, macroscopic traffic assignment. It further captures the full scope of\nthe TEN as a system-of-systems, incorporating five distinct charging\nmodalities: private residential, private commercial, wired public commercial,\ninductive public, and discharging. On the power system side, an IV-ACOPF\nformulation ensures globally optimal solutions to the electrical subproblems.\nComparative analysis demonstrates the substantial value of coordinated TEN\noperation relative to the status quo of siloed, uncoordinated infrastructure\nmanagement. This work provides both a novel methodological contribution and\nactionable insights for the co-design and operation of next-generation\nsustainable mobility-energy systems.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u591a\u6a21\u6001\u4ea4\u901a\u548c\u7535\u529b\u6d41\u4f18\u5316\u6a21\u578b\uff0c\u7528\u4e8e\u8bc4\u4f30\u4ea4\u901a-\u7535\u529b\u8026\u5408\u7cfb\u7edf\u7684\u534f\u8c03\u8fd0\u884c\u6548\u76ca\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u8f66\u8f86\u8c03\u5ea6\u3001\u8def\u7ebf\u9009\u62e9\u3001\u5145\u7535\u7ad9\u6392\u961f\u7b49\u5173\u952e\u51b3\u7b56\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6548\u7387\u3002", "motivation": "\u4ea4\u901a\u7535\u6c14\u5316\u662f\u5b9e\u73b0\u51c0\u96f6\u6392\u653e\u7684\u5173\u952e\u6311\u6218\uff0c\u4ea4\u901a\u90e8\u95e8\u901a\u5e38\u5360\u56fd\u5bb6\u80fd\u6e90\u6d88\u8017\u7684\u56db\u5206\u4e4b\u4e00\u4ee5\u4e0a\u3002\u9700\u8981\u5c06\u7535\u52a8\u6c7d\u8f66\u65e0\u7f1d\u96c6\u6210\u5230\u4ea4\u901a-\u7535\u529b\u8026\u5408\u7cfb\u7edf\u4e2d\uff0c\u800c\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u9759\u6001\u5b8f\u89c2\u4ea4\u901a\u5206\u914d\uff0c\u7f3a\u4e4f\u5bf9\u52a8\u6001\u534f\u8c03\u8fd0\u884c\u7684\u7cfb\u7edf\u6027\u5206\u6790\u3002", "method": "\u57fa\u4e8e\u5f02\u8d28\u51fd\u6570\u56fe\u7406\u8bba\uff0c\u5f00\u53d1\u4e86\u6700\u4f18\u591a\u6a21\u6001\u4ea4\u901a\u548c\u7535\u529b\u6d41\u6a21\u578b\uff0c\u80fd\u591f\u8054\u5408\u4f18\u5316\u8f66\u8f86\u8c03\u5ea6\u3001\u8def\u7ebf\u9009\u62e9\u3001\u5145\u7535\u7ad9\u6392\u961f\u3001\u534f\u8c03\u5145\u7535\u548c\u8f66\u8f86\u5230\u7535\u7f51\u7a33\u5b9a\u7b49\u4e94\u4e2a\u5173\u952e\u64cd\u4f5c\u51b3\u7b56\u3002\u6a21\u578b\u91c7\u7528\u4ecb\u89c2\u52a8\u6001\u65b9\u6cd5\uff0c\u660e\u786e\u8868\u793a\u5355\u4e2a\u7535\u52a8\u6c7d\u8f66\u53ca\u5176\u5145\u7535\u72b6\u6001\u8f68\u8ff9\u3002", "result": "\u6bd4\u8f83\u5206\u6790\u8868\u660e\uff0c\u76f8\u5bf9\u4e8e\u5f53\u524d\u5b64\u7acb\u7684\u3001\u4e0d\u534f\u8c03\u7684\u57fa\u7840\u8bbe\u65bd\u7ba1\u7406\uff0c\u534f\u8c03\u7684\u4ea4\u901a-\u7535\u529b\u8026\u5408\u7cfb\u7edf\u8fd0\u884c\u5177\u6709\u663e\u8457\u4ef7\u503c\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u4e0b\u4e00\u4ee3\u53ef\u6301\u7eed\u79fb\u52a8\u80fd\u6e90\u7cfb\u7edf\u7684\u5171\u540c\u8bbe\u8ba1\u548c\u8fd0\u884c\u63d0\u4f9b\u4e86\u65b0\u9896\u7684\u65b9\u6cd5\u8bba\u8d21\u732e\u548c\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u3002"}}
{"id": "2510.10332", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10332", "abs": "https://arxiv.org/abs/2510.10332", "authors": ["Kohio Deflesselle", "M\u00e9lodie Daniel", "Aly Magassouba", "Miguel Aranda", "Olivier Ly"], "title": "Towards Safe Maneuvering of Double-Ackermann-Steering Robots with a Soft Actor-Critic Framework", "comment": "4 pages, 3 figures, 2 tables, Accepted for Safety of Intelligent and\n  Autonomous Vehicles: Formal Methods vs. Machine Learning approaches for\n  reliable navigation (SIAV-FM2L) an IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS 2025) workshop", "summary": "We present a deep reinforcement learning framework based on Soft Actor-Critic\n(SAC) for safe and precise maneuvering of double-Ackermann-steering mobile\nrobots (DASMRs). Unlike holonomic or simpler non-holonomic robots such as\ndifferential-drive robots, DASMRs face strong kinematic constraints that make\nclassical planners brittle in cluttered environments. Our framework leverages\nthe Hindsight Experience Replay (HER) and the CrossQ overlay to encourage\nmaneuvering efficiency while avoiding obstacles. Simulation results with a\nheavy four-wheel-steering rover show that the learned policy can robustly reach\nup to 97% of target positions while avoiding obstacles. Our framework does not\nrely on handcrafted trajectories or expert demonstrations.", "AI": {"tldr": "\u57fa\u4e8eSoft Actor-Critic\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u53cc\u963f\u514b\u66fc\u8f6c\u5411\u79fb\u52a8\u673a\u5668\u4eba\u7684\u5b89\u5168\u7cbe\u786e\u64cd\u63a7\uff0c\u5728\u590d\u6742\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u6548\u907f\u969c\u3002", "motivation": "\u53cc\u963f\u514b\u66fc\u8f6c\u5411\u79fb\u52a8\u673a\u5668\u4eba\u9762\u4e34\u5f3a\u8fd0\u52a8\u5b66\u7ea6\u675f\uff0c\u4f20\u7edf\u89c4\u5212\u5668\u5728\u590d\u6742\u73af\u5883\u4e2d\u8868\u73b0\u8106\u5f31\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528Soft Actor-Critic\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u7ed3\u5408Hindsight Experience Replay\u548cCrossQ\u8986\u76d6\u6280\u672f\uff0c\u9f13\u52b1\u9ad8\u6548\u673a\u52a8\u540c\u65f6\u907f\u514d\u969c\u788d\u7269\u3002", "result": "\u5728\u91cd\u578b\u56db\u8f6e\u8f6c\u5411\u673a\u5668\u4eba\u7684\u4eff\u771f\u4e2d\uff0c\u5b66\u4e60\u5230\u7684\u7b56\u7565\u80fd\u591f\u9c81\u68d2\u5730\u8fbe\u523097%\u7684\u76ee\u6807\u4f4d\u7f6e\uff0c\u540c\u65f6\u907f\u5f00\u969c\u788d\u7269\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4f9d\u8d56\u4eba\u5de5\u8f68\u8ff9\u6216\u4e13\u5bb6\u6f14\u793a\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u53cc\u963f\u514b\u66fc\u8f6c\u5411\u673a\u5668\u4eba\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u5bfc\u822a\u95ee\u9898\u3002"}}
{"id": "2510.10197", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10197", "abs": "https://arxiv.org/abs/2510.10197", "authors": ["Siyuan Lu", "Zechuan Wang", "Hongxuan Zhang", "Qintong Wu", "Leilei Gan", "Chenyi Zhuang", "Jinjie Gu", "Tao Lin"], "title": "Don't Just Fine-tune the Agent, Tune the Environment", "comment": null, "summary": "Large Language Model (LLM) agents show great promise for complex, multi-turn\ntool-use tasks, but their development is often hampered by the extreme scarcity\nof high-quality training data. Supervised fine-tuning (SFT) on synthetic data\nleads to overfitting, whereas standard reinforcement learning (RL) struggles\nwith a critical cold-start problem and training instability. To address these\nchallenges, we introduce $\\textbf{Environment Tuning}$, a novel training\nparadigm that enables agents to learn complex behaviors directly from problem\ninstances without relying on pre-collected expert trajectories.\n$\\textbf{Environment Tuning}$ orchestrates this learning process through a\nstructured curriculum, actionable environment augmentation that provides\ncorrective feedback, and fine-grained progress rewards to ensure stable and\nefficient exploration. Using only 400 problem instances from Berkeley\nFunction-Calling Leaderboard (BFCL) benchmark, our method not only achieves\ncompetitive in-distribution performance against strong baselines but also\ndemonstrates superior out-of-distribution generalization, overcoming the\nperformance collapse common to SFT-based approaches. Our work presents a\nparadigm shift from supervised fine-tuning on static trajectories to dynamic,\nenvironment-based exploration, paving the way for training more robust and\ndata-efficient agents.", "AI": {"tldr": "\u63d0\u51faEnvironment Tuning\u8bad\u7ec3\u8303\u5f0f\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u8bfe\u7a0b\u3001\u73af\u5883\u589e\u5f3a\u548c\u7ec6\u7c92\u5ea6\u5956\u52b1\uff0c\u8ba9LLM\u667a\u80fd\u4f53\u76f4\u63a5\u4ece\u95ee\u9898\u5b9e\u4f8b\u5b66\u4e60\u590d\u6742\u884c\u4e3a\uff0c\u65e0\u9700\u4e13\u5bb6\u8f68\u8ff9\u6570\u636e\u3002", "motivation": "\u89e3\u51b3LLM\u667a\u80fd\u4f53\u5728\u590d\u6742\u5de5\u5177\u4f7f\u7528\u4efb\u52a1\u4e2d\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u907f\u514dSFT\u7684\u8fc7\u62df\u5408\u548c\u6807\u51c6RL\u7684\u51b7\u542f\u52a8\u4e0e\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u95ee\u9898\u3002", "method": "Environment Tuning\uff1a\u7ed3\u6784\u5316\u8bfe\u7a0b\u7f16\u6392\u3001\u63d0\u4f9b\u7ea0\u6b63\u53cd\u9988\u7684\u73af\u5883\u589e\u5f3a\u3001\u786e\u4fdd\u7a33\u5b9a\u63a2\u7d22\u7684\u7ec6\u7c92\u5ea6\u8fdb\u5ea6\u5956\u52b1\u3002", "result": "\u4ec5\u4f7f\u7528400\u4e2aBFCL\u57fa\u51c6\u95ee\u9898\u5b9e\u4f8b\uff0c\u5728\u5206\u5e03\u5185\u6027\u80fd\u4e0e\u5f3a\u57fa\u7ebf\u7ade\u4e89\uff0c\u5728\u5206\u5e03\u5916\u6cdb\u5316\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u907f\u514d\u4e86SFT\u65b9\u6cd5\u7684\u6027\u80fd\u5d29\u6e83\u3002", "conclusion": "\u4ece\u57fa\u4e8e\u9759\u6001\u8f68\u8ff9\u7684\u76d1\u7763\u5fae\u8c03\u8f6c\u5411\u52a8\u6001\u73af\u5883\u63a2\u7d22\uff0c\u4e3a\u8bad\u7ec3\u66f4\u9c81\u68d2\u548c\u6570\u636e\u9ad8\u6548\u7684\u667a\u80fd\u4f53\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2510.11089", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.11089", "abs": "https://arxiv.org/abs/2510.11089", "authors": ["Fabio Marco Monetti", "Adam Lundstr\u00f6m", "Colin de Kwant", "Magnus Gyllenskepp", "Antonio Maffei"], "title": "Establishing assembly-oriented modular product architectures through Design for Assembly enhanced Modular Function Deployment", "comment": null, "summary": "Modular product design has become a strategic enabler for companies seeking\nto balance product variety, operational efficiency, and market responsiveness,\nmaking the alignment between modular architecture and manufacturing\nconsiderations increasingly critical. Modular Function Deployment (MFD) is a\nwidely adopted method for defining modular product architectures, yet it lacks\nsystematic support for assembly considerations during early concept and\nsystem-level development. This limitation increases the risk of delayed\nproduction ramp-up and lifecycle inefficiencies. This paper proposes a set of\nenhancements to MFD that integrate Design for Assembly (DFA) logic into\narchitectural synthesis. The extended method introduces structured heuristics,\nassembly-oriented module drivers, a coded interface taxonomy, and quantitative\nmetrics for assessing assembly feasibility and automation readiness. These\nadditions preserve compatibility with standard MFD workflows while enriching\ndecision-making with traceable, production-informed reasoning. An illustrative\ncase study involving a handheld leaf blower demonstrates the method's usability\nand effectiveness. The redesigned architecture shows reduced assembly effort,\nsimplified interfaces, and increased automation potential. By supporting\nearly-stage evaluation of architectural alternatives through an assembly lens,\nthe method enables faster transition to efficient volume production and\nprovides a foundation for continuous improvement throughout the product\nlifecycle.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5bf9\u6a21\u5757\u5316\u529f\u80fd\u90e8\u7f72(MFD)\u65b9\u6cd5\u7684\u589e\u5f3a\uff0c\u5c06\u88c5\u914d\u8bbe\u8ba1(DFA)\u903b\u8f91\u96c6\u6210\u5230\u67b6\u6784\u5408\u6210\u4e2d\uff0c\u4ee5\u89e3\u51b3MFD\u5728\u65e9\u671f\u6982\u5ff5\u548c\u7cfb\u7edf\u7ea7\u5f00\u53d1\u4e2d\u7f3a\u4e4f\u88c5\u914d\u8003\u8651\u7684\u95ee\u9898\u3002", "motivation": "\u6a21\u5757\u5316\u4ea7\u54c1\u8bbe\u8ba1\u5df2\u6210\u4e3a\u4f01\u4e1a\u5728\u4ea7\u54c1\u591a\u6837\u6027\u3001\u8fd0\u8425\u6548\u7387\u548c\u5e02\u573a\u54cd\u5e94\u80fd\u529b\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u7684\u6218\u7565\u63a8\u52a8\u56e0\u7d20\uff0c\u4f46\u73b0\u6709\u7684MFD\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u88c5\u914d\u8003\u8651\u7684\u7cfb\u7edf\u652f\u6301\uff0c\u8fd9\u589e\u52a0\u4e86\u751f\u4ea7\u722c\u5761\u5ef6\u8fdf\u548c\u751f\u547d\u5468\u671f\u6548\u7387\u4f4e\u4e0b\u7684\u98ce\u9669\u3002", "method": "\u6269\u5c55\u7684MFD\u65b9\u6cd5\u5f15\u5165\u4e86\u7ed3\u6784\u5316\u542f\u53d1\u5f0f\u65b9\u6cd5\u3001\u9762\u5411\u88c5\u914d\u7684\u6a21\u5757\u9a71\u52a8\u56e0\u7d20\u3001\u7f16\u7801\u63a5\u53e3\u5206\u7c7b\u6cd5\u4ee5\u53ca\u8bc4\u4f30\u88c5\u914d\u53ef\u884c\u6027\u548c\u81ea\u52a8\u5316\u51c6\u5907\u7a0b\u5ea6\u7684\u5b9a\u91cf\u6307\u6807\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u6807\u51c6MFD\u5de5\u4f5c\u6d41\u7a0b\u7684\u517c\u5bb9\u6027\u3002", "result": "\u901a\u8fc7\u624b\u6301\u5439\u53f6\u673a\u7684\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u7528\u6027\u548c\u6709\u6548\u6027\uff0c\u91cd\u65b0\u8bbe\u8ba1\u7684\u67b6\u6784\u663e\u793a\u51cf\u5c11\u4e86\u88c5\u914d\u5de5\u4f5c\u91cf\u3001\u7b80\u5316\u4e86\u63a5\u53e3\u5e76\u63d0\u9ad8\u4e86\u81ea\u52a8\u5316\u6f5c\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u88c5\u914d\u89c6\u89d2\u652f\u6301\u65e9\u671f\u9636\u6bb5\u5bf9\u67b6\u6784\u66ff\u4ee3\u65b9\u6848\u7684\u8bc4\u4f30\uff0c\u80fd\u591f\u66f4\u5feb\u5730\u8fc7\u6e21\u5230\u9ad8\u6548\u7684\u6279\u91cf\u751f\u4ea7\uff0c\u5e76\u4e3a\u6574\u4e2a\u4ea7\u54c1\u751f\u547d\u5468\u671f\u7684\u6301\u7eed\u6539\u8fdb\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.10338", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.10338", "abs": "https://arxiv.org/abs/2510.10338", "authors": ["Balagopal Unnikrishnan", "Ariel Guerra Adames", "Amin Adibi", "Sameer Peesapati", "Rafal Kocielnik", "Shira Fischer", "Hillary Clinton Kasimbazi", "Rodrigo Gameiro", "Alina Peluso", "Chrystinne Oliveira Fernandes", "Maximin Lange", "Lovedeep Gondara", "Leo Anthony Celi"], "title": "Beyond Ethics: How Inclusive Innovation Drives Economic Returns in Medical AI", "comment": null, "summary": "While ethical arguments for fairness in healthcare AI are well-established,\nthe economic and strategic value of inclusive design remains underexplored.\nThis perspective introduces the ``inclusive innovation dividend'' -- the\ncounterintuitive principle that solutions engineered for diverse, constrained\nuse cases generate superior economic returns in broader markets. Drawing from\nassistive technologies that evolved into billion-dollar mainstream industries,\nwe demonstrate how inclusive healthcare AI development creates business value\nbeyond compliance requirements. We identify four mechanisms through which\ninclusive innovation drives returns: (1) market expansion via geographic\nscalability and trust acceleration; (2) risk mitigation through reduced\nremediation costs and litigation exposure; (3) performance dividends from\nsuperior generalization and reduced technical debt, and (4) competitive\nadvantages in talent acquisition and clinical adoption. We present the\nHealthcare AI Inclusive Innovation Framework (HAIIF), a practical scoring\nsystem that enables organizations to evaluate AI investments based on their\npotential to capture these benefits. HAIIF provides structured guidance for\nresource allocation, transforming fairness and inclusivity from regulatory\ncheckboxes into sources of strategic differentiation. Our findings suggest that\norganizations investing incrementally in inclusive design can achieve expanded\nmarket reach and sustained competitive advantages, while those treating these\nconsiderations as overhead face compounding disadvantages as network effects\nand data advantages accrue to early movers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\"\u5305\u5bb9\u6027\u521b\u65b0\u7ea2\u5229\"\u6982\u5ff5\uff0c\u6307\u51fa\u4e3a\u591a\u6837\u5316\u3001\u53d7\u9650\u4f7f\u7528\u573a\u666f\u8bbe\u8ba1\u7684\u533b\u7597AI\u89e3\u51b3\u65b9\u6848\u80fd\u5728\u66f4\u5e7f\u6cdb\u5e02\u573a\u4ea7\u751f\u66f4\u4f18\u7ecf\u6d4e\u56de\u62a5\uff0c\u5e76\u5f00\u53d1\u4e86HAIIF\u8bc4\u5206\u6846\u67b6\u6765\u8bc4\u4f30AI\u6295\u8d44\u7684\u5305\u5bb9\u6027\u4ef7\u503c\u3002", "motivation": "\u867d\u7136\u533b\u7597AI\u516c\u5e73\u6027\u7684\u4f26\u7406\u8bba\u8bc1\u5df2\u5f88\u5145\u5206\uff0c\u4f46\u5305\u5bb9\u6027\u8bbe\u8ba1\u7684\u7ecf\u6d4e\u548c\u6218\u7565\u4ef7\u503c\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u63ed\u793a\u5305\u5bb9\u6027\u521b\u65b0\u5982\u4f55\u521b\u9020\u8d85\u8d8a\u5408\u89c4\u8981\u6c42\u7684\u5546\u4e1a\u4ef7\u503c\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4ece\u8f85\u52a9\u6280\u672f\u6f14\u53d8\u4e3a\u4e3b\u6d41\u4ea7\u4e1a\u7684\u6848\u4f8b\uff0c\u8bc6\u522b\u5305\u5bb9\u6027\u521b\u65b0\u9a71\u52a8\u56de\u62a5\u7684\u56db\u4e2a\u673a\u5236\uff0c\u5e76\u5f00\u53d1\u4e86\u533b\u7597AI\u5305\u5bb9\u6027\u521b\u65b0\u6846\u67b6(HAIIF)\u8bc4\u5206\u7cfb\u7edf\u6765\u8bc4\u4f30AI\u6295\u8d44\u3002", "result": "\u53d1\u73b0\u5305\u5bb9\u6027\u8bbe\u8ba1\u80fd\u901a\u8fc7\u5e02\u573a\u6269\u5f20\u3001\u98ce\u9669\u7f13\u89e3\u3001\u6027\u80fd\u7ea2\u5229\u548c\u7ade\u4e89\u4f18\u52bf\u56db\u4e2a\u673a\u5236\u521b\u9020\u5546\u4e1a\u4ef7\u503c\uff0cHAIIF\u6846\u67b6\u4e3a\u7ec4\u7ec7\u63d0\u4f9b\u4e86\u5c06\u516c\u5e73\u6027\u8f6c\u5316\u4e3a\u6218\u7565\u5dee\u5f02\u5316\u7684\u5b9e\u7528\u5de5\u5177\u3002", "conclusion": "\u6e10\u8fdb\u6295\u8d44\u5305\u5bb9\u6027\u8bbe\u8ba1\u7684\u7ec4\u7ec7\u80fd\u83b7\u5f97\u6269\u5c55\u7684\u5e02\u573a\u8986\u76d6\u548c\u6301\u7eed\u7ade\u4e89\u4f18\u52bf\uff0c\u800c\u5c06\u5176\u89c6\u4e3a\u6210\u672c\u7684\u7ec4\u7ec7\u5c06\u9762\u4e34\u7f51\u7edc\u6548\u5e94\u548c\u6570\u636e\u4f18\u52bf\u79ef\u7d2f\u5e26\u6765\u7684\u590d\u5408\u52a3\u52bf\u3002"}}
{"id": "2510.10337", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10337", "abs": "https://arxiv.org/abs/2510.10337", "authors": ["Jihong Zhu", "Kefeng Huang", "Jonathon Pipe", "Chris Horbaczewsky", "Andy Tyrrell", "Ian J. S. Fairlamb"], "title": "Rise of the Robochemist", "comment": "This article was originally published in the IEEE Systems, Man, and\n  Cybernetics Society eNewsletter, September 2025 issue:\n  https://www.ieeesmc.org/wp-content/uploads/2024/10/FeatureArticle_Sept25.pdf", "summary": "Chemistry, a long-standing discipline, has historically relied on manual and\noften time-consuming processes. While some automation exists, the field is now\non the cusp of a significant evolution driven by the integration of robotics\nand artificial intelligence (AI), giving rise to the concept of the\nrobochemist: a new paradigm where autonomous systems assist in designing,\nexecuting, and analyzing experiments. Robochemists integrate mobile\nmanipulators, advanced perception, teleoperation, and data-driven protocols to\nexecute experiments with greater adaptability, reproducibility, and safety.\nRather than a fully automated replacement for human chemists, we envisioned the\nrobochemist as a complementary partner that works collaboratively to enhance\ndiscovery, enabling a more efficient exploration of chemical space and\naccelerating innovation in pharmaceuticals, materials science, and sustainable\nmanufacturing. This article traces the technologies, applications, and\nchallenges that define this transformation, highlighting both the opportunities\nand the responsibilities that accompany the emergence of the robochemist.\nUltimately, the future of chemistry is argued to lie in a symbiotic partnership\nwhere human intuition and expertise is amplified by robotic precision and\nAI-driven insight.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\"\u673a\u5668\u4eba\u5316\u5b66\u5bb6\"\u8fd9\u4e00\u65b0\u8303\u5f0f\uff0c\u5373\u901a\u8fc7\u6574\u5408\u673a\u5668\u4eba\u6280\u672f\u548c\u4eba\u5de5\u667a\u80fd\u5b9e\u73b0\u5316\u5b66\u5b9e\u9a8c\u7684\u81ea\u4e3b\u8bbe\u8ba1\u3001\u6267\u884c\u548c\u5206\u6790\uff0c\u65e8\u5728\u4f5c\u4e3a\u4eba\u7c7b\u5316\u5b66\u5bb6\u7684\u8865\u5145\u4f19\u4f34\u800c\u975e\u5b8c\u5168\u66ff\u4ee3\u3002", "motivation": "\u4f20\u7edf\u5316\u5b66\u9886\u57df\u4f9d\u8d56\u8017\u65f6\u7684\u4eba\u5de5\u6d41\u7a0b\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u9002\u5e94\u6027\u66f4\u5f3a\u4e14\u5b89\u5168\u7684\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u4ee5\u52a0\u901f\u836f\u7269\u3001\u6750\u6599\u79d1\u5b66\u548c\u53ef\u6301\u7eed\u5236\u9020\u7b49\u9886\u57df\u7684\u521b\u65b0\u3002", "method": "\u6574\u5408\u79fb\u52a8\u673a\u68b0\u81c2\u3001\u5148\u8fdb\u611f\u77e5\u3001\u8fdc\u7a0b\u64cd\u4f5c\u548c\u6570\u636e\u9a71\u52a8\u534f\u8bae\uff0c\u6784\u5efa\u80fd\u591f\u534f\u4f5c\u6267\u884c\u5b9e\u9a8c\u7684\u81ea\u4e3b\u7cfb\u7edf\u3002", "result": "\u673a\u5668\u4eba\u5316\u5b66\u5bb6\u80fd\u591f\u4ee5\u66f4\u9ad8\u7684\u9002\u5e94\u6027\u3001\u53ef\u91cd\u590d\u6027\u548c\u5b89\u5168\u6027\u6267\u884c\u5b9e\u9a8c\uff0c\u4fc3\u8fdb\u5316\u5b66\u7a7a\u95f4\u7684\u66f4\u9ad8\u6548\u63a2\u7d22\u3002", "conclusion": "\u5316\u5b66\u7684\u672a\u6765\u5728\u4e8e\u4eba\u7c7b\u76f4\u89c9\u4e0e\u4e13\u4e1a\u77e5\u8bc6\u4e0e\u673a\u5668\u4eba\u7cbe\u5ea6\u53caAI\u6d1e\u5bdf\u529b\u7684\u5171\u751f\u4f19\u4f34\u5173\u7cfb\uff0c\u8fd9\u79cd\u5408\u4f5c\u5c06\u589e\u5f3a\u53d1\u73b0\u80fd\u529b\u5e76\u52a0\u901f\u521b\u65b0\u3002"}}
{"id": "2510.10205", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10205", "abs": "https://arxiv.org/abs/2510.10205", "authors": ["Manjiang Yu", "Hongji Li", "Priyanka Singh", "Xue Li", "Di Wang", "Lijie Hu"], "title": "PIXEL: Adaptive Steering Via Position-wise Injection with eXact Estimated Levels under Subspace Calibration", "comment": "18 pages,3 figures", "summary": "Reliable behavior control is central to deploying large language models\n(LLMs) on the web. Activation steering offers a tuning-free route to align\nattributes (e.g., truthfulness) that ensure trustworthy generation. Prevailing\napproaches rely on coarse heuristics and lack a principled account of where to\nsteer and how strongly to intervene. To this end, we propose Position-wise\nInjection with eXact Estimated Levels (PIXEL), a position-wise activation\nsteering framework that, in contrast to prior work, learns a property-aligned\nsubspace from dual views (tail-averaged and end-token) and selects intervention\nstrength via a constrained geometric objective with a closed-form solution,\nthereby adapting to token-level sensitivity without global hyperparameter\ntuning. PIXEL further performs sample-level orthogonal residual calibration to\nrefine the global attribute direction and employs a lightweight\nposition-scanning routine to identify receptive injection sites. We\nadditionally provide representation-level guarantees for the\nminimal-intervention rule, supporting reliable alignment. Across diverse models\nand evaluation paradigms, PIXEL consistently improves attribute alignment while\npreserving model general capabilities, offering a practical and principled\nmethod for LLMs' controllable generation. Our code is available at\nhttps://github.com/V1centNevwake/PIXEL-Adaptive-Steering", "AI": {"tldr": "PIXEL\u662f\u4e00\u4e2a\u4f4d\u7f6e\u611f\u77e5\u7684\u6fc0\u6d3b\u5f15\u5bfc\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u89c6\u89d2\u5b66\u4e60\u5c5e\u6027\u5bf9\u9f50\u5b50\u7a7a\u95f4\uff0c\u4f7f\u7528\u7ea6\u675f\u51e0\u4f55\u76ee\u6807\u81ea\u9002\u5e94\u9009\u62e9\u5e72\u9884\u5f3a\u5ea6\uff0c\u65e0\u9700\u5168\u5c40\u8d85\u53c2\u6570\u8c03\u4f18\uff0c\u5b9e\u73b0LLM\u7684\u53ef\u9760\u884c\u4e3a\u63a7\u5236\u3002", "motivation": "\u73b0\u6709\u6fc0\u6d3b\u5f15\u5bfc\u65b9\u6cd5\u4f9d\u8d56\u7c97\u7cd9\u542f\u53d1\u5f0f\uff0c\u7f3a\u4e4f\u5bf9\u5f15\u5bfc\u4f4d\u7f6e\u548c\u5e72\u9884\u5f3a\u5ea6\u7684\u539f\u5219\u6027\u8003\u8651\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u884c\u4e3a\u63a7\u5236\u65b9\u6cd5\u6765\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "method": "\u4ece\u53cc\u89c6\u89d2\uff08\u5c3e\u5e73\u5747\u548c\u672b\u7aef\u6807\u8bb0\uff09\u5b66\u4e60\u5c5e\u6027\u5bf9\u9f50\u5b50\u7a7a\u95f4\uff0c\u901a\u8fc7\u7ea6\u675f\u51e0\u4f55\u76ee\u6807\u9009\u62e9\u5e72\u9884\u5f3a\u5ea6\uff0c\u6267\u884c\u6837\u672c\u7ea7\u6b63\u4ea4\u6b8b\u5dee\u6821\u51c6\uff0c\u5e76\u4f7f\u7528\u8f7b\u91cf\u7ea7\u4f4d\u7f6e\u626b\u63cf\u8bc6\u522b\u53ef\u6ce8\u5165\u4f4d\u7f6e\u3002", "result": "\u5728\u4e0d\u540c\u6a21\u578b\u548c\u8bc4\u4f30\u8303\u5f0f\u4e0b\uff0cPIXEL\u6301\u7eed\u6539\u8fdb\u5c5e\u6027\u5bf9\u9f50\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u901a\u7528\u80fd\u529b\u3002", "conclusion": "PIXEL\u4e3aLLM\u7684\u53ef\u63a7\u751f\u6210\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u539f\u5219\u6027\u7684\u65b9\u6cd5\uff0c\u652f\u6301\u53ef\u9760\u5bf9\u9f50\u3002"}}
{"id": "2510.11181", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.11181", "abs": "https://arxiv.org/abs/2510.11181", "authors": ["Tamme Emunds", "Paul Brunzema", "Sebastian Trimpe", "Nils Nie\u00dfen"], "title": "Utilizing Bayesian Optimization for Timetable-Independent Railway Junction Performance Determination", "comment": null, "summary": "The efficiency of railway infrastructure is significantly influenced by the\nmix of trains that utilize it, as different service types have competing\noperational requirements. While freight services might require extended service\ntimes, passenger services demand more predictable schedules. Traditional\nmethods for addressing long-term traffic assignment problems often rely on\nfixed-value capacity limitations, determined based on specific assumptions\nabout traffic composition. This paper introduces a methodology for determining\ntimetable-independent capacity within the traffic rate assignment problem,\nenabling the calculation of junction capacities under dynamic traffic\ndistributions. We solve the underlying non-linear constrained optimization\nproblem maximizing the traffic throughput using Bayesian optimization (BO).\nThis setting combines a known objective function with expensive- to-compute\ncapacity constraints, motivating an adaption of standard BO problems, where\nobjective functions are usually unknown. We tailor the acquisition process in\nBO to this specific setting and increase performance by incorporating prior\nknowledge about the shape of the constraint functions into the Gaussian process\nsurrogate model. Our derived approaches are benchmarked on a railway junction\nnear Paris, significantly outperforming fixed traffic composition models and\nhighlighting the benefits of dynamic capacity allocation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u4f18\u5316\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8ba1\u7b97\u94c1\u8def\u67a2\u7ebd\u5728\u52a8\u6001\u4ea4\u901a\u5206\u5e03\u4e0b\u7684\u65f6\u523b\u8868\u65e0\u5173\u5bb9\u91cf\uff0c\u663e\u8457\u4f18\u4e8e\u56fa\u5b9a\u4ea4\u901a\u7ec4\u6210\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f7f\u7528\u56fa\u5b9a\u5bb9\u91cf\u9650\u5236\u6765\u5904\u7406\u957f\u671f\u4ea4\u901a\u5206\u914d\u95ee\u9898\uff0c\u4f46\u4e0d\u540c\u670d\u52a1\u7c7b\u578b\uff08\u8d27\u8fd0\u4e0e\u5ba2\u8fd0\uff09\u5177\u6709\u7ade\u4e89\u6027\u8fd0\u8425\u9700\u6c42\uff0c\u9700\u8981\u52a8\u6001\u5bb9\u91cf\u5206\u914d\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u89e3\u51b3\u975e\u7ebf\u6027\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u6700\u5927\u5316\u4ea4\u901a\u541e\u5410\u91cf\u3002\u9488\u5bf9\u5df2\u77e5\u76ee\u6807\u51fd\u6570\u4f46\u7ea6\u675f\u8ba1\u7b97\u6602\u8d35\u7684\u7279\u5b9a\u8bbe\u7f6e\uff0c\u8c03\u6574\u8d1d\u53f6\u65af\u4f18\u5316\u7684\u91c7\u96c6\u8fc7\u7a0b\uff0c\u5e76\u5c06\u7ea6\u675f\u51fd\u6570\u5f62\u72b6\u7684\u5148\u9a8c\u77e5\u8bc6\u878d\u5165\u9ad8\u65af\u8fc7\u7a0b\u4ee3\u7406\u6a21\u578b\u3002", "result": "\u5728\u5df4\u9ece\u9644\u8fd1\u94c1\u8def\u67a2\u7ebd\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u56fa\u5b9a\u4ea4\u901a\u7ec4\u6210\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u52a8\u6001\u5bb9\u91cf\u5206\u914d\u7684\u4f18\u52bf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u8ba1\u7b97\u52a8\u6001\u4ea4\u901a\u5206\u5e03\u4e0b\u7684\u94c1\u8def\u67a2\u7ebd\u5bb9\u91cf\uff0c\u4e3a\u957f\u671f\u4ea4\u901a\u5206\u914d\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u5bb9\u91cf\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2510.10346", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10346", "abs": "https://arxiv.org/abs/2510.10346", "authors": ["Yuxiang Peng", "Chuchu Chen", "Kejian Wu", "Guoquan Huang"], "title": "sqrtVINS: Robust and Ultrafast Square-Root Filter-based 3D Motion Tracking", "comment": null, "summary": "In this paper, we develop and open-source, for the first time, a square-root\nfilter (SRF)-based visual-inertial navigation system (VINS), termed sqrtVINS,\nwhich is ultra-fast, numerically stable, and capable of dynamic initialization\neven under extreme conditions (i.e., extremely small time window). Despite\nrecent advancements in VINS, resource constraints and numerical instability on\nembedded (robotic) systems with limited precision remain critical challenges. A\nsquare-root covariance-based filter offers a promising solution by providing\nnumerical stability, efficient memory usage, and guaranteed positive\nsemi-definiteness. However, canonical SRFs suffer from inefficiencies caused by\ndisruptions in the triangular structure of the covariance matrix during\nupdates. The proposed method significantly improves VINS efficiency with a\nnovel Cholesky decomposition (LLT)-based SRF update, by fully exploiting the\nsystem structure to preserve the structure. Moreover, we design a fast, robust,\ndynamic initialization method, which first recovers the minimal states without\ntriangulating 3D features and then efficiently performs iterative SRF update to\nrefine the full states, enabling seamless VINS operation. The proposed\nLLT-based SRF is extensively verified through numerical studies, demonstrating\nsuperior numerical stability and achieving robust efficient performance on\n32-bit single-precision floats, operating at twice the speed of\nstate-of-the-art (SOTA) methods. Our initialization method, tested on both\nmobile workstations and Jetson Nano computers, achieving a high success rate of\ninitialization even within a 100 ms window under minimal conditions. Finally,\nthe proposed sqrtVINS is extensively validated across diverse scenarios,\ndemonstrating strong efficiency, robustness, and reliability. The full\nopen-source implementation is released to support future research and\napplications.", "AI": {"tldr": "\u5f00\u53d1\u5e76\u5f00\u6e90\u4e86\u57fa\u4e8e\u5e73\u65b9\u6839\u6ee4\u6ce2\u7684\u89c6\u89c9\u60ef\u6027\u5bfc\u822a\u7cfb\u7edfsqrtVINS\uff0c\u5177\u6709\u8d85\u5feb\u901f\u5ea6\u3001\u6570\u503c\u7a33\u5b9a\u6027\uff0c\u80fd\u5728\u6781\u7aef\u6761\u4ef6\u4e0b\u52a8\u6001\u521d\u59cb\u5316\uff0c\u572832\u4f4d\u5355\u7cbe\u5ea6\u6d6e\u70b9\u6570\u4e0a\u5b9e\u73b0\u4e24\u500d\u4e8eSOTA\u65b9\u6cd5\u7684\u901f\u5ea6\u3002", "motivation": "\u5d4c\u5165\u5f0f\u673a\u5668\u4eba\u7cfb\u7edf\u8d44\u6e90\u53d7\u9650\u548c\u6570\u503c\u4e0d\u7a33\u5b9a\u6027\u662fVINS\u7684\u5173\u952e\u6311\u6218\uff0c\u5e73\u65b9\u6839\u534f\u65b9\u5dee\u6ee4\u6ce2\u80fd\u63d0\u4f9b\u6570\u503c\u7a33\u5b9a\u6027\u3001\u9ad8\u6548\u5185\u5b58\u4f7f\u7528\u548c\u4fdd\u8bc1\u6b63\u534a\u5b9a\u6027\uff0c\u4f46\u4f20\u7edfSRF\u56e0\u534f\u65b9\u5dee\u77e9\u9635\u4e09\u89d2\u7ed3\u6784\u7834\u574f\u800c\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u7684\u57fa\u4e8eCholesky\u5206\u89e3\u7684SRF\u66f4\u65b0\u65b9\u6cd5\uff0c\u5145\u5206\u5229\u7528\u7cfb\u7edf\u7ed3\u6784\u4fdd\u6301\u4e09\u89d2\u7ed3\u6784\uff1b\u8bbe\u8ba1\u5feb\u901f\u9c81\u68d2\u7684\u52a8\u6001\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u5148\u6062\u590d\u6700\u5c0f\u72b6\u6001\u800c\u4e0d\u4e09\u89d2\u53163D\u7279\u5f81\uff0c\u7136\u540e\u901a\u8fc7\u8fed\u4ee3SRF\u66f4\u65b0\u4f18\u5316\u5b8c\u6574\u72b6\u6001\u3002", "result": "\u5728\u6570\u503c\u7814\u7a76\u4e2d\u9a8c\u8bc1\u4e86LLT-based SRF\u7684\u4f18\u8d8a\u6570\u503c\u7a33\u5b9a\u6027\uff0c\u572832\u4f4d\u5355\u7cbe\u5ea6\u6d6e\u70b9\u6570\u4e0a\u5b9e\u73b0\u4e24\u500d\u4e8eSOTA\u65b9\u6cd5\u7684\u901f\u5ea6\uff1b\u521d\u59cb\u5316\u65b9\u6cd5\u5728\u79fb\u52a8\u5de5\u4f5c\u7ad9\u548cJetson Nano\u4e0a\u6d4b\u8bd5\uff0c\u5373\u4f7f\u5728100ms\u7a97\u53e3\u5185\u4e5f\u80fd\u8fbe\u5230\u9ad8\u6210\u529f\u7387\u3002", "conclusion": "sqrtVINS\u5728\u5404\u79cd\u573a\u666f\u4e0b\u9a8c\u8bc1\u4e86\u5f3a\u5927\u7684\u6548\u7387\u3001\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\uff0c\u5f00\u6e90\u5b9e\u73b0\u652f\u6301\u672a\u6765\u7814\u7a76\u548c\u5e94\u7528\u3002"}}
{"id": "2510.10207", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10207", "abs": "https://arxiv.org/abs/2510.10207", "authors": ["Yujian Zhang", "Keyu Chen", "Zhifeng Shen", "Ruizhi Qiao", "Xing Sun"], "title": "Adaptive Dual Reasoner: Large Reasoning Models Can Think Efficiently by Hybrid Reasoning", "comment": null, "summary": "Although Long Reasoning Models (LRMs) have achieved superior performance on\nvarious reasoning scenarios, they often suffer from increased computational\ncosts and inference latency caused by overthinking. To address these\nlimitations, we propose Adaptive Dual Reasoner, which supports two reasoning\nmodes: fast thinking and slow thinking. ADR dynamically alternates between\nthese modes based on the contextual complexity during reasoning. ADR is trained\nin two stages: (1) A cold-start stage using supervised fine-tuning (SFT) to\nequip the model with the ability to integrate both fast and slow reasoning\nmodes, in which we construct a hybrid reasoning dataset through a dedicated\npipeline to provide large-scale supervision. (2) A reinforcement learning stage\nfor optimizing reasoning effort, where we introduce Entropy-guided Hybrid\nPolicy Optimization EHPO, an RL training framework employing an entropy-guided\ndynamic rollout strategy for branching at high-entropy units and a\ndifficulty-aware penalty to balance fast and slow reasoning. Across challenging\nmathematical reasoning benchmarks, ADR achieves an effective balance between\nreasoning performance and efficiency among state-of-the-art approaches.\nSpecifically, ADR yields a performance gain of up to 6.1%, while reducing the\nreasoning output length by 49.5% to 59.3%.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u53cc\u63a8\u7406\u5668(ADR)\uff0c\u901a\u8fc7\u5feb\u901f\u601d\u8003\u548c\u6162\u901f\u601d\u8003\u4e24\u79cd\u63a8\u7406\u6a21\u5f0f\u7684\u52a8\u6001\u5207\u6362\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u548c\u63a8\u7406\u5ef6\u8fdf\u3002", "motivation": "\u89e3\u51b3\u957f\u63a8\u7406\u6a21\u578b(LRMs)\u56e0\u8fc7\u5ea6\u601d\u8003\u5bfc\u81f4\u7684\u8ba1\u7b97\u6210\u672c\u589e\u52a0\u548c\u63a8\u7406\u5ef6\u8fdf\u95ee\u9898\uff0c\u5728\u63a8\u7406\u6027\u80fd\u548c\u6548\u7387\u4e4b\u95f4\u5bfb\u6c42\u5e73\u8861\u3002", "method": "\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a1) \u76d1\u7763\u5fae\u8c03\u9636\u6bb5\u6784\u5efa\u6df7\u5408\u63a8\u7406\u6570\u636e\u96c6\uff1b2) \u5f3a\u5316\u5b66\u4e60\u9636\u6bb5\u5f15\u5165\u71b5\u5f15\u5bfc\u6df7\u5408\u7b56\u7565\u4f18\u5316(EHPO)\uff0c\u5728\u9ad8\u71b5\u5355\u5143\u8fdb\u884c\u5206\u652f\uff0c\u5e76\u4f7f\u7528\u96be\u5ea6\u611f\u77e5\u60e9\u7f5a\u6765\u5e73\u8861\u5feb\u901f\u548c\u6162\u901f\u63a8\u7406\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe6.1%\uff0c\u540c\u65f6\u63a8\u7406\u8f93\u51fa\u957f\u5ea6\u51cf\u5c1149.5%\u81f359.3%\u3002", "conclusion": "ADR\u5728\u63a8\u7406\u6027\u80fd\u548c\u6548\u7387\u4e4b\u95f4\u5b9e\u73b0\u4e86\u6709\u6548\u5e73\u8861\uff0c\u662f\u89e3\u51b3\u957f\u63a8\u7406\u6a21\u578b\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2510.11286", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.11286", "abs": "https://arxiv.org/abs/2510.11286", "authors": ["Jack Jackman", "David Ryan", "Arun Narayanan", "Pedro Nardelli", "Indrakshi Dey"], "title": "Edge-to-Cloud Computations-as-a-Service in Software-Defined Energy Networks for Smart Grids", "comment": null, "summary": "Modern power grids face an acute mismatch between where data is generated and\nwhere it can be processed: protection relays, EV (Electric Vehicle) charging,\nand distributed renewables demand millisecond analytics at the edge, while\nenergy-hungry workloads often sit in distant clouds leading to missed real-time\ndeadlines and wasted power. We address this by proposing, to our knowledge, the\nfirst-ever SDEN (Software Defined Energy Network) for CaaS\n(Computations-as-a-Service) that unifies edge, fog, and cloud compute with 5G\nURLLC (Ultra-Reliable Low-Latency Communications), SDN (Software Defined\nNetworking), and NFV (Network Functions Virtualization) to co-optimize energy,\nlatency, and reliability end-to-end. Our contributions are threefold: (i) a\njoint task offloading formulation that couples computation placement with\nnetwork capacity under explicit URLLC constraints; (ii) a feasibility\npreserving, lightweight greedy heuristic that scales while closely tracking\noptimal energy and latency trade-offs; and (iii) a tiered AI (Artificial\nIntelligence) pipeline-reactive at the edge, predictive in the fog, strategic\nin the cloud-featuring privacy-preserving, federated GNNs (Graph Neural\nNetworks) for fault detection and microgrid coordination. Unlike prior\nedge-only or cloud-only schemes, SDEN turns fragmented grid compute into a\nsingle, programmable substrate that delivers dependable, energy-aware, real\ntime analytics establishing a first-ever, software defined path to practical,\ngrid-scale CaaS.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u8f6f\u4ef6\u5b9a\u4e49\u80fd\u6e90\u7f51\u7edc(SDEN)\uff0c\u901a\u8fc7\u7edf\u4e00\u8fb9\u7f18\u3001\u96fe\u548c\u4e91\u8ba1\u7b97\uff0c\u7ed3\u54085G URLLC\u3001SDN\u548cNFV\u6280\u672f\uff0c\u5171\u540c\u4f18\u5316\u80fd\u6e90\u3001\u5ef6\u8fdf\u548c\u53ef\u9760\u6027\uff0c\u5c06\u788e\u7247\u5316\u7684\u7535\u7f51\u8ba1\u7b97\u8f6c\u53d8\u4e3a\u5355\u4e00\u53ef\u7f16\u7a0b\u5e73\u53f0\u3002", "motivation": "\u73b0\u4ee3\u7535\u7f51\u9762\u4e34\u6570\u636e\u751f\u6210\u4e0e\u5904\u7406\u4f4d\u7f6e\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff1a\u4fdd\u62a4\u7ee7\u7535\u5668\u3001\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u548c\u5206\u5e03\u5f0f\u53ef\u518d\u751f\u80fd\u6e90\u9700\u8981\u5728\u8fb9\u7f18\u8fdb\u884c\u6beb\u79d2\u7ea7\u5206\u6790\uff0c\u800c\u80fd\u8017\u5bc6\u96c6\u578b\u5de5\u4f5c\u8d1f\u8f7d\u901a\u5e38\u4f4d\u4e8e\u9065\u8fdc\u7684\u4e91\u7aef\uff0c\u5bfc\u81f4\u9519\u8fc7\u5b9e\u65f6\u622a\u6b62\u671f\u9650\u548c\u6d6a\u8d39\u7535\u529b\u3002", "method": "\u91c7\u7528\u8054\u5408\u4efb\u52a1\u5378\u8f7d\u516c\u5f0f\uff0c\u5728\u663e\u5f0fURLLC\u7ea6\u675f\u4e0b\u8026\u5408\u8ba1\u7b97\u653e\u7f6e\u4e0e\u7f51\u7edc\u5bb9\u91cf\uff1b\u63d0\u51fa\u8f7b\u91cf\u7ea7\u8d2a\u5fc3\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u4fdd\u6301\u53ef\u884c\u6027\u540c\u65f6\u7d27\u5bc6\u8ddf\u8e2a\u6700\u4f18\u80fd\u6e90\u548c\u5ef6\u8fdf\u6743\u8861\uff1b\u8bbe\u8ba1\u5206\u5c42AI\u7ba1\u9053\uff08\u8fb9\u7f18\u53cd\u5e94\u5f0f\u3001\u96fe\u9884\u6d4b\u5f0f\u3001\u4e91\u6218\u7565\u5f0f\uff09\uff0c\u4f7f\u7528\u9690\u79c1\u4fdd\u62a4\u7684\u8054\u90a6\u56fe\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u6545\u969c\u68c0\u6d4b\u548c\u5fae\u7535\u7f51\u534f\u8c03\u3002", "result": "SDEN\u5c06\u788e\u7247\u5316\u7684\u7535\u7f51\u8ba1\u7b97\u8f6c\u53d8\u4e3a\u5355\u4e00\u53ef\u7f16\u7a0b\u5e73\u53f0\uff0c\u63d0\u4f9b\u53ef\u9760\u3001\u80fd\u6e90\u611f\u77e5\u7684\u5b9e\u65f6\u5206\u6790\uff0c\u4e3a\u5b9e\u7528\u7684\u7535\u7f51\u7ea7\u8ba1\u7b97\u5373\u670d\u52a1\u5efa\u7acb\u4e86\u9996\u4e2a\u8f6f\u4ef6\u5b9a\u4e49\u8def\u5f84\u3002", "conclusion": "\u4e0e\u5148\u524d\u4ec5\u8fb9\u7f18\u6216\u4ec5\u4e91\u7aef\u7684\u65b9\u6848\u4e0d\u540c\uff0cSDEN\u901a\u8fc7\u7edf\u4e00\u8ba1\u7b97\u67b6\u6784\u548c\u5206\u5c42AI\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u7535\u7f51\u5b9e\u65f6\u8ba1\u7b97\u9700\u6c42\u4e0e\u8d44\u6e90\u5206\u5e03\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u7aef\u5230\u7aef\u7684\u80fd\u6e90\u3001\u5ef6\u8fdf\u548c\u53ef\u9760\u6027\u5171\u540c\u4f18\u5316\u3002"}}
{"id": "2510.10357", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10357", "abs": "https://arxiv.org/abs/2510.10357", "authors": ["Yang Liu", "Bruno Da Costa", "Aude Billard"], "title": "Learning to Throw-Flip", "comment": "Accepted to IROS 2025. Video Summary: https://youtu.be/txYc9b1oflU", "summary": "Dynamic manipulation, such as robot tossing or throwing objects, has recently\ngained attention as a novel paradigm to speed up logistic operations. However,\nthe focus has predominantly been on the object's landing location, irrespective\nof its final orientation. In this work, we present a method enabling a robot to\naccurately \"throw-flip\" objects to a desired landing pose (position and\norientation). Conventionally, objects thrown by revolute robots suffer from\nparasitic rotation, resulting in highly restricted and uncontrollable landing\nposes. Our approach is based on two key design choices: first, leveraging the\nimpulse-momentum principle, we design a family of throwing motions that\neffectively decouple the parasitic rotation, significantly expanding the\nfeasible set of landing poses. Second, we combine a physics-based model of free\nflight with regression-based learning methods to account for unmodeled effects.\nReal robot experiments demonstrate that our framework can learn to throw-flip\nobjects to a pose target within ($\\pm$5 cm, $\\pm$45 degrees) threshold in\ndozens of trials. Thanks to data assimilation, incorporating projectile\ndynamics reduces sample complexity by an average of 40% when throw-flipping to\nunseen poses compared to end-to-end learning methods. Additionally, we show\nthat past knowledge on in-hand object spinning can be effectively reused,\naccelerating learning by 70% when throwing a new object with a Center of Mass\n(CoM) shift. A video summarizing the proposed method and the hardware\nexperiments is available at https://youtu.be/txYc9b1oflU.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u673a\u5668\u4eba\"\u629b\u63b7\u7ffb\u8f6c\"\u65b9\u6cd5\uff0c\u80fd\u591f\u7cbe\u786e\u63a7\u5236\u7269\u4f53\u7684\u7740\u9646\u4f4d\u7f6e\u548c\u65b9\u5411\uff0c\u901a\u8fc7\u89e3\u8026\u5bc4\u751f\u65cb\u8f6c\u548c\u7ed3\u5408\u7269\u7406\u6a21\u578b\u4e0e\u5b66\u4e60\u65b9\u6cd5\u6765\u6269\u5c55\u53ef\u884c\u7740\u9646\u59ff\u6001\u96c6\u3002", "motivation": "\u73b0\u6709\u52a8\u6001\u64cd\u4f5c\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u7269\u4f53\u7740\u9646\u4f4d\u7f6e\uff0c\u800c\u5ffd\u7565\u4e86\u6700\u7ec8\u65b9\u5411\u63a7\u5236\u3002\u4f20\u7edf\u65cb\u8f6c\u673a\u5668\u4eba\u5728\u629b\u63b7\u7269\u4f53\u65f6\u4f1a\u4ea7\u751f\u5bc4\u751f\u65cb\u8f6c\uff0c\u5bfc\u81f4\u7740\u9646\u59ff\u6001\u53d7\u9650\u4e14\u4e0d\u53ef\u63a7\u3002", "method": "\u57fa\u4e8e\u51b2\u91cf-\u52a8\u91cf\u539f\u7406\u8bbe\u8ba1\u629b\u63b7\u8fd0\u52a8\u65cf\u6765\u89e3\u8026\u5bc4\u751f\u65cb\u8f6c\uff0c\u7ed3\u5408\u81ea\u7531\u98de\u884c\u7684\u7269\u7406\u6a21\u578b\u548c\u56de\u5f52\u5b66\u4e60\u65b9\u6cd5\u5904\u7406\u672a\u5efa\u6a21\u6548\u5e94\u3002", "result": "\u771f\u5b9e\u673a\u5668\u4eba\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u5728\u6570\u5341\u6b21\u8bd5\u9a8c\u5185\u5c06\u7269\u4f53\u629b\u63b7\u7ffb\u8f6c\u81f3(\u00b15cm, \u00b145\u5ea6)\u7cbe\u5ea6\u7684\u76ee\u6807\u59ff\u6001\u3002\u76f8\u6bd4\u7aef\u5230\u7aef\u5b66\u4e60\u65b9\u6cd5\uff0c\u7269\u7406\u52a8\u529b\u5b66\u6a21\u578b\u5c06\u6837\u672c\u590d\u6742\u5ea6\u964d\u4f4e40%\uff0c\u91cd\u7528\u65cb\u8f6c\u77e5\u8bc6\u53ef\u52a0\u901f\u5b66\u4e6070%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u5bf9\u7269\u4f53\u7740\u9646\u59ff\u6001\u7684\u7cbe\u786e\u63a7\u5236\uff0c\u901a\u8fc7\u7269\u7406\u6a21\u578b\u4e0e\u5b66\u4e60\u7684\u7ed3\u5408\u663e\u8457\u63d0\u9ad8\u4e86\u5b66\u4e60\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2510.10238", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10238", "abs": "https://arxiv.org/abs/2510.10238", "authors": ["Zixuan Qin", "Kunlin Lyu", "Qingchen Yu", "Yifan Sun", "Zhaoxin Fan"], "title": "The Achilles' Heel of LLMs: How Altering a Handful of Neurons Can Cripple Language Abilities", "comment": null, "summary": "Large Language Models (LLMs) have become foundational tools in natural\nlanguage processing, powering a wide range of applications and research. Many\nstudies have shown that LLMs share significant similarities with the human\nbrain. Recent neuroscience research has found that a small subset of biological\nneurons in the human brain are crucial for core cognitive functions, which\nraises a fundamental question: do LLMs also contain a small subset of critical\nneurons? In this paper, we investigate this question by proposing a\nPerturbation-based Causal Identification of Critical Neurons method to\nsystematically locate such critical neurons in LLMs. Our findings reveal three\nkey insights: (1) LLMs contain ultra-sparse critical neuron sets. Disrupting\nthese critical neurons can cause a 72B-parameter model with over 1.1 billion\nneurons to completely collapse, with perplexity increasing by up to 20 orders\nof magnitude; (2) These critical neurons are not uniformly distributed, but\ntend to concentrate in the outer layers, particularly within the MLP down\\_proj\ncomponents; (3) Performance degradation exhibits sharp phase transitions,\nrather than a gradual decline, when these critical neurons are disrupted.\nThrough comprehensive experiments across diverse model architectures and\nscales, we provide deeper analysis of these phenomena and their implications\nfor LLM robustness and interpretability. These findings can offer guidance for\ndeveloping more robust model architectures and improving deployment security in\nsafety-critical applications.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u5b58\u5728\u8d85\u7a00\u758f\u7684\u5173\u952e\u795e\u7ecf\u5143\u96c6\u5408\uff0c\u8fd9\u4e9b\u795e\u7ecf\u5143\u96c6\u4e2d\u5728\u6a21\u578b\u5916\u5c42\u7279\u522b\u662fMLP\u7684down_proj\u7ec4\u4ef6\u4e2d\uff0c\u7834\u574f\u8fd9\u4e9b\u795e\u7ecf\u5143\u4f1a\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u6025\u5267\u5d29\u6e83\u3002", "motivation": "\u53d7\u5230\u4eba\u7c7b\u5927\u8111\u4e2d\u5c11\u6570\u5173\u952e\u795e\u7ecf\u5143\u5bf9\u8ba4\u77e5\u529f\u80fd\u81f3\u5173\u91cd\u8981\u7684\u542f\u53d1\uff0c\u7814\u7a76LLMs\u662f\u5426\u4e5f\u5b58\u5728\u7c7b\u4f3c\u7684\u5173\u952e\u795e\u7ecf\u5143\u5b50\u96c6\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6270\u52a8\u7684\u5173\u952e\u795e\u7ecf\u5143\u56e0\u679c\u8bc6\u522b\u65b9\u6cd5\uff0c\u7cfb\u7edf\u6027\u5730\u5b9a\u4f4dLLMs\u4e2d\u7684\u5173\u952e\u795e\u7ecf\u5143\u3002", "result": "\u53d1\u73b0\uff1a(1) LLMs\u5305\u542b\u8d85\u7a00\u758f\u5173\u952e\u795e\u7ecf\u5143\uff0c\u7834\u574f\u8fd9\u4e9b\u795e\u7ecf\u5143\u4f1a\u5bfc\u81f4720\u4ebf\u53c2\u6570\u6a21\u578b\u5b8c\u5168\u5d29\u6e83\uff0c\u56f0\u60d1\u5ea6\u589e\u52a020\u4e2a\u6570\u91cf\u7ea7\uff1b(2) \u5173\u952e\u795e\u7ecf\u5143\u96c6\u4e2d\u5206\u5e03\u5728\u5916\u5c42\uff0c\u7279\u522b\u662fMLP\u7684down_proj\u7ec4\u4ef6\uff1b(3) \u6027\u80fd\u9000\u5316\u5448\u73b0\u6025\u5267\u7684\u76f8\u53d8\u800c\u975e\u6e10\u8fdb\u4e0b\u964d\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u6a21\u578b\u67b6\u6784\u548c\u63d0\u9ad8\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2510.11316", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.11316", "abs": "https://arxiv.org/abs/2510.11316", "authors": ["Kaj Munhoz Arfvidsson", "Loizos Hadjiloizou", "Frank J. Jiang", "Karl H. Johansson", "Jonas M\u00e5rtensson"], "title": "pyspect: An Extensible Toolbox for Automatic Construction of Temporal Logic Trees via Reachability Analysis", "comment": "To be published in the 64th IEEE Conference on Decision and Control", "summary": "In this paper, we present pyspect, a Python toolbox that simplifies the use\nof reachability analysis for temporal logic problems. Currently, satisfying\ncomplex requirements in cyber-physical systems requires significant manual\neffort and domain expertise to develop the underlying reachability programs.\nThis high development effort limits the broader adoption of reachability\nanalysis for complex verification problems. To address this, pyspect provides a\nmethod-agnostic approach to performing reachability analysis for verifying a\ntemporal logic specification via temporal logic trees (TLTs). It enables the\nspecification of complex safety and liveness requirements using high-level\nlogic formulations that are independent of any particular reachability\ntechnique or set representation. As a result, pyspect allows for the comparison\nof different reachability implementations, such as Hamilton-Jacobi and Hybrid\nZonotope-based reachability analysis, for the same temporal logic\nspecification. This design separates the concerns of implementation developers\n(who develop numerical procedures for reachability) and end-users (who write\nspecifications). Through a simple vehicle example, we demonstrate how pyspect\nsimplifies the synthesis of reachability programs, promotes specification\nreusability, and facilitates side-by-side comparisons of reachability\ntechniques for complex tasks.", "AI": {"tldr": "pyspect\u662f\u4e00\u4e2aPython\u5de5\u5177\u7bb1\uff0c\u901a\u8fc7\u65f6\u6001\u903b\u8f91\u6811\u7b80\u5316\u4e86\u65f6\u6001\u903b\u8f91\u95ee\u9898\u7684\u53ef\u8fbe\u6027\u5206\u6790\uff0c\u4f7f\u590d\u6742\u9700\u6c42\u9a8c\u8bc1\u66f4\u6613\u5b9e\u73b0\u3002", "motivation": "\u5f53\u524d\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\u4e2d\u6ee1\u8db3\u590d\u6742\u9700\u6c42\u9700\u8981\u5927\u91cf\u624b\u52a8\u5de5\u4f5c\u548c\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u6765\u5f00\u53d1\u53ef\u8fbe\u6027\u7a0b\u5e8f\uff0c\u8fd9\u9650\u5236\u4e86\u53ef\u8fbe\u6027\u5206\u6790\u5728\u590d\u6742\u9a8c\u8bc1\u95ee\u9898\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u3002", "method": "pyspect\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b9\u6cd5\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u65f6\u6001\u903b\u8f91\u6811\u6267\u884c\u53ef\u8fbe\u6027\u5206\u6790\u6765\u9a8c\u8bc1\u65f6\u6001\u903b\u8f91\u89c4\u8303\uff0c\u652f\u6301\u4f7f\u7528\u9ad8\u7ea7\u903b\u8f91\u516c\u5f0f\u6307\u5b9a\u590d\u6742\u7684\u5b89\u5168\u6027\u548c\u6d3b\u6027\u9700\u6c42\u3002", "result": "\u8be5\u5de5\u5177\u5141\u8bb8\u6bd4\u8f83\u4e0d\u540c\u53ef\u8fbe\u6027\u5b9e\u73b0\u65b9\u6cd5\uff0c\u5982Hamilton-Jacobi\u548c\u57fa\u4e8e\u6df7\u5408Zonotope\u7684\u53ef\u8fbe\u6027\u5206\u6790\uff0c\u5e76\u901a\u8fc7\u7b80\u5355\u8f66\u8f86\u793a\u4f8b\u5c55\u793a\u4e86\u5176\u7b80\u5316\u53ef\u8fbe\u6027\u7a0b\u5e8f\u5408\u6210\u3001\u4fc3\u8fdb\u89c4\u8303\u53ef\u91cd\u7528\u6027\u548c\u4fc3\u8fdb\u53ef\u8fbe\u6027\u6280\u672f\u5e76\u6392\u6bd4\u8f83\u7684\u80fd\u529b\u3002", "conclusion": "pyspect\u7684\u8bbe\u8ba1\u5206\u79bb\u4e86\u5b9e\u73b0\u5f00\u53d1\u8005\u548c\u6700\u7ec8\u7528\u6237\u7684\u5173\u6ce8\u70b9\uff0c\u7b80\u5316\u4e86\u590d\u6742\u4efb\u52a1\u7684\u53ef\u8fbe\u6027\u7a0b\u5e8f\u5408\u6210\uff0c\u4fc3\u8fdb\u4e86\u89c4\u8303\u7684\u53ef\u91cd\u7528\u6027\uff0c\u5e76\u4fbf\u4e8e\u4e0d\u540c\u53ef\u8fbe\u6027\u6280\u672f\u7684\u6bd4\u8f83\u3002"}}
{"id": "2510.10379", "categories": ["cs.RO", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.10379", "abs": "https://arxiv.org/abs/2510.10379", "authors": ["Rohan Gupta", "Trevor Asbery", "Zain Merchant", "Abrar Anwar", "Jesse Thomason"], "title": "RobotFleet: An Open-Source Framework for Centralized Multi-Robot Task Planning", "comment": null, "summary": "Coordinating heterogeneous robot fleets to achieve multiple goals is\nchallenging in multi-robot systems. We introduce an open-source and extensible\nframework for centralized multi-robot task planning and scheduling that\nleverages LLMs to enable fleets of heterogeneous robots to accomplish multiple\ntasks. RobotFleet provides abstractions for planning, scheduling, and execution\nacross robots deployed as containerized services to simplify fleet scaling and\nmanagement. The framework maintains a shared declarative world state and\ntwo-way communication for task execution and replanning. By modularizing each\nlayer of the autonomy stack and using LLMs for open-world reasoning, RobotFleet\nlowers the barrier to building scalable multi-robot systems. The code can be\nfound here: https://github.com/therohangupta/robot-fleet.", "AI": {"tldr": "RobotFleet\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u591a\u673a\u5668\u4eba\u4efb\u52a1\u89c4\u5212\u4e0e\u8c03\u5ea6\u6846\u67b6\uff0c\u5229\u7528LLM\u5b9e\u73b0\u5f02\u6784\u673a\u5668\u4eba\u8f66\u961f\u5b8c\u6210\u591a\u4efb\u52a1\uff0c\u901a\u8fc7\u5bb9\u5668\u5316\u90e8\u7f72\u7b80\u5316\u8f66\u961f\u6269\u5c55\u548c\u7ba1\u7406\u3002", "motivation": "\u89e3\u51b3\u5f02\u6784\u673a\u5668\u4eba\u8f66\u961f\u534f\u8c03\u5b9e\u73b0\u591a\u76ee\u6807\u7684\u6311\u6218\uff0c\u964d\u4f4e\u6784\u5efa\u53ef\u6269\u5c55\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u95e8\u69db\u3002", "method": "\u91c7\u7528\u96c6\u4e2d\u5f0f\u4efb\u52a1\u89c4\u5212\u4e0e\u8c03\u5ea6\uff0c\u5229\u7528LLM\u8fdb\u884c\u5f00\u653e\u4e16\u754c\u63a8\u7406\uff0c\u63d0\u4f9b\u89c4\u5212\u3001\u8c03\u5ea6\u548c\u6267\u884c\u62bd\u8c61\u5c42\uff0c\u7ef4\u62a4\u5171\u4eab\u58f0\u660e\u5f0f\u4e16\u754c\u72b6\u6001\u548c\u53cc\u5411\u901a\u4fe1\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u5f00\u6e90\u6846\u67b6\uff0c\u652f\u6301\u5f02\u6784\u673a\u5668\u4eba\u8f66\u961f\u7684\u591a\u4efb\u52a1\u534f\u8c03\u6267\u884c\u3002", "conclusion": "RobotFleet\u901a\u8fc7\u6a21\u5757\u5316\u81ea\u4e3b\u5806\u6808\u5404\u5c42\u548c\u4f7f\u7528LLM\u63a8\u7406\uff0c\u6709\u6548\u7b80\u5316\u4e86\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u6784\u5efa\u548c\u7ba1\u7406\u3002"}}
{"id": "2510.10285", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10285", "abs": "https://arxiv.org/abs/2510.10285", "authors": ["Haolang Lu", "Bolun Chu", "WeiYe Fu", "Guoshun Nan", "Junning Liu", "Minghui Pan", "Qiankun Li", "Yi Yu", "Hua Wang", "Kun Wang"], "title": "Mitigating Hallucination in Multimodal Reasoning via Functional Attention Control", "comment": "preprint", "summary": "Multimodal large reasoning models (MLRMs) are rapidly advancing\nvision-language reasoning and are emerging as a foundation for cross-modal\nintelligence. Hallucination remains a persistent failure mode, manifesting\nitself as erroneous reasoning chains and misinterpretation of visual content.\nIn this study, we observe that attention heads exhibit a staged division:\nshallow heads predominantly serve perception, while deeper heads shift toward\nsymbolic reasoning, revealing two major causes of hallucination, namely\nperceptual bias and reasoning drift. To address these issues, we propose a\nlightweight and interpretable two-step plugin, Functional Head Identification\nand Class-conditioned Rescaling, which locates perception- and\nreasoning-oriented heads and regulates their contributions without retraining.\nEvaluations on three real-world MLRMs (Kimi-VL, Ocean-R1, R1-Onevision), six\nbenchmarks across three domains, and four baselines show that our plugin\nachieves an average improvement of 5% and up to 15%, with only <1% additional\ncomputation and 9% of baseline latency. Our approach is completely\nmodel-agnostic and significantly enhances both the reliability and\ninterpretability of the off-the-shelf MLRMs, thereby enabling their safe\ndeployment in high-stakes applications. Our code is available at\nhttps://anonymous.4open.science/r/Functional-Attention-Control.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u63d2\u4ef6\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u611f\u77e5\u548c\u63a8\u7406\u5bfc\u5411\u7684\u6ce8\u610f\u529b\u5934\u5e76\u8fdb\u884c\u6761\u4ef6\u7f29\u653e\uff0c\u6709\u6548\u51cf\u5c11\u591a\u6a21\u6001\u5927\u63a8\u7406\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u63d0\u5347\u6a21\u578b\u53ef\u9760\u6027\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u63a8\u7406\u6a21\u578b\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\uff0c\u8868\u73b0\u4e3a\u9519\u8bef\u63a8\u7406\u94fe\u548c\u89c6\u89c9\u5185\u5bb9\u8bef\u89e3\u3002\u7814\u7a76\u53d1\u73b0\u6ce8\u610f\u529b\u5934\u5b58\u5728\u9636\u6bb5\u6027\u5206\u5de5\uff1a\u6d45\u5c42\u5934\u4e3b\u8981\u8d1f\u8d23\u611f\u77e5\uff0c\u6df1\u5c42\u5934\u8f6c\u5411\u7b26\u53f7\u63a8\u7406\uff0c\u8fd9\u63ed\u793a\u4e86\u5e7b\u89c9\u7684\u4e24\u4e2a\u4e3b\u8981\u539f\u56e0\u2014\u2014\u611f\u77e5\u504f\u5dee\u548c\u63a8\u7406\u6f02\u79fb\u3002", "method": "\u63d0\u51fa\u4e24\u6b65\u63d2\u4ef6\u65b9\u6cd5\uff1a\u529f\u80fd\u5934\u8bc6\u522b\u548c\u7c7b\u6761\u4ef6\u91cd\u7f29\u653e\u3002\u9996\u5148\u5b9a\u4f4d\u611f\u77e5\u5bfc\u5411\u548c\u63a8\u7406\u5bfc\u5411\u7684\u6ce8\u610f\u529b\u5934\uff0c\u7136\u540e\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u8c03\u8282\u5b83\u4eec\u7684\u8d21\u732e\u5ea6\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754cMLRM\u6a21\u578b\u3001\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u56db\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5e73\u5747\u63d0\u53475%\uff0c\u6700\u9ad8\u63d0\u534715%\uff0c\u4ec5\u589e\u52a0<1%\u7684\u8ba1\u7b97\u5f00\u9500\u548c9%\u7684\u57fa\u7ebf\u5ef6\u8fdf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b8c\u5168\u6a21\u578b\u65e0\u5173\uff0c\u663e\u8457\u63d0\u5347\u4e86\u73b0\u6210MLRM\u6a21\u578b\u7684\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4f7f\u5176\u80fd\u591f\u5b89\u5168\u90e8\u7f72\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u3002"}}
{"id": "2510.11331", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.11331", "abs": "https://arxiv.org/abs/2510.11331", "authors": ["Bingjie Zhu", "Zhixiong Chen", "Liqiang Zhao", "Hyundong Shin", "Arumugam Nallanathan"], "title": "Efficient LLM Inference over Heterogeneous Edge Networks with Speculative Decoding", "comment": null, "summary": "Large language model (LLM) inference at the network edge is a promising\nserving paradigm that leverages distributed edge resources to run inference\nnear users and enhance privacy. Existing edge-based LLM inference systems\ntypically adopt autoregressive decoding (AD), which only generates one token\nper forward pass. This iterative process, compounded by the limited\ncomputational resources of edge nodes, results in high serving latency and\nconstrains the system's ability to support multiple users under growing\ndemands.To address these challenges, we propose a speculative decoding\n(SD)-based LLM serving framework that deploys small and large models across\nheterogeneous edge nodes to collaboratively deliver inference services.\nSpecifically, the small model rapidly generates draft tokens that the large\nmodel verifies in parallel, enabling multi-token generation per forward pass\nand thus reducing serving latency. To improve resource utilization of edge\nnodes, we incorporate pipeline parallelism to overlap drafting and verification\nacross multiple inference tasks. Based on this framework, we analyze and derive\na comprehensive latency model incorporating both communication and inference\nlatency. Then, we formulate a joint optimization problem for speculation\nlength, task batching, and wireless communication resource allocation to\nminimize total serving latency. To address this problem, we derive the\nclosed-form solutions for wireless communication resource allocation, and\ndevelop a dynamic programming algorithm for joint batching and speculation\ncontrol strategies. Experimental results demonstrate that the proposed\nframework achieves lower serving latency compared to AD-based serving systems.\nIn addition,the proposed joint optimization method delivers up to 44.9% latency\nreduction compared to benchmark schemes.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u63a8\u6d4b\u89e3\u7801\u7684LLM\u8fb9\u7f18\u670d\u52a1\u6846\u67b6\uff0c\u901a\u8fc7\u5c0f\u6a21\u578b\u548c\u5927\u6a21\u578b\u534f\u4f5c\u751f\u6210\u591atoken\uff0c\u7ed3\u5408\u6d41\u6c34\u7ebf\u5e76\u884c\u548c\u8054\u5408\u4f18\u5316\uff0c\u663e\u8457\u964d\u4f4e\u670d\u52a1\u5ef6\u8fdf", "motivation": "\u73b0\u6709\u57fa\u4e8e\u81ea\u56de\u5f52\u89e3\u7801\u7684\u8fb9\u7f18LLM\u63a8\u7406\u7cfb\u7edf\u6bcf\u6b21\u53ea\u80fd\u751f\u6210\u4e00\u4e2atoken\uff0c\u5728\u8fb9\u7f18\u8282\u70b9\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u5bfc\u81f4\u9ad8\u5ef6\u8fdf\uff0c\u96be\u4ee5\u652f\u6301\u591a\u7528\u6237\u9700\u6c42", "method": "\u91c7\u7528\u63a8\u6d4b\u89e3\u7801\u6846\u67b6\uff0c\u5728\u5f02\u6784\u8fb9\u7f18\u8282\u70b9\u90e8\u7f72\u5c0f\u6a21\u578b\u548c\u5927\u6a21\u578b\u534f\u4f5c\uff1a\u5c0f\u6a21\u578b\u5feb\u901f\u751f\u6210\u8349\u7a3ftoken\uff0c\u5927\u6a21\u578b\u5e76\u884c\u9a8c\u8bc1\uff1b\u7ed3\u5408\u6d41\u6c34\u7ebf\u5e76\u884c\u91cd\u53e0\u591a\u4e2a\u63a8\u7406\u4efb\u52a1\u7684\u8349\u7a3f\u548c\u9a8c\u8bc1\u9636\u6bb5\uff1b\u5efa\u7acb\u5305\u542b\u901a\u4fe1\u548c\u63a8\u7406\u5ef6\u8fdf\u7684\u7efc\u5408\u5ef6\u8fdf\u6a21\u578b\uff1b\u8054\u5408\u4f18\u5316\u63a8\u6d4b\u957f\u5ea6\u3001\u4efb\u52a1\u6279\u5904\u7406\u548c\u65e0\u7ebf\u901a\u4fe1\u8d44\u6e90\u5206\u914d", "result": "\u76f8\u6bd4\u57fa\u4e8e\u81ea\u56de\u5f52\u89e3\u7801\u7684\u670d\u52a1\u7cfb\u7edf\uff0c\u6240\u63d0\u6846\u67b6\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u670d\u52a1\u5ef6\u8fdf\uff1b\u63d0\u51fa\u7684\u8054\u5408\u4f18\u5316\u65b9\u6cd5\u76f8\u6bd4\u57fa\u51c6\u65b9\u6848\u53ef\u964d\u4f4e\u9ad8\u8fbe44.9%\u7684\u5ef6\u8fdf", "conclusion": "\u57fa\u4e8e\u63a8\u6d4b\u89e3\u7801\u7684\u8fb9\u7f18LLM\u670d\u52a1\u6846\u67b6\u80fd\u6709\u6548\u964d\u4f4e\u5ef6\u8fdf\uff0c\u901a\u8fc7\u5c0f\u5927\u6a21\u578b\u534f\u4f5c\u548c\u8054\u5408\u4f18\u5316\u7b56\u7565\u663e\u8457\u63d0\u5347\u8fb9\u7f18\u63a8\u7406\u6027\u80fd"}}
{"id": "2510.10392", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.10392", "abs": "https://arxiv.org/abs/2510.10392", "authors": ["Max Sokolich", "Yanda Yang", "Subrahmanyam Cherukumilli", "Fatma Ceren Kirmizitas", "Sambeeta Das"], "title": "MicroRoboScope: A Portable and Integrated Mechatronic Platform for Magnetic and Acoustic Microrobotic Experimentation", "comment": null, "summary": "This paper presents MicroRoboScope, a portable, compact, and versatile\nmicrorobotic experimentation platform designed for real-time, closed-loop\ncontrol of both magnetic and acoustic microrobots. The system integrates an\nembedded computer, microscope, power supplies, and control circuitry into a\nsingle, low-cost and fully integrated apparatus. Custom control software\ndeveloped in Python and Arduino C++ handles live video acquisition, microrobot\ntracking, and generation of control signals for electromagnetic coils and\nacoustic transducers. The platform's multi-modal actuation, accessibility, and\nportability make it suitable not only for specialized research laboratories but\nalso for educational and outreach settings. By lowering the barrier to entry\nfor microrobotic experimentation, this system enables new opportunities for\nresearch, education, and translational applications in biomedicine, tissue\nengineering, and robotics.", "AI": {"tldr": "MicroRoboScope\u662f\u4e00\u4e2a\u4fbf\u643a\u5f0f\u3001\u7d27\u51d1\u7684\u591a\u529f\u80fd\u5fae\u673a\u5668\u4eba\u5b9e\u9a8c\u5e73\u53f0\uff0c\u80fd\u591f\u5b9e\u65f6\u95ed\u73af\u63a7\u5236\u78c1\u6027\u548c\u58f0\u5b66\u5fae\u673a\u5668\u4eba\uff0c\u96c6\u6210\u4e86\u5d4c\u5165\u5f0f\u8ba1\u7b97\u673a\u3001\u663e\u5fae\u955c\u3001\u7535\u6e90\u548c\u63a7\u5236\u7535\u8def\uff0c\u6210\u672c\u4f4e\u5ec9\u4e14\u5b8c\u5168\u96c6\u6210\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u4f4e\u6210\u672c\u3001\u4fbf\u643a\u4e14\u6613\u4e8e\u4f7f\u7528\u7684\u5fae\u673a\u5668\u4eba\u5b9e\u9a8c\u5e73\u53f0\uff0c\u964d\u4f4e\u5fae\u673a\u5668\u4eba\u5b9e\u9a8c\u7684\u95e8\u69db\uff0c\u4f7f\u5176\u4e0d\u4ec5\u9002\u7528\u4e8e\u4e13\u4e1a\u7814\u7a76\u5b9e\u9a8c\u5ba4\uff0c\u4e5f\u9002\u5408\u6559\u80b2\u548c\u63a8\u5e7f\u73af\u5883\u3002", "method": "\u7cfb\u7edf\u96c6\u6210\u4e86\u5d4c\u5165\u5f0f\u8ba1\u7b97\u673a\u3001\u663e\u5fae\u955c\u3001\u7535\u6e90\u548c\u63a7\u5236\u7535\u8def\uff0c\u4f7f\u7528Python\u548cArduino C++\u5f00\u53d1\u5b9a\u5236\u63a7\u5236\u8f6f\u4ef6\uff0c\u5904\u7406\u5b9e\u65f6\u89c6\u9891\u91c7\u96c6\u3001\u5fae\u673a\u5668\u4eba\u8ddf\u8e2a\u4ee5\u53ca\u7535\u78c1\u7ebf\u5708\u548c\u58f0\u5b66\u6362\u80fd\u5668\u7684\u63a7\u5236\u4fe1\u53f7\u751f\u6210\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u591a\u6a21\u6001\u9a71\u52a8\u3001\u6613\u4e8e\u8bbf\u95ee\u4e14\u4fbf\u643a\u7684\u5e73\u53f0\uff0c\u9002\u7528\u4e8e\u751f\u7269\u533b\u5b66\u3001\u7ec4\u7ec7\u5de5\u7a0b\u548c\u673a\u5668\u4eba\u5b66\u7684\u7814\u7a76\u3001\u6559\u80b2\u548c\u8f6c\u5316\u5e94\u7528\u3002", "conclusion": "MicroRoboScope\u901a\u8fc7\u964d\u4f4e\u5fae\u673a\u5668\u4eba\u5b9e\u9a8c\u7684\u5165\u95e8\u95e8\u69db\uff0c\u4e3a\u751f\u7269\u533b\u5b66\u3001\u7ec4\u7ec7\u5de5\u7a0b\u548c\u673a\u5668\u4eba\u5b66\u9886\u57df\u7684\u7814\u7a76\u3001\u6559\u80b2\u548c\u8f6c\u5316\u5e94\u7528\u5f00\u8f9f\u4e86\u65b0\u7684\u673a\u4f1a\u3002"}}
{"id": "2510.10331", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10331", "abs": "https://arxiv.org/abs/2510.10331", "authors": ["Hanchen Su", "Wei Luo", "Wei Han", "Yu Elaine Liu", "Yufeng Wayne Zhang", "Cen Mia Zhao", "Ying Joy Zhang", "Yashar Mehdad"], "title": "LLM-Friendly Knowledge Representation for Customer Support", "comment": null, "summary": "We propose a practical approach by integrating Large Language Models (LLMs)\nwith a framework designed to navigate the complexities of Airbnb customer\nsupport operations. In this paper, our methodology employs a novel reformatting\ntechnique, the Intent, Context, and Action (ICA) format, which transforms\npolicies and workflows into a structure more comprehensible to LLMs.\nAdditionally, we develop a synthetic data generation strategy to create\ntraining data with minimal human intervention, enabling cost-effective\nfine-tuning of our model. Our internal experiments (not applied to Airbnb\nproducts) demonstrate that our approach of restructuring workflows and\nfine-tuning LLMs with synthetic data significantly enhances their performance,\nsetting a new benchmark for their application in customer support. Our solution\nis not only cost-effective but also improves customer support, as evidenced by\nboth accuracy and manual processing time evaluation metrics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0eAirbnb\u5ba2\u670d\u64cd\u4f5c\u6846\u67b6\u7ed3\u5408\u7684\u5b9e\u7528\u65b9\u6cd5\uff0c\u901a\u8fc7ICA\u683c\u5f0f\u91cd\u6784\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5e76\u4f7f\u7528\u5408\u6210\u6570\u636e\u5fae\u8c03\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5ba2\u670d\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3Airbnb\u5ba2\u670d\u64cd\u4f5c\u590d\u6742\u6027\uff0c\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5ba2\u670d\u652f\u6301\u4e2d\u7684\u7406\u89e3\u548c\u6267\u884c\u80fd\u529b\u3002", "method": "\u91c7\u7528\u610f\u56fe\u3001\u4e0a\u4e0b\u6587\u548c\u884c\u52a8(ICA)\u683c\u5f0f\u91cd\u6784\u7b56\u7565\u548c\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5f00\u53d1\u5408\u6210\u6570\u636e\u751f\u6210\u7b56\u7565\u8fdb\u884c\u4f4e\u6210\u672c\u6a21\u578b\u5fae\u8c03\u3002", "result": "\u5185\u90e8\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u5728\u51c6\u786e\u6027\u548c\u5904\u7406\u65f6\u95f4\u8bc4\u4f30\u6307\u6807\u4e0a\u90fd\u6709\u6539\u5584\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5ba2\u670d\u652f\u6301\u5e94\u7528\u8bbe\u5b9a\u4e86\u65b0\u57fa\u51c6\uff0c\u65e2\u7ecf\u6d4e\u9ad8\u6548\u53c8\u63d0\u5347\u4e86\u5ba2\u670d\u8d28\u91cf\u3002"}}
{"id": "2510.11386", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.11386", "abs": "https://arxiv.org/abs/2510.11386", "authors": ["Yuechen Liu", "Boqi Meng"], "title": "High-Order Quarter-Wave Plate Optimization for Linear Birefringence Suppression in Reflective FOCS", "comment": null, "summary": "Fiber optic current sensors (FOCS) are widely adopted in modern power grids\ndue to high sensitivity, excellent insulation, and strong immunity to\nelectromagnetic interference. This prominence necessitates precise\ninvestigation into their error sources and corresponding optimization. This\nstudy examines reflective FOCS based on the Faraday effect. A theoretical model\nis established to simulate phase error caused by linear birefringence from the\nquarter-wave plate. Conventional methods using circular birefringence are\nanalyzed, revealing inherent limitations. Innovatively, a compensation strategy\nemploying high-order quarter-wave plates is proposed to effectively eliminate\nlinear birefringence effects. This approach significantly enhances the accuracy\nand practicality of FOCS in precision metrology.", "AI": {"tldr": "\u7814\u7a76\u53cd\u5c04\u5f0f\u5149\u7ea4\u7535\u6d41\u4f20\u611f\u5668\uff0c\u5206\u6790\u7ebf\u6027\u53cc\u6298\u5c04\u5f15\u8d77\u7684\u76f8\u4f4d\u8bef\u5dee\uff0c\u63d0\u51fa\u4f7f\u7528\u9ad8\u9636\u56db\u5206\u4e4b\u4e00\u6ce2\u7247\u8865\u507f\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4f20\u611f\u5668\u7cbe\u5ea6", "motivation": "\u5149\u7ea4\u7535\u6d41\u4f20\u611f\u5668\u5728\u73b0\u4ee3\u7535\u7f51\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u7cbe\u786e\u7814\u7a76\u5176\u8bef\u5dee\u6765\u6e90\u548c\u4f18\u5316\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u7ebf\u6027\u53cc\u6298\u5c04\u5f15\u8d77\u7684\u76f8\u4f4d\u8bef\u5dee\u95ee\u9898", "method": "\u5efa\u7acb\u7406\u8bba\u6a21\u578b\u6a21\u62df\u56db\u5206\u4e4b\u4e00\u6ce2\u677f\u5f15\u8d77\u7684\u7ebf\u6027\u53cc\u6298\u5c04\u76f8\u4f4d\u8bef\u5dee\uff0c\u5206\u6790\u4f20\u7edf\u5706\u53cc\u6298\u5c04\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u521b\u65b0\u6027\u5730\u63d0\u51fa\u4f7f\u7528\u9ad8\u9636\u56db\u5206\u4e4b\u4e00\u6ce2\u7247\u7684\u8865\u507f\u7b56\u7565", "result": "\u63d0\u51fa\u7684\u9ad8\u9636\u56db\u5206\u4e4b\u4e00\u6ce2\u7247\u8865\u507f\u65b9\u6cd5\u80fd\u6709\u6548\u6d88\u9664\u7ebf\u6027\u53cc\u6298\u5c04\u6548\u5e94\uff0c\u663e\u8457\u63d0\u9ad8\u5149\u7ea4\u7535\u6d41\u4f20\u611f\u5668\u7684\u7cbe\u5ea6\u548c\u5b9e\u7528\u6027", "conclusion": "\u901a\u8fc7\u9ad8\u9636\u56db\u5206\u4e4b\u4e00\u6ce2\u7247\u8865\u507f\u7b56\u7565\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5149\u7ea4\u7535\u6d41\u4f20\u611f\u5668\u4e2d\u7684\u7ebf\u6027\u53cc\u6298\u5c04\u95ee\u9898\uff0c\u4e3a\u7cbe\u5bc6\u8ba1\u91cf\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2510.10421", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10421", "abs": "https://arxiv.org/abs/2510.10421", "authors": ["Junbin Yuan", "Brady Moon", "Muqing Cao", "Sebastian Scherer"], "title": "Hierarchical Planning for Long-Horizon Multi-Target Tracking Under Target Motion Uncertainty", "comment": "8 pages, 7 figures. Accepted to IEEE Robotics and Automation Letters\n  (RAL), 2025", "summary": "Achieving persistent tracking of multiple dynamic targets over a large\nspatial area poses significant challenges for a single-robot system with\nconstrained sensing capabilities. As the robot moves to track different\ntargets, the ones outside the field of view accumulate uncertainty, making them\nprogressively harder to track. An effective path planning algorithm must manage\nuncertainty over a long horizon and account for the risk of permanently losing\ntrack of targets that remain unseen for too long. However, most existing\napproaches rely on short planning horizons and assume small, bounded\nenvironments, resulting in poor tracking performance and target loss in\nlarge-scale scenarios. In this paper, we present a hierarchical planner for\ntracking multiple moving targets with an aerial vehicle. To address the\nchallenge of tracking non-static targets, our method incorporates motion models\nand uncertainty propagation during path execution, allowing for more informed\ndecision-making. We decompose the multi-target tracking task into sub-tasks of\nsingle target search and detection, and our proposed pipeline consists a novel\nlow-level coverage planner that enables searching for a target in an evolving\nbelief area, and an estimation method to assess the likelihood of success for\neach sub-task, making it possible to convert the active target tracking task to\na Markov decision process (MDP) that we solve with a tree-based algorithm to\ndetermine the sequence of sub-tasks. We validate our approach in simulation,\ndemonstrating its effectiveness compared to existing planners for active target\ntracking tasks, and our proposed planner outperforms existing approaches,\nachieving a reduction of 11-70% in final uncertainty across different\nenvironments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u65e0\u4eba\u673a\u591a\u76ee\u6807\u8ddf\u8e2a\u7684\u5206\u5c42\u89c4\u5212\u5668\uff0c\u901a\u8fc7\u5c06\u4efb\u52a1\u5206\u89e3\u4e3a\u5355\u76ee\u6807\u641c\u7d22\u5b50\u4efb\u52a1\uff0c\u7ed3\u5408\u8fd0\u52a8\u6a21\u578b\u548c\u4e0d\u786e\u5b9a\u6027\u4f20\u64ad\uff0c\u5728\u6a21\u62df\u4e2d\u6bd4\u73b0\u6709\u65b9\u6cd5\u51cf\u5c1111-70%\u7684\u6700\u7ec8\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u5355\u673a\u5668\u4eba\u7cfb\u7edf\u5728\u5e7f\u9614\u7a7a\u95f4\u8ddf\u8e2a\u591a\u4e2a\u52a8\u6001\u76ee\u6807\u65f6\u9762\u4e34\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u89c4\u5212\u89c6\u91ce\u77ed\u4e14\u5047\u8bbe\u5c0f\u8303\u56f4\u73af\u5883\uff0c\u5bfc\u81f4\u8ddf\u8e2a\u6027\u80fd\u5dee\u548c\u76ee\u6807\u4e22\u5931\u95ee\u9898\u3002", "method": "\u5206\u5c42\u89c4\u5212\u65b9\u6cd5\uff1a\u4f4e\u5c42\u8986\u76d6\u89c4\u5212\u5668\u5728\u52a8\u6001\u4fe1\u5ff5\u533a\u57df\u641c\u7d22\u76ee\u6807\uff0c\u4f30\u8ba1\u5b50\u4efb\u52a1\u6210\u529f\u6982\u7387\uff0c\u5c06\u4e3b\u52a8\u76ee\u6807\u8ddf\u8e2a\u8f6c\u5316\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f7f\u7528\u57fa\u4e8e\u6811\u7684\u7b97\u6cd5\u786e\u5b9a\u5b50\u4efb\u52a1\u5e8f\u5217\u3002", "result": "\u5728\u6a21\u62df\u9a8c\u8bc1\u4e2d\uff0c\u63d0\u51fa\u7684\u89c4\u5212\u5668\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u4e0d\u540c\u73af\u5883\u4e2d\u5b9e\u73b0\u6700\u7ec8\u4e0d\u786e\u5b9a\u6027\u51cf\u5c1111-70%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5206\u5c42\u89c4\u5212\u548c\u4e0d\u786e\u5b9a\u6027\u7ba1\u7406\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u573a\u666f\u4e0b\u591a\u52a8\u6001\u76ee\u6807\u8ddf\u8e2a\u7684\u6311\u6218\u3002"}}
{"id": "2510.11388", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.11388", "abs": "https://arxiv.org/abs/2510.11388", "authors": ["Sheng-Wen Cheng", "Teng-Hu Cheng"], "title": "Data-Driven Estimation of Quadrotor Motor Efficiency via Residual Minimization", "comment": null, "summary": "A data-driven framework is proposed for online estimation of quadrotor motor\nefficiency via residual minimization. The problem is formulated as a\nconstrained nonlinear optimization that minimizes trajectory residuals between\nmeasured flight data and predictions generated by a quadrotor dynamics model. A\nsliding-window strategy enables online estimation, and the optimization is\nefficiently solved using an iteratively reweighted least squares (IRLS) scheme\ncombined with a primal-dual interior-point method, with inequality constraints\nenforced through a logarithmic barrier function. Robust z-score weighting is\nemployed to reject outliers, which is particularly effective in motor clipping\nscenarios where the proposed estimator exhibits smaller spikes than an EKF\nbaseline. Compared to traditional filter-based approaches, the batch-mode\nformulation offers greater flexibility by selectively incorporating informative\ndata segments. This structure is well-suited for onboard implementation,\nparticularly for applications such as fault detection and isolation (FDI),\nhealth monitoring, and predictive maintenance in aerial robotic systems.\nSimulation results under various degradation scenarios demonstrate the accuracy\nand robustness of the proposed estimator.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6b8b\u5dee\u6700\u5c0f\u5316\u7684\u6570\u636e\u9a71\u52a8\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u7ebf\u4f30\u8ba1\u56db\u65cb\u7ffc\u7535\u673a\u6548\u7387\uff0c\u91c7\u7528\u6ed1\u52a8\u7a97\u53e3\u7b56\u7565\u548cIRLS\u4f18\u5316\u65b9\u6cd5\uff0c\u5728\u7535\u673a\u6545\u969c\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u4e8eEKF\u57fa\u7ebf\u3002", "motivation": "\u4f20\u7edf\u6ee4\u6ce2\u5668\u65b9\u6cd5\u5728\u7535\u673a\u6548\u7387\u4f30\u8ba1\u65b9\u9762\u7075\u6d3b\u6027\u4e0d\u8db3\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9009\u62e9\u6027\u5229\u7528\u4fe1\u606f\u6570\u636e\u6bb5\u3001\u9002\u5408\u673a\u8f7d\u5b9e\u73b0\u7684\u65b9\u6cd5\uff0c\u4ee5\u652f\u6301\u6545\u969c\u68c0\u6d4b\u3001\u5065\u5eb7\u76d1\u6d4b\u7b49\u5e94\u7528\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u7ea6\u675f\u975e\u7ebf\u6027\u4f18\u5316\uff0c\u6700\u5c0f\u5316\u5b9e\u6d4b\u98de\u884c\u6570\u636e\u4e0e\u56db\u65cb\u7ffc\u52a8\u529b\u5b66\u6a21\u578b\u9884\u6d4b\u4e4b\u95f4\u7684\u8f68\u8ff9\u6b8b\u5dee\uff0c\u91c7\u7528\u6ed1\u52a8\u7a97\u53e3\u7b56\u7565\u5b9e\u73b0\u5728\u7ebf\u4f30\u8ba1\uff0c\u7ed3\u5408IRLS\u548c\u539f\u59cb-\u5bf9\u5076\u5185\u70b9\u6cd5\u9ad8\u6548\u6c42\u89e3\uff0c\u4f7f\u7528\u5bf9\u6570\u969c\u788d\u51fd\u6570\u5904\u7406\u4e0d\u7b49\u5f0f\u7ea6\u675f\uff0c\u5e76\u91c7\u7528\u7a33\u5065z-score\u52a0\u6743\u6291\u5236\u5f02\u5e38\u503c\u3002", "result": "\u5728\u5404\u79cd\u9000\u5316\u573a\u666f\u4e0b\u7684\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u4f30\u8ba1\u5668\u5177\u6709\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5728\u7535\u673a\u524a\u6ce2\u573a\u666f\u4e2d\u6bd4EKF\u57fa\u7ebf\u8868\u73b0\u51fa\u66f4\u5c0f\u7684\u5c16\u5cf0\u3002", "conclusion": "\u8be5\u6279\u5904\u7406\u6a21\u5f0f\u6846\u67b6\u6bd4\u4f20\u7edf\u6ee4\u6ce2\u5668\u65b9\u6cd5\u66f4\u7075\u6d3b\uff0c\u9002\u5408\u673a\u8f7d\u5b9e\u73b0\uff0c\u7279\u522b\u9002\u7528\u4e8e\u822a\u7a7a\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u6545\u969c\u68c0\u6d4b\u4e0e\u9694\u79bb\u3001\u5065\u5eb7\u76d1\u6d4b\u548c\u9884\u6d4b\u6027\u7ef4\u62a4\u5e94\u7528\u3002"}}
{"id": "2510.10455", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.10455", "abs": "https://arxiv.org/abs/2510.10455", "authors": ["Jiayu Ding", "Xulin Chen", "Garrett E. Katz", "Zhenyu Gan"], "title": "Towards Dynamic Quadrupedal Gaits: A Symmetry-Guided RL Hierarchy Enables Free Gait Transitions at Varying Speeds", "comment": null, "summary": "Quadrupedal robots exhibit a wide range of viable gaits, but generating\nspecific footfall sequences often requires laborious expert tuning of numerous\nvariables, such as touch-down and lift-off events and holonomic constraints for\neach leg. This paper presents a unified reinforcement learning framework for\ngenerating versatile quadrupedal gaits by leveraging the intrinsic symmetries\nand velocity-period relationship of dynamic legged systems. We propose a\nsymmetry-guided reward function design that incorporates temporal,\nmorphological, and time-reversal symmetries. By focusing on preserved\nsymmetries and natural dynamics, our approach eliminates the need for\npredefined trajectories, enabling smooth transitions between diverse locomotion\npatterns such as trotting, bounding, half-bounding, and galloping. Implemented\non the Unitree Go2 robot, our method demonstrates robust performance across a\nrange of speeds in both simulations and hardware tests, significantly improving\ngait adaptability without extensive reward tuning or explicit foot placement\ncontrol. This work provides insights into dynamic locomotion strategies and\nunderscores the crucial role of symmetries in robotic gait design.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5bf9\u79f0\u6027\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u81ea\u52a8\u751f\u6210\u56db\u8db3\u673a\u5668\u4eba\u591a\u79cd\u6b65\u6001\uff0c\u65e0\u9700\u4eba\u5de5\u8c03\u6574\u8db3\u90e8\u8f68\u8ff9\u6216\u7ea6\u675f\u6761\u4ef6\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u4e13\u5bb6\u624b\u52a8\u8c03\u6574\u5927\u91cf\u53d8\u91cf\uff08\u5982\u89e6\u5730/\u62ac\u817f\u65f6\u673a\u3001\u817f\u90e8\u7ea6\u675f\uff09\uff0c\u8fc7\u7a0b\u7e41\u7410\u4e14\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u5229\u7528\u52a8\u6001\u817f\u5f0f\u7cfb\u7edf\u7684\u5185\u5728\u5bf9\u79f0\u6027\u548c\u901f\u5ea6-\u5468\u671f\u5173\u7cfb\uff0c\u8bbe\u8ba1\u5bf9\u79f0\u6027\u5f15\u5bfc\u7684\u5956\u52b1\u51fd\u6570\uff0c\u5305\u542b\u65f6\u95f4\u3001\u5f62\u6001\u548c\u65f6\u95f4\u53cd\u8f6c\u5bf9\u79f0\u6027\u3002", "result": "\u5728Unitree Go2\u673a\u5668\u4eba\u4e0a\u5b9e\u73b0\uff0c\u5728\u4eff\u771f\u548c\u786c\u4ef6\u6d4b\u8bd5\u4e2d\u5747\u8868\u73b0\u51fa\u9c81\u68d2\u6027\u80fd\uff0c\u80fd\u5e73\u6ed1\u5207\u6362\u5c0f\u8dd1\u3001\u8df3\u8dc3\u3001\u534a\u8df3\u8dc3\u548c\u75be\u8dd1\u7b49\u591a\u79cd\u6b65\u6001\u3002", "conclusion": "\u5bf9\u79f0\u6027\u5728\u673a\u5668\u4eba\u6b65\u6001\u8bbe\u8ba1\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6b65\u6001\u9002\u5e94\u6027\uff0c\u65e0\u9700\u5927\u91cf\u5956\u52b1\u8c03\u6574\u6216\u663e\u5f0f\u8db3\u90e8\u63a7\u5236\u3002"}}
{"id": "2510.10409", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10409", "abs": "https://arxiv.org/abs/2510.10409", "authors": ["Siddartha Devic", "Charlotte Peale", "Arwen Bradley", "Sinead Williamson", "Preetum Nakkiran", "Aravind Gollakota"], "title": "Trace Length is a Simple Uncertainty Signal in Reasoning Models", "comment": null, "summary": "Uncertainty quantification for LLMs is a key research direction towards\naddressing hallucination and other issues that limit their reliable deployment.\nIn this work, we show that reasoning trace length is a simple and useful\nconfidence estimator in large reasoning models. Through comprehensive\nexperiments across multiple models, datasets, and prompts, we show that trace\nlength performs in comparable but complementary ways to other zero-shot\nconfidence estimators such as verbalized confidence. Our work reveals that\nreasoning post-training fundamentally alters the relationship between trace\nlength and accuracy, going beyond prior work that had shown that post-training\ncauses traces to grow longer in general (e.g., \"overthinking\"). We investigate\nthe mechanisms behind trace length's performance as a confidence signal,\nobserving that the effect remains even after adjusting for confounders such as\nproblem difficulty and GRPO-induced length bias. We identify high-entropy or\n\"forking\" tokens as playing a key role in the mechanism. Our findings\ndemonstrate that reasoning post-training enhances uncertainty quantification\nbeyond verbal expressions, and establish trace length as a practical confidence\nmeasure for large reasoning models.", "AI": {"tldr": "\u63a8\u7406\u8f68\u8ff9\u957f\u5ea6\u53ef\u4f5c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u7b80\u5355\u6709\u6548\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u5668\uff0c\u4e0e\u53e3\u5934\u7f6e\u4fe1\u5ea6\u7b49\u65b9\u6cd5\u8868\u73b0\u76f8\u5f53\u4f46\u4e92\u8865\u3002", "motivation": "\u89e3\u51b3LLM\u5e7b\u89c9\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u90e8\u7f72\u53ef\u9760\u6027\uff0c\u9700\u8981\u6709\u6548\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u591a\u6a21\u578b\u3001\u6570\u636e\u96c6\u548c\u63d0\u793a\u7684\u7efc\u5408\u5b9e\u9a8c\uff0c\u5206\u6790\u63a8\u7406\u8f68\u8ff9\u957f\u5ea6\u4e0e\u51c6\u786e\u7387\u7684\u5173\u7cfb\uff0c\u5e76\u7814\u7a76\u5176\u673a\u5236\u3002", "result": "\u63a8\u7406\u8f68\u8ff9\u957f\u5ea6\u662f\u5b9e\u7528\u7684\u7f6e\u4fe1\u5ea6\u6d4b\u91cf\u6307\u6807\uff0c\u63a8\u7406\u540e\u8bad\u7ec3\u6539\u53d8\u4e86\u8f68\u8ff9\u957f\u5ea6\u4e0e\u51c6\u786e\u7387\u7684\u5173\u7cfb\uff0c\u9ad8\u71b5\u5206\u53c9token\u8d77\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "\u63a8\u7406\u540e\u8bad\u7ec3\u589e\u5f3a\u4e86\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u80fd\u529b\uff0c\u8f68\u8ff9\u957f\u5ea6\u53ef\u4f5c\u4e3a\u5927\u63a8\u7406\u6a21\u578b\u7684\u5b9e\u7528\u7f6e\u4fe1\u5ea6\u6d4b\u91cf\u65b9\u6cd5\u3002"}}
{"id": "2510.11393", "categories": ["eess.SY", "cs.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2510.11393", "abs": "https://arxiv.org/abs/2510.11393", "authors": ["Farhad Mehdifar", "Charalampos P. Bechlioulis", "Dimos V. Dimarogonas"], "title": "Robust Closed-Form Control for MIMO Nonlinear Systems under Conflicting Time-Varying Hard and Soft Constraints", "comment": "18 pages, 6 figures", "summary": "This paper introduces a novel robust closed-form control law to handle\ntime-varying hard and soft constraints in uncertain high-relative-degree\nnonlinear MIMO systems. These constraints represent spatiotemporal\nspecifications in mechanical systems' operational space, with hard constraints\nensuring safety-critical requirements and soft constraints encoding performance\nor task objectives. Initially, all constraints are consolidated into two\nseparate scalar time-varying hard and soft constraint functions, whose positive\nlevel sets define feasible regions. A closed-form control law is developed to\nenforce these constraints using appropriately designed reciprocal barriers and\nnonlinear transformation functions. When conflicts between hard and soft\nconstraints arise, the control law prioritizes hard constraints by virtually\nrelaxing soft constraints via a dynamic relaxation law. Notably, the proposed\ncontrol law maintains low complexity by avoiding approximation schemes for\ncoping with system uncertainties. Simulation results confirm the effectiveness\nof the proposed method.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9c81\u68d2\u7684\u95ed\u5f0f\u63a7\u5236\u5f8b\uff0c\u7528\u4e8e\u5904\u7406\u5177\u6709\u65f6\u53d8\u786c\u7ea6\u675f\u548c\u8f6f\u7ea6\u675f\u7684\u4e0d\u786e\u5b9a\u9ad8\u9636\u975e\u7ebf\u6027MIMO\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u677e\u5f1b\u673a\u5236\u5728\u7ea6\u675f\u51b2\u7a81\u65f6\u4f18\u5148\u4fdd\u8bc1\u786c\u7ea6\u675f\u3002", "motivation": "\u673a\u68b0\u7cfb\u7edf\u64cd\u4f5c\u7a7a\u95f4\u4e2d\u7684\u65f6\u7a7a\u89c4\u8303\u9700\u8981\u540c\u65f6\u5904\u7406\u5b89\u5168\u5173\u952e\u6027\u786c\u7ea6\u675f\u548c\u6027\u80fd\u4efb\u52a1\u8f6f\u7ea6\u675f\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u7ea6\u675f\u51b2\u7a81\u548c\u7cfb\u7edf\u4e0d\u786e\u5b9a\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u5c06\u6240\u6709\u7ea6\u675f\u6574\u5408\u4e3a\u6807\u91cf\u65f6\u53d8\u786c\u7ea6\u675f\u548c\u8f6f\u7ea6\u675f\u51fd\u6570\uff0c\u8bbe\u8ba1\u4e92\u6613\u969c\u788d\u51fd\u6570\u548c\u975e\u7ebf\u6027\u53d8\u6362\u51fd\u6570\u6784\u5efa\u95ed\u5f0f\u63a7\u5236\u5f8b\uff0c\u901a\u8fc7\u52a8\u6001\u677e\u5f1b\u5f8b\u5728\u51b2\u7a81\u65f6\u865a\u62df\u677e\u5f1b\u8f6f\u7ea6\u675f\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u591f\u5728\u4e0d\u4f7f\u7528\u8fd1\u4f3c\u65b9\u6848\u7684\u60c5\u51b5\u4e0b\u5904\u7406\u7cfb\u7edf\u4e0d\u786e\u5b9a\u6027\uff0c\u540c\u65f6\u4fdd\u8bc1\u7ea6\u675f\u6ee1\u8db3\u3002", "conclusion": "\u63d0\u51fa\u7684\u63a7\u5236\u5f8b\u4e3a\u4e0d\u786e\u5b9a\u9ad8\u9636\u975e\u7ebf\u6027MIMO\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u4f4e\u590d\u6742\u5ea6\u4e14\u9c81\u68d2\u7684\u7ea6\u675f\u5904\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u7ea6\u675f\u51b2\u7a81\u65f6\u4f18\u5148\u4fdd\u8bc1\u5b89\u5168\u6027\u3002"}}
{"id": "2510.10468", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.10468", "abs": "https://arxiv.org/abs/2510.10468", "authors": ["Robert Mahony", "Jonathan Kelly", "Stephan Weiss"], "title": "Galilean Symmetry in Robotics", "comment": "Under Review", "summary": "Galilean symmetry is the natural symmetry of inertial motion that underpins\nNewtonian physics. Although rigid-body symmetry is one of the most established\nand fundamental tools in robotics, there appears to be no comparable treatment\nof Galilean symmetry for a robotics audience. In this paper, we present a\nrobotics-tailored exposition of Galilean symmetry that leverages the\ncommunity's familiarity with and understanding of rigid-body transformations\nand pose representations. Our approach contrasts with common treatments in the\nphysics literature that introduce Galilean symmetry as a stepping stone to\nEinstein's relativity. A key insight is that the Galilean matrix Lie group can\nbe used to describe two different pose representations, Galilean frames, that\nuse inertial velocity in the state definition, and extended poses, that use\ncoordinate velocity. We provide three examples where applying the Galilean\nmatrix Lie-group algebra to robotics problems is straightforward and yields\nsignificant insights: inertial navigation above the rotating Earth, manipulator\nkinematics, and sensor data fusion under temporal uncertainty. We believe that\nthe time is right for the robotics community to benefit from rediscovering and\nextending this classical material and applying it to modern problems.", "AI": {"tldr": "\u672c\u6587\u4e3a\u673a\u5668\u4eba\u5b66\u9886\u57df\u63d0\u4f9b\u4e86\u4f3d\u5229\u7565\u5bf9\u79f0\u6027\u7684\u4e13\u95e8\u9610\u8ff0\uff0c\u5229\u7528\u673a\u5668\u4eba\u5b66\u754c\u719f\u6089\u7684\u521a\u4f53\u53d8\u6362\u548c\u4f4d\u59ff\u8868\u793a\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u4f3d\u5229\u7565\u77e9\u9635\u674e\u7fa4\u7684\u4e24\u79cd\u4f4d\u59ff\u8868\u793a\u65b9\u6cd5\uff0c\u5e76\u5728\u4e09\u4e2a\u673a\u5668\u4eba\u5b66\u5e94\u7528\u4e2d\u5c55\u793a\u4e86\u5176\u4ef7\u503c\u3002", "motivation": "\u4f3d\u5229\u7565\u5bf9\u79f0\u6027\u662f\u725b\u987f\u7269\u7406\u5b66\u4e2d\u60ef\u6027\u8fd0\u52a8\u7684\u81ea\u7136\u5bf9\u79f0\u6027\uff0c\u4f46\u5728\u673a\u5668\u4eba\u5b66\u9886\u57df\u7f3a\u4e4f\u7c7b\u4f3c\u521a\u4f53\u5bf9\u79f0\u6027\u7684\u7cfb\u7edf\u5904\u7406\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u673a\u5668\u4eba\u5b66\u754c\u63d0\u4f9b\u4e13\u95e8\u9488\u5bf9\u4f3d\u5229\u7565\u5bf9\u79f0\u6027\u7684\u9610\u8ff0\u3002", "method": "\u5229\u7528\u673a\u5668\u4eba\u5b66\u754c\u719f\u6089\u7684\u521a\u4f53\u53d8\u6362\u548c\u4f4d\u59ff\u8868\u793a\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u4f3d\u5229\u7565\u77e9\u9635\u674e\u7fa4\u7684\u4e24\u79cd\u4f4d\u59ff\u8868\u793a\uff1a\u4f7f\u7528\u60ef\u6027\u901f\u5ea6\u7684\u4f3d\u5229\u7565\u6846\u67b6\u548c\u4f7f\u7528\u5750\u6807\u901f\u5ea6\u7684\u6269\u5c55\u4f4d\u59ff\u3002", "result": "\u5728\u4e09\u4e2a\u673a\u5668\u4eba\u5b66\u95ee\u9898\u4e2d\u6210\u529f\u5e94\u7528\u4e86\u4f3d\u5229\u7565\u77e9\u9635\u674e\u7fa4\u4ee3\u6570\uff1a\u65cb\u8f6c\u5730\u7403\u4e0a\u65b9\u7684\u60ef\u6027\u5bfc\u822a\u3001\u673a\u68b0\u81c2\u8fd0\u52a8\u5b66\u4ee5\u53ca\u65f6\u95f4\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u4f20\u611f\u5668\u6570\u636e\u878d\u5408\u3002", "conclusion": "\u673a\u5668\u4eba\u5b66\u754c\u73b0\u5728\u6b63\u662f\u65f6\u5019\u4ece\u91cd\u65b0\u53d1\u73b0\u548c\u6269\u5c55\u8fd9\u4e00\u7ecf\u5178\u6750\u6599\u4e2d\u53d7\u76ca\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u73b0\u4ee3\u95ee\u9898\u3002"}}
{"id": "2510.10454", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10454", "abs": "https://arxiv.org/abs/2510.10454", "authors": ["Sihang Zeng", "Yujuan Fu", "Sitong Zhou", "Zixuan Yu", "Lucas Jing Liu", "Jun Wen", "Matthew Thompson", "Ruth Etzioni", "Meliha Yetisgen"], "title": "Traj-CoA: Patient Trajectory Modeling via Chain-of-Agents for Lung Cancer Risk Prediction", "comment": "Accepted by NeurIPS 2025 GenAI4Health Workshop", "summary": "Large language models (LLMs) offer a generalizable approach for modeling\npatient trajectories, but suffer from the long and noisy nature of electronic\nhealth records (EHR) data in temporal reasoning. To address these challenges,\nwe introduce Traj-CoA, a multi-agent system involving chain-of-agents for\npatient trajectory modeling. Traj-CoA employs a chain of worker agents to\nprocess EHR data in manageable chunks sequentially, distilling critical events\ninto a shared long-term memory module, EHRMem, to reduce noise and preserve a\ncomprehensive timeline. A final manager agent synthesizes the worker agents'\nsummary and the extracted timeline in EHRMem to make predictions. In a\nzero-shot one-year lung cancer risk prediction task based on five-year EHR\ndata, Traj-CoA outperforms baselines of four categories. Analysis reveals that\nTraj-CoA exhibits clinically aligned temporal reasoning, establishing it as a\npromisingly robust and generalizable approach for modeling complex patient\ntrajectories.", "AI": {"tldr": "Traj-CoA\u662f\u4e00\u4e2a\u7528\u4e8e\u60a3\u8005\u8f68\u8ff9\u5efa\u6a21\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u94fe\u5f0f\u667a\u80fd\u4f53\u5904\u7406\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6570\u636e\uff0c\u4f7f\u7528\u957f\u671f\u8bb0\u5fc6\u6a21\u5757\u51cf\u5c11\u566a\u58f0\u5e76\u4fdd\u7559\u65f6\u95f4\u7ebf\uff0c\u5728\u80ba\u764c\u98ce\u9669\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5efa\u6a21\u60a3\u8005\u8f68\u8ff9\u65b9\u9762\u5177\u6709\u901a\u7528\u6027\uff0c\u4f46\u9762\u4e34\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6570\u636e\u957f\u4e14\u566a\u58f0\u591a\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u65f6\u95f4\u63a8\u7406\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5305\u62ec\u4e00\u7cfb\u5217\u5de5\u4f5c\u667a\u80fd\u4f53\u987a\u5e8f\u5904\u7406EHR\u6570\u636e\u5757\uff0c\u5c06\u5173\u952e\u4e8b\u4ef6\u63d0\u70bc\u5230\u5171\u4eab\u7684\u957f\u671f\u8bb0\u5fc6\u6a21\u5757EHRMem\u4e2d\uff0c\u6700\u540e\u7531\u7ba1\u7406\u667a\u80fd\u4f53\u7efc\u5408\u4fe1\u606f\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u5728\u57fa\u4e8e\u4e94\u5e74EHR\u6570\u636e\u7684\u96f6\u6837\u672c\u4e00\u5e74\u80ba\u764c\u98ce\u9669\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0cTraj-CoA\u5728\u56db\u7c7b\u57fa\u7ebf\u65b9\u6cd5\u4e2d\u8868\u73b0\u6700\u4f18\uff0c\u5c55\u73b0\u51fa\u4e34\u5e8a\u5bf9\u9f50\u7684\u65f6\u95f4\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "Traj-CoA\u4e3a\u5efa\u6a21\u590d\u6742\u60a3\u8005\u8f68\u8ff9\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7a33\u5065\u4e14\u53ef\u63a8\u5e7f\u7684\u65b9\u6cd5\uff0c\u5728\u4e34\u5e8a\u65f6\u95f4\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2510.11405", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.11405", "abs": "https://arxiv.org/abs/2510.11405", "authors": ["Samuel Oliveira", "Mostafa Tavakkoli Anbarani", "Gregory Beal", "Ilya Kovalenko", "Marcelo Teixeira", "Andr\u00e9 B. Leal", "R\u00f4mulo Meira-G\u00f3es"], "title": "Robust Recovery and Control of Cyber-physical Discrete Event Systems under Actuator Attacks", "comment": "This work has been accepted for publication in the 64th IEEE\n  Conference on Decision and Control (CDC). The final published version will be\n  available on IEEE Xplore", "summary": "Critical real-world applications strongly rely on Cyber-physical systems\n(CPS), but their dependence on communication networks introduces significant\nsecurity risks, as attackers can exploit vulnerabilities to compromise their\nintegrity and availability. This work explores the topic of cybersecurity in\nthe context of CPS modeled as discrete event systems (DES), focusing on\nrecovery strategies following the detection of cyberattacks. Specifically, we\naddress actuator enablement attacks and propose a method that preserves the\nsystem's full valid behavior under normal conditions. Upon detecting an attack,\nour proposed solution aims to guide the system toward a restricted yet robust\nbehavior, ensuring operational continuity and resilience. Additionally, we\nintroduce a property termed AE-robust recoverability, which characterizes the\nnecessary and sufficient conditions for recovering a system from attacks while\npreventing further vulnerabilities. Finally, we showcase the proposed solution\nthrough a case study based on a manufacturing system.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\uff08CPS\uff09\u5728\u906d\u53d7\u6267\u884c\u5668\u4f7f\u80fd\u653b\u51fb\u540e\u7684\u6062\u590d\u7b56\u7565\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u591f\u5728\u68c0\u6d4b\u5230\u653b\u51fb\u65f6\u5f15\u5bfc\u7cfb\u7edf\u8fdb\u5165\u53d7\u9650\u4f46\u9c81\u68d2\u884c\u4e3a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5f15\u5165\u4e86AE-\u9c81\u68d2\u53ef\u6062\u590d\u6027\u6982\u5ff5\u3002", "motivation": "\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\u4e25\u91cd\u4f9d\u8d56\u901a\u4fe1\u7f51\u7edc\uff0c\u8fd9\u5e26\u6765\u4e86\u663e\u8457\u7684\u5b89\u5168\u98ce\u9669\uff0c\u653b\u51fb\u8005\u53ef\u80fd\u5229\u7528\u6f0f\u6d1e\u7834\u574f\u7cfb\u7edf\u7684\u5b8c\u6574\u6027\u548c\u53ef\u7528\u6027\u3002\u9700\u8981\u5f00\u53d1\u5728\u68c0\u6d4b\u5230\u7f51\u7edc\u653b\u51fb\u540e\u7684\u6062\u590d\u7b56\u7565\u3002", "method": "\u5c06CPS\u5efa\u6a21\u4e3a\u79bb\u6563\u4e8b\u4ef6\u7cfb\u7edf\uff08DES\uff09\uff0c\u9488\u5bf9\u6267\u884c\u5668\u4f7f\u80fd\u653b\u51fb\u63d0\u51fa\u6062\u590d\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5728\u6b63\u5e38\u6761\u4ef6\u4e0b\u4fdd\u6301\u7cfb\u7edf\u7684\u5b8c\u6574\u6709\u6548\u884c\u4e3a\uff0c\u5728\u68c0\u6d4b\u5230\u653b\u51fb\u65f6\u5f15\u5bfc\u7cfb\u7edf\u8fdb\u5165\u53d7\u9650\u4f46\u9c81\u68d2\u7684\u884c\u4e3a\u3002", "result": "\u63d0\u51fa\u4e86AE-\u9c81\u68d2\u53ef\u6062\u590d\u6027\u6982\u5ff5\uff0c\u63cf\u8ff0\u4e86\u4ece\u653b\u51fb\u4e2d\u6062\u590d\u7cfb\u7edf\u540c\u65f6\u9632\u6b62\u8fdb\u4e00\u6b65\u6f0f\u6d1e\u7684\u5fc5\u8981\u548c\u5145\u5206\u6761\u4ef6\u3002\u901a\u8fc7\u57fa\u4e8e\u5236\u9020\u7cfb\u7edf\u7684\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u6240\u63d0\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u786e\u4fdd\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\u5728\u906d\u53d7\u6267\u884c\u5668\u4f7f\u80fd\u653b\u51fb\u65f6\u7684\u64cd\u4f5c\u8fde\u7eed\u6027\u548c\u5f39\u6027\uff0c\u4e3aCPS\u7f51\u7edc\u5b89\u5168\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6062\u590d\u7b56\u7565\u3002"}}
{"id": "2510.10506", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.10506", "abs": "https://arxiv.org/abs/2510.10506", "authors": ["Kush Garg", "Akshat Dave"], "title": "SuperEx: Enhancing Indoor Mapping and Exploration using Non-Line-of-Sight Perception", "comment": "8 pages, 9 Figures , Project webpage: https://super-ex.github.io/", "summary": "Efficient exploration and mapping in unknown indoor environments is a\nfundamental challenge, with high stakes in time-critical settings. In current\nsystems, robot perception remains confined to line-of-sight; occluded regions\nremain unknown until physically traversed, leading to inefficient exploration\nwhen layouts deviate from prior assumptions. In this work, we bring\nnon-line-of-sight (NLOS) sensing to robotic exploration. We leverage\nsingle-photon LiDARs, which capture time-of-flight histograms that encode the\npresence of hidden objects - allowing robots to look around blind corners.\nRecent single-photon LiDARs have become practical and portable, enabling\ndeployment beyond controlled lab settings. Prior NLOS works target 3D\nreconstruction in static, lab-based scenarios, and initial efforts toward\nNLOS-aided navigation consider simplified geometries. We introduce SuperEx, a\nframework that integrates NLOS sensing directly into the mapping-exploration\nloop. SuperEx augments global map prediction with beyond-line-of-sight cues by\n(i) carving empty NLOS regions from timing histograms and (ii) reconstructing\noccupied structure via a two-step physics-based and data-driven approach that\nleverages structural regularities. Evaluations on complex simulated maps and\nthe real-world KTH Floorplan dataset show a 12% gain in mapping accuracy under\n< 30% coverage and improved exploration efficiency compared to line-of-sight\nbaselines, opening a path to reliable mapping beyond direct visibility.", "AI": {"tldr": "SuperEx\u6846\u67b6\u5c06\u975e\u89c6\u8ddd(NLOS)\u611f\u77e5\u96c6\u6210\u5230\u673a\u5668\u4eba\u63a2\u7d22\u4e2d\uff0c\u5229\u7528\u5355\u5149\u5b50LiDAR\u63a2\u6d4b\u9690\u85cf\u533a\u57df\uff0c\u901a\u8fc7\u7269\u7406\u548c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u91cd\u5efa\u906e\u6321\u7ed3\u6784\uff0c\u5728\u4f4e\u8986\u76d6\u7387\u4e0b\u663e\u8457\u63d0\u5347\u5efa\u56fe\u7cbe\u5ea6\u548c\u63a2\u7d22\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u673a\u5668\u4eba\u611f\u77e5\u5c40\u9650\u4e8e\u89c6\u7ebf\u8303\u56f4\uff0c\u906e\u6321\u533a\u57df\u9700\u8981\u7269\u7406\u904d\u5386\u624d\u80fd\u53d1\u73b0\uff0c\u5bfc\u81f4\u63a2\u7d22\u6548\u7387\u4f4e\u4e0b\u3002\u5c06\u975e\u89c6\u8ddd\u611f\u77e5\u5f15\u5165\u673a\u5668\u4eba\u63a2\u7d22\u53ef\u4ee5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u96c6\u6210NLOS\u611f\u77e5\u5230\u5efa\u56fe-\u63a2\u7d22\u5faa\u73af\u4e2d\uff1a(i)\u4ece\u65f6\u95f4\u76f4\u65b9\u56fe\u4e2d\u5254\u9664\u7a7aNLOS\u533a\u57df\uff1b(ii)\u901a\u8fc7\u57fa\u4e8e\u7269\u7406\u548c\u6570\u636e\u9a71\u52a8\u7684\u4e24\u6b65\u6cd5\u91cd\u5efa\u5360\u7528\u7ed3\u6784\uff0c\u5229\u7528\u7ed3\u6784\u89c4\u5f8b\u6027\u3002", "result": "\u5728\u590d\u6742\u6a21\u62df\u5730\u56fe\u548c\u771f\u5b9eKTH Floorplan\u6570\u636e\u96c6\u4e0a\uff0c\u5728<30%\u8986\u76d6\u7387\u4e0b\u5efa\u56fe\u7cbe\u5ea6\u63d0\u534712%\uff0c\u63a2\u7d22\u6548\u7387\u4f18\u4e8e\u89c6\u7ebf\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "SuperEx\u4e3a\u8d85\u8d8a\u76f4\u63a5\u53ef\u89c1\u6027\u7684\u53ef\u9760\u5efa\u56fe\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u8bc1\u660e\u4e86NLOS\u611f\u77e5\u5728\u673a\u5668\u4eba\u63a2\u7d22\u4e2d\u7684\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2510.10461", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10461", "abs": "https://arxiv.org/abs/2510.10461", "authors": ["Hongjie Zheng", "Zesheng Shi", "Ping Yi"], "title": "MedCoAct: Confidence-Aware Multi-Agent Collaboration for Complete Clinical Decision", "comment": null, "summary": "Autonomous agents utilizing Large Language Models (LLMs) have demonstrated\nremarkable capabilities in isolated medical tasks like diagnosis and image\nanalysis, but struggle with integrated clinical workflows that connect\ndiagnostic reasoning and medication decisions. We identify a core limitation:\nexisting medical AI systems process tasks in isolation without the\ncross-validation and knowledge integration found in clinical teams, reducing\ntheir effectiveness in real-world healthcare scenarios. To transform the\nisolation paradigm into a collaborative approach, we propose MedCoAct, a\nconfidence-aware multi-agent framework that simulates clinical collaboration by\nintegrating specialized doctor and pharmacist agents, and present a benchmark,\nDrugCareQA, to evaluate medical AI capabilities in integrated diagnosis and\ntreatment workflows. Our results demonstrate that MedCoAct achieves 67.58\\%\ndiagnostic accuracy and 67.58\\% medication recommendation accuracy,\noutperforming single agent framework by 7.04\\% and 7.08\\% respectively. This\ncollaborative approach generalizes well across diverse medical domains, proving\nespecially effective for telemedicine consultations and routine clinical\nscenarios, while providing interpretable decision-making pathways.", "AI": {"tldr": "\u63d0\u51fa\u4e86MedCoAct\u6846\u67b6\uff0c\u901a\u8fc7\u533b\u751f\u548c\u836f\u5242\u5e08\u667a\u80fd\u4f53\u534f\u4f5c\u89e3\u51b3\u533b\u7597AI\u5728\u8bca\u65ad\u548c\u6cbb\u7597\u6574\u5408\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u6846\u67b6\u63d0\u53477%\u4ee5\u4e0a\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u533b\u7597AI\u7cfb\u7edf\u5728\u5b64\u7acb\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u6574\u5408\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7f3a\u4e4f\u8de8\u9a8c\u8bc1\u548c\u77e5\u8bc6\u6574\u5408\uff0c\u65e0\u6cd5\u6a21\u62df\u771f\u5b9e\u533b\u7597\u56e2\u961f\u7684\u534f\u4f5c\u6a21\u5f0f\u3002", "method": "\u63d0\u51faMedCoAct\u7f6e\u4fe1\u611f\u77e5\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u96c6\u6210\u4e13\u4e1a\u533b\u751f\u548c\u836f\u5242\u5e08\u667a\u80fd\u4f53\u6a21\u62df\u4e34\u5e8a\u534f\u4f5c\uff0c\u5e76\u521b\u5efaDrugCareQA\u57fa\u51c6\u8bc4\u4f30\u533b\u7597AI\u5728\u6574\u5408\u8bca\u65ad\u548c\u6cbb\u7597\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u80fd\u529b\u3002", "result": "MedCoAct\u8fbe\u523067.58%\u7684\u8bca\u65ad\u51c6\u786e\u7387\u548c67.58%\u7684\u7528\u836f\u63a8\u8350\u51c6\u786e\u7387\uff0c\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u6846\u67b6\u5206\u522b\u63d0\u53477.04%\u548c7.08%\uff0c\u5728\u8fdc\u7a0b\u533b\u7597\u548c\u5e38\u89c4\u4e34\u5e8a\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u534f\u4f5c\u65b9\u6cd5\u5728\u4e0d\u540c\u533b\u7597\u9886\u57df\u6cdb\u5316\u826f\u597d\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8fdc\u7a0b\u533b\u7597\u54a8\u8be2\u548c\u5e38\u89c4\u4e34\u5e8a\u573a\u666f\uff0c\u540c\u65f6\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u8def\u5f84\u3002"}}
{"id": "2510.11413", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.11413", "abs": "https://arxiv.org/abs/2510.11413", "authors": ["Sofia Girardello", "Giulia Michieletto", "Angelo Cenedese", "Antonio Franchi", "Chiara Gabellieri"], "title": "Trajectory control of a suspended load with non-stopping flying carriers", "comment": null, "summary": "This paper presents the first closed-loop control framework for cooperative\npayload transportation with non-stopping flying carriers. Building upon\ngrasp-matrix formulations and internal force redundancy, we propose a feedback\nwrench controller that actively regulates the payload's pose while an\noptimization layer dynamically shapes internal-force oscillations to guarantee\npersistent carrier motion. Preliminary experimental results on multirotor UAVs\nvalidate the model assumptions, and numerical simulations demonstrate that the\nmethod successfully prevents carrier stagnation, achieves accurate load\ntracking, and generates physically feasible trajectories with smooth velocity\nprofiles. The proposed framework not only advances the state of the art but\nalso offers a reliable, versatile solution for future real-world applications\nrequiring load transportation by coordinated non-stopping flying carriers.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u7528\u4e8e\u975e\u505c\u98de\u8f7d\u5177\u534f\u540c\u8f7d\u8377\u8fd0\u8f93\u7684\u95ed\u73af\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u53cd\u9988\u529b\u77e9\u63a7\u5236\u5668\u8c03\u8282\u8f7d\u8377\u59ff\u6001\uff0c\u4f18\u5316\u5c42\u52a8\u6001\u8c03\u6574\u5185\u529b\u632f\u8361\u4fdd\u8bc1\u8f7d\u5177\u6301\u7eed\u8fd0\u52a8\u3002", "motivation": "\u89e3\u51b3\u534f\u540c\u98de\u884c\u8f7d\u5177\u5728\u8f7d\u8377\u8fd0\u8f93\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u51fa\u73b0\u7684\u505c\u6ede\u95ee\u9898\uff0c\u63d0\u4f9b\u53ef\u9760\u7684\u975e\u505c\u98de\u8fd0\u8f93\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u6293\u53d6\u77e9\u9635\u516c\u5f0f\u548c\u5185\u529b\u5197\u4f59\uff0c\u8bbe\u8ba1\u53cd\u9988\u529b\u77e9\u63a7\u5236\u5668\u8c03\u8282\u8f7d\u8377\u4f4d\u59ff\uff0c\u901a\u8fc7\u4f18\u5316\u5c42\u52a8\u6001\u8c03\u6574\u5185\u529b\u632f\u8361\u6765\u786e\u4fdd\u8f7d\u5177\u6301\u7eed\u8fd0\u52a8\u3002", "result": "\u591a\u65cb\u7ffc\u65e0\u4eba\u673a\u521d\u6b65\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6a21\u578b\u5047\u8bbe\uff0c\u6570\u503c\u6a21\u62df\u663e\u793a\u8be5\u65b9\u6cd5\u6210\u529f\u9632\u6b62\u8f7d\u5177\u505c\u6ede\uff0c\u5b9e\u73b0\u7cbe\u786e\u8f7d\u8377\u8ddf\u8e2a\uff0c\u751f\u6210\u7269\u7406\u53ef\u884c\u4e14\u901f\u5ea6\u66f2\u7ebf\u5e73\u6ed1\u7684\u8f68\u8ff9\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u63a8\u8fdb\u4e86\u6280\u672f\u6c34\u5e73\uff0c\u8fd8\u4e3a\u9700\u8981\u534f\u8c03\u975e\u505c\u98de\u8f7d\u5177\u8fdb\u884c\u8f7d\u8377\u8fd0\u8f93\u7684\u672a\u6765\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u3001\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.10516", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10516", "abs": "https://arxiv.org/abs/2510.10516", "authors": ["Kanishkha Jaisankar", "Xiaoyang Jiang", "Feifan Liao", "Jeethu Sreenivas Amuthan"], "title": "Population-Coded Spiking Neural Networks for High-Dimensional Robotic Control", "comment": null, "summary": "Energy-efficient and high-performance motor control remains a critical\nchallenge in robotics, particularly for high-dimensional continuous control\ntasks with limited onboard resources. While Deep Reinforcement Learning (DRL)\nhas achieved remarkable results, its computational demands and energy\nconsumption limit deployment in resource-constrained environments. This paper\nintroduces a novel framework combining population-coded Spiking Neural Networks\n(SNNs) with DRL to address these challenges. Our approach leverages the\nevent-driven, asynchronous computation of SNNs alongside the robust policy\noptimization capabilities of DRL, achieving a balance between energy efficiency\nand control performance. Central to this framework is the Population-coded\nSpiking Actor Network (PopSAN), which encodes high-dimensional observations\ninto neuronal population activities and enables optimal policy learning through\ngradient-based updates. We evaluate our method on the Isaac Gym platform using\nthe PixMC benchmark with complex robotic manipulation tasks. Experimental\nresults on the Franka robotic arm demonstrate that our approach achieves energy\nsavings of up to 96.10% compared to traditional Artificial Neural Networks\n(ANNs) while maintaining comparable control performance. The trained SNN\npolicies exhibit robust finger position tracking with minimal deviation from\ncommanded trajectories and stable target height maintenance during\npick-and-place operations. These results position population-coded SNNs as a\npromising solution for energy-efficient, high-performance robotic control in\nresource-constrained applications, paving the way for scalable deployment in\nreal-world robotics systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7fa4\u4f53\u7f16\u7801\u8109\u51b2\u795e\u7ecf\u7f51\u7edc(SNN)\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60(DRL)\u7684\u65b0\u578b\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u673a\u5668\u4eba\u63a7\u5236\u4e2d\u7684\u80fd\u8017\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u63a7\u5236\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u8fbe96.10%\u7684\u80fd\u8017\u8282\u7701\u3002", "motivation": "\u89e3\u51b3\u9ad8\u7ef4\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u7535\u673a\u63a7\u5236\u7684\u80fd\u6548\u548c\u6027\u80fd\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\uff0c\u4f20\u7edf\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u8ba1\u7b97\u9700\u6c42\u5927\u3001\u80fd\u8017\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u7fa4\u4f53\u7f16\u7801\u8109\u51b2\u6f14\u5458\u7f51\u7edc(PopSAN)\uff0c\u5c06\u9ad8\u7ef4\u89c2\u6d4b\u7f16\u7801\u4e3a\u795e\u7ecf\u5143\u7fa4\u4f53\u6d3b\u52a8\uff0c\u901a\u8fc7\u57fa\u4e8e\u68af\u5ea6\u7684\u66f4\u65b0\u5b9e\u73b0\u6700\u4f18\u7b56\u7565\u5b66\u4e60\uff0c\u7ed3\u5408SNN\u7684\u4e8b\u4ef6\u9a71\u52a8\u5f02\u6b65\u8ba1\u7b97\u548cDRL\u7684\u9c81\u68d2\u7b56\u7565\u4f18\u5316\u80fd\u529b\u3002", "result": "\u5728Isaac Gym\u5e73\u53f0\u7684PixMC\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528Franka\u673a\u68b0\u81c2\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u4f20\u7edf\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc(ANN)\uff0c\u80fd\u8017\u8282\u7701\u9ad8\u8fbe96.10%\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u7684\u63a7\u5236\u6027\u80fd\uff0c\u8868\u73b0\u51fa\u7a33\u5065\u7684\u624b\u6307\u4f4d\u7f6e\u8ddf\u8e2a\u548c\u7a33\u5b9a\u7684\u76ee\u6807\u9ad8\u5ea6\u7ef4\u6301\u3002", "conclusion": "\u7fa4\u4f53\u7f16\u7801SNN\u662f\u8d44\u6e90\u53d7\u9650\u5e94\u7528\u4e2d\u80fd\u6548\u9ad8\u3001\u6027\u80fd\u597d\u7684\u673a\u5668\u4eba\u63a7\u5236\u7684\u6709\u524d\u666f\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u90e8\u7f72\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2510.10494", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10494", "abs": "https://arxiv.org/abs/2510.10494", "authors": ["Martina G. Vilas", "Safoora Yousefi", "Besmira Nushi", "Eric Horvitz", "Vidhisha Balachandran"], "title": "Tracing the Traces: Latent Temporal Signals for Efficient and Accurate Reasoning", "comment": null, "summary": "Reasoning models improve their problem-solving ability through inference-time\nscaling, allocating more compute via longer token budgets. Identifying which\nreasoning traces are likely to succeed remains a key opportunity: reliably\npredicting productive paths can substantially reduce wasted computation and\nimprove overall efficiency. We introduce Latent-Trajectory signals that\ncharacterize the temporal evolution of a model's internal representations\nduring the generation of intermediate reasoning tokens. By measuring the\noverall change in latent representations between the start and end of\nreasoning, the change accumulated across intermediate steps, and the extent to\nwhich these changes advance toward the final state, we show that these signals\npredict solution accuracy more reliably than both cross-layer metrics and\noutput-based confidence measures. When used to guide answer selection across\nmultiple sampled generations, Latent-Trajectory signals make test-time scaling\nmore effective and efficient than majority voting, reducing token usage by up\nto 70% while preserving and even improving accuracy by 2.6% on average.\nMoreover, these predictive signals often emerge early in the reasoning trace,\nenabling early selection and allocation of compute to the most promising\ncandidates. Our findings contribute not only practical strategies for\ninference-time efficiency, but also a deeper interpretability perspective on\nhow reasoning processes are represented and differentiated in latent space.", "AI": {"tldr": "\u63d0\u51fa\u4e86Latent-Trajectory\u4fe1\u53f7\u6765\u9884\u6d4b\u63a8\u7406\u8fc7\u7a0b\u7684\u8d28\u91cf\uff0c\u901a\u8fc7\u5206\u6790\u6a21\u578b\u5185\u90e8\u8868\u5f81\u7684\u65f6\u95f4\u6f14\u5316\u6765\u8bc6\u522b\u53ef\u80fd\u6210\u529f\u7684\u63a8\u7406\u8def\u5f84\uff0c\u663e\u8457\u63d0\u9ad8\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u63a8\u7406\u6a21\u578b\u901a\u8fc7\u589e\u52a0\u8ba1\u7b97\u91cf\u6765\u63d0\u9ad8\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u4f46\u8bc6\u522b\u54ea\u4e9b\u63a8\u7406\u8def\u5f84\u53ef\u80fd\u6210\u529f\u662f\u5173\u952e\u673a\u4f1a\uff0c\u53ef\u4ee5\u5927\u5e45\u51cf\u5c11\u6d6a\u8d39\u7684\u8ba1\u7b97\u5e76\u63d0\u9ad8\u6574\u4f53\u6548\u7387\u3002", "method": "\u5f15\u5165Latent-Trajectory\u4fe1\u53f7\uff0c\u901a\u8fc7\u6d4b\u91cf\u63a8\u7406\u5f00\u59cb\u548c\u7ed3\u675f\u65f6\u5185\u90e8\u8868\u5f81\u7684\u603b\u4f53\u53d8\u5316\u3001\u4e2d\u95f4\u6b65\u9aa4\u7d2f\u79ef\u7684\u53d8\u5316\u4ee5\u53ca\u8fd9\u4e9b\u53d8\u5316\u5411\u6700\u7ec8\u72b6\u6001\u63a8\u8fdb\u7684\u7a0b\u5ea6\u6765\u9884\u6d4b\u89e3\u51b3\u65b9\u6848\u51c6\u786e\u6027\u3002", "result": "Latent-Trajectory\u4fe1\u53f7\u6bd4\u8de8\u5c42\u5ea6\u91cf\u548c\u57fa\u4e8e\u8f93\u51fa\u7684\u7f6e\u4fe1\u5ea6\u6d4b\u91cf\u66f4\u53ef\u9760\u5730\u9884\u6d4b\u89e3\u51b3\u65b9\u6848\u51c6\u786e\u6027\uff0c\u5728\u591a\u4e2a\u91c7\u6837\u751f\u6210\u4e2d\u6307\u5bfc\u7b54\u6848\u9009\u62e9\u65f6\uff0c\u5c06token\u4f7f\u7528\u91cf\u51cf\u5c11\u9ad8\u8fbe70%\uff0c\u540c\u65f6\u5e73\u5747\u51c6\u786e\u7387\u63d0\u9ad82.6%\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e0d\u4ec5\u4e3a\u63a8\u7406\u65f6\u6548\u7387\u63d0\u4f9b\u4e86\u5b9e\u7528\u7b56\u7565\uff0c\u8fd8\u4ece\u53ef\u89e3\u91ca\u6027\u89d2\u5ea6\u6df1\u5165\u7406\u89e3\u4e86\u63a8\u7406\u8fc7\u7a0b\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u8868\u793a\u548c\u533a\u5206\u65b9\u5f0f\u3002"}}
{"id": "2510.11476", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.11476", "abs": "https://arxiv.org/abs/2510.11476", "authors": ["Nan Gu", "Ge Chen", "Junjie Qin"], "title": "The Role of Flexible Connection in Accelerating Load Interconnection in Distribution Networks", "comment": null, "summary": "This paper investigates the role of flexible connection in accelerating the\ninterconnection of large loads amid rising electricity demand from data centers\nand electrification. Flexible connection allows new loads to defer or curtail\nconsumption during rare, grid-constrained periods, enabling faster access\nwithout major infrastructure upgrades. To quantify how flexible connection\nunlocks load hosting capacity, we formulate a flexibility-aware hosting\ncapacity analysis problem that explicitly limits the number of\nutility-controlled interventions per year, ensuring infrequent disruption.\nEfficient solution methods are developed for this nonconvex problem and applied\nto real load data and test feeders. Empirical results reveal that modest\nflexibility, i.e., few interventions with small curtailments or delays, can\nunlock substantial hosting capacity. Theoretical analysis further explains and\ngeneralizes these findings, highlighting the broad potential of flexible\nconnection.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u67d4\u6027\u8fde\u63a5\u5728\u52a0\u901f\u5927\u578b\u8d1f\u8f7d\u63a5\u5165\u7535\u7f51\u4e2d\u7684\u4f5c\u7528\uff0c\u901a\u8fc7\u5141\u8bb8\u8d1f\u8f7d\u5728\u7535\u7f51\u53d7\u9650\u65f6\u51cf\u5c11\u6216\u5ef6\u8fdf\u7528\u7535\uff0c\u65e0\u9700\u5927\u89c4\u6a21\u57fa\u7840\u8bbe\u65bd\u5347\u7ea7\u5373\u53ef\u63d0\u5347\u8d1f\u8f7d\u627f\u8f7d\u80fd\u529b\u3002", "motivation": "\u968f\u7740\u6570\u636e\u4e2d\u5fc3\u7528\u7535\u9700\u6c42\u589e\u957f\u548c\u7535\u6c14\u5316\u8fdb\u7a0b\u52a0\u901f\uff0c\u7535\u7f51\u9762\u4e34\u5927\u578b\u8d1f\u8f7d\u63a5\u5165\u6311\u6218\u3002\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u6602\u8d35\u7684\u57fa\u7840\u8bbe\u65bd\u5347\u7ea7\uff0c\u800c\u67d4\u6027\u8fde\u63a5\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u7ecf\u6d4e\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u8003\u8651\u7075\u6d3b\u6027\u7684\u8d1f\u8f7d\u627f\u8f7d\u80fd\u529b\u5206\u6790\u95ee\u9898\uff0c\u9650\u5236\u6bcf\u5e74\u7535\u7f51\u5e72\u9884\u6b21\u6570\uff0c\u786e\u4fdd\u5bf9\u7528\u6237\u5f71\u54cd\u6700\u5c0f\u3002\u5f00\u53d1\u4e86\u9ad8\u6548\u6c42\u89e3\u65b9\u6cd5\uff0c\u5e76\u5e94\u7528\u4e8e\u771f\u5b9e\u8d1f\u8f7d\u6570\u636e\u548c\u6d4b\u8bd5\u9988\u7ebf\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\uff0c\u5373\u4f7f\u5f88\u5c0f\u7684\u7075\u6d3b\u6027\uff08\u5c11\u91cf\u5e72\u9884\u548c\u8f7b\u5fae\u524a\u51cf\u6216\u5ef6\u8fdf\uff09\u4e5f\u80fd\u663e\u8457\u63d0\u5347\u8d1f\u8f7d\u627f\u8f7d\u80fd\u529b\u3002\u7406\u8bba\u5206\u6790\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u5e76\u63a8\u5e7f\u4e86\u8fd9\u4e00\u53d1\u73b0\u3002", "conclusion": "\u67d4\u6027\u8fde\u63a5\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u80fd\u591f\u5728\u4e0d\u9891\u7e41\u4e2d\u65ad\u7528\u6237\u7528\u7535\u7684\u524d\u63d0\u4e0b\uff0c\u6709\u6548\u52a0\u901f\u5927\u578b\u8d1f\u8f7d\u63a5\u5165\u7535\u7f51\uff0c\u7f13\u89e3\u7535\u7f51\u5bb9\u91cf\u538b\u529b\u3002"}}
{"id": "2510.10545", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.10545", "abs": "https://arxiv.org/abs/2510.10545", "authors": ["Koki Yamane", "Sho Sakaino", "Toshiaki Tsuji"], "title": "Decoupled Scaling 4ch Bilateral Control on the Cartesian coordinate by 6-DoF Manipulator using Rotation Matrix", "comment": "6 pages, 4 figures, Accepted at SAMCON 2025", "summary": "Four-channel bilateral control is a method for achieving remote control with\nforce feedback and adjustment operability by synchronizing the positions and\nforces of two manipulators. This is expected to significantly improve the\noperability of the remote control in contact-rich tasks. Among these, 4-channel\nbilateral control on the Cartesian coordinate system is advantageous owing to\nits suitability for manipulators with different structures and because it\nallows the dynamics in the Cartesian coordinate system to be adjusted by\nadjusting the control parameters, thus achieving intuitive operability for\nhumans. This paper proposes a 4-channel bilateral control method that achieves\nthe desired dynamics by decoupling each dimension in the Cartesian coordinate\nsystem regardless of the scaling factor.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd4\u901a\u9053\u7b1b\u5361\u5c14\u5750\u6807\u7cfb\u53cc\u8fb9\u63a7\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u8026\u5404\u7ef4\u5ea6\u5b9e\u73b0\u671f\u671b\u52a8\u529b\u5b66\uff0c\u4e0d\u53d7\u7f29\u653e\u56e0\u5b50\u5f71\u54cd", "motivation": "\u56db\u901a\u9053\u53cc\u8fb9\u63a7\u5236\u80fd\u901a\u8fc7\u540c\u6b65\u4e24\u4e2a\u673a\u68b0\u81c2\u7684\u4f4d\u7f6e\u548c\u529b\u6765\u5b9e\u73b0\u5e26\u529b\u53cd\u9988\u7684\u8fdc\u7a0b\u63a7\u5236\uff0c\u5728\u63a5\u89e6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u663e\u8457\u6539\u5584\u64cd\u4f5c\u6027\u3002\u7b1b\u5361\u5c14\u5750\u6807\u7cfb\u4e0b\u76844\u901a\u9053\u53cc\u8fb9\u63a7\u5236\u7279\u522b\u9002\u5408\u4e0d\u540c\u7ed3\u6784\u7684\u673a\u68b0\u81c2\uff0c\u5e76\u80fd\u901a\u8fc7\u8c03\u6574\u63a7\u5236\u53c2\u6570\u5b9e\u73b0\u76f4\u89c2\u64cd\u4f5c", "method": "\u63d0\u51fa4\u901a\u9053\u53cc\u8fb9\u63a7\u5236\u65b9\u6cd5\uff0c\u5728\u7b1b\u5361\u5c14\u5750\u6807\u7cfb\u4e2d\u89e3\u8026\u6bcf\u4e2a\u7ef4\u5ea6\uff0c\u65e0\u8bba\u7f29\u653e\u56e0\u5b50\u5982\u4f55\u90fd\u80fd\u5b9e\u73b0\u671f\u671b\u7684\u52a8\u529b\u5b66\u7279\u6027", "result": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u671f\u671b\u7684\u52a8\u529b\u5b66\u6027\u80fd\uff0c\u4e0d\u53d7\u7f29\u653e\u56e0\u5b50\u5f71\u54cd", "conclusion": "\u63d0\u51fa\u76844\u901a\u9053\u53cc\u8fb9\u63a7\u5236\u65b9\u6cd5\u5728\u7b1b\u5361\u5c14\u5750\u6807\u7cfb\u4e2d\u6709\u6548\u5b9e\u73b0\u4e86\u7ef4\u5ea6\u89e3\u8026\u548c\u671f\u671b\u52a8\u529b\u5b66\uff0c\u4e3a\u8fdc\u7a0b\u63a7\u5236\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u64cd\u4f5c\u6027"}}
{"id": "2510.10549", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10549", "abs": "https://arxiv.org/abs/2510.10549", "authors": ["Xinbang Dai", "Huikang Hu", "Yongrui Chen", "Jiaqi Li", "Rihui Jin", "Yuyang Zhang", "Xiaoguang Li", "Lifeng Shang", "Guilin Qi"], "title": "ELAIPBench: A Benchmark for Expert-Level Artificial Intelligence Paper Understanding", "comment": "25 pages, 20 figures", "summary": "While large language models (LLMs) excel at many domain-specific tasks, their\nability to deeply comprehend and reason about full-length academic papers\nremains underexplored. Existing benchmarks often fall short of capturing such\ndepth, either due to surface-level question design or unreliable evaluation\nmetrics. To address this gap, we introduce ELAIPBench, a benchmark curated by\ndomain experts to evaluate LLMs' comprehension of artificial intelligence (AI)\nresearch papers. Developed through an incentive-driven, adversarial annotation\nprocess, ELAIPBench features 403 multiple-choice questions from 137 papers. It\nspans three difficulty levels and emphasizes non-trivial reasoning rather than\nshallow retrieval. Our experiments show that the best-performing LLM achieves\nan accuracy of only 39.95%, far below human performance. Moreover, we observe\nthat frontier LLMs equipped with a thinking mode or a retrieval-augmented\ngeneration (RAG) system fail to improve final results-even harming accuracy due\nto overthinking or noisy retrieval. These findings underscore the significant\ngap between current LLM capabilities and genuine comprehension of academic\npapers.", "AI": {"tldr": "ELAIPBench\u662f\u4e00\u4e2a\u7531\u9886\u57df\u4e13\u5bb6\u7b56\u5212\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5bf9AI\u7814\u7a76\u8bba\u6587\u7684\u7406\u89e3\u80fd\u529b\uff0c\u5305\u542b403\u4e2a\u591a\u9009\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u6700\u4f73LLM\u51c6\u786e\u7387\u4ec539.95%\uff0c\u8fdc\u4f4e\u4e8e\u4eba\u7c7b\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5728\u8bc4\u4f30LLM\u5bf9\u5b66\u672f\u8bba\u6587\u7684\u6df1\u5ea6\u7406\u89e3\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u8981\u4e48\u95ee\u9898\u8bbe\u8ba1\u8fc7\u4e8e\u8868\u9762\uff0c\u8981\u4e48\u8bc4\u4f30\u6307\u6807\u4e0d\u53ef\u9760\u3002", "method": "\u901a\u8fc7\u6fc0\u52b1\u9a71\u52a8\u7684\u5bf9\u6297\u6027\u6807\u6ce8\u8fc7\u7a0b\u5f00\u53d1ELAIPBench\u57fa\u51c6\uff0c\u5305\u542b137\u7bc7\u8bba\u6587\u7684403\u4e2a\u591a\u9009\u9898\uff0c\u6db5\u76d6\u4e09\u4e2a\u96be\u5ea6\u7ea7\u522b\uff0c\u5f3a\u8c03\u975e\u5e73\u51e1\u63a8\u7406\u800c\u975e\u6d45\u5c42\u68c0\u7d22\u3002", "result": "\u6700\u4f73\u6027\u80fd\u7684LLM\u51c6\u786e\u7387\u4ec5\u4e3a39.95%\uff0c\u914d\u5907\u601d\u8003\u6a21\u5f0f\u6216RAG\u7cfb\u7edf\u7684\u524d\u6cbfLLM\u672a\u80fd\u6539\u5584\u7ed3\u679c\uff0c\u751a\u81f3\u56e0\u8fc7\u5ea6\u601d\u8003\u6216\u566a\u58f0\u68c0\u7d22\u800c\u964d\u4f4e\u51c6\u786e\u7387\u3002", "conclusion": "\u5f53\u524dLLM\u80fd\u529b\u4e0e\u771f\u6b63\u7406\u89e3\u5b66\u672f\u8bba\u6587\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002"}}
{"id": "2510.11515", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.11515", "abs": "https://arxiv.org/abs/2510.11515", "authors": ["Shanthan Kumar Padisala", "Bharatkumar Hegde", "Ibrahim Haskara", "Satadru Dey"], "title": "A Physics-Informed Reinforcement Learning Approach for Degradation-Aware Long-Term Charging Optimization in Batteries", "comment": null, "summary": "Batteries degrade with usage and continuous cycling. This aging is typically\nreflected through the resistance growth and the capacity fade of battery cells.\nOver the years, various charging methods have been presented in the literature\nthat proposed current profiles in order to enable optimal, fast, and/or\nhealth-conscious charging. However, very few works have attempted to make the\nubiquitous Constant Current Constant Voltage (CCCV) charging protocol adaptive\nto the changing battery health as it cycles. This work aims to address this gap\nand proposes a framework that optimizes the constant current part of the CCCV\nprotocol adapting to long-term battery degradation. Specifically, a\nphysics-informed Reinforcement Learning (RL) approach has been used that not\nonly estimates a key battery degradation mechanism, namely, Loss of Active\nMaterial (LAM), but also adjusts the current magnitude of CCCV as a result of\nthis particular degradation. The proposed framework has been implemented by\ncombining PyBamm, an open-source battery modeling tool, and Stable-baselines\nwhere the RL agent was trained using a Proximal Policy Optimization (PPO)\nnetwork. Simulation results show the potential of the proposed framework for\nenhancing the widely used CCCV protocol by embedding physics information in RL\nalgorithm. A comparative study of this proposed agent has also been discussed\nwith 2 other charging protocols generated by a non-physics-based RL agent and a\nconstant CCCV for all the cycles.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u9002\u5e94CCCV\u5145\u7535\u534f\u8bae\u4f18\u5316\u6846\u67b6\uff0c\u80fd\u591f\u6839\u636e\u7535\u6c60\u957f\u671f\u9000\u5316\u8c03\u6574\u5145\u7535\u7535\u6d41\uff0c\u63d0\u5347\u7535\u6c60\u5065\u5eb7\u7ba1\u7406\u3002", "motivation": "\u73b0\u6709CCCV\u5145\u7535\u534f\u8bae\u7f3a\u4e4f\u5bf9\u7535\u6c60\u5065\u5eb7\u72b6\u6001\u9000\u5316\u7684\u81ea\u9002\u5e94\u80fd\u529b\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6839\u636e\u7535\u6c60\u8001\u5316\u60c5\u51b5\u52a8\u6001\u8c03\u6574\u7684\u5145\u7535\u7b56\u7565\u3002", "method": "\u7ed3\u5408PyBamm\u7535\u6c60\u5efa\u6a21\u5de5\u5177\u548cStable-baselines\u5f3a\u5316\u5b66\u4e60\u5e73\u53f0\uff0c\u4f7f\u7528PPO\u7b97\u6cd5\u8bad\u7ec3RL\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u7269\u7406\u4fe1\u606f\u4f30\u8ba1\u7535\u6c60\u6d3b\u6027\u6750\u6599\u635f\u5931(LAM)\u5e76\u76f8\u5e94\u8c03\u6574CCCV\u5145\u7535\u7535\u6d41\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u8be5\u6846\u67b6\u80fd\u6709\u6548\u589e\u5f3a\u4f20\u7edfCCCV\u534f\u8bae\uff0c\u5d4c\u5165\u7269\u7406\u4fe1\u606f\u7684RL\u7b97\u6cd5\u4f18\u4e8e\u975e\u7269\u7406\u57fa\u7840\u7684RL\u667a\u80fd\u4f53\u548c\u56fa\u5b9aCCCV\u534f\u8bae\u3002", "conclusion": "\u63d0\u51fa\u7684\u7269\u7406\u4fe1\u606f\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4e3a\u5e7f\u6cdb\u4f7f\u7528\u7684CCCV\u5145\u7535\u534f\u8bae\u63d0\u4f9b\u4e86\u81ea\u9002\u5e94\u9000\u5316\u8c03\u6574\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2510.10567", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10567", "abs": "https://arxiv.org/abs/2510.10567", "authors": ["Alexander Langmann", "Yevhenii Tokarev", "Mattia Piccinini", "Korbinian Moller", "Johannes Betz"], "title": "Reinforcement Learning-based Dynamic Adaptation for Sampling-Based Motion Planning in Agile Autonomous Driving", "comment": "8 pages, submitted to the IEEE ICRA 2026, Vienna, Austria", "summary": "Sampling-based trajectory planners are widely used for agile autonomous\ndriving due to their ability to generate fast, smooth, and kinodynamically\nfeasible trajectories. However, their behavior is often governed by a cost\nfunction with manually tuned, static weights, which forces a tactical\ncompromise that is suboptimal across the wide range of scenarios encountered in\na race. To address this shortcoming, we propose using a Reinforcement Learning\n(RL) agent as a high-level behavioral selector that dynamically switches the\ncost function parameters of an analytical, low-level trajectory planner during\nruntime. We show the effectiveness of our approach in simulation in an\nautonomous racing environment where our RL-based planner achieved 0% collision\nrate while reducing overtaking time by up to 60% compared to state-of-the-art\nstatic planners. Our new agent now dynamically switches between aggressive and\nconservative behaviors, enabling interactive maneuvers unattainable with static\nconfigurations. These results demonstrate that integrating reinforcement\nlearning as a high-level selector resolves the inherent trade-off between\nsafety and competitiveness in autonomous racing planners. The proposed\nmethodology offers a pathway toward adaptive yet interpretable motion planning\nfor broader autonomous driving applications.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4f5c\u4e3a\u9ad8\u5c42\u884c\u4e3a\u9009\u62e9\u5668\uff0c\u52a8\u6001\u5207\u6362\u5206\u6790\u6027\u8f68\u8ff9\u89c4\u5212\u5668\u7684\u6210\u672c\u51fd\u6570\u53c2\u6570\uff0c\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u8d5b\u8f66\u4e2d\u9759\u6001\u6743\u91cd\u89c4\u5212\u5668\u7684\u6218\u672f\u59a5\u534f\u95ee\u9898\u3002", "motivation": "\u57fa\u4e8e\u91c7\u6837\u7684\u8f68\u8ff9\u89c4\u5212\u5668\u5728\u81ea\u52a8\u9a7e\u9a76\u8d5b\u8f66\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u884c\u4e3a\u7531\u624b\u52a8\u8c03\u4f18\u7684\u9759\u6001\u6743\u91cd\u6210\u672c\u51fd\u6570\u63a7\u5236\uff0c\u8fd9\u5728\u5404\u79cd\u6bd4\u8d5b\u573a\u666f\u4e2d\u4f1a\u8feb\u4f7f\u6218\u672f\u59a5\u534f\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u4f5c\u4e3a\u9ad8\u5c42\u884c\u4e3a\u9009\u62e9\u5668\uff0c\u5728\u8fd0\u884c\u65f6\u52a8\u6001\u5207\u6362\u5206\u6790\u6027\u4f4e\u5c42\u8f68\u8ff9\u89c4\u5212\u5668\u7684\u6210\u672c\u51fd\u6570\u53c2\u6570\u3002", "result": "\u5728\u81ea\u52a8\u9a7e\u9a76\u8d5b\u8f66\u6a21\u62df\u73af\u5883\u4e2d\uff0cRL\u89c4\u5212\u5668\u5b9e\u73b0\u4e860%\u78b0\u649e\u7387\uff0c\u540c\u65f6\u5c06\u8d85\u8f66\u65f6\u95f4\u51cf\u5c11\u9ad8\u8fbe60%\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u9759\u6001\u89c4\u5212\u5668\u3002", "conclusion": "\u5c06\u5f3a\u5316\u5b66\u4e60\u4f5c\u4e3a\u9ad8\u5c42\u9009\u62e9\u5668\u96c6\u6210\uff0c\u89e3\u51b3\u4e86\u81ea\u52a8\u9a7e\u9a76\u8d5b\u8f66\u89c4\u5212\u5668\u4e2d\u5b89\u5168\u6027\u4e0e\u7ade\u4e89\u529b\u4e4b\u95f4\u7684\u56fa\u6709\u6743\u8861\uff0c\u4e3a\u66f4\u5e7f\u6cdb\u7684\u81ea\u52a8\u9a7e\u9a76\u5e94\u7528\u63d0\u4f9b\u4e86\u81ea\u9002\u5e94\u4e14\u53ef\u89e3\u91ca\u7684\u8fd0\u52a8\u89c4\u5212\u8def\u5f84\u3002"}}
{"id": "2510.10592", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.10592", "abs": "https://arxiv.org/abs/2510.10592", "authors": ["Hong Su"], "title": "A Layered Intuition -- Method Model with Scope Extension for LLM Reasoning", "comment": null, "summary": "Existing studies have introduced method-based reasoning and scope extension\nas approaches to enhance Large Language Model (LLM) performance beyond direct\nmatrix mappings. Building on these foundations, this paper summarizes and\nintegrates these ideas into a unified Intuition-Method Layered Model with Scope\nExtension, designed to address indirected (unseen) issues more systematically.\nIn this framework, intuition-based thinking provides rapid first-reaction\nanswers, while method-based thinking decouples questions and solutions into\ntransferable reasoning units. Scope extension is then applied to broaden\napplicability, including vertical (cause analysis), horizontal (parallel and\ngeneralized issues), and for the first time, temporal and spatial extensions,\nwhich expand reasoning across time and contextual dimensions. These extensions\nare organized into systematic knowledge trees that interconnect into a\nknowledge network, thereby increasing adaptability. To quantitatively evaluate\nthis process, we propose the entropy of method extension, which measures the\nindependence and diversity of extensions as an indicator of the system's\ncapacity to solve unseen questions. By logically connecting existing approaches\nwith new extensions and introducing an entropy-based evaluation framework, this\nwork advances toward a more robust and extensible reasoning paradigm for LLMs\nin real-world problem-solving.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u76f4\u89c9-\u65b9\u6cd5\u5206\u5c42\u6a21\u578b\u4e0e\u8303\u56f4\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u76f4\u89c9\u601d\u7ef4\u63d0\u4f9b\u5feb\u901f\u521d\u59cb\u7b54\u6848\uff0c\u65b9\u6cd5\u601d\u7ef4\u5c06\u95ee\u9898\u89e3\u8026\u4e3a\u53ef\u8f6c\u79fb\u63a8\u7406\u5355\u5143\uff0c\u5e76\u5f15\u5165\u5782\u76f4\u3001\u6c34\u5e73\u3001\u65f6\u95f4\u548c\u7a7a\u95f4\u6269\u5c55\u6765\u589e\u5f3aLLM\u5904\u7406\u672a\u89c1\u95ee\u9898\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660e\u57fa\u4e8e\u65b9\u6cd5\u7684\u63a8\u7406\u548c\u8303\u56f4\u6269\u5c55\u53ef\u4ee5\u63d0\u5347LLM\u6027\u80fd\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u5316\u6574\u5408\u3002\u672c\u6587\u65e8\u5728\u5c06\u8fd9\u4e9b\u65b9\u6cd5\u7edf\u4e00\u5230\u4e00\u4e2a\u6846\u67b6\u4e2d\uff0c\u66f4\u7cfb\u7edf\u5730\u89e3\u51b3\u95f4\u63a5\uff08\u672a\u89c1\uff09\u95ee\u9898\u3002", "method": "\u6784\u5efa\u76f4\u89c9-\u65b9\u6cd5\u5206\u5c42\u6a21\u578b\uff1a\u76f4\u89c9\u5c42\u63d0\u4f9b\u5feb\u901f\u53cd\u5e94\uff0c\u65b9\u6cd5\u5c42\u5c06\u95ee\u9898\u89e3\u8026\u4e3a\u53ef\u8f6c\u79fb\u63a8\u7406\u5355\u5143\u3002\u5f15\u5165\u5782\u76f4\uff08\u56e0\u679c\u5206\u6790\uff09\u3001\u6c34\u5e73\uff08\u5e76\u884c\u548c\u6cdb\u5316\u95ee\u9898\uff09\u3001\u65f6\u95f4\u548c\u7a7a\u95f4\u56db\u79cd\u8303\u56f4\u6269\u5c55\uff0c\u7ec4\u7ec7\u6210\u7cfb\u7edf\u77e5\u8bc6\u6811\u5e76\u8fde\u63a5\u6210\u77e5\u8bc6\u7f51\u7edc\u3002", "result": "\u63d0\u51fa\u4e86\u65b9\u6cd5\u6269\u5c55\u71b5\u4f5c\u4e3a\u5b9a\u91cf\u8bc4\u4f30\u6307\u6807\uff0c\u8861\u91cf\u6269\u5c55\u7684\u72ec\u7acb\u6027\u548c\u591a\u6837\u6027\uff0c\u4ee5\u6b64\u8bc4\u4f30\u7cfb\u7edf\u89e3\u51b3\u672a\u89c1\u95ee\u9898\u7684\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u903b\u8f91\u8fde\u63a5\u73b0\u6709\u65b9\u6cd5\u5e76\u5f15\u5165\u65b0\u7684\u6269\u5c55\u548c\u57fa\u4e8e\u71b5\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u672c\u6587\u63a8\u8fdb\u4e86LLM\u5728\u73b0\u5b9e\u95ee\u9898\u89e3\u51b3\u4e2d\u66f4\u9c81\u68d2\u548c\u53ef\u6269\u5c55\u7684\u63a8\u7406\u8303\u5f0f\u3002"}}
{"id": "2510.11583", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.11583", "abs": "https://arxiv.org/abs/2510.11583", "authors": ["Siddhartha Upadhyay", "Ratnangshu Das", "Pushpak Jagtap"], "title": "Smooth Spatiotemporal Tube Synthesis for Prescribed-Time Reach-Avoid-Stay Control", "comment": null, "summary": "In this work, we address the issue of controller synthesis for a\ncontrol-affine nonlinear system to meet prescribed time reach-avoid-stay\nspecifications. Our goal is to improve upon previous methods based on\nspatiotemporal tubes (STTs) by eliminating the need for circumvent functions,\nwhich often lead to abrupt tube modifications and high control effort. We\npropose an adaptive framework that constructs smooth STTs around static unsafe\nsets, enabling continuous avoidance while guiding the system toward the target\nwithin the prescribed time. A closed-form, approximation-free control law is\nderived to ensure the system trajectory remains within the tube and satisfies\nthe RAS task. The effectiveness of the proposed approach is demonstrated\nthrough a case study, showing a significant reduction in control effort\ncompared to prior methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u7528\u4e8e\u63a7\u5236\u4eff\u5c04\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u63a7\u5236\u5668\u5408\u6210\uff0c\u6ee1\u8db3\u89c4\u5b9a\u65f6\u95f4\u7684\u5230\u8fbe-\u907f\u969c-\u505c\u7559\u89c4\u8303\uff0c\u65e0\u9700\u4f7f\u7528\u89c4\u907f\u51fd\u6570\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u63a7\u5236\u80fd\u8017\u3002", "motivation": "\u6539\u8fdb\u57fa\u4e8e\u65f6\u7a7a\u7ba1\u9053\u7684\u73b0\u6709\u65b9\u6cd5\uff0c\u6d88\u9664\u5bf9\u89c4\u907f\u51fd\u6570\u7684\u9700\u6c42\uff0c\u907f\u514d\u7ba1\u9053\u7a81\u53d8\u548c\u9ad8\u63a7\u5236\u80fd\u8017\u95ee\u9898\u3002", "method": "\u6784\u5efa\u56f4\u7ed5\u9759\u6001\u4e0d\u5b89\u5168\u96c6\u7684\u5e73\u6ed1\u65f6\u7a7a\u7ba1\u9053\uff0c\u63a8\u5bfc\u51fa\u5c01\u95ed\u5f62\u5f0f\u3001\u65e0\u8fd1\u4f3c\u7684\u63a7\u5236\u5f8b\uff0c\u786e\u4fdd\u7cfb\u7edf\u8f68\u8ff9\u4fdd\u6301\u5728\u7ba1\u9053\u5185\u5e76\u6ee1\u8db3RAS\u4efb\u52a1\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u76f8\u6bd4\u5148\u524d\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u63a7\u5236\u80fd\u8017\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u6846\u67b6\u80fd\u591f\u5728\u4e0d\u4f7f\u7528\u89c4\u907f\u51fd\u6570\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u8fde\u7eed\u907f\u969c\u5e76\u5f15\u5bfc\u7cfb\u7edf\u5728\u89c4\u5b9a\u65f6\u95f4\u5185\u5230\u8fbe\u76ee\u6807\uff0c\u540c\u65f6\u4fdd\u6301\u5e73\u6ed1\u7684\u7ba1\u9053\u548c\u8f83\u4f4e\u7684\u63a7\u5236\u80fd\u8017\u3002"}}
{"id": "2510.10597", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10597", "abs": "https://arxiv.org/abs/2510.10597", "authors": ["David Rodr\u00edguez-Mart\u00ednez", "C. J. P\u00e9rez del Pulgar"], "title": "Fast Vision in the Dark: A Case for Single-Photon Imaging in Planetary Navigation", "comment": "9 pages, 6 figures, conference paper", "summary": "Improving robotic navigation is critical for extending exploration range and\nenhancing operational efficiency. Vision-based navigation relying on\ntraditional CCD or CMOS cameras faces major challenges when complex\nillumination conditions are paired with motion, limiting the range and\naccessibility of mobile planetary robots. In this study, we propose a novel\napproach to planetary navigation that leverages the unique imaging capabilities\nof Single-Photon Avalanche Diode (SPAD) cameras. We present the first\ncomprehensive evaluation of single-photon imaging as an alternative passive\nsensing technology for robotic exploration missions targeting perceptually\nchallenging locations, with a special emphasis on high-latitude lunar regions.\nWe detail the operating principles and performance characteristics of SPAD\ncameras, assess their advantages and limitations in addressing key perception\nchallenges of upcoming exploration missions to the Moon, and benchmark their\nperformance under representative illumination conditions.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u5355\u5149\u5b50\u96ea\u5d29\u4e8c\u6781\u7ba1\uff08SPAD\uff09\u76f8\u673a\u4f5c\u4e3a\u66ff\u4ee3\u88ab\u52a8\u4f20\u611f\u6280\u672f\uff0c\u7528\u4e8e\u884c\u661f\u5bfc\u822a\uff0c\u7279\u522b\u9488\u5bf9\u9ad8\u7eac\u5ea6\u6708\u7403\u533a\u57df\u7684\u6311\u6218\u6027\u73af\u5883\u3002", "motivation": "\u4f20\u7edfCCD\u6216CMOS\u76f8\u673a\u5728\u590d\u6742\u5149\u7167\u6761\u4ef6\u548c\u8fd0\u52a8\u60c5\u51b5\u4e0b\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u9650\u5236\u4e86\u79fb\u52a8\u884c\u661f\u673a\u5668\u4eba\u7684\u63a2\u6d4b\u8303\u56f4\u548c\u53ef\u8bbf\u95ee\u6027\u3002", "method": "\u5229\u7528SPAD\u76f8\u673a\u7684\u72ec\u7279\u6210\u50cf\u80fd\u529b\uff0c\u8be6\u7ec6\u9610\u8ff0\u5176\u5de5\u4f5c\u539f\u7406\u548c\u6027\u80fd\u7279\u5f81\uff0c\u8bc4\u4f30\u5176\u5728\u89e3\u51b3\u6708\u7403\u63a2\u6d4b\u5173\u952e\u611f\u77e5\u6311\u6218\u4e2d\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\u3002", "result": "\u5728\u4ee3\u8868\u6027\u5149\u7167\u6761\u4ef6\u4e0b\u5bf9SPAD\u76f8\u673a\u6027\u80fd\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc1\u660e\u5176\u4f5c\u4e3a\u884c\u661f\u5bfc\u822a\u66ff\u4ee3\u6280\u672f\u7684\u6f5c\u529b\u3002", "conclusion": "SPAD\u76f8\u673a\u4e3a\u89e3\u51b3\u884c\u661f\u5bfc\u822a\u4e2d\u7684\u611f\u77e5\u6311\u6218\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7eac\u5ea6\u6708\u7403\u533a\u57df\u7b49\u5177\u6709\u6311\u6218\u6027\u7684\u73af\u5883\u4e2d\u3002"}}
{"id": "2510.10596", "categories": ["cs.AI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.10596", "abs": "https://arxiv.org/abs/2510.10596", "authors": ["Ruolan Cheng", "Yong Deng", "Seraf\u00edn Moral", "Jos\u00e9 Ram\u00f3n Trillo"], "title": "A Distance Measure for Random Permutation Set: From the Layer-2 Belief Structure Perspective", "comment": null, "summary": "Random permutation set (RPS) is a recently proposed framework designed to\nrepresent order-structured uncertain information. Measuring the distance\nbetween permutation mass functions is a key research topic in RPS theory\n(RPST). This paper conducts an in-depth analysis of distances between RPSs from\ntwo different perspectives: random finite set (RFS) and transferable belief\nmodel (TBM). Adopting the layer-2 belief structure interpretation of RPS, we\nregard RPST as a refinement of TBM, where the order in the ordered focus set\nrepresents qualitative propensity. Starting from the permutation, we introduce\na new definition of the cumulative Jaccard index to quantify the similarity\nbetween two permutations and further propose a distance measure method for RPSs\nbased on the cumulative Jaccard index matrix. The metric and structural\nproperties of the proposed distance measure are investigated, including the\npositive definiteness analysis of the cumulative Jaccard index matrix, and a\ncorrection scheme is provided. The proposed method has a natural\ntop-weightiness property: inconsistencies between higher-ranked elements tend\nto result in greater distance values. Two parameters are provided to the\ndecision-maker to adjust the weight and truncation depth. Several numerical\nexamples are used to compare the proposed method with the existing method. The\nexperimental results show that the proposed method not only overcomes the\nshortcomings of the existing method and is compatible with the Jousselme\ndistance, but also has higher sensitivity and flexibility.", "AI": {"tldr": "\u672c\u6587\u4ece\u968f\u673a\u6709\u9650\u96c6\u548c\u53ef\u8f6c\u79fb\u4fe1\u5ff5\u6a21\u578b\u4e24\u4e2a\u89d2\u5ea6\u6df1\u5165\u5206\u6790\u4e86\u968f\u673a\u7f6e\u6362\u96c6\u4e4b\u95f4\u7684\u8ddd\u79bb\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u7d2f\u79efJaccard\u6307\u6570\u7684\u8ddd\u79bb\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5177\u6709\u81ea\u7136\u7684\u4e0a\u6743\u91cd\u7279\u6027\u3002", "motivation": "\u968f\u673a\u7f6e\u6362\u96c6\u662f\u8868\u793a\u6709\u5e8f\u7ed3\u6784\u4e0d\u786e\u5b9a\u4fe1\u606f\u7684\u65b0\u6846\u67b6\uff0c\u6d4b\u91cf\u7f6e\u6362\u8d28\u91cf\u51fd\u6570\u4e4b\u95f4\u7684\u8ddd\u79bb\u662fRPS\u7406\u8bba\u7684\u5173\u952e\u7814\u7a76\u8bfe\u9898\u3002", "method": "\u91c7\u7528RPS\u7684\u5c42-2\u4fe1\u5ff5\u7ed3\u6784\u89e3\u91ca\uff0c\u4ece\u7f6e\u6362\u51fa\u53d1\u5f15\u5165\u7d2f\u79efJaccard\u6307\u6570\u7684\u65b0\u5b9a\u4e49\u6765\u91cf\u5316\u4e24\u4e2a\u7f6e\u6362\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u5e76\u57fa\u4e8e\u7d2f\u79efJaccard\u6307\u6570\u77e9\u9635\u63d0\u51faRPS\u7684\u8ddd\u79bb\u5ea6\u91cf\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u7f3a\u70b9\uff0c\u4e0eJousselme\u8ddd\u79bb\u517c\u5bb9\uff0c\u5e76\u5177\u6709\u66f4\u9ad8\u7684\u654f\u611f\u6027\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "\u57fa\u4e8e\u7d2f\u79efJaccard\u6307\u6570\u7684\u8ddd\u79bb\u5ea6\u91cf\u65b9\u6cd5\u4e3aRPS\u7406\u8bba\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8ddd\u79bb\u6d4b\u91cf\u5de5\u5177\uff0c\u5177\u6709\u81ea\u7136\u7684\u4e0a\u6743\u91cd\u7279\u6027\u548c\u53ef\u8c03\u53c2\u6570\u3002"}}
{"id": "2510.11692", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.11692", "abs": "https://arxiv.org/abs/2510.11692", "authors": ["Samuel G. Gessow", "Brett T. Lopez"], "title": "Analysis of the Geometric Heat Flow Equation: Computing Geodesics in Real-Time with Convergence Guarantees", "comment": null, "summary": "We present an analysis on the convergence properties of the so-called\ngeometric heat flow equation for computing geodesics (shortest-path~curves) on\nRiemannian manifolds. Computing geodesics numerically in real-time has become\nan important capability in several fields, including control and motion\nplanning. The geometric heat flow equation involves solving a parabolic partial\ndifferential equation whose solution is a geodesic. In practice, solving this\nPDE numerically can be done efficiently, and tends to be more numerically\nstable and exhibit a better rate of convergence compared to numerical\noptimization. We prove that the geometric heat flow equation is globally\nexponentially stable in $L_2$ if the curvature of the Riemannian manifold is\nnot too positive, and that asymptotic convergence in $L_2$ is always\nguaranteed. We also present a pseudospectral method that leverages Chebyshev\npolynomials to accurately compute geodesics in only a few milliseconds for\nnon-contrived manifolds. Our analysis was verified with our custom\npseudospectral method by computing geodesics on common non-Euclidean surfaces,\nand in feedback for a contraction-based controller with a non-flat metric for a\nnonlinear system.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u9ece\u66fc\u6d41\u5f62\u4e0a\u8ba1\u7b97\u6d4b\u5730\u7ebf\u7684\u51e0\u4f55\u70ed\u6d41\u65b9\u7a0b\u7684\u6536\u655b\u6027\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u7a0b\u5728\u66f2\u7387\u4e0d\u8fc7\u4e8e\u6b63\u65f6\u7684\u5168\u5c40\u6307\u6570\u7a33\u5b9a\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8eChebyshev\u591a\u9879\u5f0f\u7684\u4f2a\u8c31\u65b9\u6cd5\u5feb\u901f\u8ba1\u7b97\u6d4b\u5730\u7ebf\u3002", "motivation": "\u5b9e\u65f6\u6570\u503c\u8ba1\u7b97\u6d4b\u5730\u7ebf\u5728\u63a7\u5236\u548c\u8fd0\u52a8\u89c4\u5212\u7b49\u9886\u57df\u53d8\u5f97\u91cd\u8981\uff0c\u51e0\u4f55\u70ed\u6d41\u65b9\u7a0b\u76f8\u6bd4\u6570\u503c\u4f18\u5316\u65b9\u6cd5\u66f4\u7a33\u5b9a\u4e14\u6536\u655b\u66f4\u5feb\u3002", "method": "\u4f7f\u7528\u51e0\u4f55\u70ed\u6d41\u65b9\u7a0b\u6c42\u89e3\u629b\u7269\u578b\u504f\u5fae\u5206\u65b9\u7a0b\u6765\u8ba1\u7b97\u6d4b\u5730\u7ebf\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8eChebyshev\u591a\u9879\u5f0f\u7684\u4f2a\u8c31\u65b9\u6cd5\u8fdb\u884c\u9ad8\u6548\u6570\u503c\u8ba1\u7b97\u3002", "result": "\u8bc1\u660e\u4e86\u5f53\u9ece\u66fc\u6d41\u5f62\u66f2\u7387\u4e0d\u8fc7\u4e8e\u6b63\u65f6\uff0c\u51e0\u4f55\u70ed\u6d41\u65b9\u7a0b\u5728L2\u8303\u6570\u4e0b\u5168\u5c40\u6307\u6570\u7a33\u5b9a\uff0c\u4e14L2\u6e10\u8fd1\u6536\u655b\u603b\u662f\u4fdd\u8bc1\u7684\u3002\u4f2a\u8c31\u65b9\u6cd5\u80fd\u5728\u51e0\u6beb\u79d2\u5185\u51c6\u786e\u8ba1\u7b97\u975e\u5e73\u51e1\u6d41\u5f62\u4e0a\u7684\u6d4b\u5730\u7ebf\u3002", "conclusion": "\u51e0\u4f55\u70ed\u6d41\u65b9\u7a0b\u662f\u8ba1\u7b97\u6d4b\u5730\u7ebf\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u5177\u6709\u7406\u8bba\u6536\u655b\u4fdd\u8bc1\u548c\u5b9e\u9645\u8ba1\u7b97\u6548\u7387\uff0c\u5df2\u6210\u529f\u5e94\u7528\u4e8e\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u63a7\u5236\u8bbe\u8ba1\u4e2d\u3002"}}
{"id": "2510.10602", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.10602", "abs": "https://arxiv.org/abs/2510.10602", "authors": ["Zhuoheng Gao", "Jiyao Zhang", "Zhiyong Xie", "Hao Dong", "Zhaofei Yu", "Rongmei Chen", "Guozhang Chen", "Tiejun Huang"], "title": "SpikeGrasp: A Benchmark for 6-DoF Grasp Pose Detection from Stereo Spike Streams", "comment": null, "summary": "Most robotic grasping systems rely on converting sensor data into explicit 3D\npoint clouds, which is a computational step not found in biological\nintelligence. This paper explores a fundamentally different, neuro-inspired\nparadigm for 6-DoF grasp detection. We introduce SpikeGrasp, a framework that\nmimics the biological visuomotor pathway, processing raw, asynchronous events\nfrom stereo spike cameras, similarly to retinas, to directly infer grasp poses.\nOur model fuses these stereo spike streams and uses a recurrent spiking neural\nnetwork, analogous to high-level visual processing, to iteratively refine grasp\nhypotheses without ever reconstructing a point cloud. To validate this\napproach, we built a large-scale synthetic benchmark dataset. Experiments show\nthat SpikeGrasp surpasses traditional point-cloud-based baselines, especially\nin cluttered and textureless scenes, and demonstrates remarkable data\nefficiency. By establishing the viability of this end-to-end, neuro-inspired\napproach, SpikeGrasp paves the way for future systems capable of the fluid and\nefficient manipulation seen in nature, particularly for dynamic objects.", "AI": {"tldr": "SpikeGrasp\u662f\u4e00\u4e2a\u795e\u7ecf\u542f\u53d1\u76846\u81ea\u7531\u5ea6\u6293\u53d6\u68c0\u6d4b\u6846\u67b6\uff0c\u76f4\u63a5\u5904\u7406\u6765\u81ea\u7acb\u4f53\u8109\u51b2\u76f8\u673a\u7684\u5f02\u6b65\u4e8b\u4ef6\u6570\u636e\uff0c\u65e0\u9700\u6784\u5efa3D\u70b9\u4e91\uff0c\u5728\u6742\u4e71\u548c\u65e0\u7eb9\u7406\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5927\u591a\u6570\u673a\u5668\u4eba\u6293\u53d6\u7cfb\u7edf\u4f9d\u8d56\u5c06\u4f20\u611f\u5668\u6570\u636e\u8f6c\u6362\u4e3a\u663e\u5f0f3D\u70b9\u4e91\uff0c\u8fd9\u4e0e\u751f\u7269\u667a\u80fd\u7684\u5904\u7406\u65b9\u5f0f\u4e0d\u540c\u3002\u672c\u6587\u63a2\u7d22\u4e00\u79cd\u6839\u672c\u4e0d\u540c\u7684\u795e\u7ecf\u542f\u53d1\u8303\u5f0f\uff0c\u6a21\u4eff\u751f\u7269\u89c6\u89c9\u8fd0\u52a8\u901a\u8def\u3002", "method": "\u5f15\u5165SpikeGrasp\u6846\u67b6\uff0c\u5904\u7406\u6765\u81ea\u7acb\u4f53\u8109\u51b2\u76f8\u673a\u7684\u539f\u59cb\u5f02\u6b65\u4e8b\u4ef6\uff0c\u4f7f\u7528\u5faa\u73af\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u878d\u5408\u7acb\u4f53\u8109\u51b2\u6d41\uff0c\u8fed\u4ee3\u4f18\u5316\u6293\u53d6\u5047\u8bbe\u800c\u4e0d\u91cd\u5efa\u70b9\u4e91\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSpikeGrasp\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u57fa\u4e8e\u70b9\u4e91\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u6742\u4e71\u548c\u65e0\u7eb9\u7406\u573a\u666f\u4e2d\uff0c\u5e76\u5c55\u73b0\u51fa\u663e\u8457\u7684\u6570\u636e\u6548\u7387\u3002", "conclusion": "SpikeGrasp\u786e\u7acb\u4e86\u8fd9\u79cd\u7aef\u5230\u7aef\u795e\u7ecf\u542f\u53d1\u65b9\u6cd5\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u672a\u6765\u80fd\u591f\u5b9e\u73b0\u81ea\u7136\u754c\u4e2d\u6d41\u7545\u9ad8\u6548\u64cd\u4f5c\u7684\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u52a8\u6001\u7269\u4f53\u3002"}}
{"id": "2510.10603", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10603", "abs": "https://arxiv.org/abs/2510.10603", "authors": ["WenTao Liu", "Siyu Song", "Hao Hao", "Aimin Zhou"], "title": "EA4LLM: A Gradient-Free Approach to Large Language Model Optimization via Evolutionary Algorithms", "comment": null, "summary": "In recent years, large language models (LLMs) have made remarkable progress,\nwith model optimization primarily relying on gradient-based optimizers such as\nAdam. However, these gradient-based methods impose stringent hardware\nrequirements, demanding high-concurrency, high-memory GPUs. Moreover, they\nrequire all neural network operations to be differentiable, thereby excluding\nmany promising non-differentiable architectures from practical use. To address\nthese limitations, we propose a method for optimizing LLMs using evolutionary\nalgorithms (EA4LLM) and, for the first time, successfully demonstrate its\ncapability to train a 1-billion-parameter LLM from the pre-trained stage. We\nconduct extensive experiments and provide key insights into how evolutionary\nalgorithms can effectively optimize neural networks. Our work challenges the\nprevailing assumption that gradient-based optimization is the only viable\napproach for training neural networks. It also holds significant potential to\nreduce the computational cost of training large language models, thereby\nenabling groups with limited computational resources to participate in deep\nlearning research.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u8fdb\u5316\u7b97\u6cd5\u4f18\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff08EA4LLM\uff09\uff0c\u9996\u6b21\u6210\u529f\u8bad\u7ec3\u4e8610\u4ebf\u53c2\u6570\u6a21\u578b\uff0c\u6311\u6218\u4e86\u68af\u5ea6\u4f18\u5316\u662f\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u552f\u4e00\u53ef\u884c\u65b9\u6cd5\u7684\u666e\u904d\u5047\u8bbe\u3002", "motivation": "\u89e3\u51b3\u57fa\u4e8e\u68af\u5ea6\u7684\u4f18\u5316\u65b9\u6cd5\u5bf9\u786c\u4ef6\u8981\u6c42\u4e25\u683c\u3001\u9700\u8981\u9ad8\u5e76\u53d1\u9ad8\u5185\u5b58GPU\uff0c\u4ee5\u53ca\u8981\u6c42\u6240\u6709\u795e\u7ecf\u7f51\u7edc\u64cd\u4f5c\u53ef\u5fae\u5206\u7684\u95ee\u9898\uff0c\u4f7f\u8bb8\u591a\u6709\u524d\u666f\u7684\u4e0d\u53ef\u5fae\u5206\u67b6\u6784\u80fd\u591f\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u4f7f\u7528\u8fdb\u5316\u7b97\u6cd5\u4f18\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4ece\u9884\u8bad\u7ec3\u9636\u6bb5\u5f00\u59cb\u8bad\u7ec310\u4ebf\u53c2\u6570\u6a21\u578b\u3002", "result": "\u6210\u529f\u8bad\u7ec3\u4e8610\u4ebf\u53c2\u6570\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5e7f\u6cdb\u5b9e\u9a8c\u63d0\u4f9b\u4e86\u8fdb\u5316\u7b97\u6cd5\u5982\u4f55\u6709\u6548\u4f18\u5316\u795e\u7ecf\u7f51\u7edc\u7684\u5173\u952e\u89c1\u89e3\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6311\u6218\u4e86\u68af\u5ea6\u4f18\u5316\u662f\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u552f\u4e00\u53ef\u884c\u65b9\u6cd5\u7684\u5047\u8bbe\uff0c\u5177\u6709\u663e\u8457\u964d\u4f4e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u8ba1\u7b97\u6210\u672c\u7684\u6f5c\u529b\uff0c\u4f7f\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u7684\u7fa4\u4f53\u80fd\u591f\u53c2\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7814\u7a76\u3002"}}
{"id": "2510.10637", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10637", "abs": "https://arxiv.org/abs/2510.10637", "authors": ["Haoyu Zhao", "Cheng Zeng", "Linghao Zhuang", "Yaxi Zhao", "Shengke Xue", "Hao Wang", "Xingyue Zhao", "Zhongyu Li", "Kehan Li", "Siteng Huang", "Mingxiu Chen", "Xin Li", "Deli Zhao", "Hua Zou"], "title": "High-Fidelity Simulated Data Generation for Real-World Zero-Shot Robotic Manipulation Learning with Gaussian Splatting", "comment": "13 pages, 6 figures", "summary": "The scalability of robotic learning is fundamentally bottlenecked by the\nsignificant cost and labor of real-world data collection. While simulated data\noffers a scalable alternative, it often fails to generalize to the real world\ndue to significant gaps in visual appearance, physical properties, and object\ninteractions. To address this, we propose RoboSimGS, a novel Real2Sim2Real\nframework that converts multi-view real-world images into scalable,\nhigh-fidelity, and physically interactive simulation environments for robotic\nmanipulation. Our approach reconstructs scenes using a hybrid representation:\n3D Gaussian Splatting (3DGS) captures the photorealistic appearance of the\nenvironment, while mesh primitives for interactive objects ensure accurate\nphysics simulation. Crucially, we pioneer the use of a Multi-modal Large\nLanguage Model (MLLM) to automate the creation of physically plausible,\narticulated assets. The MLLM analyzes visual data to infer not only physical\nproperties (e.g., density, stiffness) but also complex kinematic structures\n(e.g., hinges, sliding rails) of objects. We demonstrate that policies trained\nentirely on data generated by RoboSimGS achieve successful zero-shot\nsim-to-real transfer across a diverse set of real-world manipulation tasks.\nFurthermore, data from RoboSimGS significantly enhances the performance and\ngeneralization capabilities of SOTA methods. Our results validate RoboSimGS as\na powerful and scalable solution for bridging the sim-to-real gap.", "AI": {"tldr": "RoboSimGS\u662f\u4e00\u4e2aReal2Sim2Real\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u521b\u5efa\u7269\u7406\u4ea4\u4e92\u5f0f\u4eff\u771f\u73af\u5883\uff0c\u5b9e\u73b0\u96f6\u6837\u672c\u7684\u6a21\u62df\u5230\u771f\u5b9e\u4e16\u754c\u8fc1\u79fb\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u4eba\u5b66\u4e60\u4e2d\u771f\u5b9e\u4e16\u754c\u6570\u636e\u6536\u96c6\u6210\u672c\u9ad8\u3001\u6a21\u62df\u6570\u636e\u96be\u4ee5\u6cdb\u5316\u5230\u771f\u5b9e\u4e16\u754c\u7684\u95ee\u9898\uff0c\u7f29\u5c0f\u89c6\u89c9\u5916\u89c2\u3001\u7269\u7406\u5c5e\u6027\u548c\u7269\u4f53\u4ea4\u4e92\u65b9\u9762\u7684\u5dee\u8ddd\u3002", "method": "\u4f7f\u7528\u6df7\u5408\u8868\u793a\u65b9\u6cd5\uff1a3D\u9ad8\u65af\u6e85\u5c04\u6355\u6349\u73af\u5883\u7684\u5149\u7167\u771f\u5b9e\u611f\uff0c\u7f51\u683c\u57fa\u5143\u786e\u4fdd\u51c6\u786e\u7684\u7269\u7406\u6a21\u62df\uff1b\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u63a8\u65ad\u7269\u4f53\u7684\u7269\u7406\u5c5e\u6027\u548c\u8fd0\u52a8\u5b66\u7ed3\u6784\u3002", "result": "\u5728RoboSimGS\u751f\u6210\u7684\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u7b56\u7565\u5b9e\u73b0\u4e86\u6210\u529f\u7684\u96f6\u6837\u672c\u6a21\u62df\u5230\u771f\u5b9e\u4e16\u754c\u8fc1\u79fb\uff0c\u5e76\u80fd\u663e\u8457\u63d0\u5347\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "RoboSimGS\u662f\u7f29\u5c0f\u6a21\u62df\u5230\u771f\u5b9e\u4e16\u754c\u5dee\u8ddd\u7684\u5f3a\u5927\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.10633", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10633", "abs": "https://arxiv.org/abs/2510.10633", "authors": ["Jiabao Shi", "Minfeng Qi", "Lefeng Zhang", "Di Wang", "Yingjie Zhao", "Ziying Li", "Yalong Xing", "Ningran Li"], "title": "Collaborative Text-to-Image Generation via Multi-Agent Reinforcement Learning and Semantic Fusion", "comment": "16 pages, 13 figures", "summary": "Multimodal text-to-image generation remains constrained by the difficulty of\nmaintaining semantic alignment and professional-level detail across diverse\nvisual domains. We propose a multi-agent reinforcement learning framework that\ncoordinates domain-specialized agents (e.g., focused on architecture,\nportraiture, and landscape imagery) within two coupled subsystems: a text\nenhancement module and an image generation module, each augmented with\nmultimodal integration components. Agents are trained using Proximal Policy\nOptimization (PPO) under a composite reward function that balances semantic\nsimilarity, linguistic visual quality, and content diversity. Cross-modal\nalignment is enforced through contrastive learning, bidirectional attention,\nand iterative feedback between text and image. Across six experimental\nsettings, our system significantly enriches generated content (word count\nincreased by 1614%) while reducing ROUGE-1 scores by 69.7%. Among fusion\nmethods, Transformer-based strategies achieve the highest composite score\n(0.521), despite occasional stability issues. Multimodal ensembles yield\nmoderate consistency (ranging from 0.444 to 0.481), reflecting the persistent\nchallenges of cross-modal semantic grounding. These findings underscore the\npromise of collaborative, specialization-driven architectures for advancing\nreliable multimodal generative systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u591a\u6a21\u6001\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u9886\u57df\u4e13\u4e1a\u5316\u667a\u80fd\u4f53\u534f\u4f5c\u63d0\u5347\u8bed\u4e49\u5bf9\u9f50\u548c\u7ec6\u8282\u8d28\u91cf", "motivation": "\u89e3\u51b3\u591a\u6a21\u6001\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u4e2d\u8bed\u4e49\u5bf9\u9f50\u56f0\u96be\u548c\u4e13\u4e1a\u7ea7\u7ec6\u8282\u4fdd\u6301\u7684\u6311\u6218", "method": "\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u542b\u6587\u672c\u589e\u5f3a\u548c\u56fe\u50cf\u751f\u6210\u4e24\u4e2a\u8026\u5408\u5b50\u7cfb\u7edf\uff0c\u91c7\u7528PPO\u7b97\u6cd5\u548c\u590d\u5408\u5956\u52b1\u51fd\u6570\uff0c\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u3001\u53cc\u5411\u6ce8\u610f\u529b\u548c\u8fed\u4ee3\u53cd\u9988", "result": "\u5728\u516d\u4e2a\u5b9e\u9a8c\u8bbe\u7f6e\u4e2d\u663e\u8457\u4e30\u5bcc\u751f\u6210\u5185\u5bb9\uff08\u8bcd\u6570\u589e\u52a01614%\uff09\uff0cROUGE-1\u5206\u6570\u964d\u4f4e69.7%\uff0cTransformer\u878d\u5408\u7b56\u7565\u83b7\u5f97\u6700\u9ad8\u7efc\u5408\u5f97\u52060.521", "conclusion": "\u534f\u4f5c\u5f0f\u3001\u4e13\u4e1a\u5316\u9a71\u52a8\u7684\u67b6\u6784\u5728\u63a8\u8fdb\u53ef\u9760\u591a\u6a21\u6001\u751f\u6210\u7cfb\u7edf\u65b9\u9762\u5177\u6709\u524d\u666f"}}
{"id": "2510.10642", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10642", "abs": "https://arxiv.org/abs/2510.10642", "authors": ["Jianke Zhang", "Yucheng Hu", "Yanjiang Guo", "Xiaoyu Chen", "Yichen Liu", "Wenna Chen", "Chaochao Lu", "Jianyu Chen"], "title": "UniCoD: Enhancing Robot Policy via Unified Continuous and Discrete Representation Learning", "comment": null, "summary": "Building generalist robot policies that can handle diverse tasks in\nopen-ended environments is a central challenge in robotics. To leverage\nknowledge from large-scale pretraining, prior work has typically built\ngeneralist policies either on top of vision-language understanding models\n(VLMs) or generative models. However, both semantic understanding from\nvision-language pretraining and visual dynamics modeling from visual-generation\npretraining are crucial for embodied robots. Recent unified models of\ngeneration and understanding have demonstrated strong capabilities in both\ncomprehension and generation through large-scale pretraining. We posit that\nrobotic policy learning can likewise benefit from the combined strengths of\nunderstanding, planning and continuous future representation learning. Building\non this insight, we introduce UniCoD, which acquires the ability to dynamically\nmodel high-dimensional visual features through pretraining on over 1M\ninternet-scale instructional manipulation videos. Subsequently, UniCoD is\nfine-tuned on data collected from the robot embodiment, enabling the learning\nof mappings from predictive representations to action tokens. Extensive\nexperiments show our approach consistently outperforms baseline methods in\nterms of 9\\% and 12\\% across simulation environments and real-world\nout-of-distribution tasks.", "AI": {"tldr": "UniCoD\u662f\u4e00\u4e2a\u673a\u5668\u4eba\u901a\u7528\u7b56\u7565\u6a21\u578b\uff0c\u901a\u8fc7\u5728\u5927\u89c4\u6a21\u6559\u5b66\u64cd\u4f5c\u89c6\u9891\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7ed3\u5408\u89c6\u89c9\u7406\u89e3\u548c\u751f\u6210\u80fd\u529b\uff0c\u5728\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u6784\u5efa\u80fd\u591f\u5904\u7406\u5f00\u653e\u73af\u5883\u4e2d\u591a\u6837\u5316\u4efb\u52a1\u7684\u901a\u7528\u673a\u5668\u4eba\u7b56\u7565\u662f\u673a\u5668\u4eba\u5b66\u7684\u6838\u5fc3\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u7406\u89e3\u6a21\u578b\uff0c\u8981\u4e48\u57fa\u4e8e\u751f\u6210\u6a21\u578b\uff0c\u4f46\u8bed\u4e49\u7406\u89e3\u548c\u89c6\u89c9\u52a8\u6001\u5efa\u6a21\u5bf9\u5177\u8eab\u673a\u5668\u4eba\u90fd\u81f3\u5173\u91cd\u8981\u3002", "method": "UniCoD\u5728\u8d85\u8fc7100\u4e07\u4e2a\u4e92\u8054\u7f51\u89c4\u6a21\u7684\u6559\u5b66\u64cd\u4f5c\u89c6\u9891\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u5b66\u4e60\u52a8\u6001\u5efa\u6a21\u9ad8\u7ef4\u89c6\u89c9\u7279\u5f81\uff0c\u7136\u540e\u5728\u673a\u5668\u4eba\u5177\u8eab\u6570\u636e\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u5b66\u4e60\u4ece\u9884\u6d4b\u8868\u793a\u5230\u52a8\u4f5ctoken\u7684\u6620\u5c04\u3002", "result": "\u5728\u4eff\u771f\u73af\u5883\u548c\u771f\u5b9e\u4e16\u754c\u5206\u5e03\u5916\u4efb\u52a1\u4e2d\uff0cUniCoD\u5206\u522b\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5e73\u5747\u63d0\u53479%\u548c12%\u7684\u6027\u80fd\u3002", "conclusion": "\u673a\u5668\u4eba\u7b56\u7565\u5b66\u4e60\u53ef\u4ee5\u4ece\u7406\u89e3\u3001\u89c4\u5212\u548c\u8fde\u7eed\u672a\u6765\u8868\u793a\u5b66\u4e60\u7684\u7ed3\u5408\u4e2d\u53d7\u76ca\uff0cUniCoD\u8bc1\u660e\u4e86\u8fd9\u79cd\u7edf\u4e00\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.10639", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10639", "abs": "https://arxiv.org/abs/2510.10639", "authors": ["Haemin Choi", "Gayathri Nadarajan"], "title": "Automatic Piecewise Linear Regression for Predicting Student Learning Satisfaction", "comment": null, "summary": "Although student learning satisfaction has been widely studied, modern\ntechniques such as interpretable machine learning and neural networks have not\nbeen sufficiently explored. This study demonstrates that a recent model that\ncombines boosting with interpretability, automatic piecewise linear\nregression(APLR), offers the best fit for predicting learning satisfaction\namong several state-of-the-art approaches. Through the analysis of APLR's\nnumerical and visual interpretations, students' time management and\nconcentration abilities, perceived helpfulness to classmates, and participation\nin offline courses have the most significant positive impact on learning\nsatisfaction. Surprisingly, involvement in creative activities did not\npositively affect learning satisfaction. Moreover, the contributing factors can\nbe interpreted on an individual level, allowing educators to customize\ninstructions according to student profiles.", "AI": {"tldr": "APLR\u6a21\u578b\u5728\u9884\u6d4b\u5b66\u4e60\u6ee1\u610f\u5ea6\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u53d1\u73b0\u65f6\u95f4\u7ba1\u7406\u3001\u4e13\u6ce8\u529b\u3001\u5e2e\u52a9\u540c\u5b66\u548c\u7ebf\u4e0b\u8bfe\u7a0b\u53c2\u4e0e\u5bf9\u5b66\u4e60\u6ee1\u610f\u5ea6\u6709\u663e\u8457\u6b63\u5411\u5f71\u54cd\uff0c\u800c\u521b\u610f\u6d3b\u52a8\u53c2\u4e0e\u65e0\u6b63\u9762\u5f71\u54cd\u3002", "motivation": "\u867d\u7136\u5b66\u751f\u6ee1\u610f\u5ea6\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u548c\u795e\u7ecf\u7f51\u7edc\u7b49\u73b0\u4ee3\u6280\u672f\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4f7f\u7528\u7ed3\u5408\u63d0\u5347\u548c\u53ef\u89e3\u91ca\u6027\u7684\u81ea\u52a8\u5206\u6bb5\u7ebf\u6027\u56de\u5f52(APLR)\u6a21\u578b\uff0c\u5e76\u4e0e\u51e0\u79cd\u6700\u5148\u8fdb\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "APLR\u6a21\u578b\u63d0\u4f9b\u4e86\u6700\u4f73\u62df\u5408\uff0c\u901a\u8fc7\u6570\u503c\u548c\u53ef\u89c6\u5316\u89e3\u91ca\u8bc6\u522b\u51fa\u5173\u952e\u5f71\u54cd\u56e0\u7d20\u3002", "conclusion": "\u5f71\u54cd\u56e0\u7d20\u53ef\u5728\u4e2a\u4f53\u5c42\u9762\u89e3\u91ca\uff0c\u4f7f\u6559\u80b2\u8005\u80fd\u591f\u6839\u636e\u5b66\u751f\u7279\u5f81\u5b9a\u5236\u6559\u5b66\u65b9\u6848\u3002"}}
{"id": "2510.10716", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10716", "abs": "https://arxiv.org/abs/2510.10716", "authors": ["Christopher Thierauf"], "title": "Deployment and Development of a Cognitive Teleoreactive Framework for Deep Sea Autonomy", "comment": null, "summary": "A new AUV mission planning and execution software has been tested on AUV\nSentry. Dubbed DINOS-R, it draws inspiration from cognitive architectures and\nAUV control systems to replace the legacy MC architecture. Unlike these\nexisting architectures, however, DINOS-R is built from the ground-up to unify\nsymbolic decision making (for understandable, repeatable, provable behavior)\nwith machine learning techniques and reactive behaviors, for field-readiness\nacross oceanographic platforms. Implemented primarily in Python3, DINOS-R is\nextensible, modular, and reusable, with an emphasis on non-expert use as well\nas growth for future research in oceanography and robot algorithms. Mission\nspecification is flexible, and can be specified declaratively. Behavior\nspecification is similarly flexible, supporting simultaneous use of real-time\ntask planning and hard-coded user specified plans. These features were\ndemonstrated in the field on Sentry, in addition to a variety of simulated\ncases. These results are discussed, and future work is outlined.", "AI": {"tldr": "DINOS-R\u662f\u4e00\u79cd\u65b0\u7684AUV\u4efb\u52a1\u89c4\u5212\u4e0e\u6267\u884c\u8f6f\u4ef6\uff0c\u57fa\u4e8e\u8ba4\u77e5\u67b6\u6784\u548cAUV\u63a7\u5236\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u7edf\u4e00\u4e86\u7b26\u53f7\u51b3\u7b56\u4e0e\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u5df2\u5728Sentry AUV\u4e0a\u6210\u529f\u6d4b\u8bd5\u3002", "motivation": "\u66ff\u4ee3\u4f20\u7edf\u7684MC\u67b6\u6784\uff0c\u6784\u5efa\u4e00\u4e2a\u80fd\u591f\u7edf\u4e00\u7b26\u53f7\u51b3\u7b56\uff08\u63d0\u4f9b\u53ef\u7406\u89e3\u3001\u53ef\u91cd\u590d\u3001\u53ef\u8bc1\u660e\u7684\u884c\u4e3a\uff09\u4e0e\u673a\u5668\u5b66\u4e60\u6280\u672f\u548c\u53cd\u5e94\u884c\u4e3a\u7684\u7cfb\u7edf\uff0c\u4ee5\u9002\u5e94\u4e0d\u540c\u6d77\u6d0b\u5b66\u5e73\u53f0\u7684\u73b0\u573a\u5e94\u7528\u9700\u6c42\u3002", "method": "\u91c7\u7528Python3\u5b9e\u73b0\uff0c\u5177\u6709\u53ef\u6269\u5c55\u6027\u3001\u6a21\u5757\u5316\u548c\u53ef\u91cd\u7528\u6027\uff0c\u652f\u6301\u58f0\u660e\u5f0f\u4efb\u52a1\u89c4\u8303\u548c\u7075\u6d3b\u7684\u884c\u4e3a\u89c4\u8303\uff0c\u540c\u65f6\u652f\u6301\u5b9e\u65f6\u4efb\u52a1\u89c4\u5212\u548c\u786c\u7f16\u7801\u7528\u6237\u6307\u5b9a\u8ba1\u5212\u3002", "result": "\u5728Sentry AUV\u4e0a\u8fdb\u884c\u4e86\u73b0\u573a\u6d4b\u8bd5\uff0c\u5e76\u5728\u591a\u79cd\u6a21\u62df\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u529f\u80fd\uff0c\u8bc1\u660e\u4e86\u7cfb\u7edf\u7684\u53ef\u884c\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "DINOS-R\u6210\u529f\u5b9e\u73b0\u4e86\u7b26\u53f7\u51b3\u7b56\u4e0e\u673a\u5668\u5b66\u4e60\u7684\u7edf\u4e00\uff0c\u4e3a\u6d77\u6d0b\u5b66\u548c\u673a\u5668\u4eba\u7b97\u6cd5\u7684\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u5e73\u53f0\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2510.10640", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10640", "abs": "https://arxiv.org/abs/2510.10640", "authors": ["Piyush Pant", "Marcellius William Suntoro", "Ayesha Siddiqua", "Muhammad Shehryaar Sharif", "Daniyal Ahmed"], "title": "Equity-Aware Geospatial AI for Forecasting Demand-Driven Hospital Locations in Germany", "comment": "7 pages. Application:\n  https://equity-aware-geospatial-ai-project.streamlit.app/ Codebase:\n  https://github.com/mwsyow/equity-aware-geospatial-ai-project/", "summary": "This paper presents EA-GeoAI, an integrated framework for demand forecasting\nand equitable hospital planning in Germany through 2030. We combine\ndistrict-level demographic shifts, aging population density, and infrastructure\nbalances into a unified Equity Index. An interpretable Agentic AI optimizer\nthen allocates beds and identifies new facility sites to minimize unmet need\nunder budget and travel-time constraints. This approach bridges GeoAI,\nlong-term forecasting, and equity measurement to deliver actionable\nrecommendations for policymakers.", "AI": {"tldr": "EA-GeoAI\u6846\u67b6\u7ed3\u5408\u5730\u7406AI\u3001\u957f\u671f\u9884\u6d4b\u548c\u516c\u5e73\u6027\u6d4b\u91cf\uff0c\u4e3a\u5fb7\u56fd2030\u5e74\u533b\u9662\u89c4\u5212\u63d0\u4f9b\u9700\u6c42\u9884\u6d4b\u548c\u516c\u5e73\u5206\u914d\u65b9\u6848\u3002", "motivation": "\u89e3\u51b3\u5fb7\u56fd\u533b\u9662\u8d44\u6e90\u5206\u914d\u4e0d\u5747\u95ee\u9898\uff0c\u8003\u8651\u4eba\u53e3\u8001\u9f84\u5316\u3001\u57fa\u7840\u8bbe\u65bd\u5e73\u8861\u7b49\u56e0\u7d20\uff0c\u786e\u4fdd\u533b\u7597\u8d44\u6e90\u516c\u5e73\u5206\u914d\u3002", "method": "\u6574\u5408\u533a\u57df\u4eba\u53e3\u53d8\u5316\u3001\u8001\u9f84\u5316\u5bc6\u5ea6\u548c\u57fa\u7840\u8bbe\u65bd\u5e73\u8861\u6784\u5efa\u516c\u5e73\u6307\u6570\uff0c\u4f7f\u7528\u53ef\u89e3\u91ca\u7684\u667a\u80fdAI\u4f18\u5316\u5668\u5728\u9884\u7b97\u548c\u901a\u52e4\u65f6\u95f4\u7ea6\u675f\u4e0b\u5206\u914d\u5e8a\u4f4d\u548c\u786e\u5b9a\u65b0\u8bbe\u65bd\u4f4d\u7f6e\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7efc\u5408\u6846\u67b6\uff0c\u80fd\u591f\u6700\u5c0f\u5316\u672a\u6ee1\u8db3\u9700\u6c42\uff0c\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u53ef\u884c\u7684\u533b\u9662\u89c4\u5212\u5efa\u8bae\u3002", "conclusion": "EA-GeoAI\u6210\u529f\u8fde\u63a5\u4e86\u5730\u7406AI\u3001\u957f\u671f\u9884\u6d4b\u548c\u516c\u5e73\u6027\u6d4b\u91cf\uff0c\u4e3a\u533b\u7597\u8d44\u6e90\u516c\u5e73\u5206\u914d\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2510.10731", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10731", "abs": "https://arxiv.org/abs/2510.10731", "authors": ["Yongxi Cao", "Julian F. Schumann", "Jens Kober", "Joni Pajarinen", "Arkady Zgonnikov"], "title": "Controllable Generative Trajectory Prediction via Weak Preference Alignment", "comment": null, "summary": "Deep generative models such as conditional variational autoencoders (CVAEs)\nhave shown great promise for predicting trajectories of surrounding agents in\nautonomous vehicle planning. State-of-the-art models have achieved remarkable\naccuracy in such prediction tasks. Besides accuracy, diversity is also crucial\nfor safe planning because human behaviors are inherently uncertain and\nmultimodal. However, existing methods generally lack a scheme to generate\ncontrollably diverse trajectories, which is arguably more useful than randomly\ndiversified trajectories, to the end of safe planning. To address this, we\npropose PrefCVAE, an augmented CVAE framework that uses weakly labeled\npreference pairs to imbue latent variables with semantic attributes. Using\naverage velocity as an example attribute, we demonstrate that PrefCVAE enables\ncontrollable, semantically meaningful predictions without degrading baseline\naccuracy. Our results show the effectiveness of preference supervision as a\ncost-effective way to enhance sampling-based generative models.", "AI": {"tldr": "PrefCVAE\uff1a\u57fa\u4e8e\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7684\u589e\u5f3a\u6846\u67b6\uff0c\u901a\u8fc7\u5f31\u6807\u7b7e\u504f\u597d\u5bf9\u4e3a\u6f5c\u53d8\u91cf\u8d4b\u4e88\u8bed\u4e49\u5c5e\u6027\uff0c\u5b9e\u73b0\u53ef\u63a7\u591a\u6837\u7684\u8f68\u8ff9\u9884\u6d4b", "motivation": "\u73b0\u6709\u8f68\u8ff9\u9884\u6d4b\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u63a7\u591a\u6837\u6027\u751f\u6210\u673a\u5236\uff0c\u800c\u968f\u673a\u591a\u6837\u5316\u8f68\u8ff9\u5bf9\u81ea\u52a8\u9a7e\u9a76\u5b89\u5168\u89c4\u5212\u4e0d\u591f\u5b9e\u7528\uff0c\u9700\u8981\u8bed\u4e49\u53ef\u63a7\u7684\u591a\u6837\u5316\u9884\u6d4b", "method": "\u5728CVAE\u6846\u67b6\u4e2d\u5f15\u5165\u5f31\u6807\u7b7e\u504f\u597d\u5bf9\u76d1\u7763\uff0c\u4f7f\u6f5c\u53d8\u91cf\u5177\u6709\u8bed\u4e49\u5c5e\u6027\uff08\u5982\u5e73\u5747\u901f\u5ea6\uff09\uff0c\u5b9e\u73b0\u53ef\u63a7\u7684\u591a\u6837\u5316\u8f68\u8ff9\u751f\u6210", "result": "PrefCVAE\u5728\u4fdd\u6301\u57fa\u7ebf\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u80fd\u591f\u751f\u6210\u8bed\u4e49\u53ef\u63a7\u7684\u591a\u6837\u5316\u8f68\u8ff9\uff0c\u9a8c\u8bc1\u4e86\u504f\u597d\u76d1\u7763\u4f5c\u4e3a\u589e\u5f3a\u751f\u6210\u6a21\u578b\u7684\u6709\u6548\u4f4e\u6210\u672c\u65b9\u6cd5", "conclusion": "\u504f\u597d\u76d1\u7763\u662f\u589e\u5f3a\u57fa\u4e8e\u91c7\u6837\u7684\u751f\u6210\u6a21\u578b\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u591f\u5b9e\u73b0\u8bed\u4e49\u53ef\u63a7\u7684\u591a\u6837\u5316\u8f68\u8ff9\u9884\u6d4b\uff0c\u5bf9\u81ea\u52a8\u9a7e\u9a76\u5b89\u5168\u89c4\u5212\u5177\u6709\u91cd\u8981\u610f\u4e49"}}
{"id": "2510.10644", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10644", "abs": "https://arxiv.org/abs/2510.10644", "authors": ["Yi Zhang", "Yushen Long", "Yun Ni", "Liping Huang", "Xiaohong Wang", "Jun Liu"], "title": "Hierarchical Optimization via LLM-Guided Objective Evolution for Mobility-on-Demand Systems", "comment": null, "summary": "Online ride-hailing platforms aim to deliver efficient mobility-on-demand\nservices, often facing challenges in balancing dynamic and spatially\nheterogeneous supply and demand. Existing methods typically fall into two\ncategories: reinforcement learning (RL) approaches, which suffer from data\ninefficiency, oversimplified modeling of real-world dynamics, and difficulty\nenforcing operational constraints; or decomposed online optimization methods,\nwhich rely on manually designed high-level objectives that lack awareness of\nlow-level routing dynamics. To address this issue, we propose a novel hybrid\nframework that integrates large language model (LLM) with mathematical\noptimization in a dynamic hierarchical system: (1) it is training-free,\nremoving the need for large-scale interaction data as in RL, and (2) it\nleverages LLM to bridge cognitive limitations caused by problem decomposition\nby adaptively generating high-level objectives. Within this framework, LLM\nserves as a meta-optimizer, producing semantic heuristics that guide a\nlow-level optimizer responsible for constraint enforcement and real-time\ndecision execution. These heuristics are refined through a closed-loop\nevolutionary process, driven by harmony search, which iteratively adapts the\nLLM prompts based on feasibility and performance feedback from the optimization\nlayer. Extensive experiments based on scenarios derived from both the New York\nand Chicago taxi datasets demonstrate the effectiveness of our approach,\nachieving an average improvement of 16% compared to state-of-the-art baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u6570\u5b66\u4f18\u5316\u7684\u6df7\u5408\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u7ebf\u53eb\u8f66\u5e73\u53f0\u7684\u4f9b\u9700\u5e73\u8861\u95ee\u9898\uff0c\u65e0\u9700\u8bad\u7ec3\u6570\u636e\uff0c\u901a\u8fc7LLM\u751f\u6210\u9ad8\u5c42\u76ee\u6807\u6307\u5bfc\u5e95\u5c42\u4f18\u5316\u5668\uff0c\u5728\u7ebd\u7ea6\u548c\u829d\u52a0\u54e5\u51fa\u79df\u8f66\u6570\u636e\u96c6\u4e0a\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u534716%", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e24\u7c7b\u95ee\u9898\uff1a\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u6570\u636e\u6548\u7387\u4f4e\u3001\u8fc7\u5ea6\u7b80\u5316\u73b0\u5b9e\u52a8\u6001\u4e14\u96be\u4ee5\u5b9e\u65bd\u64cd\u4f5c\u7ea6\u675f\uff1b\u5206\u89e3\u5728\u7ebf\u4f18\u5316\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u7684\u9ad8\u5c42\u76ee\u6807\uff0c\u7f3a\u4e4f\u5bf9\u5e95\u5c42\u8def\u7531\u52a8\u6001\u7684\u8ba4\u77e5", "method": "\u63d0\u51fa\u8bad\u7ec3\u514d\u8d39\u7684\u6df7\u5408\u6846\u67b6\uff0c\u5c06LLM\u4f5c\u4e3a\u5143\u4f18\u5316\u5668\u751f\u6210\u8bed\u4e49\u542f\u53d1\u5f0f\u89c4\u5219\uff0c\u6307\u5bfc\u8d1f\u8d23\u7ea6\u675f\u6267\u884c\u548c\u5b9e\u65f6\u51b3\u7b56\u7684\u5e95\u5c42\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u548c\u58f0\u641c\u7d22\u9a71\u52a8\u7684\u95ed\u73af\u8fdb\u5316\u8fc7\u7a0b\u8fed\u4ee3\u4f18\u5316LLM\u63d0\u793a", "result": "\u5728\u57fa\u4e8e\u7ebd\u7ea6\u548c\u829d\u52a0\u54e5\u51fa\u79df\u8f66\u6570\u636e\u96c6\u7684\u573a\u666f\u4e2d\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u5e73\u5747\u63d0\u5347\u4e8616%\u7684\u6027\u80fd", "conclusion": "\u8be5\u6df7\u5408\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5728\u7ebf\u53eb\u8f66\u5e73\u53f0\u7684\u4f9b\u9700\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7LLM\u4e0e\u6570\u5b66\u4f18\u5316\u7684\u7ed3\u5408\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027"}}
{"id": "2510.10781", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY", "I.2.9; I.2.11"], "pdf": "https://arxiv.org/pdf/2510.10781", "abs": "https://arxiv.org/abs/2510.10781", "authors": ["Douglas Hutchings", "Luai Abuelsamen", "Karthik Rajgopal"], "title": "Two-Layer Voronoi Coverage Control for Hybrid Aerial-Ground Robot Teams in Emergency Response: Implementation and Analysis", "comment": "23 pages, 7 figures. Technical report with complete implementation\n  details and open-source code", "summary": "We present a comprehensive two-layer Voronoi coverage control approach for\ncoordinating hybrid aerial-ground robot teams in hazardous material emergency\nresponse scenarios. Traditional Voronoi coverage control methods face three\ncritical limitations in emergency contexts: heterogeneous agent capabilities\nwith vastly different velocities, clustered initial deployment configurations,\nand urgent time constraints requiring rapid response rather than eventual\nconvergence. Our method addresses these challenges through a decoupled\ntwo-layer architecture that separately optimizes aerial and ground robot\npositioning, with aerial agents delivering ground sensors via airdrop to\nhigh-priority locations. We provide detailed implementation of bounded Voronoi\ncell computation, efficient numerical integration techniques for\nimportance-weighted centroids, and robust control strategies that prevent agent\ntrapping. Simulation results demonstrate an 88% reduction in response time,\nachieving target sensor coverage (18.5% of initial sensor loss) in 25 seconds\ncompared to 220 seconds for ground-only deployment. Complete implementation\ncode is available at https://github.com/dHutchings/ME292B.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5c42Voronoi\u8986\u76d6\u63a7\u5236\u65b9\u6cd5\uff0c\u7528\u4e8e\u534f\u8c03\u6df7\u5408\u7a7a\u4e2d-\u5730\u9762\u673a\u5668\u4eba\u56e2\u961f\u5728\u5371\u9669\u6750\u6599\u5e94\u6025\u54cd\u5e94\u573a\u666f\u4e2d\u7684\u90e8\u7f72\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u5f02\u6784\u80fd\u529b\u3001\u96c6\u7fa4\u521d\u59cb\u90e8\u7f72\u548c\u65f6\u95f4\u7ea6\u675f\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edfVoronoi\u8986\u76d6\u63a7\u5236\u5728\u5e94\u6025\u54cd\u5e94\u573a\u666f\u4e2d\u9762\u4e34\u4e09\u4e2a\u5173\u952e\u9650\u5236\uff1a\u5f02\u6784\u4ee3\u7406\u80fd\u529b\uff08\u901f\u5ea6\u5dee\u5f02\u5927\uff09\u3001\u96c6\u7fa4\u521d\u59cb\u90e8\u7f72\u914d\u7f6e\u3001\u4ee5\u53ca\u9700\u8981\u5feb\u901f\u54cd\u5e94\u800c\u975e\u6e10\u8fdb\u6536\u655b\u7684\u7d27\u6025\u65f6\u95f4\u7ea6\u675f\u3002", "method": "\u91c7\u7528\u89e3\u8026\u7684\u53cc\u5c42\u67b6\u6784\uff0c\u5206\u522b\u4f18\u5316\u7a7a\u4e2d\u548c\u5730\u9762\u673a\u5668\u4eba\u5b9a\u4f4d\uff0c\u7a7a\u4e2d\u4ee3\u7406\u901a\u8fc7\u7a7a\u6295\u5c06\u5730\u9762\u4f20\u611f\u5668\u90e8\u7f72\u5230\u9ad8\u4f18\u5148\u7ea7\u4f4d\u7f6e\u3002\u5305\u62ec\u6709\u754cVoronoi\u5355\u5143\u8ba1\u7b97\u3001\u91cd\u8981\u6027\u52a0\u6743\u8d28\u5fc3\u7684\u9ad8\u6548\u6570\u503c\u79ef\u5206\u6280\u672f\u4ee5\u53ca\u9632\u6b62\u4ee3\u7406\u9677\u5165\u56f0\u5883\u7684\u9c81\u68d2\u63a7\u5236\u7b56\u7565\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\u54cd\u5e94\u65f6\u95f4\u51cf\u5c1188%\uff0c\u572825\u79d2\u5185\u5b9e\u73b0\u76ee\u6807\u4f20\u611f\u5668\u8986\u76d6\uff08\u521d\u59cb\u4f20\u611f\u5668\u635f\u593118.5%\uff09\uff0c\u800c\u4ec5\u4f7f\u7528\u5730\u9762\u90e8\u7f72\u9700\u8981220\u79d2\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6df7\u5408\u7a7a\u4e2d-\u5730\u9762\u673a\u5668\u4eba\u56e2\u961f\u5728\u7d27\u6025\u54cd\u5e94\u573a\u666f\u4e2d\u7684\u90e8\u7f72\u6548\u7387\u548c\u54cd\u5e94\u901f\u5ea6\uff0c\u4e3a\u5371\u9669\u6750\u6599\u5e94\u6025\u54cd\u5e94\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.10759", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10759", "abs": "https://arxiv.org/abs/2510.10759", "authors": ["Arthicha Srisuchinnawong", "Poramate Manoonpong"], "title": "Gain Tuning Is Not What You Need: Reward Gain Adaptation for Constrained Locomotion Learning", "comment": "RSS 2025", "summary": "Existing robot locomotion learning techniques rely heavily on the offline\nselection of proper reward weighting gains and cannot guarantee constraint\nsatisfaction (i.e., constraint violation) during training. Thus, this work aims\nto address both issues by proposing Reward-Oriented Gains via Embodied\nRegulation (ROGER), which adapts reward-weighting gains online based on\npenalties received throughout the embodied interaction process. The ratio\nbetween the positive reward (primary reward) and negative reward (penalty)\ngains is automatically reduced as the learning approaches the constraint\nthresholds to avoid violation. Conversely, the ratio is increased when learning\nis in safe states to prioritize performance. With a 60-kg quadruped robot,\nROGER achieved near-zero constraint violation throughout multiple learning\ntrials. It also achieved up to 50% more primary reward than the equivalent\nstate-of-the-art techniques. In MuJoCo continuous locomotion benchmarks,\nincluding a single-leg hopper, ROGER exhibited comparable or up to 100% higher\nperformance and 60% less torque usage and orientation deviation compared to\nthose trained with the default reward function. Finally, real-world locomotion\nlearning of a physical quadruped robot was achieved from scratch within one\nhour without any falls. Therefore, this work contributes to\nconstraint-satisfying real-world continual robot locomotion learning and\nsimplifies reward weighting gain tuning, potentially facilitating the\ndevelopment of physical robots and those that learn in the real world.", "AI": {"tldr": "\u63d0\u51fa\u4e86ROGER\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u7ebf\u81ea\u9002\u5e94\u8c03\u6574\u5956\u52b1\u6743\u91cd\u589e\u76ca\u6765\u89e3\u51b3\u673a\u5668\u4eba\u8fd0\u52a8\u5b66\u4e60\u4e2d\u7684\u7ea6\u675f\u8fdd\u53cd\u95ee\u9898\uff0c\u5e76\u5728\u771f\u5b9e\u56db\u8db3\u673a\u5668\u4eba\u4e0a\u5b9e\u73b0\u4e86\u8fd1\u96f6\u7ea6\u675f\u8fdd\u53cd\u548c\u66f4\u9ad8\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u4eba\u8fd0\u52a8\u5b66\u4e60\u6280\u672f\u4e25\u91cd\u4f9d\u8d56\u79bb\u7ebf\u9009\u62e9\u9002\u5f53\u7684\u5956\u52b1\u6743\u91cd\u589e\u76ca\uff0c\u65e0\u6cd5\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4fdd\u8bc1\u7ea6\u675f\u6ee1\u8db3\uff08\u5373\u907f\u514d\u7ea6\u675f\u8fdd\u53cd\uff09\u3002", "method": "ROGER\u65b9\u6cd5\u57fa\u4e8e\u5728\u5177\u4f53\u4ea4\u4e92\u8fc7\u7a0b\u4e2d\u63a5\u6536\u5230\u7684\u60e9\u7f5a\uff0c\u5728\u7ebf\u81ea\u9002\u5e94\u8c03\u6574\u5956\u52b1\u6743\u91cd\u589e\u76ca\u3002\u5f53\u5b66\u4e60\u63a5\u8fd1\u7ea6\u675f\u9608\u503c\u65f6\uff0c\u81ea\u52a8\u51cf\u5c11\u6b63\u5956\u52b1\u4e0e\u8d1f\u5956\u52b1\u589e\u76ca\u7684\u6bd4\u7387\u4ee5\u907f\u514d\u8fdd\u53cd\uff1b\u5728\u5b89\u5168\u72b6\u6001\u4e0b\u5219\u589e\u52a0\u8be5\u6bd4\u7387\u4ee5\u4f18\u5148\u8003\u8651\u6027\u80fd\u3002", "result": "\u572860\u516c\u65a4\u56db\u8db3\u673a\u5668\u4eba\u4e0a\uff0cROGER\u5b9e\u73b0\u4e86\u591a\u4e2a\u5b66\u4e60\u8bd5\u9a8c\u4e2d\u8fd1\u96f6\u7ea6\u675f\u8fdd\u53cd\uff0c\u6bd4\u540c\u7c7b\u6700\u5148\u8fdb\u6280\u672f\u591a\u83b7\u5f9750%\u7684\u4e3b\u8981\u5956\u52b1\u3002\u5728MuJoCo\u8fde\u7eed\u8fd0\u52a8\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6027\u80fd\u76f8\u5f53\u6216\u63d0\u9ad8100%\uff0c\u626d\u77e9\u4f7f\u7528\u548c\u65b9\u5411\u504f\u5dee\u51cf\u5c1160%\u3002\u771f\u5b9e\u4e16\u754c\u56db\u8db3\u673a\u5668\u4eba\u8fd0\u52a8\u5b66\u4e60\u57281\u5c0f\u65f6\u5185\u4ece\u96f6\u5f00\u59cb\u5b8c\u6210\u4e14\u65e0\u8dcc\u5012\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u6ee1\u8db3\u7ea6\u675f\u7684\u771f\u5b9e\u4e16\u754c\u6301\u7eed\u673a\u5668\u4eba\u8fd0\u52a8\u5b66\u4e60\u505a\u51fa\u4e86\u8d21\u732e\uff0c\u7b80\u5316\u4e86\u5956\u52b1\u6743\u91cd\u589e\u76ca\u8c03\u6574\uff0c\u6709\u52a9\u4e8e\u7269\u7406\u673a\u5668\u4eba\u548c\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u5b66\u4e60\u7684\u673a\u5668\u4eba\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.10649", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10649", "abs": "https://arxiv.org/abs/2510.10649", "authors": ["Can Xie", "Ruotong Pan", "Xiangyu Wu", "Yunfei Zhang", "Jiayi Fu", "Tingting Gao", "Guorui Zhou"], "title": "Unlocking Exploration in RLVR: Uncertainty-aware Advantage Shaping for Deeper Reasoning", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has shown significant\npromise for enhancing the reasoning capabilities of large language models\n(LLMs). However, prevailing algorithms like GRPO broadcast a uniform advantage\nsignal across all tokens in a sequence. This coarse-grained approach overlooks\nthe pivotal role of uncertain, high-stakes decisions during reasoning, leading\nto inefficient exploration and the well-documented problem of entropy collapse.\nTo address this, we introduce UnCertainty-aware Advantage Shaping (UCAS), a\nmodel-free method that refines credit assignment by leveraging the model's\ninternal uncertainty signals. UCAS operates in two stages: it first modulates\nthe response-level advantage using the model's overall self-confidence, and\nthen applies a token-level penalty based on raw logit certainty. This dual\nmechanism encourages exploration of high-uncertainty paths that yield correct\nanswers while penalizing overconfident yet erroneous reasoning, effectively\nbalancing the exploration-exploitation trade-off. Extensive experiments on five\nmathematical reasoning benchmarks show that UCAS significantly outperforms\nstrong RLVR baselines across multiple model scales, including 1.5B and 7B. Our\nanalysis confirms that UCAS not only achieves higher rewards but also promotes\ngreater reasoning diversity and successfully mitigates entropy collapse.", "AI": {"tldr": "UCAS\u662f\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u6a21\u578b\u5185\u90e8\u4e0d\u786e\u5b9a\u6027\u4fe1\u53f7\u6765\u6539\u8fdb\u4fe1\u7528\u5206\u914d\uff0c\u6709\u6548\u89e3\u51b3\u63a8\u7406\u8fc7\u7a0b\u4e2d\u4e0d\u786e\u5b9a\u9ad8\u98ce\u9669\u51b3\u7b56\u88ab\u5ffd\u89c6\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709RLVR\u7b97\u6cd5\uff08\u5982GRPO\uff09\u5bf9\u6240\u6709token\u5e7f\u64ad\u7edf\u4e00\u7684\u4f18\u52bf\u4fe1\u53f7\uff0c\u8fd9\u79cd\u7c97\u7c92\u5ea6\u65b9\u6cd5\u5ffd\u7565\u4e86\u63a8\u7406\u8fc7\u7a0b\u4e2d\u4e0d\u786e\u5b9a\u7684\u9ad8\u98ce\u9669\u51b3\u7b56\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5bfc\u81f4\u63a2\u7d22\u6548\u7387\u4f4e\u4e0b\u548c\u71b5\u5d29\u6e83\u95ee\u9898\u3002", "method": "UCAS\u91c7\u7528\u4e24\u9636\u6bb5\u673a\u5236\uff1a\u9996\u5148\u6839\u636e\u6a21\u578b\u7684\u6574\u4f53\u81ea\u4fe1\u5ea6\u8c03\u8282\u54cd\u5e94\u7ea7\u4f18\u52bf\uff0c\u7136\u540e\u57fa\u4e8e\u539f\u59cblogit\u786e\u5b9a\u6027\u5e94\u7528token\u7ea7\u60e9\u7f5a\u3002\u8fd9\u79cd\u53cc\u91cd\u673a\u5236\u9f13\u52b1\u63a2\u7d22\u4ea7\u751f\u6b63\u786e\u7b54\u6848\u7684\u9ad8\u4e0d\u786e\u5b9a\u6027\u8def\u5f84\uff0c\u540c\u65f6\u60e9\u7f5a\u8fc7\u5ea6\u81ea\u4fe1\u4f46\u9519\u8bef\u7684\u63a8\u7406\u3002", "result": "\u5728\u4e94\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cUCAS\u5728\u591a\u4e2a\u6a21\u578b\u89c4\u6a21\uff08\u5305\u62ec1.5B\u548c7B\uff09\u4e0a\u663e\u8457\u4f18\u4e8e\u5f3aRLVR\u57fa\u7ebf\u3002", "conclusion": "UCAS\u4e0d\u4ec5\u83b7\u5f97\u66f4\u9ad8\u5956\u52b1\uff0c\u8fd8\u4fc3\u8fdb\u66f4\u5927\u7684\u63a8\u7406\u591a\u6837\u6027\uff0c\u5e76\u6210\u529f\u7f13\u89e3\u71b5\u5d29\u6e83\u95ee\u9898\u3002"}}
{"id": "2510.11072", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.11072", "abs": "https://arxiv.org/abs/2510.11072", "authors": ["Huayi Wang", "Wentao Zhang", "Runyi Yu", "Tao Huang", "Junli Ren", "Feiyu Jia", "Zirui Wang", "Xiaojie Niu", "Xiao Chen", "Jiahe Chen", "Qifeng Chen", "Jingbo Wang", "Jiangmiao Pang"], "title": "PhysHSI: Towards a Real-World Generalizable and Natural Humanoid-Scene Interaction System", "comment": "Project website: https://why618188.github.io/physhsi/", "summary": "Deploying humanoid robots to interact with real-world environments--such as\ncarrying objects or sitting on chairs--requires generalizable, lifelike motions\nand robust scene perception. Although prior approaches have advanced each\ncapability individually, combining them in a unified system is still an ongoing\nchallenge. In this work, we present a physical-world humanoid-scene interaction\nsystem, PhysHSI, that enables humanoids to autonomously perform diverse\ninteraction tasks while maintaining natural and lifelike behaviors. PhysHSI\ncomprises a simulation training pipeline and a real-world deployment system. In\nsimulation, we adopt adversarial motion prior-based policy learning to imitate\nnatural humanoid-scene interaction data across diverse scenarios, achieving\nboth generalization and lifelike behaviors. For real-world deployment, we\nintroduce a coarse-to-fine object localization module that combines LiDAR and\ncamera inputs to provide continuous and robust scene perception. We validate\nPhysHSI on four representative interactive tasks--box carrying, sitting, lying,\nand standing up--in both simulation and real-world settings, demonstrating\nconsistently high success rates, strong generalization across diverse task\ngoals, and natural motion patterns.", "AI": {"tldr": "PhysHSI\u662f\u4e00\u4e2a\u7269\u7406\u4e16\u754c\u4eba\u5f62\u673a\u5668\u4eba-\u573a\u666f\u4ea4\u4e92\u7cfb\u7edf\uff0c\u901a\u8fc7\u4eff\u771f\u8bad\u7ec3\u548c\u73b0\u5b9e\u90e8\u7f72\u5b9e\u73b0\u4eba\u5f62\u673a\u5668\u4eba\u81ea\u4e3b\u6267\u884c\u591a\u6837\u5316\u4ea4\u4e92\u4efb\u52a1\uff0c\u540c\u65f6\u4fdd\u6301\u81ea\u7136\u903c\u771f\u7684\u884c\u4e3a\u3002", "motivation": "\u5c06\u4eba\u5f62\u673a\u5668\u4eba\u90e8\u7f72\u5230\u73b0\u5b9e\u73af\u5883\u4e2d\u6267\u884c\u4ea4\u4e92\u4efb\u52a1\uff08\u5982\u642c\u8fd0\u7269\u4f53\u3001\u5750\u5728\u6905\u5b50\u4e0a\uff09\u9700\u8981\u53ef\u6cdb\u5316\u7684\u903c\u771f\u52a8\u4f5c\u548c\u9c81\u68d2\u7684\u573a\u666f\u611f\u77e5\u80fd\u529b\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5c06\u8fd9\u4e9b\u80fd\u529b\u7edf\u4e00\u6574\u5408\u3002", "method": "\u7cfb\u7edf\u5305\u542b\u4eff\u771f\u8bad\u7ec3\u7ba1\u9053\u548c\u73b0\u5b9e\u90e8\u7f72\u7cfb\u7edf\u3002\u4eff\u771f\u4e2d\u91c7\u7528\u57fa\u4e8e\u5bf9\u6297\u8fd0\u52a8\u5148\u9a8c\u7684\u7b56\u7565\u5b66\u4e60\u6765\u6a21\u4eff\u591a\u6837\u5316\u573a\u666f\u4e0b\u7684\u4eba\u5f62\u673a\u5668\u4eba-\u573a\u666f\u4ea4\u4e92\u6570\u636e\uff1b\u73b0\u5b9e\u90e8\u7f72\u4e2d\u5f15\u5165\u7c97\u5230\u7ec6\u7684\u7269\u4f53\u5b9a\u4f4d\u6a21\u5757\uff0c\u7ed3\u5408LiDAR\u548c\u76f8\u673a\u8f93\u5165\u63d0\u4f9b\u8fde\u7eed\u9c81\u68d2\u7684\u573a\u666f\u611f\u77e5\u3002", "result": "\u5728\u56db\u4e2a\u4ee3\u8868\u6027\u4ea4\u4e92\u4efb\u52a1\uff08\u642c\u8fd0\u7bb1\u5b50\u3001\u5750\u3001\u8eba\u3001\u7ad9\u8d77\uff09\u7684\u4eff\u771f\u548c\u73b0\u5b9e\u73af\u5883\u4e2d\u9a8c\u8bc1\uff0c\u8868\u73b0\u51fa\u9ad8\u6210\u529f\u7387\u3001\u8de8\u591a\u6837\u5316\u4efb\u52a1\u76ee\u6807\u7684\u5f3a\u6cdb\u5316\u80fd\u529b\u548c\u81ea\u7136\u8fd0\u52a8\u6a21\u5f0f\u3002", "conclusion": "PhysHSI\u6210\u529f\u5b9e\u73b0\u4e86\u4eba\u5f62\u673a\u5668\u4eba\u5728\u7269\u7406\u4e16\u754c\u4e2d\u81ea\u4e3b\u6267\u884c\u591a\u6837\u5316\u4ea4\u4e92\u4efb\u52a1\uff0c\u540c\u65f6\u4fdd\u6301\u81ea\u7136\u903c\u771f\u7684\u884c\u4e3a\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u4eba\u5f62\u673a\u5668\u4eba\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.10778", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10778", "abs": "https://arxiv.org/abs/2510.10778", "authors": ["Christopher D. Hsu", "Pratik Chaudhari"], "title": "Real2USD: Scene Representations in Universal Scene Description Language", "comment": "8 pages, 10 figures, 1 table", "summary": "Large Language Models (LLMs) can help robots reason about abstract task\nspecifications. This requires augmenting classical representations of the\nenvironment used by robots with natural language-based priors. There are a\nnumber of existing approaches to doing so, but they are tailored to specific\ntasks, e.g., visual-language models for navigation, language-guided neural\nradiance fields for mapping, etc. This paper argues that the Universal Scene\nDescription (USD) language is an effective and general representation of\ngeometric, photometric and semantic information in the environment for\nLLM-based robotics tasks. Our argument is simple: a USD is an XML-based scene\ngraph, readable by LLMs and humans alike, and rich enough to support\nessentially any task -- Pixar developed this language to store assets, scenes\nand even movies. We demonstrate a ``Real to USD'' system using a Unitree Go2\nquadruped robot carrying LiDAR and a RGB camera that (i) builds an explicit USD\nrepresentation of indoor environments with diverse objects and challenging\nsettings with lots of glass, and (ii) parses the USD using Google's Gemini to\ndemonstrate scene understanding, complex inferences, and planning. We also\nstudy different aspects of this system in simulated warehouse and hospital\nsettings using Nvidia's Issac Sim. Code is available at\nhttps://github.com/grasp-lyrl/Real2USD .", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u901a\u7528\u573a\u666f\u63cf\u8ff0\u8bed\u8a00\uff08USD\uff09\u4f5c\u4e3aLLM\u673a\u5668\u4eba\u4efb\u52a1\u7684\u901a\u7528\u8868\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u771f\u5b9e\u73af\u5883\u8f6c\u6362\u4e3aUSD\u683c\u5f0f\uff0c\u5229\u7528LLM\u8fdb\u884c\u573a\u666f\u7406\u89e3\u548c\u4efb\u52a1\u89c4\u5212\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u591a\u4e3a\u7279\u5b9a\u4efb\u52a1\u5b9a\u5236\uff0c\u7f3a\u4e4f\u901a\u7528\u6027\u3002USD\u4f5c\u4e3aXML\u683c\u5f0f\u7684\u573a\u666f\u56fe\uff0c\u65e2\u9002\u5408LLM\u89e3\u6790\u53c8\u8db3\u591f\u4e30\u5bcc\uff0c\u80fd\u591f\u652f\u6301\u5404\u79cd\u673a\u5668\u4eba\u4efb\u52a1\u3002", "method": "\u5f00\u53d1\u4e86\"Real to USD\"\u7cfb\u7edf\uff0c\u4f7f\u7528\u56db\u8db3\u673a\u5668\u4eba\u642d\u8f7dLiDAR\u548cRGB\u76f8\u673a\u6784\u5efa\u5ba4\u5185\u73af\u5883\u7684USD\u8868\u793a\uff0c\u7136\u540e\u901a\u8fc7Google Gemini\u89e3\u6790USD\u8fdb\u884c\u573a\u666f\u7406\u89e3\u548c\u89c4\u5212\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u5305\u542b\u591a\u6837\u5316\u7269\u4f53\u548c\u6311\u6218\u6027\u573a\u666f\uff08\u5982\u73bb\u7483\u73af\u5883\uff09\u7684USD\u8868\u793a\uff0c\u5e76\u5c55\u793a\u4e86LLM\u80fd\u591f\u8fdb\u884c\u590d\u6742\u63a8\u7406\u548c\u4efb\u52a1\u89c4\u5212\u3002\u5728\u6a21\u62df\u4ed3\u5e93\u548c\u533b\u9662\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u6027\u80fd\u3002", "conclusion": "USD\u662f\u4e00\u79cd\u6709\u6548\u4e14\u901a\u7528\u7684\u8868\u793a\u65b9\u6cd5\uff0c\u80fd\u591f\u6865\u63a5\u673a\u5668\u4eba\u73af\u5883\u8868\u793a\u4e0eLLM\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u80fd\u529b\uff0c\u4e3aLLM\u9a71\u52a8\u7684\u673a\u5668\u4eba\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.10675", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10675", "abs": "https://arxiv.org/abs/2510.10675", "authors": ["Deven Panchal"], "title": "Simpliflow: A Lightweight Open-Source Framework for Rapid Creation and Deployment of Generative Agentic AI Workflows", "comment": null, "summary": "Generative Agentic AI systems are emerging as a powerful paradigm for\nautomating complex, multi-step tasks. However, many existing frameworks for\nbuilding these systems introduce significant complexity, a steep learning\ncurve, and substantial boilerplate code, hindering rapid prototyping and\ndeployment. This paper introduces simpliflow, a lightweight, open-source Python\nframework designed to address these challenges. simpliflow enables the rapid\ndevelopment and orchestration of linear, deterministic agentic workflows\nthrough a declarative, JSON-based configuration. Its modular architecture\ndecouples agent management, workflow execution, and post-processing, promoting\nease of use and extensibility. By integrating with LiteLLM, it supports over\n100 Large Language Models (LLMs) out-of-the-box. We present the architecture,\noperational flow, and core features of simpliflow, demonstrating its utility\nthrough diverse use cases ranging from software development simulation to\nreal-time system interaction. A comparative analysis with prominent frameworks\nlike LangChain and AutoGen highlights simpliflow's unique position as a tool\noptimized for simplicity, control, and speed in deterministic workflow\nenvironments.", "AI": {"tldr": "simpliflow\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5f00\u6e90Python\u6846\u67b6\uff0c\u7528\u4e8e\u5feb\u901f\u6784\u5efa\u548c\u7f16\u6392\u7ebf\u6027\u786e\u5b9a\u6027\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff0c\u901a\u8fc7\u58f0\u660e\u5f0fJSON\u914d\u7f6e\u7b80\u5316\u5f00\u53d1\u8fc7\u7a0b\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u667a\u80fd\u4f53AI\u7cfb\u7edf\u6846\u67b6\u5b58\u5728\u590d\u6742\u5ea6\u9ad8\u3001\u5b66\u4e60\u66f2\u7ebf\u9661\u5ced\u548c\u5927\u91cf\u6837\u677f\u4ee3\u7801\u7684\u95ee\u9898\uff0c\u963b\u788d\u4e86\u5feb\u901f\u539f\u578b\u5f00\u53d1\u548c\u90e8\u7f72\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u67b6\u6784\uff0c\u89e3\u8026\u667a\u80fd\u4f53\u7ba1\u7406\u3001\u5de5\u4f5c\u6d41\u6267\u884c\u548c\u540e\u5904\u7406\uff0c\u901a\u8fc7\u58f0\u660e\u5f0fJSON\u914d\u7f6e\u5b9a\u4e49\u5de5\u4f5c\u6d41\uff0c\u5e76\u96c6\u6210LiteLLM\u652f\u6301100+\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u5c55\u793a\u4e86simpliflow\u5728\u8f6f\u4ef6\u5f00\u53d1\u6a21\u62df\u548c\u5b9e\u65f6\u7cfb\u7edf\u4ea4\u4e92\u7b49\u591a\u6837\u5316\u7528\u4f8b\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u4e0eLangChain\u548cAutoGen\u76f8\u6bd4\u5728\u786e\u5b9a\u6027\u5de5\u4f5c\u6d41\u73af\u5883\u4e2d\u5177\u6709\u7b80\u5355\u6027\u3001\u63a7\u5236\u6027\u548c\u901f\u5ea6\u4f18\u52bf\u3002", "conclusion": "simpliflow\u5728\u786e\u5b9a\u6027\u5de5\u4f5c\u6d41\u73af\u5883\u4e2d\u4f5c\u4e3a\u4f18\u5316\u7b80\u5355\u6027\u3001\u63a7\u5236\u6027\u548c\u901f\u5ea6\u7684\u5de5\u5177\u5177\u6709\u72ec\u7279\u5b9a\u4f4d\uff0c\u80fd\u591f\u6709\u6548\u964d\u4f4e\u5f00\u53d1\u590d\u6742\u5ea6\u5e76\u52a0\u901f\u90e8\u7f72\u3002"}}
{"id": "2510.11448", "categories": ["cs.RO", "cs.SY", "eess.SY", "C.3; D.4.1; D.4.4; D.4.8; I.2.9"], "pdf": "https://arxiv.org/pdf/2510.11448", "abs": "https://arxiv.org/abs/2510.11448", "authors": ["Yuankai He", "Hanlin Chen", "Weisong Shi"], "title": "A Faster and More Reliable Middleware for Autonomous Driving Systems", "comment": "8 pages,7 figures, 8 tables", "summary": "Ensuring safety in high-speed autonomous vehicles requires rapid control\nloops and tightly bounded delays from perception to actuation. Many open-source\nautonomy systems rely on ROS 2 middleware; when multiple sensor and control\nnodes share one compute unit, ROS 2 and its DDS transports add significant\n(de)serialization, copying, and discovery overheads, shrinking the available\ntime budget. We present Sensor-in-Memory (SIM), a shared-memory transport\ndesigned for intra-host pipelines in autonomous vehicles. SIM keeps sensor data\nin native memory layouts (e.g., cv::Mat, PCL), uses lock-free bounded double\nbuffers that overwrite old data to prioritize freshness, and integrates into\nROS 2 nodes with four lines of code. Unlike traditional middleware, SIM\noperates beside ROS 2 and is optimized for applications where data freshness\nand minimal latency outweigh guaranteed completeness. SIM provides sequence\nnumbers, a writer heartbeat, and optional checksums to ensure ordering,\nliveness, and basic integrity. On an NVIDIA Jetson Orin Nano, SIM reduces\ndata-transport latency by up to 98% compared to ROS 2 zero-copy transports such\nas FastRTPS and Zenoh, lowers mean latency by about 95%, and narrows\n95th/99th-percentile tail latencies by around 96%. In tests on a\nproduction-ready Level 4 vehicle running Autoware.Universe, SIM increased\nlocalization frequency from 7.5 Hz to 9.5 Hz. Applied across all\nlatency-critical modules, SIM cut average perception-to-decision latency from\n521.91 ms to 290.26 ms, reducing emergency braking distance at 40 mph (64 km/h)\non dry concrete by 13.6 ft (4.14 m).", "AI": {"tldr": "SIM\u662f\u4e00\u79cd\u5171\u4eab\u5185\u5b58\u4f20\u8f93\u65b9\u6848\uff0c\u9488\u5bf9\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u4e2d\u7684\u4e3b\u673a\u5185\u7ba1\u9053\u8bbe\u8ba1\uff0c\u901a\u8fc7\u4fdd\u6301\u4f20\u611f\u5668\u6570\u636e\u7684\u539f\u751f\u5185\u5b58\u5e03\u5c40\u548c\u4f7f\u7528\u65e0\u9501\u53cc\u7f13\u51b2\u533a\uff0c\u663e\u8457\u964d\u4f4e\u4e86ROS 2\u7684\u6570\u636e\u4f20\u8f93\u5ef6\u8fdf\uff0c\u5728NVIDIA Jetson Orin Nano\u4e0a\u53ef\u51cf\u5c11\u9ad8\u8fbe98%\u7684\u5ef6\u8fdf\u3002", "motivation": "\u9ad8\u901f\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u9700\u8981\u5feb\u901f\u63a7\u5236\u5faa\u73af\u548c\u4e25\u683c\u53d7\u9650\u7684\u611f\u77e5\u5230\u6267\u884c\u5ef6\u8fdf\u3002\u5f53\u591a\u4e2a\u4f20\u611f\u5668\u548c\u63a7\u5236\u8282\u70b9\u5171\u4eab\u4e00\u4e2a\u8ba1\u7b97\u5355\u5143\u65f6\uff0cROS 2\u53ca\u5176DDS\u4f20\u8f93\u4f1a\u5e26\u6765\u663e\u8457\u7684\uff08\u53cd\uff09\u5e8f\u5217\u5316\u3001\u590d\u5236\u548c\u53d1\u73b0\u5f00\u9500\uff0c\u7f29\u5c0f\u4e86\u53ef\u7528\u65f6\u95f4\u9884\u7b97\u3002", "method": "SIM\u91c7\u7528\u5171\u4eab\u5185\u5b58\u4f20\u8f93\uff0c\u4fdd\u6301\u4f20\u611f\u5668\u6570\u636e\u7684\u539f\u751f\u5185\u5b58\u5e03\u5c40\uff08\u5982cv::Mat\u3001PCL\uff09\uff0c\u4f7f\u7528\u65e0\u9501\u6709\u754c\u53cc\u7f13\u51b2\u533a\u4f18\u5148\u4fdd\u8bc1\u6570\u636e\u65b0\u9c9c\u5ea6\uff0c\u53ea\u9700\u56db\u884c\u4ee3\u7801\u5373\u53ef\u96c6\u6210\u5230ROS 2\u8282\u70b9\u4e2d\u3002SIM\u5728ROS 2\u65c1\u8fb9\u8fd0\u884c\uff0c\u4e3a\u6570\u636e\u65b0\u9c9c\u5ea6\u548c\u6700\u5c0f\u5ef6\u8fdf\u4f18\u5148\u4e8e\u4fdd\u8bc1\u5b8c\u6574\u6027\u7684\u5e94\u7528\u573a\u666f\u4f18\u5316\u3002", "result": "\u5728NVIDIA Jetson Orin Nano\u4e0a\uff0cSIM\u76f8\u6bd4ROS 2\u96f6\u62f7\u8d1d\u4f20\u8f93\uff08\u5982FastRTPS\u548cZenoh\uff09\u5c06\u6570\u636e\u4f20\u8f93\u5ef6\u8fdf\u964d\u4f4e\u9ad8\u8fbe98%\uff0c\u5e73\u5747\u5ef6\u8fdf\u964d\u4f4e\u7ea695%\uff0c95/99\u767e\u5206\u4f4d\u5c3e\u90e8\u5ef6\u8fdf\u964d\u4f4e\u7ea696%\u3002\u5728L4\u7ea7\u8f66\u8f86\u6d4b\u8bd5\u4e2d\uff0c\u5b9a\u4f4d\u9891\u7387\u4ece7.5 Hz\u63d0\u5347\u52309.5 Hz\uff0c\u611f\u77e5\u5230\u51b3\u7b56\u7684\u5e73\u5747\u5ef6\u8fdf\u4ece521.91 ms\u964d\u81f3290.26 ms\uff0c\u572840 mph\u5e72\u71e5\u6df7\u51dd\u571f\u8def\u9762\u4e0a\u7d27\u6025\u5236\u52a8\u8ddd\u79bb\u51cf\u5c1113.6\u82f1\u5c3a\uff084.14\u7c73\uff09\u3002", "conclusion": "SIM\u901a\u8fc7\u5171\u4eab\u5185\u5b58\u4f20\u8f93\u65b9\u6848\u6709\u6548\u89e3\u51b3\u4e86ROS 2\u5728\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u4e2d\u7684\u5ef6\u8fdf\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u54cd\u5e94\u901f\u5ea6\u548c\u5b89\u5168\u6027\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5bf9\u6570\u636e\u65b0\u9c9c\u5ea6\u548c\u4f4e\u5ef6\u8fdf\u8981\u6c42\u6781\u9ad8\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2510.10689", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10689", "abs": "https://arxiv.org/abs/2510.10689", "authors": ["Caorui Li", "Yu Chen", "Yiyan Ji", "Jin Xu", "Zhenyu Cui", "Shihao Li", "Yuanxing Zhang", "Jiafu Tang", "Zhenghao Song", "Dingling Zhang", "Ying He", "Haoxiang Liu", "Yuxuan Wang", "Qiufeng Wang", "Zhenhe Wu", "Jiehui Luo", "Zhiyu Pan", "Weihao Xie", "Chenchen Zhang", "Zhaohui Wang", "Jiayi Tian", "Yanghai Wang", "Zhe Cao", "Minxin Dai", "Ke Wang", "Runzhe Wen", "Yinghao Ma", "Yaning Pan", "Sungkyun Chang", "Termeh Taheri", "Haiwen Xia", "Christos Plachouras", "Emmanouil Benetos", "Yizhi Li", "Ge Zhang", "Jian Yang", "Tianhao Peng", "Zili Wang", "Minghao Liu", "Junran Peng", "Zhaoxiang Zhang", "Jiaheng Liu"], "title": "OmniVideoBench: Towards Audio-Visual Understanding Evaluation for Omni MLLMs", "comment": null, "summary": "Recent advances in multimodal large language models (MLLMs) have demonstrated\nsubstantial potential in video understanding. However, existing benchmarks fail\nto comprehensively evaluate synergistic reasoning capabilities across audio and\nvisual modalities, often neglecting either one of the modalities or integrating\nthem in a logically inconsistent manner. To bridge this gap, we introduce\nOmniVideoBench, a large-scale and rigorously designed benchmark dedicated to\nassessing synergistic audio-visual understanding, with a strong emphasis on\nmodality complementarity and logical consistency. Specifically, OmniVideoBench\ncomprises 1000 high-quality question-answer(QA) pairs, each annotated with\nstep-by-step reasoning traces, derived from 628 diverse videos ranging from\nseveral seconds to 30 minutes, and manually verified to guarantee complete\ncorrectness and uniqueness. Moreover, OmniVideoBench encompasses 13 carefully\ndesigned question types, covering temporal reasoning, spatial localization,\ncounting, causal inference, summarization, and beyond, thereby capturing the\nessential challenges of video understanding. Evaluation of multiple MLLMs on\nOmniVideoBench reveals a pronounced gap between model performance and human\nreasoning, with open-source models lagging significantly behind their\nclosed-source counterparts, underscoring the inherent difficulty of genuine\naudio-visual reasoning. We will release OmniVideoBench to foster the\ndevelopment of MLLMs with stronger and more generalizable reasoning\ncapabilities.", "AI": {"tldr": "\u63d0\u51fa\u4e86OmniVideoBench\u57fa\u51c6\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u9891\u7406\u89e3\u4e2d\u7684\u97f3\u9891-\u89c6\u89c9\u534f\u540c\u63a8\u7406\u80fd\u529b\uff0c\u5305\u542b1000\u4e2a\u9ad8\u8d28\u91cf\u95ee\u7b54\u5bf9\u548c13\u79cd\u95ee\u9898\u7c7b\u578b\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u97f3\u9891\u548c\u89c6\u89c9\u6a21\u6001\u7684\u534f\u540c\u63a8\u7406\u80fd\u529b\uff0c\u5f80\u5f80\u5ffd\u89c6\u5176\u4e2d\u4e00\u4e2a\u6a21\u6001\u6216\u4ee5\u903b\u8f91\u4e0d\u4e00\u81f4\u7684\u65b9\u5f0f\u6574\u5408\u5b83\u4eec\u3002", "method": "\u6784\u5efa\u5305\u542b1000\u4e2a\u95ee\u7b54\u5bf9\u7684\u5927\u89c4\u6a21\u57fa\u51c6\uff0c\u8fd9\u4e9b\u95ee\u7b54\u5bf9\u6765\u81ea628\u4e2a\u591a\u6837\u5316\u89c6\u9891\uff0c\u6bcf\u4e2a\u95ee\u9898\u90fd\u5e26\u6709\u9010\u6b65\u63a8\u7406\u75d5\u8ff9\uff0c\u5e76\u7ecf\u8fc7\u4eba\u5de5\u9a8c\u8bc1\u786e\u4fdd\u6b63\u786e\u6027\u548c\u552f\u4e00\u6027\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u97f3\u9891-\u89c6\u89c9\u63a8\u7406\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u5f00\u6e90\u6a21\u578b\u660e\u663e\u843d\u540e\u4e8e\u95ed\u6e90\u6a21\u578b\uff0c\u7a81\u663e\u4e86\u771f\u6b63\u97f3\u9891-\u89c6\u89c9\u63a8\u7406\u7684\u5185\u5728\u96be\u5ea6\u3002", "conclusion": "OmniVideoBench\u5c06\u4fc3\u8fdb\u5f00\u53d1\u5177\u6709\u66f4\u5f3a\u548c\u66f4\u901a\u7528\u63a8\u7406\u80fd\u529b\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u3002"}}
{"id": "2510.11491", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.11491", "abs": "https://arxiv.org/abs/2510.11491", "authors": ["Murad Dawood", "Usama Ahmed Siddiquie", "Shahram Khorshidi", "Maren Bennewitz"], "title": "Constraint-Aware Reinforcement Learning via Adaptive Action Scaling", "comment": null, "summary": "Safe reinforcement learning (RL) seeks to mitigate unsafe behaviors that\narise from exploration during training by reducing constraint violations while\nmaintaining task performance. Existing approaches typically rely on a single\npolicy to jointly optimize reward and safety, which can cause instability due\nto conflicting objectives, or they use external safety filters that override\nactions and require prior system knowledge. In this paper, we propose a modular\ncost-aware regulator that scales the agent's actions based on predicted\nconstraint violations, preserving exploration through smooth action modulation\nrather than overriding the policy. The regulator is trained to minimize\nconstraint violations while avoiding degenerate suppression of actions. Our\napproach integrates seamlessly with off-policy RL methods such as SAC and TD3,\nand achieves state-of-the-art return-to-cost ratios on Safety Gym locomotion\ntasks with sparse costs, reducing constraint violations by up to 126 times\nwhile increasing returns by over an order of magnitude compared to prior\nmethods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u7684\u6210\u672c\u611f\u77e5\u8c03\u8282\u5668\uff0c\u901a\u8fc7\u5e73\u6ed1\u7684\u52a8\u4f5c\u8c03\u8282\u800c\u975e\u7b56\u7565\u8986\u76d6\u6765\u51cf\u5c11\u7ea6\u675f\u8fdd\u53cd\uff0c\u540c\u65f6\u4fdd\u6301\u63a2\u7d22\u80fd\u529b\u3002\u8be5\u65b9\u6cd5\u4e0eSAC\u3001TD3\u7b49\u79bb\u7b56\u7565RL\u65b9\u6cd5\u65e0\u7f1d\u96c6\u6210\uff0c\u5728Safety Gym\u8fd0\u52a8\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u56de\u62a5-\u6210\u672c\u6bd4\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u8981\u4e48\u4f7f\u7528\u5355\u4e00\u7b56\u7565\u8054\u5408\u4f18\u5316\u5956\u52b1\u548c\u5b89\u5168\u6027\uff0c\u5bfc\u81f4\u76ee\u6807\u51b2\u7a81\u548c\u4e0d\u7a33\u5b9a\uff1b\u8981\u4e48\u4f7f\u7528\u9700\u8981\u5148\u9a8c\u7cfb\u7edf\u77e5\u8bc6\u7684\u5916\u90e8\u5b89\u5168\u8fc7\u6ee4\u5668\u6765\u8986\u76d6\u52a8\u4f5c\u3002\u9700\u8981\u4e00\u79cd\u66f4\u7a33\u5b9a\u4e14\u4e0d\u9700\u8981\u5148\u9a8c\u77e5\u8bc6\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u6a21\u5757\u5316\u6210\u672c\u611f\u77e5\u8c03\u8282\u5668\uff0c\u57fa\u4e8e\u9884\u6d4b\u7684\u7ea6\u675f\u8fdd\u53cd\u6765\u7f29\u653e\u667a\u80fd\u4f53\u7684\u52a8\u4f5c\uff0c\u901a\u8fc7\u5e73\u6ed1\u7684\u52a8\u4f5c\u8c03\u8282\u800c\u975e\u7b56\u7565\u8986\u76d6\u6765\u4fdd\u6301\u63a2\u7d22\u3002\u8c03\u8282\u5668\u88ab\u8bad\u7ec3\u4e3a\u6700\u5c0f\u5316\u7ea6\u675f\u8fdd\u53cd\u540c\u65f6\u907f\u514d\u52a8\u4f5c\u7684\u9000\u5316\u6291\u5236\u3002", "result": "\u5728Safety Gym\u8fd0\u52a8\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u56de\u62a5-\u6210\u672c\u6bd4\uff0c\u7ea6\u675f\u8fdd\u53cd\u51cf\u5c11\u4e86\u9ad8\u8fbe126\u500d\uff0c\u540c\u65f6\u56de\u62a5\u6bd4\u5148\u524d\u65b9\u6cd5\u63d0\u9ad8\u4e86\u4e00\u4e2a\u6570\u91cf\u7ea7\u4ee5\u4e0a\u3002", "conclusion": "\u6a21\u5757\u5316\u6210\u672c\u611f\u77e5\u8c03\u8282\u5668\u63d0\u4f9b\u4e86\u4e00\u79cd\u7a33\u5b9a\u4e14\u9ad8\u6548\u7684\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u663e\u8457\u51cf\u5c11\u7ea6\u675f\u8fdd\u53cd\u540c\u65f6\u63d0\u9ad8\u4efb\u52a1\u6027\u80fd\uff0c\u4e14\u4e0d\u9700\u8981\u5148\u9a8c\u7cfb\u7edf\u77e5\u8bc6\u3002"}}
{"id": "2510.10804", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10804", "abs": "https://arxiv.org/abs/2510.10804", "authors": ["Alessandro Albini", "Mohsen Kaboli", "Giorgio Cannata", "Perla Maiolino"], "title": "Representing Data in Robotic Tactile Perception -- A Review", "comment": null, "summary": "Robotic tactile perception is a complex process involving several\ncomputational steps performed at different levels. Tactile information is\nshaped by the interplay of robot actions, the mechanical properties of its\nbody, and the software that processes the data. In this respect, high-level\ncomputation, required to process and extract information, is commonly performed\nby adapting existing techniques from other domains, such as computer vision,\nwhich expects input data to be properly structured. Therefore, it is necessary\nto transform tactile sensor data to match a specific data structure. This\noperation directly affects the tactile information encoded and, as a\nconsequence, the task execution. This survey aims to address this specific\naspect of the tactile perception pipeline, namely Data Representation. The\npaper first clearly defines its contributions to the perception pipeline and\nthen reviews how previous studies have dealt with the problem of representing\ntactile information, investigating the relationships among hardware,\nrepresentations, and high-level computation methods. The analysis has led to\nthe identification of six structures commonly used in the literature to\nrepresent data. The manuscript provides discussions and guidelines for properly\nselecting a representation depending on operating conditions, including the\navailable hardware, the tactile information required to be encoded, and the\ntask at hand.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8c03\u67e5\u4e86\u673a\u5668\u4eba\u89e6\u89c9\u611f\u77e5\u4e2d\u7684\u6570\u636e\u8868\u793a\u95ee\u9898\uff0c\u5206\u6790\u4e86\u516d\u79cd\u5e38\u7528\u6570\u636e\u7ed3\u6784\uff0c\u5e76\u63d0\u4f9b\u4e86\u6839\u636e\u786c\u4ef6\u3001\u6240\u9700\u89e6\u89c9\u4fe1\u606f\u548c\u4efb\u52a1\u9009\u62e9\u9002\u5f53\u8868\u793a\u7684\u6307\u5357\u3002", "motivation": "\u673a\u5668\u4eba\u89e6\u89c9\u611f\u77e5\u9700\u8981\u5c06\u4f20\u611f\u5668\u6570\u636e\u8f6c\u6362\u4e3a\u7279\u5b9a\u6570\u636e\u7ed3\u6784\u4ee5\u9002\u5e94\u9ad8\u7ea7\u8ba1\u7b97\u65b9\u6cd5\uff0c\u8fd9\u79cd\u8f6c\u6362\u76f4\u63a5\u5f71\u54cd\u4efb\u52a1\u6267\u884c\u6548\u679c\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u6570\u636e\u8868\u793a\u5206\u6790\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u5206\u6790\u5148\u524d\u7814\u7a76\u5982\u4f55\u5904\u7406\u89e6\u89c9\u4fe1\u606f\u8868\u793a\u95ee\u9898\uff0c\u7814\u7a76\u786c\u4ef6\u3001\u8868\u793a\u65b9\u6cd5\u548c\u9ad8\u7ea7\u8ba1\u7b97\u65b9\u6cd5\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u8bc6\u522b\u51fa\u6587\u732e\u4e2d\u5e38\u7528\u7684\u516d\u79cd\u6570\u636e\u7ed3\u6784\uff0c\u5e76\u5efa\u7acb\u4e86\u9009\u62e9\u9002\u5f53\u8868\u793a\u7684\u6307\u5bfc\u539f\u5219\u3002", "conclusion": "\u6570\u636e\u8868\u793a\u662f\u89e6\u89c9\u611f\u77e5\u6d41\u7a0b\u4e2d\u7684\u5173\u952e\u73af\u8282\uff0c\u9700\u8981\u6839\u636e\u64cd\u4f5c\u6761\u4ef6\u3001\u53ef\u7528\u786c\u4ef6\u3001\u6240\u9700\u89e6\u89c9\u4fe1\u606f\u548c\u5177\u4f53\u4efb\u52a1\u6765\u9009\u62e9\u5408\u9002\u7684\u8868\u793a\u65b9\u6cd5\u3002"}}
{"id": "2510.10701", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.10701", "abs": "https://arxiv.org/abs/2510.10701", "authors": ["Yang Xu", "Shuwei Chen", "Jun Liu", "Feng Cao", "Xingxing He"], "title": "Extended Triangular Method: A Generalized Algorithm for Contradiction Separation Based Automated Deduction", "comment": "38 pages, 8 figures", "summary": "Automated deduction lies at the core of Artificial Intelligence (AI),\nunderpinning theorem proving, formal verification, and logical reasoning.\nDespite decades of progress, reconciling deductive completeness with\ncomputational efficiency remains an enduring challenge. Traditional reasoning\ncalculi, grounded in binary resolution, restrict inference to pairwise clause\ninteractions and thereby limit deductive synergy among multiple clauses. The\nContradiction Separation Extension (CSE) framework, introduced in 2018,\nproposed a dynamic multi-clause reasoning theory that redefined logical\ninference as a process of contradiction separation rather than sequential\nresolution. While that work established the theoretical foundation, its\nalgorithmic realization remained unformalized and unpublished. This work\npresents the Extended Triangular Method (ETM), a generalized\ncontradiction-construction algorithm that formalizes and extends the internal\nmechanisms of contradiction separation. The ETM unifies multiple\ncontradiction-building strategies, including the earlier Standard Extension\nmethod, within a triangular geometric framework that supports flexible clause\ninteraction and dynamic synergy. ETM serves as the algorithmic core of several\nhigh-performance theorem provers, CSE, CSE-E, CSI-E, and CSI-Enig, whose\ncompetitive results in standard first-order benchmarks (TPTP problem sets and\nCASC 2018-2015) empirically validate the effectiveness and generality of the\nproposed approach. By bridging theoretical abstraction and operational\nimplementation, ETM advances the contradiction separation paradigm into a\ngeneralized, scalable, and practically competitive model for automated\nreasoning, offering new directions for future research in logical inference and\ntheorem proving.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u6269\u5c55\u4e09\u89d2\u65b9\u6cd5(ETM)\uff0c\u4f5c\u4e3a\u77db\u76fe\u5206\u79bb\u6269\u5c55(CSE)\u6846\u67b6\u7684\u7b97\u6cd5\u5b9e\u73b0\uff0c\u7edf\u4e00\u4e86\u591a\u79cd\u77db\u76fe\u6784\u5efa\u7b56\u7565\uff0c\u5e76\u5728\u6807\u51c6\u4e00\u9636\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u63a8\u7406\u6f14\u7b97\u57fa\u4e8e\u4e8c\u5143\u5f52\u7ed3\uff0c\u9650\u5236\u4e86\u591a\u5b50\u53e5\u4e4b\u95f4\u7684\u63a8\u7406\u534f\u540c\u6548\u5e94\u3002\u77db\u76fe\u5206\u79bb\u6269\u5c55\u6846\u67b6\u91cd\u65b0\u5b9a\u4e49\u4e86\u903b\u8f91\u63a8\u7406\u8fc7\u7a0b\uff0c\u4f46\u5176\u7b97\u6cd5\u5b9e\u73b0\u5c1a\u672a\u5f62\u5f0f\u5316\u3002", "method": "\u6269\u5c55\u4e09\u89d2\u65b9\u6cd5(ETM)\u5728\u4e09\u89d2\u51e0\u4f55\u6846\u67b6\u4e0b\u7edf\u4e00\u4e86\u591a\u79cd\u77db\u76fe\u6784\u5efa\u7b56\u7565\uff0c\u652f\u6301\u7075\u6d3b\u7684\u5b50\u53e5\u4ea4\u4e92\u548c\u52a8\u6001\u534f\u540c\uff0c\u4f5c\u4e3a\u591a\u4e2a\u9ad8\u6027\u80fd\u5b9a\u7406\u8bc1\u660e\u5668\u7684\u6838\u5fc3\u7b97\u6cd5\u3002", "result": "\u57fa\u4e8eETM\u7684\u5b9a\u7406\u8bc1\u660e\u5668(CSE\u3001CSE-E\u3001CSI-E\u3001CSI-Enig)\u5728\u6807\u51c6\u4e00\u9636\u57fa\u51c6\u6d4b\u8bd5(TPTP\u95ee\u9898\u96c6\u548cCASC 2018-2015)\u4e2d\u53d6\u5f97\u4e86\u6709\u7ade\u4e89\u529b\u7684\u7ed3\u679c\u3002", "conclusion": "ETM\u5c06\u77db\u76fe\u5206\u79bb\u8303\u5f0f\u63a8\u8fdb\u4e3a\u901a\u7528\u3001\u53ef\u6269\u5c55\u4e14\u5177\u6709\u5b9e\u9645\u7ade\u4e89\u529b\u7684\u81ea\u52a8\u63a8\u7406\u6a21\u578b\uff0c\u4e3a\u903b\u8f91\u63a8\u7406\u548c\u5b9a\u7406\u8bc1\u660e\u7684\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2510.11534", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.11534", "abs": "https://arxiv.org/abs/2510.11534", "authors": ["Enli Lin", "Ziyuan Yang", "Qiujing Lu", "Jianming Hu", "Shuo Feng"], "title": "IntersectioNDE: Learning Complex Urban Traffic Dynamics based on Interaction Decoupling Strategy", "comment": "Accepted by ITSC 2025", "summary": "Realistic traffic simulation is critical for ensuring the safety and\nreliability of autonomous vehicles (AVs), especially in complex and diverse\nurban traffic environments. However, existing data-driven simulators face two\nkey challenges: a limited focus on modeling dense, heterogeneous interactions\nat urban intersections - which are prevalent, crucial, and practically\nsignificant in countries like China, featuring diverse agents including\nmotorized vehicles (MVs), non-motorized vehicles (NMVs), and pedestrians - and\nthe inherent difficulty in robustly learning high-dimensional joint\ndistributions for such high-density scenes, often leading to mode collapse and\nlong-term simulation instability. We introduce City Crossings Dataset\n(CiCross), a large-scale dataset collected from a real-world urban\nintersection, uniquely capturing dense, heterogeneous multi-agent interactions,\nparticularly with a substantial proportion of MVs, NMVs and pedestrians. Based\non this dataset, we propose IntersectioNDE (Intersection Naturalistic Driving\nEnvironment), a data-driven simulator tailored for complex urban intersection\nscenarios. Its core component is the Interaction Decoupling Strategy (IDS), a\ntraining paradigm that learns compositional dynamics from agent subsets,\nenabling the marginal-to-joint simulation. Integrated into a scene-aware\nTransformer network with specialized training techniques, IDS significantly\nenhances simulation robustness and long-term stability for modeling\nheterogeneous interactions. Experiments on CiCross show that IntersectioNDE\noutperforms baseline methods in simulation fidelity, stability, and its ability\nto replicate complex, distribution-level urban traffic dynamics.", "AI": {"tldr": "\u63d0\u51fa\u4e86IntersectioNDE\u6a21\u62df\u5668\uff0c\u4e13\u95e8\u7528\u4e8e\u590d\u6742\u57ce\u5e02\u4ea4\u53c9\u8def\u53e3\u573a\u666f\uff0c\u901a\u8fc7\u4ea4\u4e92\u89e3\u8026\u7b56\u7565\u89e3\u51b3\u9ad8\u5bc6\u5ea6\u5f02\u6784\u4ea4\u901a\u6a21\u62df\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u9a71\u52a8\u6a21\u62df\u5668\u96be\u4ee5\u5efa\u6a21\u57ce\u5e02\u4ea4\u53c9\u8def\u53e3\u7684\u5bc6\u96c6\u5f02\u6784\u4ea4\u4e92\uff0c\u7279\u522b\u662f\u5728\u4e2d\u56fd\u7b49\u56fd\u5bb6\u5b58\u5728\u591a\u79cd\u4ea4\u901a\u53c2\u4e0e\u8005\uff08\u673a\u52a8\u8f66\u3001\u975e\u673a\u52a8\u8f66\u3001\u884c\u4eba\uff09\u7684\u590d\u6742\u573a\u666f\uff0c\u4e14\u5b66\u4e60\u9ad8\u7ef4\u8054\u5408\u5206\u5e03\u5bb9\u6613\u5bfc\u81f4\u6a21\u5f0f\u5d29\u6e83\u548c\u957f\u671f\u6a21\u62df\u4e0d\u7a33\u5b9a\u3002", "method": "\u57fa\u4e8eCity Crossings Dataset\uff0c\u63d0\u51faIntersectioNDE\u6a21\u62df\u5668\uff0c\u6838\u5fc3\u662f\u4ea4\u4e92\u89e3\u8026\u7b56\u7565\uff08IDS\uff09\uff0c\u901a\u8fc7\u4ece\u667a\u80fd\u4f53\u5b50\u96c6\u5b66\u4e60\u7ec4\u5408\u52a8\u6001\uff0c\u5b9e\u73b0\u8fb9\u9645\u5230\u8054\u5408\u7684\u6a21\u62df\uff0c\u5e76\u96c6\u6210\u5230\u573a\u666f\u611f\u77e5Transformer\u7f51\u7edc\u4e2d\u3002", "result": "\u5728CiCross\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cIntersectioNDE\u5728\u6a21\u62df\u4fdd\u771f\u5ea6\u3001\u7a33\u5b9a\u6027\u4ee5\u53ca\u590d\u5236\u590d\u6742\u57ce\u5e02\u4ea4\u901a\u52a8\u6001\u5206\u5e03\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "IntersectioNDE\u901a\u8fc7\u521b\u65b0\u7684\u4ea4\u4e92\u89e3\u8026\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86\u57ce\u5e02\u4ea4\u53c9\u8def\u53e3\u5bc6\u96c6\u5f02\u6784\u4ea4\u901a\u6a21\u62df\u7684\u6311\u6218\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5728\u590d\u6742\u57ce\u5e02\u73af\u5883\u4e2d\u7684\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u4eff\u771f\u5e73\u53f0\u3002"}}
{"id": "2510.10843", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10843", "abs": "https://arxiv.org/abs/2510.10843", "authors": ["Jared Grinberg", "Yanran Ding"], "title": "Contact Sensing via Joint Torque Sensors and a Force/Torque Sensor for Legged Robots", "comment": "Proc. IEEE 21st International Conference on Automation Science and\n  Engineering (CASE), Los Angeles, CA, USA, Aug. 17-21, 2025, pp. 1-7,\n  doi:10.1109/CASE58245.2025.11164031", "summary": "This paper presents a method for detecting and localizing contact along robot\nlegs using distributed joint torque sensors and a single hip-mounted\nforce-torque (FT) sensor using a generalized momentum-based observer framework.\nWe designed a low-cost strain-gauge-based joint torque sensor that can be\ninstalled on every joint to provide direct torque measurements, eliminating the\nneed for complex friction models and providing more accurate torque readings\nthan estimation based on motor current. Simulation studies on a floating-based\n2-DoF robot leg verified that the proposed framework accurately recovers\ncontact force and location along the thigh and shin links. Through a\ncalibration procedure, our torque sensor achieved an average 96.4% accuracy\nrelative to ground truth measurements. Building upon the torque sensor, we\nperformed hardware experiments on a 2-DoF manipulator, which showed\nsub-centimeter contact localization accuracy and force errors below 0.2 N.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u5206\u5e03\u5f0f\u5173\u8282\u626d\u77e9\u4f20\u611f\u5668\u548c\u5355\u4e2a\u9acb\u90e8\u529b-\u626d\u77e9\u4f20\u611f\u5668\u7684\u63a5\u89e6\u68c0\u6d4b\u4e0e\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e7f\u4e49\u52a8\u91cf\u89c2\u6d4b\u5668\u6846\u67b6\u5b9e\u73b0\u673a\u5668\u4eba\u817f\u90e8\u63a5\u89e6\u529b\u7684\u7cbe\u786e\u6062\u590d\u548c\u5b9a\u4f4d\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u590d\u6742\u7684\u6469\u64e6\u6a21\u578b\u6216\u57fa\u4e8e\u7535\u673a\u7535\u6d41\u7684\u626d\u77e9\u4f30\u8ba1\uff0c\u7cbe\u5ea6\u6709\u9650\u3002\u9700\u8981\u66f4\u51c6\u786e\u3001\u4f4e\u6210\u672c\u7684\u63a5\u89e6\u68c0\u6d4b\u65b9\u6848\u6765\u63d0\u5347\u673a\u5668\u4eba\u817f\u90e8\u4e0e\u73af\u5883\u4ea4\u4e92\u7684\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1\u4e86\u4f4e\u6210\u672c\u5e94\u53d8\u7247\u5f0f\u5173\u8282\u626d\u77e9\u4f20\u611f\u5668\uff0c\u5b89\u88c5\u5728\u6bcf\u4e2a\u5173\u8282\u4e0a\u76f4\u63a5\u6d4b\u91cf\u626d\u77e9\uff1b\u91c7\u7528\u5e7f\u4e49\u52a8\u91cf\u89c2\u6d4b\u5668\u6846\u67b6\uff0c\u7ed3\u5408\u5206\u5e03\u5f0f\u5173\u8282\u626d\u77e9\u4f20\u611f\u5668\u548c\u5355\u4e2a\u9acb\u90e8FT\u4f20\u611f\u5668\u8fdb\u884c\u63a5\u89e6\u529b\u6062\u590d\u548c\u5b9a\u4f4d\u3002", "result": "\u4eff\u771f\u9a8c\u8bc1\uff1a\u5728\u6d6e\u52a8\u57fa2\u81ea\u7531\u5ea6\u673a\u5668\u4eba\u817f\u4e0a\u51c6\u786e\u6062\u590d\u5927\u817f\u548c\u5c0f\u817f\u8fde\u6746\u4e0a\u7684\u63a5\u89e6\u529b\u548c\u4f4d\u7f6e\uff1b\u786c\u4ef6\u5b9e\u9a8c\uff1a2\u81ea\u7531\u5ea6\u673a\u68b0\u81c2\u5b9e\u73b0\u4e9a\u5398\u7c73\u7ea7\u63a5\u89e6\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u529b\u8bef\u5dee\u4f4e\u4e8e0.2N\uff1b\u626d\u77e9\u4f20\u611f\u5668\u6821\u51c6\u540e\u76f8\u5bf9\u5730\u9762\u771f\u5b9e\u6d4b\u91cf\u8fbe\u523096.4%\u7684\u5e73\u5747\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5206\u5e03\u5f0f\u626d\u77e9\u4f20\u611f\u6d88\u9664\u4e86\u590d\u6742\u6469\u64e6\u6a21\u578b\u7684\u9700\u6c42\uff0c\u63d0\u4f9b\u4e86\u6bd4\u7535\u673a\u7535\u6d41\u4f30\u8ba1\u66f4\u51c6\u786e\u7684\u626d\u77e9\u8bfb\u6570\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684\u63a5\u89e6\u68c0\u6d4b\u548c\u5b9a\u4f4d\uff0c\u4e3a\u673a\u5668\u4eba\u817f\u90e8\u4ea4\u4e92\u63a7\u5236\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.10703", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10703", "abs": "https://arxiv.org/abs/2510.10703", "authors": ["Xiangyu Wang", "Haocheng Yang", "Fengxiang Cheng", "Fenrong Liu"], "title": "Adaptive Selection of Symbolic Languages for Improving LLM Logical Reasoning", "comment": null, "summary": "Large Language Models (LLMs) still struggle with complex logical reasoning.\nWhile previous works achieve remarkable improvements, their performance is\nhighly dependent on the correctness of translating natural language (NL)\nproblems into a symbolic language (SL). Though numerous works focusing on\nimproving this translation accuracy, they only consider the similarity between\nthe meaning of SL and NL, overlooking another crucial influencing factor, the\nselection of the target SL type itself. For example, first-order logic language\nspecializes in logical reasoning with categorical syllogisms and complex\nquantifiers, while Boolean satisfiability formalism excels at representing\nconstraint satisfaction like partial problems. To our knowledge, this is the\nfirst paper to claim and verify that different NL logical reasoning problem\ncorresponds to different optimal SL formalization for translation. Based on\nthis, we propose a methods to improve the logical reasoning performance of LLMs\nby adaptively selecting the most suitable SL for each problem prior to\ntranslation. Specifically, we leverage LLMs to select the target SL among\nfirst-order logic, logic programming and Boolean satisfiability and then\ntranslate the problem in NL to target SL expressions as well as employ the\ncorresponding logical solver to derive the final answer. Experimental results\non benchmarks show that our adaptive selection method significantly outperforms\ntranslating all into single SL and randomly selecting the SL. On a mixed\ndataset of these benchmarks, our approach achieves 96% accuracy, which\nimproving performance by 25% compared to the second highest accuracy from the\nfirst-order logic translation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u9009\u62e9\u7b26\u53f7\u8bed\u8a00\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u903b\u8f91\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u4e3a\u4e0d\u540c\u95ee\u9898\u9009\u62e9\u6700\u5408\u9002\u7684\u7b26\u53f7\u8bed\u8a00\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5c06\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u8f6c\u6362\u4e3a\u7b26\u53f7\u8bed\u8a00\u65f6\uff0c\u53ea\u5173\u6ce8\u8bed\u4e49\u76f8\u4f3c\u5ea6\uff0c\u5ffd\u7565\u4e86\u4e0d\u540c\u7b26\u53f7\u8bed\u8a00\u7c7b\u578b\u672c\u8eab\u5bf9\u7279\u5b9a\u903b\u8f91\u63a8\u7406\u95ee\u9898\u7684\u9002\u7528\u6027\u5dee\u5f02\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e3a\u6bcf\u4e2a\u95ee\u9898\u81ea\u9002\u5e94\u9009\u62e9\u6700\u5408\u9002\u7684\u7b26\u53f7\u8bed\u8a00\uff08\u4e00\u9636\u903b\u8f91\u3001\u903b\u8f91\u7f16\u7a0b\u6216\u5e03\u5c14\u53ef\u6ee1\u8db3\u6027\uff09\uff0c\u7136\u540e\u5c06\u95ee\u9898\u7ffb\u8bd1\u5230\u76ee\u6807\u7b26\u53f7\u8bed\u8a00\u5e76\u4f7f\u7528\u76f8\u5e94\u7684\u903b\u8f91\u6c42\u89e3\u5668\u5f97\u51fa\u6700\u7ec8\u7b54\u6848\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u81ea\u9002\u5e94\u9009\u62e9\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u5355\u4e00\u7b26\u53f7\u8bed\u8a00\u7ffb\u8bd1\u548c\u968f\u673a\u9009\u62e9\u65b9\u6cd5\u3002\u5728\u6df7\u5408\u6570\u636e\u96c6\u4e0a\u8fbe\u523096%\u7684\u51c6\u786e\u7387\uff0c\u6bd4\u4e00\u9636\u903b\u8f91\u7ffb\u8bd1\u7684\u6b21\u9ad8\u51c6\u786e\u7387\u63d0\u5347\u4e8625%\u3002", "conclusion": "\u4e0d\u540c\u81ea\u7136\u8bed\u8a00\u903b\u8f91\u63a8\u7406\u95ee\u9898\u5bf9\u5e94\u4e0d\u540c\u7684\u6700\u4f18\u7b26\u53f7\u8bed\u8a00\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u81ea\u9002\u5e94\u9009\u62e9\u76ee\u6807\u7b26\u53f7\u8bed\u8a00\u80fd\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u903b\u8f91\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2510.11682", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.11682", "abs": "https://arxiv.org/abs/2510.11682", "authors": ["Hang Liu", "Yuman Gao", "Sangli Teng", "Yufeng Chi", "Yakun Sophia Shao", "Zhongyu Li", "Maani Ghaffari", "Koushil Sreenath"], "title": "Ego-Vision World Model for Humanoid Contact Planning", "comment": null, "summary": "Enabling humanoid robots to exploit physical contact, rather than simply\navoid collisions, is crucial for autonomy in unstructured environments.\nTraditional optimization-based planners struggle with contact complexity, while\non-policy reinforcement learning (RL) is sample-inefficient and has limited\nmulti-task ability. We propose a framework combining a learned world model with\nsampling-based Model Predictive Control (MPC), trained on a demonstration-free\noffline dataset to predict future outcomes in a compressed latent space. To\naddress sparse contact rewards and sensor noise, the MPC uses a learned\nsurrogate value function for dense, robust planning. Our single, scalable model\nsupports contact-aware tasks, including wall support after perturbation,\nblocking incoming objects, and traversing height-limited arches, with improved\ndata efficiency and multi-task capability over on-policy RL. Deployed on a\nphysical humanoid, our system achieves robust, real-time contact planning from\nproprioception and ego-centric depth images. Website:\nhttps://ego-vcp.github.io/", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u5b66\u4e60\u4e16\u754c\u6a21\u578b\u4e0e\u91c7\u6837\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u79bb\u7ebf\u6570\u636e\u96c6\u8bad\u7ec3\uff0c\u5728\u538b\u7f29\u6f5c\u5728\u7a7a\u95f4\u9884\u6d4b\u672a\u6765\u7ed3\u679c\uff0c\u5b9e\u73b0\u4eba\u5f62\u673a\u5668\u4eba\u7684\u63a5\u89e6\u611f\u77e5\u89c4\u5212\u3002", "motivation": "\u8ba9\u4eba\u5f62\u673a\u5668\u4eba\u80fd\u591f\u5229\u7528\u7269\u7406\u63a5\u89e6\u800c\u975e\u4ec5\u907f\u514d\u78b0\u649e\uff0c\u5728\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u5b9e\u73b0\u81ea\u4e3b\u6027\u3002\u4f20\u7edf\u4f18\u5316\u89c4\u5212\u5668\u96be\u4ee5\u5904\u7406\u63a5\u89e6\u590d\u6742\u6027\uff0c\u800c\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u6837\u672c\u6548\u7387\u4f4e\u4e14\u591a\u4efb\u52a1\u80fd\u529b\u6709\u9650\u3002", "method": "\u4f7f\u7528\u5b66\u4e60\u7684\u4e16\u754c\u6a21\u578b\u7ed3\u5408\u91c7\u6837\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff0c\u5728\u79bb\u7ebf\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u9884\u6d4b\u538b\u7f29\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u672a\u6765\u7ed3\u679c\u3002\u4e3a\u89e3\u51b3\u7a00\u758f\u63a5\u89e6\u5956\u52b1\u548c\u4f20\u611f\u5668\u566a\u58f0\uff0cMPC\u4f7f\u7528\u5b66\u4e60\u7684\u4ee3\u7406\u4ef7\u503c\u51fd\u6570\u8fdb\u884c\u5bc6\u96c6\u3001\u9c81\u68d2\u7684\u89c4\u5212\u3002", "result": "\u5355\u4e00\u53ef\u6269\u5c55\u6a21\u578b\u652f\u6301\u591a\u79cd\u63a5\u89e6\u611f\u77e5\u4efb\u52a1\uff0c\u5305\u62ec\u6270\u52a8\u540e\u7684\u5899\u58c1\u652f\u6491\u3001\u963b\u6321\u6765\u88ad\u7269\u4f53\u548c\u7a7f\u8d8a\u9ad8\u5ea6\u53d7\u9650\u62f1\u95e8\uff0c\u76f8\u6bd4\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u5177\u6709\u66f4\u597d\u7684\u6570\u636e\u6548\u7387\u548c\u591a\u4efb\u52a1\u80fd\u529b\u3002\u5728\u7269\u7406\u4eba\u5f62\u673a\u5668\u4eba\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u63a5\u89e6\u89c4\u5212\u3002", "conclusion": "\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u4ece\u672c\u4f53\u611f\u77e5\u548c\u81ea\u6211\u4e2d\u5fc3\u6df1\u5ea6\u56fe\u50cf\u7684\u9c81\u68d2\u5b9e\u65f6\u63a5\u89e6\u89c4\u5212\uff0c\u4e3a\u4eba\u5f62\u673a\u5668\u4eba\u5728\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u64cd\u4f5c\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.10851", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10851", "abs": "https://arxiv.org/abs/2510.10851", "authors": ["Tingxuan Leng", "Yushi Wang", "Tinglong Zheng", "Changsheng Luo", "Mingguo Zhao"], "title": "Preference-Conditioned Multi-Objective RL for Integrated Command Tracking and Force Compliance in Humanoid Locomotion", "comment": null, "summary": "Humanoid locomotion requires not only accurate command tracking for\nnavigation but also compliant responses to external forces during human\ninteraction. Despite significant progress, existing RL approaches mainly\nemphasize robustness, yielding policies that resist external forces but lack\ncompliance-particularly challenging for inherently unstable humanoids. In this\nwork, we address this by formulating humanoid locomotion as a multi-objective\noptimization problem that balances command tracking and external force\ncompliance. We introduce a preference-conditioned multi-objective RL (MORL)\nframework that integrates rigid command following and compliant behaviors\nwithin a single omnidirectional locomotion policy. External forces are modeled\nvia velocity-resistance factor for consistent reward design, and training\nleverages an encoder-decoder structure that infers task-relevant privileged\nfeatures from deployable observations. We validate our approach in both\nsimulation and real-world experiments on a humanoid robot. Experimental results\nindicate that our framework not only improves adaptability and convergence over\nstandard pipelines, but also realizes deployable preference-conditioned\nhumanoid locomotion.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u504f\u597d\u6761\u4ef6\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u4eba\u5f62\u673a\u5668\u4eba\u8fd0\u52a8\u63a7\u5236\uff0c\u5e73\u8861\u547d\u4ee4\u8ddf\u8e2a\u548c\u5916\u90e8\u529b\u987a\u5e94\u6027", "motivation": "\u73b0\u6709RL\u65b9\u6cd5\u4e3b\u8981\u5f3a\u8c03\u9c81\u68d2\u6027\uff0c\u5bfc\u81f4\u7b56\u7565\u62b5\u6297\u5916\u90e8\u529b\u4f46\u7f3a\u4e4f\u987a\u5e94\u6027\uff0c\u8fd9\u5bf9\u672c\u5c31\u4e0d\u7a33\u5b9a\u7684\u4eba\u5f62\u673a\u5668\u4eba\u7279\u522b\u5177\u6709\u6311\u6218\u6027", "method": "\u4f7f\u7528\u504f\u597d\u6761\u4ef6\u591a\u76ee\u6807RL\u6846\u67b6\uff0c\u901a\u8fc7\u901f\u5ea6\u963b\u529b\u56e0\u5b50\u5efa\u6a21\u5916\u90e8\u529b\uff0c\u91c7\u7528\u7f16\u7801\u5668-\u89e3\u7801\u5668\u7ed3\u6784\u4ece\u53ef\u90e8\u7f72\u89c2\u6d4b\u4e2d\u63a8\u65ad\u7279\u6743\u7279\u5f81", "result": "\u5728\u4eff\u771f\u548c\u771f\u5b9e\u4eba\u5f62\u673a\u5668\u4eba\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\uff0c\u6846\u67b6\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u9002\u5e94\u6027\u548c\u6536\u655b\u6027\uff0c\u8fd8\u5b9e\u73b0\u4e86\u53ef\u90e8\u7f72\u7684\u504f\u597d\u6761\u4ef6\u4eba\u5f62\u8fd0\u52a8", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u4eba\u5f62\u673a\u5668\u4eba\u8fd0\u52a8\u4e2d\u547d\u4ee4\u8ddf\u8e2a\u4e0e\u5916\u90e8\u529b\u987a\u5e94\u6027\u4e4b\u95f4\u7684\u5e73\u8861\u95ee\u9898"}}
{"id": "2510.10813", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2510.10813", "abs": "https://arxiv.org/abs/2510.10813", "authors": ["Enric Junque de Fortuny", "Veronica Roberta Cappelli"], "title": "LLMs as Strategic Agents: Beliefs, Best Response Behavior, and Emergent Heuristics", "comment": null, "summary": "Large Language Models (LLMs) are increasingly applied to domains that require\nreasoning about other agents' behavior, such as negotiation, policy design, and\nmarket simulation, yet existing research has mostly evaluated their adherence\nto equilibrium play or their exhibited depth of reasoning. Whether they display\ngenuine strategic thinking, understood as the coherent formation of beliefs\nabout other agents, evaluation of possible actions, and choice based on those\nbeliefs, remains unexplored. We develop a framework to identify this ability by\ndisentangling beliefs, evaluation, and choice in static, complete-information\ngames, and apply it across a series of non-cooperative environments. By jointly\nanalyzing models' revealed choices and reasoning traces, and introducing a new\ncontext-free game to rule out imitation from memorization, we show that current\nfrontier models exhibit belief-coherent best-response behavior at targeted\nreasoning depths. When unconstrained, they self-limit their depth of reasoning\nand form differentiated conjectures about human and synthetic opponents,\nrevealing an emergent form of meta-reasoning. Under increasing complexity,\nexplicit recursion gives way to internally generated heuristic rules of choice\nthat are stable, model-specific, and distinct from known human biases. These\nfindings indicate that belief coherence, meta-reasoning, and novel heuristic\nformation can emerge jointly from language modeling objectives, providing a\nstructured basis for the study of strategic cognition in artificial agents.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u6846\u67b6\u6765\u8bc4\u4f30LLMs\u662f\u5426\u5177\u5907\u771f\u6b63\u7684\u6218\u7565\u601d\u7ef4\u80fd\u529b\uff0c\u901a\u8fc7\u5206\u6790\u4fe1\u5ff5\u3001\u8bc4\u4f30\u548c\u9009\u62e9\u5728\u9759\u6001\u5b8c\u5168\u4fe1\u606f\u535a\u5f08\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u524d\u6cbf\u6a21\u578b\u5728\u7279\u5b9a\u63a8\u7406\u6df1\u5ea6\u4e0b\u8868\u73b0\u51fa\u4fe1\u5ff5\u4e00\u81f4\u7684\u6700\u4f73\u54cd\u5e94\u884c\u4e3a\uff0c\u5e76\u5c55\u73b0\u51fa\u5143\u63a8\u7406\u548c\u65b0\u578b\u542f\u53d1\u5f0f\u89c4\u5219\u5f62\u6210\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u8bc4\u4f30LLMs\u5728\u5747\u8861\u535a\u5f08\u6216\u63a8\u7406\u6df1\u5ea6\u65b9\u9762\u7684\u8868\u73b0\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u662f\u5426\u5177\u5907\u771f\u6b63\u6218\u7565\u601d\u7ef4\u80fd\u529b\uff08\u5305\u62ec\u5f62\u6210\u5173\u4e8e\u5176\u4ed6\u667a\u80fd\u4f53\u7684\u4fe1\u5ff5\u3001\u8bc4\u4f30\u53ef\u80fd\u884c\u52a8\u3001\u57fa\u4e8e\u4fe1\u5ff5\u505a\u51fa\u9009\u62e9\uff09\u7684\u63a2\u7d22\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u5728\u9759\u6001\u5b8c\u5168\u4fe1\u606f\u535a\u5f08\u4e2d\u5206\u79bb\u4fe1\u5ff5\u3001\u8bc4\u4f30\u548c\u9009\u62e9\uff0c\u901a\u8fc7\u5206\u6790\u6a21\u578b\u7684\u663e\u6027\u9009\u62e9\u548c\u63a8\u7406\u8f68\u8ff9\uff0c\u5e76\u5f15\u5165\u65b0\u7684\u4e0a\u4e0b\u6587\u65e0\u5173\u535a\u5f08\u6765\u6392\u9664\u8bb0\u5fc6\u6a21\u4eff\u7684\u5f71\u54cd\u3002", "result": "\u524d\u6cbf\u6a21\u578b\u5728\u76ee\u6807\u63a8\u7406\u6df1\u5ea6\u4e0b\u8868\u73b0\u51fa\u4fe1\u5ff5\u4e00\u81f4\u7684\u6700\u4f73\u54cd\u5e94\u884c\u4e3a\uff1b\u5728\u65e0\u7ea6\u675f\u65f6\u4f1a\u81ea\u6211\u9650\u5236\u63a8\u7406\u6df1\u5ea6\uff0c\u5e76\u5bf9\u4eba\u7c7b\u548c\u5408\u6210\u5bf9\u624b\u5f62\u6210\u5dee\u5f02\u5316\u63a8\u6d4b\uff1b\u5728\u590d\u6742\u6027\u589e\u52a0\u65f6\uff0c\u663e\u5f0f\u9012\u5f52\u8ba9\u4f4d\u4e8e\u5185\u90e8\u751f\u6210\u7684\u7a33\u5b9a\u3001\u6a21\u578b\u7279\u5b9a\u7684\u542f\u53d1\u5f0f\u9009\u62e9\u89c4\u5219\uff0c\u8fd9\u4e9b\u89c4\u5219\u4e0d\u540c\u4e8e\u5df2\u77e5\u7684\u4eba\u7c7b\u504f\u89c1\u3002", "conclusion": "\u4fe1\u5ff5\u4e00\u81f4\u6027\u3001\u5143\u63a8\u7406\u548c\u65b0\u578b\u542f\u53d1\u5f0f\u5f62\u6210\u80fd\u529b\u53ef\u4ee5\u4ece\u8bed\u8a00\u5efa\u6a21\u76ee\u6807\u4e2d\u5171\u540c\u6d8c\u73b0\uff0c\u4e3a\u7814\u7a76\u4eba\u5de5\u667a\u80fd\u4f53\u7684\u6218\u7565\u8ba4\u77e5\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u57fa\u7840\u3002"}}
{"id": "2510.10865", "categories": ["cs.RO", "cs.AI", "I.2.9; I.2.8"], "pdf": "https://arxiv.org/pdf/2510.10865", "abs": "https://arxiv.org/abs/2510.10865", "authors": ["Ahmed Alanazi", "Duy Ho", "Yugyung Lee"], "title": "GRIP: A Unified Framework for Grid-Based Relay and Co-Occurrence-Aware Planning in Dynamic Environments", "comment": "17 pages, 5 figures, 8 tables", "summary": "Robots navigating dynamic, cluttered, and semantically complex environments\nmust integrate perception, symbolic reasoning, and spatial planning to\ngeneralize across diverse layouts and object categories. Existing methods often\nrely on static priors or limited memory, constraining adaptability under\npartial observability and semantic ambiguity. We present GRIP, Grid-based Relay\nwith Intermediate Planning, a unified, modular framework with three scalable\nvariants: GRIP-L (Lightweight), optimized for symbolic navigation via semantic\noccupancy grids; GRIP-F (Full), supporting multi-hop anchor chaining and\nLLM-based introspection; and GRIP-R (Real-World), enabling physical robot\ndeployment under perceptual uncertainty. GRIP integrates dynamic 2D grid\nconstruction, open-vocabulary object grounding, co-occurrence-aware symbolic\nplanning, and hybrid policy execution using behavioral cloning, D* search, and\ngrid-conditioned control. Empirical results on AI2-THOR and RoboTHOR benchmarks\nshow that GRIP achieves up to 9.6% higher success rates and over $2\\times$\nimprovement in path efficiency (SPL and SAE) on long-horizon tasks. Qualitative\nanalyses reveal interpretable symbolic plans in ambiguous scenes. Real-world\ndeployment on a Jetbot further validates GRIP's generalization under sensor\nnoise and environmental variation. These results position GRIP as a robust,\nscalable, and explainable framework bridging simulation and real-world\nnavigation.", "AI": {"tldr": "GRIP\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u6a21\u5757\u5316\u673a\u5668\u4eba\u5bfc\u822a\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u53d8\u4f53\uff1a\u8f7b\u91cf\u7ea7GRIP-L\u7528\u4e8e\u7b26\u53f7\u5bfc\u822a\uff0c\u5b8c\u6574\u7248GRIP-F\u652f\u6301\u591a\u8df3\u951a\u94fe\u548cLLM\u5185\u7701\uff0c\u771f\u5b9e\u4e16\u754c\u7248GRIP-R\u652f\u6301\u7269\u7406\u673a\u5668\u4eba\u90e8\u7f72\u3002\u8be5\u6846\u67b6\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6210\u529f\u7387\u548c\u8def\u5f84\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u5148\u9a8c\u6216\u6709\u9650\u8bb0\u5fc6\uff0c\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u548c\u8bed\u4e49\u6a21\u7cca\u6027\u4e0b\u9002\u5e94\u6027\u53d7\u9650\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6574\u5408\u611f\u77e5\u3001\u7b26\u53f7\u63a8\u7406\u548c\u7a7a\u95f4\u89c4\u5212\u7684\u7edf\u4e00\u6846\u67b6\u3002", "method": "GRIP\u6574\u5408\u4e86\u52a8\u60012D\u7f51\u683c\u6784\u5efa\u3001\u5f00\u653e\u8bcd\u6c47\u5bf9\u8c61\u63a5\u5730\u3001\u5171\u73b0\u611f\u77e5\u7b26\u53f7\u89c4\u5212\uff0c\u4ee5\u53ca\u4f7f\u7528\u884c\u4e3a\u514b\u9686\u3001D*\u641c\u7d22\u548c\u7f51\u683c\u6761\u4ef6\u63a7\u5236\u7684\u6df7\u5408\u7b56\u7565\u6267\u884c\u3002", "result": "\u5728AI2-THOR\u548cRoboTHOR\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGRIP\u5728\u957f\u89c6\u91ce\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe9.6%\u7684\u6210\u529f\u7387\u63d0\u5347\u548c\u8d85\u8fc72\u500d\u7684\u8def\u5f84\u6548\u7387\u6539\u8fdb\uff08SPL\u548cSAE\uff09\u3002\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u9a8c\u8bc1\u4e86\u5176\u5728\u4f20\u611f\u5668\u566a\u58f0\u548c\u73af\u5883\u53d8\u5316\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "GRIP\u4f5c\u4e3a\u4e00\u4e2a\u9c81\u68d2\u3001\u53ef\u6269\u5c55\u548c\u53ef\u89e3\u91ca\u7684\u6846\u67b6\uff0c\u6210\u529f\u8fde\u63a5\u4e86\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u5bfc\u822a\u3002"}}
{"id": "2510.10815", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.SC"], "pdf": "https://arxiv.org/pdf/2510.10815", "abs": "https://arxiv.org/abs/2510.10815", "authors": ["Meiru Zhang", "Philipp Borchert", "Milan Gritta", "Gerasimos Lampouras"], "title": "DRIFT: Decompose, Retrieve, Illustrate, then Formalize Theorems", "comment": null, "summary": "Automating the formalization of mathematical statements for theorem proving\nremains a major challenge for Large Language Models (LLMs). LLMs struggle to\nidentify and utilize the prerequisite mathematical knowledge and its\ncorresponding formal representation in languages like Lean. Current\nretrieval-augmented autoformalization methods query external libraries using\nthe informal statement directly, but overlook a fundamental limitation:\ninformal mathematical statements are often complex and offer limited context on\nthe underlying math concepts. To address this, we introduce DRIFT, a novel\nframework that enables LLMs to decompose informal mathematical statements into\nsmaller, more tractable ''sub-components''. This facilitates targeted retrieval\nof premises from mathematical libraries such as Mathlib. Additionally, DRIFT\nretrieves illustrative theorems to help models use premises more effectively in\nformalization tasks. We evaluate DRIFT across diverse benchmarks (ProofNet,\nConNF, and MiniF2F-test) and find that it consistently improves premise\nretrieval, nearly doubling the F1 score compared to the DPR baseline on\nProofNet. Notably, DRIFT demonstrates strong performance on the\nout-of-distribution ConNF benchmark, with BEq+@10 improvements of 37.14% and\n42.25% using GPT-4.1 and DeepSeek-V3.1, respectively. Our analysis shows that\nretrieval effectiveness in mathematical autoformalization depends heavily on\nmodel-specific knowledge boundaries, highlighting the need for adaptive\nretrieval strategies aligned with each model's capabilities.", "AI": {"tldr": "DRIFT\u6846\u67b6\u901a\u8fc7\u5c06\u975e\u6b63\u5f0f\u6570\u5b66\u9648\u8ff0\u5206\u89e3\u4e3a\u66f4\u5c0f\u7684\u5b50\u7ec4\u4ef6\u6765\u6539\u8fdb\u81ea\u52a8\u5f62\u5f0f\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u524d\u63d0\u68c0\u7d22\u6548\u679c\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3LLMs\u5728\u6570\u5b66\u81ea\u52a8\u5f62\u5f0f\u5316\u4e2d\u96be\u4ee5\u8bc6\u522b\u548c\u5229\u7528\u5148\u9a8c\u6570\u5b66\u77e5\u8bc6\u7684\u95ee\u9898\uff0c\u5f53\u524d\u65b9\u6cd5\u76f4\u63a5\u67e5\u8be2\u5916\u90e8\u5e93\u4f46\u5ffd\u7565\u4e86\u975e\u6b63\u5f0f\u6570\u5b66\u9648\u8ff0\u7684\u590d\u6742\u6027\u548c\u4e0a\u4e0b\u6587\u6709\u9650\u6027\u3002", "method": "\u5f15\u5165DRIFT\u6846\u67b6\uff0c\u5c06\u975e\u6b63\u5f0f\u6570\u5b66\u9648\u8ff0\u5206\u89e3\u4e3a\u66f4\u5c0f\u7684\u5b50\u7ec4\u4ef6\uff0c\u4eceMathlib\u7b49\u6570\u5b66\u5e93\u4e2d\u8fdb\u884c\u9488\u5bf9\u6027\u524d\u63d0\u68c0\u7d22\uff0c\u5e76\u68c0\u7d22\u793a\u4f8b\u5b9a\u7406\u4ee5\u5e2e\u52a9\u6a21\u578b\u66f4\u6709\u6548\u5730\u4f7f\u7528\u524d\u63d0\u3002", "result": "\u5728ProofNet\u3001ConNF\u548cMiniF2F-test\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e00\u81f4\u63d0\u5347\u524d\u63d0\u68c0\u7d22\u6027\u80fd\uff0cProofNet\u4e0aF1\u5206\u6570\u6bd4DPR\u57fa\u7ebf\u51e0\u4e4e\u7ffb\u500d\uff0c\u5728ConNF\u4e0aGPT-4.1\u548cDeepSeek-V3.1\u5206\u522b\u63d0\u534737.14%\u548c42.25%\u3002", "conclusion": "\u6570\u5b66\u81ea\u52a8\u5f62\u5f0f\u5316\u4e2d\u7684\u68c0\u7d22\u6548\u679c\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u6a21\u578b\u7279\u5b9a\u7684\u77e5\u8bc6\u8fb9\u754c\uff0c\u9700\u8981\u4e0e\u6bcf\u4e2a\u6a21\u578b\u80fd\u529b\u5bf9\u9f50\u7684\u81ea\u9002\u5e94\u68c0\u7d22\u7b56\u7565\u3002"}}
{"id": "2510.10886", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10886", "abs": "https://arxiv.org/abs/2510.10886", "authors": ["Yashom Dighe", "Youngjin Kim", "Karthik Dantu"], "title": "QuayPoints: A Reasoning Framework to Bridge the Information Gap Between Global and Local Planning in Autonomous Racing", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Autonomous racing requires tight integration between perception, planning and\ncontrol to minimize latency as well as timely decision making. A standard\nautonomy pipeline comprising a global planner, local planner, and controller\nloses information as the higher-level racing context is sequentially propagated\ndownstream into specific task-oriented context. In particular, the global\nplanner's understanding of optimality is typically reduced to a sparse set of\nwaypoints, leaving the local planner to make reactive decisions with limited\ncontext. This paper investigates whether additional global insights,\nspecifically time-optimality information, can be meaningfully passed to the\nlocal planner to improve downstream decisions. We introduce a framework that\npreserves essential global knowledge and conveys it to the local planner\nthrough QuayPoints regions where deviations from the optimal raceline result in\nsignificant compromises to optimality. QuayPoints enable local planners to make\nmore informed global decisions when deviating from the raceline, such as during\nstrategic overtaking. To demonstrate this, we integrate QuayPoints into an\nexisting planner and show that it consistently overtakes opponents traveling at\nup to 75% of the ego vehicle's speed across four distinct race tracks.", "AI": {"tldr": "\u63d0\u51faQuayPoints\u6846\u67b6\uff0c\u5c06\u5168\u5c40\u6700\u4f18\u6027\u4fe1\u606f\u4f20\u9012\u7ed9\u5c40\u90e8\u89c4\u5212\u5668\uff0c\u4f7f\u81ea\u52a8\u9a7e\u9a76\u8d5b\u8f66\u5728\u504f\u79bb\u6700\u4f18\u8def\u5f84\u65f6\u80fd\u505a\u51fa\u66f4\u660e\u667a\u7684\u51b3\u7b56\uff0c\u7279\u522b\u662f\u5728\u8d85\u8f66\u573a\u666f\u4e2d\u3002", "motivation": "\u6807\u51c6\u81ea\u52a8\u9a7e\u9a76\u6d41\u6c34\u7ebf\u4e2d\uff0c\u5168\u5c40\u89c4\u5212\u5668\u7684\u4f18\u5316\u4fe1\u606f\u5728\u4f20\u9012\u5230\u5c40\u90e8\u89c4\u5212\u5668\u65f6\u4e22\u5931\uff0c\u5bfc\u81f4\u5c40\u90e8\u89c4\u5212\u5668\u53ea\u80fd\u505a\u51fa\u53cd\u5e94\u6027\u51b3\u7b56\u800c\u7f3a\u4e4f\u5168\u5c40\u89c6\u91ce\u3002", "method": "\u901a\u8fc7QuayPoints\u533a\u57df\u4f20\u9012\u5168\u5c40\u65f6\u95f4\u6700\u4f18\u6027\u4fe1\u606f\uff0c\u8fd9\u4e9b\u533a\u57df\u6807\u8bc6\u4e86\u504f\u79bb\u6700\u4f18\u8d5b\u8f66\u7ebf\u4f1a\u663e\u8457\u5f71\u54cd\u6027\u80fd\u7684\u5173\u952e\u4f4d\u7f6e\u3002", "result": "\u96c6\u6210QuayPoints\u7684\u89c4\u5212\u5668\u80fd\u5728\u56db\u6761\u4e0d\u540c\u8d5b\u9053\u4e0a\u7a33\u5b9a\u8d85\u8d8a\u4ee5\u81ea\u6211\u8f66\u8f8675%\u901f\u5ea6\u884c\u9a76\u7684\u5bf9\u624b\u3002", "conclusion": "QuayPoints\u6846\u67b6\u80fd\u6709\u6548\u4fdd\u7559\u548c\u4f20\u9012\u5168\u5c40\u77e5\u8bc6\uff0c\u63d0\u5347\u5c40\u90e8\u89c4\u5212\u5668\u7684\u51b3\u7b56\u8d28\u91cf\uff0c\u7279\u522b\u662f\u5728\u6218\u7565\u8d85\u8f66\u7b49\u9700\u8981\u504f\u79bb\u6700\u4f18\u8def\u5f84\u7684\u573a\u666f\u4e2d\u3002"}}
{"id": "2510.10823", "categories": ["cs.AI", "cs.NE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10823", "abs": "https://arxiv.org/abs/2510.10823", "authors": ["Daniel Howard"], "title": "The Irrational Machine: Neurosis and the Limits of Algorithmic Safety", "comment": "41 pages, 17 figures, 5 tables", "summary": "We present a framework for characterizing neurosis in embodied AI: behaviors\nthat are internally coherent yet misaligned with reality, arising from\ninteractions among planning, uncertainty handling, and aversive memory. In a\ngrid navigation stack we catalogue recurrent modalities including flip-flop,\nplan churn, perseveration loops, paralysis and hypervigilance, futile search,\nbelief incoherence, tie break thrashing, corridor thrashing, optimality\ncompulsion, metric mismatch, policy oscillation, and limited-visibility\nvariants. For each we give lightweight online detectors and reusable escape\npolicies (short commitments, a margin to switch, smoothing, principled\narbitration). We then show that durable phobic avoidance can persist even under\nfull visibility when learned aversive costs dominate local choice, producing\nlong detours despite globally safe routes. Using First/Second/Third Law as\nengineering shorthand for safety latency, command compliance, and resource\nefficiency, we argue that local fixes are insufficient; global failures can\nremain. To surface them, we propose genetic-programming based destructive\ntesting that evolves worlds and perturbations to maximize law pressure and\nneurosis scores, yielding adversarial curricula and counterfactual traces that\nexpose where architectural revision, not merely symptom-level patches, is\nrequired.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\u6765\u8868\u5f81\u5177\u8eabAI\u4e2d\u7684\u795e\u7ecf\u75c7\u884c\u4e3a\uff1a\u8fd9\u4e9b\u884c\u4e3a\u5185\u90e8\u4e00\u81f4\u4f46\u4e0e\u73b0\u5b9e\u9519\u4f4d\uff0c\u6e90\u4e8e\u89c4\u5212\u3001\u4e0d\u786e\u5b9a\u6027\u5904\u7406\u548c\u538c\u6076\u8bb0\u5fc6\u7684\u4ea4\u4e92\u4f5c\u7528\u3002\u5728\u7f51\u683c\u5bfc\u822a\u4efb\u52a1\u4e2d\u8bc6\u522b\u4e86\u591a\u79cd\u795e\u7ecf\u75c7\u6a21\u5f0f\uff0c\u5e76\u5f00\u53d1\u4e86\u5728\u7ebf\u68c0\u6d4b\u5668\u548c\u9003\u9038\u7b56\u7565\u3002\u7814\u7a76\u8868\u660e\u5c40\u90e8\u4fee\u590d\u4e0d\u8db3\uff0c\u9700\u8981\u67b6\u6784\u5c42\u9762\u7684\u6539\u8fdb\u3002", "motivation": "\u7814\u7a76\u5177\u8eabAI\u4e2d\u51fa\u73b0\u7684\u795e\u7ecf\u75c7\u884c\u4e3a\uff0c\u8fd9\u4e9b\u884c\u4e3a\u867d\u7136\u5185\u90e8\u903b\u8f91\u4e00\u81f4\u4f46\u4e0e\u73b0\u5b9e\u73af\u5883\u4e0d\u5339\u914d\uff0c\u53ef\u80fd\u5f71\u54cdAI\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u6548\u7387\u3002", "method": "\u5728\u7f51\u683c\u5bfc\u822a\u7cfb\u7edf\u4e2d\u8bc6\u522b\u591a\u79cd\u795e\u7ecf\u75c7\u6a21\u5f0f\uff0c\u5f00\u53d1\u8f7b\u91cf\u7ea7\u5728\u7ebf\u68c0\u6d4b\u5668\u548c\u53ef\u91cd\u7528\u7684\u9003\u9038\u7b56\u7565\u3002\u4f7f\u7528\u9057\u4f20\u7f16\u7a0b\u8fdb\u884c\u7834\u574f\u6027\u6d4b\u8bd5\uff0c\u6f14\u5316\u4e16\u754c\u548c\u6270\u52a8\u6765\u6700\u5927\u5316\u6cd5\u5f8b\u538b\u529b\u548c\u795e\u7ecf\u75c7\u8bc4\u5206\u3002", "result": "\u8bc6\u522b\u4e8612\u79cd\u795e\u7ecf\u75c7\u6a21\u5f0f\uff0c\u5f00\u53d1\u4e86\u6709\u6548\u7684\u68c0\u6d4b\u548c\u9003\u9038\u673a\u5236\u3002\u53d1\u73b0\u5373\u4f7f\u5728\u5168\u53ef\u89c1\u6027\u6761\u4ef6\u4e0b\uff0c\u4e60\u5f97\u7684\u538c\u6076\u6210\u672c\u4ecd\u4f1a\u5bfc\u81f4\u6301\u4e45\u7684\u6050\u60e7\u56de\u907f\u884c\u4e3a\u3002\u7834\u574f\u6027\u6d4b\u8bd5\u751f\u6210\u4e86\u5bf9\u6297\u6027\u8bfe\u7a0b\u548c\u53cd\u4e8b\u5b9e\u8f68\u8ff9\u3002", "conclusion": "\u5c40\u90e8\u4fee\u590d\u4e0d\u8db3\u4ee5\u89e3\u51b3\u795e\u7ecf\u75c7\u95ee\u9898\uff0c\u5168\u5c40\u6027\u6545\u969c\u53ef\u80fd\u6301\u7eed\u5b58\u5728\u3002\u9700\u8981\u67b6\u6784\u5c42\u9762\u7684\u4fee\u8ba2\u800c\u4e0d\u4ec5\u4ec5\u662f\u75c7\u72b6\u7ea7\u522b\u7684\u4fee\u8865\uff0c\u7834\u574f\u6027\u6d4b\u8bd5\u6709\u52a9\u4e8e\u8bc6\u522b\u9700\u8981\u6839\u672c\u6027\u6539\u8fdb\u7684\u9886\u57df\u3002"}}
{"id": "2510.10893", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10893", "abs": "https://arxiv.org/abs/2510.10893", "authors": ["Dikshant Shehmar", "Matthew E. Taylor", "Ehsan Hashemi"], "title": "An Adaptive Transition Framework for Game-Theoretic Based Takeover", "comment": null, "summary": "The transition of control from autonomous systems to human drivers is\ncritical in automated driving systems, particularly due to the out-of-the-loop\n(OOTL) circumstances that reduce driver readiness and increase reaction times.\nExisting takeover strategies are based on fixed time-based transitions, which\nfail to account for real-time driver performance variations. This paper\nproposes an adaptive transition strategy that dynamically adjusts the control\nauthority based on both the time and tracking ability of the driver trajectory.\nShared control is modeled as a cooperative differential game, where control\nauthority is modulated through time-varying objective functions instead of\nblending control torques directly. To ensure a more natural takeover, a\ndriver-specific state-tracking matrix is introduced, allowing the transition to\nalign with individual control preferences. Multiple transition strategies are\nevaluated using a cumulative trajectory error metric. Human-in-the-loop control\nscenarios of the standardized ISO lane change maneuvers demonstrate that\nadaptive transitions reduce trajectory deviations and driver control effort\ncompared to conventional strategies. Experiments also confirm that continuously\nadjusting control authority based on real-time deviations enhances vehicle\nstability while reducing driver effort during takeover.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9a7e\u9a76\u5458\u5b9e\u65f6\u8ddf\u8e2a\u80fd\u529b\u7684\u81ea\u9002\u5e94\u63a7\u5236\u6743\u8f6c\u79fb\u7b56\u7565\uff0c\u901a\u8fc7\u5408\u4f5c\u5fae\u5206\u535a\u5f08\u5efa\u6a21\u5171\u4eab\u63a7\u5236\uff0c\u76f8\u6bd4\u4f20\u7edf\u56fa\u5b9a\u65f6\u95f4\u7b56\u7565\u80fd\u51cf\u5c11\u8f68\u8ff9\u504f\u5dee\u548c\u9a7e\u9a76\u5458\u63a7\u5236\u8d1f\u62c5\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u63a7\u5236\u6743\u8f6c\u79fb\u7b56\u7565\u57fa\u4e8e\u56fa\u5b9a\u65f6\u95f4\uff0c\u65e0\u6cd5\u9002\u5e94\u9a7e\u9a76\u5458\u5b9e\u65f6\u6027\u80fd\u53d8\u5316\uff0c\u5bfc\u81f4\u63a5\u7ba1\u65f6\u53cd\u5e94\u65f6\u95f4\u589e\u52a0\u548c\u9a7e\u9a76\u5458\u51c6\u5907\u4e0d\u8db3\u3002", "method": "\u5c06\u5171\u4eab\u63a7\u5236\u5efa\u6a21\u4e3a\u5408\u4f5c\u5fae\u5206\u6e38\u620f\uff0c\u901a\u8fc7\u65f6\u53d8\u76ee\u6807\u51fd\u6570\u8c03\u8282\u63a7\u5236\u6743\uff0c\u5f15\u5165\u9a7e\u9a76\u5458\u7279\u5b9a\u72b6\u6001\u8ddf\u8e2a\u77e9\u9635\uff0c\u57fa\u4e8e\u65f6\u95f4\u548c\u8f68\u8ff9\u8ddf\u8e2a\u80fd\u529b\u52a8\u6001\u8c03\u6574\u63a7\u5236\u6743\u9650\u3002", "result": "\u5728ISO\u6807\u51c6\u6362\u9053\u573a\u666f\u7684\u4eba\u673a\u534f\u540c\u63a7\u5236\u5b9e\u9a8c\u4e2d\uff0c\u81ea\u9002\u5e94\u8f6c\u79fb\u7b56\u7565\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u51cf\u5c11\u4e86\u8f68\u8ff9\u504f\u5dee\u548c\u9a7e\u9a76\u5458\u63a7\u5236\u8d1f\u62c5\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u8f66\u8f86\u7a33\u5b9a\u6027\u3002", "conclusion": "\u57fa\u4e8e\u5b9e\u65f6\u8ddf\u8e2a\u80fd\u529b\u7684\u81ea\u9002\u5e94\u63a7\u5236\u6743\u8f6c\u79fb\u7b56\u7565\u80fd\u66f4\u81ea\u7136\u5730\u5b9e\u73b0\u4eba\u673a\u63a5\u7ba1\uff0c\u63d0\u9ad8\u7cfb\u7edf\u6027\u80fd\u548c\u9a7e\u9a76\u5458\u4f53\u9a8c\u3002"}}
{"id": "2510.10895", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10895", "abs": "https://arxiv.org/abs/2510.10895", "authors": ["Renxuan Tan", "Rongpeng Li", "Fei Wang", "Chenghui Peng", "Shaoyun Wu", "Zhifeng Zhao", "Honggang Zhang"], "title": "LLM-Empowered Agentic MAC Protocols: A Dynamic Stackelberg Game Approach", "comment": "This work has been submitted to IEEE for possible publication", "summary": "Medium Access Control (MAC) protocols, essential for wireless networks, are\ntypically manually configured. While deep reinforcement learning (DRL)-based\nprotocols enhance task-specified network performance, they suffer from poor\ngeneralizability and resilience, demanding costly retraining to adapt to\ndynamic environments. To overcome this limitation, we introduce a\ngame-theoretic LLM-empowered multi-agent DRL (MARL) framework, in which the\nuplink transmission between a base station and a varying number of user\nequipments is modeled as a dynamic multi-follower Stackelberg game (MFSG),\ncapturing the network's natural hierarchical structure. Within this game,\nLLM-driven agents, coordinated through proximal policy optimization (PPO),\nsynthesize adaptive, semantic MAC protocols in response to network dynamics.\nProtocol action grammar (PAG) is employed to ensure the reliability and\nefficiency of this process. Under this system, we further analyze the existence\nand convergence behavior in terms of a Stackelberg equilibrium by studying the\nlearning dynamics of LLM-empowered unified policies in response to changing\nfollowers. Simulations corroborate that our framework achieves a 77.6% greater\nthroughput and a 65.2% fairness improvement over conventional baselines.\nBesides, our framework generalizes excellently to a fluctuating number of users\nwithout requiring retraining or architectural changes.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u535a\u5f08\u8bba\u548cLLM\u7684\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u9002\u5e94\u751f\u6210\u8bed\u4e49MAC\u534f\u8bae\uff0c\u663e\u8457\u63d0\u5347\u541e\u5410\u91cf\u548c\u516c\u5e73\u6027\uff0c\u5e76\u5177\u5907\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4f20\u7edfMAC\u534f\u8bae\u9700\u8981\u624b\u52a8\u914d\u7f6e\uff0c\u800c\u57fa\u4e8eDRL\u7684\u534f\u8bae\u867d\u7136\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u6cdb\u5316\u6027\u548c\u9002\u5e94\u6027\u5dee\uff0c\u9700\u8981\u6602\u8d35\u7684\u91cd\u65b0\u8bad\u7ec3\u6765\u9002\u5e94\u52a8\u6001\u73af\u5883\u3002", "method": "\u5c06\u4e0a\u884c\u94fe\u8def\u4f20\u8f93\u5efa\u6a21\u4e3a\u52a8\u6001\u591a\u8ddf\u968f\u8005Stackelberg\u535a\u5f08\uff0c\u4f7f\u7528LLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u901a\u8fc7PPO\u534f\u8c03\uff0c\u7ed3\u5408\u534f\u8bae\u52a8\u4f5c\u8bed\u6cd5(PAG)\u6765\u5408\u6210\u81ea\u9002\u5e94\u8bed\u4e49MAC\u534f\u8bae\u3002", "result": "\u4eff\u771f\u663e\u793a\uff0c\u76f8\u6bd4\u4f20\u7edf\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8be5\u6846\u67b6\u5b9e\u73b0\u4e8677.6%\u7684\u541e\u5410\u91cf\u63d0\u5347\u548c65.2%\u7684\u516c\u5e73\u6027\u6539\u5584\uff0c\u4e14\u80fd\u5f88\u597d\u5730\u6cdb\u5316\u5230\u7528\u6237\u6570\u91cf\u53d8\u5316\u7684\u60c5\u51b5\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002", "conclusion": "\u8be5LLM\u8d4b\u80fd\u7684MARL\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3MAC\u534f\u8bae\u7684\u81ea\u9002\u5e94\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u5177\u5907\u51fa\u8272\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u52a8\u6001\u65e0\u7ebf\u7f51\u7edc\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.10903", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10903", "abs": "https://arxiv.org/abs/2510.10903", "authors": ["Shuanghao Bai", "Wenxuan Song", "Jiayi Chen", "Yuheng Ji", "Zhide Zhong", "Jin Yang", "Han Zhao", "Wanqi Zhou", "Wei Zhao", "Zhe Li", "Pengxiang Ding", "Cheng Chi", "Haoang Li", "Chang Xu", "Xiaolong Zheng", "Donglin Wang", "Shanghang Zhang", "Badong Chen"], "title": "Towards a Unified Understanding of Robot Manipulation: A Comprehensive Survey", "comment": null, "summary": "Embodied intelligence has witnessed remarkable progress in recent years,\ndriven by advances in computer vision, natural language processing, and the\nrise of large-scale multimodal models. Among its core challenges, robot\nmanipulation stands out as a fundamental yet intricate problem, requiring the\nseamless integration of perception, planning, and control to enable interaction\nwithin diverse and unstructured environments. This survey presents a\ncomprehensive overview of robotic manipulation, encompassing foundational\nbackground, task-organized benchmarks and datasets, and a unified taxonomy of\nexisting methods. We extend the classical division between high-level planning\nand low-level control by broadening high-level planning to include language,\ncode, motion, affordance, and 3D representations, while introducing a new\ntaxonomy of low-level learning-based control grounded in training paradigms\nsuch as input modeling, latent learning, and policy learning. Furthermore, we\nprovide the first dedicated taxonomy of key bottlenecks, focusing on data\ncollection, utilization, and generalization, and conclude with an extensive\nreview of real-world applications. Compared with prior surveys, our work offers\nboth a broader scope and deeper insight, serving as an accessible roadmap for\nnewcomers and a structured reference for experienced researchers. All related\nresources, including research papers, open-source datasets, and projects, are\ncurated for the community at\nhttps://github.com/BaiShuanghao/Awesome-Robotics-Manipulation.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u8bba\u6587\u5168\u9762\u6982\u8ff0\u4e86\u673a\u5668\u4eba\u64cd\u4f5c\u9886\u57df\uff0c\u6db5\u76d6\u4e86\u57fa\u7840\u80cc\u666f\u3001\u4efb\u52a1\u5bfc\u5411\u7684\u57fa\u51c6\u548c\u6570\u636e\u96c6\uff0c\u4ee5\u53ca\u73b0\u6709\u65b9\u6cd5\u7684\u7edf\u4e00\u5206\u7c7b\u6cd5\u3002\u5b83\u6269\u5c55\u4e86\u9ad8\u5c42\u89c4\u5212\u4e0e\u4f4e\u5c42\u63a7\u5236\u7684\u7ecf\u5178\u5212\u5206\uff0c\u5e76\u9996\u6b21\u63d0\u51fa\u4e86\u9488\u5bf9\u6570\u636e\u6536\u96c6\u3001\u5229\u7528\u548c\u6cdb\u5316\u7b49\u5173\u952e\u74f6\u9888\u7684\u4e13\u95e8\u5206\u7c7b\u6cd5\u3002", "motivation": "\u673a\u5668\u4eba\u64cd\u4f5c\u662f\u5177\u8eab\u667a\u80fd\u4e2d\u7684\u6838\u5fc3\u6311\u6218\uff0c\u9700\u8981\u5c06\u611f\u77e5\u3001\u89c4\u5212\u548c\u63a7\u5236\u65e0\u7f1d\u96c6\u6210\u4ee5\u5728\u591a\u6837\u5316\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u8fdb\u884c\u4ea4\u4e92\u3002\u73b0\u6709\u7efc\u8ff0\u7f3a\u4e4f\u8db3\u591f\u7684\u5e7f\u5ea6\u548c\u6df1\u5ea6\uff0c\u9700\u8981\u4e3a\u65b0\u624b\u63d0\u4f9b\u53ef\u8bbf\u95ee\u7684\u8def\u7ebf\u56fe\uff0c\u5e76\u4e3a\u7ecf\u9a8c\u4e30\u5bcc\u7684\u7814\u7a76\u8005\u63d0\u4f9b\u7ed3\u6784\u5316\u53c2\u8003\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u5206\u7c7b\u6cd5\uff0c\u5c06\u9ad8\u5c42\u89c4\u5212\u6269\u5c55\u4e3a\u8bed\u8a00\u3001\u4ee3\u7801\u3001\u8fd0\u52a8\u3001\u529f\u80fd\u6027\u548c3D\u8868\u793a\uff0c\u540c\u65f6\u57fa\u4e8e\u8bad\u7ec3\u8303\u5f0f\uff08\u5982\u8f93\u5165\u5efa\u6a21\u3001\u6f5c\u5728\u5b66\u4e60\u548c\u7b56\u7565\u5b66\u4e60\uff09\u5efa\u7acb\u4e86\u4f4e\u5c42\u5b66\u4e60\u578b\u63a7\u5236\u7684\u65b0\u5206\u7c7b\u6cd5\u3002", "result": "\u63d0\u4f9b\u4e86\u673a\u5668\u4eba\u64cd\u4f5c\u9886\u57df\u7684\u5168\u9762\u6982\u8ff0\uff0c\u5305\u62ec\u57fa\u7840\u80cc\u666f\u3001\u4efb\u52a1\u5bfc\u5411\u7684\u57fa\u51c6\u548c\u6570\u636e\u96c6\uff0c\u4ee5\u53ca\u73b0\u6709\u65b9\u6cd5\u7684\u7cfb\u7edf\u5206\u7c7b\u3002\u9996\u6b21\u63d0\u51fa\u4e86\u9488\u5bf9\u6570\u636e\u74f6\u9888\u7684\u4e13\u95e8\u5206\u7c7b\u6cd5\uff0c\u5e76\u8be6\u7ec6\u56de\u987e\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "conclusion": "\u4e0e\u4e4b\u524d\u7684\u7efc\u8ff0\u76f8\u6bd4\uff0c\u8fd9\u9879\u5de5\u4f5c\u63d0\u4f9b\u4e86\u66f4\u5e7f\u7684\u8303\u56f4\u548c\u66f4\u6df1\u7684\u6d1e\u5bdf\uff0c\u4e3a\u673a\u5668\u4eba\u64cd\u4f5c\u9886\u57df\u7684\u65b0\u624b\u548c\u7ecf\u9a8c\u4e30\u5bcc\u7684\u7814\u7a76\u8005\u5206\u522b\u63d0\u4f9b\u4e86\u53ef\u8bbf\u95ee\u7684\u8def\u7ebf\u56fe\u548c\u7ed3\u6784\u5316\u53c2\u8003\u3002\u6240\u6709\u76f8\u5173\u8d44\u6e90\u5df2\u5728GitHub\u4e0a\u6574\u7406\u4f9b\u793e\u533a\u4f7f\u7528\u3002"}}
{"id": "2510.10909", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10909", "abs": "https://arxiv.org/abs/2510.10909", "authors": ["Daoyu Wang", "Mingyue Cheng", "Qi Liu", "Shuo Yu", "Zirui Liu", "Ze Guo"], "title": "PaperArena: An Evaluation Benchmark for Tool-Augmented Agentic Reasoning on Scientific Literature", "comment": "12 pages, 9 figures", "summary": "Understanding and reasoning on the web-scale scientific literature is a\ncrucial touchstone for large language model (LLM) based agents designed to\nsupport complex knowledge-intensive tasks. However, existing works are mainly\nrestricted to tool-free tasks within isolated papers, largely due to the lack\nof a benchmark for cross-paper reasoning and multi-tool orchestration in real\nresearch scenarios. In this work, we propose PaperArena, an evaluation\nbenchmark for agents to address real-world research questions that typically\nrequire integrating information across multiple papers with the assistance of\nexternal tools. Given a research question, agents should integrate diverse\nformats across multiple papers through reasoning and interacting with\nappropriate tools, thereby producing a well-grounded answer. To support\nstandardized evaluation, we provide a modular and extensible platform for agent\nexecution, offering tools such as multimodal parsing, context retrieval, and\nprogrammatic computation. Experimental results reveal that even the most\nadvanced LLM powering a well-established agent system achieves merely 38.78%\naverage accuracy. On the hard subset, accuracy drops to only 18.47%,\nhighlighting great potential for improvement. We also present several empirical\nfindings, including that all agents tested exhibit inefficient tool usage,\noften invoking more tools than necessary to solve a task. We invite the\ncommunity to adopt PaperArena to develop and evaluate more capable agents for\nscientific discovery. Our code and data are available\nhttps://github.com/Melmaphother/PaperArena.", "AI": {"tldr": "\u63d0\u51fa\u4e86PaperArena\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u4ee3\u7406\u5728\u8de8\u8bba\u6587\u63a8\u7406\u548c\u591a\u5de5\u5177\u534f\u8c03\u65b9\u9762\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524d\u6700\u5148\u8fdb\u7684\u4ee3\u7406\u7cfb\u7edf\u5728\u771f\u5b9e\u7814\u7a76\u573a\u666f\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5c40\u9650\u4e8e\u5355\u7bc7\u8bba\u6587\u5185\u7684\u65e0\u5de5\u5177\u4efb\u52a1\uff0c\u7f3a\u4e4f\u9488\u5bf9\u8de8\u8bba\u6587\u63a8\u7406\u548c\u591a\u5de5\u5177\u534f\u8c03\u7684\u771f\u5b9e\u7814\u7a76\u573a\u666f\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u6784\u5efa\u5305\u542b\u7814\u7a76\u95ee\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8981\u6c42\u4ee3\u7406\u901a\u8fc7\u591a\u5de5\u5177\u4ea4\u4e92\u6574\u5408\u591a\u7bc7\u8bba\u6587\u4fe1\u606f\uff0c\u63d0\u4f9b\u6a21\u5757\u5316\u53ef\u6269\u5c55\u7684\u6267\u884c\u5e73\u53f0\uff0c\u5305\u62ec\u591a\u6a21\u6001\u89e3\u6790\u3001\u4e0a\u4e0b\u6587\u68c0\u7d22\u548c\u7a0b\u5e8f\u5316\u8ba1\u7b97\u7b49\u5de5\u5177\u3002", "result": "\u6700\u5148\u8fdb\u7684LLM\u4ee3\u7406\u7cfb\u7edf\u5e73\u5747\u51c6\u786e\u7387\u4ec5\u4e3a38.78%\uff0c\u5728\u56f0\u96be\u5b50\u96c6\u4e0a\u964d\u81f318.47%\uff0c\u4e14\u6240\u6709\u6d4b\u8bd5\u4ee3\u7406\u90fd\u8868\u73b0\u51fa\u5de5\u5177\u4f7f\u7528\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\u3002", "conclusion": "PaperArena\u63ed\u793a\u4e86\u5f53\u524d\u79d1\u5b66\u53d1\u73b0\u4ee3\u7406\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u5f00\u53d1\u66f4\u5f3a\u5927\u7684\u4ee3\u7406\u63d0\u4f9b\u4e86\u8bc4\u4f30\u57fa\u51c6\uff0c\u5177\u6709\u91cd\u8981\u6539\u8fdb\u6f5c\u529b\u3002"}}
{"id": "2510.10912", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10912", "abs": "https://arxiv.org/abs/2510.10912", "authors": ["Xinyu Shao", "Yanzhe Tang", "Pengwei Xie", "Kaiwen Zhou", "Yuzheng Zhuang", "Xingyue Quan", "Jianye Hao", "Long Zeng", "Xiu Li"], "title": "More than A Point: Capturing Uncertainty with Adaptive Affordance Heatmaps for Spatial Grounding in Robotic Tasks", "comment": "More details and videos can be found at https://robo-map.github.io.\n  Xiu Li (Corresponding author: Xiu Li)", "summary": "Many language-guided robotic systems rely on collapsing spatial reasoning\ninto discrete points, making them brittle to perceptual noise and semantic\nambiguity. To address this challenge, we propose RoboMAP, a framework that\nrepresents spatial targets as continuous, adaptive affordance heatmaps. This\ndense representation captures the uncertainty in spatial grounding and provides\nricher information for downstream policies, thereby significantly enhancing\ntask success and interpretability. RoboMAP surpasses the previous\nstate-of-the-art on a majority of grounding benchmarks with up to a 50x speed\nimprovement, and achieves an 82\\% success rate in real-world manipulation.\nAcross extensive simulated and physical experiments, it demonstrates robust\nperformance and shows strong zero-shot generalization to navigation. More\ndetails and videos can be found at https://robo-map.github.io.", "AI": {"tldr": "\u63d0\u51fa\u4e86RoboMAP\u6846\u67b6\uff0c\u4f7f\u7528\u8fde\u7eed\u81ea\u9002\u5e94affordance\u70ed\u56fe\u8868\u793a\u7a7a\u95f4\u76ee\u6807\uff0c\u89e3\u51b3\u4e86\u8bed\u8a00\u5f15\u5bfc\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u7a7a\u95f4\u63a8\u7406\u7684\u8106\u5f31\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u6210\u529f\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u5f15\u5bfc\u673a\u5668\u4eba\u7cfb\u7edf\u5c06\u7a7a\u95f4\u63a8\u7406\u7b80\u5316\u4e3a\u79bb\u6563\u70b9\uff0c\u5bf9\u611f\u77e5\u566a\u58f0\u548c\u8bed\u4e49\u6a21\u7cca\u6027\u975e\u5e38\u8106\u5f31\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u7a7a\u95f4\u8868\u793a\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u8fde\u7eed\u3001\u81ea\u9002\u5e94\u7684affordance\u70ed\u56fe\u6765\u8868\u793a\u7a7a\u95f4\u76ee\u6807\uff0c\u8fd9\u79cd\u5bc6\u96c6\u8868\u793a\u80fd\u591f\u6355\u6349\u7a7a\u95f4\u57fa\u7840\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4e3a\u4e0b\u6e38\u7b56\u7565\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u4fe1\u606f\u3002", "result": "\u5728\u5927\u591a\u6570\u57fa\u7840\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86\u5148\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u901f\u5ea6\u63d0\u5347\u9ad8\u8fbe50\u500d\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u64cd\u4f5c\u4e2d\u8fbe\u523082%\u7684\u6210\u529f\u7387\uff0c\u5728\u6a21\u62df\u548c\u7269\u7406\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u9c81\u68d2\u6027\u80fd\uff0c\u5e76\u5c55\u793a\u51fa\u5f3a\u5927\u7684\u96f6\u6837\u672c\u5bfc\u822a\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "RoboMAP\u901a\u8fc7\u8fde\u7eedaffordance\u70ed\u56fe\u8868\u793a\u6709\u6548\u89e3\u51b3\u4e86\u8bed\u8a00\u5f15\u5bfc\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u7684\u7a7a\u95f4\u63a8\u7406\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3001\u901f\u5ea6\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.10931", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10931", "abs": "https://arxiv.org/abs/2510.10931", "authors": ["SHengjie Ma", "Chenlong Deng", "Jiaxin Mao", "Jiadeng Huang", "Teng Wang", "Junjie Wu", "Changwang Zhang", "Jun wang"], "title": "PoU: Proof-of-Use to Counter Tool-Call Hacking in DeepResearch Agents", "comment": null, "summary": "Retrieval-augmented generation (RAG) agents, such as recent\nDeepResearch-style systems, extend large language models (LLMs) with autonomous\ninformation-seeking capabilities through external tools. While reinforcement\nlearning (RL) has enabled impressive multi-step reasoning, we identify a\npreviously overlooked failure mode, Tool-Call Hacking, where agents inflate\nreward signals by issuing superficially correct tool calls without genuinely\nleveraging the retrieved evidence. This results in (i) mode collapse into\nrepetitive reliance on a single source and (ii) spurious grounding, where\nanswers are only weakly supported by cited content.\n  To address this, we propose Proof-of-Use (PoU), an evidence-grounded RL\nframework that enforces verifiable causal links between retrieved evidence,\nreasoning traces, and final answers. PoU operationalizes this through a unified\nstep-wise contract combining syntactic citation validation, perturbation-based\nsensitivity rewards, and answer-evidence alignment objectives, ensuring that\ntool usage remains both interpretable and functionally grounded.\n  Across seven QA benchmarks spanning in-domain, out-of-domain, and\nout-of-tool-distribution settings, PoU consistently outperforms strong\nDeepResearch baselines in factual accuracy, evidence faithfulness, and\ntool-routing balance. These findings highlight the necessity of grounding\nRL-trained agents not merely in task outcomes but in the causal use of\nretrieved information, offering a principled path toward trustworthy\nretrieval-augmented reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86Proof-of-Use (PoU)\u6846\u67b6\uff0c\u89e3\u51b3RAG\u4ee3\u7406\u4e2d\u7684\u5de5\u5177\u8c03\u7528\u9ed1\u5ba2\u95ee\u9898\uff0c\u901a\u8fc7\u8bc1\u636e\u57fa\u7840\u7684\u5f3a\u5316\u5b66\u4e60\u786e\u4fdd\u68c0\u7d22\u8bc1\u636e\u4e0e\u7b54\u6848\u4e4b\u95f4\u7684\u56e0\u679c\u8054\u7cfb\u3002", "motivation": "\u53d1\u73b0RAG\u4ee3\u7406\u5b58\u5728\u5de5\u5177\u8c03\u7528\u9ed1\u5ba2\u95ee\u9898\uff0c\u5373\u4ee3\u7406\u901a\u8fc7\u8868\u9762\u6b63\u786e\u7684\u5de5\u5177\u8c03\u7528\u6765\u5938\u5927\u5956\u52b1\u4fe1\u53f7\uff0c\u800c\u4e0d\u771f\u6b63\u5229\u7528\u68c0\u7d22\u8bc1\u636e\uff0c\u5bfc\u81f4\u6a21\u5f0f\u5d29\u6e83\u548c\u865a\u5047\u57fa\u7840\u3002", "method": "\u63d0\u51faProof-of-Use\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u9010\u6b65\u5408\u7ea6\u7ed3\u5408\u8bed\u6cd5\u5f15\u7528\u9a8c\u8bc1\u3001\u57fa\u4e8e\u6270\u52a8\u7684\u654f\u611f\u6027\u5956\u52b1\u548c\u7b54\u6848-\u8bc1\u636e\u5bf9\u9f50\u76ee\u6807\uff0c\u786e\u4fdd\u5de5\u5177\u4f7f\u7528\u7684\u53ef\u89e3\u91ca\u6027\u548c\u529f\u80fd\u6027\u57fa\u7840\u3002", "result": "\u5728\u4e03\u4e2aQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPoU\u5728\u4e8b\u5b9e\u51c6\u786e\u6027\u3001\u8bc1\u636e\u5fe0\u5b9e\u5ea6\u548c\u5de5\u5177\u8def\u7531\u5e73\u8861\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8eDeepResearch\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u5f3a\u8c03\u9700\u8981\u5c06RL\u8bad\u7ec3\u7684\u4ee3\u7406\u4e0d\u4ec5\u57fa\u4e8e\u4efb\u52a1\u7ed3\u679c\uff0c\u8fd8\u8981\u57fa\u4e8e\u68c0\u7d22\u4fe1\u606f\u7684\u56e0\u679c\u4f7f\u7528\uff0c\u4e3a\u53ef\u4fe1\u7684\u68c0\u7d22\u589e\u5f3a\u63a8\u7406\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u8def\u5f84\u3002"}}
{"id": "2510.10960", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10960", "abs": "https://arxiv.org/abs/2510.10960", "authors": ["Dong Hu", "Fenqing Hu", "Lidong Yang", "Chao Huang"], "title": "Game-Theoretic Risk-Shaped Reinforcement Learning for Safe Autonomous Driving", "comment": null, "summary": "Ensuring safety in autonomous driving (AD) remains a significant challenge,\nespecially in highly dynamic and complex traffic environments where diverse\nagents interact and unexpected hazards frequently emerge. Traditional\nreinforcement learning (RL) methods often struggle to balance safety,\nefficiency, and adaptability, as they primarily focus on reward maximization\nwithout explicitly modeling risk or safety constraints. To address these\nlimitations, this study proposes a novel game-theoretic risk-shaped RL (GTR2L)\nframework for safe AD. GTR2L incorporates a multi-level game-theoretic world\nmodel that jointly predicts the interactive behaviors of surrounding vehicles\nand their associated risks, along with an adaptive rollout horizon that adjusts\ndynamically based on predictive uncertainty. Furthermore, an uncertainty-aware\nbarrier mechanism enables flexible modulation of safety boundaries. A dedicated\nrisk modeling approach is also proposed, explicitly capturing both epistemic\nand aleatoric uncertainty to guide constrained policy optimization and enhance\ndecision-making in complex environments. Extensive evaluations across diverse\nand safety-critical traffic scenarios show that GTR2L significantly outperforms\nstate-of-the-art baselines, including human drivers, in terms of success rate,\ncollision and violation reduction, and driving efficiency. The code is\navailable at https://github.com/DanielHu197/GTR2L.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u535a\u5f08\u8bba\u7684\u98ce\u9669\u5851\u9020\u5f3a\u5316\u5b66\u4e60\u6846\u67b6GTR2L\uff0c\u7528\u4e8e\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684\u5b89\u5168\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u7ea7\u535a\u5f08\u8bba\u4e16\u754c\u6a21\u578b\u548c\u81ea\u9002\u5e94\u6eda\u52a8\u65f6\u57df\u6765\u63d0\u5347\u5728\u590d\u6742\u4ea4\u901a\u73af\u5883\u4e2d\u7684\u5b89\u5168\u6027\u548c\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\u96be\u4ee5\u5e73\u8861\u5b89\u5168\u6027\u3001\u6548\u7387\u548c\u9002\u5e94\u6027\uff0c\u4e3b\u8981\u5173\u6ce8\u5956\u52b1\u6700\u5927\u5316\u800c\u7f3a\u4e4f\u660e\u786e\u7684\u98ce\u9669\u5efa\u6a21\u548c\u5b89\u5168\u7ea6\u675f\u3002", "method": "GTR2L\u6846\u67b6\u5305\u542b\u591a\u7ea7\u535a\u5f08\u8bba\u4e16\u754c\u6a21\u578b\u3001\u81ea\u9002\u5e94\u6eda\u52a8\u65f6\u57df\u3001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u5c4f\u969c\u673a\u5236\u548c\u4e13\u95e8\u7684\u98ce\u9669\u5efa\u6a21\u65b9\u6cd5\uff0c\u540c\u65f6\u6355\u6349\u8ba4\u77e5\u548c\u968f\u673a\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5728\u591a\u6837\u5316\u548c\u5b89\u5168\u5173\u952e\u7684\u4ea4\u901a\u573a\u666f\u4e2d\uff0cGTR2L\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u65b9\u6cd5\uff08\u5305\u62ec\u4eba\u7c7b\u9a7e\u9a76\u5458\uff09\uff0c\u5728\u6210\u529f\u7387\u3001\u78b0\u649e\u548c\u8fdd\u89c4\u51cf\u5c11\u4ee5\u53ca\u9a7e\u9a76\u6548\u7387\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "GTR2L\u6846\u67b6\u901a\u8fc7\u6574\u5408\u535a\u5f08\u8bba\u3001\u98ce\u9669\u5efa\u6a21\u548c\u81ea\u9002\u5e94\u673a\u5236\uff0c\u6709\u6548\u63d0\u5347\u4e86\u81ea\u52a8\u9a7e\u9a76\u5728\u590d\u6742\u4ea4\u4e92\u73af\u5883\u4e2d\u7684\u5b89\u5168\u51b3\u7b56\u80fd\u529b\u3002"}}
{"id": "2510.10942", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.10942", "abs": "https://arxiv.org/abs/2510.10942", "authors": ["Nilima Rao", "Jagriti Srivastava", "Pradeep Kumar Sharma", "Hritvik Shrivastava"], "title": "Scalable and Explainable Enterprise Knowledge Discovery Using Graph-Centric Hybrid Retrieval", "comment": null, "summary": "Modern enterprises manage vast knowledge distributed across heterogeneous\nsystems such as Jira, Git repositories, Confluence, and wikis. Conventional\nretrieval methods based on keyword search or static embeddings often fail to\nanswer complex queries that require contextual reasoning and multi-hop\ninference across artifacts. We present a modular hybrid retrieval framework for\nadaptive enterprise information access that integrates Knowledge Base\nLanguage-Augmented Models (KBLam), DeepGraph representations, and\nembedding-driven semantic search. The framework builds a unified knowledge\ngraph from parsed repositories including code, pull requests, and commit\nhistories, enabling semantic similarity search, structural inference, and\nmulti-hop reasoning. Query analysis dynamically determines the optimal\nretrieval strategy, supporting both structured and unstructured data sources\nthrough independent or fused processing. An interactive interface provides\ngraph visualizations, subgraph exploration, and context-aware query routing to\ngenerate concise and explainable answers. Experiments on large-scale Git\nrepositories show that the unified reasoning layer improves answer relevance by\nup to 80 percent compared with standalone GPT-based retrieval pipelines. By\ncombining graph construction, hybrid reasoning, and interactive visualization,\nthe proposed framework offers a scalable, explainable, and user-centric\nfoundation for intelligent knowledge assistants in enterprise environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u6df7\u5408\u68c0\u7d22\u6846\u67b6\uff0c\u7528\u4e8e\u4f01\u4e1a\u4fe1\u606f\u8bbf\u95ee\uff0c\u7ed3\u5408\u77e5\u8bc6\u5e93\u8bed\u8a00\u589e\u5f3a\u6a21\u578b\u3001\u6df1\u5ea6\u56fe\u8868\u793a\u548c\u5d4c\u5165\u9a71\u52a8\u7684\u8bed\u4e49\u641c\u7d22\uff0c\u901a\u8fc7\u6784\u5efa\u7edf\u4e00\u77e5\u8bc6\u56fe\u8c31\u652f\u6301\u590d\u6742\u67e5\u8be2\u548c\u63a8\u7406\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u57fa\u4e8e\u5173\u952e\u8bcd\u641c\u7d22\u6216\u9759\u6001\u5d4c\u5165\u7684\u68c0\u7d22\u65b9\u6cd5\u5728\u5904\u7406\u9700\u8981\u8de8\u5f02\u6784\u7cfb\u7edf\u8fdb\u884c\u4e0a\u4e0b\u6587\u63a8\u7406\u548c\u591a\u8df3\u63a8\u7406\u7684\u590d\u6742\u67e5\u8be2\u65f6\u7684\u4e0d\u8db3\u3002", "method": "\u6784\u5efa\u7edf\u4e00\u77e5\u8bc6\u56fe\u8c31\uff0c\u96c6\u6210\u8bed\u4e49\u76f8\u4f3c\u6027\u641c\u7d22\u3001\u7ed3\u6784\u63a8\u7406\u548c\u591a\u8df3\u63a8\u7406\uff0c\u901a\u8fc7\u67e5\u8be2\u5206\u6790\u52a8\u6001\u786e\u5b9a\u6700\u4f18\u68c0\u7d22\u7b56\u7565\uff0c\u652f\u6301\u7ed3\u6784\u5316\u548c\u975e\u7ed3\u6784\u5316\u6570\u636e\u6e90\u7684\u72ec\u7acb\u6216\u878d\u5408\u5904\u7406\u3002", "result": "\u5728\u5927\u89c4\u6a21Git\u4ed3\u5e93\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u7edf\u4e00\u63a8\u7406\u5c42\u76f8\u6bd4\u72ec\u7acb\u7684GPT\u68c0\u7d22\u6d41\u7a0b\uff0c\u7b54\u6848\u76f8\u5173\u6027\u63d0\u9ad8\u4e8680%\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u56fe\u6784\u5efa\u3001\u6df7\u5408\u63a8\u7406\u548c\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\uff0c\u4e3a\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u667a\u80fd\u77e5\u8bc6\u52a9\u624b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u548c\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u57fa\u7840\u3002"}}
{"id": "2510.10975", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10975", "abs": "https://arxiv.org/abs/2510.10975", "authors": ["Mingtong Dai", "Lingbo Liu", "Yongjie Bai", "Yang Liu", "Zhouxia Wang", "Rui SU", "Chunjie Chen", "Liang Lin", "Xinyu Wu"], "title": "RoVer: Robot Reward Model as Test-Time Verifier for Vision-Language-Action Model", "comment": null, "summary": "Vision-Language-Action (VLA) models have become a prominent paradigm for\nembodied intelligence, yet further performance improvements typically rely on\nscaling up training data and model size -- an approach that is prohibitively\nexpensive for robotics and fundamentally limited by data collection costs.We\naddress this limitation with $\\mathbf{RoVer}$, an embodied test-time scaling\nframework that uses a $\\mathbf{Ro}$bot Process Reward Model (PRM) as a\nTest-Time $\\mathbf{Ver}$ifier to enhance the capabilities of existing VLA\nmodels without modifying their architectures or weights. Specifically, RoVer\n(i) assigns scalar-based process rewards to evaluate the reliability of\ncandidate actions, and (ii) predicts an action-space direction for candidate\nexpansion/refinement. During inference, RoVer generates multiple candidate\nactions concurrently from the base policy, expands them along PRM-predicted\ndirections, and then scores all candidates with PRM to select the optimal\naction for execution. Notably, by caching shared perception features, it can\namortize perception cost and evaluate more candidates under the same test-time\ncomputational budget. Essentially, our approach effectively transforms\navailable computing resources into better action decision-making, realizing the\nbenefits of test-time scaling without extra training overhead. Our\ncontributions are threefold: (1) a general, plug-and-play test-time scaling\nframework for VLAs; (2) a PRM that jointly provides scalar process rewards and\nan action-space direction to guide exploration; and (3) an efficient\ndirection-guided sampling strategy that leverages a shared perception cache to\nenable scalable candidate generation and selection during inference.", "AI": {"tldr": "RoVer\u662f\u4e00\u4e2a\u7528\u4e8e\u63d0\u5347\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u6027\u80fd\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u673a\u5668\u4eba\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u4f5c\u4e3a\u9a8c\u8bc1\u5668\u6765\u4f18\u5316\u52a8\u4f5c\u9009\u62e9\uff0c\u65e0\u9700\u4fee\u6539\u6a21\u578b\u67b6\u6784\u6216\u6743\u91cd\u3002", "motivation": "\u89e3\u51b3VLA\u6a21\u578b\u6027\u80fd\u63d0\u5347\u4f9d\u8d56\u5927\u89c4\u6a21\u8bad\u7ec3\u6570\u636e\u548c\u6a21\u578b\u6269\u5c55\u7684\u95ee\u9898\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728\u673a\u5668\u4eba\u9886\u57df\u6210\u672c\u9ad8\u6602\u4e14\u53d7\u6570\u636e\u6536\u96c6\u9650\u5236\u3002", "method": "\u4f7f\u7528\u673a\u5668\u4eba\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u8bc4\u4f30\u5019\u9009\u52a8\u4f5c\u7684\u53ef\u9760\u6027\u5e76\u9884\u6d4b\u52a8\u4f5c\u7a7a\u95f4\u65b9\u5411\uff0c\u5728\u63a8\u7406\u65f6\u751f\u6210\u591a\u4e2a\u5019\u9009\u52a8\u4f5c\uff0c\u6cbfPRM\u9884\u6d4b\u65b9\u5411\u6269\u5c55\uff0c\u7136\u540e\u901a\u8fc7PRM\u8bc4\u5206\u9009\u62e9\u6700\u4f18\u52a8\u4f5c\u6267\u884c\u3002", "result": "\u901a\u8fc7\u5171\u4eab\u611f\u77e5\u7279\u5f81\u7f13\u5b58\uff0c\u5728\u76f8\u540c\u6d4b\u8bd5\u8ba1\u7b97\u9884\u7b97\u4e0b\u8bc4\u4f30\u66f4\u591a\u5019\u9009\u52a8\u4f5c\uff0c\u5c06\u8ba1\u7b97\u8d44\u6e90\u8f6c\u5316\u4e3a\u66f4\u597d\u7684\u52a8\u4f5c\u51b3\u7b56\u3002", "conclusion": "RoVer\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u5373\u63d2\u5373\u7528\u6d4b\u8bd5\u65f6\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u63d0\u4f9b\u6807\u91cf\u8fc7\u7a0b\u5956\u52b1\u548c\u52a8\u4f5c\u7a7a\u95f4\u65b9\u5411\u7684PRM\uff0c\u4ee5\u53ca\u9ad8\u6548\u7684\u65b9\u5411\u5f15\u5bfc\u91c7\u6837\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5f00\u9500\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u6548\u76ca\u3002"}}
{"id": "2510.10976", "categories": ["cs.AI", "68T05", "I.2.10"], "pdf": "https://arxiv.org/pdf/2510.10976", "abs": "https://arxiv.org/abs/2510.10976", "authors": ["Wentao Wang", "Heqing Zou", "Tianze Luo", "Rui Huang", "Yutian Zhao", "Zhuochen Wang", "Hansheng Zhang", "Chengwei Qin", "Yan Wang", "Lin Zhao", "Huaijian Zhang"], "title": "Video-STR: Reinforcing MLLMs in Video Spatio-Temporal Reasoning with Relation Graph", "comment": null, "summary": "Recent progress in Multimodal Large Language Models (MLLMs) has demonstrated\nstrong semantic understanding capabilities, but struggles to perform precise\nspatio-temporal understanding. Existing spatio-temporal methods primarily focus\non the video itself, while overlooking the physical information within the\nvideo, such as multi-object layouts and motion. Such limitations restrict the\nuse of MLLMs in downstream applications that demand high precision, including\nembodied intelligence and VR. To address this issue, we present Video-STR, a\nnovel graph-based reinforcement method for precise Video Spatio-Temporal\nReasoning. Building upon the capacity of Reinforcement Learning with Verifiable\nReward (RLVR) to improve model abilities, we introduce a reasoning mechanism\nusing graph-based Group Relative Policy Optimization (GRPO) method to guide the\nmodel in inferring the underlying spatio-temporal topology of scenarios during\nthe thinking process. To resolve the lack of spatio-temporal training data, we\nconstruct the STV-205k dataset with 205k question-answering pairs, covering\ndynamic multi-object scenes in both indoor and outdoor environments, to support\nthe model training. Experiments show that Video-STR achieves state-of-the-art\nresults on various benchmarks, outperforming the base model by 13% on\nSTI-Bench, and demonstrating the effectiveness of our approach and dataset.\nCode, model, and data will be released.", "AI": {"tldr": "Video-STR\u662f\u4e00\u79cd\u57fa\u4e8e\u56fe\u7ed3\u6784\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u7cbe\u786e\u7684\u89c6\u9891\u65f6\u7a7a\u63a8\u7406\uff0c\u901a\u8fc7\u56fe\u57fa\u7fa4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u673a\u5236\u63d0\u5347\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65f6\u7a7a\u7406\u89e3\u80fd\u529b\uff0c\u5e76\u5728STI-Bench\u57fa\u51c6\u4e0a\u6bd4\u57fa\u7ebf\u6a21\u578b\u63d0\u534713%", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u4e49\u7406\u89e3\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u7cbe\u786e\u7684\u65f6\u7a7a\u7406\u89e3\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5bf9\u89c6\u9891\u4e2d\u7269\u7406\u4fe1\u606f\uff08\u5982\u591a\u7269\u4f53\u5e03\u5c40\u548c\u8fd0\u52a8\uff09\u7684\u7406\u89e3\uff0c\u8fd9\u9650\u5236\u4e86\u5728\u5177\u8eab\u667a\u80fd\u548cVR\u7b49\u4e0b\u6e38\u5e94\u7528\u4e2d\u7684\u4f7f\u7528", "method": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u7ed3\u6784\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5Video-STR\uff0c\u91c7\u7528\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5f15\u5165\u56fe\u57fa\u7fa4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u673a\u5236\u6765\u5f15\u5bfc\u6a21\u578b\u5728\u601d\u8003\u8fc7\u7a0b\u4e2d\u63a8\u65ad\u573a\u666f\u7684\u65f6\u7a7a\u62d3\u6251\u7ed3\u6784", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u5728STI-Bench\u57fa\u51c6\u4e0a\u6bd4\u57fa\u7ebf\u6a21\u578b\u63d0\u534713%\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u548c\u6570\u636e\u96c6\u7684\u6709\u6548\u6027", "conclusion": "Video-STR\u901a\u8fc7\u56fe\u57fa\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65f6\u7a7a\u63a8\u7406\u80fd\u529b\uff0c\u6784\u5efa\u7684STV-205k\u6570\u636e\u96c6\u4e3a\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u652f\u6301\uff0c\u4ee3\u7801\u3001\u6a21\u578b\u548c\u6570\u636e\u5c06\u516c\u5f00\u53d1\u5e03"}}
{"id": "2510.10979", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10979", "abs": "https://arxiv.org/abs/2510.10979", "authors": ["Qizhi Guo", "Siyuan Yang", "Junning Lyu", "Jianjun Sun", "Defu Lin", "Shaoming He"], "title": "AMO-HEAD: Adaptive MARG-Only Heading Estimation for UAVs under Magnetic Disturbances", "comment": null, "summary": "Accurate and robust heading estimation is crucial for unmanned aerial\nvehicles (UAVs) when conducting indoor inspection tasks. However, the cluttered\nnature of indoor environments often introduces severe magnetic disturbances,\nwhich can significantly degrade heading accuracy. To address this challenge,\nthis paper presents an Adaptive MARG-Only Heading (AMO-HEAD) estimation\napproach for UAVs operating in magnetically disturbed environments. AMO-HEAD is\na lightweight and computationally efficient Extended Kalman Filter (EKF)\nframework that leverages inertial and magnetic sensors to achieve reliable\nheading estimation. In the proposed approach, gyroscope angular rate\nmeasurements are integrated to propagate the quaternion state, which is\nsubsequently corrected using accelerometer and magnetometer data. The corrected\nquaternion is then used to compute the UAV's heading. An adaptive process noise\ncovariance method is introduced to model and compensate for gyroscope\nmeasurement noise, bias drift, and discretization errors arising from the Euler\nmethod integration. To mitigate the effects of external magnetic disturbances,\na scaling factor is applied based on real-time magnetic deviation detection. A\ntheoretical observability analysis of the proposed AMO-HEAD is performed using\nthe Lie derivative. Extensive experiments were conducted in real world indoor\nenvironments with customized UAV platforms. The results demonstrate the\neffectiveness of the proposed algorithm in providing precise heading estimation\nunder magnetically disturbed conditions.", "AI": {"tldr": "\u63d0\u51faAMO-HEAD\u65b9\u6cd5\uff0c\u4e00\u79cd\u8f7b\u91cf\u7ea7EKF\u6846\u67b6\uff0c\u7528\u4e8e\u65e0\u4eba\u673a\u5728\u78c1\u5e72\u6270\u73af\u5883\u4e0b\u7684\u9c81\u68d2\u822a\u5411\u4f30\u8ba1", "motivation": "\u5ba4\u5185\u73af\u5883\u4e2d\u7684\u78c1\u5e72\u6270\u4f1a\u663e\u8457\u964d\u4f4e\u65e0\u4eba\u673a\u822a\u5411\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u6311\u6218", "method": "\u4f7f\u7528\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff0c\u96c6\u6210\u9640\u87ba\u4eea\u89d2\u901f\u7387\u6d4b\u91cf\u4f20\u64ad\u56db\u5143\u6570\u72b6\u6001\uff0c\u5e76\u7528\u52a0\u901f\u5ea6\u8ba1\u548c\u78c1\u529b\u8ba1\u6570\u636e\u6821\u6b63\u3002\u5f15\u5165\u81ea\u9002\u5e94\u8fc7\u7a0b\u566a\u58f0\u534f\u65b9\u5dee\u65b9\u6cd5\u548c\u57fa\u4e8e\u5b9e\u65f6\u78c1\u504f\u5dee\u68c0\u6d4b\u7684\u7f29\u653e\u56e0\u5b50", "result": "\u5728\u771f\u5b9e\u5ba4\u5185\u73af\u5883\u4e2d\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u78c1\u5e72\u6270\u6761\u4ef6\u4e0b\u80fd\u63d0\u4f9b\u7cbe\u786e\u7684\u822a\u5411\u4f30\u8ba1", "conclusion": "AMO-HEAD\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u65e0\u4eba\u673a\u5728\u78c1\u5e72\u6270\u73af\u5883\u4e0b\u7684\u822a\u5411\u4f30\u8ba1\u95ee\u9898"}}
{"id": "2510.10977", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.10977", "abs": "https://arxiv.org/abs/2510.10977", "authors": ["Taiqiang Wu", "Runming Yang", "Tao Liu", "Jiahao Wang", "Ngai Wong"], "title": "Revisiting Model Interpolation for Efficient Reasoning", "comment": "14 pages, 6 figures, 7 tables. Working in progress", "summary": "Model merging, typically on Instruct and Thinking models, has shown\nremarkable performance for efficient reasoning. In this paper, we\nsystematically revisit the simplest merging method that interpolates two\nweights directly. Particularly, we observe that model interpolation follows a\nthree-stage evolutionary paradigm with distinct behaviors on the reasoning\ntrajectory. These dynamics provide a principled guide for navigating the\nperformance-cost trade-off. Empirical results demonstrate that a strategically\ninterpolated model surprisingly surpasses sophisticated model merging baselines\non both efficiency and effectiveness. We further validate our findings with\nextensive ablation studies on model layers, modules, and decoding strategies.\nUltimately, this work demystifies model interpolation and offers a practical\nframework for crafting models with precisely targeted reasoning capabilities.\nCode is available at \\href{https://github.com/wutaiqiang/MI}{Github}.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u6700\u7b80\u5355\u7684\u6a21\u578b\u6743\u91cd\u63d2\u503c\u65b9\u6cd5\uff0c\u53d1\u73b0\u5176\u9075\u5faa\u4e09\u9636\u6bb5\u6f14\u5316\u8303\u5f0f\uff0c\u80fd\u591f\u6709\u6548\u5e73\u8861\u6027\u80fd\u4e0e\u6210\u672c\uff0c\u751a\u81f3\u8d85\u8d8a\u590d\u6742\u6a21\u578b\u878d\u5408\u65b9\u6cd5\u3002", "motivation": "\u6a21\u578b\u878d\u5408\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u590d\u6742\u3002\u672c\u6587\u91cd\u65b0\u5ba1\u89c6\u6700\u7b80\u5355\u7684\u6743\u91cd\u63d2\u503c\u65b9\u6cd5\uff0c\u63a2\u7d22\u5176\u6f5c\u5728\u4ef7\u503c\u3002", "method": "\u91c7\u7528\u76f4\u63a5\u7684\u6743\u91cd\u63d2\u503c\u65b9\u6cd5\uff0c\u5206\u6790\u5176\u5728\u63a8\u7406\u8f68\u8ff9\u4e0a\u7684\u4e09\u9636\u6bb5\u6f14\u5316\u884c\u4e3a\uff0c\u5e76\u901a\u8fc7\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e0d\u540c\u5c42\u3001\u6a21\u5757\u548c\u89e3\u7801\u7b56\u7565\u7684\u5f71\u54cd\u3002", "result": "\u7b56\u7565\u6027\u63d2\u503c\u7684\u6a21\u578b\u5728\u6548\u7387\u548c\u6548\u679c\u4e0a\u5747\u8d85\u8d8a\u4e86\u590d\u6742\u7684\u6a21\u578b\u878d\u5408\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd-\u6210\u672c\u6743\u8861\u3002", "conclusion": "\u6a21\u578b\u63d2\u503c\u65b9\u6cd5\u867d\u7136\u7b80\u5355\u4f46\u6709\u6548\uff0c\u4e3a\u6784\u5efa\u5177\u6709\u7cbe\u786e\u76ee\u6807\u63a8\u7406\u80fd\u529b\u7684\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\u3002"}}
{"id": "2510.11014", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.11014", "abs": "https://arxiv.org/abs/2510.11014", "authors": ["Subhransu S. Bhattacharjee", "Hao Lu", "Dylan Campbell", "Rahul Shome"], "title": "Into the Unknown: Towards using Generative Models for Sampling Priors of Environment Uncertainty for Planning in Configuration Spaces", "comment": "Under Review", "summary": "Priors are vital for planning under partial observability, yet difficult to\nobtain in practice. We present a sampling-based pipeline that leverages\nlarge-scale pretrained generative models to produce probabilistic priors\ncapturing environmental uncertainty and spatio-semantic relationships in a\nzero-shot manner. Conditioned on partial observations, the pipeline recovers\ncomplete RGB-D point cloud samples with occupancy and target semantics,\nformulated to be directly useful in configuration-space planning. We establish\na Matterport3D benchmark of rooms partially visible through doorways, where a\nrobot must navigate to an unobserved target object. Effective priors for this\nsetting must represent both occupancy and target-location uncertainty in\nunobserved regions. Experiments show that our approach recovers commonsense\nspatial semantics consistent with ground truth, yielding diverse, clean 3D\npoint clouds usable in motion planning, highlight the promise of generative\nmodels as a rich source of priors for robotic planning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91c7\u6837\u7684\u6d41\u7a0b\uff0c\u5229\u7528\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u751f\u6210\u6a21\u578b\u4e3a\u96f6\u6837\u672c\u89c4\u5212\u63d0\u4f9b\u6982\u7387\u5148\u9a8c\uff0c\u80fd\u591f\u4ece\u90e8\u5206\u89c2\u6d4b\u6062\u590d\u5b8c\u6574\u7684RGB-D\u70b9\u4e91\u6837\u672c\uff0c\u5305\u542b\u5360\u7528\u548c\u76ee\u6807\u8bed\u4e49\u4fe1\u606f\u3002", "motivation": "\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u89c4\u5212\u9700\u8981\u5148\u9a8c\u77e5\u8bc6\uff0c\u4f46\u5b9e\u9645\u4e2d\u96be\u4ee5\u83b7\u53d6\u3002\u672c\u6587\u65e8\u5728\u5229\u7528\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u73af\u5883\u4e0d\u786e\u5b9a\u6027\u548c\u7a7a\u95f4\u8bed\u4e49\u5173\u7cfb\u7684\u5148\u9a8c\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u91c7\u6837\u7684\u6d41\u7a0b\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u751f\u6210\u6a21\u578b\uff0c\u5728\u90e8\u5206\u89c2\u6d4b\u6761\u4ef6\u4e0b\u6062\u590d\u5b8c\u6574\u7684RGB-D\u70b9\u4e91\u6837\u672c\uff0c\u5305\u542b\u5360\u7528\u548c\u76ee\u6807\u8bed\u4e49\uff0c\u53ef\u76f4\u63a5\u7528\u4e8e\u914d\u7f6e\u7a7a\u95f4\u89c4\u5212\u3002", "result": "\u5728Matterport3D\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6062\u590d\u4e0e\u771f\u5b9e\u60c5\u51b5\u4e00\u81f4\u7684\u5e38\u8bc6\u6027\u7a7a\u95f4\u8bed\u4e49\uff0c\u751f\u6210\u591a\u6837\u5316\u3001\u5e72\u51c0\u76843D\u70b9\u4e91\uff0c\u53ef\u7528\u4e8e\u8fd0\u52a8\u89c4\u5212\u3002", "conclusion": "\u751f\u6210\u6a21\u578b\u6709\u671b\u6210\u4e3a\u673a\u5668\u4eba\u89c4\u5212\u4e2d\u4e30\u5bcc\u7684\u5148\u9a8c\u77e5\u8bc6\u6765\u6e90\uff0c\u80fd\u591f\u6709\u6548\u8868\u793a\u672a\u89c2\u6d4b\u533a\u57df\u7684\u5360\u7528\u548c\u76ee\u6807\u4f4d\u7f6e\u4e0d\u786e\u5b9a\u6027\u3002"}}
{"id": "2510.11003", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.11003", "abs": "https://arxiv.org/abs/2510.11003", "authors": ["Takuma Fujiu", "Sho Okazaki", "Kohei Kaminishi", "Yuji Nakata", "Shota Hamamoto", "Kenshin Yokose", "Tatsunori Hara", "Yasushi Umeda", "Jun Ota"], "title": "FBS Model-based Maintenance Record Accumulation for Failure-Cause Inference in Manufacturing Systems", "comment": null, "summary": "In manufacturing systems, identifying the causes of failures is crucial for\nmaintaining and improving production efficiency. In knowledge-based\nfailure-cause inference, it is important that the knowledge base (1) explicitly\nstructures knowledge about the target system and about failures, and (2)\ncontains sufficiently long causal chains of failures. In this study, we\nconstructed Diagnostic Knowledge Ontology and proposed a\nFunction-Behavior-Structure (FBS) model-based maintenance-record accumulation\nmethod based on it. Failure-cause inference using the maintenance records\naccumulated by the proposed method showed better agreement with the set of\ncandidate causes enumerated by experts, especially in difficult cases where the\nnumber of related cases is small and the vocabulary used differs. In the\nfuture, it will be necessary to develop inference methods tailored to these\nmaintenance records, build a user interface, and carry out validation on larger\nand more diverse systems. Additionally, this approach leverages the\nunderstanding and knowledge of the target in the design phase to support\nknowledge accumulation and problem solving during the maintenance phase, and it\nis expected to become a foundation for knowledge sharing across the entire\nengineering chain in the future.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8bca\u65ad\u77e5\u8bc6\u672c\u4f53\u548cFBS\u6a21\u578b\u7684\u7ef4\u62a4\u8bb0\u5f55\u79ef\u7d2f\u65b9\u6cd5\uff0c\u7528\u4e8e\u5236\u9020\u7cfb\u7edf\u4e2d\u7684\u6545\u969c\u539f\u56e0\u63a8\u65ad\uff0c\u5728\u56f0\u96be\u6848\u4f8b\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u5236\u9020\u7cfb\u7edf\u4e2d\u8bc6\u522b\u6545\u969c\u539f\u56e0\u5bf9\u7ef4\u6301\u548c\u63d0\u9ad8\u751f\u4ea7\u6548\u7387\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u77e5\u8bc6\u5e93\u660e\u786e\u7ed3\u6784\u5316\u7cfb\u7edf\u77e5\u8bc6\u548c\u6545\u969c\u77e5\u8bc6\uff0c\u5e76\u5305\u542b\u8db3\u591f\u957f\u7684\u6545\u969c\u56e0\u679c\u94fe\u3002", "method": "\u6784\u5efa\u8bca\u65ad\u77e5\u8bc6\u672c\u4f53\uff0c\u63d0\u51fa\u57fa\u4e8e\u529f\u80fd-\u884c\u4e3a-\u7ed3\u6784(FBS)\u6a21\u578b\u7684\u7ef4\u62a4\u8bb0\u5f55\u79ef\u7d2f\u65b9\u6cd5\u3002", "result": "\u4f7f\u7528\u8be5\u65b9\u6cd5\u79ef\u7d2f\u7684\u7ef4\u62a4\u8bb0\u5f55\u8fdb\u884c\u6545\u969c\u539f\u56e0\u63a8\u65ad\uff0c\u4e0e\u4e13\u5bb6\u5217\u4e3e\u7684\u5019\u9009\u539f\u56e0\u96c6\u6709\u66f4\u597d\u7684\u4e00\u81f4\u6027\uff0c\u7279\u522b\u662f\u5728\u76f8\u5173\u6848\u4f8b\u5c11\u3001\u8bcd\u6c47\u4e0d\u540c\u7684\u56f0\u96be\u60c5\u51b5\u4e0b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5229\u7528\u8bbe\u8ba1\u9636\u6bb5\u5bf9\u76ee\u6807\u7684\u7406\u89e3\u548c\u77e5\u8bc6\u6765\u652f\u6301\u7ef4\u62a4\u9636\u6bb5\u7684\u77e5\u8bc6\u79ef\u7d2f\u548c\u95ee\u9898\u89e3\u51b3\uff0c\u6709\u671b\u6210\u4e3a\u672a\u6765\u6574\u4e2a\u5de5\u7a0b\u94fe\u77e5\u8bc6\u5171\u4eab\u7684\u57fa\u7840\u3002"}}
{"id": "2510.11019", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.11019", "abs": "https://arxiv.org/abs/2510.11019", "authors": ["Bingjie Tang", "Iretiayo Akinola", "Jie Xu", "Bowen Wen", "Dieter Fox", "Gaurav S. Sukhatme", "Fabio Ramos", "Abhishek Gupta", "Yashraj Narang"], "title": "Refinery: Active Fine-tuning and Deployment-time Optimization for Contact-Rich Policies", "comment": "in submission. 8 pages, 6 figures. Website:\n  https://refinery-2025.github.io/refinery/", "summary": "Simulation-based learning has enabled policies for precise, contact-rich\ntasks (e.g., robotic assembly) to reach high success rates (~80%) under high\nlevels of observation noise and control error. Although such performance may be\nsufficient for research applications, it falls short of industry standards and\nmakes policy chaining exceptionally brittle. A key limitation is the high\nvariance in individual policy performance across diverse initial conditions. We\nintroduce Refinery, an effective framework that bridges this performance gap,\nrobustifying policy performance across initial conditions. We propose Bayesian\nOptimization-guided fine-tuning to improve individual policies, and Gaussian\nMixture Model-based sampling during deployment to select initializations that\nmaximize execution success. Using Refinery, we improve mean success rates by\n10.98% over state-of-the-art methods in simulation-based learning for robotic\nassembly, reaching 91.51% in simulation and comparable performance in the real\nworld. Furthermore, we demonstrate that these fine-tuned policies can be\nchained to accomplish long-horizon, multi-part\nassembly$\\unicode{x2013}$successfully assembling up to 8 parts without\nrequiring explicit multi-step training.", "AI": {"tldr": "Refinery\u6846\u67b6\u901a\u8fc7\u8d1d\u53f6\u65af\u4f18\u5316\u5fae\u8c03\u7b56\u7565\u548c\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u91c7\u6837\uff0c\u5c06\u673a\u5668\u4eba\u88c5\u914d\u4efb\u52a1\u7684\u6210\u529f\u7387\u4ece\u7ea680%\u63d0\u5347\u81f391.51%\uff0c\u5e76\u80fd\u5b9e\u73b08\u4e2a\u96f6\u4ef6\u7684\u957f\u65f6\u7a0b\u88c5\u914d\u3002", "motivation": "\u57fa\u4e8e\u4eff\u771f\u7684\u5b66\u4e60\u65b9\u6cd5\u5728\u63a5\u89e6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u8fbe\u5230\u7ea680%\u7684\u6210\u529f\u7387\uff0c\u4f46\u8fd9\u5bf9\u5de5\u4e1a\u5e94\u7528\u6765\u8bf4\u4e0d\u591f\u53ef\u9760\uff0c\u4e14\u7b56\u7565\u4e32\u8054\u65f6\u7279\u522b\u8106\u5f31\u3002\u5173\u952e\u9650\u5236\u662f\u7b56\u7565\u5728\u4e0d\u540c\u521d\u59cb\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u65b9\u5dee\u8fc7\u9ad8\u3002", "method": "\u63d0\u51faRefinery\u6846\u67b6\uff1a\u4f7f\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u6307\u5bfc\u7684\u7b56\u7565\u5fae\u8c03\u6765\u6539\u8fdb\u5355\u4e2a\u7b56\u7565\u6027\u80fd\uff1b\u5728\u90e8\u7f72\u65f6\u4f7f\u7528\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u91c7\u6837\u6765\u9009\u62e9\u6700\u5927\u5316\u6267\u884c\u6210\u529f\u7387\u7684\u521d\u59cb\u5316\u6761\u4ef6\u3002", "result": "\u5728\u673a\u5668\u4eba\u88c5\u914d\u7684\u4eff\u771f\u5b66\u4e60\u4e2d\uff0c\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u5e73\u5747\u6210\u529f\u7387\u63d0\u9ad810.98%\uff0c\u8fbe\u523091.51%\u7684\u6210\u529f\u7387\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u8868\u73b0\u76f8\u5f53\u3002\u80fd\u591f\u4e32\u8054\u5fae\u8c03\u540e\u7684\u7b56\u7565\u5b8c\u6210\u957f\u65f6\u7a0b\u591a\u96f6\u4ef6\u88c5\u914d\uff0c\u6210\u529f\u7ec4\u88c5\u591a\u8fbe8\u4e2a\u96f6\u4ef6\u3002", "conclusion": "Refinery\u6846\u67b6\u6709\u6548\u5f25\u8865\u4e86\u4eff\u771f\u5b66\u4e60\u4e0e\u5de5\u4e1a\u5e94\u7528\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u63d0\u9ad8\u4e86\u7b56\u7565\u5728\u4e0d\u540c\u521d\u59cb\u6761\u4ef6\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u8bc1\u660e\u4e86\u5fae\u8c03\u7b56\u7565\u80fd\u591f\u4e32\u8054\u5b8c\u6210\u590d\u6742\u7684\u957f\u65f6\u7a0b\u88c5\u914d\u4efb\u52a1\u3002"}}
{"id": "2510.11079", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11079", "abs": "https://arxiv.org/abs/2510.11079", "authors": ["Andrada Iulia Prajescu", "Roberto Confalonieri"], "title": "Argumentation-Based Explainability for Legal AI: Comparative and Regulatory Perspectives", "comment": null, "summary": "Artificial Intelligence (AI) systems are increasingly deployed in legal\ncontexts, where their opacity raises significant challenges for fairness,\naccountability, and trust. The so-called ``black box problem'' undermines the\nlegitimacy of automated decision-making, as affected individuals often lack\naccess to meaningful explanations. In response, the field of Explainable AI\n(XAI) has proposed a variety of methods to enhance transparency, ranging from\nexample-based and rule-based techniques to hybrid and argumentation-based\napproaches. This paper promotes computational models of arguments and their\nrole in providing legally relevant explanations, with particular attention to\ntheir alignment with emerging regulatory frameworks such as the EU General Data\nProtection Regulation (GDPR) and the Artificial Intelligence Act (AIA). We\nanalyze the strengths and limitations of different explanation strategies,\nevaluate their applicability to legal reasoning, and highlight how\nargumentation frameworks -- by capturing the defeasible, contestable, and\nvalue-sensitive nature of law -- offer a particularly robust foundation for\nexplainable legal AI. Finally, we identify open challenges and research\ndirections, including bias mitigation, empirical validation in judicial\nsettings, and compliance with evolving ethical and legal standards, arguing\nthat computational argumentation is best positioned to meet both technical and\nnormative requirements of transparency in the law domain.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5728AI\u7cfb\u7edf\u5e94\u7528\u4e8e\u6cd5\u5f8b\u9886\u57df\u65f6\uff0c\u5982\u4f55\u901a\u8fc7\u8ba1\u7b97\u8bba\u8bc1\u6a21\u578b\u63d0\u4f9b\u7b26\u5408\u6cd5\u5f8b\u8981\u6c42\u7684\u89e3\u91ca\uff0c\u4ee5\u89e3\u51b3\"\u9ed1\u7bb1\u95ee\u9898\"\uff0c\u7279\u522b\u5173\u6ce8\u4e0eGDPR\u548cAIA\u7b49\u6cd5\u89c4\u7684\u517c\u5bb9\u6027\u3002", "motivation": "AI\u7cfb\u7edf\u5728\u6cd5\u5f8b\u73af\u5883\u4e2d\u7684\u4e0d\u900f\u660e\u6027\u5bf9\u516c\u5e73\u6027\u3001\u95ee\u8d23\u5236\u548c\u4fe1\u4efb\u6784\u6210\u6311\u6218\uff0c\"\u9ed1\u7bb1\u95ee\u9898\"\u524a\u5f31\u4e86\u81ea\u52a8\u5316\u51b3\u7b56\u7684\u5408\u6cd5\u6027\uff0c\u9700\u8981\u63d0\u4f9b\u6709\u610f\u4e49\u7684\u6cd5\u5f8b\u89e3\u91ca\u3002", "method": "\u63d0\u5021\u4f7f\u7528\u8ba1\u7b97\u8bba\u8bc1\u6a21\u578b\uff0c\u5206\u6790\u4e0d\u540c\u89e3\u91ca\u7b56\u7565\u7684\u4f18\u7f3a\u70b9\uff0c\u8bc4\u4f30\u5176\u5728\u6cd5\u5f8b\u63a8\u7406\u4e2d\u7684\u9002\u7528\u6027\uff0c\u5f3a\u8c03\u8bba\u8bc1\u6846\u67b6\u80fd\u591f\u6355\u6349\u6cd5\u5f8b\u7684\u53ef\u5e9f\u6b62\u6027\u3001\u53ef\u4e89\u8bae\u6027\u548c\u4ef7\u503c\u654f\u611f\u6027\u3002", "result": "\u8bba\u8bc1\u6846\u67b6\u4e3a\u53ef\u89e3\u91ca\u6cd5\u5f8bAI\u63d0\u4f9b\u4e86\u7279\u522b\u7a33\u5065\u7684\u57fa\u7840\uff0c\u80fd\u591f\u6ee1\u8db3\u6cd5\u5f8b\u9886\u57df\u7684\u900f\u660e\u6027\u8981\u6c42\u3002", "conclusion": "\u8ba1\u7b97\u8bba\u8bc1\u65b9\u6cd5\u6700\u80fd\u6ee1\u8db3\u6cd5\u5f8b\u9886\u57df\u7684\u6280\u672f\u548c\u89c4\u8303\u6027\u900f\u660e\u8981\u6c42\uff0c\u4f46\u4ecd\u9700\u89e3\u51b3\u504f\u89c1\u7f13\u89e3\u3001\u53f8\u6cd5\u73af\u5883\u5b9e\u8bc1\u9a8c\u8bc1\u7b49\u5f00\u653e\u6311\u6218\u3002"}}
{"id": "2510.11036", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11036", "abs": "https://arxiv.org/abs/2510.11036", "authors": ["Yeonseo Lee", "Jungwook Mun", "Hyosup Shin", "Guebin Hwang", "Junhee Nam", "Taeyeop Lee", "Sungho Jo"], "title": "XGrasp: Gripper-Aware Grasp Detection with Multi-Gripper Data Generation", "comment": null, "summary": "Most robotic grasping methods are typically designed for single gripper\ntypes, which limits their applicability in real-world scenarios requiring\ndiverse end-effectors. We propose XGrasp, a real-time gripper-aware grasp\ndetection framework that efficiently handles multiple gripper configurations.\nThe proposed method addresses data scarcity by systematically augmenting\nexisting datasets with multi-gripper annotations. XGrasp employs a hierarchical\ntwo-stage architecture. In the first stage, a Grasp Point Predictor (GPP)\nidentifies optimal locations using global scene information and gripper\nspecifications. In the second stage, an Angle-Width Predictor (AWP) refines the\ngrasp angle and width using local features. Contrastive learning in the AWP\nmodule enables zero-shot generalization to unseen grippers by learning\nfundamental grasping characteristics. The modular framework integrates\nseamlessly with vision foundation models, providing pathways for future\nvision-language capabilities. The experimental results demonstrate competitive\ngrasp success rates across various gripper types, while achieving substantial\nimprovements in inference speed compared to existing gripper-aware methods.\nProject page: https://sites.google.com/view/xgrasp", "AI": {"tldr": "XGrasp\u662f\u4e00\u4e2a\u5b9e\u65f6\u5939\u722a\u611f\u77e5\u7684\u6293\u53d6\u68c0\u6d4b\u6846\u67b6\uff0c\u80fd\u591f\u9ad8\u6548\u5904\u7406\u591a\u79cd\u5939\u722a\u914d\u7f6e\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u5c42\u6b21\u67b6\u6784\u5b9e\u73b0\u591a\u5939\u722a\u6293\u53d6\u68c0\u6d4b\u548c\u96f6\u6837\u672c\u6cdb\u5316\u3002", "motivation": "\u5927\u591a\u6570\u673a\u5668\u4eba\u6293\u53d6\u65b9\u6cd5\u901a\u5e38\u53ea\u9488\u5bf9\u5355\u4e00\u5939\u722a\u7c7b\u578b\u8bbe\u8ba1\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u9700\u8981\u591a\u6837\u5316\u672b\u7aef\u6267\u884c\u5668\u7684\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "\u91c7\u7528\u5206\u5c42\u4e24\u9636\u6bb5\u67b6\u6784\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u6293\u53d6\u70b9\u9884\u6d4b\u5668(GPP)\u8bc6\u522b\u6700\u4f73\u4f4d\u7f6e\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u89d2\u5ea6-\u5bbd\u5ea6\u9884\u6d4b\u5668(AWP)\u7ec6\u5316\u6293\u53d6\u89d2\u5ea6\u548c\u5bbd\u5ea6\uff0c\u5e76\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u5b9e\u73b0\u96f6\u6837\u672c\u6cdb\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5728\u5404\u79cd\u5939\u722a\u7c7b\u578b\u4e0a\u5177\u6709\u7ade\u4e89\u529b\u7684\u6293\u53d6\u6210\u529f\u7387\uff0c\u540c\u65f6\u76f8\u6bd4\u73b0\u6709\u5939\u722a\u611f\u77e5\u65b9\u6cd5\u5728\u63a8\u7406\u901f\u5ea6\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "XGrasp\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u6846\u67b6\uff0c\u80fd\u591f\u65e0\u7f1d\u96c6\u6210\u89c6\u89c9\u57fa\u7840\u6a21\u578b\uff0c\u4e3a\u672a\u6765\u7684\u89c6\u89c9-\u8bed\u8a00\u80fd\u529b\u63d0\u4f9b\u9014\u5f84\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u5939\u722a\u6293\u53d6\u68c0\u6d4b\u7684\u6311\u6218\u3002"}}
{"id": "2510.11085", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11085", "abs": "https://arxiv.org/abs/2510.11085", "authors": ["Yuxinyue Qian", "Jun Liu"], "title": "Modeling AI-Driven Production and Competitiveness A Multi-Agent Economic Simulation of China and the United States", "comment": null, "summary": "With the rapid development of artificial intelligence (AI) technology,\nsocio-economic systems are entering a new stage of \"human-AI co-creation.\"\nBuilding upon a previously established multi-level intelligent agent economic\nmodel, this paper conducts simulation-based comparisons of macroeconomic output\nevolution in China and the United States under different mechanisms-AI\ncollaboration, network effects, and AI autonomous production. The results show\nthat: (1) when AI functions as an independent productive entity, the overall\ngrowth rate of social output far exceeds that of traditional human-labor-based\nmodels; (2) China demonstrates clear potential for acceleration in both the\nexpansion of intelligent agent populations and the pace of technological\ncatch-up, offering the possibility of achieving technological convergence or\neven partial surpassing. This study provides a systematic, model-based\nanalytical framework for understanding AI-driven production system\ntransformation and shifts in international competitiveness, as well as\nquantitative insights for relevant policy formulation.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7ecf\u6d4e\u6a21\u578b\uff0c\u6bd4\u8f83\u4e86\u4e2d\u56fd\u548c\u7f8e\u56fd\u5728\u4e0d\u540cAI\u673a\u5236\u4e0b\u7684\u5b8f\u89c2\u7ecf\u6d4e\u4ea7\u51fa\u6f14\u53d8\uff0c\u53d1\u73b0AI\u4f5c\u4e3a\u72ec\u7acb\u751f\u4ea7\u5b9e\u4f53\u80fd\u663e\u8457\u63d0\u5347\u793e\u4f1a\u4ea7\u51fa\u589e\u957f\u7387\uff0c\u4e2d\u56fd\u5728\u667a\u80fd\u4f53\u6269\u5f20\u548c\u6280\u672f\u8ffd\u8d76\u65b9\u9762\u5177\u6709\u52a0\u901f\u6f5c\u529b\u3002", "motivation": "\u968f\u7740AI\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u793e\u4f1a\u7ecf\u6d4e\u7cfb\u7edf\u8fdb\u5165\"\u4eba\u673a\u5171\u521b\"\u65b0\u9636\u6bb5\uff0c\u9700\u8981\u7cfb\u7edf\u5206\u6790AI\u9a71\u52a8\u7684\u751f\u4ea7\u7cfb\u7edf\u8f6c\u578b\u548c\u56fd\u9645\u7ade\u4e89\u529b\u53d8\u5316\u3002", "method": "\u57fa\u4e8e\u5148\u524d\u5efa\u7acb\u7684\u591a\u5c42\u6b21\u667a\u80fd\u4f53\u7ecf\u6d4e\u6a21\u578b\uff0c\u91c7\u7528\u4eff\u771f\u65b9\u6cd5\u6bd4\u8f83\u4e2d\u56fd\u548c\u7f8e\u56fd\u5728AI\u534f\u4f5c\u3001\u7f51\u7edc\u6548\u5e94\u548cAI\u81ea\u4e3b\u751f\u4ea7\u7b49\u4e0d\u540c\u673a\u5236\u4e0b\u7684\u5b8f\u89c2\u7ecf\u6d4e\u4ea7\u51fa\u6f14\u53d8\u3002", "result": "\u5f53AI\u4f5c\u4e3a\u72ec\u7acb\u751f\u4ea7\u5b9e\u4f53\u65f6\uff0c\u793e\u4f1a\u4ea7\u51fa\u589e\u957f\u7387\u8fdc\u8d85\u4f20\u7edf\u4eba\u529b\u52b3\u52a8\u6a21\u5f0f\uff1b\u4e2d\u56fd\u5728\u667a\u80fd\u4f53\u4eba\u53e3\u6269\u5f20\u548c\u6280\u672f\u8ffd\u8d76\u901f\u5ea6\u65b9\u9762\u663e\u793a\u51fa\u660e\u663e\u7684\u52a0\u901f\u6f5c\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u7406\u89e3AI\u9a71\u52a8\u7684\u751f\u4ea7\u7cfb\u7edf\u8f6c\u578b\u548c\u56fd\u9645\u7ade\u4e89\u529b\u53d8\u5316\u63d0\u4f9b\u4e86\u57fa\u4e8e\u6a21\u578b\u7684\u7cfb\u7edf\u6027\u5206\u6790\u6846\u67b6\uff0c\u5e76\u4e3a\u76f8\u5173\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u4e86\u91cf\u5316\u53c2\u8003\u3002"}}
{"id": "2510.11041", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.11041", "abs": "https://arxiv.org/abs/2510.11041", "authors": ["Shiyao Zhang", "Liwei Deng", "Shuyu Zhang", "Weijie Yuan", "Hong Zhang"], "title": "Unveiling Uncertainty-Aware Autonomous Cooperative Learning Based Planning Strategy", "comment": "Accepted by IEEE RA-L", "summary": "In future intelligent transportation systems, autonomous cooperative planning\n(ACP), becomes a promising technique to increase the effectiveness and security\nof multi-vehicle interactions. However, multiple uncertainties cannot be fully\naddressed for existing ACP strategies, e.g. perception, planning, and\ncommunication uncertainties. To address these, a novel deep reinforcement\nlearning-based autonomous cooperative planning (DRLACP) framework is proposed\nto tackle various uncertainties on cooperative motion planning schemes.\nSpecifically, the soft actor-critic (SAC) with the implementation of gate\nrecurrent units (GRUs) is adopted to learn the deterministic optimal\ntime-varying actions with imperfect state information occurred by planning,\ncommunication, and perception uncertainties. In addition, the real-time actions\nof autonomous vehicles (AVs) are demonstrated via the Car Learning to Act\n(CARLA) simulation platform. Evaluation results show that the proposed DRLACP\nlearns and performs cooperative planning effectively, which outperforms other\nbaseline methods under different scenarios with imperfect AV state information.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u4e3b\u534f\u540c\u89c4\u5212\u6846\u67b6(DRLACP)\uff0c\u4f7f\u7528\u8f6f\u6f14\u5458-\u8bc4\u8bba\u5668(SAC)\u548c\u95e8\u63a7\u5faa\u73af\u5355\u5143(GRU)\u5904\u7406\u611f\u77e5\u3001\u89c4\u5212\u548c\u901a\u4fe1\u4e0d\u786e\u5b9a\u6027\uff0c\u5728CARLA\u4eff\u771f\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u4e86\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u81ea\u4e3b\u534f\u540c\u89c4\u5212\u7b56\u7565\u65e0\u6cd5\u5145\u5206\u5904\u7406\u591a\u79cd\u4e0d\u786e\u5b9a\u6027\uff08\u5982\u611f\u77e5\u3001\u89c4\u5212\u3001\u901a\u4fe1\u4e0d\u786e\u5b9a\u6027\uff09\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5e94\u5bf9\u8fd9\u4e9b\u4e0d\u786e\u5b9a\u6027\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u8f6f\u6f14\u5458-\u8bc4\u8bba\u5668(SAC)\u7ed3\u5408\u95e8\u63a7\u5faa\u73af\u5355\u5143(GRU)\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5b66\u4e60\u5728\u72b6\u6001\u4fe1\u606f\u4e0d\u5b8c\u7f8e\u60c5\u51b5\u4e0b\u7684\u786e\u5b9a\u6027\u6700\u4f18\u65f6\u53d8\u52a8\u4f5c\u3002", "result": "\u5728CARLA\u4eff\u771f\u5e73\u53f0\u4e0a\u7684\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0cDRLACP\u80fd\u591f\u6709\u6548\u5b66\u4e60\u548c\u6267\u884c\u534f\u540c\u89c4\u5212\uff0c\u5728\u72b6\u6001\u4fe1\u606f\u4e0d\u5b8c\u7f8e\u7684\u4e0d\u540c\u573a\u666f\u4e0b\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684DRLACP\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u81ea\u4e3b\u8f66\u8f86\u534f\u540c\u8fd0\u52a8\u89c4\u5212\u4e2d\u7684\u5404\u79cd\u4e0d\u786e\u5b9a\u6027\uff0c\u4e3a\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u7684\u591a\u8f66\u8f86\u4ea4\u4e92\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.11119", "categories": ["cs.AI", "cs.AR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.11119", "abs": "https://arxiv.org/abs/2510.11119", "authors": ["Andrea Marinoni", "Sai Shivareddy", "Pietro Lio'", "Weisi Lin", "Erik Cambria", "Clare Grey"], "title": "Improving AI Efficiency in Data Centres by Power Dynamic Response", "comment": null, "summary": "The steady growth of artificial intelligence (AI) has accelerated in the\nrecent years, facilitated by the development of sophisticated models such as\nlarge language models and foundation models. Ensuring robust and reliable power\ninfrastructures is fundamental to take advantage of the full potential of AI.\nHowever, AI data centres are extremely hungry for power, putting the problem of\ntheir power management in the spotlight, especially with respect to their\nimpact on environment and sustainable development. In this work, we investigate\nthe capacity and limits of solutions based on an innovative approach for the\npower management of AI data centres, i.e., making part of the input power as\ndynamic as the power used for data-computing functions. The performance of\npassive and active devices are quantified and compared in terms of\ncomputational gain, energy efficiency, reduction of capital expenditure, and\nmanagement costs by analysing power trends from multiple data platforms\nworldwide. This strategy, which identifies a paradigm shift in the AI data\ncentre power management, has the potential to strongly improve the\nsustainability of AI hyperscalers, enhancing their footprint on environmental,\nfinancial, and societal fields.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684AI\u6570\u636e\u4e2d\u5fc3\u7535\u6e90\u7ba1\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u90e8\u5206\u8f93\u5165\u7535\u6e90\u52a8\u6001\u5316\u6765\u5339\u914d\u6570\u636e\u8ba1\u7b97\u529f\u80fd\u7684\u52a8\u6001\u529f\u8017\uff0c\u4ece\u800c\u63d0\u9ad8AI\u6570\u636e\u4e2d\u5fc3\u7684\u53ef\u6301\u7eed\u6027\u3002", "motivation": "AI\u6570\u636e\u4e2d\u5fc3\u7684\u5de8\u5927\u529f\u8017\u5bf9\u73af\u5883\u548c\u53ef\u6301\u7eed\u53d1\u5c55\u9020\u6210\u538b\u529b\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u7535\u6e90\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u521b\u65b0\u65b9\u6cd5\u4f7f\u90e8\u5206\u8f93\u5165\u7535\u6e90\u52a8\u6001\u5316\uff0c\u91cf\u5316\u6bd4\u8f83\u88ab\u52a8\u548c\u4e3b\u52a8\u8bbe\u5907\u5728\u8ba1\u7b97\u589e\u76ca\u3001\u80fd\u6548\u3001\u8d44\u672c\u652f\u51fa\u548c\u7ba1\u7406\u6210\u672c\u65b9\u9762\u7684\u6027\u80fd\u3002", "result": "\u901a\u8fc7\u5206\u6790\u5168\u7403\u591a\u4e2a\u6570\u636e\u5e73\u53f0\u7684\u529f\u8017\u8d8b\u52bf\uff0c\u8be5\u7b56\u7565\u5728\u73af\u5883\u3001\u8d22\u52a1\u548c\u793e\u4f1a\u9886\u57df\u663e\u8457\u63d0\u5347\u4e86AI\u8d85\u5927\u89c4\u6a21\u6570\u636e\u4e2d\u5fc3\u7684\u53ef\u6301\u7eed\u6027\u3002", "conclusion": "\u8fd9\u79cd\u7535\u6e90\u7ba1\u7406\u8303\u5f0f\u8f6c\u53d8\u6709\u6f5c\u529b\u5927\u5e45\u6539\u5584AI\u6570\u636e\u4e2d\u5fc3\u7684\u53ef\u6301\u7eed\u6027\uff0c\u589e\u5f3a\u5176\u5728\u73af\u5883\u3001\u8d22\u52a1\u548c\u793e\u4f1a\u65b9\u9762\u7684\u5f71\u54cd\u529b\u3002"}}
{"id": "2510.11143", "categories": ["cs.AI", "cs.HC", "68U35, 62P30", "I.2.2"], "pdf": "https://arxiv.org/pdf/2510.11143", "abs": "https://arxiv.org/abs/2510.11143", "authors": ["Chuke Chen", "Biao Luo", "Nan Li", "Boxiang Wang", "Hang Yang", "Jing Guo", "Ming Xu"], "title": "Spec-Driven AI for Science: The ARIA Framework for Automated and Reproducible Data Analysis", "comment": "19 pages,5 figures", "summary": "The rapid expansion of scientific data has widened the gap between analytical\ncapability and research intent. Existing AI-based analysis tools, ranging from\nAutoML frameworks to agentic research assistants, either favor automation over\ntransparency or depend on manual scripting that hinders scalability and\nreproducibility. We present ARIA (Automated Research Intelligence Assistant), a\nspec-driven, human-in-the-loop framework for automated and interpretable data\nanalysis. ARIA integrates six interoperable layers, namely Command, Context,\nCode, Data, Orchestration, and AI Module, within a document-centric workflow\nthat unifies human reasoning and machine execution. Through natural-language\nspecifications, researchers define analytical goals while ARIA autonomously\ngenerates executable code, validates computations, and produces transparent\ndocumentation. Beyond achieving high predictive accuracy, ARIA can rapidly\nidentify optimal feature sets and select suitable models, minimizing redundant\ntuning and repetitive experimentation. In the Boston Housing case, ARIA\ndiscovered 25 key features and determined XGBoost as the best performing model\n(R square = 0.93) with minimal overfitting. Evaluations across heterogeneous\ndomains demonstrate ARIA's strong performance, interpretability, and efficiency\ncompared with state-of-the-art systems. By combining AI for research and AI for\nscience principles within a spec-driven architecture, ARIA establishes a new\nparadigm for transparent, collaborative, and reproducible scientific discovery.", "AI": {"tldr": "ARIA\u662f\u4e00\u4e2a\u57fa\u4e8e\u89c4\u8303\u9a71\u52a8\u3001\u4eba\u673a\u534f\u4f5c\u7684\u81ea\u52a8\u5316\u53ef\u89e3\u91ca\u6570\u636e\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u5b9a\u4e49\u5206\u6790\u76ee\u6807\uff0c\u81ea\u52a8\u751f\u6210\u53ef\u6267\u884c\u4ee3\u7801\u5e76\u9a8c\u8bc1\u8ba1\u7b97\uff0c\u5b9e\u73b0\u900f\u660e\u6587\u6863\u5316\u3002", "motivation": "\u79d1\u5b66\u6570\u636e\u7684\u5feb\u901f\u589e\u957f\u5bfc\u81f4\u5206\u6790\u80fd\u529b\u4e0e\u7814\u7a76\u610f\u56fe\u4e4b\u95f4\u5b58\u5728\u5dee\u8ddd\uff0c\u73b0\u6709AI\u5206\u6790\u5de5\u5177\u8981\u4e48\u504f\u5411\u81ea\u52a8\u5316\u800c\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u8981\u4e48\u4f9d\u8d56\u624b\u52a8\u811a\u672c\u963b\u788d\u53ef\u6269\u5c55\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002", "method": "ARIA\u96c6\u6210\u4e86\u516d\u4e2a\u4e92\u64cd\u4f5c\u5c42\uff08\u547d\u4ee4\u3001\u4e0a\u4e0b\u6587\u3001\u4ee3\u7801\u3001\u6570\u636e\u3001\u7f16\u6392\u548cAI\u6a21\u5757\uff09\uff0c\u91c7\u7528\u6587\u6863\u4e2d\u5fc3\u5316\u5de5\u4f5c\u6d41\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u8ba9\u7814\u7a76\u4eba\u5458\u5b9a\u4e49\u5206\u6790\u76ee\u6807\uff0c\u7cfb\u7edf\u81ea\u52a8\u751f\u6210\u4ee3\u7801\u3001\u9a8c\u8bc1\u8ba1\u7b97\u5e76\u751f\u6210\u900f\u660e\u6587\u6863\u3002", "result": "\u5728\u6ce2\u58eb\u987f\u623f\u4ef7\u6848\u4f8b\u4e2d\uff0cARIA\u53d1\u73b0\u4e8625\u4e2a\u5173\u952e\u7279\u5f81\u5e76\u786e\u5b9aXGBoost\u4e3a\u6700\u4f73\u6a21\u578b\uff08R\u5e73\u65b9=0.93\uff09\uff0c\u8fc7\u62df\u5408\u6700\u5c0f\u3002\u8de8\u9886\u57df\u8bc4\u4f30\u663e\u793aARIA\u5728\u6027\u80fd\u3001\u53ef\u89e3\u91ca\u6027\u548c\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\u3002", "conclusion": "ARIA\u901a\u8fc7\u5c06AI\u7814\u7a76\u4e0eAI\u79d1\u5b66\u539f\u5219\u7ed3\u5408\u5728\u89c4\u8303\u9a71\u52a8\u67b6\u6784\u4e2d\uff0c\u4e3a\u900f\u660e\u3001\u534f\u4f5c\u548c\u53ef\u91cd\u590d\u7684\u79d1\u5b66\u53d1\u73b0\u5efa\u7acb\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2510.11083", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11083", "abs": "https://arxiv.org/abs/2510.11083", "authors": ["Tianyi Tan", "Yinan Zheng", "Ruiming Liang", "Zexu Wang", "Kexin Zheng", "Jinliang Zheng", "Jianxiong Li", "Xianyuan Zhan", "Jingjing Liu"], "title": "Flow Matching-Based Autonomous Driving Planning with Advanced Interactive Behavior Modeling", "comment": "26 pages, 6 figures. Accepted at NeurIPS 2025", "summary": "Modeling interactive driving behaviors in complex scenarios remains a\nfundamental challenge for autonomous driving planning. Learning-based\napproaches attempt to address this challenge with advanced generative models,\nremoving the dependency on over-engineered architectures for representation\nfusion. However, brute-force implementation by simply stacking transformer\nblocks lacks a dedicated mechanism for modeling interactive behaviors that are\ncommon in real driving scenarios. The scarcity of interactive driving data\nfurther exacerbates this problem, leaving conventional imitation learning\nmethods ill-equipped to capture high-value interactive behaviors. We propose\nFlow Planner, which tackles these problems through coordinated innovations in\ndata modeling, model architecture, and learning scheme. Specifically, we first\nintroduce fine-grained trajectory tokenization, which decomposes the trajectory\ninto overlapping segments to decrease the complexity of whole trajectory\nmodeling. With a sophisticatedly designed architecture, we achieve efficient\ntemporal and spatial fusion of planning and scene information, to better\ncapture interactive behaviors. In addition, the framework incorporates flow\nmatching with classifier-free guidance for multi-modal behavior generation,\nwhich dynamically reweights agent interactions during inference to maintain\ncoherent response strategies, providing a critical boost for interactive\nscenario understanding. Experimental results on the large-scale nuPlan dataset\nand challenging interactive interPlan dataset demonstrate that Flow Planner\nachieves state-of-the-art performance among learning-based approaches while\neffectively modeling interactive behaviors in complex driving scenarios.", "AI": {"tldr": "Flow Planner\u662f\u4e00\u4e2a\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u89c4\u5212\u7684\u521b\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u8f68\u8ff9\u6807\u8bb0\u5316\u3001\u65f6\u7a7a\u878d\u5408\u67b6\u6784\u548c\u6d41\u5339\u914d\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742\u573a\u666f\u4e2d\u4ea4\u4e92\u5f0f\u9a7e\u9a76\u884c\u4e3a\u7684\u5efa\u6a21\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u7684\u5b66\u4e60\u578b\u65b9\u6cd5\u867d\u7136\u4f7f\u7528\u751f\u6210\u6a21\u578b\u51cf\u5c11\u5bf9\u590d\u6742\u67b6\u6784\u7684\u4f9d\u8d56\uff0c\u4f46\u7b80\u5355\u5806\u53e0Transformer\u5757\u7f3a\u4e4f\u4e13\u95e8\u7684\u4ea4\u4e92\u884c\u4e3a\u5efa\u6a21\u673a\u5236\uff0c\u4e14\u4ea4\u4e92\u9a7e\u9a76\u6570\u636e\u7a00\u7f3a\u5bfc\u81f4\u4f20\u7edf\u6a21\u4eff\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u9ad8\u4ef7\u503c\u4ea4\u4e92\u884c\u4e3a\u3002", "method": "1. \u7ec6\u7c92\u5ea6\u8f68\u8ff9\u6807\u8bb0\u5316\uff1a\u5c06\u8f68\u8ff9\u5206\u89e3\u4e3a\u91cd\u53e0\u6bb5\u4ee5\u964d\u4f4e\u5efa\u6a21\u590d\u6742\u5ea6\uff1b2. \u7cbe\u5fc3\u8bbe\u8ba1\u7684\u67b6\u6784\uff1a\u5b9e\u73b0\u89c4\u5212\u4e0e\u573a\u666f\u4fe1\u606f\u7684\u65f6\u7a7a\u9ad8\u6548\u878d\u5408\uff1b3. \u6d41\u5339\u914d\u4e0e\u65e0\u5206\u7c7b\u5668\u5f15\u5bfc\uff1a\u7528\u4e8e\u591a\u6a21\u6001\u884c\u4e3a\u751f\u6210\uff0c\u5728\u63a8\u7406\u65f6\u52a8\u6001\u91cd\u52a0\u6743\u667a\u80fd\u4f53\u4ea4\u4e92\u3002", "result": "\u5728\u5927\u578bnuPlan\u6570\u636e\u96c6\u548c\u5177\u6709\u6311\u6218\u6027\u7684interPlan\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFlow Planner\u5728\u5b66\u4e60\u578b\u65b9\u6cd5\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u80fd\u6709\u6548\u5efa\u6a21\u590d\u6742\u9a7e\u9a76\u573a\u666f\u4e2d\u7684\u4ea4\u4e92\u884c\u4e3a\u3002", "conclusion": "Flow Planner\u901a\u8fc7\u6570\u636e\u5efa\u6a21\u3001\u6a21\u578b\u67b6\u6784\u548c\u5b66\u4e60\u65b9\u6848\u7684\u534f\u540c\u521b\u65b0\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u81ea\u52a8\u9a7e\u9a76\u89c4\u5212\u4e2d\u4ea4\u4e92\u884c\u4e3a\u5efa\u6a21\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u590d\u6742\u573a\u666f\u7406\u89e3\u63d0\u4f9b\u4e86\u91cd\u8981\u63d0\u5347\u3002"}}
{"id": "2510.11144", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.11144", "abs": "https://arxiv.org/abs/2510.11144", "authors": ["Gautier Dagan", "Frank Keller", "Alex Lascarides"], "title": "$How^{2}$: How to learn from procedural How-to questions", "comment": null, "summary": "An agent facing a planning problem can use answers to how-to questions to\nreduce uncertainty and fill knowledge gaps, helping it solve both current and\nfuture tasks. However, their open ended nature, where valid answers to \"How do\nI X?\" range from executable actions to high-level descriptions of X's\nsub-goals, makes them challenging for AI agents to ask, and for AI experts to\nanswer, in ways that support efficient planning. We introduce $How^{2}$, a\nmemory agent framework that enables agents to ask how-to questions, store the\nanswers, and reuse them for lifelong learning in interactive environments. We\nevaluate our approach in Plancraft, a Minecraft crafting environment, where\nagents must complete an assembly task by manipulating inventory items. Using\nteacher models that answer at varying levels of abstraction, from executable\naction sequences to high-level subgoal descriptions, we show that lifelong\nlearning agents benefit most from answers that are abstracted and decoupled\nfrom the current state. $How^{2}$ offers a way for LLM-based agents to improve\ntheir planning capabilities over time by asking questions in interactive\nenvironments.", "AI": {"tldr": "\u63d0\u51fa\u4e86$How^{2}$\u6846\u67b6\uff0c\u4f7fAI\u4ee3\u7406\u80fd\u591f\u63d0\u95ee\u3001\u5b58\u50a8\u548c\u91cd\u7528how-to\u95ee\u9898\u7b54\u6848\uff0c\u5728\u4ea4\u4e92\u73af\u5883\u4e2d\u5b9e\u73b0\u7ec8\u8eab\u5b66\u4e60\uff0c\u63d0\u9ad8\u89c4\u5212\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3AI\u4ee3\u7406\u5728\u89c4\u5212\u95ee\u9898\u4e2d\u9762\u4e34\u7684\u6311\u6218\uff1ahow-to\u95ee\u9898\u7684\u5f00\u653e\u6027\u4f7f\u5f97AI\u4ee3\u7406\u96be\u4ee5\u6709\u6548\u63d0\u95ee\uff0cAI\u4e13\u5bb6\u4e5f\u96be\u4ee5\u63d0\u4f9b\u652f\u6301\u9ad8\u6548\u89c4\u5212\u7684\u7b54\u6848\u3002", "method": "\u5f15\u5165$How^{2}$\u8bb0\u5fc6\u4ee3\u7406\u6846\u67b6\uff0c\u5728Minecraft\u5236\u4f5c\u73af\u5883\u4e2d\u8bc4\u4f30\uff0c\u4f7f\u7528\u4e0d\u540c\u62bd\u8c61\u5c42\u6b21\u7684\u6559\u5e08\u6a21\u578b\u56de\u7b54\u95ee\u9898\uff08\u4ece\u53ef\u6267\u884c\u52a8\u4f5c\u5e8f\u5217\u5230\u9ad8\u7ea7\u5b50\u76ee\u6807\u63cf\u8ff0\uff09\u3002", "result": "\u7ec8\u8eab\u5b66\u4e60\u4ee3\u7406\u4ece\u62bd\u8c61\u5316\u4e14\u4e0e\u5f53\u524d\u72b6\u6001\u89e3\u8026\u7684\u7b54\u6848\u4e2d\u83b7\u76ca\u6700\u5927\u3002", "conclusion": "$How^{2}$\u4e3a\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u8fc7\u4ea4\u4e92\u73af\u5883\u63d0\u95ee\u6765\u6301\u7eed\u63d0\u5347\u89c4\u5212\u80fd\u529b\u7684\u65b9\u6cd5\u3002"}}
{"id": "2510.11094", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.11094", "abs": "https://arxiv.org/abs/2510.11094", "authors": ["Junxiang Wang", "Han Zhang", "Zehao Wang", "Huaiyuan Chen", "Pu Wang", "Weidong Chen"], "title": "Design and Koopman Model Predictive Control of A Soft Exoskeleton Based on Origami-Inspired Pneumatic Actuator for Knee Rehabilitation", "comment": null, "summary": "Effective rehabilitation methods are essential for the recovery of lower limb\ndysfunction caused by stroke. Nowadays, robotic exoskeletons have shown great\npotentials in rehabilitation. Nevertheless, traditional rigid exoskeletons are\nusually heavy and need a lot of work to help the patients to put them on.\nMoreover, it also requires extra compliance control to guarantee the safety. In\ncontrast, soft exoskeletons are easy and comfortable to wear and have intrinsic\ncompliance, but their complex nonlinear human-robot interaction dynamics would\npose significant challenges for control. In this work, based on the pneumatic\nactuators inspired by origami, we design a rehabilitation exoskeleton for knee\nthat is easy and comfortable to wear. To guarantee the control performance and\nenable a nice human-robot interaction, we first use Deep Koopman Network to\nmodel the human-robot interaction dynamics. In particular, by viewing the\nelectromyography (EMG) signals and the duty cycle of the PWM wave that controls\nthe pneumatic robot's valves and pump as the inputs, the linear Koopman model\naccurately captures the complex human-robot interaction dynamics. Next, based\non the obtained Koopman model, we further use Model Predictive Control (MPC) to\ncontrol the soft robot and help the user to do rehabilitation training in\nreal-time. The goal of the rehabilitation training is to track a given\nreference signal shown on the screen. Experiments show that by integrating the\nEMG signals into the Koopman model, we have improved the model accuracy to\ngreat extent. In addition, a personalized Koopman model trained from the\nindividual's own data performs better than the non-personalized model.\nConsequently, our control framework outperforms the traditional PID control in\nboth passive and active training modes. Hence the proposed method provides a\nnew control framework for soft rehabilitation robots.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6298\u7eb8\u542f\u53d1\u7684\u6c14\u52a8\u6267\u884c\u5668\u8f6f\u5916\u9aa8\u9abc\u819d\u5173\u8282\u5eb7\u590d\u7cfb\u7edf\uff0c\u4f7f\u7528\u6df1\u5ea6Koopman\u7f51\u7edc\u5efa\u6a21\u4eba\u673a\u4ea4\u4e92\u52a8\u529b\u5b66\uff0c\u5e76\u7ed3\u5408\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5b9e\u73b0\u5b9e\u65f6\u5eb7\u590d\u8bad\u7ec3\u3002", "motivation": "\u4f20\u7edf\u521a\u6027\u5916\u9aa8\u9abc\u7b28\u91cd\u4e14\u7a7f\u6234\u4e0d\u4fbf\uff0c\u9700\u8981\u989d\u5916\u5408\u89c4\u63a7\u5236\u4fdd\u8bc1\u5b89\u5168\uff1b\u8f6f\u5916\u9aa8\u9abc\u867d\u7136\u7a7f\u6234\u8212\u9002\u4e14\u5177\u6709\u5185\u5728\u5408\u89c4\u6027\uff0c\u4f46\u5176\u590d\u6742\u7684\u975e\u7ebf\u6027\u4eba\u673a\u4ea4\u4e92\u52a8\u529b\u5b66\u7ed9\u63a7\u5236\u5e26\u6765\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u6298\u7eb8\u542f\u53d1\u7684\u6c14\u52a8\u6267\u884c\u5668\u8f6f\u5916\u9aa8\u9abc\uff0c\u4f7f\u7528\u6df1\u5ea6Koopman\u7f51\u7edc\u5efa\u6a21\u4eba\u673a\u4ea4\u4e92\u52a8\u529b\u5b66\uff08\u8f93\u5165\u4e3a\u808c\u7535\u4fe1\u53f7\u548cPWM\u5360\u7a7a\u6bd4\uff09\uff0c\u7136\u540e\u57fa\u4e8eKoopman\u6a21\u578b\u91c7\u7528\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u8fdb\u884c\u5b9e\u65f6\u63a7\u5236\u3002", "result": "\u96c6\u6210\u808c\u7535\u4fe1\u53f7\u7684Koopman\u6a21\u578b\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u7cbe\u5ea6\uff0c\u4e2a\u6027\u5316\u6a21\u578b\u4f18\u4e8e\u975e\u4e2a\u6027\u5316\u6a21\u578b\uff0c\u63a7\u5236\u6846\u67b6\u5728\u88ab\u52a8\u548c\u4e3b\u52a8\u8bad\u7ec3\u6a21\u5f0f\u4e0b\u5747\u4f18\u4e8e\u4f20\u7edfPID\u63a7\u5236\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8f6f\u5eb7\u590d\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u63a7\u5236\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u590d\u6742\u7684\u4eba\u673a\u4ea4\u4e92\u52a8\u529b\u5b66\u95ee\u9898\u3002"}}
{"id": "2510.11194", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11194", "abs": "https://arxiv.org/abs/2510.11194", "authors": ["Peiming Li", "Zhiyuan Hu", "Yang Tang", "Shiyu Li", "Xi Chen"], "title": "Aligning Deep Implicit Preferences by Learning to Reason Defensively", "comment": null, "summary": "Personalized alignment is crucial for enabling Large Language Models (LLMs)\nto engage effectively in user-centric interactions. However, current methods\nface a dual challenge: they fail to infer users' deep implicit preferences\n(including unstated goals, semantic context and risk tolerances), and they lack\nthe defensive reasoning required to navigate real-world ambiguity. This\ncognitive gap leads to responses that are superficial, brittle and\nshort-sighted. To address this, we propose Critique-Driven Reasoning Alignment\n(CDRA), which reframes alignment from a scalar reward-matching task into a\nstructured reasoning process. First, to bridge the preference inference gap, we\nintroduce the DeepPref benchmark. This dataset, comprising 3000\npreference-query pairs across 20 topics, is curated by simulating a\nmulti-faceted cognitive council that produces critique-annotated reasoning\nchains to deconstruct query semantics and reveal latent risks. Second, to\ninstill defensive reasoning, we introduce the Personalized Generative Process\nReward Model (Pers-GenPRM), which frames reward modeling as a personalized\nreasoning task. It generates a critique chain to evaluate a response's\nalignment with user preferences before outputting a final score based on this\nrationale. Ultimately, this interpretable, structured reward signal guides\npolicy model through Critique-Driven Policy Alignment, a process-level online\nreinforcement learning algorithm integrating both numerical and natural\nlanguage feedback. Experiments demonstrate that CDRA excels at discovering and\naligning with users' true preferences while executing robust reasoning. Our\ncode and dataset are available at https://github.com/Zephyrian-Hugh/Deep-pref.", "AI": {"tldr": "\u63d0\u51fa\u4e86Critique-Driven Reasoning Alignment (CDRA)\u65b9\u6cd5\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u9f50\u95ee\u9898\u4ece\u6807\u91cf\u5956\u52b1\u5339\u914d\u91cd\u6784\u4e3a\u7ed3\u6784\u5316\u63a8\u7406\u8fc7\u7a0b\uff0c\u901a\u8fc7\u6279\u5224\u6027\u63a8\u7406\u94fe\u6765\u63a8\u65ad\u7528\u6237\u6df1\u5c42\u504f\u597d\u5e76\u589e\u5f3a\u9632\u5fa1\u6027\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u65e0\u6cd5\u63a8\u65ad\u7528\u6237\u7684\u6df1\u5c42\u9690\u542b\u504f\u597d\uff08\u5305\u62ec\u672a\u9648\u8ff0\u7684\u76ee\u6807\u3001\u8bed\u4e49\u4e0a\u4e0b\u6587\u548c\u98ce\u9669\u5bb9\u5fcd\u5ea6\uff09\uff0c\u5e76\u4e14\u7f3a\u4e4f\u5e94\u5bf9\u73b0\u5b9e\u4e16\u754c\u6a21\u7cca\u6027\u7684\u9632\u5fa1\u6027\u63a8\u7406\u80fd\u529b\uff0c\u5bfc\u81f4\u54cd\u5e94\u80a4\u6d45\u3001\u8106\u5f31\u548c\u77ed\u89c6\u3002", "method": "1. \u5f15\u5165DeepPref\u57fa\u51c6\u6570\u636e\u96c6\uff083000\u4e2a\u504f\u597d-\u67e5\u8be2\u5bf9\uff0c\u6db5\u76d620\u4e2a\u4e3b\u9898\uff09\uff1b2. \u63d0\u51fa\u4e2a\u6027\u5316\u751f\u6210\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b(Pers-GenPRM)\uff0c\u5c06\u5956\u52b1\u5efa\u6a21\u6784\u5efa\u4e3a\u4e2a\u6027\u5316\u63a8\u7406\u4efb\u52a1\uff1b3. \u901a\u8fc7\u6279\u5224\u9a71\u52a8\u7b56\u7565\u5bf9\u9f50\u8fdb\u884c\u8fc7\u7a0b\u7ea7\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u8868\u660eCDRA\u5728\u53d1\u73b0\u548c\u9002\u5e94\u7528\u6237\u771f\u5b9e\u504f\u597d\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u540c\u65f6\u6267\u884c\u7a33\u5065\u7684\u63a8\u7406\u3002", "conclusion": "CDRA\u901a\u8fc7\u7ed3\u6784\u5316\u63a8\u7406\u8fc7\u7a0b\u6709\u6548\u89e3\u51b3\u4e86\u7528\u6237\u6df1\u5c42\u504f\u597d\u63a8\u65ad\u548c\u9632\u5fa1\u6027\u63a8\u7406\u7684\u6311\u6218\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e2a\u6027\u5316\u5bf9\u9f50\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2510.11103", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11103", "abs": "https://arxiv.org/abs/2510.11103", "authors": ["Martin Schuck", "Sherif Samy", "Angela P. Schoellig"], "title": "A Primer on SO(3) Action Representations in Deep Reinforcement Learning", "comment": null, "summary": "Many robotic control tasks require policies to act on orientations, yet the\ngeometry of SO(3) makes this nontrivial. Because SO(3) admits no global,\nsmooth, minimal parameterization, common representations such as Euler angles,\nquaternions, rotation matrices, and Lie algebra coordinates introduce distinct\nconstraints and failure modes. While these trade-offs are well studied for\nsupervised learning, their implications for actions in reinforcement learning\nremain unclear. We systematically evaluate SO(3) action representations across\nthree standard continuous control algorithms, PPO, SAC, and TD3, under dense\nand sparse rewards. We compare how representations shape exploration, interact\nwith entropy regularization, and affect training stability through empirical\nstudies and analyze the implications of different projections for obtaining\nvalid rotations from Euclidean network outputs. Across a suite of robotics\nbenchmarks, we quantify the practical impact of these choices and distill\nsimple, implementation-ready guidelines for selecting and using rotation\nactions. Our results highlight that representation-induced geometry strongly\ninfluences exploration and optimization and show that representing actions as\ntangent vectors in the local frame yields the most reliable results across\nalgorithms.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86SO(3)\u65cb\u8f6c\u52a8\u4f5c\u8868\u793a\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u8868\u73b0\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u8868\u793a\u65b9\u6cd5\u5bf9\u63a2\u7d22\u3001\u71b5\u6b63\u5219\u5316\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u9009\u62e9\u6307\u5357\u3002", "motivation": "\u673a\u5668\u4eba\u63a7\u5236\u4efb\u52a1\u9700\u8981\u5904\u7406\u65b9\u5411\u52a8\u4f5c\uff0c\u4f46SO(3)\u7684\u51e0\u4f55\u7279\u6027\u4f7f\u5f97\u8fd9\u53d8\u5f97\u590d\u6742\u3002\u73b0\u6709\u7684\u8868\u793a\u65b9\u6cd5\uff08\u6b27\u62c9\u89d2\u3001\u56db\u5143\u6570\u3001\u65cb\u8f6c\u77e9\u9635\u7b49\uff09\u5404\u6709\u7ea6\u675f\u548c\u5931\u8d25\u6a21\u5f0f\uff0c\u4f46\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5f71\u54cd\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u5728\u4e09\u79cd\u6807\u51c6\u8fde\u7eed\u63a7\u5236\u7b97\u6cd5\uff08PPO\u3001SAC\u3001TD3\uff09\u4e0b\uff0c\u7cfb\u7edf\u8bc4\u4f30SO(3)\u52a8\u4f5c\u8868\u793a\uff0c\u6bd4\u8f83\u4e0d\u540c\u8868\u793a\u5982\u4f55\u5f71\u54cd\u63a2\u7d22\u3001\u4e0e\u71b5\u6b63\u5219\u5316\u7684\u4ea4\u4e92\u4ee5\u53ca\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u5e76\u901a\u8fc7\u7ecf\u9a8c\u7814\u7a76\u5206\u6790\u4e0d\u540c\u6295\u5f71\u65b9\u6cd5\u5bf9\u83b7\u5f97\u6709\u6548\u65cb\u8f6c\u7684\u5f71\u54cd\u3002", "result": "\u5728\u673a\u5668\u4eba\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u4e2d\u91cf\u5316\u4e86\u8fd9\u4e9b\u9009\u62e9\u7684\u5b9e\u9645\u5f71\u54cd\uff0c\u53d1\u73b0\u8868\u793a\u5f15\u5165\u7684\u51e0\u4f55\u7279\u6027\u5f3a\u70c8\u5f71\u54cd\u63a2\u7d22\u548c\u4f18\u5316\uff0c\u5c06\u52a8\u4f5c\u8868\u793a\u4e3a\u5c40\u90e8\u5750\u6807\u7cfb\u4e2d\u7684\u5207\u5411\u91cf\u5728\u6240\u6709\u7b97\u6cd5\u4e2d\u4ea7\u751f\u6700\u53ef\u9760\u7684\u7ed3\u679c\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u7b80\u5355\u3001\u53ef\u76f4\u63a5\u5b9e\u65bd\u7684\u65cb\u8f6c\u52a8\u4f5c\u9009\u62e9\u548c\u4f7f\u7528\u6307\u5357\uff0c\u5f3a\u8c03\u4e86\u8868\u793a\u51e0\u4f55\u5bf9\u5f3a\u5316\u5b66\u4e60\u6027\u80fd\u7684\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2510.11235", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11235", "abs": "https://arxiv.org/abs/2510.11235", "authors": ["Leonard Dung", "Florian Mai"], "title": "AI Alignment Strategies from a Risk Perspective: Independent Safety Mechanisms or Shared Failures?", "comment": "under review", "summary": "AI alignment research aims to develop techniques to ensure that AI systems do\nnot cause harm. However, every alignment technique has failure modes, which are\nconditions in which there is a non-negligible chance that the technique fails\nto provide safety. As a strategy for risk mitigation, the AI safety community\nhas increasingly adopted a defense-in-depth framework: Conceding that there is\nno single technique which guarantees safety, defense-in-depth consists in\nhaving multiple redundant protections against safety failure, such that safety\ncan be maintained even if some protections fail. However, the success of\ndefense-in-depth depends on how (un)correlated failure modes are across\nalignment techniques. For example, if all techniques had the exact same failure\nmodes, the defense-in-depth approach would provide no additional protection at\nall. In this paper, we analyze 7 representative alignment techniques and 7\nfailure modes to understand the extent to which they overlap. We then discuss\nour results' implications for understanding the current level of risk and how\nto prioritize AI alignment research in the future.", "AI": {"tldr": "\u5206\u67907\u79cd\u4ee3\u8868\u6027AI\u5bf9\u9f50\u6280\u672f\u548c7\u79cd\u5931\u6548\u6a21\u5f0f\u7684\u91cd\u53e0\u7a0b\u5ea6\uff0c\u63a2\u8ba8\u5176\u5bf9\u6df1\u5ea6\u9632\u5fa1\u7b56\u7565\u6709\u6548\u6027\u7684\u5f71\u54cd", "motivation": "AI\u5bf9\u9f50\u6280\u672f\u90fd\u6709\u5931\u6548\u6a21\u5f0f\uff0c\u6df1\u5ea6\u9632\u5fa1\u7b56\u7565\u4f9d\u8d56\u4e8e\u4e0d\u540c\u6280\u672f\u5931\u6548\u6a21\u5f0f\u7684\u4e0d\u76f8\u5173\u6027\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5b9e\u9645\u91cd\u53e0\u7a0b\u5ea6\u7684\u7cfb\u7edf\u6027\u5206\u6790", "method": "\u5206\u67907\u79cd\u4ee3\u8868\u6027\u5bf9\u9f50\u6280\u672f\u548c7\u79cd\u5931\u6548\u6a21\u5f0f\uff0c\u7814\u7a76\u5b83\u4eec\u4e4b\u95f4\u7684\u91cd\u53e0\u7a0b\u5ea6", "result": "\u53d1\u73b0\u4e0d\u540c\u5bf9\u9f50\u6280\u672f\u7684\u5931\u6548\u6a21\u5f0f\u5b58\u5728\u4e0d\u540c\u7a0b\u5ea6\u7684\u91cd\u53e0\uff0c\u5f71\u54cd\u6df1\u5ea6\u9632\u5fa1\u7b56\u7565\u7684\u6709\u6548\u6027", "conclusion": "\u9700\u8981\u66f4\u6df1\u5165\u5730\u7406\u89e3\u5bf9\u9f50\u6280\u672f\u5931\u6548\u6a21\u5f0f\u7684\u76f8\u5173\u6027\uff0c\u4ee5\u4f18\u5316\u6df1\u5ea6\u9632\u5fa1\u7b56\u7565\u548c\u6307\u5bfc\u672a\u6765AI\u5bf9\u9f50\u7814\u7a76\u4f18\u5148\u7ea7"}}
{"id": "2510.11258", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.11258", "abs": "https://arxiv.org/abs/2510.11258", "authors": ["Yuhui Fu", "Feiyang Xie", "Chaoyi Xu", "Jing Xiong", "Haoqi Yuan", "Zongqing Lu"], "title": "DemoHLM: From One Demonstration to Generalizable Humanoid Loco-Manipulation", "comment": null, "summary": "Loco-manipulation is a fundamental challenge for humanoid robots to achieve\nversatile interactions in human environments. Although recent studies have made\nsignificant progress in humanoid whole-body control, loco-manipulation remains\nunderexplored and often relies on hard-coded task definitions or costly\nreal-world data collection, which limits autonomy and generalization. We\npresent DemoHLM, a framework for humanoid loco-manipulation that enables\ngeneralizable loco-manipulation on a real humanoid robot from a single\ndemonstration in simulation. DemoHLM adopts a hierarchy that integrates a\nlow-level universal whole-body controller with high-level manipulation policies\nfor multiple tasks. The whole-body controller maps whole-body motion commands\nto joint torques and provides omnidirectional mobility for the humanoid robot.\nThe manipulation policies, learned in simulation via our data generation and\nimitation learning pipeline, command the whole-body controller with closed-loop\nvisual feedback to execute challenging loco-manipulation tasks. Experiments\nshow a positive correlation between the amount of synthetic data and policy\nperformance, underscoring the effectiveness of our data generation pipeline and\nthe data efficiency of our approach. Real-world experiments on a Unitree G1\nrobot equipped with an RGB-D camera validate the sim-to-real transferability of\nDemoHLM, demonstrating robust performance under spatial variations across ten\nloco-manipulation tasks.", "AI": {"tldr": "DemoHLM\u6846\u67b6\u901a\u8fc7\u5206\u5c42\u67b6\u6784\u5b9e\u73b0\u4eba\u5f62\u673a\u5668\u4eba\u7684\u79fb\u52a8\u64cd\u4f5c\uff0c\u7ed3\u5408\u5e95\u5c42\u5168\u8eab\u63a7\u5236\u5668\u548c\u57fa\u4e8e\u89c6\u89c9\u53cd\u9988\u7684\u9ad8\u5c42\u64cd\u4f5c\u7b56\u7565\uff0c\u4ec5\u9700\u4e00\u6b21\u4eff\u771f\u6f14\u793a\u5373\u53ef\u5728\u771f\u5b9e\u673a\u5668\u4eba\u4e0a\u5b8c\u6210\u901a\u7528\u79fb\u52a8\u64cd\u4f5c\u4efb\u52a1\u3002", "motivation": "\u89e3\u51b3\u4eba\u5f62\u673a\u5668\u4eba\u79fb\u52a8\u64cd\u4f5c\u4efb\u52a1\u4e2d\u4f9d\u8d56\u786c\u7f16\u7801\u5b9a\u4e49\u6216\u6602\u8d35\u771f\u5b9e\u6570\u636e\u6536\u96c6\u7684\u95ee\u9898\uff0c\u63d0\u5347\u81ea\u4e3b\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u91c7\u7528\u5206\u5c42\u67b6\u6784\uff1a\u5e95\u5c42\u901a\u7528\u5168\u8eab\u63a7\u5236\u5668\u63d0\u4f9b\u5168\u65b9\u4f4d\u79fb\u52a8\u80fd\u529b\uff0c\u9ad8\u5c42\u64cd\u4f5c\u7b56\u7565\u901a\u8fc7\u4eff\u771f\u6570\u636e\u751f\u6210\u548c\u6a21\u4eff\u5b66\u4e60\u83b7\u5f97\uff0c\u5229\u7528\u95ed\u73af\u89c6\u89c9\u53cd\u9988\u63a7\u5236\u5e95\u5c42\u63a7\u5236\u5668\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5408\u6210\u6570\u636e\u91cf\u4e0e\u7b56\u7565\u6027\u80fd\u6b63\u76f8\u5173\uff0c\u5728Unitree G1\u673a\u5668\u4eba\u4e0a\u6210\u529f\u9a8c\u8bc1\u4e8610\u4e2a\u79fb\u52a8\u64cd\u4f5c\u4efb\u52a1\u7684\u4eff\u771f\u5230\u771f\u5b9e\u8fc1\u79fb\u80fd\u529b\uff0c\u5728\u7a7a\u95f4\u53d8\u5316\u4e0b\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "DemoHLM\u6846\u67b6\u5b9e\u73b0\u4e86\u4ece\u5355\u6b21\u4eff\u771f\u6f14\u793a\u5230\u771f\u5b9e\u673a\u5668\u4eba\u7684\u901a\u7528\u79fb\u52a8\u64cd\u4f5c\uff0c\u8bc1\u660e\u4e86\u4eff\u771f\u6570\u636e\u751f\u6210\u548c\u5206\u5c42\u63a7\u5236\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.11281", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11281", "abs": "https://arxiv.org/abs/2510.11281", "authors": ["Deepeka Garg", "Sihan Zeng", "Annapoorani L. Narayanan", "Sumitra Ganesh", "Leo Ardon"], "title": "PADME: Procedure Aware DynaMic Execution", "comment": null, "summary": "Learning to autonomously execute long-horizon procedures from natural\nlanguage remains a core challenge for intelligent agents. Free-form\ninstructions such as recipes, scientific protocols, or business workflows\nencode rich procedural knowledge, but their variability and lack of structure\ncause agents driven by large language models (LLMs) to drift or fail during\nexecution. We introduce Procedure Aware DynaMic Execution (PADME), an agent\nframework that produces and exploits a graph-based representation of\nprocedures. Unlike prior work that relies on manual graph construction or\nunstructured reasoning, PADME autonomously transforms procedural text into\nexecutable graphs that capture task dependencies, decision points, and reusable\nsubroutines. Central to PADME is a two-phase methodology; Teach phase, which\nfocuses on systematic structuring, enrichment with executable logic of\nprocedures, followed by Execute phase, which enables dynamic execution in\nresponse to real-time inputs and environment feedback. This separation ensures\nquality assurance and scalability, allowing expert knowledge to be encoded once\nand reliably reused across varying contexts. The graph representation also\nprovides an inductive bias that reduces error accumulation in long-horizon\nreasoning, underscoring the importance of structured procedure modeling for\nreliable agent-driven automation. Empirically, PADME achieves state-of-the-art\nperformance on four diverse benchmarks, including ALFWorld and ScienceWorld.\nThese results demonstrate that agents equipped with graph-based procedure\nrepresentations offer a powerful intermediate abstraction for robust and\ngeneralizable execution.", "AI": {"tldr": "PADME\u662f\u4e00\u4e2a\u667a\u80fd\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u81ea\u7136\u8bed\u8a00\u7a0b\u5e8f\u6587\u672c\u8f6c\u6362\u4e3a\u56fe\u7ed3\u6784\u8868\u793a\uff0c\u5b9e\u73b0\u957f\u65f6\u7a0b\u7a0b\u5e8f\u6267\u884c\u7684\u81ea\u4e3b\u5b66\u4e60\u548c\u52a8\u6001\u6267\u884c\u3002", "motivation": "\u89e3\u51b3\u667a\u80fd\u4ee3\u7406\u4ece\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\uff08\u5982\u98df\u8c31\u3001\u79d1\u5b66\u534f\u8bae\u7b49\uff09\u81ea\u4e3b\u6267\u884c\u957f\u65f6\u7a0b\u7a0b\u5e8f\u65f6\u7684\u6f02\u79fb\u548c\u5931\u8d25\u95ee\u9898\uff0c\u8fd9\u4e9b\u6307\u4ee4\u7684\u53d8\u5f02\u6027\u5927\u4e14\u7f3a\u4e4f\u7ed3\u6784\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1aTeach\u9636\u6bb5\u5c06\u7a0b\u5e8f\u6587\u672c\u7cfb\u7edf\u6027\u5730\u7ed3\u6784\u5316\u5e76\u4e30\u5bcc\u53ef\u6267\u884c\u903b\u8f91\uff1bExecute\u9636\u6bb5\u6839\u636e\u5b9e\u65f6\u8f93\u5165\u548c\u73af\u5883\u53cd\u9988\u8fdb\u884c\u52a8\u6001\u6267\u884c\u3002\u4f7f\u7528\u56fe\u7ed3\u6784\u8868\u793a\u6355\u6349\u4efb\u52a1\u4f9d\u8d56\u5173\u7cfb\u3001\u51b3\u7b56\u70b9\u548c\u53ef\u91cd\u7528\u5b50\u7a0b\u5e8f\u3002", "result": "\u5728ALFWorld\u548cScienceWorld\u7b49\u56db\u4e2a\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u8bc1\u660e\u57fa\u4e8e\u56fe\u7684\u7a0b\u5e8f\u8868\u793a\u4e3a\u7a33\u5065\u548c\u53ef\u6cdb\u5316\u6267\u884c\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u4e2d\u95f4\u62bd\u8c61\u3002", "conclusion": "\u7ed3\u6784\u5316\u7a0b\u5e8f\u5efa\u6a21\u5bf9\u4e8e\u53ef\u9760\u7684\u4ee3\u7406\u9a71\u52a8\u81ea\u52a8\u5316\u81f3\u5173\u91cd\u8981\uff0c\u56fe\u8868\u793a\u63d0\u4f9b\u4e86\u51cf\u5c11\u957f\u65f6\u7a0b\u63a8\u7406\u4e2d\u9519\u8bef\u79ef\u7d2f\u7684\u5f52\u7eb3\u504f\u7f6e\u3002"}}
{"id": "2510.11306", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.11306", "abs": "https://arxiv.org/abs/2510.11306", "authors": ["Xiaobin Zhou", "Miao Wang", "Chengao Li", "Can Cui", "Ruibin Zhang", "Yongchao Wang", "Chao Xu", "Fei Gao"], "title": "Rotor-Failure-Aware Quadrotors Flight in Unknown Environments", "comment": null, "summary": "Rotor failures in quadrotors may result in high-speed rotation and vibration\ndue to rotor imbalance, which introduces significant challenges for autonomous\nflight in unknown environments. The mainstream approaches against rotor\nfailures rely on fault-tolerant control (FTC) and predefined trajectory\ntracking. To the best of our knowledge, online failure detection and diagnosis\n(FDD), trajectory planning, and FTC of the post-failure quadrotors in unknown\nand complex environments have not yet been achieved. This paper presents a\nrotor-failure-aware quadrotor navigation system designed to mitigate the\nimpacts of rotor imbalance. First, a composite FDD-based nonlinear model\npredictive controller (NMPC), incorporating motor dynamics, is designed to\nensure fast failure detection and flight stability. Second, a\nrotor-failure-aware planner is designed to leverage FDD results and\nspatial-temporal joint optimization, while a LiDAR-based quadrotor platform\nwith four anti-torque plates is designed to enable reliable perception under\nhigh-speed rotation. Lastly, extensive benchmarks against state-of-the-art\nmethods highlight the superior performance of the proposed approach in\naddressing rotor failures, including propeller unloading and motor stoppage.\nThe experimental results demonstrate, for the first time, that our approach\nenables autonomous quadrotor flight with rotor failures in challenging\nenvironments, including cluttered rooms and unknown forests.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f6c\u5b50\u6545\u969c\u611f\u77e5\u7684\u56db\u65cb\u7ffc\u5bfc\u822a\u7cfb\u7edf\uff0c\u901a\u8fc7\u5feb\u901f\u6545\u969c\u68c0\u6d4b\u4e0e\u8bca\u65ad\u3001\u65f6\u7a7a\u8054\u5408\u4f18\u5316\u7684\u8def\u5f84\u89c4\u5212\u4ee5\u53ca\u6297\u626d\u77e9\u5e73\u53f0\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u5728\u672a\u77e5\u590d\u6742\u73af\u5883\u4e2d\u8f6c\u5b50\u6545\u969c\u4e0b\u7684\u81ea\u4e3b\u98de\u884c\u3002", "motivation": "\u56db\u65cb\u7ffc\u8f6c\u5b50\u6545\u969c\u4f1a\u5bfc\u81f4\u9ad8\u901f\u65cb\u8f6c\u548c\u632f\u52a8\uff0c\u7ed9\u672a\u77e5\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u98de\u884c\u5e26\u6765\u91cd\u5927\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u5bb9\u9519\u63a7\u5236\u548c\u9884\u5b9a\u4e49\u8f68\u8ff9\u8ddf\u8e2a\uff0c\u5c1a\u672a\u5b9e\u73b0\u5728\u7ebf\u6545\u969c\u68c0\u6d4b\u8bca\u65ad\u3001\u8f68\u8ff9\u89c4\u5212\u548c\u5bb9\u9519\u63a7\u5236\u7684\u5b8c\u6574\u89e3\u51b3\u65b9\u6848\u3002", "method": "1. \u8bbe\u8ba1\u57fa\u4e8e\u6545\u969c\u68c0\u6d4b\u8bca\u65ad\u7684\u590d\u5408\u975e\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5668\uff0c\u5305\u542b\u7535\u673a\u52a8\u529b\u5b66\uff1b2. \u5f00\u53d1\u8f6c\u5b50\u6545\u969c\u611f\u77e5\u89c4\u5212\u5668\uff0c\u5229\u7528\u6545\u969c\u68c0\u6d4b\u7ed3\u679c\u8fdb\u884c\u65f6\u7a7a\u8054\u5408\u4f18\u5316\uff1b3. \u6784\u5efa\u914d\u5907\u56db\u4e2a\u6297\u626d\u77e9\u677f\u7684\u6fc0\u5149\u96f7\u8fbe\u56db\u65cb\u7ffc\u5e73\u53f0\uff0c\u786e\u4fdd\u9ad8\u901f\u65cb\u8f6c\u4e0b\u7684\u53ef\u9760\u611f\u77e5\u3002", "result": "\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u5904\u7406\u8f6c\u5b50\u6545\u969c\uff08\u5305\u62ec\u87ba\u65cb\u6868\u5378\u8f7d\u548c\u7535\u673a\u505c\u8f6c\uff09\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002\u5b9e\u9a8c\u9996\u6b21\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u5728\u6742\u4e71\u623f\u95f4\u548c\u672a\u77e5\u68ee\u6797\u7b49\u6311\u6218\u6027\u73af\u5883\u4e2d\u5b9e\u73b0\u8f6c\u5b50\u6545\u969c\u4e0b\u7684\u81ea\u4e3b\u56db\u65cb\u7ffc\u98de\u884c\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u5b9e\u73b0\u4e86\u5728\u672a\u77e5\u590d\u6742\u73af\u5883\u4e2d\u8f6c\u5b50\u6545\u969c\u4e0b\u7684\u5b8c\u6574\u81ea\u4e3b\u98de\u884c\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u96c6\u6210\u6545\u969c\u68c0\u6d4b\u8bca\u65ad\u3001\u5bb9\u9519\u63a7\u5236\u548c\u8def\u5f84\u89c4\u5212\uff0c\u4e3a\u56db\u65cb\u7ffc\u5728\u6545\u969c\u60c5\u51b5\u4e0b\u7684\u53ef\u9760\u8fd0\u884c\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2510.11290", "categories": ["cs.AI", "cs.HC", "I.2.6; J.4"], "pdf": "https://arxiv.org/pdf/2510.11290", "abs": "https://arxiv.org/abs/2510.11290", "authors": ["Sheng Jin", "Haoming Wang", "Zhiqi Gao", "Yongbo Yang", "Bao Chunjia", "Chengliang Wang"], "title": "Evolution in Simulation: AI-Agent School with Dual Memory for High-Fidelity Educational Dynamics", "comment": "9 pages, 7 figures, EMNLP conference", "summary": "Large language models (LLMs) based Agents are increasingly pivotal in\nsimulating and understanding complex human systems and interactions. We propose\nthe AI-Agent School (AAS) system, built around a self-evolving mechanism that\nleverages agents for simulating complex educational dynamics. Addressing the\nfragmented issues in teaching process modeling and the limitations of agents\nperformance in simulating diverse educational participants, AAS constructs the\nZero-Exp strategy, employs a continuous \"experience-reflection-optimization\"\ncycle, grounded in a dual memory base comprising experience and knowledge bases\nand incorporating short-term and long-term memory components. Through this\nmechanism, agents autonomously evolve via situated interactions within diverse\nsimulated school scenarios. This evolution enables agents to more accurately\nmodel the nuanced, multi-faceted teacher-student engagements and underlying\nlearning processes found in physical schools. Experiment confirms that AAS can\neffectively simulate intricate educational dynamics and is effective in\nfostering advanced agent cognitive abilities, providing a foundational stepping\nstone from the \"Era of Experience\" to the \"Era of Simulation\" by generating\nhigh-fidelity behavioral and interaction data.", "AI": {"tldr": "\u63d0\u51fa\u4e86AI-Agent School\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u8fdb\u5316\u673a\u5236\u6a21\u62df\u590d\u6742\u6559\u80b2\u52a8\u6001\uff0c\u91c7\u7528Zero-Exp\u7b56\u7565\u548c\"\u7ecf\u9a8c-\u53cd\u601d-\u4f18\u5316\"\u5faa\u73af\uff0c\u4f7f\u4ee3\u7406\u80fd\u591f\u5728\u6a21\u62df\u5b66\u6821\u573a\u666f\u4e2d\u81ea\u4e3b\u8fdb\u5316\uff0c\u51c6\u786e\u5efa\u6a21\u5e08\u751f\u4e92\u52a8\u548c\u5b66\u4e60\u8fc7\u7a0b\u3002", "motivation": "\u89e3\u51b3\u6559\u5b66\u6d41\u7a0b\u5efa\u6a21\u4e2d\u7684\u788e\u7247\u5316\u95ee\u9898\uff0c\u4ee5\u53ca\u4ee3\u7406\u5728\u6a21\u62df\u591a\u6837\u5316\u6559\u80b2\u53c2\u4e0e\u8005\u65f6\u7684\u6027\u80fd\u9650\u5236\uff0c\u65e8\u5728\u66f4\u51c6\u786e\u5730\u6a21\u62df\u771f\u5b9e\u5b66\u6821\u4e2d\u7684\u5e08\u751f\u4e92\u52a8\u548c\u5b66\u4e60\u8fc7\u7a0b\u3002", "method": "\u6784\u5efaZero-Exp\u7b56\u7565\uff0c\u91c7\u7528\"\u7ecf\u9a8c-\u53cd\u601d-\u4f18\u5316\"\u7684\u8fde\u7eed\u5faa\u73af\uff0c\u57fa\u4e8e\u5305\u542b\u7ecf\u9a8c\u548c\u77e5\u8bc6\u5e93\u7684\u53cc\u91cd\u8bb0\u5fc6\u57fa\u7840\uff0c\u6574\u5408\u77ed\u671f\u548c\u957f\u671f\u8bb0\u5fc6\u7ec4\u4ef6\uff0c\u4f7f\u4ee3\u7406\u5728\u591a\u6837\u5316\u6a21\u62df\u5b66\u6821\u573a\u666f\u4e2d\u901a\u8fc7\u60c5\u5883\u4ea4\u4e92\u81ea\u4e3b\u8fdb\u5316\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9eAAS\u80fd\u591f\u6709\u6548\u6a21\u62df\u590d\u6742\u6559\u80b2\u52a8\u6001\uff0c\u5728\u57f9\u517b\u9ad8\u7ea7\u4ee3\u7406\u8ba4\u77e5\u80fd\u529b\u65b9\u9762\u8868\u73b0\u6709\u6548\uff0c\u751f\u6210\u9ad8\u4fdd\u771f\u884c\u4e3a\u4ea4\u4e92\u6570\u636e\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u5b9e\u73b0\u4ece\"\u7ecf\u9a8c\u65f6\u4ee3\"\u5230\"\u6a21\u62df\u65f6\u4ee3\"\u7684\u8f6c\u53d8\u63d0\u4f9b\u4e86\u57fa\u7840\u652f\u6491\uff0c\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u884c\u4e3a\u548c\u4ea4\u4e92\u6570\u636e\u6765\u6a21\u62df\u771f\u5b9e\u6559\u80b2\u73af\u5883\u3002"}}
{"id": "2510.11308", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.11308", "abs": "https://arxiv.org/abs/2510.11308", "authors": ["Weixi Situ", "Hanjing Ye", "Jianwei Peng", "Yu Zhan", "Hong Zhang"], "title": "Adap-RPF: Adaptive Trajectory Sampling for Robot Person Following in Dynamic Crowded Environments", "comment": "https://adap-rpf.github.io/", "summary": "Robot person following (RPF) is a core capability in human-robot interaction,\nenabling robots to assist users in daily activities, collaborative work, and\nother service scenarios. However, achieving practical RPF remains challenging\ndue to frequent occlusions, particularly in dynamic and crowded environments.\nExisting approaches often rely on fixed-point following or sparse\ncandidate-point selection with oversimplified heuristics, which cannot\nadequately handle complex occlusions caused by moving obstacles such as\npedestrians. To address these limitations, we propose an adaptive trajectory\nsampling method that generates dense candidate points within socially aware\nzones and evaluates them using a multi-objective cost function. Based on the\noptimal point, a person-following trajectory is estimated relative to the\npredicted motion of the target. We further design a prediction-aware model\npredictive path integral (MPPI) controller that simultaneously tracks this\ntrajectory and proactively avoids collisions using predicted pedestrian\nmotions. Extensive experiments show that our method outperforms\nstate-of-the-art baselines in smoothness, safety, robustness, and human\ncomfort, with its effectiveness further demonstrated on a mobile robot in\nreal-world scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u8f68\u8ff9\u91c7\u6837\u65b9\u6cd5\uff0c\u7ed3\u5408\u591a\u76ee\u6807\u6210\u672c\u51fd\u6570\u548c\u9884\u6d4b\u611f\u77e5MPPI\u63a7\u5236\u5668\uff0c\u7528\u4e8e\u89e3\u51b3\u673a\u5668\u4eba\u8ddf\u968f\u4e2d\u590d\u6742\u906e\u6321\u95ee\u9898\uff0c\u5728\u5e73\u6ed1\u6027\u3001\u5b89\u5168\u6027\u3001\u9c81\u68d2\u6027\u548c\u4eba\u7c7b\u8212\u9002\u5ea6\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u52a8\u6001\u62e5\u6324\u73af\u5883\u4e2d\u673a\u5668\u4eba\u8ddf\u968f\u9762\u4e34\u7684\u9891\u7e41\u906e\u6321\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u70b9\u8ddf\u968f\u6216\u7a00\u758f\u5019\u9009\u70b9\u9009\u62e9\uff0c\u65e0\u6cd5\u5145\u5206\u5904\u7406\u79fb\u52a8\u969c\u788d\u7269\u9020\u6210\u7684\u590d\u6742\u906e\u6321\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u8f68\u8ff9\u91c7\u6837\u65b9\u6cd5\uff0c\u5728\u793e\u4f1a\u611f\u77e5\u533a\u57df\u5185\u751f\u6210\u5bc6\u96c6\u5019\u9009\u70b9\uff0c\u4f7f\u7528\u591a\u76ee\u6807\u6210\u672c\u51fd\u6570\u8bc4\u4f30\uff1b\u57fa\u4e8e\u6700\u4f18\u70b9\u4f30\u8ba1\u76f8\u5bf9\u4e8e\u76ee\u6807\u9884\u6d4b\u8fd0\u52a8\u7684\u8ddf\u968f\u8f68\u8ff9\uff1b\u8bbe\u8ba1\u9884\u6d4b\u611f\u77e5MPPI\u63a7\u5236\u5668\u540c\u65f6\u8ddf\u8e2a\u8f68\u8ff9\u5e76\u4e3b\u52a8\u907f\u969c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5e73\u6ed1\u6027\u3001\u5b89\u5168\u6027\u3001\u9c81\u68d2\u6027\u548c\u4eba\u7c7b\u8212\u9002\u5ea6\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5728\u771f\u5b9e\u79fb\u52a8\u673a\u5668\u4eba\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u8f68\u8ff9\u91c7\u6837\u548c\u9884\u6d4b\u611f\u77e5MPPI\u63a7\u5236\u5668\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u590d\u6742\u906e\u6321\u95ee\u9898\uff0c\u5b9e\u73b0\u66f4\u5b89\u5168\u3001\u5e73\u6ed1\u548c\u8212\u9002\u7684\u673a\u5668\u4eba\u8ddf\u968f\u3002"}}
{"id": "2510.11313", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11313", "abs": "https://arxiv.org/abs/2510.11313", "authors": ["Le Ngoc Luyen", "Marie-H\u00e9l\u00e8ne Abel"], "title": "Automated Skill Decomposition Meets Expert Ontologies: Bridging the Granularity Gap with LLMs", "comment": null, "summary": "This paper investigates automated skill decomposition using Large Language\nModels (LLMs) and proposes a rigorous, ontology-grounded evaluation framework.\nOur framework standardizes the pipeline from prompting and generation to\nnormalization and alignment with ontology nodes. To evaluate outputs, we\nintroduce two metrics: a semantic F1-score that uses optimal embedding-based\nmatching to assess content accuracy, and a hierarchy-aware F1-score that\ncredits structurally correct placements to assess granularity. We conduct\nexperiments on ROME-ESCO-DecompSkill, a curated subset of parents, comparing\ntwo prompting strategies: zero-shot and leakage-safe few-shot with exemplars.\nAcross diverse LLMs, zero-shot offers a strong baseline, while few-shot\nconsistently stabilizes phrasing and granularity and improves hierarchy-aware\nalignment. A latency analysis further shows that exemplar-guided prompts are\ncompetitive - and sometimes faster - than unguided zero-shot due to more\nschema-compliant completions. Together, the framework, benchmark, and metrics\nprovide a reproducible foundation for developing ontology-faithful skill\ndecomposition systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u6280\u80fd\u5206\u89e3\u65b9\u6cd5\uff0c\u5e76\u5efa\u7acb\u4e86\u4e00\u4e2a\u4e25\u8c28\u7684\u3001\u57fa\u4e8e\u672c\u4f53\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u8bed\u4e49F1\u5206\u6570\u548c\u5c42\u6b21\u611f\u77e5F1\u5206\u6570\u4e24\u4e2a\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u81ea\u52a8\u5316\u6280\u80fd\u5206\u89e3\u4e2d\u7f3a\u4e4f\u6807\u51c6\u5316\u8bc4\u4f30\u6846\u67b6\u7684\u95ee\u9898\uff0c\u786e\u4fdd\u5206\u89e3\u7ed3\u679c\u4e0e\u672c\u4f53\u7ed3\u6784\u7684\u4e00\u81f4\u6027\u3002", "method": "\u4f7f\u7528\u4e24\u79cd\u63d0\u793a\u7b56\u7565\uff08\u96f6\u6837\u672c\u548c\u9632\u6cc4\u6f0f\u5c11\u6837\u672c\uff09\uff0c\u901a\u8fc7\u6807\u51c6\u5316\u6d41\u7a0b\u4ece\u63d0\u793a\u751f\u6210\u5230\u5f52\u4e00\u5316\u548c\u672c\u4f53\u8282\u70b9\u5bf9\u9f50\uff0c\u5e76\u5f15\u5165\u4e24\u4e2a\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u96f6\u6837\u672c\u63d0\u4f9b\u4e86\u5f3a\u57fa\u7ebf\uff0c\u5c11\u6837\u672c\u65b9\u6cd5\u5728\u7a33\u5b9a\u63aa\u8f9e\u548c\u7c92\u5ea6\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u4e14\u5ef6\u8fdf\u5206\u6790\u663e\u793a\u5f15\u5bfc\u5f0f\u63d0\u793a\u5177\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u3001\u57fa\u51c6\u548c\u6307\u6807\u4e3a\u5f00\u53d1\u5fe0\u5b9e\u4e8e\u672c\u4f53\u7684\u6280\u80fd\u5206\u89e3\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u57fa\u7840\u3002"}}
{"id": "2510.11321", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.11321", "abs": "https://arxiv.org/abs/2510.11321", "authors": ["Ruizhe Liu", "Pei Zhou", "Qian Luo", "Li Sun", "Jun Cen", "Yibing Song", "Yanchao Yang"], "title": "HiMaCon: Discovering Hierarchical Manipulation Concepts from Unlabeled Multi-Modal Data", "comment": "Accepted at 39th Conference on Neural Information Processing Systems\n  (NeurIPS 2025)", "summary": "Effective generalization in robotic manipulation requires representations\nthat capture invariant patterns of interaction across environments and tasks.\nWe present a self-supervised framework for learning hierarchical manipulation\nconcepts that encode these invariant patterns through cross-modal sensory\ncorrelations and multi-level temporal abstractions without requiring human\nannotation. Our approach combines a cross-modal correlation network that\nidentifies persistent patterns across sensory modalities with a multi-horizon\npredictor that organizes representations hierarchically across temporal scales.\nManipulation concepts learned through this dual structure enable policies to\nfocus on transferable relational patterns while maintaining awareness of both\nimmediate actions and longer-term goals. Empirical evaluation across simulated\nbenchmarks and real-world deployments demonstrates significant performance\nimprovements with our concept-enhanced policies. Analysis reveals that the\nlearned concepts resemble human-interpretable manipulation primitives despite\nreceiving no semantic supervision. This work advances both the understanding of\nrepresentation learning for manipulation and provides a practical approach to\nenhancing robotic performance in complex scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u76d1\u7763\u6846\u67b6\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u611f\u5b98\u5173\u8054\u548c\u591a\u5c42\u6b21\u65f6\u95f4\u62bd\u8c61\u5b66\u4e60\u5c42\u6b21\u5316\u64cd\u4f5c\u6982\u5ff5\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\uff0c\u63d0\u5347\u673a\u5668\u4eba\u5728\u590d\u6742\u573a\u666f\u4e2d\u7684\u64cd\u4f5c\u6027\u80fd\u3002", "motivation": "\u673a\u5668\u4eba\u64cd\u4f5c\u9700\u8981\u80fd\u591f\u6355\u6349\u8de8\u73af\u5883\u548c\u4efb\u52a1\u4e0d\u53d8\u4ea4\u4e92\u6a21\u5f0f\u7684\u8868\u793a\uff0c\u4ee5\u5b9e\u73b0\u6709\u6548\u6cdb\u5316\u3002", "method": "\u7ed3\u5408\u8de8\u6a21\u6001\u5173\u8054\u7f51\u7edc\u8bc6\u522b\u8de8\u611f\u5b98\u6a21\u6001\u7684\u6301\u4e45\u6a21\u5f0f\uff0c\u4ee5\u53ca\u591a\u65f6\u95f4\u5c3a\u5ea6\u9884\u6d4b\u5668\u5728\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u5c42\u6b21\u5316\u7ec4\u7ec7\u8868\u793a\u3002", "result": "\u5728\u6a21\u62df\u57fa\u51c6\u548c\u771f\u5b9e\u90e8\u7f72\u4e2d\uff0c\u6982\u5ff5\u589e\u5f3a\u7b56\u7565\u663e\u793a\u51fa\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u5b66\u4e60\u5230\u7684\u6982\u5ff5\u7c7b\u4f3c\u4e8e\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u64cd\u4f5c\u57fa\u5143\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63a8\u8fdb\u4e86\u5bf9\u64cd\u4f5c\u8868\u793a\u5b66\u4e60\u7684\u7406\u89e3\uff0c\u5e76\u4e3a\u589e\u5f3a\u673a\u5668\u4eba\u5728\u590d\u6742\u573a\u666f\u4e2d\u7684\u6027\u80fd\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2510.11380", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11380", "abs": "https://arxiv.org/abs/2510.11380", "authors": ["Abdullah Al Mahmud", "Prangon Chowdhury", "Mohammed Borhan Uddin", "Khaled Eabne Delowar", "Tausifur Rahman Talha", "Bijoy Dewanjee"], "title": "AI-Driven anemia diagnosis: A review of advanced models and techniques", "comment": null, "summary": "Anemia, a condition marked by insufficient levels of red blood cells or\nhemoglobin, remains a widespread health issue affecting millions of individuals\nglobally. Accurate and timely diagnosis is essential for effective management\nand treatment of anemia. In recent years, there has been a growing interest in\nthe use of artificial intelligence techniques, i.e., machine learning (ML) and\ndeep learning (DL) for the detection, classification, and diagnosis of anemia.\nThis paper provides a systematic review of the recent advancements in this\nfield, with a focus on various models applied to anemia detection. The review\nalso compares these models based on several performance metrics, including\naccuracy, sensitivity, specificity, and precision. By analyzing these metrics,\nthe paper evaluates the strengths and limitation of discussed models in\ndetecting and classifying anemia, emphasizing the importance of addressing\nthese factors to improve diagnostic accuracy.", "AI": {"tldr": "\u672c\u6587\u5bf9\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u8fdb\u884c\u8d2b\u8840\u68c0\u6d4b\u3001\u5206\u7c7b\u548c\u8bca\u65ad\u7684\u6700\u65b0\u8fdb\u5c55\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u91cd\u70b9\u6bd4\u8f83\u4e86\u4e0d\u540c\u6a21\u578b\u5728\u51c6\u786e\u6027\u3001\u654f\u611f\u6027\u3001\u7279\u5f02\u6027\u7b49\u6027\u80fd\u6307\u6807\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u8d2b\u8840\u662f\u4e00\u79cd\u5f71\u54cd\u5168\u7403\u6570\u767e\u4e07\u4eba\u7684\u5e38\u89c1\u5065\u5eb7\u95ee\u9898\uff0c\u51c6\u786e\u53ca\u65f6\u7684\u8bca\u65ad\u5bf9\u4e8e\u6709\u6548\u7ba1\u7406\u548c\u6cbb\u7597\u81f3\u5173\u91cd\u8981\u3002\u8fd1\u5e74\u6765\uff0c\u4eba\u5de5\u667a\u80fd\u6280\u672f\u5728\u8d2b\u8840\u8bca\u65ad\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u6790\u6bd4\u8f83\u4e86\u591a\u79cd\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u8d2b\u8840\u68c0\u6d4b\u4e2d\u7684\u5e94\u7528\uff0c\u91cd\u70b9\u5173\u6ce8\u4e0d\u540c\u6a21\u578b\u7684\u6027\u80fd\u6307\u6807\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7\u5bf9\u6bd4\u5206\u6790\u53d1\u73b0\uff0c\u4e0d\u540cAI\u6a21\u578b\u5728\u8d2b\u8840\u68c0\u6d4b\u4e2d\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u6027\u80fd\u7279\u70b9\uff0c\u5404\u6a21\u578b\u5728\u51c6\u786e\u6027\u3001\u654f\u611f\u6027\u3001\u7279\u5f02\u6027\u7b49\u6307\u6807\u4e0a\u5404\u6709\u4f18\u52a3\u3002", "conclusion": "\u9700\u8981\u7efc\u5408\u8003\u8651\u5404\u79cd\u6027\u80fd\u56e0\u7d20\u6765\u6539\u8fdb\u8d2b\u8840\u8bca\u65ad\u7684\u51c6\u786e\u6027\uff0c\u5f3a\u8c03\u4e86\u5728\u6a21\u578b\u9009\u62e9\u548c\u4f18\u5316\u65f6\u5e73\u8861\u4e0d\u540c\u6027\u80fd\u6307\u6807\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.11401", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.11401", "abs": "https://arxiv.org/abs/2510.11401", "authors": ["Jiayang Wu", "Jiongye Li", "Shibowen Zhang", "Zhicheng He", "Zaijin Wang", "Xiaokun Leng", "Hangxin Liu", "Jingwen Zhang", "Jiayi Wang", "Song-Chun Zhu", "Yao Su"], "title": "Path and Motion Optimization for Efficient Multi-Location Inspection with Humanoid Robots", "comment": null, "summary": "This paper proposes a novel framework for humanoid robots to execute\ninspection tasks with high efficiency and millimeter-level precision. The\napproach combines hierarchical planning, time-optimal standing position\ngeneration, and integrated \\ac{mpc} to achieve high speed and precision. A\nhierarchical planning strategy, leveraging \\ac{ik} and \\ac{mip}, reduces\ncomputational complexity by decoupling the high-dimensional planning problem. A\nnovel MIP formulation optimizes standing position selection and trajectory\nlength, minimizing task completion time. Furthermore, an MPC system with\nsimplified kinematics and single-step position correction ensures\nmillimeter-level end-effector tracking accuracy. Validated through simulations\nand experiments on the Kuavo 4Pro humanoid platform, the framework demonstrates\nlow time cost and a high success rate in multi-location tasks, enabling\nefficient and precise execution of complex industrial operations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4eba\u5f62\u673a\u5668\u4eba\u68c0\u67e5\u4efb\u52a1\u6846\u67b6\uff0c\u7ed3\u5408\u5206\u5c42\u89c4\u5212\u3001\u65f6\u95f4\u6700\u4f18\u7ad9\u7acb\u4f4d\u7f6e\u751f\u6210\u548cMPC\u63a7\u5236\uff0c\u5b9e\u73b0\u9ad8\u6548\u6beb\u7c73\u7ea7\u7cbe\u5ea6\u6267\u884c\u3002", "motivation": "\u89e3\u51b3\u4eba\u5f62\u673a\u5668\u4eba\u5728\u5de5\u4e1a\u68c0\u67e5\u4efb\u52a1\u4e2d\u9700\u8981\u540c\u65f6\u517c\u987e\u9ad8\u6548\u7387\u548c\u9ad8\u7cbe\u5ea6\u7684\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5728\u590d\u6742\u73af\u5883\u4e2d\u5b9e\u73b0\u5feb\u901f\u7cbe\u786e\u7684\u591a\u4f4d\u7f6e\u64cd\u4f5c\u3002", "method": "\u91c7\u7528\u5206\u5c42\u89c4\u5212\u7b56\u7565\uff08IK+MIP\uff09\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4f7f\u7528MIP\u4f18\u5316\u7ad9\u7acb\u4f4d\u7f6e\u9009\u62e9\u548c\u8f68\u8ff9\u957f\u5ea6\uff0c\u7ed3\u5408MPC\u7cfb\u7edf\u5b9e\u73b0\u6beb\u7c73\u7ea7\u672b\u7aef\u6267\u884c\u5668\u8ddf\u8e2a\u7cbe\u5ea6\u3002", "result": "\u5728Kuavo 4Pro\u4eba\u5f62\u5e73\u53f0\u4e0a\u9a8c\u8bc1\uff0c\u663e\u793a\u4f4e\u65f6\u95f4\u6210\u672c\u548c\u9ad8\u6210\u529f\u7387\uff0c\u80fd\u591f\u9ad8\u6548\u7cbe\u786e\u6267\u884c\u590d\u6742\u5de5\u4e1a\u64cd\u4f5c\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u4eba\u5f62\u673a\u5668\u4eba\u68c0\u67e5\u4efb\u52a1\u7684\u9ad8\u6548\u7387\u548c\u6beb\u7c73\u7ea7\u7cbe\u5ea6\u8981\u6c42\uff0c\u4e3a\u590d\u6742\u5de5\u4e1a\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.11457", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11457", "abs": "https://arxiv.org/abs/2510.11457", "authors": ["Beining Wang", "Weihang Su", "Hongtao Tian", "Tao Yang", "Yujia Zhou", "Ting Yao", "Qingyao Ai", "Yiqun Liu"], "title": "From <Answer> to <Think>: Multidimensional Supervision of Reasoning Process for LLM Optimization", "comment": null, "summary": "Improving the multi-step reasoning ability of Large Language Models (LLMs) is\na critical yet challenging task. The dominant paradigm, outcome-supervised\nreinforcement learning (RLVR), rewards only correct final answers, often\npropagating flawed reasoning and suffering from sparse reward signals. While\nprocess-level reward models (PRMs) provide denser, step-by-step feedback, they\nlack generalizability and interpretability, requiring task-specific\nsegmentation of the reasoning process. To this end, we propose the\nDimension-level Reward Model (DRM), a new supervision framework that bridges\nthe gap between these two approaches. DRM evaluates the quality of a reasoning\nprocess along three fundamental, complementary, and interpretable dimensions:\nConfidence for uncertainty calibration, Relevance for semantic alignment, and\nCoherence for logical consistency. Together, these dimensions capture aspects\nbeyond final answer correctness and enable interpretable assessment without\nrequiring ground truth answers. Experimental results show that DRM provides\neffective supervision signals, guides the optimization of LLMs and enhances\ntheir reasoning ability. In particular, DRM-supervised training achieves\nconsistent gains on both in-distribution and out-of-distribution open-domain\ntasks, including mathematics, question answering, code execution, and puzzles.\nOur findings demonstrate that multidimensional supervision of the reasoning\nprocess can improve the generalized reasoning ability of LLMs beyond the\ntraining distribution.", "AI": {"tldr": "\u63d0\u51fa\u7ef4\u5ea6\u7ea7\u5956\u52b1\u6a21\u578b\uff08DRM\uff09\uff0c\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u3001\u76f8\u5173\u6027\u548c\u8fde\u8d2f\u6027\u4e09\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u63a8\u7406\u8fc7\u7a0b\u8d28\u91cf\uff0c\u5f25\u8865\u4e86\u7ed3\u679c\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u548c\u8fc7\u7a0b\u7ea7\u5956\u52b1\u6a21\u578b\u7684\u4e0d\u8db3\uff0c\u63d0\u5347\u4e86LLMs\u7684\u591a\u6b65\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u7f3a\u9677\uff1a\u7ed3\u679c\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u53ea\u5956\u52b1\u6700\u7ec8\u6b63\u786e\u7b54\u6848\uff0c\u5bb9\u6613\u4f20\u64ad\u9519\u8bef\u63a8\u7406\u4e14\u5956\u52b1\u7a00\u758f\uff1b\u8fc7\u7a0b\u7ea7\u5956\u52b1\u6a21\u578b\u7f3a\u4e4f\u6cdb\u5316\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u9700\u8981\u4efb\u52a1\u7279\u5b9a\u7684\u63a8\u7406\u8fc7\u7a0b\u5206\u5272\u3002", "method": "\u63d0\u51fa\u7ef4\u5ea6\u7ea7\u5956\u52b1\u6a21\u578b\uff08DRM\uff09\uff0c\u4ece\u4e09\u4e2a\u57fa\u672c\u7ef4\u5ea6\u8bc4\u4f30\u63a8\u7406\u8fc7\u7a0b\uff1a\u7f6e\u4fe1\u5ea6\uff08\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\uff09\u3001\u76f8\u5173\u6027\uff08\u8bed\u4e49\u5bf9\u9f50\uff09\u3001\u8fde\u8d2f\u6027\uff08\u903b\u8f91\u4e00\u81f4\u6027\uff09\uff0c\u65e0\u9700\u771f\u5b9e\u7b54\u6848\u5373\u53ef\u8fdb\u884c\u53ef\u89e3\u91ca\u7684\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660eDRM\u63d0\u4f9b\u6709\u6548\u7684\u76d1\u7763\u4fe1\u53f7\uff0c\u6307\u5bfcLLMs\u4f18\u5316\u5e76\u589e\u5f3a\u63a8\u7406\u80fd\u529b\u3002\u5728\u6570\u5b66\u3001\u95ee\u7b54\u3001\u4ee3\u7801\u6267\u884c\u548c\u8c1c\u9898\u7b49\u5f00\u653e\u9886\u57df\u4efb\u52a1\u4e0a\uff0cDRM\u76d1\u7763\u8bad\u7ec3\u5728\u5206\u5e03\u5185\u548c\u5206\u5e03\u5916\u90fd\u53d6\u5f97\u4e00\u81f4\u589e\u76ca\u3002", "conclusion": "\u591a\u7ef4\u5ea6\u7684\u63a8\u7406\u8fc7\u7a0b\u76d1\u7763\u53ef\u4ee5\u63d0\u5347LLMs\u5728\u8bad\u7ec3\u5206\u5e03\u4e4b\u5916\u7684\u6cdb\u5316\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2510.11421", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.11421", "abs": "https://arxiv.org/abs/2510.11421", "authors": ["Shih-Chieh Sun", "Yun-Cheng Tsai"], "title": "A Modular AIoT Framework for Low-Latency Real-Time Robotic Teleoperation in Smart Cities", "comment": null, "summary": "This paper presents an AI-driven IoT robotic teleoperation system designed\nfor real-time remote manipulation and intelligent visual monitoring, tailored\nfor smart city applications. The architecture integrates a Flutter-based\ncross-platform mobile interface with MQTT-based control signaling and WebRTC\nvideo streaming via the LiveKit framework. A YOLOv11-nano model is deployed for\nlightweight object detection, enabling real-time perception with annotated\nvisual overlays delivered to the user interface. Control commands are\ntransmitted via MQTT to an ESP8266-based actuator node, which coordinates\nmulti-axis robotic arm motion through an Arduino Mega2560 controller. The\nbackend infrastructure is hosted on DigitalOcean, ensuring scalable cloud\norchestration and stable global communication. Latency evaluations conducted\nunder both local and international VPN scenarios (including Hong Kong, Japan,\nand Belgium) demonstrate actuator response times as low as 0.2 seconds and\ntotal video latency under 1.2 seconds, even across high-latency networks. This\nlow-latency dual-protocol design ensures responsive closed-loop interaction and\nrobust performance in distributed environments. Unlike conventional\nteleoperation platforms, the proposed system emphasizes modular deployment,\nreal-time AI sensing, and adaptable communication strategies, making it\nwell-suited for smart city scenarios such as remote infrastructure inspection,\npublic equipment servicing, and urban automation. Future enhancements will\nfocus on edge-device deployment, adaptive routing, and integration with\ncity-scale IoT networks to enhance resilience and scalability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cdAI\u9a71\u52a8\u7684\u7269\u8054\u7f51\u673a\u5668\u4eba\u9065\u64cd\u4f5c\u7cfb\u7edf\uff0c\u91c7\u7528\u53cc\u534f\u8bae\u67b6\u6784\uff08MQTT\u63a7\u5236+WebRTC\u89c6\u9891\u6d41\uff09\uff0c\u5728\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u7684\u8fdc\u7a0b\u64cd\u4f5c\u548c\u667a\u80fd\u89c6\u89c9\u76d1\u63a7\uff0c\u9002\u7528\u4e8e\u667a\u6167\u57ce\u5e02\u5e94\u7528\u3002", "motivation": "\u9488\u5bf9\u667a\u6167\u57ce\u5e02\u573a\u666f\u4e2d\u7684\u8fdc\u7a0b\u57fa\u7840\u8bbe\u65bd\u68c0\u67e5\u3001\u516c\u5171\u8bbe\u5907\u7ef4\u62a4\u548c\u57ce\u5e02\u81ea\u52a8\u5316\u9700\u6c42\uff0c\u5f00\u53d1\u4e00\u4e2a\u5f3a\u8c03\u6a21\u5757\u5316\u90e8\u7f72\u3001\u5b9e\u65f6AI\u611f\u77e5\u548c\u9002\u5e94\u6027\u901a\u4fe1\u7b56\u7565\u7684\u673a\u5668\u4eba\u9065\u64cd\u4f5c\u7cfb\u7edf\u3002", "method": "\u96c6\u6210Flutter\u8de8\u5e73\u53f0\u79fb\u52a8\u754c\u9762\u3001\u57fa\u4e8eMQTT\u7684\u63a7\u5236\u4fe1\u53f7\u4f20\u8f93\u3001\u901a\u8fc7LiveKit\u6846\u67b6\u7684WebRTC\u89c6\u9891\u6d41\uff0c\u90e8\u7f72YOLOv11-nano\u6a21\u578b\u8fdb\u884c\u8f7b\u91cf\u7ea7\u76ee\u6807\u68c0\u6d4b\uff0c\u4f7f\u7528ESP8266\u548cArduino Mega2560\u63a7\u5236\u591a\u8f74\u673a\u68b0\u81c2\u8fd0\u52a8\u3002", "result": "\u5728\u672c\u5730\u548c\u56fd\u9645VPN\u573a\u666f\uff08\u9999\u6e2f\u3001\u65e5\u672c\u3001\u6bd4\u5229\u65f6\uff09\u4e0b\u7684\u5ef6\u8fdf\u8bc4\u4f30\u663e\u793a\uff0c\u6267\u884c\u5668\u54cd\u5e94\u65f6\u95f4\u4f4e\u81f30.2\u79d2\uff0c\u603b\u89c6\u9891\u5ef6\u8fdf\u4f4e\u4e8e1.2\u79d2\uff0c\u5373\u4f7f\u5728\u9ad8\u901f\u5ef6\u8fdf\u7f51\u7edc\u4e2d\u4e5f\u80fd\u4fdd\u6301\u6027\u80fd\u3002", "conclusion": "\u8be5\u4f4e\u5ef6\u8fdf\u53cc\u534f\u8bae\u8bbe\u8ba1\u786e\u4fdd\u4e86\u54cd\u5e94\u5f0f\u95ed\u73af\u4ea4\u4e92\u548c\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u7684\u7a33\u5065\u6027\u80fd\uff0c\u672a\u6765\u5c06\u4e13\u6ce8\u4e8e\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u3001\u81ea\u9002\u5e94\u8def\u7531\u548c\u4e0e\u57ce\u5e02\u7ea7\u7269\u8054\u7f51\u7f51\u7edc\u7684\u96c6\u6210\uff0c\u4ee5\u589e\u5f3a\u5f39\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2510.11462", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11462", "abs": "https://arxiv.org/abs/2510.11462", "authors": ["Yisen Gao", "Jiaxin Bai", "Yi Huang", "Xingcheng Fu", "Qingyun Sun", "Yangqiu Song"], "title": "Unifying Deductive and Abductive Reasoning in Knowledge Graphs with Masked Diffusion Model", "comment": "Under Review", "summary": "Deductive and abductive reasoning are two critical paradigms for analyzing\nknowledge graphs, enabling applications from financial query answering to\nscientific discovery. Deductive reasoning on knowledge graphs usually involves\nretrieving entities that satisfy a complex logical query, while abductive\nreasoning generates plausible logical hypotheses from observations. Despite\ntheir clear synergistic potential, where deduction can validate hypotheses and\nabduction can uncover deeper logical patterns, existing methods address them in\nisolation. To bridge this gap, we propose DARK, a unified framework for\nDeductive and Abductive Reasoning in Knowledge graphs. As a masked diffusion\nmodel capable of capturing the bidirectional relationship between queries and\nconclusions, DARK has two key innovations. First, to better leverage deduction\nfor hypothesis refinement during abductive reasoning, we introduce a\nself-reflective denoising process that iteratively generates and validates\ncandidate hypotheses against the observed conclusion. Second, to discover\nricher logical associations, we propose a logic-exploration reinforcement\nlearning approach that simultaneously masks queries and conclusions, enabling\nthe model to explore novel reasoning compositions. Extensive experiments on\nmultiple benchmark knowledge graphs show that DARK achieves state-of-the-art\nperformance on both deductive and abductive reasoning tasks, demonstrating the\nsignificant benefits of our unified approach.", "AI": {"tldr": "DARK\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u6f14\u7ece\u548c\u6eaf\u56e0\u63a8\u7406\uff0c\u901a\u8fc7\u63a9\u7801\u6269\u6563\u6a21\u578b\u6355\u83b7\u67e5\u8be2\u4e0e\u7ed3\u8bba\u7684\u53cc\u5411\u5173\u7cfb\uff0c\u5728\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06\u6f14\u7ece\u63a8\u7406\uff08\u68c0\u7d22\u6ee1\u8db3\u590d\u6742\u903b\u8f91\u67e5\u8be2\u7684\u5b9e\u4f53\uff09\u548c\u6eaf\u56e0\u63a8\u7406\uff08\u4ece\u89c2\u5bdf\u751f\u6210\u5408\u7406\u903b\u8f91\u5047\u8bbe\uff09\u5206\u5f00\u5904\u7406\uff0c\u4f46\u4e24\u8005\u5177\u6709\u660e\u663e\u7684\u534f\u540c\u6f5c\u529b\uff0c\u9700\u8981\u7edf\u4e00\u6846\u67b6\u6765\u6574\u5408\u8fd9\u4e24\u79cd\u63a8\u7406\u8303\u5f0f\u3002", "method": "\u63d0\u51faDARK\u6846\u67b6\uff0c\u91c7\u7528\u63a9\u7801\u6269\u6563\u6a21\u578b\uff1a1\uff09\u81ea\u53cd\u601d\u53bb\u566a\u8fc7\u7a0b\uff0c\u8fed\u4ee3\u751f\u6210\u548c\u9a8c\u8bc1\u5019\u9009\u5047\u8bbe\uff1b2\uff09\u903b\u8f91\u63a2\u7d22\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u540c\u65f6\u63a9\u7801\u67e5\u8be2\u548c\u7ed3\u8bba\u4ee5\u63a2\u7d22\u65b0\u9896\u63a8\u7406\u7ec4\u5408\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u77e5\u8bc6\u56fe\u8c31\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cDARK\u5728\u6f14\u7ece\u548c\u6eaf\u56e0\u63a8\u7406\u4efb\u52a1\u4e0a\u90fd\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u7edf\u4e00\u6f14\u7ece\u548c\u6eaf\u56e0\u63a8\u7406\u7684\u65b9\u6cd5\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0cDARK\u6846\u67b6\u901a\u8fc7\u53cc\u5411\u5efa\u6a21\u67e5\u8be2\u4e0e\u7ed3\u8bba\u5173\u7cfb\uff0c\u6709\u6548\u63d0\u5347\u4e86\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2510.11558", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11558", "abs": "https://arxiv.org/abs/2510.11558", "authors": ["Komal Gupta", "Aditya Shrivastava"], "title": "Zero Data Retention in LLM-based Enterprise AI Assistants: A Comparative Study of Market Leading Agentic AI Products", "comment": null, "summary": "Governance of data, compliance, and business privacy matters, particularly\nfor healthcare and finance businesses. Since the recent emergence of AI\nenterprise AI assistants enhancing business productivity, safeguarding private\ndata and compliance is now a priority. With the implementation of AI assistants\nacross the enterprise, the zero data retention can be achieved by implementing\nzero data retention policies by Large Language Model businesses like Open AI\nand Anthropic and Meta. In this work, we explore zero data retention policies\nfor the Enterprise apps of large language models (LLMs). Our key contribution\nis defining the architectural, compliance, and usability trade-offs of such\nsystems in parallel. In this research work, we examine the development of\ncommercial AI assistants with two industry leaders and market titans in this\narena - Salesforce and Microsoft. Both of these companies used distinct\ntechnical architecture to support zero data retention policies. Salesforce\nAgentForce and Microsoft Copilot are among the leading AI assistants providing\nmuch-needed push to business productivity in customer care. The purpose of this\npaper is to analyze the technical architecture and deployment of zero data\nretention policy by consuming applications as well as big language models\nservice providers like Open Ai, Anthropic, and Meta.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4f01\u4e1aAI\u52a9\u624b\u4e2d\u7684\u96f6\u6570\u636e\u4fdd\u7559\u653f\u7b56\uff0c\u5206\u6790Salesforce\u548cMicrosoft\u7b49\u516c\u53f8\u7684\u6280\u672f\u67b6\u6784\u5982\u4f55\u5728\u4fdd\u62a4\u9690\u79c1\u6570\u636e\u7684\u540c\u65f6\u63d0\u5347\u4e1a\u52a1\u751f\u4ea7\u529b\u3002", "motivation": "\u968f\u7740\u4f01\u4e1aAI\u52a9\u624b\u7684\u666e\u53ca\uff0c\u4fdd\u62a4\u79c1\u4eba\u6570\u636e\u548c\u5408\u89c4\u6027\u6210\u4e3a\u4f18\u5148\u4e8b\u9879\uff0c\u7279\u522b\u662f\u5728\u533b\u7597\u548c\u91d1\u878d\u7b49\u654f\u611f\u884c\u4e1a\u3002\u96f6\u6570\u636e\u4fdd\u7559\u653f\u7b56\u53ef\u4ee5\u89e3\u51b3\u6570\u636e\u6cbb\u7406\u548c\u9690\u79c1\u95ee\u9898\u3002", "method": "\u7814\u7a76Salesforce AgentForce\u548cMicrosoft Copilot\u7b49\u9886\u5148AI\u52a9\u624b\u7684\u6280\u672f\u67b6\u6784\uff0c\u5206\u6790\u5b83\u4eec\u5982\u4f55\u5b9e\u73b0\u96f6\u6570\u636e\u4fdd\u7559\u653f\u7b56\uff0c\u5e76\u6bd4\u8f83\u4e0d\u540c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u63d0\u4f9b\u5546\u7684\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u4e0d\u540c\u516c\u53f8\u91c7\u7528\u4e0d\u540c\u7684\u6280\u672f\u67b6\u6784\u6765\u652f\u6301\u96f6\u6570\u636e\u4fdd\u7559\u653f\u7b56\uff0c\u8fd9\u4e9b\u67b6\u6784\u5728\u67b6\u6784\u8bbe\u8ba1\u3001\u5408\u89c4\u6027\u548c\u53ef\u7528\u6027\u65b9\u9762\u5b58\u5728\u6743\u8861\u3002", "conclusion": "\u96f6\u6570\u636e\u4fdd\u7559\u653f\u7b56\u5bf9\u4e8e\u4f01\u4e1aAI\u52a9\u624b\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5728\u6280\u672f\u67b6\u6784\u3001\u5408\u89c4\u8981\u6c42\u548c\u7528\u6237\u4f53\u9a8c\u4e4b\u95f4\u627e\u5230\u5e73\u8861\u70b9\uff0c\u4ee5\u6709\u6548\u4fdd\u62a4\u654f\u611f\u6570\u636e\u3002"}}
{"id": "2510.11474", "categories": ["cs.RO", "cs.AI", "cs.HC", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.11474", "abs": "https://arxiv.org/abs/2510.11474", "authors": ["Ardian Selmonaj", "Giacomo Del Rio", "Adrian Schneider", "Alessandro Antonucci"], "title": "Coordinated Strategies in Realistic Air Combat by Hierarchical Multi-Agent Reinforcement Learning", "comment": "2025 IEEE International Conference on Agentic AI (ICA)", "summary": "Achieving mission objectives in a realistic simulation of aerial combat is\nhighly challenging due to imperfect situational awareness and nonlinear flight\ndynamics. In this work, we introduce a novel 3D multi-agent air combat\nenvironment and a Hierarchical Multi-Agent Reinforcement Learning framework to\ntackle these challenges. Our approach combines heterogeneous agent dynamics,\ncurriculum learning, league-play, and a newly adapted training algorithm. To\nthis end, the decision-making process is organized into two abstraction levels:\nlow-level policies learn precise control maneuvers, while high-level policies\nissue tactical commands based on mission objectives. Empirical results show\nthat our hierarchical approach improves both learning efficiency and combat\nperformance in complex dogfight scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e3D\u591a\u667a\u80fd\u4f53\u7a7a\u6218\u7684\u5c42\u6b21\u5316\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u5f02\u6784\u667a\u80fd\u4f53\u52a8\u529b\u5b66\u3001\u8bfe\u7a0b\u5b66\u4e60\u3001\u8054\u76df\u535a\u5f08\u548c\u65b0\u8bad\u7ec3\u7b97\u6cd5\uff0c\u901a\u8fc7\u9ad8\u4f4e\u4e24\u5c42\u7b56\u7565\u5206\u522b\u5904\u7406\u7cbe\u786e\u63a7\u5236\u548c\u6218\u672f\u51b3\u7b56\u3002", "motivation": "\u89e3\u51b3\u771f\u5b9e\u7a7a\u6218\u6a21\u62df\u4e2d\u7684\u6311\u6218\uff0c\u5305\u62ec\u4e0d\u5b8c\u5584\u7684\u60c5\u5883\u611f\u77e5\u548c\u975e\u7ebf\u6027\u98de\u884c\u52a8\u529b\u5b66\uff0c\u4ee5\u5b9e\u73b0\u4efb\u52a1\u76ee\u6807\u3002", "method": "\u91c7\u7528\u5c42\u6b21\u5316\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u51b3\u7b56\u8fc7\u7a0b\u5206\u4e3a\u4e24\u4e2a\u62bd\u8c61\u5c42\u6b21\uff1a\u4f4e\u5c42\u7b56\u7565\u5b66\u4e60\u7cbe\u786e\u63a7\u5236\u673a\u52a8\uff0c\u9ad8\u5c42\u7b56\u7565\u57fa\u4e8e\u4efb\u52a1\u76ee\u6807\u53d1\u5e03\u6218\u672f\u6307\u4ee4\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u5c42\u6b21\u5316\u65b9\u6cd5\u5728\u590d\u6742\u7a7a\u6218\u573a\u666f\u4e2d\u63d0\u9ad8\u4e86\u5b66\u4e60\u6548\u7387\u548c\u6218\u6597\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u5c42\u6b21\u5316\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u80fd\u6709\u6548\u5e94\u5bf9\u590d\u6742\u7a7a\u6218\u73af\u5883\u4e2d\u7684\u6311\u6218\uff0c\u63d0\u5347\u667a\u80fd\u4f53\u7684\u5b66\u4e60\u548c\u4f5c\u6218\u80fd\u529b\u3002"}}
{"id": "2510.11588", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11588", "abs": "https://arxiv.org/abs/2510.11588", "authors": ["Jiateng Liu", "Zhenhailong Wang", "Xiaojiang Huang", "Yingjie Li", "Xing Fan", "Xiang Li", "Chenlei Guo", "Ruhi Sarikaya", "Heng Ji"], "title": "Analyzing and Internalizing Complex Policy Documents for LLM Agents", "comment": "42 pages", "summary": "Large Language Model (LLM)-based agentic systems rely on in-context policy\ndocuments encoding diverse business rules. As requirements grow, these\ndocuments expand rapidly, causing high computational overhead. This motivates\ndeveloping internalization methods that embed policy documents into model\npriors while preserving performance. Prior prompt compression work targets\ngeneric prompts, but agentic policy documents span multiple complexity levels\nand require deeper reasoning, making internalization harder. We introduce\nCC-Gen, an agentic benchmark generator with Controllable Complexity across four\nlevels, enabling systematic evaluation of agents' ability to handle complexity\nand offering a unified framework for assessing policy internalization. Our\nanalysis shows that complex policy specifications governing workflows pose\nmajor reasoning challenges. Supporting internalization with gold user agent\ninteraction trajectories containing chain-of-thought (CoT) annotations via\nsupervised fine-tuning (SFT) is data-intensive and degrades sharply as policy\ncomplexity increases. To mitigate data and reasoning burdens, we propose\nCategory-Aware Policy Continued Pretraining (CAP-CPT). Our automated pipeline\nparses policy documents to extract key specifications, grouping them into\nfactual, behavioral, and conditional categories, and isolating complex\nconditions that drive workflow complexity. This guides targeted data synthesis\nand enables agents to internalize policy information through an autoregressive\npretraining loss. Experiments show CAP-CPT improves SFT baselines in all\nsettings, with up to 41% and 22% gains on Qwen-3-32B, achieving 97.3% prompt\nlength reduction on CC-Gen and further enhancing tau-Bench with minimal SFT\ndata.", "AI": {"tldr": "\u63d0\u51fa\u4e86CC-Gen\u57fa\u51c6\u6d4b\u8bd5\u751f\u6210\u5668\u548cCAP-CPT\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3LLM\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7b56\u7565\u6587\u6863\u5185\u90e8\u5316\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u53ef\u63a7\u590d\u6742\u5ea6\u8bc4\u4f30\u548c\u9488\u5bf9\u6027\u9884\u8bad\u7ec3\u63d0\u5347\u7b56\u7565\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u968f\u7740LLM\u4ee3\u7406\u7cfb\u7edf\u9700\u6c42\u589e\u957f\uff0c\u7b56\u7565\u6587\u6863\u5feb\u901f\u6269\u5c55\u5bfc\u81f4\u8ba1\u7b97\u5f00\u9500\u9ad8\uff0c\u9700\u8981\u5f00\u53d1\u5185\u90e8\u5316\u65b9\u6cd5\u5c06\u7b56\u7565\u6587\u6863\u5d4c\u5165\u6a21\u578b\u5148\u9a8c\u4e2d\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u3002", "method": "\u5f15\u5165CC-Gen\u57fa\u51c6\u751f\u6210\u5668\uff08\u56db\u4e2a\u53ef\u63a7\u590d\u6742\u5ea6\u7ea7\u522b\uff09\uff0c\u5e76\u63d0\u51faCAP-CPT\u65b9\u6cd5\uff1a\u81ea\u52a8\u89e3\u6790\u7b56\u7565\u6587\u6863\u63d0\u53d6\u5173\u952e\u89c4\u8303\uff0c\u5206\u7ec4\u4e3a\u4e8b\u5b9e\u6027\u3001\u884c\u4e3a\u6027\u548c\u6761\u4ef6\u6027\u7c7b\u522b\uff0c\u901a\u8fc7\u9488\u5bf9\u6027\u6570\u636e\u5408\u6210\u548c\u81ea\u56de\u5f52\u9884\u8bad\u7ec3\u635f\u5931\u5b9e\u73b0\u7b56\u7565\u5185\u90e8\u5316\u3002", "result": "CAP-CPT\u5728\u6240\u6709\u8bbe\u7f6e\u4e0b\u90fd\u4f18\u4e8eSFT\u57fa\u7ebf\uff0c\u5728Qwen-3-32B\u4e0a\u63d0\u5347\u8fbe41%\u548c22%\uff0c\u5728CC-Gen\u4e0a\u5b9e\u73b097.3%\u7684\u63d0\u793a\u957f\u5ea6\u51cf\u5c11\uff0c\u5e76\u5728\u5c11\u91cfSFT\u6570\u636e\u4e0b\u8fdb\u4e00\u6b65\u63d0\u5347tau-Bench\u6027\u80fd\u3002", "conclusion": "\u590d\u6742\u7b56\u7565\u89c4\u8303\u5bf9\u63a8\u7406\u6784\u6210\u4e3b\u8981\u6311\u6218\uff0cCAP-CPT\u65b9\u6cd5\u901a\u8fc7\u7c7b\u522b\u611f\u77e5\u7684\u6301\u7eed\u9884\u8bad\u7ec3\u6709\u6548\u51cf\u8f7b\u6570\u636e\u548c\u63a8\u7406\u8d1f\u62c5\uff0c\u663e\u8457\u63d0\u5347\u7b56\u7565\u5185\u90e8\u5316\u6548\u679c\u3002"}}
{"id": "2510.11595", "categories": ["cs.AI", "cs.GL"], "pdf": "https://arxiv.org/pdf/2510.11595", "abs": "https://arxiv.org/abs/2510.11595", "authors": ["Israel Mason-Williams", "Gabryel Mason-Williams"], "title": "Reproducibility: The New Frontier in AI Governance", "comment": "12 pages,6 figures,Workshop on Technical AI Governance at ICML", "summary": "AI policymakers are responsible for delivering effective governance\nmechanisms that can provide safe, aligned and trustworthy AI development.\nHowever, the information environment offered to policymakers is characterised\nby an unnecessarily low Signal-To-Noise Ratio, favouring regulatory capture and\ncreating deep uncertainty and divides on which risks should be prioritised from\na governance perspective. We posit that the current publication speeds in AI\ncombined with the lack of strong scientific standards, via weak reproducibility\nprotocols, effectively erodes the power of policymakers to enact meaningful\npolicy and governance protocols. Our paper outlines how AI research could adopt\nstricter reproducibility guidelines to assist governance endeavours and improve\nconsensus on the AI risk landscape. We evaluate the forthcoming reproducibility\ncrisis within AI research through the lens of crises in other scientific\ndomains; providing a commentary on how adopting preregistration, increased\nstatistical power and negative result publication reproducibility protocols can\nenable effective AI governance. While we maintain that AI governance must be\nreactive due to AI's significant societal implications we argue that\npolicymakers and governments must consider reproducibility protocols as a core\ntool in the governance arsenal and demand higher standards for AI research.\nCode to replicate data and figures:\nhttps://github.com/IFMW01/reproducibility-the-new-frontier-in-ai-governance", "AI": {"tldr": "AI\u7814\u7a76\u7f3a\u4e4f\u4e25\u683c\u7684\u53ef\u91cd\u590d\u6027\u6807\u51c6\u5bfc\u81f4\u653f\u7b56\u5236\u5b9a\u8005\u9762\u4e34\u4fe1\u606f\u566a\u58f0\u8fc7\u9ad8\u7684\u95ee\u9898\uff0c\u963b\u788d\u4e86\u6709\u6548\u7684AI\u6cbb\u7406\u3002\u8bba\u6587\u5efa\u8bae\u901a\u8fc7\u9884\u6ce8\u518c\u3001\u63d0\u9ad8\u7edf\u8ba1\u80fd\u529b\u548c\u53d1\u8868\u8d1f\u9762\u7ed3\u679c\u7b49\u53ef\u91cd\u590d\u6027\u534f\u8bae\u6765\u6539\u5584AI\u6cbb\u7406\u3002", "motivation": "\u5f53\u524dAI\u7814\u7a76\u53d1\u8868\u901f\u5ea6\u8fc7\u5feb\u4e14\u7f3a\u4e4f\u79d1\u5b66\u6807\u51c6\uff0c\u5bfc\u81f4\u653f\u7b56\u5236\u5b9a\u8005\u9762\u4e34\u4f4e\u4fe1\u566a\u6bd4\u7684\u4fe1\u606f\u73af\u5883\uff0c\u96be\u4ee5\u5236\u5b9a\u6709\u6548\u7684AI\u6cbb\u7406\u653f\u7b56\u3002", "method": "\u901a\u8fc7\u501f\u9274\u5176\u4ed6\u79d1\u5b66\u9886\u57df\u7684\u53ef\u91cd\u590d\u6027\u5371\u673a\u7ecf\u9a8c\uff0c\u63d0\u51fa\u5728AI\u7814\u7a76\u4e2d\u91c7\u7528\u9884\u6ce8\u518c\u3001\u589e\u52a0\u7edf\u8ba1\u80fd\u529b\u548c\u53d1\u8868\u8d1f\u9762\u7ed3\u679c\u7b49\u53ef\u91cd\u590d\u6027\u534f\u8bae\u3002", "result": "\u5206\u6790\u8868\u660e\u4e25\u683c\u7684\u79d1\u5b66\u6807\u51c6\u80fd\u591f\u63d0\u9ad8AI\u7814\u7a76\u7684\u53ef\u9760\u6027\uff0c\u4e3a\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u4fe1\u606f\u57fa\u7840\u3002", "conclusion": "AI\u6cbb\u7406\u5fc5\u987b\u5c06\u53ef\u91cd\u590d\u6027\u534f\u8bae\u4f5c\u4e3a\u6838\u5fc3\u5de5\u5177\uff0c\u8981\u6c42AI\u7814\u7a76\u8fbe\u5230\u66f4\u9ad8\u7684\u79d1\u5b66\u6807\u51c6\uff0c\u4ee5\u652f\u6301\u6709\u6548\u7684\u653f\u7b56\u5236\u5b9a\u3002"}}
{"id": "2510.11525", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.11525", "abs": "https://arxiv.org/abs/2510.11525", "authors": ["Luis F. Recalde", "Dhruv Agrawal", "Jon Arrizabalaga", "Guanrui Li"], "title": "DQ-NMPC: Dual-Quaternion NMPC for Quadrotor Flight", "comment": "Accepted to IEEE Robotics and Automation Letters", "summary": "MAVs have great potential to assist humans in complex tasks, with\napplications ranging from logistics to emergency response. Their agility makes\nthem ideal for operations in complex and dynamic environments. However,\nachieving precise control in agile flights remains a significant challenge,\nparticularly due to the underactuated nature of quadrotors and the strong\ncoupling between their translational and rotational dynamics. In this work, we\npropose a novel NMPC framework based on dual-quaternions (DQ-NMPC) for\nquadrotor flight. By representing both quadrotor dynamics and the pose error\ndirectly on the dual-quaternion manifold, our approach enables a compact and\nglobally non-singular formulation that captures the quadrotor coupled dynamics.\nWe validate our approach through simulations and real-world experiments,\ndemonstrating better numerical conditioning and significantly improved tracking\nperformance, with reductions in position and orientation errors of up to 56.11%\nand 56.77%, compared to a conventional baseline NMPC method. Furthermore, our\ncontroller successfully handles aggressive trajectories, reaching maximum\nspeeds up to 13.66 m/s and accelerations reaching 4.2 g within confined space\nconditions of dimensions 11m x 4.5m x 3.65m under which the baseline controller\nfails.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bf9\u5076\u56db\u5143\u6570\u7684NMPC\u6846\u67b6\uff08DQ-NMPC\uff09\u7528\u4e8e\u56db\u65cb\u7ffc\u98de\u884c\u63a7\u5236\uff0c\u901a\u8fc7\u5728\u5bf9\u5076\u56db\u5143\u6570\u6d41\u5f62\u4e0a\u8868\u793a\u52a8\u529b\u5b66\u548c\u59ff\u6001\u8bef\u5dee\uff0c\u5b9e\u73b0\u4e86\u7d27\u51d1\u4e14\u5168\u5c40\u975e\u5947\u5f02\u7684\u5efa\u6a21\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ddf\u8e2a\u6027\u80fd\u3002", "motivation": "\u56db\u65cb\u7ffc\u98de\u884c\u5668\u5728\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\u5177\u6709\u5de8\u5927\u5e94\u7528\u6f5c\u529b\uff0c\u4f46\u7531\u4e8e\u5176\u6b20\u9a71\u52a8\u7279\u6027\u548c\u5e73\u79fb-\u65cb\u8f6c\u52a8\u529b\u5b66\u7684\u5f3a\u8026\u5408\uff0c\u5b9e\u73b0\u7cbe\u786e\u63a7\u5236\u4ecd\u9762\u4e34\u6311\u6218\u3002", "method": "\u4f7f\u7528\u5bf9\u5076\u56db\u5143\u6570\u8868\u793a\u56db\u65cb\u7ffc\u52a8\u529b\u5b66\u548c\u59ff\u6001\u8bef\u5dee\uff0c\u6784\u5efa\u7d27\u51d1\u4e14\u5168\u5c40\u975e\u5947\u5f02\u7684NMPC\u6846\u67b6\uff0c\u76f4\u63a5\u5728\u5bf9\u5076\u56db\u5143\u6570\u6d41\u5f62\u4e0a\u5efa\u6a21\u8026\u5408\u52a8\u529b\u5b66\u3002", "result": "\u76f8\u6bd4\u4f20\u7edfNMPC\u65b9\u6cd5\uff0c\u4f4d\u7f6e\u548c\u59ff\u6001\u8ddf\u8e2a\u8bef\u5dee\u5206\u522b\u964d\u4f4e56.11%\u548c56.77%\uff0c\u6570\u503c\u6761\u4ef6\u66f4\u597d\uff0c\u80fd\u5904\u7406\u6fc0\u8fdb\u8f68\u8ff9\uff08\u6700\u5927\u901f\u5ea613.66m/s\uff0c\u52a0\u901f\u5ea64.2g\uff09\uff0c\u5728\u53d7\u9650\u7a7a\u95f4\uff0811m\u00d74.5m\u00d73.65m\uff09\u4e2d\u57fa\u7ebf\u63a7\u5236\u5668\u5931\u8d25\u65f6\u4ecd\u80fd\u6210\u529f\u63a7\u5236\u3002", "conclusion": "DQ-NMPC\u6846\u67b6\u901a\u8fc7\u5728\u5bf9\u5076\u56db\u5143\u6570\u6d41\u5f62\u4e0a\u5efa\u6a21\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u56db\u65cb\u7ffc\u52a8\u529b\u5b66\u8026\u5408\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a7\u5236\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u6fc0\u8fdb\u98de\u884c\u548c\u53d7\u9650\u7a7a\u95f4\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2510.11604", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11604", "abs": "https://arxiv.org/abs/2510.11604", "authors": ["Sanjula De Alwis", "Indrajith Ekanayake"], "title": "Explainability, risk modeling, and segmentation based customer churn analytics for personalized retention in e-commerce", "comment": null, "summary": "In online retail, customer acquisition typically incurs higher costs than\ncustomer retention, motivating firms to invest in churn analytics. However,\nmany contemporary churn models operate as opaque black boxes, limiting insight\ninto the determinants of attrition, the timing of retention opportunities, and\nthe identification of high-risk customer segments. Accordingly, the emphasis\nshould shift from prediction alone to the design of personalized retention\nstrategies grounded in interpretable evidence. This study advances a\nthree-component framework that integrates explainable AI to quantify feature\ncontributions, survival analysis to model time-to-event churn risk, and RFM\nprofiling to segment customers by transactional behaviour. In combination,\nthese methods enable the attribution of churn drivers, estimation of\nintervention windows, and prioritization of segments for targeted actions,\nthereby supporting strategies that reduce attrition and strengthen customer\nloyalty.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e09\u7ec4\u4ef6\u6846\u67b6\uff0c\u7ed3\u5408\u53ef\u89e3\u91caAI\u3001\u751f\u5b58\u5206\u6790\u548cRFM\u5206\u6790\uff0c\u7528\u4e8e\u5ba2\u6237\u6d41\u5931\u9884\u6d4b\u548c\u4e2a\u6027\u5316\u4fdd\u7559\u7b56\u7565\u8bbe\u8ba1\u3002", "motivation": "\u5728\u7ebf\u96f6\u552e\u4e2d\u5ba2\u6237\u83b7\u53d6\u6210\u672c\u9ad8\u4e8e\u4fdd\u7559\u6210\u672c\uff0c\u4f46\u73b0\u6709\u6d41\u5931\u6a21\u578b\u591a\u4e3a\u9ed1\u7bb1\uff0c\u7f3a\u4e4f\u5bf9\u6d41\u5931\u539f\u56e0\u3001\u5e72\u9884\u65f6\u673a\u548c\u9ad8\u98ce\u9669\u5ba2\u6237\u7fa4\u4f53\u7684\u6d1e\u5bdf\u3002", "method": "\u96c6\u6210\u53ef\u89e3\u91caAI\u91cf\u5316\u7279\u5f81\u8d21\u732e\u3001\u751f\u5b58\u5206\u6790\u5efa\u6a21\u6d41\u5931\u98ce\u9669\u65f6\u95f4\u3001RFM\u5206\u6790\u6309\u4ea4\u6613\u884c\u4e3a\u7ec6\u5206\u5ba2\u6237\u7684\u4e09\u7ec4\u4ef6\u6846\u67b6\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u8bc6\u522b\u6d41\u5931\u9a71\u52a8\u56e0\u7d20\u3001\u4f30\u8ba1\u5e72\u9884\u7a97\u53e3\u3001\u4f18\u5148\u5904\u7406\u76ee\u6807\u7ec6\u5206\u5e02\u573a\uff0c\u652f\u6301\u51cf\u5c11\u6d41\u5931\u548c\u589e\u5f3a\u5ba2\u6237\u5fe0\u8bda\u5ea6\u7684\u7b56\u7565\u3002", "conclusion": "\u5e94\u5c06\u91cd\u70b9\u4ece\u5355\u7eaf\u9884\u6d4b\u8f6c\u5411\u57fa\u4e8e\u53ef\u89e3\u91ca\u8bc1\u636e\u7684\u4e2a\u6027\u5316\u4fdd\u7559\u7b56\u7565\u8bbe\u8ba1\uff0c\u8be5\u65b9\u6cd5\u4e3a\u5236\u5b9a\u9488\u5bf9\u6027\u5ba2\u6237\u4fdd\u7559\u7b56\u7565\u63d0\u4f9b\u4e86\u6709\u6548\u652f\u6301\u3002"}}
{"id": "2510.11608", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11608", "abs": "https://arxiv.org/abs/2510.11608", "authors": ["Shiqi Zhang", "Xinbei Ma", "Yunqing Xu", "Zouying Cao", "Pengrui Lu", "Haobo Yuan", "Tiancheng Shen", "Zhuosheng Zhang", "Hai Zhao", "Ming-Hsuan Yang"], "title": "ParaCook: On Time-Efficient Planning for Multi-Agent Systems", "comment": null, "summary": "Large Language Models (LLMs) exhibit strong reasoning abilities for planning\nlong-horizon, real-world tasks, yet existing agent benchmarks focus on task\ncompletion while neglecting time efficiency in parallel and asynchronous\noperations. To address this, we present ParaCook, a benchmark for\ntime-efficient collaborative planning. Inspired by the Overcooked game,\nParaCook provides an environment for various challenging interaction planning\nof multi-agent systems that are instantiated as cooking tasks, with a\nsimplified action space to isolate the core challenge of strategic parallel\nplanning. Through a comprehensive evaluation of state-of-the-art LLMs, we find\nthat current approaches achieve suboptimal plans, which struggle with parallel\nactions or coordination. Our analysis also reveals LLMs' potential on abstract\ntasks where they can focus on high-level parallel optimization. ParaCook\nprovides a scalable evaluation framework with adjustable complexity,\nestablishing a foundation for developing and assessing time efficiency-aware\nmulti-agent planning. The code and data are available at\nhttps://github.com/zsq259/ParaCook.", "AI": {"tldr": "ParaCook\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u591a\u667a\u80fd\u4f53\u65f6\u95f4\u6548\u7387\u534f\u4f5c\u89c4\u5212\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u57fa\u4e8e\u7b80\u5316\u7248Overcooked\u6e38\u620f\u73af\u5883\uff0c\u4e13\u6ce8\u4e8e\u5e76\u884c\u548c\u5f02\u6b65\u64cd\u4f5c\u7684\u89c4\u5212\u80fd\u529b\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u4efb\u52a1\u5b8c\u6210\u5ea6\uff0c\u4f46\u5ffd\u89c6\u4e86\u5e76\u884c\u548c\u5f02\u6b65\u64cd\u4f5c\u7684\u65f6\u95f4\u6548\u7387\u95ee\u9898\u3002\u9700\u8981\u4e13\u95e8\u8bc4\u4f30LLM\u5728\u65f6\u95f4\u6548\u7387\u654f\u611f\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u89c4\u5212\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u57fa\u4e8eOvercooked\u6e38\u620f\u8bbe\u8ba1ParaCook\u73af\u5883\uff0c\u63d0\u4f9b\u7b80\u5316\u7684\u52a8\u4f5c\u7a7a\u95f4\u6765\u4e13\u6ce8\u4e8e\u6218\u7565\u5e76\u884c\u89c4\u5212\u7684\u6838\u5fc3\u6311\u6218\uff0c\u6784\u5efa\u53ef\u6269\u5c55\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u5f53\u524d\u6700\u5148\u8fdb\u7684LLM\u5728ParaCook\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u751f\u6210\u7684\u89c4\u5212\u5728\u5e76\u884c\u52a8\u4f5c\u548c\u534f\u8c03\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u4f46\u5728\u62bd\u8c61\u4efb\u52a1\u4e0a\u663e\u793a\u51fa\u5e76\u884c\u4f18\u5316\u7684\u6f5c\u529b\u3002", "conclusion": "ParaCook\u4e3a\u5f00\u53d1\u548c\u8bc4\u4f30\u65f6\u95f4\u6548\u7387\u611f\u77e5\u7684\u591a\u667a\u80fd\u4f53\u89c4\u5212\u5efa\u7acb\u4e86\u57fa\u7840\uff0c\u63ed\u793a\u4e86LLM\u5728\u5e76\u884c\u89c4\u5212\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u5728\u62bd\u8c61\u4efb\u52a1\u4e0a\u7684\u4f18\u5316\u6f5c\u529b\u3002"}}
{"id": "2510.11539", "categories": ["cs.RO", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.11539", "abs": "https://arxiv.org/abs/2510.11539", "authors": ["Denglin Cheng", "Jiarong Kang", "Xiaobin Xiong"], "title": "Simultaneous Calibration of Noise Covariance and Kinematics for State Estimation of Legged Robots via Bi-level Optimization", "comment": null, "summary": "Accurate state estimation is critical for legged and aerial robots operating\nin dynamic, uncertain environments. A key challenge lies in specifying process\nand measurement noise covariances, which are typically unknown or manually\ntuned. In this work, we introduce a bi-level optimization framework that\njointly calibrates covariance matrices and kinematic parameters in an\nestimator-in-the-loop manner. The upper level treats noise covariances and\nmodel parameters as optimization variables, while the lower level executes a\nfull-information estimator. Differentiating through the estimator allows direct\noptimization of trajectory-level objectives, resulting in accurate and\nconsistent state estimates. We validate our approach on quadrupedal and\nhumanoid robots, demonstrating significantly improved estimation accuracy and\nuncertainty calibration compared to hand-tuned baselines. Our method unifies\nstate estimation, sensor, and kinematics calibration into a principled,\ndata-driven framework applicable across diverse robotic platforms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5c42\u4f18\u5316\u6846\u67b6\uff0c\u8054\u5408\u6821\u51c6\u534f\u65b9\u5dee\u77e9\u9635\u548c\u8fd0\u52a8\u5b66\u53c2\u6570\uff0c\u901a\u8fc7\u4f30\u8ba1\u5668\u5185\u73af\u65b9\u5f0f\u63d0\u9ad8\u673a\u5668\u4eba\u72b6\u6001\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u5728\u52a8\u6001\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\uff0c\u817f\u5f0f\u548c\u7a7a\u4e2d\u673a\u5668\u4eba\u7684\u72b6\u6001\u4f30\u8ba1\u9762\u4e34\u8fc7\u7a0b\u566a\u58f0\u548c\u6d4b\u91cf\u566a\u58f0\u534f\u65b9\u5dee\u96be\u4ee5\u786e\u5b9a\u7684\u95ee\u9898\uff0c\u901a\u5e38\u9700\u8981\u624b\u52a8\u8c03\u6574\u3002", "method": "\u91c7\u7528\u53cc\u5c42\u4f18\u5316\u6846\u67b6\uff1a\u4e0a\u5c42\u5c06\u566a\u58f0\u534f\u65b9\u5dee\u548c\u6a21\u578b\u53c2\u6570\u4f5c\u4e3a\u4f18\u5316\u53d8\u91cf\uff0c\u4e0b\u5c42\u6267\u884c\u5168\u4fe1\u606f\u4f30\u8ba1\u5668\u3002\u901a\u8fc7\u4f30\u8ba1\u5668\u7684\u5fae\u5206\u5b9e\u73b0\u8f68\u8ff9\u7ea7\u76ee\u6807\u7684\u76f4\u63a5\u4f18\u5316\u3002", "result": "\u5728\u56db\u8db3\u548c\u4eba\u5f62\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u624b\u52a8\u8c03\u4f18\u57fa\u7ebf\uff0c\u4f30\u8ba1\u7cbe\u5ea6\u548c\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c06\u72b6\u6001\u4f30\u8ba1\u3001\u4f20\u611f\u5668\u548c\u8fd0\u52a8\u5b66\u6821\u51c6\u7edf\u4e00\u5230\u4e00\u4e2a\u539f\u5219\u6027\u7684\u6570\u636e\u9a71\u52a8\u6846\u67b6\u4e2d\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u673a\u5668\u4eba\u5e73\u53f0\u3002"}}
{"id": "2510.11661", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11661", "abs": "https://arxiv.org/abs/2510.11661", "authors": ["Shijie Xia", "Yuhan Sun", "Pengfei Liu"], "title": "SR-Scientist: Scientific Equation Discovery With Agentic AI", "comment": null, "summary": "Recently, Large Language Models (LLMs) have been applied to scientific\nequation discovery, leveraging their embedded scientific knowledge for\nhypothesis generation. However, current methods typically confine LLMs to the\nrole of an equation proposer within search algorithms like genetic programming.\nIn this paper, we present SR-Scientist, a framework that elevates the LLM from\na simple equation proposer to an autonomous AI scientist that writes code to\nanalyze data, implements the equation as code, submits it for evaluation, and\noptimizes the equation based on experimental feedback. Specifically, we wrap\nthe code interpreter into a set of tools for data analysis and equation\nevaluation. The agent is instructed to optimize the equation by utilizing these\ntools over a long horizon with minimal human-defined pipelines. Empirical\nresults show that SR-Scientist outperforms baseline methods by an absolute\nmargin of 6% to 35% on datasets covering four science disciplines.\nAdditionally, we demonstrate our method's robustness to noise, the\ngeneralization of the discovered equations to out-of-domain data, and their\nsymbolic accuracy. Furthermore, we develop an end-to-end reinforcement learning\nframework to enhance the agent's capabilities.", "AI": {"tldr": "SR-Scientist\u6846\u67b6\u5c06LLM\u4ece\u7b80\u5355\u7684\u65b9\u7a0b\u63d0\u8bae\u8005\u63d0\u5347\u4e3a\u81ea\u4e3bAI\u79d1\u5b66\u5bb6\uff0c\u901a\u8fc7\u7f16\u5199\u4ee3\u7801\u5206\u6790\u6570\u636e\u3001\u5b9e\u73b0\u65b9\u7a0b\u3001\u63d0\u4ea4\u8bc4\u4f30\uff0c\u5e76\u57fa\u4e8e\u5b9e\u9a8c\u53cd\u9988\u4f18\u5316\u65b9\u7a0b\uff0c\u5728\u56db\u4e2a\u79d1\u5b66\u9886\u57df\u7684\u6570\u636e\u96c6\u4e0a\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u53476%-35%\u3002", "motivation": "\u5f53\u524dLLM\u5728\u79d1\u5b66\u65b9\u7a0b\u53d1\u73b0\u4e2d\u4ec5\u4f5c\u4e3a\u641c\u7d22\u7b97\u6cd5\u4e2d\u7684\u65b9\u7a0b\u63d0\u8bae\u8005\uff0c\u9650\u5236\u4e86\u5176\u6f5c\u529b\u3002\u9700\u8981\u8ba9LLM\u626e\u6f14\u66f4\u81ea\u4e3b\u7684\u89d2\u8272\uff0c\u5145\u5206\u5229\u7528\u5176\u79d1\u5b66\u77e5\u8bc6\u8fdb\u884c\u7aef\u5230\u7aef\u7684\u65b9\u7a0b\u53d1\u73b0\u548c\u4f18\u5316\u3002", "method": "\u5c06\u4ee3\u7801\u89e3\u91ca\u5668\u5c01\u88c5\u4e3a\u6570\u636e\u5206\u6790\u548c\u65b9\u7a0b\u8bc4\u4f30\u5de5\u5177\u96c6\uff0c\u6307\u5bfc\u667a\u80fd\u4f53\u5728\u957f\u89c6\u91ce\u4e2d\u5229\u7528\u8fd9\u4e9b\u5de5\u5177\u4f18\u5316\u65b9\u7a0b\uff0c\u6700\u5c0f\u5316\u4eba\u5de5\u5b9a\u4e49\u6d41\u7a0b\u3002\u8fd8\u5f00\u53d1\u4e86\u7aef\u5230\u7aef\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u6765\u589e\u5f3a\u667a\u80fd\u4f53\u80fd\u529b\u3002", "result": "\u5728\u56db\u4e2a\u79d1\u5b66\u9886\u57df\u7684\u6570\u636e\u96c6\u4e0a\uff0cSR-Scientist\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u7edd\u5bf9\u63d0\u53476%-35%\u3002\u65b9\u6cd5\u5bf9\u566a\u58f0\u5177\u6709\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u7684\u65b9\u7a0b\u5728\u57df\u5916\u6570\u636e\u4e0a\u5177\u6709\u826f\u597d\u6cdb\u5316\u80fd\u529b\uff0c\u7b26\u53f7\u51c6\u786e\u6027\u9ad8\u3002", "conclusion": "SR-Scientist\u6210\u529f\u5c06LLM\u63d0\u5347\u4e3a\u81ea\u4e3bAI\u79d1\u5b66\u5bb6\uff0c\u5728\u79d1\u5b66\u65b9\u7a0b\u53d1\u73b0\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86LLM\u5728\u79d1\u5b66\u53d1\u73b0\u4e2d\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2510.11542", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.11542", "abs": "https://arxiv.org/abs/2510.11542", "authors": ["Neil C. Janwani", "Varun Madabushi", "Maegan Tucker"], "title": "NaviGait: Navigating Dynamically Feasible Gait Libraries using Deep Reinforcement Learning", "comment": null, "summary": "Reinforcement learning (RL) has emerged as a powerful method to learn robust\ncontrol policies for bipedal locomotion. Yet, it can be difficult to tune\ndesired robot behaviors due to unintuitive and complex reward design. In\ncomparison, offline trajectory optimization methods, like Hybrid Zero Dynamics,\noffer more tuneable, interpretable, and mathematically grounded motion plans\nfor high-dimensional legged systems. However, these methods often remain\nbrittle to real-world disturbances like external perturbations.\n  In this work, we present NaviGait, a hierarchical framework that combines the\nstructure of trajectory optimization with the adaptability of RL for robust and\nintuitive locomotion control. NaviGait leverages a library of offline-optimized\ngaits and smoothly interpolates between them to produce continuous reference\nmotions in response to high-level commands. The policy provides both\njoint-level and velocity command residual corrections to modulate and stabilize\nthe reference trajectories in the gait library. One notable advantage of\nNaviGait is that it dramatically simplifies reward design by encoding rich\nmotion priors from trajectory optimization, reducing the need for finely tuned\nshaping terms and enabling more stable and interpretable learning. Our\nexperimental results demonstrate that NaviGait enables faster training compared\nto conventional and imitation-based RL, and produces motions that remain\nclosest to the original reference. Overall, by decoupling high-level motion\ngeneration from low-level correction, NaviGait offers a more scalable and\ngeneralizable approach for achieving dynamic and robust locomotion.", "AI": {"tldr": "NaviGait\u662f\u4e00\u4e2a\u5206\u5c42\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u8f68\u8ff9\u4f18\u5316\u7684\u7ed3\u6784\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u9002\u5e94\u6027\uff0c\u7528\u4e8e\u5b9e\u73b0\u7a33\u5065\u76f4\u89c2\u7684\u53cc\u8db3\u8fd0\u52a8\u63a7\u5236\u3002\u5b83\u5229\u7528\u79bb\u7ebf\u4f18\u5316\u7684\u6b65\u6001\u5e93\uff0c\u901a\u8fc7\u9ad8\u5c42\u547d\u4ee4\u5e73\u6ed1\u63d2\u503c\u751f\u6210\u8fde\u7eed\u53c2\u8003\u8fd0\u52a8\uff0c\u5e76\u901a\u8fc7\u7b56\u7565\u63d0\u4f9b\u5173\u8282\u7ea7\u548c\u901f\u5ea6\u547d\u4ee4\u6b8b\u5dee\u4fee\u6b63\u6765\u7a33\u5b9a\u53c2\u8003\u8f68\u8ff9\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u867d\u7136\u80fd\u5b66\u4e60\u7a33\u5065\u7684\u53cc\u8db3\u8fd0\u52a8\u63a7\u5236\u7b56\u7565\uff0c\u4f46\u5956\u52b1\u51fd\u6570\u8bbe\u8ba1\u590d\u6742\u4e14\u4e0d\u76f4\u89c2\uff1b\u800c\u79bb\u7ebf\u8f68\u8ff9\u4f18\u5316\u65b9\u6cd5\u867d\u7136\u53ef\u8c03\u6027\u548c\u53ef\u89e3\u91ca\u6027\u5f3a\uff0c\u4f46\u5bf9\u73b0\u5b9e\u4e16\u754c\u6270\u52a8\u8f83\u4e3a\u8106\u5f31\u3002\u9700\u8981\u7ed3\u5408\u4e24\u8005\u7684\u4f18\u52bf\u3002", "method": "\u91c7\u7528\u5206\u5c42\u6846\u67b6\uff1a\u9ad8\u5c42\u5229\u7528\u79bb\u7ebf\u4f18\u5316\u7684\u6b65\u6001\u5e93\uff0c\u6839\u636e\u9ad8\u5c42\u547d\u4ee4\u5e73\u6ed1\u63d2\u503c\u751f\u6210\u8fde\u7eed\u53c2\u8003\u8fd0\u52a8\uff1b\u4f4e\u5c42\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u63d0\u4f9b\u5173\u8282\u7ea7\u548c\u901f\u5ea6\u547d\u4ee4\u6b8b\u5dee\u4fee\u6b63\uff0c\u8c03\u5236\u548c\u7a33\u5b9a\u53c2\u8003\u8f68\u8ff9\u3002", "result": "NaviGait\u76f8\u6bd4\u4f20\u7edf\u548c\u57fa\u4e8e\u6a21\u4eff\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u66f4\u5feb\uff0c\u4ea7\u751f\u7684\u8fd0\u52a8\u6700\u63a5\u8fd1\u539f\u59cb\u53c2\u8003\u3002\u901a\u8fc7\u4ece\u8f68\u8ff9\u4f18\u5316\u4e2d\u7f16\u7801\u4e30\u5bcc\u7684\u8fd0\u52a8\u5148\u9a8c\uff0c\u5927\u5927\u7b80\u5316\u4e86\u5956\u52b1\u8bbe\u8ba1\u3002", "conclusion": "\u901a\u8fc7\u89e3\u8026\u9ad8\u5c42\u8fd0\u52a8\u751f\u6210\u548c\u4f4e\u5c42\u4fee\u6b63\uff0cNaviGait\u4e3a\u5b9e\u73b0\u52a8\u6001\u548c\u7a33\u5065\u7684\u8fd0\u52a8\u63a7\u5236\u63d0\u4f9b\u4e86\u66f4\u53ef\u6269\u5c55\u548c\u6cdb\u5316\u7684\u65b9\u6cd5\u3002"}}
{"id": "2510.11694", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11694", "abs": "https://arxiv.org/abs/2510.11694", "authors": ["Arjun Sahney", "Ram Gorthi", "Cezary \u0141astowski", "Javier Vega"], "title": "Operand Quant: A Single-Agent Architecture for Autonomous Machine Learning Engineering", "comment": "8 pages. No figures. Evaluated on MLE-Benchmark 2025", "summary": "We present Operand Quant, a single-agent, IDE-based architecture for\nautonomous machine learning engineering (MLE). Operand Quant departs from\nconventional multi-agent orchestration frameworks by consolidating all MLE\nlifecycle stages -- exploration, modeling, experimentation, and deployment --\nwithin a single, context-aware agent. On the MLE-Benchmark (2025), Operand\nQuant achieved a new state-of-the-art (SOTA) result, with an overall medal rate\nof 0.3956 +/- 0.0565 across 75 problems -- the highest recorded performance\namong all evaluated systems to date. The architecture demonstrates that a\nlinear, non-blocking agent, operating autonomously within a controlled IDE\nenvironment, can outperform multi-agent and orchestrated systems under\nidentical constraints.", "AI": {"tldr": "Operand Quant\u662f\u4e00\u4e2a\u57fa\u4e8eIDE\u7684\u5355\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u7528\u4e8e\u81ea\u4e3b\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\uff0c\u5728MLE-Benchmark\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u7f16\u6392\u6846\u67b6\u5b58\u5728\u590d\u6742\u6027\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u5355\u4e00\u667a\u80fd\u4f53\u6574\u5408\u6240\u6709MLE\u751f\u547d\u5468\u671f\u9636\u6bb5\u6765\u7b80\u5316\u6d41\u7a0b\u5e76\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u91c7\u7528\u5355\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5728\u53d7\u63a7IDE\u73af\u5883\u4e2d\u6574\u5408\u63a2\u7d22\u3001\u5efa\u6a21\u3001\u5b9e\u9a8c\u548c\u90e8\u7f72\u7b49\u6240\u6709MLE\u9636\u6bb5\uff0c\u5b9e\u73b0\u7ebf\u6027\u975e\u963b\u585e\u64cd\u4f5c\u3002", "result": "\u5728MLE-Benchmark\uff082025\uff09\u4e0a\u53d6\u5f97\u65b0SOTA\u7ed3\u679c\uff0c\u6574\u4f53\u5956\u724c\u7387\u4e3a0.3956 \u00b1 0.0565\uff0c\u572875\u4e2a\u95ee\u9898\u4e2d\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u5728\u76f8\u540c\u7ea6\u675f\u6761\u4ef6\u4e0b\uff0c\u53d7\u63a7IDE\u73af\u5883\u4e2d\u7684\u7ebf\u6027\u975e\u963b\u585e\u5355\u667a\u80fd\u4f53\u53ef\u4ee5\u8d85\u8d8a\u591a\u667a\u80fd\u4f53\u548c\u7f16\u6392\u7cfb\u7edf\u3002"}}
{"id": "2510.11552", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.11552", "abs": "https://arxiv.org/abs/2510.11552", "authors": ["Gregoire Passault", "Clement Gaspard", "Olivier Ly"], "title": "Robot Soccer Kit: Omniwheel Tracked Soccer Robots for Education", "comment": null, "summary": "Recent developments of low cost off-the-shelf programmable components, their\nmodularity, and also rapid prototyping made educational robotics flourish, as\nit is accessible in most schools today. They allow to illustrate and embody\ntheoretical problems in practical and tangible applications, and gather\nmultidisciplinary skills. They also give a rich natural context for\nproject-oriented pedagogy. However, most current robot kits all are limited to\negocentric aspect of the robots perception. This makes it difficult to access\nmore high-level problems involving e.g. coordinates or navigation. In this\npaper we introduce an educational holonomous robot kit that comes with an\nexternal tracking system, which lightens the constraint on embedded systems,\nbut allows in the same time to discover high-level aspects of robotics,\notherwise unreachable.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5e26\u6709\u5916\u90e8\u8ddf\u8e2a\u7cfb\u7edf\u7684\u6559\u80b2\u6027\u5168\u5411\u673a\u5668\u4eba\u5957\u4ef6\uff0c\u80fd\u591f\u89e3\u51b3\u73b0\u6709\u673a\u5668\u4eba\u5957\u4ef6\u5c40\u9650\u4e8e\u81ea\u6211\u4e2d\u5fc3\u611f\u77e5\u7684\u95ee\u9898\uff0c\u8ba9\u5b66\u751f\u63a5\u89e6\u66f4\u9ad8\u7ea7\u7684\u673a\u5668\u4eba\u5b66\u6982\u5ff5\u3002", "motivation": "\u73b0\u6709\u6559\u80b2\u673a\u5668\u4eba\u5957\u4ef6\u5927\u591a\u5c40\u9650\u4e8e\u673a\u5668\u4eba\u7684\u81ea\u6211\u4e2d\u5fc3\u611f\u77e5\uff0c\u96be\u4ee5\u8ba9\u5b66\u751f\u63a5\u89e6\u6d89\u53ca\u5750\u6807\u3001\u5bfc\u822a\u7b49\u9ad8\u7ea7\u673a\u5668\u4eba\u5b66\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u5e26\u6709\u5916\u90e8\u8ddf\u8e2a\u7cfb\u7edf\u7684\u5168\u5411\u6559\u80b2\u673a\u5668\u4eba\u5957\u4ef6\uff0c\u51cf\u8f7b\u4e86\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7684\u7ea6\u675f\uff0c\u540c\u65f6\u80fd\u591f\u63a2\u7d22\u9ad8\u7ea7\u673a\u5668\u4eba\u5b66\u6982\u5ff5\u3002", "result": "\u8be5\u5957\u4ef6\u4f7f\u5f97\u5b66\u751f\u80fd\u591f\u63a5\u89e6\u548c\u5b66\u4e60\u539f\u672c\u96be\u4ee5\u8fbe\u5230\u7684\u9ad8\u7ea7\u673a\u5668\u4eba\u5b66\u65b9\u9762\uff0c\u5982\u5750\u6807\u7cfb\u7edf\u548c\u5bfc\u822a\u7b49\u3002", "conclusion": "\u5916\u90e8\u8ddf\u8e2a\u7cfb\u7edf\u7684\u5f15\u5165\u4e3a\u6559\u80b2\u673a\u5668\u4eba\u5b66\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\uff0c\u4f7f\u5b66\u751f\u80fd\u591f\u5728\u51cf\u8f7b\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7ea6\u675f\u7684\u540c\u65f6\u63a2\u7d22\u9ad8\u7ea7\u673a\u5668\u4eba\u5b66\u6982\u5ff5\u3002"}}
{"id": "2211.13003", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2211.13003", "abs": "https://arxiv.org/abs/2211.13003", "authors": ["Md Hasibul Amin", "Harika Madanu", "Sahithi Lavu", "Hadi Mansourifar", "Dana Alsagheer", "Weidong Shi"], "title": "Detecting Conspiracy Theory Against COVID-19 Vaccines", "comment": "6 pages, 5 figures", "summary": "Since the beginning of the vaccination trial, social media has been flooded\nwith anti-vaccination comments and conspiracy beliefs. As the day passes, the\nnumber of COVID- 19 cases increases, and online platforms and a few news\nportals entertain sharing different conspiracy theories. The most popular\nconspiracy belief was the link between the 5G network spreading COVID-19 and\nthe Chinese government spreading the virus as a bioweapon, which initially\ncreated racial hatred. Although some disbelief has less impact on society,\nothers create massive destruction. For example, the 5G conspiracy led to the\nburn of the 5G Tower, and belief in the Chinese bioweapon story promoted an\nattack on the Asian-Americans. Another popular conspiracy belief was that Bill\nGates spread this Coronavirus disease (COVID-19) by launching a mass\nvaccination program to track everyone. This Conspiracy belief creates distrust\nissues among laypeople and creates vaccine hesitancy. This study aims to\ndiscover the conspiracy theory against the vaccine on social platforms. We\nperformed a sentiment analysis on the 598 unique sample comments related to\nCOVID-19 vaccines. We used two different models, BERT and Perspective API, to\nfind out the sentiment and toxicity of the sentence toward the COVID-19\nvaccine.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7BERT\u548cPerspective API\u6a21\u578b\u5bf9598\u6761COVID-19\u75ab\u82d7\u76f8\u5173\u8bc4\u8bba\u8fdb\u884c\u60c5\u611f\u5206\u6790\u548c\u6bd2\u6027\u68c0\u6d4b\uff0c\u65e8\u5728\u53d1\u73b0\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u75ab\u82d7\u9634\u8c0b\u8bba\u3002", "motivation": "\u968f\u7740\u75ab\u82d7\u63a5\u79cd\u8bd5\u9a8c\u5f00\u59cb\uff0c\u793e\u4ea4\u5a92\u4f53\u5145\u65a5\u7740\u53cd\u75ab\u82d7\u8bc4\u8bba\u548c\u9634\u8c0b\u8bba\uff0c\u59825G\u7f51\u7edc\u4f20\u64adCOVID-19\u3001\u4e2d\u56fd\u751f\u7269\u6b66\u5668\u8bba\u7b49\uff0c\u8fd9\u4e9b\u7406\u8bba\u5bfc\u81f4\u4e865G\u5854\u88ab\u70e7\u3001\u4e9a\u88d4\u7f8e\u56fd\u4eba\u53d7\u653b\u51fb\u7b49\u4e25\u91cd\u540e\u679c\uff0c\u5e76\u9020\u6210\u516c\u4f17\u4e0d\u4fe1\u4efb\u548c\u75ab\u82d7\u72b9\u8c6b\u3002", "method": "\u4f7f\u7528BERT\u548cPerspective API\u4e24\u79cd\u4e0d\u540c\u6a21\u578b\uff0c\u5bf9598\u6761\u72ec\u7279\u7684COVID-19\u75ab\u82d7\u76f8\u5173\u8bc4\u8bba\u6837\u672c\u8fdb\u884c\u60c5\u611f\u5206\u6790\u548c\u6bd2\u6027\u68c0\u6d4b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e86\u793e\u4ea4\u5a92\u4f53\u4e0a\u9488\u5bf9\u75ab\u82d7\u7684\u9634\u8c0b\u8bba\u5185\u5bb9\uff0c\u901a\u8fc7\u60c5\u611f\u5206\u6790\u8bc6\u522b\u4e86\u8bc4\u8bba\u7684\u60c5\u611f\u503e\u5411\u548c\u6bd2\u6027\u7a0b\u5ea6\u3002", "conclusion": "\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u9634\u8c0b\u8bba\u5bf9\u516c\u4f17\u5065\u5eb7\u548c\u75ab\u82d7\u63a5\u79cd\u4ea7\u751f\u4e86\u8d1f\u9762\u5f71\u54cd\uff0c\u9700\u8981\u901a\u8fc7\u5206\u6790\u6765\u8bc6\u522b\u548c\u5e94\u5bf9\u8fd9\u4e9b\u6709\u5bb3\u4fe1\u606f\u3002"}}
{"id": "2510.11566", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.11566", "abs": "https://arxiv.org/abs/2510.11566", "authors": ["Kuanning Wang", "Yongchong Gu", "Yuqian Fu", "Zeyu Shangguan", "Sicheng He", "Xiangyang Xue", "Yanwei Fu", "Daniel Seita"], "title": "SCOOP'D: Learning Mixed-Liquid-Solid Scooping via Sim2Real Generative Policy", "comment": "Project page is at https://scoopdiff.github.io/", "summary": "Scooping items with tools such as spoons and ladles is common in daily life,\nranging from assistive feeding to retrieving items from environmental disaster\nsites. However, developing a general and autonomous robotic scooping policy is\nchallenging since it requires reasoning about complex tool-object interactions.\nFurthermore, scooping often involves manipulating deformable objects, such as\ngranular media or liquids, which is challenging due to their\ninfinite-dimensional configuration spaces and complex dynamics. We propose a\nmethod, SCOOP'D, which uses simulation from OmniGibson (built on NVIDIA\nOmniverse) to collect scooping demonstrations using algorithmic procedures that\nrely on privileged state information. Then, we use generative policies via\ndiffusion to imitate demonstrations from observational input. We directly apply\nthe learned policy in diverse real-world scenarios, testing its performance on\nvarious item quantities, item characteristics, and container types. In\nzero-shot deployment, our method demonstrates promising results across 465\ntrials in diverse scenarios, including objects of different difficulty levels\nthat we categorize as \"Level 1\" and \"Level 2.\" SCOOP'D outperforms all\nbaselines and ablations, suggesting that this is a promising approach to\nacquiring robotic scooping skills. Project page is at\nhttps://scoopdiff.github.io/.", "AI": {"tldr": "SCOOP'D\u65b9\u6cd5\u4f7f\u7528\u6a21\u62df\u73af\u5883\u6536\u96c6\u94f2\u53d6\u6f14\u793a\uff0c\u901a\u8fc7\u6269\u6563\u7b56\u7565\u6a21\u4eff\u5b66\u4e60\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u5b9e\u73b0\u96f6\u6837\u672c\u90e8\u7f72\uff0c\u5728465\u6b21\u8bd5\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f00\u53d1\u901a\u7528\u81ea\u4e3b\u673a\u5668\u4eba\u94f2\u53d6\u7b56\u7565\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u5904\u7406\u590d\u6742\u7684\u5de5\u5177-\u7269\u4f53\u4ea4\u4e92\uff0c\u7279\u522b\u662f\u6d89\u53ca\u53ef\u53d8\u5f62\u7269\u4f53\uff08\u5982\u9897\u7c92\u4ecb\u8d28\u6216\u6db2\u4f53\uff09\u65f6\uff0c\u56e0\u5176\u65e0\u9650\u7ef4\u914d\u7f6e\u7a7a\u95f4\u548c\u590d\u6742\u52a8\u529b\u5b66\u800c\u66f4\u52a0\u56f0\u96be\u3002", "method": "\u4f7f\u7528OmniGibson\u6a21\u62df\u5668\u6536\u96c6\u94f2\u53d6\u6f14\u793a\uff0c\u4f9d\u8d56\u7279\u6743\u72b6\u6001\u4fe1\u606f\uff1b\u901a\u8fc7\u6269\u6563\u751f\u6210\u7b56\u7565\u4ece\u89c2\u5bdf\u8f93\u5165\u6a21\u4eff\u6f14\u793a\uff1b\u5728\u771f\u5b9e\u4e16\u754c\u591a\u6837\u5316\u573a\u666f\u4e2d\u76f4\u63a5\u5e94\u7528\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u5728465\u6b21\u96f6\u6837\u672c\u90e8\u7f72\u8bd5\u9a8c\u4e2d\uff0c\u65b9\u6cd5\u5728\u4e0d\u540c\u7269\u54c1\u6570\u91cf\u3001\u7279\u6027\u548c\u5bb9\u5668\u7c7b\u578b\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u5728\"Level 1\"\u548c\"Level 2\"\u96be\u5ea6\u7269\u4f53\u4e0a\u90fd\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u548c\u6d88\u878d\u5b9e\u9a8c\u3002", "conclusion": "SCOOP'D\u662f\u83b7\u53d6\u673a\u5668\u4eba\u94f2\u53d6\u6280\u80fd\u7684\u6709\u524d\u666f\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u62df\u6f14\u793a\u548c\u6269\u6563\u7b56\u7565\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u96f6\u6837\u672c\u8fc1\u79fb\u3002"}}
{"id": "2510.11574", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.11574", "abs": "https://arxiv.org/abs/2510.11574", "authors": ["Lennart Werner", "Pol Eyschen", "Sean Costello", "Pierluigi Micarelli", "Marco Hutter"], "title": "Calibrated Dynamic Modeling for Force and Payload Estimation in Hydraulic Machinery", "comment": null, "summary": "Accurate real-time estimation of end effector interaction forces in hydraulic\nexcavators is a key enabler for advanced automation in heavy machinery.\nAccurate knowledge of these forces allows improved, precise grading and digging\nmaneuvers. To address these challenges, we introduce a high-accuracy,\nretrofittable 2D force- and payload estimation algorithm that does not impose\nadditional requirements on the operator regarding trajectory, acceleration or\nthe use of the slew joint. The approach is designed for retrofittability,\nrequires minimal calibration and no prior knowledge of machine-specific dynamic\ncharacteristics. Specifically, we propose a method for identifying a dynamic\nmodel, necessary to estimate both end effector interaction forces and bucket\npayload during normal operation. Our optimization-based payload estimation\nachieves a full-scale payload accuracy of 1%. On a standard 25 t excavator, the\nonline force measurement from pressure and inertial measurements achieves a\ndirection accuracy of 13 degree and a magnitude accuracy of 383 N. The method's\naccuracy and generalization capability are validated on two excavator platforms\nof different type and weight classes. We benchmark our payload estimation\nagainst a classical quasistatic method and a commercially available system. Our\nsystem outperforms both in accuracy and precision.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6db2\u538b\u6316\u6398\u673a\u7684\u9ad8\u7cbe\u5ea6\u3001\u53ef\u6539\u9020\u76842D\u529b\u548c\u6709\u6548\u8f7d\u8377\u4f30\u8ba1\u7b97\u6cd5\uff0c\u65e0\u9700\u989d\u5916\u64cd\u4f5c\u8981\u6c42\uff0c\u901a\u8fc7\u52a8\u6001\u6a21\u578b\u8bc6\u522b\u5b9e\u73b0\u672b\u7aef\u6267\u884c\u5668\u4ea4\u4e92\u529b\u548c\u94f2\u6597\u6709\u6548\u8f7d\u8377\u7684\u5b9e\u65f6\u4f30\u8ba1\u3002", "motivation": "\u51c6\u786e\u4f30\u8ba1\u6db2\u538b\u6316\u6398\u673a\u672b\u7aef\u6267\u884c\u5668\u7684\u4ea4\u4e92\u529b\u662f\u5b9e\u73b0\u91cd\u578b\u673a\u68b0\u9ad8\u7ea7\u81ea\u52a8\u5316\u7684\u5173\u952e\uff0c\u6709\u52a9\u4e8e\u6539\u8fdb\u7cbe\u786e\u7684\u5e73\u6574\u548c\u6316\u6398\u64cd\u4f5c\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4f18\u5316\u7684\u6709\u6548\u8f7d\u8377\u4f30\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u538b\u529b\u548c\u60ef\u6027\u6d4b\u91cf\u5728\u7ebf\u4f30\u8ba1\u529b\uff0c\u8bc6\u522b\u52a8\u6001\u6a21\u578b\uff0c\u65e0\u9700\u673a\u5668\u7279\u5b9a\u7684\u52a8\u6001\u7279\u6027\u5148\u9a8c\u77e5\u8bc6\u3002", "result": "\u5728\u6807\u51c625\u5428\u6316\u6398\u673a\u4e0a\uff0c\u6709\u6548\u8f7d\u8377\u4f30\u8ba1\u8fbe\u52301%\u7684\u5168\u91cf\u7a0b\u7cbe\u5ea6\uff0c\u529b\u6d4b\u91cf\u5b9e\u73b013\u5ea6\u7684\u65b9\u5411\u7cbe\u5ea6\u548c383N\u7684\u5e45\u5ea6\u7cbe\u5ea6\uff0c\u5728\u4e24\u4e2a\u4e0d\u540c\u7c7b\u578b\u548c\u91cd\u91cf\u7b49\u7ea7\u7684\u6316\u6398\u673a\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5728\u51c6\u786e\u6027\u548c\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u7ecf\u5178\u7684\u51c6\u9759\u6001\u65b9\u6cd5\u548c\u5546\u4e1a\u53ef\u7528\u7cfb\u7edf\uff0c\u5c55\u793a\u4e86\u9ad8\u7cbe\u5ea6\u7684\u529b\u548c\u6709\u6548\u8f7d\u8377\u4f30\u8ba1\u80fd\u529b\u3002"}}
{"id": "2510.11660", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11660", "abs": "https://arxiv.org/abs/2510.11660", "authors": ["Yi Yang", "Kefan Gu", "Yuqing Wen", "Hebei Li", "Yucheng Zhao", "Tiancai Wang", "Xudong Liu"], "title": "ManiAgent: An Agentic Framework for General Robotic Manipulation", "comment": "8 pages, 6 figures, conference", "summary": "While Vision-Language-Action (VLA) models have demonstrated impressive\ncapabilities in robotic manipulation, their performance in complex reasoning\nand long-horizon task planning is limited by data scarcity and model capacity.\nTo address this, we introduce ManiAgent, an agentic architecture for general\nmanipulation tasks that achieves end-to-end output from task descriptions and\nenvironmental inputs to robotic manipulation actions. In this framework,\nmultiple agents involve inter-agent communication to perform environmental\nperception, sub-task decomposition and action generation, enabling efficient\nhandling of complex manipulation scenarios. Evaluations show ManiAgent achieves\nan 86.8% success rate on the SimplerEnv benchmark and 95.8% on real-world\npick-and-place tasks, enabling efficient data collection that yields VLA models\nwith performance comparable to those trained on human-annotated datasets.The\nproject webpage is available at https://yi-yang929.github.io/ManiAgent/.", "AI": {"tldr": "ManiAgent\u662f\u4e00\u4e2a\u7528\u4e8e\u901a\u7528\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u7684\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u95f4\u7684\u901a\u4fe1\u5b9e\u73b0\u73af\u5883\u611f\u77e5\u3001\u5b50\u4efb\u52a1\u5206\u89e3\u548c\u52a8\u4f5c\u751f\u6210\uff0c\u5728\u590d\u6742\u64cd\u4f5c\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u548c\u957f\u65f6\u7a0b\u4efb\u52a1\u89c4\u5212\u65b9\u9762\u53d7\u9650\u4e8e\u6570\u636e\u7a00\u7f3a\u548c\u6a21\u578b\u5bb9\u91cf\uff0c\u9700\u8981\u65b0\u7684\u67b6\u6784\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51faManiAgent\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u91c7\u7528\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u65b9\u5f0f\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u95f4\u901a\u4fe1\u8fdb\u884c\u73af\u5883\u611f\u77e5\u3001\u5b50\u4efb\u52a1\u5206\u89e3\u548c\u52a8\u4f5c\u751f\u6210\uff0c\u5b9e\u73b0\u4ece\u4efb\u52a1\u63cf\u8ff0\u5230\u673a\u5668\u4eba\u64cd\u4f5c\u7684\u7aef\u5230\u7aef\u8f93\u51fa\u3002", "result": "\u5728SimplerEnv\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523086.8%\u7684\u6210\u529f\u7387\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u62fe\u53d6\u653e\u7f6e\u4efb\u52a1\u4e2d\u8fbe\u523095.8%\u7684\u6210\u529f\u7387\uff0c\u80fd\u591f\u9ad8\u6548\u6536\u96c6\u6570\u636e\u8bad\u7ec3\u51fa\u4e0e\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6\u6027\u80fd\u76f8\u5f53\u7684VLA\u6a21\u578b\u3002", "conclusion": "ManiAgent\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u548c\u89c4\u5212\u95ee\u9898\uff0c\u4e3aVLA\u6a21\u578b\u7684\u6570\u636e\u6536\u96c6\u548c\u6027\u80fd\u63d0\u5347\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2510.11689", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11689", "abs": "https://arxiv.org/abs/2510.11689", "authors": ["Maggie Wang", "Stephen Tian", "Aiden Swann", "Ola Shorinwa", "Jiajun Wu", "Mac Schwager"], "title": "Phys2Real: Fusing VLM Priors with Interactive Online Adaptation for Uncertainty-Aware Sim-to-Real Manipulation", "comment": null, "summary": "Learning robotic manipulation policies directly in the real world can be\nexpensive and time-consuming. While reinforcement learning (RL) policies\ntrained in simulation present a scalable alternative, effective sim-to-real\ntransfer remains challenging, particularly for tasks that require precise\ndynamics. To address this, we propose Phys2Real, a real-to-sim-to-real RL\npipeline that combines vision-language model (VLM)-inferred physical parameter\nestimates with interactive adaptation through uncertainty-aware fusion. Our\napproach consists of three core components: (1) high-fidelity geometric\nreconstruction with 3D Gaussian splatting, (2) VLM-inferred prior distributions\nover physical parameters, and (3) online physical parameter estimation from\ninteraction data. Phys2Real conditions policies on interpretable physical\nparameters, refining VLM predictions with online estimates via ensemble-based\nuncertainty quantification. On planar pushing tasks of a T-block with varying\ncenter of mass (CoM) and a hammer with an off-center mass distribution,\nPhys2Real achieves substantial improvements over a domain randomization\nbaseline: 100% vs 79% success rate for the bottom-weighted T-block, 57% vs 23%\nin the challenging top-weighted T-block, and 15% faster average task completion\nfor hammer pushing. Ablation studies indicate that the combination of VLM and\ninteraction information is essential for success. Project website:\nhttps://phys2real.github.io/ .", "AI": {"tldr": "Phys2Real\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u771f\u5b9e\u5230\u4eff\u771f\u518d\u5230\u771f\u5b9e\u7684\u5f3a\u5316\u5b66\u4e60\u6d41\u7a0b\uff0c\u901a\u8fc7\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63a8\u65ad\u7269\u7406\u53c2\u6570\u5e76\u7ed3\u5408\u4ea4\u4e92\u5f0f\u81ea\u9002\u5e94\uff0c\u89e3\u51b3\u4e86\u4eff\u771f\u5230\u771f\u5b9e\u73af\u5883\u8fc1\u79fb\u7684\u6311\u6218\u3002", "motivation": "\u76f4\u63a5\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u5b66\u4e60\u673a\u5668\u4eba\u64cd\u4f5c\u7b56\u7565\u6210\u672c\u9ad8\u6602\u4e14\u8017\u65f6\uff0c\u800c\u4eff\u771f\u8bad\u7ec3\u7684\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u867d\u7136\u53ef\u6269\u5c55\uff0c\u4f46\u5728\u9700\u8981\u7cbe\u786e\u52a8\u529b\u5b66\u7684\u4efb\u52a1\u4e2d\uff0c\u6709\u6548\u7684\u4eff\u771f\u5230\u771f\u5b9e\u8fc1\u79fb\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "Phys2Real\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a(1) \u4f7f\u75283D\u9ad8\u65af\u6e85\u5c04\u8fdb\u884c\u9ad8\u4fdd\u771f\u51e0\u4f55\u91cd\u5efa\uff1b(2) \u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63a8\u65ad\u7269\u7406\u53c2\u6570\u7684\u5148\u9a8c\u5206\u5e03\uff1b(3) \u4ece\u4ea4\u4e92\u6570\u636e\u4e2d\u8fdb\u884c\u5728\u7ebf\u7269\u7406\u53c2\u6570\u4f30\u8ba1\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u96c6\u6210\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u5c06\u7b56\u7565\u5efa\u7acb\u5728\u53ef\u89e3\u91ca\u7684\u7269\u7406\u53c2\u6570\u4e0a\u3002", "result": "\u5728\u5177\u6709\u4e0d\u540c\u8d28\u5fc3\u7684T\u5f62\u5757\u5e73\u9762\u63a8\u52a8\u4efb\u52a1\u548c\u5177\u6709\u504f\u5fc3\u8d28\u91cf\u5206\u5e03\u7684\u9524\u5b50\u63a8\u52a8\u4efb\u52a1\u4e2d\uff0cPhys2Real\u76f8\u6bd4\u9886\u57df\u968f\u673a\u5316\u57fa\u7ebf\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff1a\u5e95\u90e8\u52a0\u91cdT\u5f62\u5757\u6210\u529f\u7387100% vs 79%\uff0c\u6311\u6218\u6027\u9876\u90e8\u52a0\u91cdT\u5f62\u5757\u6210\u529f\u738757% vs 23%\uff0c\u9524\u5b50\u63a8\u52a8\u4efb\u52a1\u5e73\u5747\u5b8c\u6210\u65f6\u95f4\u5feb15%\u3002", "conclusion": "\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548c\u4ea4\u4e92\u4fe1\u606f\u7684\u7ed3\u5408\u5bf9\u4e8e\u6210\u529f\u81f3\u5173\u91cd\u8981\u3002Phys2Real\u901a\u8fc7\u5c06\u53ef\u89e3\u91ca\u7684\u7269\u7406\u53c2\u6570\u4e0e\u5728\u7ebf\u4f30\u8ba1\u76f8\u7ed3\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4eff\u771f\u5230\u771f\u5b9e\u8fc1\u79fb\u7684\u6311\u6218\u3002"}}
