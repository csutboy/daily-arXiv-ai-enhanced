<div id=toc></div>

# Table of Contents

- [econ.GN](#econ.GN) [Total: 5]
- [econ.TH](#econ.TH) [Total: 5]
- [cs.ET](#cs.ET) [Total: 1]
- [stat.AP](#stat.AP) [Total: 8]
- [econ.EM](#econ.EM) [Total: 2]
- [cs.CY](#cs.CY) [Total: 11]
- [cs.SI](#cs.SI) [Total: 2]
- [cs.AI](#cs.AI) [Total: 41]
- [cs.RO](#cs.RO) [Total: 28]
- [eess.SY](#eess.SY) [Total: 21]


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [1] [Big Wins, Small Net Gains: Direct and Spillover Effects of First Industry Entries in Puerto Rico](https://arxiv.org/abs/2511.19469)
*Jorge A. Arroyo*

Main category: econ.GN

TL;DR: 研究首次大规模产业进入如何重塑波多黎各本地及邻近劳动力市场，发现直接就业和工资增长显著但区域净效应较小，强调空间溢出效应在评估地方政策时的重要性。


<details>
  <summary>Details</summary>
Motivation: 探究首次大规模产业进入对当地和邻近劳动力市场的重塑作用，特别关注空间溢出效应，为评估地方产业政策提供实证依据。

Method: 使用2014Q1-2025Q1季度市政-产业数据，结合交错采用DID估计器、基于插补的事件研究方法和双重稳健DID框架，考虑邻接图上的空间干扰。

Result: 受处理市政-产业单元在0-16季度内就业和工资显著增长，同行业邻近地区短期增长但中期逆转，跨行业和全行业溢出效应小且不精确。

Conclusion: 首次大规模产业进入产生显著的本地收益，但区域净就业增长较小且不确定性高，评估地方政策时必须考虑空间溢出效应。

Abstract: I study how first sizable industry entries reshape local and neighboring labor markets in Puerto Rico. Using over a decade of quarterly municipality--industry data (2014Q1--2025Q1), I identify ``first sizable entries'' as large, persistent jumps in establishments, covered employment, and wage bill, and treat these as shocks to local industry presence at the municipio--industry level. Methodologically, I combine staggered-adoption difference-in-differences estimators that are robust to heterogeneous treatment timing with an imputation-based event-study approach, and I use a doubly robust difference-in-differences framework that explicitly allows for interference through pre-specified exposure mappings on a contiguity graph. The estimates show large and persistent direct gains in covered employment and wage bill in the treated municipality--industry cells over 0--16 quarters. Same-industry neighbors experience sizable short-run gains that reverse over the medium run, while within-municipality cross-industry and neighbor all-industries spillovers are small and imprecisely estimated. Once these spillovers are taken into account and spatially robust inference and sensitivity checks are applied, the net regional 0--16 quarter effect on covered employment is positive but modest in magnitude and estimated with considerable uncertainty. The results imply that first sizable entries generate substantial local gains where they occur, but much smaller and less precisely measured net employment gains for the broader regional economy, highlighting the importance of accounting for spatial spillovers when evaluating place-based policies.

</details>


### [2] [Cash Transfers in the Perinatal Period and Child Welfare System Involvement Among Infants: Evidence from the Rx Kids Program in Flint, Michigan](https://arxiv.org/abs/2511.19570)
*Sumit Agarwal,H. Luke Shaefer,Samiul Jubaed,William Schneider,Eric Finegood,Mona Hanna*

Main category: econ.GN

TL;DR: 密歇根州弗林特市实施的Rx Kids无条件现金转移计划显著降低了婴儿虐待指控率，与对照组相比减少了7个百分点（32%相对减少）。


<details>
  <summary>Details</summary>
Motivation: 婴儿是儿童虐待最脆弱的群体，这可能部分与围产期经济不稳定有关。研究旨在评估无条件现金转移对预防儿童虐待的影响。

Method: 使用合成双重差分法，比较弗林特市在Rx Kids计划实施前后6个月内婴儿虐待指控率的变化，并与无该计划的对照城市进行对比。

Result: Rx Kids实施后，弗林特市婴儿虐待指控率从21.7%降至15.5%，而对照组从19.5%升至20.6%。该计划与7.0个百分点的显著减少相关（p=0.021），相当于干预前水平的32%减少。

Conclusion: Rx Kids产前和婴儿现金处方计划显著减少了婴儿虐待指控，为经济稳定在预防儿童福利系统介入中的作用提供了重要证据。

Abstract: Infants are most vulnerable to child maltreatment, which may be due in part to economic instability during the perinatal period. In 2024, Rx Kids was launched in Flint, Michigan, achieving near 100% aggregate take up and providing every expectant mother with unconditional cash transfers during pregnancy and infancy. Synthetic difference-in-differences was used to compare changes in allegations of maltreatment within the first six months of life in Flint before and after implementation of Rx Kids relative to the corresponding change in control cities without the program. In the three years prior to the implementation of Rx Kids, the proportion of infants with a maltreatment allegation within the first six months of life was 21.7% in Flint and 19.5% among control cities. After implementation of Rx Kids in 2024, the maltreatment allegation rate dropped to 15.5% in Flint, falling below the maltreatment allegation rate of 20.6% among the control cities. Rx Kids was associated with a statistically significant 7.0 percentage-point decrease in the maltreatment allegation rate (p = 0.021), corresponding to a 32% decrease relative to the pre-intervention period. There was a decrease in the rate of neglect-related, non-neglect-related, and substantiated allegations; these were directionally consistent with the primary outcome but not statistically significant. Results were robust to alternative model specifications. The Rx Kids prenatal and infant cash prescription program led to a significant reduction in allegations of maltreatment among infants. These findings provide important evidence about the role of economic stability in preventing child welfare system involvement.

</details>


### [3] [Total Factor Productivity and its determinants: an analysis of the relationship at firm level through unsupervised learning techniques](https://arxiv.org/abs/2511.19627)
*Paolo Pedotti*

Main category: econ.GN

TL;DR: 使用无监督学习技术识别企业全要素生产率的关键决定因素，发现盈利能力、信贷/债务指标、成本与资本效率以及研发活动是主要影响因素。


<details>
  <summary>Details</summary>
Motivation: 解决企业异质性问题，通过自下而上的方法重新审视企业标准分类，识别影响企业全要素生产率的关键特征。

Method: 使用无监督学习技术（主成分分析、自组织映射、聚类），基于ORBIS数据库的大样本数据，分析2015-2019年和2020年两个时期。

Result: 在两个时期中，生产率增长的主要决定因素都与盈利能力、信贷/债务指标、成本与资本效率以及研发活动相关。

Conclusion: 发现了决定因素与生产率增长之间的线性关系，为理解企业生产率提供了新的分析框架。

Abstract: The paper is related to the identification of firm's features which serve as determinants for firm's total factor productivity through unsupervised learning techniques (principal component analysis, self organizing maps, clustering). This bottom-up approach can effectively manage the problem of the heterogeneity of the firms and provides new ways to look at firms' standard classifications. Using the large sample provided by the ORBIS database, the analyses covers the years before the outbreak of Covid-19 (2015-2019) and the immediate post-Covid period (year 2020). It has been shown that in both periods, the main determinants of productivity growth are related to profitability, credit/debts measures, cost and capital efficiency, and effort and outcome of the R&D activity conducted by the firms. Finally, a linear relationship between determinants and productivity growth has been found.

</details>


### [4] [Spiral of Silence: How Neutral Moderation Polarizes Content Creation](https://arxiv.org/abs/2511.19680)
*Ying Bao,Jessie Liu*

Main category: econ.GN

TL;DR: 内容审核在意识形态多元的在线环境中如何影响内容创作，即使中立地针对毒性内容，也可能抑制非毒性内容创作，特别是来自意识形态少数群体的创作。


<details>
  <summary>Details</summary>
Motivation: 研究内容审核在意识形态多元在线环境中的影响，探讨即使中立审核毒性内容，如何可能无意中抑制非毒性内容创作，特别是意识形态少数群体的创作。

Method: 开发一个模型，用户既是创作者也是消费者，具有不同的意识形态归属和产生毒性内容的倾向，分析情感极化与内容审核的相互作用。

Result: 即使针对毒性的意识形态中立审核也会抑制非毒性内容创作，特别是来自意识形态少数群体；内容移除产生外部性，非毒性内容获得更多曝光，但多数群体创作者不内化负面溢出效应，导致少数群体创作减少和内容供应极化。

Conclusion: 内容审核中的偏见不一定反映规则偏见，而是可能作为均衡中的自我审查内生出现；内容个性化与审核政策的相互作用需要进一步探索。

Abstract: This paper investigates how content moderation affects content creation in an ideologically diverse online environments. We develop a model in which users act as both creators and consumers, differing in their ideological affiliation and propensity to produce toxic content. Affective polarization, i.e., users' aversion to ideologically opposed content, interacts with moderation in unintended ways. We show that even ideologically neutral moderation that targets only toxicity can suppress non-toxic content creation, particularly from ideological minorities. Our analysis reveals a content-level externality: when toxic content is removed, non-toxic posts gain exposure. While creators from the ideological majority group sometimes benefit from this exposure, they do not internalize the negative spillovers, i.e., increased out-group animosity toward minority creators. This can discourage minority creation and polarize the content supply, ultimately leaving minority users in a more ideologically imbalanced environment: a mechanism reminiscent of the "spiral of silence." Thus, our model offers an alternative perspective to a common debate: what appears as bias in moderation needs not reflect bias in rules, but can instead emerge endogenously as self-censorship in equilibrium. We also extend the model to explore how content personalization interacts with moderation policies.

</details>


### [5] [Solving Heterogeneous Agent Models with Physics-informed Neural Networks](https://arxiv.org/abs/2511.20283)
*Marta Grzeskiewicz*

Main category: econ.GN

TL;DR: 本文提出了一种基于物理信息神经网络(PINNs)的ABH-PINN求解器，用于解决连续时间异质代理人模型的计算挑战，替代传统的网格求解方法。


<details>
  <summary>Details</summary>
Motivation: 异质代理人模型比代表性代理人框架更现实，但在连续时间下存在显著计算挑战。传统的网格求解器面临维度诅咒、高计算成本和数值不准确等问题。

Method: 使用物理信息神经网络(PINNs)，将Hamilton-Jacobi-Bellman和Kolmogorov Forward方程直接嵌入神经网络训练目标，用无网格、可微分函数学习替代网格近似。

Result: 初步结果显示，基于PINN的方法能够获得经济上有效的结果，与已建立的有限差分求解器相匹配。

Conclusion: ABH-PINN求解器具有改进的可扩展性、更平滑的解决方案和计算效率等PINNs优势，为异质代理人模型提供了有前景的求解方法。

Abstract: Understanding household behaviour is essential for modelling macroeconomic dynamics and designing effective policy. While heterogeneous agent models offer a more realistic alternative to representative agent frameworks, their implementation poses significant computational challenges, particularly in continuous time. The Aiyagari-Bewley-Huggett (ABH) framework, recast as a system of partial differential equations, typically relies on grid-based solvers that suffer from the curse of dimensionality, high computational cost, and numerical inaccuracies. This paper introduces the ABH-PINN solver, an approach based on Physics-Informed Neural Networks (PINNs), which embeds the Hamilton-Jacobi-Bellman and Kolmogorov Forward equations directly into the neural network training objective. By replacing grid-based approximation with mesh-free, differentiable function learning, the ABH-PINN solver benefits from the advantages of PINNs of improved scalability, smoother solutions, and computational efficiency. Preliminary results show that the PINN-based approach is able to obtain economically valid results matching the established finite-difference solvers.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [6] [Dynamic Mechanism Collapse: A Boundary Characterization](https://arxiv.org/abs/2511.19781)
*Xiaopeng Zeng,Erbao Cao,Xiangqian Yang*

Main category: econ.TH

TL;DR: 本文研究在贝叶斯环境中，当存在公共信号且无跨期承诺时，卖方如何随时间分配一次性资源。给出了最优动态机制退化为简单终端设计的充要条件：在日期0进行单一公共实验，然后在确定日期执行后验依赖的静态机制，无需进一步披露。


<details>
  <summary>Details</summary>
Motivation: 研究在什么条件下动态机制具有价值，以及何时最优动态机制可以简化为简单的终端设计，从而避免复杂的动态披露过程。

Method: 结合信念空间上的鞅凹化与凹包络的仿射支撑对偶，通过存在全局仿射影子价值来支持后验收益前沿并统一约束所有历史依赖收益。

Result: 当存在全局仿射影子价值时，最优动态机制退化为简单终端设计；当该条件不满足时，崩溃统计量能识别产生真正动态价值的日期和公共状态变量。

Conclusion: 通过仿射支撑对偶和鞅凹化的结合，为动态机制设计提供了简洁的充要条件，揭示了动态价值产生的关键因素。

Abstract: When are dynamics valuable? In Bayesian environments with public signals and no intertemporal commitment, we study a seller who allocates an economically single-shot resource over time. We provide necessary and sufficient conditions under which the optimal dynamic mechanism collapses to a simple terminal design: a single public experiment at date 0 followed by a posterior-dependent static mechanism executed at a deterministic date, with no further disclosure. The key condition is the existence of a global affine shadow value that supports the posterior-based revenue frontier and uniformly bounds all history-dependent revenues. When this condition fails, a collapse statistic pinpoints the dates and public state variables that generate genuine dynamic value. The characterization combines martingale concavification on the belief space with an affine-support duality for concave envelopes.

</details>


### [7] [Expectation-enforcing strategies for repeated games](https://arxiv.org/abs/2511.19828)
*Nikos Dimou,Alex McAvoy*

Main category: econ.TH

TL;DR: 本文为零行列式策略理论提供了通用框架，在折扣重复博弈中建立了任意线性或非线性收益关系的强制执行条件，并证明简单两点反应式学习策略即可实现所有可执行关系。


<details>
  <summary>Details</summary>
Motivation: 虽然零行列式策略在无限期博弈中已被广泛研究，但在折扣博弈、非线性收益关系、复杂战略环境和长记忆行为方面的扩展仍不完善。本文旨在填补这一空白。

Method: 建立了折扣博弈中任意收益关系强制执行的必要和充分条件，证明所有可执行关系都能通过简单的两点反应式学习策略实现，该策略仅依赖对手最近行动和玩家自身先前混合行动。

Result: 确定了可执行收益关系的精确特征，证明了简单反应式策略的通用性，并在多个博弈模型中具体分析了敲诈、慷慨、均衡和公平策略的可执行条件。

Conclusion: 本文为折扣重复博弈中的收益关系强制执行提供了完整理论框架，证明了简单策略的普遍适用性，并精确刻画了各类策略在多种博弈环境中的可执行条件。

Abstract: Originating in evolutionary game theory, the class of "zero-determinant" strategies enables a player to unilaterally enforce linear payoff relationships in simple repeated games. An upshot of this kind of payoff constraint is that it can shape the incentives for the opponent in a predetermined way. An example is when a player ensures that the agents get equal payoffs. While extensively studied in infinite-horizon games, extensions to discounted games, nonlinear payoff relationships, richer strategic environments, and behaviors with long memory remain incompletely understood. In this paper, we provide necessary and sufficient conditions for a player to enforce arbitrary payoff relationships (linear or nonlinear), in expectation, in discounted games. These conditions characterize precisely which payoff relationships are enforceable using strategies of arbitrary complexity. Our main result establishes that any such enforceable relationship can actually be implemented using a simple two-point reactive learning strategy, which conditions on the opponent's most recent action and the player's own previous mixed action, using information from only one round into the past. For additive payoff constraints, we show that enforcement is possible using even simpler (reactive) strategies that depend solely on the opponent's last move. In other words, this tractable class is universal within expectation-enforcing strategies. As examples, we apply these results to characterize extortionate, generous, equalizer, and fair strategies in the iterated prisoner's dilemma, asymmetric donation game, nonlinear donation game, and the hawk-dove game, identifying precisely when each class of strategy is enforceable and with what minimum discount factor.

</details>


### [8] [Dynamic Reward Design](https://arxiv.org/abs/2511.19838)
*Yijun Liu*

Main category: econ.TH

TL;DR: 该论文研究了一个动态筛选模型，其中委托人雇佣具有有限责任的代理人。代理人的工作成本是独立同分布的随机变量，工作状态可公开观察。最优机制不独立处理每个时期，而是采用延迟支付并要求代理人连续工作。


<details>
  <summary>Details</summary>
Motivation: 研究在有限责任约束下，当代理人工作成本独立同分布且跨期收益可加时，最优机制是否应该独立处理每个时期，以及如何设计激励机制。

Method: 构建动态筛选模型，分析有限责任约束下的最优机制设计，推导出最优支付方案和工作安排的特征。

Result: 发现最优机制不独立处理每个时期，而是采用延迟支付策略，并要求代理人一旦开始工作就必须连续工作直到结束。在某些条件下允许代理人灵活选择开始工作时间，但一旦开始就必须连续工作。

Conclusion: 即使在成本独立同分布和收益可加的情况下，有限责任约束使得最优机制必须跨期关联，通过延迟支付和连续工作要求来提供有效激励。

Abstract: This paper studies a dynamic screening model in which a principal hires an agent with limited liability. The agent's private cost of working is an i.i.d. draw from a continuous distribution. His working status is publicly observable. The limited liability constraint requires that payments remain nonnegative at all times. In this setting, despite costs being i.i.d. and the payoffs being additively separable across periods, the optimal mechanism does not treat each period independently. Instead, it features backloading payments and requires the agent to work in consecutive periods. Specifically, I characterize conditions under which the optimal mechanism either grants the agent flexibility to start working in any period or restricts the starting period to the first. In either case, once the agent begins working, he is incentivized to work consecutively until the end.

</details>


### [9] [Reserve System with Beneficiary-Share Guarantee](https://arxiv.org/abs/2511.20077)
*Yuan Gao,Xi Jin,Manshu Khanna*

Main category: econ.TH

TL;DR: 本文研究了具有最低受益者份额保证的分配系统，分析了目标匹配与总匹配最大化之间的权衡关系，并刻画了完整的非支配前沿。


<details>
  <summary>Details</summary>
Motivation: 研究具有受益者份额保证的分配问题，这类政策虽然能促进目标匹配，但会与最大化总匹配产生内在冲突，需要系统性地分析这种权衡关系。

Method: 使用最小循环来刻画完整的非支配前沿，开发了重复匈牙利算法在多项式时间内计算所有前沿点，并分析了机制设计属性。

Result: 发现前沿具有凹结构和单调递减斜率，从最大目标匹配到最大总匹配的转换最多减少一半匹配，机制可以尊重类别依赖优先级但必然违反路径独立性。

Conclusion: 这些结果为在不同分配背景下严格评估受益者份额政策提供了理论基础和分析工具。

Abstract: We study allocation problems with reserve systems under minimum beneficiary-share guarantees, requirements that targeted matches constitute at least a specified percentage of total matches. While such mandates promote targeted matches, they inherently conflict with maximizing total matches. We characterize the complete non-domination frontier using minimal cycles, where each point represents an allocation that cannot increase targeted matches without sacrificing total matches. Our main results: (i) the frontier exhibits concave structure with monotonically decreasing slope, (ii) traversing from maximum targeted matches to maximum total matches reduces matches by at most half, (iii) the Repeated Hungarian Algorithm computes all frontier points in polynomial time, and (iv) mechanisms with beneficiary-share guarantees can respect category-dependent priority orderings but necessarily violate path-independence. These results enable rigorous evaluation of beneficiary-share policies across diverse allocation contexts.

</details>


### [10] [Recursive contracts in non-convex environments](https://arxiv.org/abs/2511.20303)
*Chengfeng Shen,Felix Kübler,Zhennan Zhou*

Main category: econ.TH

TL;DR: 本文研究了具有前瞻性约束的非凸动态优化问题，证明了在假设规划者可以使用公共随机化设备且前瞻性约束只需在期望中成立的情况下，递归乘子公式给出最优值。


<details>
  <summary>Details</summary>
Motivation: 研究非凸动态优化问题中前瞻性约束的处理方法，探讨随机化在解决此类问题中的作用。

Method: 使用递归乘子公式，分析sup-inf和inf-sup问题表述对最优彩票时机和约束期望值的影响，提供从函数方程解中恢复最优策略的一般方法。

Result: 证明了在公共随机化设备和期望约束条件下，递归乘子公式能给出最优值，并展示了彩票在某些经济问题中的必要性。

Conclusion: 彩票的使用对于某些经济问题的优化解是必要的，特别是在Ramsey最优政府政策问题中，彩票在最优解中起着关键作用。

Abstract: In this paper we examine non-convex dynamic optimization problems with forward looking constraints. We prove that the recursive multiplier formulation in \cite{marcet2019recursive} gives the optimal value if one assumes that the planner has access to a public randomization device and forward looking constraints only have to hold in expectations. Whether one formulates the functional equation as a sup-inf problem or as an inf-sup problem is essential for the timing of the optimal lottery and for determining which constraints have to hold in expectations. We discuss for which economic problems the use of lotteries can be considered a reasonable assumption. We provide a general method to recover the optimal policy from a solution of the functional equation. As an application of our results, we consider the Ramsey problem of optimal government policy and give examples where lotteries are essential for the optimal solution.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [11] [An End-to-End Distributed Quantum Circuit Simulator](https://arxiv.org/abs/2511.19791)
*Sen Zhang,Lingjun Xiong,Yipie Liu,Brian L. Mark,Lei Yang,Zebo Yang,Weiwen Jiang*

Main category: cs.ET

TL;DR: SimDisQ是首个端到端的电路级分布式量子计算模拟器，填补了量子软件生态中缺乏能够模拟异构后端、噪声连接和分布式执行的模拟器的空白。


<details>
  <summary>Details</summary>
Motivation: 分布式量子计算（DQC）是扩展量子计算规模的重要途径，但目前成熟的DQC平台尚不可用，研究人员需要评估DQC的优势和新兴设计，但现有软件生态系统缺乏能够模拟异构后端、噪声连接和分布式执行的电路级模拟器。

Method: 提出SimDisQ模拟器，包含一套新颖的DQC导向自动化模拟工具包和通信噪声模型，能够与主流量子软件生态系统中的现有工具包互操作。

Result: 基准测试实验回答了社区中的几个开放性问题，例如在合理的纠缠分布保真度下，超导和囚禁离子量子位的噪声模拟显示异构量子处理单元确实能够产生更高的执行保真度。

Conclusion: SimDisQ为分布式量子计算提供了定量探索架构设计权衡、通信保真度约束以及DQC引入的新电路优化挑战的基础，为这一有前景方向的研究奠定了基础。

Abstract: Quantum computing has made substantial progress in recent years; however, its scalability remains constrained on a monolithic quantum processing unit (QPU). Distributed quantum computing (DQC) offers a pathway by coordinating multiple QPUs to execute large-scale circuits. Yet, DQC still faces practical barriers, as its realization depends on advances in hardware-level components such as quantum transducers and high-fidelity entanglement-distribution modules. While these technologies continue to improve, mature DQC platforms remain unavailable. In the meantime, researchers need to assess the benefits of DQC and evaluate emerging DQC designs, but the software ecosystem lacks a circuit-level simulator that models heterogeneous backends, noisy connections, and distributed execution. To fill this gap, this paper proposes SimDisQ, the first end-to-end circuit-level DQC simulator, composed of a set of novel DQC-oriented automated simulation toolkits and communication noise models that can interoperate with existing toolkits in mainstream quantum software ecosystems. Leveraging circuit-level simulation capabilities, SimDisQ enables quantitative exploration of architectural design trade-offs, communication fidelity constraints, and new circuit optimization challenges introduced by DQC, providing a foundation for future research in this promising direction. Benchmarking experiments using SimDisQ respond to a couple of open questions in the community; for example, noisy simulation of superconducting and trapped-ion qubits, with a reasonable entanglement-distribution fidelity, reveal that heterogeneous QPUs can indeed yield higher execution fidelity.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [12] [Beyond the ACE Score: Replicable Combinations of Adverse Childhood Experiences That Worsen Depression Risk](https://arxiv.org/abs/2511.19574)
*Ruizhe Zhang,Jooyoung Kong,Dylan S. Small,William Bekerman*

Main category: stat.AP

TL;DR: 本研究开发了一种数据轮换框架，识别可复现的童年不良经历组合模式，相比传统的ACE总分筛查方法，能更准确地识别成人抑郁症高风险人群。


<details>
  <summary>Details</summary>
Motivation: 传统的童年不良经历单一累加评分方法在个体层面判别能力较差，需要开发更精确的筛查方法来识别真正的高风险人群，以优化临床筛查资源配置。

Method: 采用数据轮换框架结合等渗子组选择方法，在单调性假设下识别高风险子组，使用频率编码保留ACE强度信息，控制家庭错误率。

Result: 在BRFSS 2022数据上验证，在相同特异性水平下，相比ACE总分截断法，新方法的敏感性提高了26%，能更有效地识别抑郁症高风险人群。

Conclusion: 基于模式的可复现高风险子组筛查方法比传统ACE总分筛查更有效，提供了易于实施的临床筛查触发条件，有助于精准分配稀缺的临床筛查资源。

Abstract: Adverse childhood experiences (ACEs) are categories of childhood abuse, neglect, and household dysfunction. Screening by a single additive ACE score (e.g., a $\ge 4$ cutoff) has poor individual-level discrimination. We instead identify replicable combinations of ACEs that elevate adult depression risk. Our data turnover framework enables a single research team to explore, confirm, and replicate within one observational dataset while controlling the family-wise error rate. We integrate isotonic subgroup selection (ISS) to estimate a higher-risk subgroup under a monotonicity assumption -- additional ACE exposure or higher intensity cannot reduce depression risk. We pre-specify a risk threshold $τ$ corresponding to roughly a two-fold increase in the odds of depression relative to the no-ACE baseline. Within data turnover, the prespecified component improves power while maintaining FWER control, as demonstrated in simulations. Guided by EDA, we adopt frequency coding for ACE items, retaining intensity information that reduces false positives relative to binary or score codings. The result is a replicable, pattern-based higher-risk subgroup. On held-out BRFSS 2022, we show that, at the same level of specificity (0.95), using our replicable subgroup as the screening rule increases sensitivity by 26\% compared with an ACE-score cutoff, yielding concrete triggers that are straightforward to implement and help target scarce clinical screening resources toward truly higher-risk profiles.

</details>


### [13] [A Win-Expectancy Framework for Contextualizing Runs Batted In: Introducing ARBI and CRBI](https://arxiv.org/abs/2511.19642)
*Wuhuan Deng*

Main category: stat.AP

TL;DR: 本文提出了两种新的情境感知指标ARBI和CRBI，通过整合胜率期望来改进传统打点统计，更准确地衡量击球员的进攻贡献。


<details>
  <summary>Details</summary>
Motivation: 传统打点统计将所有打点视为同等重要，忽略了比赛情境（如杠杆率、比分状态、得分对胜率的影响），无法反映打点的真实价值。

Method: ARBI根据得分事件前后的胜率期望变化重新调整每个打点的价值；CRBI进一步考虑事件结束时的终末胜率期望，区分相同胜率变化但不同竞争影响的打点。

Result: ARBI和CRBI提供了经过校准的情境敏感指标，能更准确地反映打点生产的真实价值，区分高杠杆和低杠杆情境下的打点贡献。

Conclusion: ARBI和CRBI现代化了打点统计的解释，在球员评估、预测、合同评估和棒球分析决策中具有广泛应用价值。

Abstract: Runs Batted IN (RBI) records the number of runs a hitter directly drives in during their plate appearances and reflects a batter's ability to convert opportunities into scoring. Because producing runs determines game outcomes, RBI has long served as a central statistic in evaluating offensive performance. However, traditional RBI treats all batted-in runs equally and ignores th game context in which they occur, such as leverage, score state, and the actual impact of a run on a team's chance of winning. In this paper, we introduce two new context-aware metrics-Adjusted RBI (ARBI) and Contextual RBI (CRBI)-that address the fundamental limitations of RBI by incorporating Win Expectancy (WE). ARBI rescales each RBI according to the change in WE before and after the scoring event, assigning more value to runs that meaningfully shift the likelihood of winning and less to runs scored in low-leverage situations. We then extend this framework to CRBI, which further differentiates RBIs with the same WE change by accounting for the terminal WE at the end of the event. This refinement captures the idea that an RBI increasing WE from, for example, 0.45 to 0.65 has a larger competitive impact than one increasing WE from 0.05 to 0.25, even though both represent a 20% increase. Together, ARBI and CRBI provide calibrated, context-sensitive measures of offensive contribution that more accurately reflect the true value of run production. These metrics modernize the interpretation of RBI and have broad applications in player evaluation, forecasting, contract evaluation, and decision-making in baseball analytics.

</details>


### [14] [Introducing Discipline Score Based on League Overall Swinging Probability](https://arxiv.org/abs/2511.19672)
*Wuhuan Deng,Scott Nestler*

Main category: stat.AP

TL;DR: 提出两个新指标DS和ADS，用于评估击球员对坏球的纪律性，与联盟平均水平对比


<details>
  <summary>Details</summary>
Motivation: 现有指标大多无法准确捕捉击球员放掉坏球的能力，而好球区纪律性是击球员成功的重要特征

Method: 引入纪律性得分(DS)和调整纪律性得分(ADS)，基于击球员对坏球的处理与联盟预测趋势的对比

Result: 开发了能够量化评估击球员放掉坏球能力的新指标

Conclusion: DS和ADS指标能更好地评估击球员的纪律性，特别是对坏球的识别能力

Abstract: Plate discipline is an important feature of a hitter's success. Hitter who are able to recognize good pitches to swing at and balls to take are generally recognized as disciplined hitters. Although there are some metrics that can provide insight into the patience of a hitter, most do not capture the ability of a batter to take balls. In this research, we introduce two new metrics, Discipline Score (DS) and Adjusted Discipline Score (ADS), which evaluate batters' discipline when the pitch is a ball compared with the predicted tendencies of all batters in the league.

</details>


### [15] [Anchoring Convenience Survey Samples to a Baseline Census for Vaccine Coverage Monitoring in Global Health](https://arxiv.org/abs/2511.19742)
*Nathaniel Dyrkton,Shomoita Alam,Susan Shepherd,Ibrahim Sana,Kevin Phelan,Jay JH Park*

Main category: stat.AP

TL;DR: 本研究评估了使用校准加权设计法和逻辑回归插补法来估计MCV1疫苗覆盖率的混合调查方法，该方法将非概率随访调查与概率基线普查相结合以校正选择偏倚。


<details>
  <summary>Details</summary>
Motivation: 在乍得和尼日尔农村地区儿童疫苗监测项目的背景下，需要更经济实用的疫苗覆盖率评估方法，以替代传统概率调查的挑战。

Method: 采用模拟研究，评估校准加权设计法和逻辑回归插补法，考虑不同程度的选择偏倚(OR 1.0-1.5)、村庄抽样比例(25-75%)和调查响应率(50-80%)。

Result: 在较现实的场景中(OR≤1.2)，两种方法表现良好，偏差较低且覆盖率接近95%。在最差场景下(OR=1.5, 25%村庄抽样, 50%响应率)，偏差仍≤2.1%。

Conclusion: 混合锚定调查方法是疫苗监测的可行选择，特别是在选择偏倚较小的情况下表现优异。

Abstract: While conducting probabilistic surveys is the gold standard for assessing vaccine coverage, implementing these surveys poses challenges for global health. There is a need for more convenient option that is more affordable and practical. Motivated by childhood vaccine monitoring programs in rural areas of Chad and Niger, we conducted a simulation study to evaluate calibration-weighted design-based and logistic regression-based imputation estimators of the finite-population proportion of MCV1 coverage. These estimators use a hybrid approach that anchors non-probabilistic follow-up survey to probabilistic baseline census to account for selection bias. We explored varying degrees of non-ignorable selection bias (odds ratios from 1.0-1.5), percentage of villages sampled (25-75%), and village-level survey response rate to the follow-up survey (50-80%). Our performance metrics included bias, coverage, and proportion of simulated 95% confidence intervals falling within equivalence margins of 5% and 7.5% (equivalence tolerance). For both adjustment methods, the performance worsened with higher selection bias and lower response rate and generally improved as a larger proportion of villages was sampled. Under the worst scenario with 1.5 OR, 25% village sampled, and 50% survey response rate, both methods showed empirical biases of 2.1% or less, below 95% coverage, and low equivalence tolerances. In more realistic scenarios, the performance of our estimators showed lower biases and close to 95% coverage. For example, at OR$\leq$1.2, both methods showed high performance, except at the lowest village sampling and participation rates. Our simulations show that a hybrid anchoring survey approach is a feasible survey option for vaccine monitoring.

</details>


### [16] [Non-stationarities in extreme hourly precipitation over the Piave Basin, northern Italy](https://arxiv.org/abs/2511.20069)
*Dáire Healy,Ilaria Prosdocimi,Isadora Antoniano-Villalobos*

Main category: stat.AP

TL;DR: 该研究分析了意大利皮亚韦河流域极端小时降水的时空特征，发现边际分布和空间依赖结构存在季节性模式，且极端事件的空间依赖随事件极端程度增加而减弱。研究比较了多种协变量依赖模型，发现仅建模边际非平稳性不足以完全捕捉极端降水的变异性。


<details>
  <summary>Details</summary>
Motivation: 准确描述极端降水过程的时空特征对于更好地评估相关风险至关重要，现有研究在同时建模边际和依赖结构的非平稳性方面存在不足。

Method: 使用观测的小时降雨数据，识别不同时空尺度的气候协变量，比较了最近提出的协变量依赖模型，并采用灵活的max-id模型来学习极端水平下降水过程的时空变异性。

Result: 研究发现边际分布和极值依赖都存在季节性变化，空间依赖随事件极端程度增加而减弱。仅建模边际非平稳性不能完全捕捉极端降水的变异性，需要同时捕捉极值依赖的季节性变化。

Conclusion: 为了准确描述极端降水过程，需要同时考虑边际分布和依赖结构的非平稳性，特别是极值依赖的季节性变化特征。

Abstract: We study the spatio-temporal features of extremal sub-daily precipitation data over the Piave river basin in northeast Italy using a rich database of observed hourly rainfall. Empirical evidence suggests that both the marginal and dependence structures for extreme precipitation in the area exhibit seasonal patterns, and spatial dependence appears to weaken as events become more extreme. We investigate factors affecting the marginal distributions, the spatial dependence and the interplay between them. Capturing these features is essential to provide a realistic description of extreme precipitation processes in order to better estimate their associated risks. With this aim, we identify various climatic covariates at different spatio-temporal scales and explore their usefulness. We go beyond existing literature by investigating and comparing the performance of recently proposed covariate-dependent models for both the marginal and dependence structures of extremes. Furthermore, a flexible max-id model, which encompasses both asymptotic dependence and independence, is used to learn about the spatio-temporal variability of rainfall processes at extreme levels. We find that modelling non-stationarity only at the marginal level does not fully capture the variability of precipitation extremes, and that it is important to also capture the seasonal variation of extremal dependence.

</details>


### [17] [Efficient multi-fidelity Gaussian process regression for noisy outputs and non-nested experimental designs](https://arxiv.org/abs/2511.20183)
*Nils Baillie,Baptiste Kerleguer,Cyril Feau,Josselin Garnier*

Main category: stat.AP

TL;DR: 提出了一种多保真度高斯过程代理建模方法，能够处理非嵌套且含噪声的高保真度和低保真度数据集，通过EM算法估计参数并推导出闭式更新公式。


<details>
  <summary>Details</summary>
Motivation: 解决传统多保真度建模方法在处理非嵌套、含噪声数据集时的局限性，提高参数估计的效率和可扩展性。

Method: 基于递归自回归模型的多保真度高斯过程建模，使用EM算法进行参数估计，当缩放因子为参数化线性预测函数时推导出闭式更新公式。

Result: 提出了解耦优化策略，比直接最大似然最大化更高效和可扩展，在不同复杂度应用案例中进行了基准测试。

Conclusion: 该方法能够有效处理非嵌套含噪声多保真度数据，提供了一种高效且可扩展的参数选择策略。

Abstract: This paper presents a multi-fidelity Gaussian process surrogate modeling that generalizes the recursive formulation of the auto-regressive model when the high-fidelity and low-fidelity data sets are noisy and not necessarily nested. The estimation of high-fidelity parameters by the EM (expectation-maximization) algorithm is shown to be still possible in this context and a closed-form update formula is derived when the scaling factor is a parametric linear predictor function. This yields a decoupled optimization strategy for the parameter selection that is more efficient and scalable than the direct maximum likelihood maximization. The proposed approach is compared to other multi-fidelity models, and benchmarks for different application cases of increasing complexity are provided.

</details>


### [18] [Investigating access to support centers for Violence Against Women in Apulia: A Spatial analysis over multiple years](https://arxiv.org/abs/2511.20481)
*Leonardo Cefalo,Crescenza Calculli,Alessio Pollice*

Main category: stat.AP

TL;DR: 本文提出了一个贝叶斯时空泊松回归模型来分析意大利南部地区女性暴力的空间变异性，发现支持服务的可及性、教育水平和经济发展程度是影响暴力报告和发生率的关键因素。


<details>
  <summary>Details</summary>
Motivation: 解决女性暴力在不同城市间空间变异性的建模挑战，研究社会经济特征和当地脆弱性对性别暴力发生率和报告的影响。

Method: 使用贝叶斯时空泊松回归模型，在集成嵌套拉普拉斯近似框架内比较四种空间模型，分析2021-2024年普利亚大区反暴力中心访问数据。

Result: 支持服务的可及性随居住地距离增加而减少；教育水平较低地区存在报告不足；经济发展程度较高地区报告的暴力发生率可能较低。

Conclusion: 空间建模在捕捉报告动态和为政策干预提供信息方面具有关键作用，强调了支持中心位置战略重要性。

Abstract: In this study, we address the challenge of modelling the spatial variability in violence against women across municipalities in a Southern Italian region by proposing a Bayesian spatio-temporal Poisson regression model. Using data on access to Local Anti-Violence Centers in the Apulia region from 2021 to 2024, we investigate the impact of municipality-level socioeconomic characteristics and local vulnerabilities on both the incidence and reporting of gender-based violence. To explicitly account for spatial dependence, we compare four spatial models within the Integrated Nested Laplace Approximation framework for Bayesian model estimation. We assess the relative fit of the competing models, discussing their prior assumptions, spatial confounding effects, and inferential implications. Our findings indicate that access to support services decreases with distance from the residential municipality, highlighting spatial constraints in reporting and the strategic importance of support center location. Furthermore, lower education levels appear to contribute to under-reporting in disadvantaged areas, while higher economic development may be associated with a lower incidence of reported violence. This study emphasises the critical role of spatial modelling in capturing reporting dynamics and informing policy interventions.

</details>


### [19] [Discovering Spatial Patterns of Readmission Risk Using a Bayesian Competing Risks Model with Spatially Varying Coefficients](https://arxiv.org/abs/2511.20616)
*Yueming Shen,Christian Pean,David Dunson,Samuel Berchuck*

Main category: stat.AP

TL;DR: 提出了一种贝叶斯方法，将点参考空间效应引入竞争风险比例风险模型，用于电子健康记录中的时间-事件分析，通过高斯过程先验和希尔伯特空间低秩近似提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 随着对健康社会决定因素的关注增加，需要能够考虑患者地理位置的方法来研究风险因素与疾病结局的关联。

Method: 使用高斯过程先验处理空间变化的截距和斜率，采用希尔伯特空间低秩近似处理大量空间位置，基线风险曲线建模为分段常数，引入乘法伽马过程先验进行收缩和平滑，最后使用基于损失的聚类方法识别高风险区域。

Result: 该方法提高了推断效率，并在杜克医院老年患者上肢骨折再入院风险分析中提供了有价值的政策决策见解。

Conclusion: 所提出的方法在计算效率和空间风险识别方面表现良好，为下游政策决策提供了有用工具。

Abstract: Time-to-event models are commonly used to study associations between risk factors and disease outcomes in the setting of electronic health records (EHR). In recent years, focus has intensified on social determinants of health, highlighting the need for methods that account for patients' locations. We propose a Bayesian approach for introducing point-referenced spatial effects into a competing risks proportional hazards model. Our method leverages Gaussian process (GP) priors for spatially varying intercept and slope. To improve computational efficiency under a large number of spatial locations, we implemented a Hilbert space low-rank approximation of the GP. We modeled the baseline hazard curves as piecewise constant, and introduced a novel multiplicative gamma process prior to induce shrinkage and smoothing. A loss-based clustering method was then used on the spatial random effects to identify high-risk regions. We demonstrate the utility of this method through simulation and a real-world analysis of EHR data from Duke Hospital to study readmission risk of elderly patients with upper extremity fractures. Our results showed that the proposed method improved inference efficiency and provided valuable insights for downstream policy decisions.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [20] [Individual and group fairness in geographical partitioning](https://arxiv.org/abs/2511.19722)
*Ilya O. Ryzhov,John Gunnar Carlsson,Yinchu Zhu*

Main category: econ.EM

TL;DR: 本文提出了一种新的地理分区问题，确保不同人口群体在每个设施中都能获得公平代表，解决了Dvoretzky等人1951年提出的开放性问题。


<details>
  <summary>Details</summary>
Motivation: 社会经济隔离在学校分区等场景中普遍存在，导致某些群体在某些区域被过度或不足代表，这与机会和结果的不平等密切相关。

Method: 将问题建模为地理分区问题，证明最优解是加性加权Voronoi图的新推广，并提出简单高效的算法来计算该解。

Result: 在包含7个人口群体和78个区域办公室的现实案例研究中验证了方法的有效性和实际洞察潜力。

Conclusion: 该方法成功解决了长期存在的开放性问题，为公平地理分区提供了理论框架和实用算法。

Abstract: Socioeconomic segregation often arises in school districting and other contexts, causing some groups to be over- or under-represented within a particular district. This phenomenon is closely linked with disparities in opportunities and outcomes. We formulate a new class of geographical partitioning problems in which the population is heterogeneous, and it is necessary to ensure fair representation for each group at each facility. We prove that the optimal solution is a novel generalization of the additively weighted Voronoi diagram, and we propose a simple and efficient algorithm to compute it, thus resolving an open question dating back to Dvoretzky et al. (1951). The efficacy and potential for practical insight of the approach are demonstrated in a realistic case study involving seven demographic groups and $78$ district offices.

</details>


### [21] [Institutional Learning and Volatility Transmission in ASEAN Equity Markets: A Network-Integrated Regime-Dependent Approach](https://arxiv.org/abs/2511.19824)
*Junlin Yang*

Main category: econ.EM

TL;DR: 本文研究了制度学习和区域溢出如何影响东盟股市波动动态，通过构建高频制度学习指数和两个新波动框架，发现制度学习放大短期冲击敏感性但加速危机后正常化，网络互动改善尾部行为和短期预测。


<details>
  <summary>Details</summary>
Motivation: 现有研究将制度质量视为静态背景特征，本文将其建模为对政策冲击、信息压力和危机事件做出反应的动态机制，以更好地理解东盟股市波动动态。

Method: 使用2010-2024年印尼、马来西亚、菲律宾和泰国的日度数据，通过MIDAS-EPU方法构建高频制度学习指数，提出制度响应动态模型(IRDM)和网络集成IRDM(N-IRDM)两个新波动框架。

Result: 制度学习放大短期冲击敏感性但加速危机后正常化，危机记忆项解释持续波动聚类，网络互动改善尾部行为和短期预测，N-IRDM显著优于基准GARCH模型。

Conclusion: 制度具有双重作用，研究结果为透明度提升、宏观审慎沟通和区域协调治理提供了政策启示。

Abstract: This paper investigates how institutional learning and regional spillovers shape volatility dynamics in ASEAN equity markets. Using daily data for Indonesia, Malaysia, the Philippines, and Thailand from 2010 to 2024, we construct a high-frequency institutional learning index via a MIDAS-EPU approach. Unlike existing studies that treat institutional quality as a static background characteristic, this paper models institutions as a dynamic mechanism that reacts to policy shocks, information pressure, and crisis events. Building on this perspective, we introduce two new volatility frameworks: the Institutional Response Dynamics Model (IRDM), which embeds crisis memory, policy shocks, and information flows; and the Network-Integrated IRDM (N-IRDM), which incorporates dynamic-correlation and institutional-similarity networks to capture cross-market transmission. Empirical results show that institutional learning amplifies short-run sensitivity to shocks yet accelerates post-crisis normalization. Crisis-memory terms explain prolonged volatility clustering, while network interactions improve tail behavior and short-horizon forecasts. Robustness checks using placebo and lagged networks indicate that spillovers reflect a strong regional common factor rather than dependence on specific correlation topologies. Diebold-Mariano and ENCNEW tests confirm that the N-IRDM significantly outperforms baseline GARCH benchmarks. The findings highlight a dual role of institutions and offer policy insights on transparency enhancement, macroprudential communication, and coordinated regional governance.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [22] [Human Experts' Evaluation of Generative AI for Contextualizing STEAM Education in the Global South](https://arxiv.org/abs/2511.19482)
*Matthew Nyaaba,Macharious Nabang,Patrick Kyeremeh,Ibrahim Nantomah,Collins Owusu-Fordjour,Martin Ako,Bismark Nyaaba Akanzire,Kassim Korah Nantom,Cecilia Issaka,Xiaoming Zhai*

Main category: cs.CY

TL;DR: 研究评估了生成式AI在加纳STEAM教育中的文化情境化能力，发现AI结合定制工具能创造比标准教案更具文化响应性的课程，但在处理文化多元性方面仍有局限。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI在全球化南方STEAM教育中的文化情境化潜力，特别是在加纳这样的多元文化环境中如何将抽象课程标准与学习者文化知识相结合。

Method: 采用收敛混合方法设计，四位STEAM专家使用验证过的25项文化响应教学法评分表，评估AI生成的课程计划与加纳国家课程评估委员会标准教案的对比。

Result: AI辅助课程在文化基础和教学响应性方面优于标准教案，能整合本土知识、双语元素和本地相关案例，但在数学和计算领域文化细微差别有限，且难以充分代表加纳文化多元性。

Conclusion: AI在教育情境化中具有潜力但需要教师调解、社区参与和文化调适，未来需进行课堂试验、扩大专家参与和使用本土语言语料库进行模型微调。

Abstract: This study investigates how human experts evaluate the capacity of Generative AI (GenAI) to contextualize STEAM education in the Global South, with a focus on Ghana. Using a convergent mixed-methods design, four STEAM specialists assessed GenAI-generated lesson plans created with a customized Culturally Responsive Lesson Planner (CRLP) and compared them to standardized lesson plans from the Ghana National Council for Curriculum and Assessment (NaCCA). Quantitative ratings were based on a validated 25-item Culturally Responsive Pedagogy Rubric measuring bias awareness, cultural representation, contextual relevance, linguistic responsiveness, and teacher agency. Qualitative reflections provided additional insight into how GenAI handles cultural and pedagogical appropriateness.
  Findings show that GenAI, when paired with the CRLP tool, can support contextualized STEAM instruction by linking abstract curriculum standards to learners' cultural knowledge, community practices, and everyday experiences. Experts rated GenAI-assisted lessons as more culturally grounded and pedagogically responsive than NaCCA plans, integrating Indigenous knowledge, bilingual elements, and locally relevant examples. However, GenAI struggled to represent Ghana's cultural pluralism, often offering surface-level references to language, history, and identity. These weaknesses were most evident in Mathematics and Computing, where cultural nuance was limited. The results highlight the need for continued teacher mediation, community involvement, and culturally attuned refinement of AI outputs. Future work should include classroom trials, expanded expert participation, and model fine-tuning using Indigenous language corpora to strengthen cultural fidelity in Global South contexts.

</details>


### [23] [Building Resilient Information Ecosystems: Large LLM-Generated Dataset of Persuasion Attacks](https://arxiv.org/abs/2511.19488)
*Hsien-Te Kao,Aleksey Panasyuk,Peter Bautista,William Dupree,Gabriel Ganberg,Jeffrey M. Beaubien,Laura Cassani,Svitlana Volkova*

Main category: cs.CY

TL;DR: 本文构建了一个大型LLM生成的劝说攻击数据集，包含13.4万条由GPT-4、Gemma 2和Llama 3.1针对机构新闻生成的攻击，涵盖23种劝说技巧，用于分析不同模型的攻击策略并支持主动防御。


<details>
  <summary>Details</summary>
Motivation: 生成式AI模型能够快速大规模生成有说服力的内容，与官方信息形成竞争性叙事，使机构处于被动地位，难以维持沟通效果。

Method: 创建包含134,136条攻击的大型数据集，这些攻击由三种LLM针对10个机构的972份新闻稿生成，涵盖新闻稿声明和社交媒体帖子两种媒介，分析23种劝说技巧和道德共鸣。

Result: GPT-4攻击主要关注关怀，权威和忠诚也起作用；Gemma 2强调关怀和权威；Llama 3.1以忠诚和关怀为中心。不同模型展现出不同的劝说策略偏好。

Conclusion: 分析LLM生成的劝说攻击能够实现主动防御，为组织创建声誉护甲，推动信息生态系统中有效且具有韧性的沟通发展。

Abstract: Organization's communication is essential for public trust, but the rise of generative AI models has introduced significant challenges by generating persuasive content that can form competing narratives with official messages from government and commercial organizations at speed and scale. This has left agencies in a reactive position, often unaware of how these models construct their persuasive strategies, making it more difficult to sustain communication effectiveness. In this paper, we introduce a large LLM-generated persuasion attack dataset, which includes 134,136 attacks generated by GPT-4, Gemma 2, and Llama 3.1 on agency news. These attacks span 23 persuasive techniques from SemEval 2023 Task 3, directed toward 972 press releases from ten agencies. The generated attacks come in two mediums, press release statements and social media posts, covering both long-form and short-form communication strategies. We analyzed the moral resonance of these persuasion attacks to understand their attack vectors. GPT-4's attacks mainly focus on Care, with Authority and Loyalty also playing a role. Gemma 2 emphasizes Care and Authority, while Llama 3.1 centers on Loyalty and Care. Analyzing LLM-generated persuasive attacks across models will enable proactive defense, allow to create the reputation armor for organizations, and propel the development of both effective and resilient communications in the information ecosystem.

</details>


### [24] [Forecasting AI Time Horizon Under Compute Slowdowns](https://arxiv.org/abs/2511.19492)
*Parker Whitfill,Ben Snodin,Joel Becker*

Main category: cs.CY

TL;DR: 该论文分析了计算能力增长放缓对AI智能体能力预测的影响，发现时间范围增长必须与计算增长成正比，并预测在某些情况下会出现显著延迟。


<details>
  <summary>Details</summary>
Motivation: 研究计算能力扩展是否能在2030年前保持当前速度，以及计算增长放缓如何影响AI智能体能力预测，特别是时间范围指标的预测。

Method: 建立时间范围作为训练计算和算法函数的模型，结合计算投资对算法进步的影响模型，基于2019-2025年时间范围和计算以恒定速率增长的经验事实进行推导。

Result: 推导出时间范围增长必须与计算增长成正比，并提供有限的实验证据支持这一理论。使用该模型预测在OpenAI计算预测下的时间范围增长。

Conclusion: 计算增长放缓会导致AI智能体能力发展显著延迟，例如80%可靠性的1个月时间范围比简单趋势外推预测晚7年实现。

Abstract: METR's time horizon metric has grown exponentially since 2019, along with compute. However, it is unclear whether compute scaling will persist at current rates through 2030, raising the question of how possible compute slowdowns might impact AI agent capability forecasts. Given a model of time horizon as a function of training compute and algorithms, along with a model of how compute investment spills into algorithmic progress (which, notably, precludes the possibility of a software-only singularity), and the empirical fact that both time horizon and compute have grown at constant rates over 2019--2025, we derive that time horizon growth must be proportional to compute growth. We provide additional, albeit limited, experimental evidence consistent with this theory. We use our model to project time horizon growth under OpenAI's compute projection, finding substantial projected delays in some cases. For example, 1-month time horizons at $80\%$ reliability occur $7$ years later than simple trend extrapolation suggests.

</details>


### [25] [Towards Synergistic Teacher-AI Interactions with Generative Artificial Intelligence](https://arxiv.org/abs/2511.19580)
*Mutlu Cukurova,Wannapon Suraworachet,Qi Zhou,Sahan Bulathwela*

Main category: cs.CY

TL;DR: 本文提出了教师与生成式AI协作的五层次框架，探讨了GenAI在教育中的应用对教师专业实践的影响，从替代到互补再到能力增强的不同可能性。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在教育中的广泛应用给教师带来了适应挑战，虽然提供了可访问性、可扩展性和生产力的机会，但也引发了教师自主权减少、认知退化和教师职业去专业化等担忧。

Method: 基于先前AI教育文献和系统文献综述，构建了教师-AI协作的五层次概念框架：交易性、情境性、操作性、实践性和协同性协作。

Result: 提出了支持教师-AI协作所需的技术条件，并基于实证观察描绘了超越个体教师自主权的未来愿景，强调教师与AI之间的协作决策、协商和共同推理。

Conclusion: 需要超越教师-AI协作的社会技术因素考量，以确保教师与AI在教育中的协同作用在伦理和实践上都能实现，达到双方单独无法实现的成果。

Abstract: Generative artificial intelligence (GenAI) is increasingly used in education, posing significant challenges for teachers adapting to these changes. GenAI offers unprecedented opportunities for accessibility, scalability and productivity in educational tasks. However, the automation of teaching tasks through GenAI raises concerns about reduced teacher agency, potential cognitive atrophy, and the broader deprofessionalisation of teaching. Drawing findings from prior literature on AI in Education, and refining through a recent systematic literature review, this chapter presents a conceptualisation of five levels of teacher-AI teaming: transactional, situational, operational, praxical and synergistic teaming. The framework aims to capture the nuanced dynamics of teacher-AI interactions, particularly with GenAI, that may lead to the replacement, complementarity, or augmentation of teachers' competences and professional practice. GenAI technological affordances required in supporting teaming, along with empirical studies, are discussed. Drawing on empirical observations, we outline a future vision that moves beyond individual teacher agency toward collaborative decision-making between teachers and AI, in which both agents engage in negotiation, constructive challenge, and co-reasoning that enhance each other's capabilities and enable outcomes neither could realise independently. Further discussion of socio-technical factors beyond teacher-AI teaming is also included to streamline the synergy of teachers and AI in education ethically and practically.

</details>


### [26] [The DataSquad Experiment: Lessons for Preparing Data and Computer Scientists for Work](https://arxiv.org/abs/2511.19688)
*Paula Lackie,Elliot Pickens,Dashiell Coyier*

Main category: cs.CY

TL;DR: Carleton College的DataSquad项目通过结构化同伴指导和真实客户项目，解决文理学院数据服务能力有限和学生实践经验缺乏的问题，培养本科生数据技能。


<details>
  <summary>Details</summary>
Motivation: 小型文理学院数据服务能力有限，学生缺乏数据实践机会，需要建立可持续的数据服务模式同时培养学生专业技能。

Method: 采用带薪工作学习职位，通过结构化同伴指导、基于项目的学习和沟通培训，让学生从基础数据分析逐步过渡到软件开发。

Result: 项目成功实施，UCLA等院校通过"DataSquad International"采用该模式，使用公开共享材料。

Conclusion: 结构化同伴指导能同时提升机构数据服务水平和学生专业能力与自信心，该模式具有可移植性。

Abstract: The DataSquad at Carleton College addresses a common problem at small liberal arts colleges: limited capacity for data services and few opportunities for students to gain practical experience with data and software development. Academic Technologist Paula Lackie designed the program as a work-study position that trains undergraduates through structured peer mentorship and real client projects. Students tackle data problems of increasing complexity-from basic data analysis to software development-while learning FAIR data principles and open science practices. The model's core components (peer mentorship structure, project-based learning, and communication training) make it adaptable to other institutions. UCLA and other colleges have adopted the model using openly shared materials through "DataSquad International." This paper describes the program's implementation at Carleton College and examines how structured peer mentorship can simultaneously improve institutional data services and provide students with professional skills and confidence.

</details>


### [27] [International AI Safety Report 2025: Second Key Update: Technical Safeguards and Risk Management](https://arxiv.org/abs/2511.19863)
*Yoshua Bengio,Stephen Clare,Carina Prunkl,Maksym Andriushchenko,Ben Bucknall,Philip Fox,Nestor Maslej,Conor McGlynn,Malcolm Murray,Shalaleh Rismani,Stephen Casper,Jessica Newman,Daniel Privitera,Sören Mindermann,Daron Acemoglu,Thomas G. Dietterich,Fredrik Heintz,Geoffrey Hinton,Nick Jennings,Susan Leavy,Teresa Ludermir,Vidushi Marda,Helen Margetts,John McDermid,Jane Munga,Arvind Narayanan,Alondra Nelson,Clara Neppel,Gopal Ramchurn,Stuart Russell,Marietje Schaake,Bernhard Schölkopf,Alavaro Soto,Lee Tiedrich,Gaël Varoquaux,Andrew Yao,Ya-Qin Zhang,Leandro Aguirre,Olubunmi Ajala,Fahad Albalawi,Noora AlMalek,Christian Busch,André Carvalho,Jonathan Collas,Amandeep Gill,Ahmet Hatip,Juha Heikkilä,Chris Johnson,Gill Jolly,Ziv Katzir,Mary Kerema,Hiroaki Kitano,Antonio Krüger,Aoife McLysaght,Oleksii Molchanovskyi,Andrea Monti,Kyoung Mu Lee,Mona Nemer,Nuria Oliver,Raquel Pezoa,Audrey Plonk,José Portillo,Balaraman Ravindran,Hammam Riza,Crystal Rugege,Haroon Sheikh,Denise Wong,Yi Zeng,Liming Zhu*

Main category: cs.CY

TL;DR: 2025年国际AI安全报告更新：评估通用AI风险管理新进展，包括开发者采取的安全措施、技术改进和新兴治理框架。


<details>
  <summary>Details</summary>
Motivation: 随着通用AI能力的快速发展，需要持续评估和更新风险管理方法，特别是针对生物武器等高风险滥用场景。

Method: 通过分析AI开发者、研究机构和公共机构的最新实践，包括增强安全防护、对抗训练、数据管理和监控系统等技术手段。

Result: 主要AI开发者已对新型号实施额外安全措施；前沿AI安全框架发布公司数量翻倍；政府和国际组织开始建立透明度与风险评估为主的治理框架。

Conclusion: 通用AI风险管理在技术和制度层面都有显著进展，但仍需持续努力应对新兴风险。

Abstract: This second update to the 2025 International AI Safety Report assesses new developments in general-purpose AI risk management over the past year. It examines how researchers, public institutions, and AI developers are approaching risk management for general-purpose AI. In recent months, for example, three leading AI developers applied enhanced safeguards to their new models, as their internal pre-deployment testing could not rule out the possibility that these models could be misused to help create biological weapons. Beyond specific precautionary measures, there have been a range of other advances in techniques for making AI models and systems more reliable and resistant to misuse. These include new approaches in adversarial training, data curation, and monitoring systems. In parallel, institutional frameworks that operationalise and formalise these technical capabilities are starting to emerge: the number of companies publishing Frontier AI Safety Frameworks more than doubled in 2025, and governments and international organisations have established a small number of governance frameworks for general-purpose AI, focusing largely on transparency and risk assessment.

</details>


### [28] [Invisible in Search? Auditing Aesthetic Bias in the Visual Representation of Holocaust Victims on Google](https://arxiv.org/abs/2511.20036)
*Mykola Makhortykh,Tobias Rohrbach,Maryna Sydorova*

Main category: cs.CY

TL;DR: 对Google上大屠杀受害者视觉呈现的比较审计显示，存在男性主导的呈现偏向，过度强调暴行背景，可能掩盖性别特定的苦难并削弱共情潜力。


<details>
  <summary>Details</summary>
Motivation: 信息检索系统在塑造社会现实表征方面日益重要，但面临美学偏见等伦理挑战。现有研究多关注当代社会问题，而历史表征特别是敏感历史事件如大屠杀的美学偏见研究存在空白。

Method: 对Google上大屠杀受害者视觉呈现进行对比审计研究。

Result: 发现Google倾向于传播男性主导的大屠杀受害者表征，强调暴行背景，可能使性别特定苦难隐形并降低共情潜力。不同地理位置的呈现存在差异，表明搜索算法可能产生自身的受害者美学。

Conclusion: 搜索算法在历史表征中产生美学偏见，需要关注其对敏感历史事件呈现的伦理影响。

Abstract: Information retrieval systems, such as search engines, increasingly shape the representation of the past and present states of social reality. Despite their importance, these systems face challenges in dealing with the ethical aspects of representation due to various forms of bias, including aesthetic bias that perpetuates hegemonic patterns of representation. While most research on aesthetic bias has examined it in the context of current societal issues, it is also crucial for historical representation, particularly of sensitive subjects such as historical atrocities. To address this gap, we conduct a comparative audit of the visual representation of Holocaust victims on Google. We find that Google tends to propagate a male-dominated representation of Holocaust victims with an emphasis on atrocity context, risking rendering invisible gender-specific suffering and decreasing potential for nurturing empathy. We also observe a variation in representation across geographic locations, suggesting that search algorithms may produce their own aesthetic of victimhood.

</details>


### [29] [The Making of Digital Ghosts: Designing Ethical AI Afterlives](https://arxiv.org/abs/2511.20094)
*Giovanni Spitale,Federico Germani*

Main category: cs.CY

TL;DR: 本文对AI驱动的数字来世技术进行概念和伦理分析，提出了数字幽灵的定义、九维分类法，以及构建合乎伦理的数字幽灵的关键原则。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术发展，模拟逝者的聊天机器人、语音克隆和视频化身正从科幻走向商业现实，这重塑了人们的哀悼和纪念方式，需要对其伦理影响进行系统分析。

Method: 通过概念分析定义数字幽灵，追踪其在个人、商业和机构背景下的兴起，识别核心伦理张力，并提出九维分类法来分析这些技术。

Result: 识别了围绕悲伤与福祉、真实性与欺骗、同意与死后隐私、尊严与歪曲、哀悼商业化等核心伦理问题，并提出了合乎伦理的数字幽灵应具备的特征。

Conclusion: 需要有针对性的监管和专业指南，确保数字幽灵能够帮助纪念而不陷入欺骗形式，强调生前意图、相互同意、透明数据使用等关键原则的重要性。

Abstract: Advances in artificial intelligence now make it possible to simulate the dead through chatbots, voice clones, and video avatars trained on a person's digital traces. These "digital ghosts" are moving from fiction to commercial reality, reshaping how people mourn and remember. This paper offers a conceptual and ethical analysis of AI-mediated digital afterlives. We define what counts as a digital ghost, trace their rise across personal, commercial, and institutional contexts, and identify core ethical tensions around grief and well-being, truthfulness and deception, consent and posthumous privacy, dignity and misrepresentation, and the commercialization of mourning. To analyze these challenges, we propose a nine-dimensional taxonomy of digital afterlife technologies and, building on it, outline the features of an ethically acceptable digital ghost: premortem intent, mutual consent, transparent and limited data use, clear disclosure, restricted purposes and access, family or estate stewardship, and minimal behavioral agency. We argue for targeted regulation and professional guidelines to ensure that digital ghosts can aid remembrance without slipping into forms of deception.

</details>


### [30] [Dual Stressors in Engineering Education: Lagged Causal Effects of Academic Staff Strikes and Inflation on Dropout within the CAPIRE Framework](https://arxiv.org/abs/2511.20130)
*H. R. Paz*

Main category: cs.CY

TL;DR: 该研究验证了双重压力假说，发现阿根廷工程专业中教师罢工（近端冲击）和通货膨胀（远端冲击）共同影响学生辍学率，其中罢工滞后两学期与入学时通胀的交互作用对辍学有显著因果影响。


<details>
  <summary>Details</summary>
Motivation: 验证双重压力假说，探究学术机构罢工和宏观经济冲击如何共同影响高等教育中的学生辍学行为。

Method: 使用包含1,343名学生的纵向面板数据，采用LinearDML估计器和双重机器学习方法，分析罢工暴露及其与入学时通胀的交互作用对辍学的滞后因果效应。

Result: 罢工滞后两学期在简单模型中显著影响辍学（ATE=0.0323, p=0.0173），但在控制学业进度等因素后主效应不显著；罢工与入学通胀的交互作用保持稳健正相关（估计值=0.0625, p=0.0033）。

Conclusion: 宏观冲击作为耦合压力源通过课程摩擦和财务韧性中介影响学生辍学，而非孤立事件，支持了CAPIRE-MACRO基于代理的模拟结果。

Abstract: This study provides a causal validation of the dual-stressor hypothesis in a long-cycle engineering programme in Argentina, testing whether academic staff strikes (proximal shocks) and inflation (distal shocks) jointly shape student dropout. Using a leak-aware longitudinal panel of 1,343 students and a manually implemented LinearDML estimator, we estimate lagged causal effects of strike exposure and its interaction with inflation at entry. The temporal profile is clear: only strikes occurring two semesters earlier have a significant impact on next-semester dropout in simple lagged logit models (ATE = 0.0323, p = 0.0173), while other lags are negligible. When we move to double machine learning and control flexibly for academic progression, curriculum friction and calendar effects, the main effect of strikes at lag 2 becomes small and statistically non-significant, but the interaction between strikes and inflation at entry remains positive and robust (estimate = 0.0625, p = 0.0033). A placebo model with a synthetic strike variable yields null effects, and a robustness audit (seed sensitivity, model comparisons, SHAP inspection) confirms the stability of the interaction across specifications. SHAP analysis also reveals that Strikes_Lag2 and Inflation_at_Entry jointly contribute strongly to predicted dropout risk. These findings align with the CAPIRE-MACRO agent-based simulations and support the view that macro shocks act as coupled stressors mediated by curriculum friction and financial resilience rather than isolated events.

</details>


### [31] [Assessing the Effectiveness of Selective Marketing to Broaden Participation in CS Education](https://arxiv.org/abs/2511.20554)
*Aditya Shah,Tyler Menezes*

Main category: cs.CY

TL;DR: 本研究通过改进教育性黑客松的营销策略，成功提高了边缘化和低收入社区学生的参与比例，同时保持了总体参与人数。


<details>
  <summary>Details</summary>
Motivation: 计算教育领域的课外项目通常依赖营销策略来吸引参与者，但现有文献缺乏关于如何有效营销这些项目的指导。本研究旨在探索如何通过改进营销策略来拓宽计算教育的参与范围。

Method: 对一个面向中学生的教育性黑客松项目进行营销策略调整：减少对富裕家庭的推广、使用针对学校的定向沟通、在初期宣传中强调成本支持。然后比较干预前后的参与情况和人口统计数据。

Result: 干预后，来自边缘化和低收入社区的学生比例显著提高，总体参与人数没有减少。

Conclusion: 通过有针对性的营销策略调整，可以在不降低总体参与率的情况下，有效提高计算教育项目中边缘化和低收入学生的参与度。

Abstract: Many studies have aimed to broaden participation in computing (BPC) through extracurricular educational initiatives. When these initiatives are structured as open-enrollment extracurricular programs, their success often depends on their marketing approach. However, there is little in the computing education research literature about how to conduct effective marketing for these initiatives. We describe the changes made to the marketing strategy of one such program, an educational hackathon for middle school and high school students in the Pacific Northwest. These included reducing promotion to affluent families, using targeted school-based communication, and emphasizing cost supports during initial promotion. We then compare attendance and self-reported demographics before and after the intervention. Results indicate a higher proportion of students from marginalized and low-income communities and no reduction in overall attendance.

</details>


### [32] [Behavioural Sciences and the Regulation of Privacy on the Internet](https://arxiv.org/abs/2511.20637)
*Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 本文探讨行为科学对互联网隐私监管的政策启示，特别关注行为定向营销。作者认为仅靠数据保护法不足以保护隐私，建议禁止某些有害的行为定向实践。


<details>
  <summary>Details</summary>
Motivation: 行为定向营销通过追踪用户在线行为来展示个性化广告，现有数据保护法可能不足以有效保护隐私，需要从行为科学角度重新审视监管政策。

Method: 通过分析行为定向营销的技术原理和隐私影响，结合行为科学理论，论证现有法律保护的局限性。

Result: 研究发现仅依靠数据保护法执行无法充分保护隐私，某些行为定向实践对社会整体有害。

Conclusion: 如果某些行为定向实践对社会不利，政策制定者应考虑直接禁止这些实践，而不仅仅依赖数据保护法的执行。

Abstract: This chapter examines the policy implications of behavioural sciences insights for the regulation of privacy on the Internet, by focusing in particular on behavioural targeting. This marketing technique involves tracking people's online behaviour to use the collected information to show people individually targeted advertisements. Enforcing data protection law may not be enough to protect privacy in this area. I argue that, if society is better off when certain behavioural targeting practices do not happen, policymakers should consider banning them.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [33] [Large Scale Community-Aware Network Generation](https://arxiv.org/abs/2511.19717)
*Vikram Ramavarapu,João Alfredo Cardoso Lamy,Mohammad Dindoost,David A. Bader*

Main category: cs.SI

TL;DR: RECCS+和RECCS++是RECCS算法的增强版本，通过并行化和算法优化实现了显著的速度提升，分别达到49倍和139倍的加速比，使算法能够扩展到超过1亿节点和近20亿边的大规模网络。


<details>
  <summary>Details</summary>
Motivation: 由于真实网络缺乏带标签的基准事实，评估社区检测算法具有挑战性。需要能够生成带基准事实社区标签的合成网络生成器，但现有方法在处理大规模网络时效率不足。

Method: RECCS+在保持原始RECCS算法保真度的同时，通过协调器实现多进程并行化和多线程技术。RECCS++在此基础上增加了算法优化以实现进一步的加速。

Result: 实验结果显示，RECCS+和RECCS++在基准数据集上分别实现了最高49倍和139倍的加速比，其中RECCS++的性能提升涉及适度的准确性权衡。

Conclusion: 通过性能提升，RECCS++现在能够扩展到超过1亿节点和近20亿边的大规模网络，为社区检测算法的评估提供了高效的合成网络生成工具。

Abstract: Community detection, or network clustering, is used to identify latent community structure in networks. Due to the scarcity of labeled ground truth in real-world networks, evaluating these algorithms poses significant challenges. To address this, researchers use synthetic network generators that produce networks with ground-truth community labels. RECCS is one such algorithm that takes a network and its clustering as input and generates a synthetic network through a modular pipeline. Each generated ground truth cluster preserves key characteristics of the corresponding input cluster, including connectivity, minimum degree, and degree sequence distribution. The output consists of a synthetically generated network, and disjoint ground truth cluster labels for all nodes. In this paper, we present two enhanced versions: RECCS+ and RECCS++. RECCS+ maintains algorithmic fidelity to the original RECCS while introducing parallelization through an orchestrator that coordinates algorithmic components across multiple processes and employs multithreading. RECCS++ builds upon this foundation with additional algorithmic optimizations to achieve further speedup. Our experimental results demonstrate that RECCS+ and RECCS++ achieve speedups of up to 49x and 139x respectively on our benchmark datasets, with RECCS++'s additional performance gains involving a modest accuracy tradeoff. With this newfound performance, RECCS++ can now scale to networks with over 100 million nodes and nearly 2 billion edges.

</details>


### [34] [Modelling the Spread of Toxicity and Exploring its Mitigation on Online Social Networks](https://arxiv.org/abs/2511.20546)
*Aatman Vaidya,Harsh Bhagat,Seema Nagar,Amit A. Nanavati*

Main category: cs.SI

TL;DR: 该研究提出了一种新的仇恨言论传播模型，将用户视为毒性的转换者而非简单的传播者，并通过部署和平机器人来减少网络毒性。


<details>
  <summary>Details</summary>
Motivation: 在线平台上的仇恨言论与现实世界暴力事件密切相关，迫切需要理解毒性内容如何传播以及如何在社交网络上缓解。现有研究通常将用户简单分为仇恨和非仇恨两类，缺乏对用户行为动态变化的考虑。

Method: 将用户建模为毒性的转换者（放大、衰减或复制毒性），通过时间序列分析Twitter、Koo和Gab平台数据，开发包含时变用户行为的网络传播模型，并模拟部署和平机器人进行干预。

Result: 研究发现：(a)毒性在网络中不守恒；(b)只有部分用户随时间改变行为；(c)行为改变用户间不存在同质性。用户对毒性的"偏移"取决于输入毒性和用户类别。和平机器人干预能减少毒性，但效果取决于网络结构和部署策略。

Conclusion: 用户作为毒性转换者的模型能更准确地描述仇恨言论传播，基于用户行为动态的干预策略（如和平机器人）有望有效减少网络毒性，但需要针对具体网络结构优化部署。

Abstract: Hate speech on online platforms has been credibly linked to multiple instances of real world violence. This calls for an urgent need to understand how toxic content spreads and how it might be mitigated on online social networks, and expectedly has been the topic of extensive research in recent times. Prior work has largely modelled hate through epidemic or spread activation based diffusion models, in which the users are often divided into two categories, hateful or not. In this work, users are treated as transformers of toxicity, based on how they respond to incoming toxicity. Compared with the incoming toxicity, users amplify, attenuate, or replicate (effectively, transform) the toxicity and send it forward. We do a temporal analysis of toxicity on Twitter, Koo and Gab and find that (a) toxicity is not conserved in the network; (b) only a subset of users change behaviour over time; and (c) there is no evidence of homophily among behaviour-changing users. In our model, each user transforms incoming toxicity by applying a "shift" to it prior to sending it forward. Based on this, we develop a network model of toxicity spread that incorporates time-varying behaviour of users. We find that the "shift" applied by a user is dependent on the input toxicity and the category. Based on this finding, we propose an intervention strategy for toxicity reduction. This is simulated by deploying peace-bots. Through experiments on both real-world and synthetic networks, we demonstrate that peace-bot interventions can reduce toxicity, though their effectiveness depends on network structure and placement strategy.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [35] [Using Wearable Devices to Improve Chronic PainTreatment among Patients with Opioid Use Disorder](https://arxiv.org/abs/2511.19577)
*Abhay Goyal,Navin Kumar,Kimberly DiMeola,Rafael Trujillo,Soorya Ram Shimgekar,Christian Poellabauer,Pi Zonooz,Ermonda Gjoni-Markaj,Declan Barry,Lynn Madden*

Main category: cs.AI

TL;DR: 本研究探索了使用可穿戴设备和AI方法预测慢性疼痛和鸦片使用障碍患者的疼痛峰值，发现机器学习模型预测准确率较高，但大型语言模型在此领域的应用效果有限。


<details>
  <summary>Details</summary>
Motivation: 慢性疼痛和鸦片使用障碍是相互关联的常见慢性疾病，目前缺乏针对这两种疾病的整合治疗方案。可穿戴设备有潜力监测复杂患者信息，但大型语言模型在疼痛峰值分析中的应用尚未被探索。

Method: 采用试点研究方法，使用可穿戴设备收集数据，并应用多种AI方法（包括机器学习和大型语言模型）分析疼痛峰值的临床相关性。

Result: 机器学习模型在预测疼痛峰值方面取得了相对较高的准确率（>0.7），但大型语言模型在提供疼痛峰值见解方面表现有限。

Conclusion: 可穿戴设备的实时监测结合先进AI模型可以促进疼痛峰值的早期检测，支持个性化干预。鉴于大型语言模型整体表现有限，需要开发能够在此背景下提供可操作见解的大型语言模型。

Abstract: Chronic pain (CP) and opioid use disorder (OUD) are common and interrelated chronic medical conditions. Currently, there is a paucity of evidence-based integrated treatments for CP and OUD among individuals receiving medication for opioid use disorder (MOUD). Wearable devices have the potential to monitor complex patient information and inform treatment development for persons with OUD and CP, including pain variability (e.g., exacerbations of pain or pain spikes) and clinical correlates (e.g., perceived stress). However, the application of large language models (LLMs) with wearable data for understanding pain spikes, remains unexplored. Consequently, the aim of this pilot study was to examine the clinical correlates of pain spikes using a range of AI approaches. We found that machine learning models achieved relatively high accuracy (>0.7) in predicting pain spikes, while LLMs were limited in providing insights on pain spikes. Real-time monitoring through wearable devices, combined with advanced AI models, could facilitate early detection of pain spikes and support personalized interventions that may help mitigate the risk of opioid relapse, improve adherence to MOUD, and enhance the integration of CP and OUD care. Given overall limited LLM performance, these findings highlight the need to develop LLMs which can provide actionable insights in the OUD/CP context.

</details>


### [36] [Fara-7B: An Efficient Agentic Model for Computer Use](https://arxiv.org/abs/2511.19663)
*Ahmed Awadallah,Yash Lara,Raghav Magazine,Hussein Mozannar,Akshay Nambi,Yash Pandya,Aravind Rajeswaran,Corby Rosset,Alexey Taymanov,Vibhav Vineet,Spencer Whitehead,Andrew Zhao*

Main category: cs.AI

TL;DR: FaraGen是一个用于多步骤网页任务的合成数据生成系统，能够生成多样化的任务和解决方案，并筛选成功轨迹。基于这些数据训练的Fara-7B模型在多个基准测试中表现优异，甚至能与更大的前沿模型竞争。


<details>
  <summary>Details</summary>
Motivation: 计算机使用代理（CUA）的发展受到缺乏大规模高质量数据集的限制，现有数据集无法捕捉人类与计算机的交互方式。

Method: 开发FaraGen系统生成合成数据，包括提出多样化任务、生成多个解决方案尝试，并使用多个验证器筛选成功轨迹。基于这些数据训练Fara-7B模型，该模型仅通过截图感知计算机，通过预测坐标执行动作。

Result: FaraGen能以约1美元的成本生成每个验证轨迹，具有高吞吐量、产量和多样性。Fara-7B在WebVoyager、Online-Mind2Web和WebTailBench等基准测试中优于同类规模模型，并与更大的前沿模型竞争。

Conclusion: 可扩展的数据生成系统在推进小型高效代理模型方面具有关键优势。Fara-7B模型已开源发布，同时发布了WebTailBench基准测试。

Abstract: Progress in computer use agents (CUAs) has been constrained by the absence of large and high-quality datasets that capture how humans interact with a computer. While LLMs have thrived on abundant textual data, no comparable corpus exists for CUA trajectories. To address these gaps, we introduce FaraGen, a novel synthetic data generation system for multi-step web tasks. FaraGen can propose diverse tasks from frequently used websites, generate multiple solution attempts, and filter successful trajectories using multiple verifiers. It achieves high throughput, yield, and diversity for multi-step web tasks, producing verified trajectories at approximately $1 each. We use this data to train Fara-7B, a native CUA model that perceives the computer using only screenshots, executes actions via predicted coordinates, and is small enough to run on-device. We find that Fara-7B outperforms other CUA models of comparable size on benchmarks like WebVoyager, Online-Mind2Web, and WebTailBench -- our novel benchmark that better captures under-represented web tasks in pre-existing benchmarks. Furthermore, Fara-7B is competitive with much larger frontier models, illustrating key benefits of scalable data generation systems in advancing small efficient agentic models. We are making Fara-7B open-weight on Microsoft Foundry and HuggingFace, and we are releasing WebTailBench.

</details>


### [37] [HeaRT: A Hierarchical Circuit Reasoning Tree-Based Agentic Framework for AMS Design Optimization](https://arxiv.org/abs/2511.19669)
*Souradip Poddar,Chia-Tung Ho,Ziming Wei,Weidong Cao,Haoxing Ren,David Z. Pan*

Main category: cs.AI

TL;DR: HeaRT是一个基础推理引擎，用于AMS设计自动化，实现了>97%的推理准确率和>98%的Pass@1性能，在40电路基准测试中表现优异，且运行成本仅为SOTA基线的0.5倍。


<details>
  <summary>Details</summary>
Motivation: 传统AI驱动的AMS设计自动化算法受限于对高质量数据集的依赖、跨架构可移植性差以及缺乏自适应机制。

Method: 提出HeaRT基础推理引擎，作为智能自适应设计优化的第一步，采用人类风格的设计优化方法。

Result: HeaRT在电路复杂度增加时仍保持高精度，在尺寸和拓扑设计适应任务中实现>3倍的收敛速度提升，同时保留先前的设计意图。

Conclusion: HeaRT是向智能自适应AMS设计自动化迈出的重要一步，显著提升了设计效率和性能。

Abstract: Conventional AI-driven AMS design automation algorithms remain constrained by their reliance on high-quality datasets to capture underlying circuit behavior, coupled with poor transferability across architectures, and a lack of adaptive mechanisms. This work proposes HeaRT, a foundational reasoning engine for automation loops and a first step toward intelligent, adaptive, human-style design optimization. HeaRT consistently demonstrates reasoning accuracy >97% and Pass@1 performance >98% across our 40-circuit benchmark repository, even as circuit complexity increases, while operating at <0.5x real-time token budget of SOTA baselines. Our experiments show that HeaRT yields >3x faster convergence in both sizing and topology design adaptation tasks across diverse optimization approaches, while preserving prior design intent.

</details>


### [38] [FISCAL: Financial Synthetic Claim-document Augmented Learning for Efficient Fact-Checking](https://arxiv.org/abs/2511.19671)
*Rishab Sharma,Iman Saberi,Elham Alipour,Jie JW Wu,Fatemeh Fard*

Main category: cs.AI

TL;DR: 提出了FISCAL框架，用于生成金融事实核查的合成数据，并训练了轻量级验证器MiniCheck-FISCAL，在多个金融数据集上表现出色，接近更大模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前金融应用中的大语言模型存在事实可靠性不足和计算效率低下的问题，需要开发更高效且准确的解决方案。

Method: 使用FISCAL框架生成金融合成数据FISCAL-data，并基于此训练轻量级验证器MiniCheck-FISCAL。

Result: MiniCheck-FISCAL在多个金融数据集上超越了GPT-3.5 Turbo和类似规模的开源模型，接近Mixtral-8x22B等大20倍模型的准确性，在外部数据集上与GPT-4o和Claude-3.5表现相当。

Conclusion: 领域特定的合成数据结合高效微调，能使紧凑模型在金融AI应用中达到最先进的准确性、鲁棒性和可扩展性。

Abstract: Financial applications of large language models (LLMs) require factual reliability and computational efficiency, yet current systems often hallucinate details and depend on prohibitively large models. We propose FISCAL (Financial Synthetic Claim-Document Augmented Learning), a modular framework for generating synthetic data tailored to financial fact-checking. Using FISCAL, we generate a dataset called FISCAL-data and use it to train MiniCheck-FISCAL, a lightweight verifier for numerical financial claims. MiniCheck-FISCAL outperforms its baseline, surpasses GPT-3.5 Turbo and other open-source peers of similar size, and approaches the accuracy of much larger systems (20x), such as Mixtral-8x22B and Command R+. On external datasets FinDVer and Fin-Fact, it rivals GPT-4o and Claude-3.5 while outperforming Gemini-1.5 Flash. These results show that domain-specific synthetic data, combined with efficient fine-tuning, enables compact models to achieve state-of-the-art accuracy, robustness, and scalability for practical financial AI. The dataset and scripts are available in the project repository (link provided in the paper).

</details>


### [39] [Scaling Item-to-Standard Alignment with Large Language Models: Accuracy, Limits, and Solutions](https://arxiv.org/abs/2511.19749)
*Farzan Karimi-Malekabadi,Pooya Razavi,Sonya Powers*

Main category: cs.AI

TL;DR: 本研究探讨了大型语言模型(LLMs)在加速教育评估项目与内容标准对齐过程中的应用潜力，通过三个实验验证了LLMs在识别错误对齐项目、选择正确技能标准以及预筛选候选技能方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的人工对齐评审虽然准确但耗时耗力，特别是在大型项目库中。研究旨在探索LLMs是否能加速这一过程而不牺牲准确性。

Method: 使用超过12,000个K-5年级的项目-技能对，测试了三种LLM模型(GPT-3.5 Turbo、GPT-4o-mini和GPT-4o)，涵盖三个任务：识别错误对齐项目、从完整标准集中选择正确技能、以及在分类前缩小候选列表。

Result: GPT-4o-mini在识别对齐状态方面达到83-94%的准确率；数学领域表现强劲，但阅读领域因标准语义重叠而表现较低；预筛选候选技能显著改善结果，正确技能出现在前五建议中的概率超过95%。

Conclusion: LLMs特别是结合候选筛选策略时，能显著减少人工评审负担同时保持对齐准确性。建议开发结合LLM筛选和人工评审的混合流程，为持续项目验证和教学对齐提供可扩展解决方案。

Abstract: As educational systems evolve, ensuring that assessment items remain aligned with content standards is essential for maintaining fairness and instructional relevance. Traditional human alignment reviews are accurate but slow and labor-intensive, especially across large item banks. This study examines whether Large Language Models (LLMs) can accelerate this process without sacrificing accuracy. Using over 12,000 item-skill pairs in grades K-5, we tested three LLMs (GPT-3.5 Turbo, GPT-4o-mini, and GPT-4o) across three tasks that mirror real-world challenges: identifying misaligned items, selecting the correct skill from the full set of standards, and narrowing candidate lists prior to classification. In Study 1, GPT-4o-mini correctly identified alignment status in approximately 83-94% of cases, including subtle misalignments. In Study 2, performance remained strong in mathematics but was lower for reading, where standards are more semantically overlapping. Study 3 demonstrated that pre-filtering candidate skills substantially improved results, with the correct skill appearing among the top five suggestions more than 95% of the time. These findings suggest that LLMs, particularly when paired with candidate filtering strategies, can significantly reduce the manual burden of item review while preserving alignment accuracy. We recommend the development of hybrid pipelines that combine LLM-based screening with human review in ambiguous cases, offering a scalable solution for ongoing item validation and instructional alignment.

</details>


### [40] [Scaling Agentic Reinforcement Learning for Tool-Integrated Reasoning in VLMs](https://arxiv.org/abs/2511.19773)
*Meng Lu,Ran Xu,Yi Fang,Wenxuan Zhang,Yue Yu,Gaurav Srivastava,Yuchen Zhuang,Mohamed Elhoseiny,Charles Fleming,Carl Yang,Zhengzhong Tu,Yang Xie,Guanghua Xiao,Hanrui Wang,Di Jin,Wenqi Shi,Xuan Wang*

Main category: cs.AI

TL;DR: VISTA-Gym是一个可扩展的训练环境，旨在增强视觉语言模型的多步骤视觉推理能力，通过统一多模态任务接口和工具集成来训练VISTA-R1模型，在11个VQA基准测试中显著优于同类模型。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在图像理解方面表现良好，但在多步骤视觉推理和工具集成方面能力有限，需要专门的训练环境来提升这些能力。

Method: 开发VISTA-Gym训练环境，统一7个任务13个数据集的多模态推理任务，提供标准化视觉工具接口、可执行交互循环和反馈信号，通过多轮轨迹采样和端到端强化学习训练VISTA-R1模型。

Result: VISTA-R1-8B在11个公开推理密集型VQA基准测试中，比同类规模的最先进基线模型性能提升9.51%-18.72%。

Conclusion: VISTA-Gym是解锁视觉语言模型工具集成推理能力的有效训练平台，显著提升了模型在复杂视觉推理任务中的表现。

Abstract: While recent vision-language models (VLMs) demonstrate strong image understanding, their ability to "think with images", i.e., to reason through multi-step visual interactions, remains limited. We introduce VISTA-Gym, a scalable training environment for incentivizing tool-integrated visual reasoning capabilities in VLMs. VISTA-Gym unifies diverse real-world multimodal reasoning tasks (7 tasks from 13 datasets in total) with a standardized interface for visual tools (e.g., grounding, parsing), executable interaction loops, verifiable feedback signals, and efficient trajectory logging, enabling visual agentic reinforcement learning at scale. While recent VLMs exhibit strong text-only reasoning, both proprietary and open-source models still struggle with tool selection, invocation, and coordination. With VISTA-Gym, we train VISTA-R1 to interleave tool-use with agentic reasoning via multi-turn trajectory sampling and end-to-end reinforcement learning. Extensive experiments across 11 public reasoning-intensive VQA benchmarks show that VISTA-R1-8B outperforms state-of-the-art baselines with similar sizes by 9.51%-18.72%, demonstrating VISTA-Gym as an effective training ground to unlock the tool-integrated reasoning capabilities for VLMs.

</details>


### [41] [NOEM$^{3}$A: A Neuro-Symbolic Ontology-Enhanced Method for Multi-Intent Understanding in Mobile Agents](https://arxiv.org/abs/2511.19780)
*Ioannis Tzachristas,Aifen Sui*

Main category: cs.AI

TL;DR: 提出一种神经符号框架，通过将结构化意图本体与紧凑语言模型集成，实现移动AI代理的多意图理解。该方法利用检索增强提示、logit偏置和可选分类头，将符号意图结构注入输入和输出表示中。


<details>
  <summary>Details</summary>
Motivation: 解决移动AI代理中多意图理解的挑战，通过在紧凑模型中注入符号意图结构，实现准确且高效的设备端自然语言理解。

Method: 集成结构化意图本体与紧凑语言模型，采用检索增强提示、logit偏置和可选分类头，将符号意图结构注入输入和输出表示。

Result: 在MultiWOZ 2.3的模糊/苛刻对话子集上，3B Llama模型通过本体增强接近GPT-4准确率（85% vs 90%），同时大幅降低能耗和内存占用。

Conclusion: 符号对齐是实现在设备端准确高效自然语言理解的有效策略，本体增强模型产生更接地气、消歧的多意图解释。

Abstract: We introduce a neuro-symbolic framework for multi-intent understanding in mobile AI agents by integrating a structured intent ontology with compact language models. Our method leverages retrieval-augmented prompting, logit biasing and optional classification heads to inject symbolic intent structure into both input and output representations. We formalize a new evaluation metric-Semantic Intent Similarity (SIS)-based on hierarchical ontology depth, capturing semantic proximity even when predicted intents differ lexically. Experiments on a subset of ambiguous/demanding dialogues of MultiWOZ 2.3 (with oracle labels from GPT-o3) demonstrate that a 3B Llama model with ontology augmentation approaches GPT-4 accuracy (85% vs 90%) at a tiny fraction of the energy and memory footprint. Qualitative comparisons show that ontology-augmented models produce more grounded, disambiguated multi-intent interpretations. Our results validate symbolic alignment as an effective strategy for enabling accurate and efficient on-device NLU.

</details>


### [42] [KOM: A Multi-Agent Artificial Intelligence System for Precision Management of Knee Osteoarthritis (KOA)](https://arxiv.org/abs/2511.19798)
*Weizhi Liu,Xi Chen,Zekun Jiang,Liang Zhao,Kunyuan Jiang,Ruisi Tang,Li Wang,Mingke You,Hanyu Zhou,Hongyu Chen,Qiankun Xiong,Yong Nie,Kang Li,Jian Li*

Main category: cs.AI

TL;DR: KOM是一个用于膝骨关节炎管理的多智能体系统，能够自动化评估、风险预测和治疗处方，在资源有限的环境中提高诊疗效率。


<details>
  <summary>Details</summary>
Motivation: 膝骨关节炎影响全球6亿多人，个性化多学科干预虽有效但资源需求大，难以在资源有限环境中实施。

Method: 开发KOM多智能体系统，自动化KOA评估、风险预测和治疗处方生成，支持基于患者个体特征的定制管理计划。

Result: 基准实验显示KOM在影像分析和处方生成方面优于通用大语言模型；随机三臂模拟研究表明与临床医生协作可将诊断和规划时间减少38.5%，并提高治疗质量。

Conclusion: KOM有助于实现自动化KOA管理，整合到临床工作流程中可提高护理效率，其模块化架构对其他慢性病AI辅助管理系统开发具有参考价值。

Abstract: Knee osteoarthritis (KOA) affects more than 600 million individuals globally and is associated with significant pain, functional impairment, and disability. While personalized multidisciplinary interventions have the potential to slow disease progression and enhance quality of life, they typically require substantial medical resources and expertise, making them difficult to implement in resource-limited settings. To address this challenge, we developed KOM, a multi-agent system designed to automate KOA evaluation, risk prediction, and treatment prescription. This system assists clinicians in performing essential tasks across the KOA care pathway and supports the generation of tailored management plans based on individual patient profiles, disease status, risk factors, and contraindications. In benchmark experiments, KOM demonstrated superior performance compared to several general-purpose large language models in imaging analysis and prescription generation. A randomized three-arm simulation study further revealed that collaboration between KOM and clinicians reduced total diagnostic and planning time by 38.5% and resulted in improved treatment quality compared to each approach used independently. These findings indicate that KOM could help facilitate automated KOA management and, when integrated into clinical workflows, has the potential to enhance care efficiency. The modular architecture of KOM may also offer valuable insights for developing AI-assisted management systems for other chronic conditions.

</details>


### [43] [A Unified Evaluation-Instructed Framework for Query-Dependent Prompt Optimization](https://arxiv.org/abs/2511.19829)
*Ke Chen,Yifeng Wang,Hassan Almosapeeh,Haohan Wang*

Main category: cs.AI

TL;DR: 提出了一种基于评估指导的提示优化方法，通过建立系统化的提示评估框架和训练执行无关的评估器，实现可解释的、查询依赖的提示优化。


<details>
  <summary>Details</summary>
Motivation: 现有提示优化方法主要优化静态模板，在复杂动态场景中效果有限；查询依赖方法依赖不稳定的文本反馈或黑盒奖励模型，提供弱且不可解释的优化信号；提示质量缺乏统一系统定义。

Method: 建立性能导向的系统化提示评估框架；开发并微调执行无关的评估器，直接从文本预测多维质量分数；评估器指导指标感知的优化器诊断失败模式并以可解释方式重写提示。

Result: 评估器在预测提示性能方面达到最高准确率；评估指导的优化在8个数据集和3个骨干模型上持续超越静态模板和查询依赖基线方法。

Conclusion: 提出了统一的、基于指标的提示质量视角，证明了评估指导的优化管道能够在多样化任务中提供稳定、可解释且模型无关的改进。

Abstract: Most prompt-optimization methods refine a single static template, making them ineffective in complex and dynamic user scenarios. Existing query-dependent approaches rely on unstable textual feedback or black-box reward models, providing weak and uninterpretable optimization signals. More fundamentally, prompt quality itself lacks a unified, systematic definition, resulting in fragmented and unreliable evaluation signals. Our approach first establishes a performance-oriented, systematic, and comprehensive prompt evaluation framework. Furthermore, we develop and finetune an execution-free evaluator that predicts multi-dimensional quality scores directly from text. The evaluator then instructs a metric-aware optimizer that diagnoses failure modes and rewrites prompts in an interpretable, query-dependent manner. Our evaluator achieves the strongest accuracy in predicting prompt performance, and the evaluation-instructed optimization consistently surpass both static-template and query-dependent baselines across eight datasets and on three backbone models. Overall, we propose a unified, metric-grounded perspective on prompt quality, and demonstrated that our evaluation-instructed optimization pipeline delivers stable, interpretable, and model-agnostic improvements across diverse tasks.

</details>


### [44] [Reinforcement Learning with $ω$-Regular Objectives and Constraints](https://arxiv.org/abs/2511.19849)
*Dominik Wagner,Leon Witzman,Luke Ong*

Main category: cs.AI

TL;DR: 提出一种结合ω-正则目标和显式约束的强化学习方法，解决传统标量奖励表达能力有限和安全性-性能权衡问题


<details>
  <summary>Details</summary>
Motivation: 传统强化学习依赖标量奖励，表达能力有限且容易导致奖励破解，无法有效表达时间性、条件性或安全关键目标，同时单一标量指标掩盖了安全性-性能权衡

Method: 开发基于线性规划的模型强化学习算法，结合ω-正则目标和约束，将安全要求和优化目标分开处理

Result: 算法在极限情况下能产生最大化满足ω-正则目标概率的策略，同时遵守指定阈值的ω-正则约束

Conclusion: 建立了到约束极限平均问题的转换，并保持最优性保证，为解决安全强化学习问题提供了新框架

Abstract: Reinforcement learning (RL) commonly relies on scalar rewards with limited ability to express temporal, conditional, or safety-critical goals, and can lead to reward hacking. Temporal logic expressible via the more general class of $ω$-regular objectives addresses this by precisely specifying rich behavioural properties. Even still, measuring performance by a single scalar (be it reward or satisfaction probability) masks safety-performance trade-offs that arise in settings with a tolerable level of risk.
  We address both limitations simultaneously by combining $ω$-regular objectives with explicit constraints, allowing safety requirements and optimisation targets to be treated separately. We develop a model-based RL algorithm based on linear programming, which in the limit produces a policy maximising the probability of satisfying an $ω$-regular objective while also adhering to $ω$-regular constraints within specified thresholds. Furthermore, we establish a translation to constrained limit-average problems with optimality-preserving guarantees.

</details>


### [45] [MicroSims: A Framework for AI-Generated, Scalable Educational Simulations with Universal Embedding and Adaptive Learning Support](https://arxiv.org/abs/2511.19864)
*Valerie Lockhart,Dan McCreary,Troy A. Peterson*

Main category: cs.AI

TL;DR: MicroSims是一个用于创建轻量级交互式教育模拟的AI驱动框架，通过标准化设计模式、iframe架构和可修改代码，使教育工作者无需编程知识就能快速生成和定制模拟内容。


<details>
  <summary>Details</summary>
Motivation: 传统教育模拟创建需要大量资源和技术专长，限制了其广泛应用。MicroSims旨在解决成本、技术复杂性和平台依赖等障碍，促进教育公平。

Method: 采用标准化设计模式实现AI辅助生成，iframe架构确保通用嵌入和沙盒安全，透明可修改代码支持定制化，包含设计原则、技术架构、元数据标准和开发工作流程。

Result: 基于物理教育研究和STEM元分析，交互式模拟可将概念理解提升30-40%。MicroSims在保持这些益处的同时降低了创建门槛。

Conclusion: MicroSims为全球教育工作者提供了按需创建定制化、课程对齐模拟的能力，为基于AI的自适应学习系统奠定了基础。

Abstract: Educational simulations have long been recognized as powerful tools for enhancing learning outcomes, yet their creation has traditionally required substantial resources and technical expertise. This paper introduces MicroSims a novel framework for creating lightweight, interactive educational simulations that can be rapidly generated using artificial intelligence, universally embedded across digital learning platforms, and easily customized without programming knowledge. MicroSims occupy a unique position at the intersection of three key innovations: (1) standardized design patterns that enable AI-assisted generation, (2) iframe-based architecture that provides universal embedding and sandboxed security, and (3) transparent, modifiable code that supports customization and pedagogical transparency. We present a comprehensive framework encompassing design principles, technical architecture, metadata standards, and development workflows. Drawing on empirical research from physics education studies and meta-analyses across STEM disciplines, we demonstrate that interactive simulations can improve conceptual understanding by up to 30-40\% compared to traditional instruction. MicroSims extend these benefits while addressing persistent barriers of cost, technical complexity, and platform dependence. This work has significant implications for educational equity, and low-cost intelligent interactive textbooks that enabling educators worldwide to create customized, curriculum-aligned simulations on demand. We discuss implementation considerations, present evidence of effectiveness, and outline future directions for AI-powered adaptive learning systems built on the MicroSim foundation.

</details>


### [46] [Agentic AI-Empowered Conversational Embodied Intelligence Networks in 6G](https://arxiv.org/abs/2511.19865)
*Mingkai Chen,Zijie Feng,Lei Wang,Yaser Khamayseh*

Main category: cs.AI

TL;DR: 提出CC-EIN网络解决6G时代多智能体语义协作问题，通过多模态融合、自适应语义通信和可解释性机制，在灾后救援场景中实现95.4%任务完成率和95%传输效率。


<details>
  <summary>Details</summary>
Motivation: 现有系统在多模态信息融合、自适应通信和决策可解释性方面存在不足，难以满足6G时代多智能体设备复杂任务执行的需求。

Method: 集成多模态特征融合(PerceptiNet)、自适应语义通信、任务协调机制和可解释性模块(InDec)，通过Grad-CAM可视化增强决策透明度。

Result: 在灾后救援场景仿真中，达到95.4%任务完成率和95%传输效率，同时保持强语义一致性和能量效率。

Conclusion: CC-EIN有效解决了多智能体语义协作中的关键挑战，为6G时代智能设备协作提供了可行解决方案。

Abstract: In the 6G era, semantic collaboration among multiple embodied intelligent devices (MEIDs) becomes crucial for complex task execution. However, existing systems face challenges in multimodal information fusion, adaptive communication, and decision interpretability. To address these limitations, we propose a collaborative Conversational Embodied Intelligence Network (CC-EIN) integrating multimodal feature fusion, adaptive semantic communication, task coordination, and interpretability. PerceptiNet performs cross-modal fusion of image and radar data to generate unified semantic representations. An adaptive semantic communication strategy dynamically adjusts coding schemes and transmission power according to task urgency and channel quality. A semantic-driven collaboration mechanism further supports task decomposition and conflict-free coordination among heterogeneous devices. Finally, the InDec module enhances decision transparency through Grad-CAM visualization. Simulation results in post-earthquake rescue scenarios demonstrate that CC-EIN achieves 95.4% task completion rate and 95% transmission efficiency while maintaining strong semantic consistency and energy efficiency.

</details>


### [47] [Simulated Self-Assessment in Large Language Models: A Psychometric Approach to AI Self-Efficacy](https://arxiv.org/abs/2511.19872)
*Daniel I Jackson,Emma L Jensen,Syed-Amad Hussain,Emre Sezgin*

Main category: cs.AI

TL;DR: 该研究将通用自我效能感量表(GSES)应用于10个大型语言模型，发现在不同任务条件下模型表现出不同的自我效能感水平，但自我评估并不能可靠反映实际能力。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型的自我评估能力，因为自我评估是可靠智能的关键方面，而现有评估主要关注任务准确性。

Method: 将10项通用自我效能感量表(GSES)应用于10个LLM，在四种条件下进行测试：无任务、计算推理、社会推理和摘要任务，分析响应稳定性、自我效能感水平和实际表现的关系。

Result: 模型在不同条件下表现出显著不同的自我效能感水平，总体得分低于人类标准。所有模型在计算和社会问题上都达到完美准确率，但摘要表现差异很大。自我评估不能可靠反映能力，高自我效能感模型可能表现较差，低自我效能感模型反而表现准确。

Conclusion: 心理测量提示为LLM沟通行为提供了结构化洞察，但不能提供校准的性能估计。自我效能感较高的模型倾向于使用更自信、拟人化的推理风格，而得分较低的模型则反映谨慎、去拟人化的解释。

Abstract: Self-assessment is a key aspect of reliable intelligence, yet evaluations of large language models (LLMs) focus mainly on task accuracy. We adapted the 10-item General Self-Efficacy Scale (GSES) to elicit simulated self-assessments from ten LLMs across four conditions: no task, computational reasoning, social reasoning, and summarization. GSES responses were highly stable across repeated administrations and randomized item orders. However, models showed significantly different self-efficacy levels across conditions, with aggregate scores lower than human norms. All models achieved perfect accuracy on computational and social questions, whereas summarization performance varied widely. Self-assessment did not reliably reflect ability: several low-scoring models performed accurately, while some high-scoring models produced weaker summaries. Follow-up confidence prompts yielded modest, mostly downward revisions, suggesting mild overestimation in first-pass assessments. Qualitative analysis showed that higher self-efficacy corresponded to more assertive, anthropomorphic reasoning styles, whereas lower scores reflected cautious, de-anthropomorphized explanations. Psychometric prompting provides structured insight into LLM communication behavior but not calibrated performance estimates.

</details>


### [48] [RPM-MCTS: Knowledge-Retrieval as Process Reward Model with Monte Carlo Tree Search for Code Generation](https://arxiv.org/abs/2511.19895)
*Yuanyuan Lin,Xiangyu Ouyang,Teng Zhang,Kaixin Sui*

Main category: cs.AI

TL;DR: RPM-MCTS是一种基于蒙特卡洛树搜索的代码生成方法，通过知识检索作为过程奖励模型来评估中间算法步骤，无需复杂训练，能减少15%的token消耗并提升代码生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于树搜索的代码生成方法难以有效评估中间算法步骤，无法及时定位和纠正错误步骤，导致生成错误代码和计算成本增加。

Method: 使用知识检索作为过程奖励模型，在扩展阶段采用相似性过滤去除冗余节点，利用沙箱执行反馈定位错误步骤并进行针对性修正。

Result: 在四个公共代码生成基准测试中优于当前最先进方法，token消耗减少约15%，使用RPM-MCTS构建的数据进行全微调可显著提升基础模型的代码能力。

Conclusion: RPM-MCTS通过知识检索和沙箱反馈有效解决了中间步骤评估和错误修正问题，在提升代码生成质量的同时降低了计算成本。

Abstract: Tree search-based methods have made significant progress in enhancing the code generation capabilities of large language models. However, due to the difficulty in effectively evaluating intermediate algorithmic steps and the inability to locate and timely correct erroneous steps, these methods often generate incorrect code and incur increased computational costs. To tackle these problems, we propose RPM-MCTS, an effective method that utilizes Knowledge-Retrieval as Process Reward Model based on Monte Carlo Tree Search to evaluate intermediate algorithmic steps. By utilizing knowledge base retrieval, RPM-MCTS avoids the complex training of process reward models. During the expansion phase, similarity filtering is employed to remove redundant nodes, ensuring diversity in reasoning paths. Furthermore, our method utilizes sandbox execution feedback to locate erroneous algorithmic steps during generation, enabling timely and targeted corrections. Extensive experiments on four public code generation benchmarks demonstrate that RPM-MCTS outperforms current state-of-the-art methods while achieving an approximately 15% reduction in token consumption. Furthermore, full fine-tuning of the base model using the data constructed by RPM-MCTS significantly enhances its code capabilities.

</details>


### [49] [Semantic-KG: Using Knowledge Graphs to Construct Benchmarks for Measuring Semantic Similarity](https://arxiv.org/abs/2511.19925)
*Qiyao Wei,Edward Morrell,Lea Goetz,Mihaela van der Schaar*

Main category: cs.AI

TL;DR: 本文提出了一种基于知识图谱生成基准数据集的新方法，用于评估LLM输出语义相似度方法的性能，解决了现有基准数据集生成成本高、领域适用性有限等问题。


<details>
  <summary>Details</summary>
Motivation: 当前语义相似度方法可能更关注句法或词汇形式而非语义内容，现有基准数据集存在生成成本高、领域适用性有限、等价定义不明确等局限性。

Method: 利用知识图谱生成语义相似或不相似的自然语言陈述对，其中不相似对分为四种子类型，在四个不同领域生成基准数据集，并比较传统NLP评分和LLM作为评判者的性能。

Result: 语义变化的子类型和基准领域都会影响语义相似度方法的性能，没有一种方法始终表现最优。

Conclusion: 研究结果对使用LLM作为评判者检测文本语义内容具有重要启示，代码和数据集已开源。

Abstract: Evaluating the open-form textual responses generated by Large Language Models (LLMs) typically requires measuring the semantic similarity of the response to a (human generated) reference. However, there is evidence that current semantic similarity methods may capture syntactic or lexical forms over semantic content. While benchmarks exist for semantic equivalence, they often suffer from high generation costs due to reliance on subjective human judgment, limited availability for domain-specific applications, and unclear definitions of equivalence. This paper introduces a novel method for generating benchmarks to evaluate semantic similarity methods for LLM outputs, specifically addressing these limitations. Our approach leverages knowledge graphs (KGs) to generate pairs of natural-language statements that are semantically similar or dissimilar, with dissimilar pairs categorized into one of four sub-types. We generate benchmark datasets in four different domains (general knowledge, biomedicine, finance, biology), and conduct a comparative study of semantic similarity methods including traditional natural language processing scores and LLM-as-a-judge predictions. We observe that the sub-type of semantic variation, as well as the domain of the benchmark impact the performance of semantic similarity methods, with no method being consistently superior. Our results present important implications for the use of LLM-as-a-judge in detecting the semantic content of text. Code is available at https://github.com/QiyaoWei/semantic-kg and the dataset is available at https://huggingface.co/datasets/QiyaoWei/Semantic-KG.

</details>


### [50] [A System-Level Taxonomy of Failure Modes in Large Language Model Applications](https://arxiv.org/abs/2511.19933)
*Vaishali Vinay*

Main category: cs.AI

TL;DR: 本文提出了一个系统级分类法，识别了15种真实世界LLM应用中的隐藏故障模式，分析了现有评估方法的局限性，并提出了构建可靠LLM系统的设计原则。


<details>
  <summary>Details</summary>
Motivation: 随着LLM被快速集成到决策支持工具和自动化工作流中，其在生产环境中的行为仍然难以理解，且故障模式与传统机器学习模型有本质不同。

Method: 提出系统级分类法识别15种隐藏故障模式，分析评估与监控实践的差距，并研究部署挑战。

Result: 识别了多步推理漂移、潜在不一致性、上下文边界退化、错误工具调用、版本漂移和成本驱动性能崩溃等关键故障模式。

Conclusion: 通过将LLM可靠性框架化为系统工程问题而非纯模型中心问题，为未来评估方法、AI系统鲁棒性和可靠LLM部署研究提供了分析基础。

Abstract: Large language models (LLMs) are being rapidly integrated into decision-support tools, automation workflows, and AI-enabled software systems. However, their behavior in production environments remains poorly understood, and their failure patterns differ fundamentally from those of traditional machine learning models. This paper presents a system-level taxonomy of fifteen hidden failure modes that arise in real-world LLM applications, including multi-step reasoning drift, latent inconsistency, context-boundary degradation, incorrect tool invocation, version drift, and cost-driven performance collapse. Using this taxonomy, we analyze the growing gap in evaluation and monitoring practices: existing benchmarks measure knowledge or reasoning but provide little insight into stability, reproducibility, drift, or workflow integration. We further examine the production challenges associated with deploying LLMs - including observability limitations, cost constraints, and update-induced regressions - and outline high-level design principles for building reliable, maintainable, and cost-aware LLM systems. Finally, we outline high-level design principles for building reliable, maintainable, and cost-aware LLM-based systems. By framing LLM reliability as a system-engineering problem rather than a purely model-centric one, this work provides an analytical foundation for future research on evaluation methodology, AI system robustness, and dependable LLM deployment.

</details>


### [51] [M$^3$Prune: Hierarchical Communication Graph Pruning for Efficient Multi-Modal Multi-Agent Retrieval-Augmented Generation](https://arxiv.org/abs/2511.19969)
*Weizi Shao,Taolin Zhang,Zijie Zhou,Chen Chen,Chengyu Wang,Xiaofeng He*

Main category: cs.AI

TL;DR: 提出了M³Prune框架，通过跨模态图剪枝消除冗余边，在多模态检索增强生成任务中实现性能与token开销的最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统存在显著的token开销和计算成本问题，限制了大规模部署。

Method: 首先进行模态内图稀疏化识别关键边，然后构建动态通信拓扑进行模态间图稀疏化，最后渐进剪枝冗余边获得高效分层拓扑。

Result: 在通用和领域特定mRAG基准测试中，方法持续优于单智能体和鲁棒多智能体系统，同时显著减少token消耗。

Conclusion: M³Prune框架有效解决了多智能体系统的效率问题，在保持性能的同时大幅降低计算开销。

Abstract: Recent advancements in multi-modal retrieval-augmented generation (mRAG), which enhance multi-modal large language models (MLLMs) with external knowledge, have demonstrated that the collective intelligence of multiple agents can significantly outperform a single model through effective communication. Despite impressive performance, existing multi-agent systems inherently incur substantial token overhead and increased computational costs, posing challenges for large-scale deployment. To address these issues, we propose a novel Multi-Modal Multi-agent hierarchical communication graph PRUNING framework, termed M$^3$Prune. Our framework eliminates redundant edges across different modalities, achieving an optimal balance between task performance and token overhead. Specifically, M$^3$Prune first applies intra-modal graph sparsification to textual and visual modalities, identifying the edges most critical for solving the task. Subsequently, we construct a dynamic communication topology using these key edges for inter-modal graph sparsification. Finally, we progressively prune redundant edges to obtain a more efficient and hierarchical topology. Extensive experiments on both general and domain-specific mRAG benchmarks demonstrate that our method consistently outperforms both single-agent and robust multi-agent mRAG systems while significantly reducing token consumption.

</details>


### [52] [Reducing Latency of LLM Search Agent via Speculation-based Algorithm-System Co-Design](https://arxiv.org/abs/2511.20048)
*Zixiao Huang,Wen Zeng,Tianyu Fu,Tengxuan Liu,Yizhou Sun,Ke Hong,Xinhao Yang,Chengchun Liu,Yan Li,Quanlu Zhang,Guohao Dai,Zhenhua Zhu,Yu Wang*

Main category: cs.AI

TL;DR: SPAgent通过算法-系统协同设计框架，使用两阶段自适应推测机制和两级调度器，显著降低基于LLM的搜索代理的延迟，实现最高1.65倍的端到端加速，同时保持或提高准确性。


<details>
  <summary>Details</summary>
Motivation: 基于LLM的搜索代理性能强大但延迟严重，因为每个步骤都需要串行化的LLM推理和工具执行。传统推测范式虽然能打破串行执行，但效益有限，因为保留了完整原始工作负载并增加了额外推理开销。

Method: SPAgent采用算法-系统协同设计：算法层面引入两阶段自适应推测机制，在安全时选择性省略验证；系统层面使用两级调度器根据引擎负载调节推测请求，确保推测始终有益。

Result: 在广泛的实验设置中，SPAgent实现了最高1.65倍的端到端加速，同时保持相同甚至更高的准确性，使多步搜索代理的实际部署成为可能。

Conclusion: SPAgent通过扩展推测在搜索代理中的作用，有效解决了LLM搜索代理的延迟瓶颈，为多步搜索代理的实际部署提供了可行方案。

Abstract: LLM-based search agents achieve strong performance but suffer from severe latency, as each step requires serialized LLM reasoning followed by action of tool execution. We revisit this bottleneck through the lens of speculation. While traditional predict-verify speculation paradigm can break serial execution, its benefit remains limited, as it retains the full original workload and adds extra inference overhead. We observe that early agent steps often involve simple evidence-gathering, where correct actions can often be predicted without full reasoning. Building on these observations, we present SPAgent, an algorithm-system co-design framework that expands the role of speculation in search agents to reduce latency. Algorithmically, SPAgent introduces a two-phase adaptive speculation mechanism that selectively omits verification when safe. System-wise, a two-level scheduler regulates speculative requests based on engine load to ensure speculation remains beneficial. We implement SPAgent in real-world systems. Across extensive experimental settings, SPAgent achieves up to $1.65\times$ end-to-end speedup while maintaining same or even achieving higher accuracy, enabling practical deployment of multi-step search agents.

</details>


### [53] ["Are We Done Yet?": A Vision-Based Judge for Autonomous Task Completion of Computer Use Agents](https://arxiv.org/abs/2511.20067)
*Marta Sumyk,Oleksandr Kosovan*

Main category: cs.AI

TL;DR: 提出了一个基于视觉语言模型的自主评估框架，通过屏幕截图和任务描述来评估计算机使用代理的任务完成情况，显著提高了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 计算机使用代理在自主操作数字界面时，往往无法可靠判断任务是否完成，需要有效的评估机制来提高可靠性。

Method: 使用视觉语言模型直接从屏幕截图和任务描述中评估任务完成情况，构建了涵盖42个macOS应用和1,260个人工标注任务的数据集。

Result: 框架在任务成功检测中达到73%的准确率，应用评估反馈后整体任务成功率平均相对提升27%。

Conclusion: 基于视觉的评估可以作为有效的反馈机制，显著提高自主计算机使用代理的可靠性和自我纠正能力。

Abstract: Computer Use Agents (CUAs) are designed to autonomously operate digital interfaces, yet they often fail to reliably determine whether a given task has been completed. We present an autonomous evaluation and feedback framework that uses vision-language models to assess task completion directly from screenshots and task descriptions. Our dataset covers 42 built-in macOS applications and 1,260 human-labeled tasks across a wide range of scenarios. Our framework achieves up to 73 percent accuracy in task success detection and yields an average relative improvement of 27 percent in overall task success when evaluator feedback is applied. These results show that vision-based evaluation can serve as an effective feedback mechanism that improves the reliability and self-correction of autonomous computer-use agents.

</details>


### [54] [VICoT-Agent: A Vision-Interleaved Chain-of-Thought Framework for Interpretable Multimodal Reasoning and Scalable Remote Sensing Analysis](https://arxiv.org/abs/2511.20085)
*Chujie Wang,Zhiyuan Luo,Ruiqi Liu,Can Ran,Shenghua Fan,Xi Chen,Chu He*

Main category: cs.AI

TL;DR: 提出了VICoT多模态智能体框架，通过动态整合视觉工具到思维链中实现显式多轮推理，在遥感图像分析任务中显著优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 遥感图像分析任务正从传统目标识别向复杂智能推理演进，需要更强的推理能力和灵活的工具调用能力。

Method: 采用基于栈的推理结构和模块化MCP兼容工具套件，使LLM能够高效执行多轮交错的视觉语言推理任务；提出推理栈蒸馏方法将复杂智能体行为迁移到轻量级模型。

Result: 在多个遥感基准测试中，VICoT在推理透明度、执行效率和生成质量方面显著优于现有SOTA框架。

Conclusion: VICoT框架通过显式多轮推理和工具动态整合，有效提升了遥感图像分析的推理能力和灵活性，并通过蒸馏方法实现了复杂推理能力的轻量化迁移。

Abstract: The current remote sensing image analysis task is increasingly evolving from traditional object recognition to complex intelligence reasoning, which places higher requirements on the model's reasoning ability and the flexibility of tool invocation. To this end, we propose a new multimodal agent framework, Vision-Interleaved Chain-of-Thought Framework (VICoT), which implements explicit multi-round reasoning by dynamically incorporating visual tools into the chain of thought. Through a stack-based reasoning structure and a modular MCP-compatible tool suite, VICoT enables LLMs to efficiently perform multi-round, interleaved vision-language reasoning tasks with strong generalization and flexibility.We also propose the Reasoning Stack distillation method to migrate complex Agent behaviors to small, lightweight models, which ensures the reasoning capability while significantly reducing complexity. Experiments on multiple remote sensing benchmarks demonstrate that VICoT significantly outperforms existing SOTA frameworks in reasoning transparency, execution efficiency, and generation quality.

</details>


### [55] [From data to concepts via wiring diagrams](https://arxiv.org/abs/2511.20138)
*Jason Lo,Mohammadnima Jafari*

Main category: cs.AI

TL;DR: 本文提出了准骨架接线图的概念，证明其与Hasse图对应，并设计了从序列数据中提取接线图的算法。该算法在分析自主代理玩电脑游戏时成功识别了获胜策略，并与DBSCAN和凝聚层次聚类算法进行了性能比较。


<details>
  <summary>Details</summary>
Motivation: 接线图是表示抽象概念（如时间过程）的有向标记图。研究旨在开发从序列数据中提取接线图的有效方法，以分析复杂系统中的行为模式。

Method: 引入准骨架接线图概念，证明其与Hasse图的对应关系，设计基于此的算法从序列数据中提取接线图。使用聚类技术（DBSCAN和凝聚层次聚类）进行比较分析。

Result: 算法成功识别了自主代理在电脑游戏中的获胜策略。与标准聚类方法相比，主要算法在数据扰动情况下表现更优。

Conclusion: 该研究将范畴论、图论、聚类、强化学习和数据工程技术相结合，为从序列数据中提取接线图提供了有效的理论框架和算法工具。

Abstract: A wiring diagram is a labeled directed graph that represents an abstract concept such as a temporal process. In this article, we introduce the notion of a quasi-skeleton wiring diagram graph, and prove that quasi-skeleton wiring diagram graphs correspond to Hasse diagrams. Using this result, we designed algorithms that extract wiring diagrams from sequential data. We used our algorithms in analyzing the behavior of an autonomous agent playing a computer game, and the algorithms correctly identified the winning strategies. We compared the performance of our main algorithm with two other algorithms based on standard clustering techniques (DBSCAN and agglomerative hierarchical), including when some of the data was perturbed. Overall, this article brings together techniques in category theory, graph theory, clustering, reinforcement learning, and data engineering.

</details>


### [56] [Towards Benign Memory Forgetting for Selective Multimodal Large Language Model Unlearning](https://arxiv.org/abs/2511.20196)
*Zhen Zeng,Leijiang Gu,Zhangling Duan,Feng Li,Zenglin Shi,Cees G. M. Snoek,Meng Wang*

Main category: cs.AI

TL;DR: 本文提出SMFA方法，通过记忆遗忘适配器和保留锚点引导的掩码机制，实现多模态大语言模型对隐私敏感信息的精确可控遗忘，同时保持模型的一般图像理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型会无意中记忆隐私敏感信息，而现有的遗忘方法在移除这些知识时往往会损害模型的通用图像理解性能，无法实现良性遗忘。

Method: 提出Sculpted Memory Forgetting Adapter (SMFA)，首先微调模型将敏感响应替换为拒绝回答，得到记忆遗忘适配器，然后应用保留锚点引导的掩码机制防止对无关知识和理解能力的干扰。

Result: 实验表明，与现有方法不同，SMFA能够实现精确可控的遗忘，同时保持模型的基础图像理解能力。

Conclusion: SMFA方法成功解决了多模态大语言模型隐私敏感信息遗忘的问题，在移除敏感知识的同时有效保留了模型的通用视觉理解能力。

Abstract: Multimodal Large Language Models (MLLMs) achieve remarkable capabilities but can inadvertently memorize privacy-sensitive information. Although existing unlearning methods can remove such knowledge, they fail to achieve benign forgetting because they often degrade the model's general image understanding performance. To address this, we propose the Sculpted Memory Forgetting Adapter (SMFA), which confines forgetting to targeted memory regions while preserving overall capabilities. SMFA first fine-tunes the model to replace sensitive responses with refusals, yielding a memory forgetting adapter, and then applies a retaining anchor-guided masking mechanism to prevent interference with unrelated knowledge and understanding ability. To systematically evaluate selective MLLM unlearning, we introduce S-MLLMUn Bench, the first benchmark designed to jointly assess the removal of sensitive knowledge and retention of general visual understanding. Extensive experiments show that, unlike prior methods, SMFA achieves precise and controllable unlearning while maintaining the model's foundational image understanding.

</details>


### [57] [Interactive AI NPCs Powered by LLMs: Technical Report for the CPDC Challenge 2025](https://arxiv.org/abs/2511.20200)
*Yitian Huang,Yuxuan Lei,Jianxun Lian,Hao Liao*

Main category: cs.AI

TL;DR: 提出了一个简单有效的框架，在CPDC 2025挑战赛中取得优异成绩，包括API Track第一名和GPU Track第三名。


<details>
  <summary>Details</summary>
Motivation: 解决工具调用稳定性、执行可靠性和角色扮演指导的问题，同时缓解小样本过拟合。

Method: 上下文工程（动态工具剪枝、角色剪裁、参数归一化、函数合并）和GRPO训练（用强化学习替代监督微调）。

Result: 在最终评估中，Task 2 API排名第一，Task 1 API排名第二，Task 3 API和GPU Track均排名第三。

Conclusion: 该方法在常识人物接地对话任务中表现出色，证明了框架的有效性。

Abstract: This report presents the solution and results of our team MSRA\_SC in the Commonsense Persona-Grounded Dialogue Challenge (CPDC 2025). We propose a simple yet effective framework that unifies improvements across both GPU Track and API Track. Our method centers on two key components. First, Context Engineering applies dynamic tool pruning and persona clipping for input compression, combined with post-processing techniques such as parameter normalization and function merging. Together with manually refined prompts, this design improves tool call stability, execution reliability, and role-playing guidance. Second, in the GPU Track, we further adopt GRPO training, replacing supervised fine-tuning with reinforcement learning directly optimized by reward signals. This mitigates small-sample overfitting and significantly enhances task-oriented dialogue performance. In the final evaluation, our team ranks 1st in Task 2 API, 2nd in Task 1 API, and 3rd in both Task 3 API and GPU track, demonstrating the effectiveness of our approach. Our code is publicly available at https://gitlab.aicrowd.com/nikoo_yu/cpdc-2025-winning-solution

</details>


### [58] [CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents](https://arxiv.org/abs/2511.20216)
*Haebin Seong,Sungmin Kim,Minchan Kim,Yongjun Cho,Myunchul Joe,Suhwan Choi,Jaeyoon Jung,Jiyong Youn,Yoonshik Kim,Samwoo Seong,Yubeen Park,Youngjae Yu,Yunsung Lee*

Main category: cs.AI

TL;DR: CostNav是首个评估自主送货机器人商业可行性的微观导航经济测试平台，通过成本收益分析揭示导航研究指标与商业部署之间的差距。


<details>
  <summary>Details</summary>
Motivation: 现有导航基准只关注任务成功率，忽略了经济可行性这一对商业部署至关重要的因素。

Method: CostNav建模完整的经济生命周期，包括硬件、训练、能源、维护成本和配送收入，使用行业参数进行成本收益分析。

Result: 基准模型达到43.0%的服务水平协议合规率，但不可行：每次运行亏损30.009美元，维护成本占99.7%，主要来自碰撞。

Conclusion: CostNav填补了导航研究与商业部署之间的鸿沟，为评估基于规则的导航、模仿学习和成本感知强化学习提供了基础。

Abstract: Existing navigation benchmarks focus on task success metrics while overlooking economic viability -- critical for commercial deployment of autonomous delivery robots. We introduce \emph{CostNav}, a \textbf{Micro-Navigation Economic Testbed} that evaluates embodied agents through comprehensive cost-revenue analysis aligned with real-world business operations. CostNav models the complete economic lifecycle including hardware, training, energy, maintenance costs, and delivery revenue with service-level agreements, using industry-derived parameters. \textbf{To our knowledge, CostNav is the first work to quantitatively expose the gap between navigation research metrics and commercial viability}, revealing that optimizing for task success fundamentally differs from optimizing for economic deployment. Our cost model uses parameters derived from industry data sources (energy rates, delivery service pricing), and we project from a reduced-scale simulation to realistic deliveries. Under this projection, the baseline achieves 43.0\% SLA compliance but is \emph{not} commercially viable: yielding a loss of \$30.009 per run with no finite break-even point, because operating costs are dominated by collision-induced maintenance, which accounts for 99.7\% of per-run costs and highlights collision avoidance as a key optimization target. We demonstrate a learning-based on-device navigation baseline and establish a foundation for evaluating rule-based navigation, imitation learning, and cost-aware RL training. CostNav bridges the gap between navigation research and commercial deployment, enabling data-driven decisions about economic trade-offs across navigation paradigms.

</details>


### [59] [Actionable and diverse counterfactual explanations incorporating domain knowledge and causal constraints](https://arxiv.org/abs/2511.20236)
*Szymon Bobek,Łukasz Bałec,Grzegorz J. Nalepa*

Main category: cs.AI

TL;DR: 提出DANCE方法，通过整合特征依赖关系和因果约束来生成多样化、可操作且符合知识约束的反事实解释，确保反事实的合理性和现实可行性。


<details>
  <summary>Details</summary>
Motivation: 现有反事实解释方法往往忽略真实数据集中的复杂依赖关系，导致产生不现实或不切实际的修改。受网络安全在电子邮件营销领域应用的启发，需要确保反事实的合理性和现实可行性。

Method: 提出DANCE方法，从数据中学习线性和非线性约束，或整合专家提供的依赖图，确保反事实合理且可操作。通过保持与特征关系的一致性，生成符合现实约束的解释。

Result: 在140个公共数据集上的广泛评估表明，该方法能够生成有意义、领域相关的反事实，在广泛使用的指标上优于其他现有方法。

Conclusion: DANCE方法有效解决了现有算法在合理性、多样性和稀疏性方面的关键限制，为反事实解释提供了更实用的解决方案。

Abstract: Counterfactual explanations enhance the actionable interpretability of machine learning models by identifying the minimal changes required to achieve a desired outcome of the model. However, existing methods often ignore the complex dependencies in real-world datasets, leading to unrealistic or impractical modifications. Motivated by cybersecurity applications in the email marketing domain, we propose a method for generating Diverse, Actionable, and kNowledge-Constrained Explanations (DANCE), which incorporates feature dependencies and causal constraints to ensure plausibility and real-world feasibility of counterfactuals. Our method learns linear and nonlinear constraints from data or integrates expert-provided dependency graphs, ensuring counterfactuals are plausible and actionable. By maintaining consistency with feature relationships, the method produces explanations that align with real-world constraints. Additionally, it balances plausibility, diversity, and sparsity, effectively addressing key limitations in existing algorithms. The work is developed based on a real-life case study with Freshmail, the largest email marketing company in Poland and supported by a joint R&D project Sendguard. Furthermore, we provide an extensive evaluation using 140 public datasets, which highlights its ability to generate meaningful, domain-relevant counterfactuals that outperform other existing approaches based on widely used metrics. The source code for reproduction of the results can be found in a GitHub repository we provide.

</details>


### [60] [SMoG: Schema Matching on Graph](https://arxiv.org/abs/2511.20285)
*Mingyu Jeon,Jaeyoung Suh,Suwan Cho*

Main category: cs.AI

TL;DR: SMoG框架使用简单的1跳SPARQL查询进行知识图谱增强的模式匹配，在医疗数据集成中实现高性能、高可解释性和低存储需求


<details>
  <summary>Details</summary>
Motivation: 解决LLM在模式匹配中的幻觉问题和缺乏最新领域知识的问题，同时避免现有KG增强方法的复杂多跳查询和存储密集型检索

Method: 基于知识图谱问答的成功策略，使用迭代执行的简单1跳SPARQL查询，直接查询SPARQL端点

Result: 在真实医疗数据集上实现与最先进基线相当的性能，同时提高可解释性和可靠性

Conclusion: SMoG在知识图谱增强的模式匹配中有效且高效，特别适用于医疗领域的OMOP CDM对齐任务

Abstract: Schema matching is a critical task in data integration, particularly in the medical domain where disparate Electronic Health Record (EHR) systems must be aligned to standard models like OMOP CDM. While Large Language Models (LLMs) have shown promise in schema matching, they suffer from hallucination and lack of up-to-date domain knowledge. Knowledge Graphs (KGs) offer a solution by providing structured, verifiable knowledge. However, existing KG-augmented LLM approaches often rely on inefficient complex multi-hop queries or storage-intensive vector-based retrieval methods. This paper introduces SMoG (Schema Matching on Graph), a novel framework that leverages iterative execution of simple 1-hop SPARQL queries, inspired by successful strategies in Knowledge Graph Question Answering (KGQA). SMoG enhances explainability and reliability by generating human-verifiable query paths while significantly reducing storage requirements by directly querying SPARQL endpoints. Experimental results on real-world medical datasets demonstrate that SMoG achieves performance comparable to state-of-the-art baselines, validating its effectiveness and efficiency in KG-augmented schema matching.

</details>


### [61] [Improving Language Agents through BREW](https://arxiv.org/abs/2511.20297)
*Shashank Kirtania,Param Biyani,Priyanshu Gupta,Yasharth Bajpai,Roshni Iyer,Sumit Gulwani,Gustavo Soares*

Main category: cs.AI

TL;DR: BREW框架通过构建和优化经验知识库来改进LLM智能体，在保持计算效率的同时提升任务精度10-20%，减少API调用10-15%，实现更透明可控的智能体优化。


<details>
  <summary>Details</summary>
Motivation: 当前基于PPO和GRPO的智能体训练方法计算开销大，收敛困难，且生成的策略难以解释、适应或增量改进。需要一种更实用、可解释的智能体优化方法。

Method: 提出BREW框架，通过构建和优化经验知识库来优化智能体。引入有效的记忆分区方法提高检索和优化效率，使用任务评分器和行为准则学习洞察，利用状态空间搜索确保鲁棒性。

Result: 在OSWorld、τ²Bench和SpreadsheetBench等真实世界基准测试中，BREW实现了10-20%的任务精度提升，10-15%的API/工具调用减少，执行时间更快，同时保持与基础模型相当的计算效率。

Conclusion: 与将记忆视为静态上下文的先前工作不同，BREW将知识库建立为模块化和可控的智能体优化基础——一个用于以透明、可解释和可扩展方式塑造行为的明确杠杆。

Abstract: Large Language Model (LLM)-based agents are increasingly applied to tasks requiring structured reasoning, tool use, and environmental adaptation, such as data manipulation, multistep planning, and computer-use automation. However, despite their versatility, current training paradigms for model weight optimization methods, like PPO and GRPO, remain relatively impractical with their high computational overhead for rollout convergence. In addition, the resulting agent policies are difficult to interpret, adapt, or incrementally improve. To address this, we investigate creating and refining structured memory of experiential learning of an agent from its environment as an alternative route to agent optimization. We introduce BREW (Bootstrapping expeRientially-learned Environmental knoWledge), a framework for agent optimization for downstream tasks via KB construction and refinement. In our formulation, we introduce an effective method for partitioning agent memory for more efficient retrieval and refinement. BREW uses task graders and behavior rubrics to learn insights while leveraging state-space search for ensuring robustness from the noise and non-specificity in natural language. Empirical results on real world, domain-grounded benchmarks -- OSWorld, $τ^2$Bench, and SpreadsheetBench -- show BREW achieves $10-20\%$ improvement in task precision, $10-15\%$ reduction in API/tool calls leading to faster execution time, all while maintaining computational efficiency on par with base models. Unlike prior work where memory is treated as static context, we establish the KB as a modular and controllable substrate for agent optimization -- an explicit lever for shaping behavior in a transparent, interpretable, and extensible manner.

</details>


### [62] [Data Augmentation Techniques to Reverse-Engineer Neural Network Weights from Input-Output Queries](https://arxiv.org/abs/2511.20312)
*Alexander Beiser,Flavio Martinelli,Wulfram Gerstner,Johanni Brea*

Main category: cs.AI

TL;DR: 提出新的数据增强技术来改进教师网络参数的反向工程，能够恢复参数数量是训练数据100倍的网络。


<details>
  <summary>Details</summary>
Motivation: 现有方法在教师网络参数多于训练数据时会失败，因为学生会过度拟合查询数据而不是对齐教师参数。需要更好的数据增强技术来充分采样教师网络的输入-输出映射。

Method: 设计专门针对网络隐藏层表示空间采样的新数据增强技术，而不是使用标准增强方法如旋转、翻转和添加噪声。

Result: 新增强技术扩展了可恢复网络大小的最先进范围，能够恢复参数数量是训练数据100倍的网络。

Conclusion: 专门设计的表示空间数据增强技术显著改进了教师网络参数的反向工程效果。

Abstract: Network weights can be reverse-engineered given enough informative samples of a network's input-output function. In a teacher-student setup, this translates into collecting a dataset of the teacher mapping -- querying the teacher -- and fitting a student to imitate such mapping. A sensible choice of queries is the dataset the teacher is trained on. But current methods fail when the teacher parameters are more numerous than the training data, because the student overfits to the queries instead of aligning its parameters to the teacher. In this work, we explore augmentation techniques to best sample the input-output mapping of a teacher network, with the goal of eliciting a rich set of representations from the teacher hidden layers. We discover that standard augmentations such as rotation, flipping, and adding noise, bring little to no improvement to the identification problem. We design new data augmentation techniques tailored to better sample the representational space of the network's hidden layers. With our augmentations we extend the state-of-the-art range of recoverable network sizes. To test their scalability, we show that we can recover networks of up to 100 times more parameters than training data-points.

</details>


### [63] [Active Inference in Discrete State Spaces from First Principles](https://arxiv.org/abs/2511.20321)
*Patrick Kenny*

Main category: cs.AI

TL;DR: 本文区分了主动推理与自由能原理，提出在离散状态空间中实现主动推理的优化可表述为约束散度最小化问题，可通过标准平均场方法求解，无需依赖期望自由能概念。


<details>
  <summary>Details</summary>
Motivation: 澄清主动推理概念，将其与自由能原理分离开来，展示主动推理在离散状态空间中的实现方式。

Method: 将主动推理优化问题表述为约束散度最小化问题，使用标准平均场方法求解，不依赖期望自由能概念。

Result: 在建模感知时，提出的感知/行动散度准则与变分自由能一致；在建模行动时，与期望自由能泛函相差一个熵正则项。

Conclusion: 主动推理可以通过约束散度最小化框架实现，无需诉诸期望自由能概念，这为理解主动推理提供了更清晰的数学基础。

Abstract: We seek to clarify the concept of active inference by disentangling it from the Free Energy Principle. We show how the optimizations that need to be carried out in order to implement active inference in discrete state spaces can be formulated as constrained divergence minimization problems which can be solved by standard mean field methods that do not appeal to the idea of expected free energy. When it is used to model perception, the perception/action divergence criterion that we propose coincides with variational free energy. When it is used to model action, it differs from an expected free energy functional by an entropy regularizer.

</details>


### [64] [NNGPT: Rethinking AutoML with Large Language Models](https://arxiv.org/abs/2511.20333)
*Roman Kochnev,Waleed Khalid,Tolgay Atinc Uzun,Xi Zhang,Yashkumar Sanjaybhai Dhameliya,Furui Qin,Chandini Vysyaraju,Raghuvir Duvvuri,Avi Goyal,Dmitry Ignatov,Radu Timofte*

Main category: cs.AI

TL;DR: NNGPT是一个开源框架，将大型语言模型转化为用于神经网络开发的自改进AutoML引擎，通过生成-评估-自改进的闭环系统持续优化模型性能。


<details>
  <summary>Details</summary>
Motivation: 构建自改进AI系统是AI领域的根本挑战，现有框架在神经网络数据集扩展和持续优化方面存在局限。

Method: 集成五个协同的LLM管道：零样本架构合成、超参数优化、代码感知精度预测、检索增强的PyTorch块合成和强化学习，基于LEMUR数据集构建闭环系统。

Result: NN-RAG在1,289个目标上达到73%可执行性，HPO在LEMUR上RMSE为0.60优于Optuna，已生成超过5K验证模型。

Conclusion: NNGPT被证明是一个自主的AutoML引擎，能够显著减少试验次数并提升性能，代码将公开发布以促进社区使用。

Abstract: Building self-improving AI systems remains a fundamental challenge in the AI domain. We present NNGPT, an open-source framework that turns a large language model (LLM) into a self-improving AutoML engine for neural network development, primarily for computer vision. Unlike previous frameworks, NNGPT extends the dataset of neural networks by generating new models, enabling continuous fine-tuning of LLMs based on closed-loop system of generation, assessment, and self-improvement. It integrates within one unified workflow five synergistic LLM-based pipelines: zero-shot architecture synthesis, hyperparameter optimization (HPO), code-aware accuracy/early-stop prediction, retrieval-augmented synthesis of scope-closed PyTorch blocks (NN-RAG), and reinforcement learning. Built on the LEMUR dataset as an audited corpus with reproducible metrics, NNGPT emits from a single prompt and validates network architecture, preprocessing code, and hyperparameters, executes them end-to-end, and learns from result. The PyTorch adapter makes NNGPT framework-agnostic, enabling strong performance: NN-RAG achieves 73% executability on 1,289 targets, 3-shot prompting boosts accuracy on common datasets, and hash-based deduplication saves hundreds of runs. One-shot prediction matches search-based AutoML, reducing the need for numerous trials. HPO on LEMUR achieves RMSE 0.60, outperforming Optuna (0.64), while the code-aware predictor reaches RMSE 0.14 with Pearson r=0.78. The system has already generated over 5K validated models, proving NNGPT as an autonomous AutoML engine. Upon acceptance, the code, prompts, and checkpoints will be released for public access to enable reproducibility and facilitate community usage.

</details>


### [65] [VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning](https://arxiv.org/abs/2511.20422)
*Bo Pang,Chenxi Xu,Jierui Ren,Guoping Wang,Sheng Li*

Main category: cs.AI

TL;DR: VibraVerse是一个大规模几何-声学对齐数据集，通过CLASP对比学习框架建立物理一致性跨模态对齐，从3D几何到物理属性再到声学信号的因果链，为物理一致的多模态学习提供基准。


<details>
  <summary>Details</summary>
Motivation: 现有多模态学习框架缺乏物理一致性，忽视了物体几何、材料、振动模式和产生声音之间的内在因果关系，需要建立基于物理定律的感知模型。

Method: 构建VibraVerse数据集，包含3D模型的物理属性和体积几何，计算模态特征参数进行冲击声合成；提出CLASP对比学习框架实现跨模态对齐，保持物理结构到声学响应的因果对应。

Result: 在几何到声音预测、声音引导形状重建和跨模态表示学习等基准任务上，基于VibraVerse训练的模型展现出更高的准确性、可解释性和跨模态泛化能力。

Conclusion: VibraVerse为物理一致和因果可解释的多模态学习建立了基准，为声音引导的具身感知和物理世界理解提供了基础，数据集将开源。

Abstract: Understanding the physical world requires perceptual models grounded in physical laws rather than mere statistical correlations. However, existing multimodal learning frameworks, focused on vision and language, lack physical consistency and overlook the intrinsic causal relationships among an object's geometry, material, vibration modes, and the sounds it produces. We introduce VibraVerse, a large-scale geometry-acoustics alignment dataset that explicitly bridges the causal chain from 3D geometry -> physical attributes -> modal parameters -> acoustic signals. Each 3D model has explicit physical properties (density, Young's modulus, Poisson's ratio) and volumetric geometry, from which modal eigenfrequencies and eigenvectors are computed for impact sound synthesis under controlled excitations. To establish this coherence, we introduce CLASP, a contrastive learning framework for cross-modal alignment that preserves the causal correspondence between an object's physical structure and its acoustic response. This framework enforces physically consistent alignment across modalities, ensuring that every sample is coherent, traceable to the governing equations, and embedded within a unified representation space spanning shape, image, and sound. Built upon VibraVerse, we define a suite of benchmark tasks for geometry-to-sound prediction, sound-guided shape reconstruction, and cross-modal representation learning. Extensive validations on these tasks demonstrate that models trained on VibraVerse exhibit superior accuracy, interpretability, and generalization across modalities. These results establish VibraVerse as a benchmark for physically consistent and causally interpretable multimodal learning, providing a foundation for sound-guided embodied perception and a deeper understanding of the physical world. The dataset will be open-sourced.

</details>


### [66] [DRAFT-RL: Multi-Agent Chain-of-Draft Reasoning for Reinforcement Learning-Enhanced LLMs](https://arxiv.org/abs/2511.20468)
*Yuanhao Li,Mingshan Liu,Hongbo Wang,Yiding Zhang,Yifei Ma,Wei Tan*

Main category: cs.AI

TL;DR: DRAFT-RL是一个新颖的多智能体强化学习框架，将链式草稿推理集成到多智能体训练中，通过生成多个草稿、同行评估和奖励模型选择来提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的多智能体反思框架通常依赖单次响应，缺乏推理探索的结构多样性，限制了LLM智能体的推理能力。

Method: 每个智能体为每个查询生成多个草稿，由同行智能体和学习的奖励模型评估，选择最有前景的轨迹，通过actor-critic学习优化未来推理策略。

Result: 在代码合成、符号数学和知识密集型问答等复杂推理任务上，DRAFT-RL在准确性和收敛速度方面显著优于现有的反思和基于RL的智能体。

Conclusion: DRAFT-RL通过显式多路径探索、同行引导反思和奖励对齐选择，实现了更鲁棒和可解释的LLM智能体行为。

Abstract: Large Language Models (LLMs) have shown impressive capabilities in multi-step reasoning and problem-solving.Recent works introduce multi-agent reflection frameworks where multiple LLM agents critique and refine each other's outputs using reinforcement learning (RL). However, these approaches often rely on single-shot responses and lack structural diversity in reasoning exploration. In this paper, we propose DRAFT-RL, a novel framework that integrates Chain-of-Draft (CoD) reasoning into multi-agent RL training. Instead of generating single responses, each agent produces multiple drafts per query, which are then evaluated by peer agents and a learned reward model to identify the most promising trajectory. These selected drafts are used to refine future reasoning strategies through actor-critic learning.DRAFT-RL enables explicit multi-path exploration, peer-guided reflection, and reward-aligned selection, resulting in more robust and interpretable LLM agent behavior. We evaluate our method on complex reasoning tasks including code synthesis, symbolic math, and knowledge-intensive QA,demonstrating that DRAFT-RL outperforms existing reflective and RL-based agents by significant margins in both accuracy and convergence speed

</details>


### [67] [Universe of Thoughts: Enabling Creative Reasoning with Large Language Models](https://arxiv.org/abs/2511.20471)
*Yuto Suzuki,Farnoush Banaei-Kashani*

Main category: cs.AI

TL;DR: 本文提出了一个基于大语言模型的创造性推理框架，包括组合式、探索式和转化式三种核心推理范式，并开发了"思想宇宙"方法来实现这些创造性过程。


<details>
  <summary>Details</summary>
Motivation: 现有推理模型主要关注常规问题解决，但在药物发现、商业策略等需要创新解决方案的领域，创造性推理至关重要。

Method: 提出了基于认知科学原理的计算框架，包含三种创造性推理范式，并开发了UoT方法来实现这些过程。

Result: 与最先进的推理技术和商业模型相比，UoT在创造性推理方面表现出优越性能。

Conclusion: UoT框架为LLM的创造性推理提供了系统方法，在需要创新解决方案的领域具有重要应用价值。

Abstract: Reasoning based on Large Language Models (LLMs) has garnered increasing attention due to outstanding performance of these models in mathematical and complex logical tasks. Beginning with the Chain-of-Thought (CoT) prompting technique, numerous reasoning methods have emerged that decompose problems into smaller, sequential steps (or thoughts). However, existing reasoning models focus on conventional problem-solving and do not necessarily generate creative solutions by ``creative reasoning''. In domains where the solution space is expansive and conventional solutions are suboptimal, such as drug discovery or business strategization, creative reasoning to discover innovative solutions is crucial. To address this gap, first we introduce a computational framework for creative reasoning inspired by established cognitive science principles. With this framework, we propose three core creative reasoning paradigms, namely, \textit{combinational}, \textit{exploratory}, and \textit{transformative} reasoning, where each offers specific directions for systematic exploration of the universe of thoughts to generate creative solutions. Next, to materialize this framework using LLMs, we introduce the \textit{Universe of Thoughts} (or \textit{UoT}, for short), a novel set of methods to implement the aforementioned three creative processes. Finally, we introduce three novel tasks that necessitate creative problem-solving, along with an evaluation benchmark to assess creativity from three orthogonal perspectives: feasibility as constraint, and utility and novelty as metrics. With a comparative analysis against the state-of-the-art (SOTA) reasoning techniques as well as representative commercial models with reasoning capability, we show that UoT demonstrates superior performance in creative reasoning.

</details>


### [68] [Quantifying the Privacy Implications of High-Fidelity Synthetic Network Traffic](https://arxiv.org/abs/2511.20497)
*Van Tran,Shinan Liu,Tian Li,Nick Feamster*

Main category: cs.AI

TL;DR: 本文提出了针对合成网络流量的隐私评估指标，发现不同生成模型存在显著的隐私泄露风险，MIA攻击成功率最高达88%，网络标识符恢复率可达100%。


<details>
  <summary>Details</summary>
Motivation: 解决合成网络流量数据稀缺和隐私问题，但现有生成模型产生的流量并非天然隐私保护，其敏感信息泄露程度和测量方法尚未充分探索。

Method: 引入了一套全面的隐私评估指标，结合标准方法（如成员推断攻击MIA和数据提取攻击）与网络特定标识符和属性，系统评估不同代表性生成模型的脆弱性。

Result: 结果显示不同模型和数据集间的隐私风险存在显著差异，MIA成功率从0%到88%，网络标识符恢复率可达100%，揭示了严重的隐私漏洞。

Conclusion: 识别了影响攻击结果的关键因素（如训练数据多样性和模型拟合度），为设计最小化隐私泄露的生成模型提供了可操作指导，建立了更安全的合成网络流量生成基础。

Abstract: To address the scarcity and privacy concerns of network traffic data, various generative models have been developed to produce synthetic traffic. However, synthetic traffic is not inherently privacy-preserving, and the extent to which it leaks sensitive information, and how to measure such leakage, remain largely unexplored. This challenge is further compounded by the diversity of model architectures, which shape how traffic is represented and synthesized. We introduce a comprehensive set of privacy metrics for synthetic network traffic, combining standard approaches like membership inference attacks (MIA) and data extraction attacks with network-specific identifiers and attributes. Using these metrics, we systematically evaluate the vulnerability of different representative generative models and examine the factors that influence attack success. Our results reveal substantial variability in privacy risks across models and datasets. MIA success ranges from 0% to 88%, and up to 100% of network identifiers can be recovered from generated traffic, highlighting serious privacy vulnerabilities. We further identify key factors that significantly affect attack outcomes, including training data diversity and how well the generative model fits the training data. These findings provide actionable guidance for designing and deploying generative models that minimize privacy leakage, establishing a foundation for safer synthetic network traffic generation.

</details>


### [69] [FRAGMENTA: End-to-end Fragmentation-based Generative Model with Agentic Tuning for Drug Lead Optimization](https://arxiv.org/abs/2511.20510)
*Yuto Suzuki,Paul Awolade,Daniel V. LaBarbera,Farnoush Banaei-Kashani*

Main category: cs.AI

TL;DR: FRAGMENTA是一个用于药物先导化合物优化的端到端框架，包含生成模型和智能AI系统，通过动态Q学习优化分子碎片化和生成，并通过对话反馈学习领域知识，在癌症药物发现实验中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 分子生成在药物发现中很重要，但类别特定数据集通常少于100个训练样本。现有碎片化方法多样性有限且错过关键片段，模型调优需要化学家和AI工程师之间的缓慢协作。

Method: 1) 新颖生成模型，将碎片化重构为"词汇选择"问题，使用动态Q学习联合优化碎片化和生成；2) 智能AI系统通过领域专家的对话反馈精炼目标，逐步学习领域知识实现自动化调优。

Result: 在真实癌症药物发现实验中，FRAGMENTA的人类-智能体配置识别的高分分子数量是基线的近两倍。完全自主的智能体-智能体系统优于传统的人类-人类调优。

Conclusion: FRAGMENTA展示了智能体调优在捕捉专家意图方面的有效性，能够自动化药物发现流程并提高效率。

Abstract: Molecule generation using generative AI is vital for drug discovery, yet class-specific datasets often contain fewer than 100 training examples. While fragment-based models handle limited data better than atom-based approaches, existing heuristic fragmentation limits diversity and misses key fragments. Additionally, model tuning typically requires slow, indirect collaboration between medicinal chemists and AI engineers. We introduce FRAGMENTA, an end-to-end framework for drug lead optimization comprising: 1) a novel generative model that reframes fragmentation as a "vocabulary selection" problem, using dynamic Q-learning to jointly optimize fragmentation and generation; and 2) an agentic AI system that refines objectives via conversational feedback from domain experts. This system removes the AI engineer from the loop and progressively learns domain knowledge to eventually automate tuning. In real-world cancer drug discovery experiments, FRAGMENTA's Human-Agent configuration identified nearly twice as many high-scoring molecules as baselines. Furthermore, the fully autonomous Agent-Agent system outperformed traditional Human-Human tuning, demonstrating the efficacy of agentic tuning in capturing expert intent.

</details>


### [70] [Assessing LLMs' Performance: Insights from the Chinese Pharmacist Exam](https://arxiv.org/abs/2511.20526)
*Xinran Wang,Boran Zhu,Shujuan Zhou,Ziwen Long,Dehua Zhou,Shu Zhang*

Main category: cs.AI

TL;DR: 本研究比较了ChatGPT-4o和DeepSeek-R1在中国药师执业资格考试中的表现，发现DeepSeek-R1在准确率上显著优于ChatGPT-4o（90.0% vs 76.1%）。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在数字健康教育和评估中的应用日益增多，需要评估其在特定领域高利害认证任务中的能力。中国药师执业资格考试作为标准化基准，适合评估模型在药学领域的临床和理论能力。

Method: 收集2017-2021年官方考试中的2,306道纯文本选择题，排除含表格或图像的题目。将题目以中文原格式输入模型，评估模型响应的准确率，使用Pearson卡方检验比较整体表现，Fisher精确检验分析年度选择题准确率。

Result: DeepSeek-R1整体准确率显著高于ChatGPT-4o（90.0% vs 76.1%，p < 0.001）。单元分析显示DeepSeek-R1在基础和临床综合模块中表现一致更优。虽然年度选择题表现也倾向于DeepSeek-R1，但在任何特定单元-年份组合中这一差距未达到统计显著性。

Conclusion: DeepSeek-R1在药师执业资格考试的结构和语义要求方面表现出良好的对齐性。这些发现表明特定领域模型在此背景下值得进一步研究，同时也强调了在法律和伦理敏感情境中保持人工监督的必要性。

Abstract: Background: As large language models (LLMs) become increasingly integrated into digital health education and assessment workflows, their capabilities in supporting high-stakes, domain-specific certification tasks remain underexplored.In China, the national pharmacist licensure exam serves as a standardized benchmark for evaluating pharmacists' clinical and theoretical competencies. Objective: This study aimed to compare the performance of two LLMs: ChatGPT-4o and DeepSeek-R1 on real questions from the Chinese Pharmacist Licensing Examination (2017-2021), and to discuss the implications of these performance differences for AI-enabled formative evaluation. Methods: A total of 2,306 multiple-choice (text-only) questions were compiled from official exams, training materials, and public databases. Questions containing tables or images were excluded. Each item was input in its original Chinese format, and model responses were evaluated for exact accuracy. Pearson's Chi-squared test was used to compare overall performance, and Fisher's exact test was applied to year-wise multiple-choice accuracy. Results: DeepSeek-R1 outperformed ChatGPT-4o with a significantly higher overall accuracy (90.0% vs. 76.1%, p < 0.001). Unit-level analyses revealed consistent advantages for DeepSeek-R1, particularly in foundational and clinical synthesis modules. While year-by-year multiple-choice performance also favored DeepSeek-R1, this performance gap did not reach statistical significance in any specific unit-year (all p > 0.05). Conclusion: DeepSeek-R1 demonstrated robust alignment with the structural and semantic demands of the pharmacist licensure exam. These findings suggest that domain-specific models warrant further investigation for this context, while also reinforcing the necessity of human oversight in legally and ethically sensitive contexts.

</details>


### [71] [Beyond Generation: Multi-Hop Reasoning for Factual Accuracy in Vision-Language Models](https://arxiv.org/abs/2511.20531)
*Shamima Hossain*

Main category: cs.AI

TL;DR: 提出一个基于知识图谱的视觉语言模型推理框架，通过多跳验证提升事实准确性，在初步实验中实现了约31%的事实准确率提升


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型虽然功能强大，但常常产生事实不准确的输出，缺乏稳健的推理能力。目前对外部知识集成的研究主要集中在纯语言模型，而在多模态视觉语言模型中的探索不足

Method: 开发了一个知识引导的推理框架，利用结构化知识图谱进行多跳验证。方法包括视觉实体识别、知识图谱遍历和基于事实的标题精炼等多个系统推理步骤

Result: 在由Google Landmarks v2、Conceptual captions和Coco captions混合组成的定制数据集上进行初步实验，结果显示事实准确率提高了约31%

Conclusion: 这项工作展示了集成外部知识在推进视觉语言模型推理方面的潜力，为构建更可靠、知识更丰富的多模态系统铺平了道路

Abstract: Visual Language Models (VLMs) are powerful generative tools but often produce factually inaccurate outputs due to a lack of robust reasoning capabilities. While extensive research has been conducted on integrating external knowledge for reasoning in large language models (LLMs), such efforts remain underexplored in VLMs, where the challenge is compounded by the need to bridge multiple modalities seamlessly. This work introduces a framework for knowledge-guided reasoning in VLMs, leveraging structured knowledge graphs for multi-hop verification using image-captioning task to illustrate our framework. Our approach enables systematic reasoning across multiple steps, including visual entity recognition, knowledge graph traversal, and fact-based caption refinement. We evaluate the framework using hierarchical, triple-based and bullet-point based knowledge representations, analyzing their effectiveness in factual accuracy and logical inference. Empirical results show that our approach improves factual accuracy by approximately 31% on preliminary experiments on a curated dataset of mixtures from Google Landmarks v2, Conceptual captions and Coco captions revealing key insights into reasoning patterns and failure modes. This work demonstrates the potential of integrating external knowledge for advancing reasoning in VLMs, paving the way for more reliable and knowledgable multimodal systems.

</details>


### [72] [PaTAS: A Parallel System for Trust Propagation in Neural Networks Using Subjective Logic](https://arxiv.org/abs/2511.20586)
*Koffi Ismael Ouattara,Ioannis Krontiris,Theo Dimitrakos,Dennis Eisermann,Frank Kargl*

Main category: cs.AI

TL;DR: 提出了PaTAS框架，使用主观逻辑在神经网络中建模和传播信任度，通过并行信任节点和函数评估输入、参数和激活的可靠性，提供可解释的信任评估。


<details>
  <summary>Details</summary>
Motivation: 传统评估指标如准确率无法捕捉模型预测的不确定性或可靠性，特别是在对抗性或退化条件下。需要一种能量化模型信任度的系统来确保AI系统在安全关键应用中的可信度。

Method: PaTAS框架包含信任节点和信任函数，在标准神经网络计算中并行运行，传播输入、参数和激活的信任度。定义了参数信任更新机制和推理路径信任评估方法。

Result: 在真实世界和对抗性数据集上的实验表明，PaTAS产生可解释、对称且收敛的信任估计，能有效区分良性输入和对抗性输入，识别模型置信度与实际可靠性不一致的情况。

Conclusion: PaTAS通过在神经架构中实现透明和可量化的信任推理，为评估AI生命周期中的模型可靠性提供了原则性基础。

Abstract: Trustworthiness has become a key requirement for the deployment of artificial intelligence systems in safety-critical applications. Conventional evaluation metrics such as accuracy and precision fail to capture uncertainty or the reliability of model predictions, particularly under adversarial or degraded conditions. This paper introduces the \emph{Parallel Trust Assessment System (PaTAS)}, a framework for modeling and propagating trust in neural networks using Subjective Logic (SL). PaTAS operates in parallel with standard neural computation through \emph{Trust Nodes} and \emph{Trust Functions} that propagate input, parameter, and activation trust across the network. The framework defines a \emph{Parameter Trust Update} mechanism to refine parameter reliability during training and an \emph{Inference-Path Trust Assessment (IPTA)} method to compute instance-specific trust at inference. Experiments on real-world and adversarial datasets demonstrate that PaTAS produces interpretable, symmetric, and convergent trust estimates that complement accuracy and expose reliability gaps in poisoned, biased, or uncertain data scenarios. The results show that PaTAS effectively distinguishes between benign and adversarial inputs and identifies cases where model confidence diverges from actual reliability. By enabling transparent and quantifiable trust reasoning within neural architectures, PaTAS provides a principled foundation for evaluating model reliability across the AI lifecycle.

</details>


### [73] [Building a Foundation Model for Trajectory from Scratch](https://arxiv.org/abs/2511.20610)
*Gaspard Merten,Mahmoud Sakr,Gilles Dejaegere*

Main category: cs.AI

TL;DR: 本教程通过代码驱动的分步过程，展示了从GPT-2开始构建轨迹基础模型的最小实现，比较了TrajFM和TrajGPT等代表性模型，并介绍了TimesFM的补丁方法等补充技术。


<details>
  <summary>Details</summary>
Motivation: 虽然基础模型在人工智能中具有变革性，但为移动轨迹从头开始构建这些模型的方法尚不明确或缺乏文档记录，本教程旨在填补这一空白。

Method: 通过代码驱动的分步过程，演示如何将GPT-2适配于时空数据，并比较代表性轨迹基础模型的架构创新和差异。

Result: 提供了构建和评估移动基础模型的实用指南，支持SIGSPATIAL社区在此领域的研究工作。

Conclusion: 创建这种教育材料对于支持SIGSPATIAL社区构建和评估移动基础模型、提高移动AI研究清晰度和同行评审效果是及时且不可或缺的。

Abstract: Foundation models are transformative in artificial intelligence, but building them from scratch, especially for mobility trajectories, is not yet clear or documented. This tutorial bridges this gap by demonstrating the steps and code of a minimal implementation of a trajectory-focused foundation model starting from GPT-2. Through a concise, step-by-step, code-driven process, we demonstrate adapting GPT-2 for spatiotemporal data. We then review and compare representative trajectory foundation models, such as TrajFM and TrajGPT, highlighting their architectural innovations and differences. Additionally, we introduce complementary techniques from related domains, like TimesFM's patching approach. Targeted at researchers and practitioners, this tutorial aims to explain the concepts and terminology of foundation models, at the implementation level. We find it timely and indispensable to create this educational material in order to support the SIGSPATIAL community in building and evaluating mobility foundation models, enhancing both research clarity and peer-review effectiveness in mobility AI.

</details>


### [74] [Copyright Detection in Large Language Models: An Ethical Approach to Generative AI Development](https://arxiv.org/abs/2511.20623)
*David Szczecina,Senan Gaffori,Edmond Li*

Main category: cs.AI

TL;DR: 开发了一个开源版权检测平台，帮助内容创作者验证其作品是否被用于LLM训练数据集，相比现有方法计算开销降低10-30%，并提供用户友好的界面。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型广泛使用引发版权内容未经授权纳入训练数据的担忧，现有检测框架计算密集且对独立创作者不友好，需要可扩展、透明且用户友好的解决方案。

Method: 通过优化API调用效率，改进相似性检测和数据集验证，构建具有直观用户界面和可扩展后端的开源平台。

Result: 计算开销降低10-30%，提供用户友好的检测界面，增强AI开发透明度和伦理合规性。

Conclusion: 该框架为负责任AI开发和版权执法研究奠定基础，有助于提高AI开发的透明度。

Abstract: The widespread use of Large Language Models (LLMs) raises critical concerns regarding the unauthorized inclusion of copyrighted content in training data. Existing detection frameworks, such as DE-COP, are computationally intensive, and largely inaccessible to independent creators. As legal scrutiny increases, there is a pressing need for a scalable, transparent, and user-friendly solution. This paper introduce an open-source copyright detection platform that enables content creators to verify whether their work was used in LLM training datasets. Our approach enhances existing methodologies by facilitating ease of use, improving similarity detection, optimizing dataset validation, and reducing computational overhead by 10-30% with efficient API calls. With an intuitive user interface and scalable backend, this framework contributes to increasing transparency in AI development and ethical compliance, facilitating the foundation for further research in responsible AI development and copyright enforcement.

</details>


### [75] [Fighting AI with AI: Leveraging Foundation Models for Assuring AI-Enabled Safety-Critical Systems](https://arxiv.org/abs/2511.20627)
*Anastasia Mavridou,Divya Gopinath,Corina S. Păsăreanu*

Main category: cs.AI

TL;DR: 提出了REACT和SemaLens两个互补组件，利用AI技术解决安全关键系统中AI组件集成的验证挑战，从非正式需求到验证实现提供完整解决方案。


<details>
  <summary>Details</summary>
Motivation: AI组件（特别是深度神经网络）集成到航空航天和自动驾驶等安全关键系统中面临验证挑战，AI系统的不透明性以及高层需求与低层网络表示之间的语义鸿沟阻碍了传统验证方法。

Method: REACT使用大语言模型连接非正式自然语言需求和形式化规范，实现早期验证；SemaLens利用视觉语言模型基于人类可理解概念对DNN感知系统进行推理、测试和监控。

Result: 构建了从非正式需求到验证实现的完整管道，解决了需求工程中的模糊性和可扩展性瓶颈问题。

Conclusion: 利用AI技术本身可以解决AI系统集成到安全关键系统中的验证挑战，REACT和SemaLens提供了有效的解决方案。

Abstract: The integration of AI components, particularly Deep Neural Networks (DNNs), into safety-critical systems such as aerospace and autonomous vehicles presents fundamental challenges for assurance. The opacity of AI systems, combined with the semantic gap between high-level requirements and low-level network representations, creates barriers to traditional verification approaches. These AI-specific challenges are amplified by longstanding issues in Requirements Engineering, including ambiguity in natural language specifications and scalability bottlenecks in formalization. We propose an approach that leverages AI itself to address these challenges through two complementary components. REACT (Requirements Engineering with AI for Consistency and Testing) employs Large Language Models (LLMs) to bridge the gap between informal natural language requirements and formal specifications, enabling early verification and validation. SemaLens (Semantic Analysis of Visual Perception using large Multi-modal models) utilizes Vision Language Models (VLMs) to reason about, test, and monitor DNN-based perception systems using human-understandable concepts. Together, these components provide a comprehensive pipeline from informal requirements to validated implementations.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [76] [Discover, Learn, and Reinforce: Scaling Vision-Language-Action Pretraining with Diverse RL-Generated Trajectories](https://arxiv.org/abs/2511.19528)
*Rushuai Yang,Zhiyuan Feng,Tianxiang Zhang,Kaixin Wang,Chuheng Zhang,Li Zhao,Xiu Su,Yi Chen,Jiang Bian*

Main category: cs.RO

TL;DR: 提出了DLR框架，通过信息论模式发现生成多种不同的高成功率行为模式，为视觉-语言-动作模型预训练提供更丰富的数据。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作模型预训练需要大量多样化、高质量的操作轨迹数据，但人类远程操作成本高且难以扩展。强化学习方法虽然能通过自主探索学习有用技能，但标准RL训练会收敛到单一执行模式，限制了其在大规模预训练中的实用性。

Method: DLR（发现、学习和强化）是一个信息论模式发现框架，能够生成多种不同的高成功率行为模式。该框架在LIBERO基准上生成明显更多样化的轨迹语料库。

Result: DLR为同一任务学习多种不同的高成功率策略，而标准RL只发现一种策略，因此覆盖了更广泛的状态-动作空间。在未见过的下游任务套件上，使用DLR多样化RL数据预训练的VLA模型优于使用同等规模标准RL数据集训练的模型。

Conclusion: DLR展现出单一模式RL所缺乏的正向数据扩展行为，将多模式RL定位为具身基础模型的实用、可扩展数据引擎。

Abstract: Scaling vision-language-action (VLA) model pre-training requires large volumes of diverse, high-quality manipulation trajectories. Most current data is obtained via human teleoperation, which is expensive and difficult to scale. Reinforcement learning (RL) methods learn useful skills through autonomous exploration, making them a viable approach for generating data. However, standard RL training collapses to a narrow execution pattern, limiting its utility for large-scale pre-training. We propose Discover, Lea rn and Reinforce (DLR), an information-theoretic pattern discovery framework that generates multiple distinct, high-success behavioral patterns for VLA pretraining. Empirically, DLR generates a markedly more diverse trajectory corpus on LIBERO. Specifically, it learns multiple distinct, high-success strategies for the same task where standard RL discovers only one, and hence it covers substantially broader regions of the state-action space. When adapted to unseen downstream task suites, VLA models pretrained on our diverse RL data surpass counterparts trained on equal-sized standard RL datasets. Moreover, DLR exhibits positive data-scaling behavior that single-pattern RL lacks. These results position multi-pattern RL as a practical, scalable data engine for embodied foundation models.

</details>


### [77] [A Virtual Mechanical Interaction Layer Enables Resilient Human-to-Robot Object Handovers](https://arxiv.org/abs/2511.19543)
*Omar Faris,Sławomir Tadeja,Fulvio Forni*

Main category: cs.RO

TL;DR: 本文提出了一种基于虚拟模型控制和增强现实的人机物体交接方法，能够适应交接过程中的动态变化和不确定性。


<details>
  <summary>Details</summary>
Motivation: 解决人机物体交接过程中因物体姿态复杂变化导致的效率问题，确保机器人动作的适应性和鲁棒性。

Method: 使用虚拟模型控制创建交互层来控制机器人并适应交接过程的动态变化，同时利用增强现实促进人机双向通信。

Result: 实验表明控制器对各种不确定性具有鲁棒性，用户研究显示参与者普遍偏好所提出的方法。

Conclusion: 该方法在人机物体交接中表现良好，为未来交互适应开发提供了指导性见解。

Abstract: Object handover is a common form of interaction that is widely present in collaborative tasks. However, achieving it efficiently remains a challenge. We address the problem of ensuring resilient robotic actions that can adapt to complex changes in object pose during human-to-robot object handovers. We propose the use of Virtual Model Control to create an interaction layer that controls the robot and adapts to the dynamic changes in the handover process. Additionally, we propose the use of augmented reality to facilitate bidirectional communication between humans and robots during handovers. We assess the performance of our controller in a set of experiments that demonstrate its resilience to various sources of uncertainties, including complex changes to the object's pose during the handover. Finally, we performed a user study with 16 participants to understand human preferences for different robot control profiles and augmented reality visuals in object handovers. Our results showed a general preference for the proposed approach and revealed insights that can guide further development in adapting the interaction with the user.

</details>


### [78] [Robot-Powered Data Flywheels: Deploying Robots in the Wild for Continual Data Collection and Foundation Model Adaptation](https://arxiv.org/abs/2511.19647)
*Jennifer Grannen,Michelle Pan,Kenneth Llontop,Cherie Ho,Mark Zolotas,Jeannette Bohg,Dorsa Sadigh*

Main category: cs.RO

TL;DR: 提出了机器人驱动的数据飞轮框架，将机器人从基础模型消费者转变为数据生成器，通过在真实环境中部署机器人收集数据来改进基础模型的性能。


<details>
  <summary>Details</summary>
Motivation: 基础模型在互联网预训练数据上表现良好，但在真实世界非结构化环境中表现脆弱。机器人作为具身智能体，能够收集大规模真实世界数据来弥补这一差距。

Method: 开发了Scanford移动机械臂，在图书馆部署2周，自主扫描书架，使用视觉语言模型识别书籍，并利用图书馆目录自动标注图像。

Result: 从2103个书架收集数据，将书籍识别准确率从32.0%提升至71.8%，多语言OCR性能从24.8%提升至46.6%（英文）和30.8%提升至38.0%（中文），节省约18.7小时人工时间。

Conclusion: 机器人驱动的数据飞轮既能减少实际部署中的人工努力，又能为持续适应现实世界复杂性提供新途径。

Abstract: Foundation models (FM) have unlocked powerful zero-shot capabilities in vision and language, yet their reliance on internet pretraining data leaves them brittle in unstructured, real-world settings. The messy, real-world data encountered during deployment (e.g. occluded or multilingual text) remains massively underrepresented in existing corpora. Robots, as embodied agents, are uniquely positioned to close this gap: they can act in physical environments to collect large-scale, real-world data that enriches FM training with precisely the examples current models lack. We introduce the Robot-Powered Data Flywheel, a framework that transforms robots from FM consumers into data generators. By deploying robots equipped with FMs in the wild, we enable a virtuous cycle: robots perform useful tasks while collecting real-world data that improves both domain-specific adaptation and domain-adjacent generalization. We instantiate this framework with Scanford, a mobile manipulator deployed in the East Asia Library for 2 weeks. Scanford autonomously scans shelves, identifies books using a vision-language model (VLM), and leverages the library catalog to label images without human annotation. This deployment both aids librarians and produces a dataset to finetune the underlying VLM, improving performance on the domain-specific in-the-wild library setting and on domain-adjacent multilingual OCR benchmarks. Using data collected from 2103 shelves, Scanford improves VLM performance on book identification from 32.0% to 71.8% and boosts domain-adjacent multilingual OCR from 24.8% to 46.6% (English) and 30.8% to 38.0% (Chinese), while saving an ~18.7 hrs of human time. These results highlight how robot-powered data flywheels can both reduce human effort in real deployments and unlock new pathways for continually adapting FMs to the messiness of reality. More details are at: https://scanford-robot.github.io

</details>


### [79] [Online Learning-Enhanced High Order Adaptive Safety Control](https://arxiv.org/abs/2511.19651)
*Lishuo Pan,Mattia Catellani,Thales C. Silva,Lorenzo Sabattini,Nora Ayanian*

Main category: cs.RO

TL;DR: 提出了一种基于神经ODE的在线学习增强高阶自适应控制屏障函数方法，能够在复杂时变模型扰动下实时提高CBF认证系统的安全性，并在38g纳米四旋翼上成功验证，在18km/h风速下保持与障碍物的安全距离。


<details>
  <summary>Details</summary>
Motivation: 控制屏障函数(CBFs)是保证系统安全性的有效工具，但其安全保证的成功转移到现实系统严重依赖于模型准确性。有效载荷或风扰动等会显著影响飞行器动力学并使安全保证失效。

Method: 使用神经ODE开发高效的在线学习增强高阶自适应控制屏障函数，结合混合自适应CBF控制器。

Result: 在38g纳米四旋翼上成功部署，在18km/h风速下能够保持与障碍物的安全距离。

Conclusion: 该方法能够在复杂时变模型扰动下实时提高CBF认证系统的安全性，为现实世界系统的安全控制提供了有效解决方案。

Abstract: Control barrier functions (CBFs) are an effective model-based tool to formally certify the safety of a system. With the growing complexity of modern control problems, CBFs have received increasing attention in both optimization-based and learning-based control communities as a safety filter, owing to their provable guarantees. However, success in transferring these guarantees to real-world systems is critically tied to model accuracy. For example, payloads or wind disturbances can significantly influence the dynamics of an aerial vehicle and invalidate the safety guarantee. In this work, we propose an efficient yet flexible online learning-enhanced high-order adaptive control barrier function using Neural ODEs. Our approach improves the safety of a CBF-certified system on the fly, even under complex time-varying model perturbations. In particular, we deploy our hybrid adaptive CBF controller on a 38g nano quadrotor, keeping a safe distance from the obstacle, against 18km/h wind.

</details>


### [80] [Flow-Based Path Planning for Multiple Homogenous UAVs for Outdoor Formation-Flying](https://arxiv.org/abs/2511.19653)
*Mahmud Suhaimi Ibrahim,Shantanu Rahman,Muhammad Samin Hasan,Minhaj Uddin Ahmad,Abdullah Abrar*

Main category: cs.RO

TL;DR: 使用流网络方法为多无人机编队飞行规划无碰撞路径，包含三个主要步骤：构建流网络图、寻找最小成本路径、应用Ford-Fulkerson方法确保最大流量（无碰撞）。


<details>
  <summary>Details</summary>
Motivation: 多无人机编队飞行中，无碰撞路径规划是最关键的组成部分，需要确保同质无人机在飞行过程中不会相互碰撞。

Method: 1) 从物理GPS坐标构建流网络图；2) 使用图基路径寻找算法找到最小成本（最短距离）路径；3) 实施Ford-Fulkerson方法找到具有最大流量（无碰撞）的路径。

Result: 对最多64架无人机进行了各种编队的模拟，随后用3架四旋翼无人机进行了实际实验。测试结果表明该方法能够有效生成安全的无碰撞路径。

Conclusion: 该方法能够为多无人机编队飞行产生安全、无碰撞的路径，证明了其物理可行性和有效性。

Abstract: Collision-free path planning is the most crucial component in multi-UAV formation-flying (MFF). We use unlabeled homogenous quadcopters (UAVs) to demonstrate the use of a flow network to create complete (inter-UAV) collision-free paths. This procedure has three main parts: 1) Creating a flow network graph from physical GPS coordinates, 2) Finding a path of minimum cost (least distance) using any graph-based path-finding algorithm, and 3) Implementing the Ford-Fulkerson Method to find the paths with the maximum flow (no collision). Simulations of up to 64 UAVs were conducted for various formations, followed by a practical experiment with 3 quadcopters for testing physical plausibility and feasibility. The results of these tests show the efficacy of this method's ability to produce safe, collision-free paths.

</details>


### [81] [Development of a Testbed for Autonomous Vehicles: Integrating MPC Control with Monocular Camera Lane Detection](https://arxiv.org/abs/2511.19655)
*Shantanu Rahman,Nayeb Hasin,Mainul Islam*

Main category: cs.RO

TL;DR: 提出了一种结合车道识别与模型预测控制(MPC)的新方法，用于提高自动驾驶汽车轨迹跟踪的精度和稳定性，在仿真中轨迹跟踪误差降低了27.65%。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在道路应用中需要提高轨迹跟踪的精度和稳定性，特别是对于采用阿克曼转向机制的标准车辆。

Method: 使用边缘识别、滑动窗口直线识别进行车道线提取，结合基于自行车车辆动力学模型的MPC控制器，在ROS Gazebo中构建单车道道路仿真模型进行验证。

Result: 仿真结果显示，最优跟踪轨迹与目标轨迹之间的均方根误差降低了27.65%，证明了所开发控制器的高鲁棒性和灵活性。

Conclusion: 提出的车道识别与MPC结合方法有效提高了自动驾驶车辆的轨迹跟踪性能，具有实际应用价值。

Abstract: Autonomous vehicles are becoming popular day by day not only for autonomous road traversal but also for industrial automation, farming and military. Most of the standard vehicles follow the Ackermann style steering mechanism. This has become to de facto standard for large and long faring vehicles. The local planner of an autonomous vehicle controls the low-level vehicle movement upon which the vehicle will perform its motor actuation. In our work, we focus on autonomous vehicles in road and perform experiments to analyze the effect of low-level controllers in the simulation and a real environment. To increase the precision and stability of trajectory tracking in autonomous cars, a novel method that combines lane identification with Model Predictive Control (MPC) is presented. The research focuses on camera-equipped autonomous vehicles and uses methods like edge recognition, sliding window-based straight-line identification for lane line extraction, and dynamic region of interest (ROI) extraction. Next, to follow the identified lane line, an MPC built on a bicycle vehicle dynamics model is created. A single-lane road simulation model is built using ROS Gazebo and tested in order to verify the controller's performance. The root mean square error between the optimal tracking trajectory and the target trajectory was reduced by 27.65% in the simulation results, demonstrating the high robustness and flexibility of the developed controller.

</details>


### [82] [Multi-Agent gatekeeper: Safe Flight Planning and Formation Control for Urban Air Mobility](https://arxiv.org/abs/2511.19691)
*Thomas Marshall Vielmetti,Devansh R Agrawal,Dimitra Panagou*

Main category: cs.RO

TL;DR: 提出Multi-Agent Gatekeeper框架，为3D拥挤环境中的领导者-跟随者编队控制提供可证明的安全保证，通过领导者预计算安全轨迹作为共享备份，确保跟随者始终拥有安全备份机动。


<details>
  <summary>Details</summary>
Motivation: 现有方法面临权衡：在线规划器和控制器缺乏正式安全保证，而离线规划器无法适应代理数量或期望编队的变化。需要一种既能提供安全保证又具有适应性的解决方案。

Method: 采用混合架构，单个领导者跟踪预计算的安全轨迹作为共享轨迹备份集，跟随者执行名义编队保持跟踪控制器，始终拥有沿领导者路径的已知安全备份机动。

Result: 在模拟3D城市环境中，100次随机试验中实现了100%的避碰成功率，显著优于基线CBF和NMPC方法，并在四旋翼无人机团队上验证了轨迹的物理可行性。

Conclusion: 该方法为多智能体系统提供了可证明的安全保证，成功解决了领导者-跟随者编队控制在复杂3D环境中的安全协调问题。

Abstract: We present Multi-Agent gatekeeper, a framework that provides provable safety guarantees for leader-follower formation control in cluttered 3D environments. Existing methods face a trad-off: online planners and controllers lack formal safety guarantees, while offline planners lack adaptability to changes in the number of agents or desired formation. To address this gap, we propose a hybrid architecture where a single leader tracks a pre-computed, safe trajectory, which serves as a shared trajectory backup set for all follower agents. Followers execute a nominal formation-keeping tracking controller, and are guaranteed to remain safe by always possessing a known-safe backup maneuver along the leader's path. We formally prove this method ensures collision avoidance with both static obstacles and other agents. The primary contributions are: (1) the multi-agent gatekeeper algorithm, which extends our single-agent gatekeeper framework to multi-agent systems; (2) the trajectory backup set for provably safe inter-agent coordination for leader-follower formation control; and (3) the first application of the gatekeeper framework in a 3D environment. We demonstrate our approach in a simulated 3D urban environment, where it achieved a 100% collision-avoidance success rate across 100 randomized trials, significantly outperforming baseline CBF and NMPC methods. Finally, we demonstrate the physical feasibility of the resulting trajectories on a team of quadcopters.

</details>


### [83] [Whole-Body Inverse Dynamics MPC for Legged Loco-Manipulation](https://arxiv.org/abs/2511.19709)
*Lukas Molnar,Jin Cheng,Gabriele Fadini,Dongho Kang,Fatemeh Zargarbashi,Stelian Coros*

Main category: cs.RO

TL;DR: 提出了一种全身模型预测控制框架，通过全阶逆动力学直接优化关节扭矩，实现运动和力的统一规划与执行，在四足机器人上实现了80Hz的实时性能。


<details>
  <summary>Details</summary>
Motivation: 全身运动操作需要协调全身运动来有效操纵物体，同时保持运动稳定性，这对规划和控制都提出了重大挑战。

Method: 使用全身模型预测控制框架，通过全阶逆动力学直接优化关节扭矩，采用Pinocchio、CasADi软件框架和Fatrop内点求解器实现。

Result: 在配备机械臂的Unitree B2四足机器人上实现了80Hz的实时性能，成功完成了拉重物、推箱子和擦白板等实际交互任务。

Conclusion: 该MPC框架能够实现物理一致的全身行为，有效处理系统动力学和物理约束，为全身运动操作提供了统一的规划和控制解决方案。

Abstract: Loco-manipulation demands coordinated whole-body motion to manipulate objects effectively while maintaining locomotion stability, presenting significant challenges for both planning and control. In this work, we propose a whole-body model predictive control (MPC) framework that directly optimizes joint torques through full-order inverse dynamics, enabling unified motion and force planning and execution within a single predictive layer. This approach allows emergent, physically consistent whole-body behaviors that account for the system's dynamics and physical constraints. We implement our MPC formulation using open software frameworks (Pinocchio and CasADi), along with the state-of-the-art interior-point solver Fatrop. In real-world experiments on a Unitree B2 quadruped equipped with a Unitree Z1 manipulator arm, our MPC formulation achieves real-time performance at 80 Hz. We demonstrate loco-manipulation tasks that demand fine control over the end-effector's position and force to perform real-world interactions like pulling heavy loads, pushing boxes, and wiping whiteboards.

</details>


### [84] [Unifying Perception and Action: A Hybrid-Modality Pipeline with Implicit Visual Chain-of-Thought for Robotic Action Generation](https://arxiv.org/abs/2511.19859)
*Xiangkai Ma,Lekai Xing,Han Zhang,Wenzhong Li,Sanglu Lu*

Main category: cs.RO

TL;DR: 提出了VITA框架，通过构建视觉和动作的共享离散潜在空间，解决了视觉观察与低级动作之间的模态差距问题，同时将视觉动态作为运动规划的归纳偏置。


<details>
  <summary>Details</summary>
Motivation: 基于思维链的视觉-语言-动作模型在机器人代理方面取得显著成功，但纯文本思维链难以捕捉复杂空间环境中的场景细节，且现有方法面临视觉观察与动作的模态差距以及视觉预测与动作生成目标冲突的问题。

Method: 提出视觉集成轨迹对齐(VITA)框架，学习视觉和动作的共享离散潜在空间，通过隐式视觉思维链同时解码生成未来帧预测和机器人动作，将视觉动态内化为运动规划的归纳偏置。

Result: 在CALVIN、LIBERO和SimplerEnv基准上分别比现有基线提升14.5%、9.6%和12.1%，在六个真实世界任务中平均成功率达到80.5%。

Conclusion: VITA框架在模拟和真实环境中均表现出最先进的性能，展示了其作为通用机器人操作模型的潜力。

Abstract: Vision-Language-Action (VLA) models built upon Chain-of-Thought (CoT) have achieved remarkable success in advancing general-purpose robotic agents, owing to its significant perceptual comprehension. Recently, since text-only CoT struggles to adequately capture scene details in complex spatial environments, a highly promising strategy involves leveraging visual priors to guide robotic action generation. Nevertheless, these strategies face two inherent challenges: (i) a modality gap between visual observations and low-level actions, and (ii) unstable training due to competing objectives between visual prediction and action generation. To address these challenges, we propose a Vision-Integrated Trajectory Alignment (VITA) framework that learns a shared discrete latent space for vision and action, enabling joint modeling of perception and motor control. VITA introduces a implicit visual CoT: autoregressively generated tokens is simultaneously decoded into future frames predictions and robot actions, thereby internalizing visual dynamics as an inductive bias for motion planning. Extensive experiments on simulated and real-world environments demonstrate state-of-the-art performance. VITA improves 14.5\%, 9.6\% and 12.1\% over existing baselines on CALVIN, LIBERO and SimplerEnv. Furthermore, VITA attains an average success rate of 80.5\% across six real-world tasks, demonstrating its potential as a generalist robotic manipulation model.

</details>


### [85] [Human-Centered Cooperative Control Coupling Autonomous and Haptic Shared Control via Control Barrier Function](https://arxiv.org/abs/2511.19869)
*Eito Sato,Takahiro Wada*

Main category: cs.RO

TL;DR: 提出了一种结合独立自主控制器与触觉共享控制的协作框架，在安全区域内忽略操纵杆输入，其他情况下启用触觉共享控制，提高了远程操作的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统触觉共享控制在最大化控制强度时，由于操纵杆和人类手臂的动力学影响机器人行为，其自主控制性能受到限制。

Method: 提出协作框架，将独立于操纵杆的自主控制器与触觉共享控制耦合。使用控制屏障函数在人类操作员实时确定的安全区域内忽略操纵杆输入，其他情况下启用触觉共享控制。

Result: 在虚拟环境中对远程操作水下机器人进行模拟任务的初步实验表明，相比传统触觉共享控制，该方法提高了准确性并减少了所需时间。

Conclusion: 所提出的协作框架能够有效克服传统触觉共享控制的局限性，在远程操作中实现更好的性能表现。

Abstract: Haptic shared control (HSC) is effective in teleoperation when full autonomy is limited by uncertainty or sensing constraints. However, autonomous control performance achieved by maximizing HSC strength is limited because the dynamics of the joystick and human arm affect the robot's behavior. We propose a cooperative framework coupling a joystick-independent autonomous controller with HSC. A control barrier function ignores joystick inputs within a safe region determined by the human operator in real-time, while HSC is engaged otherwise. A pilot experiment on simulated tasks with tele-operated underwater robot in virtual environment demonstrated improved accuracy and reduced required time over conventional HSC.

</details>


### [86] [CoC-VLA: Delving into Adversarial Domain Transfer for Explainable Autonomous Driving via Chain-of-Causality Visual-Language-Action Model](https://arxiv.org/abs/2511.19914)
*Dapeng Zhang,Fei Shen,Rui Zhao,Yinda Chen,Peng Zhi,Chenyang Li,Rui Zhou,Qingguo Zhou*

Main category: cs.RO

TL;DR: 提出CoC-VLA框架，通过对抗迁移学习将模拟环境中的长尾场景处理能力转移到真实世界自动驾驶系统中


<details>
  <summary>Details</summary>
Motivation: 现有方法要么依赖真实世界数据（适合工业部署），要么使用模拟数据（针对罕见场景），但很少能有效整合两者的互补优势

Method: 使用教师-学生VLM模型和判别器，通过对抗训练将模拟环境中的长尾处理能力迁移到真实世界，采用链式因果视觉语言模型整合时序信息

Result: 框架支持复杂驾驶逻辑的推理，能够将模拟环境中的长尾场景处理能力有效迁移到真实世界部署

Conclusion: CoC-VLA框架成功解决了模拟与真实世界数据整合的挑战，提升了自动驾驶系统在复杂长尾场景中的处理能力

Abstract: Autonomous driving represents a prominent application of artificial intelligence. Recent approaches have shifted from focusing solely on common scenarios to addressing complex, long-tail situations such as subtle human behaviors, traffic accidents, and non-compliant driving patterns. Given the demonstrated capabilities of large language models (LLMs) in understanding visual and natural language inputs and following instructions, recent methods have integrated LLMs into autonomous driving systems to enhance reasoning, interpretability, and performance across diverse scenarios. However, existing methods typically rely either on real-world data, which is suitable for industrial deployment, or on simulation data tailored to rare or hard case scenarios. Few approaches effectively integrate the complementary advantages of both data sources. To address this limitation, we propose a novel VLM-guided, end-to-end adversarial transfer framework for autonomous driving that transfers long-tail handling capabilities from simulation to real-world deployment, named CoC-VLA. The framework comprises a teacher VLM model, a student VLM model, and a discriminator. Both the teacher and student VLM models utilize a shared base architecture, termed the Chain-of-Causality Visual-Language Model (CoC VLM), which integrates temporal information via an end-to-end text adapter. This architecture supports chain-of-thought reasoning to infer complex driving logic. The teacher and student VLM models are pre-trained separately on simulated and real-world datasets. The discriminator is trained adversarially to facilitate the transfer of long-tail handling capabilities from simulated to real-world environments by the student VLM model, using a novel backpropagation strategy.

</details>


### [87] [Collaborate sim and real: Robot Bin Packing Learning in Real-world and Physical Engine](https://arxiv.org/abs/2511.19932)
*Lidi Zhang,Han Wu,Liyu Zhang,Ruofeng Liu,Haotian Wang,Chao Li,Desheng Zhang,Yunhuai Liu,Tian He*

Main category: cs.RO

TL;DR: 提出了一种混合强化学习框架，通过物理仿真与真实世界数据反馈协作，解决3D装箱问题中的仿真到现实差距问题，显著降低了包装坍塌率。


<details>
  <summary>Details</summary>
Motivation: 现有方法将3D装箱问题建模为离散静态过程，而实际应用涉及连续重力驱动交互，这种理想化简化导致实际部署不可行（如不稳定包装）。物理仿真虽能模拟重力效应，但由于真实物体物理属性的动态变化，存在仿真到现实的差距。

Method: 混合强化学习框架：1）在仿真中应用领域随机化，让智能体接触各种物理参数以增强泛化能力；2）基于真实世界部署反馈对RL智能体进行微调，进一步降低坍塌率。

Result: 实验表明该方法在仿真和真实场景中均实现了更低的坍塌率。在物流系统中的大规模部署验证了实际有效性，相比基线方法包装坍塌率降低了35%。

Conclusion: 所提出的混合RL框架有效弥合了仿真与现实之间的差距，显著提高了3D装箱的稳定性，在实际物流系统中具有重要应用价值。

Abstract: The 3D bin packing problem, with its diverse industrial applications, has garnered significant research attention in recent years. Existing approaches typically model it as a discrete and static process, while real-world applications involve continuous gravity-driven interactions. This idealized simplification leads to infeasible deployments (e.g., unstable packing) in practice. Simulations with physical engine offer an opportunity to emulate continuous gravity effects, enabling the training of reinforcement learning (RL) agents to address such limitations and improve packing stability. However, a simulation-to-reality gap persists due to dynamic variations in physical properties of real-world objects, such as various friction coefficients, elasticity, and non-uniform weight distributions. To bridge this gap, we propose a hybrid RL framework that collaborates with physical simulation with real-world data feedback. Firstly, domain randomization is applied during simulation to expose agents to a spectrum of physical parameters, enhancing their generalization capability. Secondly, the RL agent is fine-tuned with real-world deployment feedback, further reducing collapse rates. Extensive experiments demonstrate that our method achieves lower collapse rates in both simulated and real-world scenarios. Large-scale deployments in logistics systems validate the practical effectiveness, with a 35\% reduction in packing collapse compared to baseline methods.

</details>


### [88] [ShapeForce: Low-Cost Soft Robotic Wrist for Contact-Rich Manipulation](https://arxiv.org/abs/2511.19955)
*Jinxuan Zhu,Zihao Yan,Yangyu Xiao,Jingxiang Guo,Chenrui Tie,Xinyi Cao,Yuhang Zheng,Lin Shao*

Main category: cs.RO

TL;DR: ShapeForce是一个低成本、即插即用的软腕装置，通过将外力转换为可测量的变形来提供类似力的信号，用于接触丰富的机器人操作任务。


<details>
  <summary>Details</summary>
Motivation: 六维力扭矩传感器成本高且易碎，限制了在接触丰富任务中的应用。需要一种成本效益高、易于获取的接触反馈方案。

Method: 通过柔性核心将外力和扭矩转换为可测量的变形，使用基于标记的姿态跟踪估计变形，并将其转换为类似力的信号。无需校准或专用电子设备。

Result: 在多种接触丰富任务和操作策略的广泛实验中，ShapeForce以极低成本实现了与六维力扭矩传感器相当的性能。

Conclusion: ShapeForce提供了一种经济高效的接触反馈解决方案，能够替代昂贵的六维力扭矩传感器，在接触丰富的机器人操作中表现优异。

Abstract: Contact feedback is essential for contact-rich robotic manipulation, as it allows the robot to detect subtle interaction changes and adjust its actions accordingly. Six-axis force-torque sensors are commonly used to obtain contact feedback, but their high cost and fragility have discouraged many researchers from adopting them in contact-rich tasks. To offer a more cost-efficient and easy-accessible source of contact feedback, we present ShapeForce, a low-cost, plug-and-play soft wrist that provides force-like signals for contact-rich robotic manipulation. Inspired by how humans rely on relative force changes in contact rather than precise force magnitudes, ShapeForce converts external force and torque into measurable deformations of its compliant core, which are then estimated via marker-based pose tracking and converted into force-like signals. Our design eliminates the need for calibration or specialized electronics to obtain exact values, and instead focuses on capturing force and torque changes sufficient for enabling contact-rich manipulation. Extensive experiments across diverse contact-rich tasks and manipulation policies demonstrate that ShapeForce delivers performance comparable to six-axis force-torque sensors at an extremely low cost.

</details>


### [89] [Active3D: Active High-Fidelity 3D Reconstruction via Hierarchical Uncertainty Quantification](https://arxiv.org/abs/2511.20050)
*Yan Li,Yingzhao Li,Gim Hee Lee*

Main category: cs.RO

TL;DR: 提出了一种用于高保真3D重建的主动探索框架，通过构建多级不确定性空间和不确定性驱动的运动规划来选择最佳视角。


<details>
  <summary>Details</summary>
Motivation: 解决3D重建中如何有效选择信息量最大的视角来优化重建质量的问题，特别是在复杂场景下实现高效和安全的探索。

Method: 采用混合隐式-显式表示融合神经场与高斯基元，构建分层不确定性体积，提出不确定性驱动的关键帧选择策略和风险敏感的路径规划器。

Result: 在具有挑战性的基准测试中，该方法在准确性、完整性和渲染质量方面均达到最先进水平。

Conclusion: 该方法在真实世界主动重建和机器人感知任务中表现出色，证明了其有效性。

Abstract: In this paper, we present an active exploration framework for high-fidelity 3D reconstruction that incrementally builds a multi-level uncertainty space and selects next-best-views through an uncertainty-driven motion planner. We introduce a hybrid implicit-explicit representation that fuses neural fields with Gaussian primitives to jointly capture global structural priors and locally observed details. Based on this hybrid state, we derive a hierarchical uncertainty volume that quantifies both implicit global structure quality and explicit local surface confidence. To focus optimization on the most informative regions, we propose an uncertainty-driven keyframe selection strategy that anchors high-entropy viewpoints as sparse attention nodes, coupled with a viewpoint-space sliding window for uncertainty-aware local refinement. The planning module formulates next-best-view selection as an Expected Hybrid Information Gain problem and incorporates a risk-sensitive path planner to ensure efficient and safe exploration. Extensive experiments on challenging benchmarks demonstrate that our approach consistently achieves state-of-the-art accuracy, completeness, and rendering quality, highlighting its effectiveness for real-world active reconstruction and robotic perception tasks.

</details>


### [90] [Hibikino-Musashi@Home 2025 Team Description Paper](https://arxiv.org/abs/2511.20180)
*Ryohei Kobayashi,Kosei Isomoto,Kosei Yamao,Soma Fumoto,Koshun Arimura,Naoki Yamaguchi,Akinobu Mizutani,Tomoya Shiba,Kouki Kimizuka,Yuta Ohno,Ryo Terashima,Hiromasa Yamaguchi,Tomoaki Fujino,Ryoga Maruno,Wataru Yoshimura,Kazuhito Mine,Tang Phu Thien Nhan,Yuga Yano,Yuichiro Tanaka,Takeshi Nishida,Takashi Morie,Hakaru Tamukoh*

Main category: cs.RO

TL;DR: Hibikino-Musashi@Home团队开发了机器人视觉系统训练数据集生成器、开源开发环境、LLM驱动的任务规划器、脑启发记忆模型，并改进了导航系统，旨在设计能够在家中为人类提供个性化辅助的服务机器人。


<details>
  <summary>Details</summary>
Motivation: 设计能够在家中为人类提供辅助的服务机器人，通过持续参加比赛来评估和改进系统性能。

Method: 开发数据集生成器训练机器人视觉系统，创建开源开发环境，使用大语言模型进行任务规划，研究脑启发记忆模型以适应个性化家庭环境，改进导航系统。

Result: 构建了完整的家庭服务机器人系统，包括视觉、规划、记忆和导航等核心模块，为个性化家庭辅助提供了技术基础。

Conclusion: 该团队通过多技术融合的方法开发了家庭服务机器人系统，并通过竞赛持续优化，为实现直观和个性化的家庭辅助服务奠定了基础。

Abstract: This paper provides an overview of the techniques employed by Hibikino-Musashi@Home, which intends to participate in the domestic standard platform league. The team developed a dataset generator for training a robot vision system and an open-source development environment running on a Human Support Robot simulator. The large-language-model-powered task planner selects appropriate primitive skills to perform the task requested by the user. Moreover, the team has focused on research involving brain-inspired memory models for adaptation to individual home environments. This approach aims to provide intuitive and personalized assistance. Additionally, the team contributed to the reusability of the navigation system developed by Pumas in RoboCup2024. The team aimed to design a home service robot to assist humans in their homes and continuously attend competitions to evaluate and improve the developed system.

</details>


### [91] [Toward generic control for soft robotic systems](https://arxiv.org/abs/2511.20226)
*Yu Sun,Yaosheng Deng,Wenjie Mei,Xiaogang Xiong,Yang Bai,Masaki Ogura,Zeyu Zhou,Mir Feroskhan,Michael Yu Wang,Qiyang Zuo,Yao Li,Yunjiang Lou*

Main category: cs.RO

TL;DR: 提出了一种基于控制柔顺性的通用软体机器人控制框架，通过高层运动意图表达和局部自主细节解决，实现跨形态和驱动机制的稳定、安全控制。


<details>
  <summary>Details</summary>
Motivation: 当前软体机器人控制方法分散，不同形态和驱动方案需要特定控制器。传统刚体控制逻辑依赖精确模型和严格执行，不适合软体机器人。控制柔顺性（容忍和利用近似动作表示）应是鲁棒性和适应性的基础，而非需要消除的干扰。

Method: 借鉴人类运动控制原理，通过高层运动趋势表达意图，反射和生物力学机制自主解决局部细节。提出基于控制柔顺性的通用软体机器人控制框架。

Result: 在多种形态和驱动机制的机器人上验证，实现了稳定、安全且跨平台可转移的行为。

Conclusion: 拥抱而非抵抗控制柔顺性，可为统一软体机器人控制提供广泛应用基础。

Abstract: Soft robotics has advanced rapidly, yet its control methods remain fragmented: different morphologies and actuation schemes still require task-specific controllers, hindering theoretical integration and large-scale deployment. A generic control framework is therefore essential, and a key obstacle lies in the persistent use of rigid-body control logic, which relies on precise models and strict low-level execution. Such a paradigm is effective for rigid robots but fails for soft robots, where the ability to tolerate and exploit approximate action representations, i.e., control compliance, is the basis of robustness and adaptability rather than a disturbance to be eliminated. Control should thus shift from suppressing compliance to explicitly exploiting it. Human motor control exemplifies this principle: instead of computing exact dynamics or issuing detailed muscle-level commands, it expresses intention through high-level movement tendencies, while reflexes and biomechanical mechanisms autonomously resolve local details. This architecture enables robustness, flexibility, and cross-task generalization. Motivated by this insight, we propose a generic soft-robot control framework grounded in control compliance and validate it across robots with diverse morphologies and actuation mechanisms. The results demonstrate stable, safe, and cross-platform transferable behavior, indicating that embracing control compliance, rather than resisting it, may provide a widely applicable foundation for unified soft-robot control.

</details>


### [92] [HAFO: Humanoid Force-Adaptive Control for Intense External Force Interaction Environments](https://arxiv.org/abs/2511.20275)
*Chenhui Dong,Haozhe Xu,Wenhao Feng,Zhipeng Wang,Yanmin Zhou,Yifei Zhao,Bin He*

Main category: cs.RO

TL;DR: 提出HAFO双智能体强化学习控制框架，通过耦合训练同时优化稳健的步态策略和精确的上半身操作策略，在强外力交互环境下实现人形机器人的稳定控制。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习控制器在仿人机器人步态和轻负载操作方面取得进展，但在强外力交互下实现稳健精确运动仍面临挑战。

Method: 采用双智能体强化学习框架，通过弹簧-阻尼系统显式建模外部拉力扰动，利用非对称Actor-Critic框架，其中Critic网络访问特权弹簧阻尼力信息指导Actor网络学习可泛化的稳健策略。

Result: HAFO在各种强外力交互下实现了人形机器人的稳定控制，在负载任务中表现出色，并在绳索张力扰动下确保机器人稳定运行。

Conclusion: HAFO框架能够有效处理强外力交互，为仿人机器人在复杂环境中的稳健操作提供了可行解决方案。

Abstract: Reinforcement learning controllers have made impressive progress in humanoid locomotion and light load manipulation. However, achieving robust and precise motion with strong force interaction remains a significant challenge. Based on the above limitations, this paper proposes HAFO, a dual-agent reinforcement learning control framework that simultaneously optimizes both a robust locomotion strategy and a precise upper-body manipulation strategy through coupled training under external force interaction environments. Simultaneously, we explicitly model the external pulling disturbances through a spring-damper system and achieve fine-grained force control by manipulating the virtual spring. During this process, the reinforcement-learning policy spontaneously generates disturbance-rejection response by exploiting environmental feedback. Moreover, HAFO employs an asymmetric Actor-Critic framework in which the Critic-network access to privileged spring-damping forces guides the actor-network to learn a generalizable, robust policy for resisting external disturbances. The experimental results demonstrate that HAFO achieves stable control of humanoid robot under various strong force interactions, showing remarkable performance in load tasks and ensuring stable robot operation under rope tension disturbances. Project website: hafo-robot.github.io.

</details>


### [93] [Dynamic-ICP: Doppler-Aware Iterative Closest Point Registration for Dynamic Scenes](https://arxiv.org/abs/2511.20292)
*Dong Wang,Daniel Casado Herraez,Stefan May,Andreas Nüchter*

Main category: cs.RO

TL;DR: Dynamic-ICP是一种基于多普勒的LiDAR里程计方法，通过结合几何残差和多普勒残差，在高度动态环境中实现稳健的位姿估计，无需外部传感器或标定。


<details>
  <summary>Details</summary>
Motivation: 在高度动态环境中，传统的ICP方法假设场景近似静态，在重复或低纹理几何中性能下降。需要一种能够处理动态物体的可靠里程计方法。

Method: 1) 通过稳健回归从多普勒速度估计自我运动并构建速度滤波器；2) 聚类动态物体并重建物体平移速度；3) 使用恒定速度模型预测动态点；4) 结合点对面几何残差和旋转不变的多普勒残差进行扫描对齐。

Result: 在三个数据集上的评估显示，Dynamic-ICP在旋转稳定性和平移精度上持续优于现有最先进方法，能够实时运行。

Conclusion: Dynamic-ICP提供了一种轻量级的解决方案，能够直接集成到现有流程中，在动态环境中实现稳健的配准。

Abstract: Reliable odometry in highly dynamic environments remains challenging when it relies on ICP-based registration: ICP assumes near-static scenes and degrades in repetitive or low-texture geometry. We introduce Dynamic-ICP, a Doppler-aware registration framework. The method (i) estimates ego motion from per-point Doppler velocity via robust regression and builds a velocity filter, (ii) clusters dynamic objects and reconstructs object-wise translational velocities from ego-compensated radial measurements, (iii) predicts dynamic points with a constant-velocity model, and (iv) aligns scans using a compact objective that combines point-to-plane geometry residual with a translation-invariant, rotation-only Doppler residual. The approach requires no external sensors or sensor-vehicle calibration and operates directly on FMCW LiDAR range and Doppler velocities. We evaluate Dynamic-ICP on three datasets-HeRCULES, HeLiPR, AevaScenes-focusing on highly dynamic scenes. Dynamic-ICP consistently improves rotational stability and translation accuracy over the state-of-the-art methods. Our approach is also simple to integrate into existing pipelines, runs in real time, and provides a lightweight solution for robust registration in dynamic environments. To encourage further research, the code is available at: https://github.com/JMUWRobotics/Dynamic-ICP.

</details>


### [94] [How Robot Kinematics Influence Human Performance in Virtual Robot-to-Human Handover Tasks](https://arxiv.org/abs/2511.20299)
*Róisín Keenan,Joost C. Dessing*

Main category: cs.RO

TL;DR: 研究通过VR实验探索人机协作中的物体传递任务，发现人类从机器人提供的早期视觉信息和类人平滑轨迹中受益，这有助于提高预测准确性和同步性。


<details>
  <summary>Details</summary>
Motivation: 随着机器人系统越来越多地融入人类工作环境，需要优化人机协调协作，特别是在物体传递等交互任务中。

Method: 使用VR模拟机器人传递任务，分别考察四个因素对人类表现的影响：任务启动控制和机器人运动同步性、伙伴外观、机器人速度曲线、旋转物体运动时机。

Result: 实验表明，人类受益于机器人提供早期视觉信息和类人平滑轨迹，这些因素不同程度地改善了预测准确性和交互同步性。

Conclusion: 人机交互设计应让人类能够利用其检测生物运动的自然能力，这可以减少机器人计算成本或人类认知适应需求。

Abstract: Recent advancements in robotics have increased the possibilities for integrating robotic systems into human-involved workplaces, highlighting the need to examine and optimize human-robot coordination in collaborative settings. This study explores human-robot interactions during handover tasks using Virtual Reality (VR) to investigate differences in human motor performance across various task dynamics and robot kinematics. A VR-based robot handover simulation afforded safe and controlled assessments of human-robot interactions. In separate experiments, four potential influences on human performance were examined (1) control over task initiation and robot movement synchrony (temporal and spatiotemporal); (2) partner appearance (human versus robotic); (3) robot velocity profiles (minimum jerk, constant velocity, constant acceleration, and biphasic); and (4) the timing of rotational object motion. Findings across experiments emphasize humans benefit from robots providing early and salient visual information about task-relevant object motion, and advantages of human-like smooth robot trajectories. To varying degrees, these manipulations improved predictive accuracy and synchronization during interaction. This suggests that human-robot interactions should be designed to allow humans to leverage their natural capabilities for detecting biological motion, which conversely may reduce the need for costly robotic computations or added cognitive adaptation on the human side.

</details>


### [95] [ArtiBench and ArtiBrain: Benchmarking Generalizable Vision-Language Articulated Object Manipulation](https://arxiv.org/abs/2511.20330)
*Yuhan Wu,Tiantian Wei,Shuo Wang,ZhiChao Wang,Yanyong Zhang,Daniel Cremers,Yan Xia*

Main category: cs.RO

TL;DR: 提出了ArtiBench基准测试和ArtiBrain框架，用于解决关节物体操作中的泛化挑战，结合高层推理和自适应低层控制，在多个环境中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言和基于扩散的策略在跨部件、实例和类别的关节操作中泛化能力不足，需要解决物理一致性和长时程交互的挑战。

Method: ArtiBrain框架包含VLM任务推理器进行子目标分解和验证，混合控制器结合几何感知关键帧执行和可供性引导扩散，以及持续积累成功经验的Affordance Memory Bank。

Result: 在ArtiBench基准测试上的广泛实验表明，ArtiBrain在鲁棒性和泛化能力上显著优于最先进的多模态和基于扩散的方法。

Conclusion: ArtiBrain通过模块化框架统一高层推理和自适应低层控制，有效解决了关节物体操作的泛化挑战，为交互式操作提供了可靠解决方案。

Abstract: Interactive articulated manipulation requires long-horizon, multi-step interactions with appliances while maintaining physical consistency. Existing vision-language and diffusion-based policies struggle to generalize across parts, instances, and categories. We first introduce ArtiBench, a five-level benchmark covering kitchen, storage, office, and tool environments. ArtiBench enables structured evaluation from cross-part and cross-instance variation to long-horizon multi-object tasks, revealing the core generalization challenges of articulated object manipulation. Building on this benchmark, we propose ArtiBrain, a modular framework that unifies high-level reasoning with adaptive low-level control. ArtiBrain uses a VLM-based Task Reasoner (GPT-4.1) to decompose and validate subgoals, and employs a Hybrid Controller that combines geometry-aware keyframe execution with affordance-guided diffusion for precise and interpretable manipulation. An Affordance Memory Bank continually accumulates successful execution episodes and propagates part-level actionable affordances to unseen articulated parts and configurations. Extensive experiments on ArtiBench show that our ArtiBrain significantly outperforms state-of-the-art multimodal and diffusion-based methods in robustness and generalization. Code and dataset will be released upon acceptance.

</details>


### [96] [Quality-guided UAV Surface Exploration for 3D Reconstruction](https://arxiv.org/abs/2511.20353)
*Benjamin Sportich,Kenza Boubakri,Olivier Simonin,Alessandro Renzaglia*

Main category: cs.RO

TL;DR: 提出了一种用于空中机器人的模块化Next-Best-View规划框架，使用重建质量目标指导探索规划，通过自适应视图生成和选择方法，在覆盖范围、3D地图质量和路径效率方面优于传统NBV策略。


<details>
  <summary>Details</summary>
Motivation: 自主机器人在未知环境中的建图应用广泛，但现有规划策略往往忽视不同应用场景（如快速信息收集和建筑物结构评估）的不同需求，需要针对特定目标的方法论。

Method: 采用模块化NBV规划框架，引入基于TSDF环境表示中编码的不确定性的高效视图生成和候选视点选择方法，能够自适应于用户定义的质量要求。

Result: 在真实环境中的广泛模拟验证表明，该方法成功根据用户目标调整行为，在覆盖范围、最终3D地图质量和路径效率方面持续优于传统NBV策略。

Conclusion: 所提出的框架能够针对预定目标做出明智且高效的探索决策，为不同质量要求的建图任务提供了有效的解决方案。

Abstract: Reasons for mapping an unknown environment with autonomous robots are wide-ranging, but in practice, they are often overlooked when developing planning strategies. Rapid information gathering and comprehensive structural assessment of buildings have different requirements and therefore necessitate distinct methodologies. In this paper, we propose a novel modular Next-Best-View (NBV) planning framework for aerial robots that explicitly uses a reconstruction quality objective to guide the exploration planning. In particular, our approach introduces new and efficient methods for view generation and selection of viewpoint candidates that are adaptive to the user-defined quality requirements, fully exploiting the uncertainty encoded in a Truncated Signed Distance field (TSDF) representation of the environment. This results in informed and efficient exploration decisions tailored towards the predetermined objective. Finally, we validate our method via extensive simulations in realistic environments. We demonstrate that it successfully adjusts its behavior to the user goal while consistently outperforming conventional NBV strategies in terms of coverage, quality of the final 3D map and path efficiency.

</details>


### [97] [Power-Efficient Autonomous Mobile Robots](https://arxiv.org/abs/2511.20467)
*Liangkai Liu,Weisong Shi,Kang G. Shin*

Main category: cs.RO

TL;DR: pNav是一个新型电源管理系统，通过联合优化自主移动机器人的物理/机械和网络子系统，显著提高其功率/能效。


<details>
  <summary>Details</summary>
Motivation: 通过分析AMR的功耗特征，发现实现CPS能效面临三个挑战：系统功耗分解的变异性、环境感知导航局部性、以及C和P子系统的协调问题。

Method: 采用多层面方法：集成毫秒级功耗预测、实时建模和监控导航时空局部性、动态协调软件和硬件配置。基于ROS导航栈、2D LiDAR和摄像头进行原型开发。

Result: 在真实机器人和Gazebo环境中的深度评估显示，功耗预测准确率>96%，功耗降低38.1%，且不影响导航精度和安全性。

Conclusion: pNav系统有效解决了AMR的能效问题，通过联合优化网络和物理子系统实现了显著的功耗降低。

Abstract: This paper presents pNav, a novel power-management system that significantly enhances the power/energy-efficiency of Autonomous Mobile Robots (AMRs) by jointly optimizing their physical/mechanical and cyber subsystems. By profiling AMRs' power consumption, we identify three challenges in achieving CPS (cyber-physical system) power-efficiency that involve both cyber (C) and physical (P) subsystems: (1) variabilities of system power consumption breakdown, (2) environment-aware navigation locality, and (3) coordination of C and P subsystems. pNav takes a multi-faceted approach to achieve power-efficiency of AMRs. First, it integrates millisecond-level power consumption prediction for both C and P subsystems. Second, it includes novel real-time modeling and monitoring of spatial and temporal navigation localities for AMRs. Third, it supports dynamic coordination of AMR software (navigation, detection) and hardware (motors, DVFS driver) configurations. pNav is prototyped using the Robot Operating System (ROS) Navigation Stack, 2D LiDAR, and camera. Our in-depth evaluation with a real robot and Gazebo environments demonstrates a >96% accuracy in predicting power consumption and a 38.1% reduction in power consumption without compromising navigation accuracy and safety.

</details>


### [98] [Improved adaptive wind driven optimization algorithm for real-time path planning](https://arxiv.org/abs/2511.20394)
*Shiqian Liu,Azlan Mohd Zain,Le-le Mao*

Main category: cs.RO

TL;DR: 提出了一种改进的风驱动优化算法MAWDO，通过分层引导机制在动态环境中实现更好的路径规划，相比现有方法缩短路径长度3.51%-14.93%，并生成更平滑的轨迹。


<details>
  <summary>Details</summary>
Motivation: 动态环境中的实时适应性是自主导航的关键挑战，传统路径规划方法在动态环境中适应性不足，而风驱动优化算法因其物理可解释的搜索动态而显示出潜力。

Method: 提出多层级自适应风驱动优化(MAWDO)，采用分层引导机制将种群划分为多个组，分别由个体、区域和全局领导者引导，以平衡探索和开发能力。

Result: 在16个基准函数上评估显示MAWDO在优化精度、收敛稳定性和适应性方面优于现有元启发式算法。在动态路径规划中，路径长度缩短至469.28像素，相比MEWDO、AWDO和WDO分别提升3.51%、11.63%和14.93%，最优性差距最小(1.01)，平滑度为0.71。

Conclusion: MAWDO能够生成更平滑、更短且无碰撞的轨迹，证明了其在复杂环境中实时路径规划的有效性。

Abstract: Recently, path planning has achieved remarkable progress in enhancing global search capability and convergence accuracy through heuristic and learning-inspired optimization frameworks. However, real-time adaptability in dynamic environments remains a critical challenge for autonomous navigation, particularly when robots must generate collision-free, smooth, and efficient trajectories under complex constraints. By analyzing the difficulties in dynamic path planning, the Wind Driven Optimization (WDO) algorithm emerges as a promising framework owing to its physically interpretable search dynamics. Motivated by these observations, this work revisits the WDO principle and proposes a variant formulation, Multi-hierarchical adaptive wind driven optimization(MAWDO), that improves adaptability and robustness in time-varying environments. To mitigate instability and premature convergence, a hierarchical-guidance mechanism divides the population into multiple groups guided by individual, regional, and global leaders to balance exploration and exploitation. Extensive evaluations on sixteen benchmark functions show that MAWDO achieves superior optimization accuracy, convergence stability, and adaptability over state-of-the art metaheuristics. In dynamic path planning, MAWDO shortens the path length to 469.28 pixels, improving over Multi-strategy ensemble wind driven optimization(MEWDO), Adaptive wind driven optimization(AWDO) and WDO by 3.51\%, 11.63\% and 14.93\%, and achieves the smallest optimality gap (1.01) with smoothness 0.71 versus 13.50 and 15.67 for AWDO and WDO, leading to smoother, shorter, and collision-free trajectories that confirm its effectiveness for real-time path planning in complex environments.

</details>


### [99] [Safe and Stable Neural Network Dynamical Systems for Robot Motion Planning](https://arxiv.org/abs/2511.20593)
*Allen Emmanuel Binny,Mahathi Anand,Hugo T. M. Kussaba,Lingyun Chen,Shreenabh Agrawal,Fares J. Abu-Dakka,Abdalla Swikir*

Main category: cs.RO

TL;DR: S²-NNDS是一个从演示中学习机器人运动的框架，同时学习神经动态系统以及神经Lyapunov稳定性和屏障安全证书，提供概率安全保证。


<details>
  <summary>Details</summary>
Motivation: 在复杂非线性任务中，从演示中学习安全稳定的机器人运动仍然具有挑战性，特别是在动态、障碍物丰富的环境中。

Method: 利用神经网络捕捉复杂机器人运动，通过分裂保形预测在学习证书中提供概率保证，与传统限制性多项式参数化方法不同。

Result: 在2D和3D数据集（包括LASA手写和Franka Emika Panda机器人演示）上的实验验证了S²-NNDS从潜在不安全演示中学习鲁棒、安全、稳定运动的有效性。

Conclusion: S²-NNDS框架能够同时学习表达性神经动态系统和安全稳定性证书，在复杂环境中实现安全稳定的机器人运动学习。

Abstract: Learning safe and stable robot motions from demonstrations remains a challenge, especially in complex, nonlinear tasks involving dynamic, obstacle-rich environments. In this paper, we propose Safe and Stable Neural Network Dynamical Systems S$^2$-NNDS, a learning-from-demonstration framework that simultaneously learns expressive neural dynamical systems alongside neural Lyapunov stability and barrier safety certificates. Unlike traditional approaches with restrictive polynomial parameterizations, S$^2$-NNDS leverages neural networks to capture complex robot motions providing probabilistic guarantees through split conformal prediction in learned certificates. Experimental results on various 2D and 3D datasets -- including LASA handwriting and demonstrations recorded kinesthetically from the Franka Emika Panda robot -- validate S$^2$-NNDS effectiveness in learning robust, safe, and stable motions from potentially unsafe demonstrations.

</details>


### [100] [Kleinkram: Open Robotic Data Management](https://arxiv.org/abs/2511.20492)
*Cyrill Püntener,Johann Schwabe,Dominique Garmier,Jonas Frey,Marco Hutter*

Main category: cs.RO

TL;DR: Kleinkram是一个开源的机器人数据集管理系统，提供可扩展的存储、索引和共享功能，支持ROS bags和MCAP等标准格式，并包含基于Docker的工作流执行器。


<details>
  <summary>Details</summary>
Motivation: 解决大规模、非结构化机器人数据集的管理挑战，支持从单个实验到大规模研究数据集的存储和共享需求。

Method: 采用模块化的本地云解决方案，集成S3兼容存储，支持标准数据格式，并内置基于Docker的Action Runner执行自定义工作流。

Result: 已成功管理超过30TB来自不同机器人系统的数据，通过现代Web界面和CLI简化了研究生命周期。

Conclusion: Kleinkram为机器人研究社区提供了一个高效、灵活的数据集管理解决方案，支持数据验证、整理和基准测试等任务。

Abstract: We introduce Kleinkram, a free and open-source system designed to solve the challenge of managing massive, unstructured robotic datasets. Designed as a modular, on-premises cloud solution, Kleinkram enables scalable storage, indexing, and sharing of datasets, ranging from individual experiments to large-scale research collections. Kleinkram natively integrates with standard formats such as ROS bags and MCAP and utilises S3-compatible storage for flexibility. Beyond storage, Kleinkram features an integrated "Action Runner" that executes customizable Docker-based workflows for data validation, curation, and benchmarking. Kleinkram has successfully managed over 30 TB of data from diverse robotic systems, streamlining the research lifecycle through a modern web interface and a robust Command Line Interface (CLI).

</details>


### [101] [Metric, inertially aligned monocular state estimation via kinetodynamic priors](https://arxiv.org/abs/2511.20496)
*Jiaxin Liu,Min Li,Wanting Xu,Liang Li,Jiaqi Yang,Laurent Kneip*

Main category: cs.RO

TL;DR: 提出了一种将现有刚体姿态估计方法扩展到非刚性系统的方法，通过结合可学习的变形-力模型和连续时间B样条运动模型，在柔性机器人系统中实现准确的状态估计。


<details>
  <summary>Details</summary>
Motivation: 柔性机器人系统的动态变形结构使刚体假设失效，给准确状态估计带来重大挑战，需要开发能够处理非刚性系统的方法。

Method: 使用多层感知机学习注入式变形-力模型，结合连续时间B样条运动模型，通过连续应用牛顿第二定律建立视觉轨迹加速度与变形诱导加速度之间的物理联系。

Result: 方法不仅能在非刚性平台上实现鲁棒准确的姿态估计，还能通过正确建模的平台物理特性激发惯性传感特性，成功解决了单目视觉里程计中度量尺度和重力恢复的典型不适定问题。

Conclusion: 该方法有效扩展了姿态估计方法的应用范围，为柔性机器人系统的状态估计提供了可行的解决方案，并在简单弹簧-相机系统上验证了其可行性。

Abstract: Accurate state estimation for flexible robotic systems poses significant challenges, particular for platforms with dynamically deforming structures that invalidate rigid-body assumptions. This paper tackles this problem and allows to extend existing rigid-body pose estimation methods to non-rigid systems. Our approach hinges on two core assumptions: first, the elastic properties are captured by an injective deformation-force model, efficiently learned via a Multi-Layer Perceptron; second, we solve the platform's inherently smooth motion using continuous-time B-spline kinematic models. By continuously applying Newton's Second Law, our method establishes a physical link between visually-derived trajectory acceleration and predicted deformation-induced acceleration. We demonstrate that our approach not only enables robust and accurate pose estimation on non-rigid platforms, but that the properly modeled platform physics instigate inertial sensing properties. We demonstrate this feasibility on a simple spring-camera system, and show how it robustly resolves the typically ill-posed problem of metric scale and gravity recovery in monocular visual odometry.

</details>


### [102] [Gated Uncertainty-Aware Runtime Dual Invariants for Neural Signal-Controlled Robotics](https://arxiv.org/abs/2511.20570)
*Tasha Kim,Oiwi Parker Jones*

Main category: cs.RO

TL;DR: GUARDIAN是一个实时神经符号验证框架，通过结合置信度校准的脑信号解码和符号目标基础，为神经信号控制的机器人系统提供逻辑安全和生理信任保障。


<details>
  <summary>Details</summary>
Motivation: 安全关键的辅助系统需要从神经信号直接解码用户意图，这要求严格的可靠性和信任保证。

Method: 采用双层级运行时监控，结合置信度校准的脑信号解码与符号目标基础，在BNCI2014运动想象EEG数据集上进行验证。

Result: 系统在轻量级解码器架构下达到94-97%的安全率，在模拟噪声测试中实现1.7倍的正确干预，监控器以100Hz频率和亚毫秒延迟运行。

Conclusion: GUARDIAN框架能够提供可扩展的安全保障，产生从意图到行动的可审计追踪，将神经证据与可验证的机器人行动联系起来。

Abstract: Safety-critical assistive systems that directly decode user intent from neural signals require rigorous guarantees of reliability and trust. We present GUARDIAN (Gated Uncertainty-Aware Runtime Dual Invariants), a framework for real-time neuro-symbolic verification for neural signal-controlled robotics. GUARDIAN enforces both logical safety and physiological trust by coupling confidence-calibrated brain signal decoding with symbolic goal grounding and dual-layer runtime monitoring. On the BNCI2014 motor imagery electroencephalogram (EEG) dataset with 9 subjects and 5,184 trials, the system performs at a high safety rate of 94-97% even with lightweight decoder architectures with low test accuracies (27-46%) and high ECE confidence miscalibration (0.22-0.41). We demonstrate 1.7x correct interventions in simulated noise testing versus at baseline. The monitor operates at 100Hz and sub-millisecond decision latency, making it practically viable for closed-loop neural signal-based systems. Across 21 ablation results, GUARDIAN exhibits a graduated response to signal degradation, and produces auditable traces from intent, plan to action, helping to link neural evidence to verifiable robot action.

</details>


### [103] [Reinforcing Action Policies by Prophesying](https://arxiv.org/abs/2511.20633)
*Jiahui Zhang,Ze Huang,Chun Gu,Zipei Ma,Li Zhang*

Main category: cs.RO

TL;DR: ProphRL通过结合学习的世界模型Prophet和专门针对流式动作头的强化学习算法FA-GRPO，解决了VLA策略在模仿学习中存在的过拟合和分布偏移问题，实现了数据高效和优化稳定的VLA后训练。


<details>
  <summary>Details</summary>
Motivation: 大多数VLA策略仅通过模仿学习训练，容易过拟合演示数据且在分布偏移下表现脆弱。强化学习能直接优化任务奖励但真实机器人交互成本高，传统模拟器难以构建和迁移。

Method: 提出Prophet作为统一动作到视频的机器人驱动预训练模型，学习可重用的动作-结果动态；在此基础上使用FA-GRPO强化动作策略，结合FlowScale进行梯度重缩放。

Result: 在公开基准测试上获得5-17%的成功率提升，在真实机器人上获得24-30%的提升，适用于不同的VLA变体。

Conclusion: ProphRL为VLA后训练提供了一条实用、数据和计算高效的道路，显著提升了VLA策略的泛化能力和性能。

Abstract: Vision-Language-Action (VLA) policies excel in aligning language, perception, and robot control. However, most VLAs are trained purely by imitation, which overfits to demonstrations, and is brittle under distribution shift. Reinforcement learning (RL) directly optimizes task reward and thus addresses this misalignment, but real-robot interaction is expensive and conventional simulators are hard to engineer and transfer. We address both data efficiency and optimization stability in VLA post-training via a learned world model and an RL procedure tailored to flow-based action heads. Specifically, we introduce Prophet, a unified action-to-video robot actuation pretrained across large-scale, heterogeneous robot data to learn reusable action-outcome dynamics. It is able to few-shot adapt to new robots, objects, and environments, yielding a rollout-ready simulator. Upon Prophet, we reinforce action policies with Flow-action-GRPO (FA-GRPO), which adapts Flow-GRPO to operate on VLA actions, and with FlowScale, a stepwise reweighting that rescales per-step gradients in the flow head. Together, Prophet, FA-GRPO, and FlowScale constitute ProphRL, a practical, data- and compute-efficient path to VLA post-training. Experiments show 5-17% success gains on public benchmarks and 24-30% gains on real robots across different VLA variants.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [104] [Power sector models featuring individual BEV profiles: Assessing the time-accuracy trade-off](https://arxiv.org/abs/2511.19449)
*Adeline Guéret*

Main category: eess.SY

TL;DR: 研究电动汽车充电对电力系统的影响，发现使用多个独立BEV档案比单一聚合档案更准确，但需要平衡档案数量与计算效率。建议每20-25万辆车使用一个档案作为经验法则。


<details>
  <summary>Details</summary>
Motivation: 理解电动汽车普及对电力系统的挑战和机遇，需要准确反映"部门耦合"的建模方法，避免聚合过程中信息丢失。

Method: 采用包含多个独立BEV档案的建模方法，研究不同档案数量对结果准确性和计算效率的影响，并分析档案选择对最优解的影响。

Result: 过少的档案会导致最优解失真，但超过一定阈值后增加档案不会显著提升结果稳健性。对于500万至2000万辆BEV车队，建议每20-25万辆车使用一个档案。

Conclusion: 在BEV建模中需要平衡档案数量与计算效率，采用适当的档案数量可以确保准确结果而不产生过多计算负担。

Abstract: Electrifying passenger cars will impact future power systems. To understand the challenges and opportunities that arise, it is necessary to reflect "sector coupling" in the modeling space. This paper focuses on a specific modeling approach that includes dozens of individual BEV profiles rather than one aggregated BEV profile. Although including additional BEV profiles increases model complexity and runtime, it avoids losing information in the aggregation process. We investigate how many profiles are needed to ensure the accuracy of the results and the extent to which fewer profiles can be traded for runtime efficiency gains. We also examine whether selecting specific profiles influences optimal results. We demonstrate that including too few profiles may result in distorted optimal solutions. However, beyond a certain threshold, adding more profiles does not significantly enhance the robustness of the results. More generally, for fleets of 5 to 20 million BEVs, we derive a rule of thumb consisting in including enough profiles such that each profile represents 200,000 to 250,000 vehicles, ensuring accurate results without excessive runtime.

</details>


### [105] [Strong Duality and Dual Ascent Approach to Continuous-Time Chance-Constrained Stochastic Optimal Control](https://arxiv.org/abs/2511.19451)
*Apurva Patil,Alfredo Duarte,Fabrizio Bisetti,Takashi Tanaka*

Main category: eess.SY

TL;DR: 该论文提出了一种解决连续时间连续空间机会约束随机最优控制问题的方法，通过退出时间概念将机会约束转化为期望函数，利用对偶公式和路径积分方法进行数值求解。


<details>
  <summary>Details</summary>
Motivation: 解决连续时间连续空间中随机系统满足状态约束的概率有明确上限的最优控制问题，避免传统方法的保守近似。

Method: 利用退出时间概念将机会约束转化为期望函数，采用对偶公式将约束纳入成本函数，使用路径积分方法通过梯度上升求解对偶问题。

Result: 在特定系统动态和成本函数假设下，证明了原始机会约束问题与其对偶问题之间的强对偶性，并通过移动机器人运动规划仿真验证了方法的有效性。

Conclusion: 提出的方法能够有效解决连续时间连续空间机会约束随机最优控制问题，路径积分方法相比有限差分法具有更好的性能。

Abstract: The paper addresses a continuous-time continuous-space chance-constrained stochastic optimal control (SOC) problem where the probability of failure to satisfy given state constraints is explicitly bounded. We leverage the notion of exit time from continuous-time stochastic calculus to formulate a chance-constrained SOC problem. Without any conservative approximation, the chance constraint is transformed into an expectation of an indicator function which can be incorporated into the cost function by considering a dual formulation. We then express the dual function in terms of the solution to a Hamilton-Jacobi-Bellman partial differential equation parameterized by the dual variable. Under a certain assumption on the system dynamics and cost function, it is shown that a strong duality holds between the primal chance-constrained problem and its dual. The Path integral approach is utilized to numerically solve the dual problem via gradient ascent using open-loop samples of system trajectories. We present simulation studies on chance-constrained motion planning for spatial navigation of mobile robots and the solution of the path integral approach is compared with that of the finite difference method.

</details>


### [106] [Quantum-Enhanced Reinforcement Learning for Accelerating Newton-Raphson Convergence with Ising Machines: A Case Study for Power Flow Analysis](https://arxiv.org/abs/2511.20237)
*Zeynab Kaseb,Matthias Moller,Lindsay Spoor,Jerry J. Guo,Yu Xiang,Peter Palensky,Pedro P. Vergara*

Main category: eess.SY

TL;DR: 使用强化学习优化牛顿-拉夫逊法的初始化，结合量子退火器解决大规模动作空间的计算成本问题，显著提升收敛速度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统牛顿-拉夫逊法在不良初始化或极端运行场景下性能下降，特别是在高可再生能源渗透率情况下，传统初始化策略往往导致收敛缓慢甚至发散。

Method: 提出强化学习优化NR初始化，引入量子增强的RL环境更新机制，将电压调整任务建模为二次无约束二进制优化问题，集成量子/数字退火器评估状态转移。

Result: 结果显示收敛速度显著提升，NR迭代次数减少，在不同运行条件下鲁棒性增强。

Conclusion: 量子增强的强化学习方法能有效解决牛顿-拉夫逊法在极端场景下的初始化问题，提高计算效率和系统稳定性。

Abstract: The Newton-Raphson (NR) method is widely used for solving power flow (PF) equations due to its quadratic convergence. However, its performance deteriorates under poor initialization or extreme operating scenarios, e.g., high levels of renewable energy penetration. Traditional NR initialization strategies often fail to address these challenges, resulting in slow convergence or even divergence. We propose the use of reinforcement learning (RL) to optimize the initialization of NR, and introduce a novel quantum-enhanced RL environment update mechanism to mitigate the significant computational cost of evaluating power system states over a combinatorially large action space at each RL timestep by formulating the voltage adjustment task as a quadratic unconstrained binary optimization problem. Specifically, quantum/digital annealers are integrated into the RL environment update to evaluate state transitions using a problem Hamiltonian designed for PF. Results demonstrate significant improvements in convergence speed, a reduction in NR iteration counts, and enhanced robustness under different operating conditions.

</details>


### [107] [A Data-Driven Model Predictive Control Framework for Multi-Aircraft TMA Routing Under Travel Time Uncertainty](https://arxiv.org/abs/2511.19452)
*Yi Zhang,Yushen Long,Liping Huang,Yicheng Zhang,Sheng Zhang,Yifang Yin*

Main category: eess.SY

TL;DR: 提出一个闭环框架，用于终端机动区域内多航空器的无冲突路由和调度，旨在减少拥堵并提高着陆效率。


<details>
  <summary>Details</summary>
Motivation: 解决终端机动区域内的航空器拥堵问题，提高跑道吞吐量和着陆效率，为空中交通管制员提供实时决策支持。

Method: 采用数据驱动的到达输入，建立混合整数优化模型，结合扩展的终端机动区域网络，实施滚动时域模型预测控制策略，并与交通模拟器进行闭环集成。

Result: 在高峰拥堵期间计算时间减少7倍，蒙特卡洛模拟验证了框架在旅行时间扰动下的鲁棒性，展示了操作弹性和计算可扩展性。

Conclusion: 该框架通过实时优化和自适应重新规划，为空中交通管制员提供了可行的决策支持，显著提高了终端机动区域的管理效率。

Abstract: This paper presents a closed-loop framework for conflict-free routing and scheduling of multi-aircraft in Terminal Manoeuvring Areas (TMA), aimed at reducing congestion and enhancing landing efficiency. Leveraging data-driven arrival inputs (either historical or predicted), we formulate a mixed-integer optimization model for real-time control, incorporating an extended TMA network spanning a 50-nautical-mile radius around Changi Airport. The model enforces safety separation, speed adjustments, and holding time constraints while maximizing runway throughput. A rolling-horizon Model Predictive Control (MPC) strategy enables closed-loop integration with a traffic simulator, dynamically updating commands based on real-time system states and predictions. Computational efficiency is validated across diverse traffic scenarios, demonstrating a 7-fold reduction in computation time during peak congestion compared to onetime optimization, using Singapore ADS-B dataset. Monte Carlo simulations under travel time disturbances further confirm the framework's robustness. Results highlight the approach's operational resilience and computational scalability, offering actionable decision support for Air Traffic Controller Officers (ATCOs) through real-time optimization and adaptive replanning.

</details>


### [108] [A K-means Inspired Solution Framework for Large-Scale Multi-Traveling Salesman Problems](https://arxiv.org/abs/2511.19454)
*Xiubin Chen*

Main category: eess.SY

TL;DR: 提出基于K-means的任务分配框架，将多旅行商问题重构为空间约束分类过程，显著降低计算复杂度，适用于大规模场景（如1000个智能体和5000个目标）。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法在处理大规模多智能体任务分配时计算成本过高，难以满足无人系统大规模协调的需求。

Method: 采用"先聚类后路由"的分解策略，利用空间相干性快速估计路径成本并高效分组任务，将MTSP重构为空间约束分类问题。

Result: 仿真结果表明，该框架在极大规模场景下仍能保持高质量解，计算效率显著提升。

Conclusion: 这种基于聚类的分解策略为大规模多智能体任务分配提供了高效可靠的解决方案。

Abstract: The Multi-Traveling Salesman Problem (MTSP) is a commonly used mathematical model for multi-agent task allocation. However, as the number of agents and task targets increases, existing optimization-based methods often incur prohibitive computational costs, posing significant challenges to large-scale coordination in unmanned systems. To address this issue, this paper proposes a K-means-inspired task allocation framework that reformulates the MTSP as a spatially constrained classification process. By leveraging spatial coherence, the proposed method enables fast estimation of path costs and efficient task grouping, thereby fundamentally reducing overall computational complexity. Extensive simulation results demonstrate that the framework can maintain high solution quality even in extremely large-scale scenarios-for instance, in tasks involving 1000 agents and 5000 targets. The findings indicate that this "cluster-then-route" decomposition strategy offers an efficient and reliable solution for large-scale multi-agent task allocation.

</details>


### [109] [Active Secure Neighbor Selection in Multi-Agent Systems with Byzantine Attacks](https://arxiv.org/abs/2511.19522)
*Jinming Gao,Yijing Wang,Wentao Zhang,Rui Zhao,Yang Shi,Zhiqiang Zuo*

Main category: eess.SY

TL;DR: 提出了一种基于主动安全邻居选择框架的多智能体系统弹性控制方法，通过构建预判别图并动态选择邻居，在拜占庭攻击下实现弹性共识，同时降低通信负担。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统在存在拜占庭敌对者时的弹性控制问题，传统方法通常需要较强的初始连通性假设且通信开销较大。

Method: 首先构建预判别图定义候选邻居集，然后提出动态入邻居选择策略，每个智能体主动选择预判别邻居的子集，选择数量可调以平衡通信开销和鲁棒性。

Result: 该方法能够在检测和隔离拜占庭智能体后，在正常智能体间重建有向生成树，实现弹性共识，且不要求正常智能体间的初始连通性假设。

Conclusion: 所提出的主动安全邻居选择框架有效降低了通信负担，同时保持了对敌对行为的弹性，数值示例验证了方法的有效性。

Abstract: This paper investigates the problem of resilient control for multi-agent systems in the presence of Byzantine adversaries via an active secure neighbor selection framework. A pre-discriminative graph is first constructed to characterize the admissible set of candidate neighbors for each agent. Based on this graph, a dynamic in-neighbor selection strategy is proposed, wherein each agent actively selects a subset of its pre-discriminative neighbors. The number of selected neighbors is adjustable, allowing for a trade-off between communication overhead and robustness, with the minimal case requiring only a single in-neighbor. The proposed strategy facilitates the reconstruction of a directed spanning tree among normal agents following the detection and isolation of Byzantine agents. It achieves resilient consensus without imposing any assumptions on the initial connectivity among normal agents. Moreover, the approach significantly reduces communication burden while maintaining resilience to adversarial behavior. A numerical example is provided to illustrate the effectiveness of the proposed method.

</details>


### [110] [State Feedback Controllers with Operational Constraints](https://arxiv.org/abs/2511.19683)
*Eugene Lavretsky*

Main category: eess.SY

TL;DR: 本文针对多输入多输出线性时不变系统，开发了一种带有最小/最大运行限制约束的状态反馈控制设计，解决了具有输入和输出约束的伺服跟踪控制问题。


<details>
  <summary>Details</summary>
Motivation: 为多输入多输出线性时不变系统设计能够在运行限制约束下工作的伺服跟踪控制器，特别是针对航空飞行关键系统，确保系统在约束范围内安全运行。

Method: 基于Nagumo定理的前向不变性、比较引理用于输入/输出不等式约束的包含，以及最小范数最优控制器进行综合。包括静态和动态伺服控制器设计，动态控制器还包含抗饱和保护逻辑。

Result: 提出的控制方法能够有效处理输入和输出约束，确保系统在指定限制范围内运行，类似于控制屏障函数方法。

Conclusion: 所开发的控制方法为具有运行约束的多输入多输出系统提供了一种有效的解决方案，特别适用于航空飞行关键系统，通过仿真研究验证了其优势。

Abstract: In this paper, a state feedback control design with min/max operational limiting constraints is developed for multi-input-multi-output linear time invariant systems. Specifically, servo-tracking control problems with input and output constraints are considered. For static servo-controllers, the output design limits are imposed component-wise on the system selected output, which is of the same dimension as the control input. For dynamic servo-controllers, operational constraints are applied to the system inputs and outputs. The proposed control solution also includes an anti-windup protection logic for dynamic servo-controllers with integral action. The developed method is based on the Nagumo Theorem for forward invariance, the Comparison Lemma for inclusion of input/output inequality constraints, and on the min-norm optimal controllers for synthesis. The derived design is similar and directly related to the method of Control Barrier Functions. Simulation trade studies are presented to illustrate benefits of the proposed control methodology for aerial flight critical systems.

</details>


### [111] [Understanding Risk and Revenue in the Nordic 15-minute mFRR market: An EV Aggregation Study](https://arxiv.org/abs/2511.19715)
*Theodor Hagström,Lars Herre*

Main category: eess.SY

TL;DR: 研究电动汽车车队参与北欧15分钟mFRR能源激活市场的商业模式，通过风险感知随机优化协调日前调度与15分钟mFRR投标，提高预期利润并降低下行风险。


<details>
  <summary>Details</summary>
Motivation: 脱碳化、去中心化和间歇性推动灵活性市场向更短市场时间单位发展，更短的MTU和关闸时间降低了需求侧聚合商的进入门槛，这些聚合商在较长时间尺度上面临显著不确定性。

Method: 将车队灵活性表示为具有时变功率和能量包络的虚拟电池，制定风险感知随机优化，协调日前调度与15分钟mFRR投标，使用保守可用性和CVaR增强目标函数。

Result: 在两种价格情景下，协同优化都提高了预期利润并降低了下行风险：模型在日前购买更少能源，将采购转向mFRR下调，同时平整充电计划以保持mFRR上调资格。利润分解显示提升主要来自更高的mFRR下调收入和减少对平仓日前头寸的依赖。

Conclusion: 协同优化策略能有效提升电动汽车车队在灵活性市场中的盈利能力，讨论了投标的操作影响，并提出了两个扩展：滚动45分钟重新优化和V2G框架。

Abstract: Decarbonisation, decentralisation, and intermittency are driving the development of flexibility markets towards shorter market time units (MTU). Shorter MTUs and shorter gate closures lower the entrance barriers of demand side aggregators that face significant uncertainty on longer time scales. We study the business case for aggregated EV fleets participating in the Nordic 15-minute mFRR Energy Activation Market (EAM). Motivated by increasing system granularity and rapid EV uptake, we represent fleet flexibility as a virtual battery with time-varying power and energy envelopes and formulate a risk-aware stochastic optimisation that co-ordinates day-ahead scheduling with quarter-hour mFRR bidding. Using synthetic residential charging cohorts and observed day-ahead prices on two stylised days, we compare an independent day-ahead baseline to a co-optimised strategy under conservative availability and a CVaR-augmented objective. Across both price cases, co-optimisation increases expected profit and lowers downside risk: the model buys less energy day-ahead and shifts procurement toward mFRR down while flattening the charging plan to retain eligibility for mFRR up. Profit decomposition shows that the uplift is driven by higher mFRR down revenues and reduced reliance on unwinding day-ahead positions. We discuss operational implications for bidding and outline two extensions: rolling 45-minute re-optimisation and a V2G framework.

</details>


### [112] [Multi-Hypotheses Ego-Tracking for Resilient Navigation](https://arxiv.org/abs/2511.19770)
*Peter Iwer Hoedt Karstensen,Roberto Galeazzi*

Main category: eess.SY

TL;DR: 提出了一种结合多假设估计和泊松二项窗口计数检测器的弹性导航架构，用于对抗RF定位系统中的欺骗攻击和传感器操纵。


<details>
  <summary>Details</summary>
Motivation: 依赖RF定位的自主机器人容易受到欺骗和传感器操纵攻击，需要开发能够识别和隔离异常的安全导航系统。

Method: 采用多假设估计与泊松二项窗口计数检测器进行异常识别和隔离，通过状态机协调操作、诊断和缓解之间的转换，当检测到攻击时使用基于微分平坦度的轨迹重规划进行信息收集机动。

Result: 案例研究表明，该系统能有效检测偏置传感器，在持续欺骗攻击下保持状态估计并恢复名义操作。

Conclusion: 所提出的弹性导航架构能够有效应对RF定位系统中的安全威胁，确保自主机器人在对抗环境下的可靠运行。

Abstract: Autonomous robots relying on radio frequency (RF)-based localization such as global navigation satellite system (GNSS), ultra-wide band (UWB), and 5G integrated sensing and communication (ISAC) are vulnerable to spoofing and sensor manipulation. This paper presents a resilient navigation architecture that combines multi-hypothesis estimation with a Poisson binomial windowed-count detector for anomaly identification and isolation. A state machine coordinates transitions between operation, diagnosis, and mitigation, enabling adaptive response to adversarial conditions. When attacks are detected, trajectory re-planning based on differential flatness allows information-gathering maneuvers minimizing performance loss. Case studies demonstrate effective detection of biased sensors, maintenance of state estimation, and recovery of nominal operation under persistent spoofing attacks

</details>


### [113] [An Exact Solution Algorithm for the Bi-Level Optimization Problem of Electric Vehicles Charging Station Placement](https://arxiv.org/abs/2511.19884)
*Mobina Nankali,Michael W. Levin*

Main category: eess.SY

TL;DR: 本文提出了首个用于大规模电动汽车充电站选址问题的精确求解算法，通过分支定价割平面方法在合理时间内获得全局最优解。


<details>
  <summary>Details</summary>
Motivation: 现有研究依赖无法保证最优性的启发式方法，或需要过长运行时间的精确算法，无法满足实际决策需求。

Method: 采用双层优化模型，上层规划者在预算约束下选择充电站位置最大化净收益，下层EV用户选择路线和充电站最小化出行和充电成本。提出分支定价割平面算法，结合值函数割和列生成技术。

Result: 在马萨诸塞州东部网络、阿纳海姆网络和巴塞罗那网络上进行实验，算法在几分钟内终止，最优性差距低于1%，计算速度比现有方法快两个数量级。

Conclusion: 该算法成功处理超过30万个可行组合的问题，将电动汽车充电基础设施规划从计算上不可行的问题转变为适合实际决策的可处理优化任务。

Abstract: This work addresses electric vehicle (EV) charging station placement through a bi-level optimization model, where the upper-level planner maximizes net revenue by selecting station locations under budget constraints, while EV users at the lower level choose routes and charging stations to minimize travel and charging costs. To account for range anxiety, we construct a battery-expanded network and apply a shortest path algorithm with Frank-Wolfe traffic assignment. Our primary contribution is developing the first exact solution algorithm for large scale EV charging station placement problems. We propose a Branch-and-Price-and-Cut algorithm enhanced with value function cuts and column generation. While existing research relies on heuristic methods that provide no optimality guarantees or exact algorithms that require prohibitively long runtimes, our exact algorithm delivers globally optimal solutions with mathematical certainty under a reasonable runtime. Computational experiments on the Eastern Massachusetts network (74 nodes, 248 links), the Anaheim network (416 nodes, 914 links), and the Barcelona network (110 zones, 1,020 nodes, and 2,512 links) demonstrate exceptional performance. Our algorithm terminates within minutes rather than hours, while achieving optimality gaps below 1% across all instances. This result represents a computational speedup of over two orders of magnitude compared to existing methods. The algorithm successfully handles problems with over 300,000 feasible combinations, which transform EV charging infrastructure planning from a computationally prohibitive problem into a tractable optimization task suitable for practical decision making problem for real world networks.

</details>


### [114] [Toward Trustworthy Digital Twins in Agentic AI-based Wireless Network Optimization: Challenges, Solutions, and Opportunities](https://arxiv.org/abs/2511.19961)
*Zhenyu Tao,Wei Xu,Xiaohu You*

Main category: eess.SY

TL;DR: 提出统一的数字孪生评估框架，从传统物理精度指标转向任务中心化评估，确保基于智能AI的网络优化中可信赖的数字孪生。


<details>
  <summary>Details</summary>
Motivation: 现代无线网络优化面临高动态性和复杂性挑战，智能AI提供有前景的解决方案，但实际应用受限于高昂的探索成本和现实风险。数字孪生技术提供安全训练环境，但其有效性取决于保真度。

Method: 引入统一的数字孪生评估框架，从孤立物理精度指标转向整体任务中心化评估，作为无线网络数字孪生设计、选择和生命周期管理的有效指南。

Result: 在真实无线网络测试平台上的案例研究表明，该评估框架可用于预筛选候选数字孪生，显著降低训练和测试成本，同时不牺牲部署性能。

Conclusion: 该评估框架为基于智能AI的网络优化提供了可信赖的数字孪生保障，并讨论了潜在的研究机会。

Abstract: Optimizing modern wireless networks is exceptionally challenging due to their high dynamism and complexity. While the agentic artificial intelligence (AI) powered by reinforcement learning (RL) offers a promising solution, its practical application is limited by prohibitive exploration costs and potential risks in the real world. The emerging digital twin (DT) technology provides a safe and controlled virtual environment for agentic AI training, but its effectiveness critically depends on the DT's fidelity. Policies trained in a low-fidelity DT that does not accurately represent the physical network may experience severe performance degradation upon real-world deployment. In this article, we introduce a unified DT evaluation framework to ensure trustworthy DTs in agentic AI-based network optimization. This evaluation framework shifts from conventional isolated physical accuracy metrics, such as wireless channel and user trajectory similarities, to a more holistic, task-centric DT assessment. We demonstrate it as an effective guideline for design, selection, and lifecycle management of wireless network DTs. A comprehensive case study on a real-world wireless network testbed shows how this evaluation framework is used to pre-filter candidate DTs, leading to a significant reduction in training and testing costs without sacrificing deployment performance. Finally, potential research opportunities are discussed.

</details>


### [115] [Assessing the Technical and Environmental Impacts of Energy Management Systems in Smart Ports](https://arxiv.org/abs/2511.20043)
*Youzhe Yang,Hafiz Majid Hussain,Juha Haakana,Pedro Nardelli*

Main category: eess.SY

TL;DR: 本文评估了智能港口能源管理系统(EMS)的实施效果，发现其能显著降低能耗7%-8%、碳排放11%-12%，并节省30%运营成本，但面临系统集成、数据质量等挑战。


<details>
  <summary>Details</summary>
Motivation: 为帮助港口减少海事行业环境影响，遵守欧洲绿色协议和可持续发展目标，需要系统实施综合能源管理解决方案。

Method: 首先对汉堡、热那亚、裕廊和上海洋山四期等主要港口案例进行系统文献回顾，然后构建优化模型模拟负荷调度、碳减排和运输调度。

Result: EMS部署使年能耗降低约7%-8%，碳排放减少11%-12%，并实现30%的成本节约。

Conclusion: 研究结果为港口管理者和政策制定者提供了宝贵见解，支持向更可持续和高效的港口运营转型，但需解决系统集成、数据质量等关键挑战。

Abstract: A vital strategy for ports to mitigate the environmental impact of the maritime industry, while complying with frameworks such as the European Green Deal and the Sustainable Development Goals (SDGs), entails the systematic implementation of comprehensive energy management solutions. This paper provides a baseline evaluation of the energy management systems (EMSs) implementation and their impact on energy consumption, carbon emissions, and operational costs in smart ports. Initially, we provide a systematic review of the literature focusing on case studies from prominent ports, including Hamburg, Genoa, Jurong, and Shanghai Yangshan Phase IV. The analysis emphasises key aspects such as energy efficiency, reductions in emissions, and the minimization of operational costs. Subsequently, we formulate an optimisation model to simulate load dispatch, carbon emission reduction, and transport scheduling. Results indicate that EMS deployment reduces annual energy consumption and carbon emissions significantly by approximately 7%-8% and 11%-12% respectively, while achieving substantial cost savings of 30%. The study also identifies critical challenges, including system integration, data quality issues, cybersecurity risks, and the need for standardization. These findings provide valuable insights for port authorities and policymakers, supporting the transition toward more sustainable and efficient port operations.

</details>


### [116] [Occlusion-Aware Multi-Object Tracking via Expected Probability of Detection](https://arxiv.org/abs/2511.20239)
*Jan Krejčí,Oliver Kost,Yuxuan Xia,Lennart Svensson,Ondřej Straka*

Main category: eess.SY

TL;DR: 提出了一种改进的多目标跟踪方法，通过考虑目标间相互遮挡对检测概率的影响，使用基于减少Palm密度的期望检测概率来系统性地处理所有目标的不确定性。


<details>
  <summary>Details</summary>
Motivation: 在多目标系统中，目标之间可能存在相互遮挡，影响传感器的检测概率。现有方法未能系统性地考虑所有目标存在带来的不确定性。

Method: 增强标准点目标模型，为每个目标分配期望检测概率，该期望基于减少Palm密度计算（即条件于目标存在）。使用带标记的多伯努利混合(MBM)滤波器进行视觉跟踪应用。

Result: 该方法能够清晰且可管理地考虑所有目标相关的不确定性，相比现有方法更系统地处理遮挡问题。

Conclusion: 提出的方法通过考虑目标间遮挡效应，为多目标跟踪提供了一种原则性的解决方案，能够更好地处理传感器检测概率的不确定性。

Abstract: This paper addresses multi-object systems, where objects may occlude one another relative to the sensor. The standard point-object model for detection-based sensors is enhanced so that the probability of detection considers the presence of all objects. A principled tracking method is derived, assigning each object an expected probability of detection, where the expectation is taken over the reduced Palm density, which means conditionally on the object's existence. The assigned probability thus considers the object's visibility relative to the sensor, under the presence of other objects. Unlike existing methods, the proposed method systematically accounts for uncertainties related to all objects in a clear and manageable way. The method is demonstrated through a visual tracking application using the multi-Bernoulli mixture (MBM) filter with marks.

</details>


### [117] [LLM-Driven Transient Stability Assessment: From Automated Simulation to Neural Architecture Design](https://arxiv.org/abs/2511.20276)
*Lianzhe Hu,Yu Wang,Bikash Pal*

Main category: eess.SY

TL;DR: 提出了一个基于LLM的端到端工作流，用于电力系统暂态稳定评估的自动化和智能化，通过LLM驱动的神经网络设计管道自动优化TSA模型，在IEEE 39节点系统中达到93.71%的测试精度。


<details>
  <summary>Details</summary>
Motivation: 解决电力系统暂态稳定评估中自动化和智能化不足的问题，传统方法依赖人工设计，效率低下且难以扩展。

Method: 集成大型语言模型与专业模拟器(ANDES)，通过自然语言自动生成和筛选扰动场景，采用LLM驱动的神经网络设计管道通过性能引导的闭环反馈自主设计和优化TSA模型。

Result: 在IEEE 39节点系统中，LLM-NND模型在四类TSA任务上达到93.71%的测试精度，仅需4.78M参数，实时推理延迟小于0.95毫秒/样本，相比手动设计的DenseNet(25.9M参数，80.05%精度)同时提高了精度和效率。

Conclusion: LLM代理能够可靠地加速TSA研究从场景生成、数据采集到模型设计和解释的全过程，提供了一个可扩展的范式，可轻松扩展到其他电力系统任务。

Abstract: This paper presents an LLM-driven, end-to-end workflow that addresses the lack of automation and intelligence in power system transient stability assessment (TSA). The proposed agentic framework integrates large language models (LLMs) with a professional simulator (ANDES) to automatically generate and filter disturbance scenarios from natural language, and employs an LLM-driven Neural Network Design (LLM-NND) pipeline to autonomously design and optimize TSA models through performance-guided, closed-loop feedback. On the IEEE 39-bus system, the LLM-NND models achieve 93.71% test accuracy on four-class TSA with only 4.78M parameters, while maintaining real-time inference latency (less than 0.95 ms per sample). Compared with a manually designed DenseNet (25.9M parameters, 80.05% accuracy), the proposed approach jointly improves accuracy and efficiency. Ablation studies confirm that the synergy among domain-grounded retrieval, reasoning augmentation, and feedback mechanisms is essential for robust automation. The results demonstrate that LLM agents can reliably accelerate TSA research from scenario generation and data acquisition to model design and interpretation, offering a scalable paradigm that is readily extensible to other power system tasks such as optimal power flow, fault analysis, and market operations.

</details>


### [118] [SAFE-IMM: Robust and Lightweight Radar-Based Object Tracking on Mobile Platforms](https://arxiv.org/abs/2511.20294)
*Dnyandeep Mandaokar,Bernhard Rinner*

Main category: eess.SY

TL;DR: SAFE-IMM是一种轻量级IMM滤波器变体，通过安全协方差感知门控机制，在资源受限平台上实现快速响应和平稳跟踪的平衡。


<details>
  <summary>Details</summary>
Motivation: 传统IMM滤波器在融合模型时存在滞后问题，而赢家通吃方法虽然响应快但会产生不连续性，需要在移动和资源受限平台上实现响应性和鲁棒性的平衡。

Method: 提出SAFE-IMM方法，采用安全协方差感知门控，仅在从混合模型到获胜模型的跳跃被证明有界时才允许赢家通吃策略。

Result: 在仿真和nuScenes前雷达数据上的实验表明，SAFE-IMM实现了高精度实时跟踪，减少了ID切换，同时保持竞争性能。

Conclusion: SAFE-IMM方法简单易集成、数值稳定、对杂波鲁棒，在响应性和平滑性之间提供了实用的平衡。

Abstract: Tracking maneuvering targets requires estimators that are both responsive and robust. Interacting Multiple Model (IMM) filters are a standard tracking approach, but fusing models via Gaussian mixtures can lag during maneuvers. Recent winnertakes-all (WTA) approaches react quickly but may produce discontinuities. We propose SAFE-IMM, a lightweight IMM variant for tracking on mobile and resource-limited platforms with a safe covariance-aware gate that permits WTA only when the implied jump from the mixture to the winner is provably bounded. In simulations and on nuScenes front-radar data, SAFE-IMM achieves high accuracy at real-time rates, reducing ID switches while maintaining competitive performance. The method is simple to integrate, numerically stable, and clutter-robust, offering a practical balance between responsiveness and smoothness.

</details>


### [119] [Accelerating Time-Optimal Trajectory Planning for Connected and Automated Vehicles with Graph Neural Networks](https://arxiv.org/abs/2511.20383)
*Viet-Anh Le,Andreas A. Malikopoulos*

Main category: eess.SY

TL;DR: 提出基于图神经网络的学习框架，加速联网自动驾驶车辆的时间和能量最优轨迹规划，通过GNN学习离线数据生成在线预测作为优化热启动，实现实时多智能体重规划。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体协调问题中的实时轨迹规划挑战，需要在满足约束的同时最小化旅行时间，传统方法计算成本高难以实时执行。

Method: 将多智能体协调问题建模为合作轨迹规划问题，使用GNN架构从离线数据学习时间最优轨迹规划的解，在线预测作为数值优化的热启动解。

Result: 学习增强方法显著减少计算时间，同时确保所有状态、输入和安全约束得到满足，实现实时多智能体重规划。

Conclusion: 基于GNN的学习框架能够有效加速CAV的轨迹规划，通过离线学习在线预测实现实时性能，为多智能体协调提供可行解决方案。

Abstract: In this paper, we present a learning-based framework that accelerates time- and energy-optimal trajectory planning for connected and automated vehicles (CAVs) using graph neural networks (GNNs). We formulate the multi-agent coordination problem encountered in traffic scenarios as a cooperative trajectory planning problem that minimizes travel time, subject to motion primitives derived from energy-optimal solutions. The effectiveness of this framework can be further improved through replanning at each time step, enabling the system to incorporate newly observed information. To achieve real-time execution of such a multi-agent replanning scheme, we employ a GNN architecture to learn the solutions of the time-optimal trajectory planning problem from offline-generated data. The trained model produces online predictions that serve as warm-start solutions for numerical optimization, thereby enabling rapid computation of minimal exit times and the associated feasible trajectories. This learning-augmented approach substantially reduces computation time while ensuring that all state, input, and safety constraints are satisfied.

</details>


### [120] [Adaptive Meshing for CPA Lyapunov Function Synthesis](https://arxiv.org/abs/2511.20443)
*Amy K. Strong,Samuel Akinwande,Leila Bridgeman*

Main category: eess.SY

TL;DR: 本文研究了三种更高效的网格划分方法（自适应网格、基于系统模型的网格以及两者结合）来降低连续分段仿射Lyapunov函数合成的计算成本。


<details>
  <summary>Details</summary>
Motivation: 连续分段仿射Lyapunov函数合成方法在更精细的网格上计算成本较高，特别是在高维系统中，需要寻找更高效的网格划分方法来减少计算负担。

Method: 探索了三种网格划分方法：自适应网格划分、基于系统模型知识的网格划分以及两者的组合方法，并通过二维和三维非线性动力系统的数值算例进行比较。

Result: 通过数值算例验证了三种方法在提高计算效率方面的有效性。

Conclusion: 提出的三种网格划分方法能够更高效地合成Lyapunov函数，降低计算成本，特别是在高维非线性系统分析中具有应用价值。

Abstract: Continuous piecewise affine (CPA) Lyapunov function synthesis is one method to perform Lyapunov stability analysis for nonlinear systems. This method first generates a mesh over the region of interest in the system's state space and then solves a linear program (LP), which enforces constraints on each vertex of the mesh, to synthesize a Lyapunov function. Finer meshes broaden the class of Lyapunov function candidates, but CPA function synthesis is more computationally expensive for finer meshes -- particularly so in higher dimensional systems. This paper explores methods to mesh the region of interest more efficiently so that a Lyapunov function can be synthesized using less computational effort. Three methods are explored -- adaptive meshing, meshing using knowledge of the system model, and a combination of the two. Numerical examples for two and three dimensional nonlinear dynamical systems are used to compare the efficacy of the three methods.

</details>


### [121] [Learning Control Barrier Functions with Deterministic Safety Guarantees](https://arxiv.org/abs/2511.20463)
*Amy K. Strong,Ali Kashani,Claus Danielson,Leila Bridgeman*

Main category: eess.SY

TL;DR: 该论文提出了一种使用ReLU神经网络构建连续分段仿射屏障函数的方法，通过数据驱动优化为非线性动力系统提供确定性安全保障。


<details>
  <summary>Details</summary>
Motivation: 为非线性、非自治动力系统计算有效的安全集和屏障函数是一个困难任务，需要数据驱动的方法来获得具有确定性保证的控制不变性。

Method: 利用ReLU神经网络创建连续分段仿射屏障函数，通过采样的一步轨迹数据，采用迭代凸上界方法解决非凸优化问题。

Result: 在二维自治和非自治动力系统上验证了方法的有效性，能够获得具有确定性安全保证的安全集。

Conclusion: 该方法成功地为非线性动力系统构建了数据驱动的屏障函数，提供了确定性的安全保障。

Abstract: Barrier functions (BFs) characterize safe sets of dynamical systems, where hard constraints are never violated as the system evolves over time. Computing a valid safe set and BF for a nonlinear (and potentially unmodeled), non-autonomous dynamical system is a difficult task. This work explores the design of BFs using data to obtain safe sets with deterministic assurances of control invariance. We leverage ReLU neural networks (NNs) to create continuous piecewise affine (CPA) BFs with deterministic safety guarantees for Lipschitz continuous, discrete-time dynamical system using sampled one-step trajectories. The CPA structure admits a novel classifier term to create a relaxed \ac{bf} condition and construction via a data driven constrained optimization. We use iterative convex overbounding (ICO) to solve this nonconvex optimization problem through a series of convex optimization steps. We then demonstrate our method's efficacy on two-dimensional autonomous and non-autonomous dynamical systems.

</details>


### [122] [Causal Feature Selection for Weather-Driven Residential Load Forecasting](https://arxiv.org/abs/2511.20508)
*Elise Zhang,François Mirallès,Stéphane Dellacherie,Di Wu,Benoit Boulet*

Main category: eess.SY

TL;DR: 研究探讨了因果特征选择在短期负荷预测中如何提高天气变量的简约性和鲁棒性，通过比较不同特征选择方法在三个时间序列模型上的表现。


<details>
  <summary>Details</summary>
Motivation: 天气是住宅电力需求的主要外部驱动因素，但添加过多气象协变量会增加模型复杂性并可能降低准确性。需要一种原则性的特征选择框架来优化预测性能。

Method: 使用安大略省南部的两个开源数据集，比较了无特征选择、非因果选择和PCMCI因果选择三种方法，在GRU、TCN和PatchTST三个时间序列模型上进行城市级预测。

Result: 非因果选择优先考虑辐射和湿度变量，而因果选择强调更直接的热驱动因素并修剪间接协变量。因果特征选择在预测准确性和极端天气鲁棒性方面表现良好。

Conclusion: 因果特征选择可以作为现代预测器的实用补充，在将天气因素整合到住宅负荷预测时提高模型的简约性和鲁棒性。

Abstract: Weather is a dominant external driver of residential electricity demand, but adding many meteorological covariates can inflate model complexity and may even impair accuracy. Selecting appropriate exogenous features is non-trivial and calls for a principled selection framework, given the direct operational implications for day-to-day planning and reliability. This work investigates whether causal feature selection can retain the most informative weather drivers while improving parsimony and robustness for short-term load forecasting. We present a case study on Southern Ontario with two open-source datasets: (i) IESO hourly electricity consumption by Forward Sortation Areas; (ii) ERA5 weather reanalysis data. We compare different feature selection regimes (no feature selection, non-causal selection, PCMCI-causal selection) on city-level forecasting with three different time series forecasting models: GRU, TCN, PatchTST. In the feature analysis, non-causal selection prioritizes radiation and moisture variables that show correlational dependence, whereas PCMCI-causal selection emphasizes more direct thermal drivers and prunes the indirect covariates. We detail the evaluation pipeline and report diagnostics on prediction accuracy and extreme-weather robustness, positioning causal feature selection as a practical complement to modern forecasters when integrating weather into residential load forecasting.

</details>


### [123] [From Features to States: Data-Driven Selection of Measured State Variables via RFE-DMDc](https://arxiv.org/abs/2511.20552)
*Haoyu Wang,Andrea Alfonsi,Roberto Ponciroli,Richard Vilim*

Main category: eess.SY

TL;DR: RFE-DMDc是一种数据驱动的工作流，通过递归特征消除选择最小化物理意义变量集，然后使用带控制的动态模态分解建立线性状态空间模型，在保持竞争性预测精度的同时显著降低计算时间。


<details>
  <summary>Details</summary>
Motivation: 对于许多工程系统，基于第一性原理的模型识别不切实际，需要数据驱动的方法来构建用于控制和诊断的数字孪生。

Method: 使用递归特征消除选择最小化物理意义变量集，然后通过带控制的动态模态分解推导线性状态空间模型，包含跨子系统选择步骤以缓解多组件系统中的特征遮蔽问题。

Result: 在RLC基准测试和集成能源系统上，RFE-DMDc始终恢复紧凑的状态集（约10个变量），测试误差与GA-DMDc相当，但计算时间减少一个数量级。

Conclusion: 所选变量在子系统间保持清晰的物理解释，所得模型展现出竞争性的预测精度、计算效率和抗过拟合鲁棒性。

Abstract: The behavior of a dynamical system under a given set of inputs can be captured by tracking the response of an optimal subset of process variables (\textit{state variables}). For many engineering systems, however, first-principles, model-based identification is impractical, motivating data-driven approaches for Digital Twins used in control and diagnostics. In this paper, we present RFE-DMDc, a supervised, data-driven workflow that uses Recursive Feature Elimination (RFE) to select a minimal, physically meaningful set of variables to monitor and then derives a linear state-space model via Dynamic Mode Decomposition with Control (DMDc). The workflow includes a cross-subsystem selection step that mitigates feature \textit{overshadowing} in multi-component systems. To corroborate the results, we implement a GA-DMDc baseline that jointly optimizes the state set and model fit under a common accuracy cost on states and outputs. Across a truth-known RLC benchmark and a realistic Integrated Energy System (IES) with multiple thermally coupled components and thousands of candidate variables, RFE-DMDc consistently recovers compact state sets (\(\approx 10\) variables) that achieve test errors comparable to GA-DMDc while requiring an order of magnitude less computational time. The selected variables retain clear physical interpretation across subsystems, and the resulting models demonstrate competitive predictive accuracy, computational efficiency, and robustness to overfitting.

</details>


### [124] [Exploring Urban Air Mobility Adoption Potential in San Francisco Bay Area Region: A Systems of Systems Level Case Study on Passenger Waiting Times and Travel Efficiency](https://arxiv.org/abs/2511.20603)
*Winfrey Paul Sagayam Dennis*

Main category: eess.SY

TL;DR: 评估旧金山湾区城市空中交通(UAM)的可行性，通过多智能体仿真比较UAM与传统地面交通的时间效率，发现在高峰时段可减少80%的旅行时间。


<details>
  <summary>Details</summary>
Motivation: 随着电动垂直起降(eVTOL)车辆的发展，城市空中交通有望缓解城市交通拥堵，需要评估其在旧金山湾区的系统级采用潜力。

Method: 在MATLAB中开发多智能体仿真，使用泊松过程模拟随机乘客流和周转约束下的需求到达，评估机队运营。

Result: 在高峰需求时段，UAM可将整个区域的旅行时间减少高达80%。

Conclusion: 机队规模、乘客请求量和周转时间等关键运营因素直接影响等待时间、运营成本和用户接受度，对机队调度优化至关重要。

Abstract: Urban Air mobility has gained momentum with recent advancements in the electric vertical take-off and landing (eVTOL) vehicles, offering faster point-to-point air taxi services that could help relieve traffic congestion in chronically overburdened cities. The research assesses the feasibility and systems-of-systems level adoption potential of UAM operations in the San Francisco Bay Area by comparing passenger departure, waiting, travel, and arrival times across key regional nodes, including San Francisco, Oakland, San Jose, and Palo Alto airports, with conventional ground transportation. A multi-agent simulation was developed in MATLAB to evaluate the fleet operations and to model demand arrival using a Poisson process under stochastic passenger flows and turnaround constraints. Results indicate that utilizing UAM during peak demand could reduce total travel times up to eighty percent across the region. The findings of this paper highlight the critical operational factors for fleet schedule optimization. Especially how the fleet size, passengers' request volumes, and turnaround time directly influence waiting time, operating cost, and overall user acceptance.

</details>
