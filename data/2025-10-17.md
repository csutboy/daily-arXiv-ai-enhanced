<div id=toc></div>

# Table of Contents

- [econ.EM](#econ.EM) [Total: 2]
- [cs.RO](#cs.RO) [Total: 37]
- [cs.ET](#cs.ET) [Total: 1]
- [econ.TH](#econ.TH) [Total: 2]
- [cs.SI](#cs.SI) [Total: 2]
- [cs.AI](#cs.AI) [Total: 53]
- [cs.CY](#cs.CY) [Total: 4]
- [stat.AP](#stat.AP) [Total: 4]
- [eess.SY](#eess.SY) [Total: 13]
- [econ.GN](#econ.GN) [Total: 2]


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [1] [Debiased Kernel Estimation of Spot Volatility in the Presence of Infinite Variation Jumps](https://arxiv.org/abs/2510.14285)
*B. Cooper Boniece,José E. Figueroa-López,Tianwei Zhou*

Main category: econ.EM

TL;DR: 该论文提出了截断核估计器及其去偏变体，用于估计具有无界变化跳跃的Itô半鞅的瞬时波动率，将跳跃活动指数的有效估计范围从Y<4/3扩展到Y<20/11，几乎覆盖了全部允许范围Y<2。


<details>
  <summary>Details</summary>
Motivation: 金融计量经济学中的波动率估计在跳跃活动较高时变得特别困难，这在高度交易的金融证券中经常观察到。现有方法在跳跃活动指数Y较高时表现不佳。

Method: 构建了截断核估计器和去偏变体，使用无界核函数来减小渐近方差，方法更简单易实现，且在更灵活的模型假设下具有更广泛的适用性。

Result: 新方法将有效估计范围扩展到Y<20/11，渐近方差更小，模拟研究证实了在有限样本中显著优于竞争方法。

Conclusion: 提出的估计器扩展了瞬时波动率估计的效率边界，几乎覆盖了全部允许的跳跃活动范围，具有更小的渐近方差、更简单的实现和更广泛的适用性。

Abstract: Volatility estimation is a central problem in financial econometrics, but
becomes particularly challenging when jump activity is high, a phenomenon
observed empirically in highly traded financial securities. In this paper, we
revisit the problem of spot volatility estimation for an It\^o semimartingale
with jumps of unbounded variation. We construct truncated kernel-based
estimators and debiased variants that extend the efficiency frontier for spot
volatility estimation in terms of the jump activity index $Y$, raising the
previous bound $Y<4/3$ to $Y<20/11$, thereby covering nearly the entire
admissible range $Y<2$. Compared with earlier work, our approach attains
smaller asymptotic variances through the use of unbounded kernels, is simpler
to implement, and has broader applicability under more flexible model
assumptions. A comprehensive simulation study confirms that our procedures
substantially outperform competing methods in finite samples.

</details>


### [2] [Dynamic Spatial Treatment Effect Boundaries: A Continuous Functional Framework from Navier-Stokes Equations](https://arxiv.org/abs/2510.14409)
*Tatsuru Kikuchi*

Main category: econ.EM

TL;DR: 开发了一个基于Navier-Stokes偏微分方程的动态空间处理效应边界理论框架，将处理强度定义为时空连续函数，建立了处理效应的标度律，并通过卫星观测数据验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统离散处理效应估计方法无法充分分析传播动态、边界演化和累积暴露模式，需要建立连续函数框架来统一空间计量经济学与数学物理方法。

Method: 基于Navier-Stokes偏微分方程建立连续函数框架，利用Kummer合流超几何函数和修正贝塞尔函数的精确自相似解，推导处理效应的标度律，并通过4200万TROPOMI卫星观测数据和蒙特卡洛模拟进行实证验证。

Result: 实证验证显示NO2污染呈现强指数空间衰减（κs=0.004每公里，R²=0.35），可检测边界达572公里。蒙特卡洛模拟表明在边界检测和假阳性避免方面优于离散参数方法（94% vs 27%正确拒绝）。区域异质性分析验证了诊断能力。

Conclusion: 连续函数视角统一了空间计量经济学与数学物理，为边界检测、暴露量化和政策评估提供了理论基础，适用于环境经济学、银行和医疗等多个领域。

Abstract: I develop a comprehensive theoretical framework for dynamic spatial treatment
effect boundaries using continuous functional definitions grounded in
Navier-Stokes partial differential equations. Rather than discrete treatment
effect estimators, the framework characterizes treatment intensity as a
continuous function $\tau(\mathbf{x}, t)$ over space-time, enabling rigorous
analysis of propagation dynamics, boundary evolution, and cumulative exposure
patterns. Building on exact self-similar solutions expressible through Kummer
confluent hypergeometric and modified Bessel functions, I establish that
treatment effects follow scaling laws $\tau(d, t) = t^{-\alpha} f(d/t^\beta)$
where exponents characterize diffusion mechanisms. Empirical validation using
42 million TROPOMI satellite observations of NO$_2$ pollution from U.S.
coal-fired power plants demonstrates strong exponential spatial decay
($\kappa_s = 0.004$ per km, $R^2 = 0.35$) with detectable boundaries at 572 km.
Monte Carlo simulations confirm superior performance over discrete parametric
methods in boundary detection and false positive avoidance (94\% vs 27\%
correct rejection). Regional heterogeneity analysis validates diagnostic
capability: positive decay parameters within 100 km confirm coal plant
dominance; negative parameters beyond 100 km correctly signal when urban
sources dominate. The continuous functional perspective unifies spatial
econometrics with mathematical physics, providing theoretically grounded
methods for boundary detection, exposure quantification, and policy evaluation
across environmental economics, banking, and healthcare applications.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [3] [A Diffusion-Refined Planner with Reinforcement Learning Priors for Confined-Space Parking](https://arxiv.org/abs/2510.14000)
*Mingyang Jiang,Yueyuan Li,Jiaru Zhang,Songan Zhang,Ming Yang*

Main category: cs.RO

TL;DR: DRIP是一种基于强化学习先验动作分布的扩散精化规划器，通过RL预训练策略提供先验分布来正则化扩散训练，在推理阶段将粗略先验精化为更精确的动作分布，提高受限空间停车规划的成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 随着停车需求的增长，需要能在受限空间中可靠运行的自动化停车规划方法。在复杂受限环境中，高精度操纵对于规划成功至关重要，但现有方法依赖显式动作建模，难以准确建模最优动作分布。

Method: 提出DRIP方法：1) RL预训练策略提供先验动作分布来正则化扩散训练；2) 推理阶段通过去噪过程将粗略先验精化为精确动作分布；3) 训练时通过RL先验分布引导去噪轨迹，获得良好初始化。

Result: 在不同空间约束程度的停车场景中评估，实验结果表明该方法在受限空间停车环境中显著提高了规划性能，同时在常见场景中保持了强泛化能力。

Conclusion: DRIP通过结合RL先验和扩散精化，实现了更准确的动作建模、更高的规划成功率和更少的推理步骤，有效解决了受限空间停车规划问题。

Abstract: The growing demand for parking has increased the need for automated parking
planning methods that can operate reliably in confined spaces. In restricted
and complex environments, high-precision maneuvers are required to achieve a
high success rate in planning, yet existing approaches often rely on explicit
action modeling, which faces challenges when accurately modeling the optimal
action distribution. In this paper, we propose DRIP, a diffusion-refined
planner anchored in reinforcement learning (RL) prior action distribution, in
which an RL-pretrained policy provides prior action distributions to regularize
the diffusion training process. During the inference phase the denoising
process refines these coarse priors into more precise action distributions. By
steering the denoising trajectory through the reinforcement learning prior
distribution during training, the diffusion model inherits a well-informed
initialization, resulting in more accurate action modeling, a higher planning
success rate, and reduced inference steps. We evaluate our approach across
parking scenarios with varying degrees of spatial constraints. Experimental
results demonstrate that our method significantly improves planning performance
in confined-space parking environments while maintaining strong generalization
in common scenarios.

</details>


### [4] [Spatially Intelligent Patrol Routes for Concealed Emitter Localization by Robot Swarms](https://arxiv.org/abs/2510.14018)
*Adam Morris,Timothy Pelham,Edmund R. Hunt*

Main category: cs.RO

TL;DR: 本文提出了一种设计空间智能机器人群体行为的方法，用于定位隐藏的无线电发射器。通过差分进化生成几何巡逻路线，不依赖发射器参数即可定位未知信号。


<details>
  <summary>Details</summary>
Motivation: 解决电磁监视中定位未知信号的关键挑战，传统方法依赖发射器参数，而该方法能够独立于发射器参数进行定位。

Method: 使用差分进化算法生成几何巡逻路线，模拟四机器人群体在八种配置下运行，基于指定巡逻形状和感知能力（全向或定向天线）分配预生成的巡逻路线。

Result: 定向天线的平均检测成功率为98.75%，全向天线为80.25%；定向天线的定位误差为1.01-1.30米，全向天线为1.67-1.90米；定向天线还受益于更短的巡逻边。

Conclusion: 群体预测电磁现象的能力直接依赖于其与环境的物理交互，通过优化的巡逻路线和天线选择实现的空间智能是有效机器人监视的关键设计考虑因素。

Abstract: This paper introduces a method for designing spatially intelligent robot
swarm behaviors to localize concealed radio emitters. We use differential
evolution to generate geometric patrol routes that localize unknown signals
independently of emitter parameters, a key challenge in electromagnetic
surveillance. Patrol shape and antenna type are shown to influence information
gain, which in turn determines the effective triangulation coverage. We
simulate a four-robot swarm across eight configurations, assigning
pre-generated patrol routes based on a specified patrol shape and sensing
capability (antenna type: omnidirectional or directional). An emitter is placed
within the map for each trial, with randomized position, transmission power and
frequency. Results show that omnidirectional localization success rates are
driven primarily by source location rather than signal properties, with
failures occurring most often when sources are placed in peripheral areas of
the map. Directional antennas are able to overcome this limitation due to their
higher gain and directivity, with an average detection success rate of 98.75%
compared to 80.25% for omnidirectional. Average localization errors range from
1.01-1.30 m for directional sensing and 1.67-1.90 m for omnidirectional
sensing; while directional sensing also benefits from shorter patrol edges.
These results demonstrate that a swarm's ability to predict electromagnetic
phenomena is directly dependent on its physical interaction with the
environment. Consequently, spatial intelligence, realized here through
optimized patrol routes and antenna selection, is a critical design
consideration for effective robotic surveillance.

</details>


### [5] [Adaptive Obstacle-Aware Task Assignment and Planning for Heterogeneous Robot Teaming](https://arxiv.org/abs/2510.14063)
*Nan Li,Jiming Ren,Haris Miller,Samuel Coogan,Karen M. Feigh,Ye Zhao*

Main category: cs.RO

TL;DR: 提出OATH框架，通过自适应Halton序列地图和集群-拍卖-选择机制，解决多智能体任务分配中的可扩展性、空间推理和障碍物环境适应性挑战。


<details>
  <summary>Details</summary>
Motivation: 多智能体任务分配与规划在可扩展性、空间推理和障碍物丰富环境适应性方面仍面临挑战，需要新的解决方案。

Method: 开发自适应Halton序列地图（首次在MATP中应用Halton采样），提出集群-拍卖-选择框架，集成障碍感知聚类、加权拍卖和集群内任务选择，并利用LLM解释人类指令实时指导规划器。

Result: 在NVIDIA Isaac Sim中验证，相比最先进的MATP基线，在任务分配质量、可扩展性、动态变化适应性和整体执行性能方面有显著提升。

Conclusion: OATH框架通过创新的障碍感知策略有效协调异构机器人团队，保持可扩展性和接近最优的分配性能。

Abstract: Multi-Agent Task Assignment and Planning (MATP) has attracted growing
attention but remains challenging in terms of scalability, spatial reasoning,
and adaptability in obstacle-rich environments. To address these challenges, we
propose OATH: Adaptive Obstacle-Aware Task Assignment and Planning for
Heterogeneous Robot Teaming, which advances MATP by introducing a novel
obstacle-aware strategy for task assignment. First, we develop an adaptive
Halton sequence map, the first known application of Halton sampling with
obstacle-aware adaptation in MATP, which adjusts sampling density based on
obstacle distribution. Second, we propose a cluster-auction-selection framework
that integrates obstacle-aware clustering with weighted auctions and
intra-cluster task selection. These mechanisms jointly enable effective
coordination among heterogeneous robots while maintaining scalability and
near-optimal allocation performance. In addition, our framework leverages an
LLM to interpret human instructions and directly guide the planner in real
time. We validate OATH in NVIDIA Isaac Sim, showing substantial improvements in
task assignment quality, scalability, adaptability to dynamic changes, and
overall execution performance compared to state-of-the-art MATP baselines. A
project website is available at https://llm-oath.github.io/.

</details>


### [6] [Optimistic Reinforcement Learning-Based Skill Insertions for Task and Motion Planning](https://arxiv.org/abs/2510.14065)
*Gaoyuan Liu,Joris de Winter,Yuri Durodie,Denis Steckelmacher,Ann Nowe,Bram Vanderborght*

Main category: cs.RO

TL;DR: 本文提出了一种将强化学习技能集成到任务和运动规划(TAMP)管道中的方法，通过数据驱动的逻辑组件定义RL技能，并设计计划细化子程序来处理效果不确定性。


<details>
  <summary>Details</summary>
Motivation: TAMP在机器人操作中需要长时域推理，但处理具有不确定性的概率动作仍然具有挑战性。而RL擅长获取鲁棒的短时域操作技能，但缺乏长时域规划能力。

Method: 将RL技能集成到TAMP中，每个RL技能除了策略外还包含数据驱动的逻辑组件，使技能能够被符号规划部署。设计了计划细化子程序来处理效果不确定性。

Result: 实验表明，通过嵌入RL技能，扩展了TAMP在概率技能领域的能力，并相比之前的方法提高了规划效率。

Conclusion: 该方法成功地将RL技能与TAMP相结合，解决了概率动作规划问题，提高了机器人操作任务的规划效率和能力。

Abstract: Task and motion planning (TAMP) for robotics manipulation necessitates
long-horizon reasoning involving versatile actions and skills. While
deterministic actions can be crafted by sampling or optimizing with certain
constraints, planning actions with uncertainty, i.e., probabilistic actions,
remains a challenge for TAMP. On the contrary, Reinforcement Learning (RL)
excels in acquiring versatile, yet short-horizon, manipulation skills that are
robust with uncertainties. In this letter, we design a method that integrates
RL skills into TAMP pipelines. Besides the policy, a RL skill is defined with
data-driven logical components that enable the skill to be deployed by symbolic
planning. A plan refinement sub-routine is designed to further tackle the
inevitable effect uncertainties. In the experiments, we compare our method with
baseline hierarchical planning from both TAMP and RL fields and illustrate the
strength of the method. The results show that by embedding RL skills, we extend
the capability of TAMP to domains with probabilistic skills, and improve the
planning efficiency compared to the previous methods.

</details>


### [7] [Partial Feedback Linearization Control of a Cable-Suspended Multirotor Platform for Stabilization of an Attached Load](https://arxiv.org/abs/2510.14072)
*Hemjyoti Das,Christian Ott*

Main category: cs.RO

TL;DR: 提出了一种基于部分反馈线性化的控制方法，用于稳定带有负载的悬挂空中平台，适用于建筑工地的起重机应用。


<details>
  <summary>Details</summary>
Motivation: 开发适用于建筑工地起重机应用的控制方法，能够处理重物搬运和保持，同时考虑系统欠驱动特性和耦合动力学。

Method: 使用部分反馈线性化控制方法，考虑系统的欠驱动特性，并利用耦合动力学进行稳定，仅依赖机载传感器。

Result: 通过数值稳定性分析证明耦合项对系统稳定至关重要，进行了鲁棒性分析，并通过仿真和实验验证了控制方法的有效性。

Conclusion: 所提出的控制方法能够有效稳定悬挂空中平台，在存在外部风扰动、传感器噪声和系统动力学不确定性的情况下表现出良好的鲁棒性。

Abstract: In this work, we present a novel control approach based on partial feedback
linearization (PFL) for the stabilization of a suspended aerial platform with
an attached load. Such systems are envisioned for various applications in
construction sites involving cranes, such as the holding and transportation of
heavy objects. Our proposed control approach considers the underactuation of
the whole system while utilizing its coupled dynamics for stabilization. We
demonstrate using numerical stability analysis that these coupled terms are
crucial for the stabilization of the complete system. We also carried out
robustness analysis of the proposed approach in the presence of external wind
disturbances, sensor noise, and uncertainties in system dynamics. As our
envisioned target application involves cranes in outdoor construction sites,
our control approaches rely on only onboard sensors, thus making it suitable
for such applications. We carried out extensive simulation studies and
experimental tests to validate our proposed control approach.

</details>


### [8] [ViTacGen: Robotic Pushing with Vision-to-Touch Generation](https://arxiv.org/abs/2510.14117)
*Zhiyuan Wu,Yijiong Lin,Yongqiang Zhao,Xuyang Zhang,Zhuo Chen,Nathan Lepora,Shan Luo*

Main category: cs.RO

TL;DR: ViTacGen是一个机器人操作框架，通过视觉到触觉生成技术实现视觉机器人推动，无需真实高分辨率触觉传感器，在纯视觉机器人系统上实现零样本部署。


<details>
  <summary>Details</summary>
Motivation: 真实触觉传感器存在硬件限制（高成本、易碎）和部署挑战（校准、传感器差异），而纯视觉策略性能不足。受人类从视觉推断触觉状态的能力启发，提出视觉到触觉生成方法。

Method: 包含编码器-解码器视觉到触觉生成网络，从视觉图像序列生成接触深度图像（标准化触觉表示），然后通过强化学习策略融合视觉-触觉数据，基于视觉和生成触觉观测进行对比学习。

Result: 在仿真和真实世界实验中验证了方法的有效性，展示了优越性能，成功率高达86%。

Conclusion: ViTacGen框架成功实现了视觉到触觉的生成，消除了对高分辨率真实触觉传感器的依赖，能够在纯视觉机器人系统上有效部署。

Abstract: Robotic pushing is a fundamental manipulation task that requires tactile
feedback to capture subtle contact forces and dynamics between the end-effector
and the object. However, real tactile sensors often face hardware limitations
such as high costs and fragility, and deployment challenges involving
calibration and variations between different sensors, while vision-only
policies struggle with satisfactory performance. Inspired by humans' ability to
infer tactile states from vision, we propose ViTacGen, a novel robot
manipulation framework designed for visual robotic pushing with vision-to-touch
generation in reinforcement learning to eliminate the reliance on
high-resolution real tactile sensors, enabling effective zero-shot deployment
on visual-only robotic systems. Specifically, ViTacGen consists of an
encoder-decoder vision-to-touch generation network that generates contact depth
images, a standardized tactile representation, directly from visual image
sequence, followed by a reinforcement learning policy that fuses visual-tactile
data with contrastive learning based on visual and generated tactile
observations. We validate the effectiveness of our approach in both simulation
and real world experiments, demonstrating its superior performance and
achieving a success rate of up to 86\%.

</details>


### [9] [Prescribed Performance Control of Deformable Object Manipulation in Spatial Latent Space](https://arxiv.org/abs/2510.14234)
*Ning Han,Gu Gong,Bin Zhang,Yuexuan Xu,Bohan Yang,Yunhui Liu,David Navarro-Alarcon*

Main category: cs.RO

TL;DR: 提出了一种基于关键点约束的无模型方法，用于三维可变形物体的形状控制，通过深度学习提取关键点坐标作为特征向量，结合变形雅可比矩阵和性能约束控制方法实现精确控制。


<details>
  <summary>Details</summary>
Motivation: 三维可变形物体操作面临无限维状态空间和复杂变形动力学的挑战，现有方法依赖特征降维但可能丢失空间信息，需要更有效的方法来简化控制问题。

Method: 使用深度学习从点云中提取关键点坐标作为特征向量，将变形物体操作简化为视觉伺服问题，采用变形雅可比矩阵描述形状动力学，结合障碍李雅普诺夫函数开发性能约束控制方法。

Result: 实验结果表明该方法具有有效性和鲁棒性，能够实现精确的形状控制。

Conclusion: 所提出的无模型方法通过关键点提取和性能约束控制，成功解决了三维可变形物体的形状控制问题，系统稳定性得到严格证明。

Abstract: Manipulating three-dimensional (3D) deformable objects presents significant
challenges for robotic systems due to their infinite-dimensional state space
and complex deformable dynamics. This paper proposes a novel model-free
approach for shape control with constraints imposed on key points. Unlike
existing methods that rely on feature dimensionality reduction, the proposed
controller leverages the coordinates of key points as the feature vector, which
are extracted from the deformable object's point cloud using deep learning
methods. This approach not only reduces the dimensionality of the feature space
but also retains the spatial information of the object. By extracting key
points, the manipulation of deformable objects is simplified into a visual
servoing problem, where the shape dynamics are described using a deformation
Jacobian matrix. To enhance control accuracy, a prescribed performance control
method is developed by integrating barrier Lyapunov functions (BLF) to enforce
constraints on the key points. The stability of the closed-loop system is
rigorously analyzed and verified using the Lyapunov method. Experimental
results further demonstrate the effectiveness and robustness of the proposed
method.

</details>


### [10] [Learning Human-Humanoid Coordination for Collaborative Object Carrying](https://arxiv.org/abs/2510.14293)
*Yushi Du,Yixuan Li,Baoxiong Jia,Yutang Lin,Pei Zhou,Wei Liang,Yanchao Yang,Siyuan Huang*

Main category: cs.RO

TL;DR: 提出了一种仅使用本体感觉的强化学习方法COLA，通过单一策略结合领导者和跟随者行为，实现人形机器人与人类的顺从协作搬运，无需外部传感器或复杂交互模型。


<details>
  <summary>Details</summary>
Motivation: 虽然机械臂的人机协作已广泛发展，但由于人形机器人复杂的全身动力学，实现顺从的人-人形机器人协作仍未被充分探索。

Method: 使用仅本体感觉的强化学习方法COLA，在闭环环境中训练单一策略，结合领导者和跟随者行为，通过协调轨迹规划预测物体运动模式和人类意图。

Result: 模拟实验显示模型减少人类24.7%的努力，同时保持物体稳定性；真实世界实验验证了在不同物体类型和运动模式下的鲁棒协作；23名参与者的人体研究确认相比基线模型平均提升27.4%。

Conclusion: 该方法无需外部传感器或复杂交互模型即可实现顺从的人-人形机器人协作搬运，为实际部署提供了实用解决方案。

Abstract: Human-humanoid collaboration shows significant promise for applications in
healthcare, domestic assistance, and manufacturing. While compliant robot-human
collaboration has been extensively developed for robotic arms, enabling
compliant human-humanoid collaboration remains largely unexplored due to
humanoids' complex whole-body dynamics. In this paper, we propose a
proprioception-only reinforcement learning approach, COLA, that combines leader
and follower behaviors within a single policy. The model is trained in a
closed-loop environment with dynamic object interactions to predict object
motion patterns and human intentions implicitly, enabling compliant
collaboration to maintain load balance through coordinated trajectory planning.
We evaluate our approach through comprehensive simulator and real-world
experiments on collaborative carrying tasks, demonstrating the effectiveness,
generalization, and robustness of our model across various terrains and
objects. Simulation experiments demonstrate that our model reduces human effort
by 24.7%. compared to baseline approaches while maintaining object stability.
Real-world experiments validate robust collaborative carrying across different
object types (boxes, desks, stretchers, etc.) and movement patterns
(straight-line, turning, slope climbing). Human user studies with 23
participants confirm an average improvement of 27.4% compared to baseline
models. Our method enables compliant human-humanoid collaborative carrying
without requiring external sensors or complex interaction models, offering a
practical solution for real-world deployment.

</details>


### [11] [Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning](https://arxiv.org/abs/2510.14300)
*Weijie Shen,Yitian Liu,Yuhao Wu,Zhixuan Liang,Sijia Gu,Dehui Wang,Tian Nian,Lei Xu,Yusen Qin,Jiangmiao Pang,Xinping Guan,Xiaokang Yang,Yao Mu*

Main category: cs.RO

TL;DR: AdaMoE是一种基于混合专家(MoE)架构的视觉-语言-动作模型，通过继承预训练的密集VLA模型权重，并将前馈层替换为稀疏激活的MoE层来扩展动作专家，实现了计算效率与性能的平衡。


<details>
  <summary>Details</summary>
Motivation: 解决VLA模型扩展面临的两个关键挑战：(1)从头训练需要大量计算资源和数据集，而机器人数据稀缺；(2)实时控制需要平衡模型容量与计算效率。

Method: 提出AdaMoE架构，采用解耦技术将专家选择与专家权重分配分离，通过独立的尺度适配器与传统路由器协同工作，实现基于任务相关性的专家选择和独立控制的权重贡献。

Result: 在关键基准测试中持续优于基线模型：LIBERO上提升1.8%，RoboTwin上提升9.3%，真实世界实验中大幅提升21.5%。

Conclusion: 通过协作式专家利用而非赢家通吃的动态，可以在保持计算效率的同时实现更优性能，证明了专业知识无需垄断。

Abstract: Vision-Language-Action (VLA) models are experiencing rapid development and
demonstrating promising capabilities in robotic manipulation tasks. However,
scaling up VLA models presents several critical challenges: (1) Training new
VLA models from scratch demands substantial computational resources and
extensive datasets. Given the current scarcity of robot data, it becomes
particularly valuable to fully leverage well-pretrained VLA model weights
during the scaling process. (2) Real-time control requires carefully balancing
model capacity with computational efficiency. To address these challenges, We
propose AdaMoE, a Mixture-of-Experts (MoE) architecture that inherits
pretrained weights from dense VLA models, and scales up the action expert by
substituting the feedforward layers into sparsely activated MoE layers. AdaMoE
employs a decoupling technique that decouples expert selection from expert
weighting through an independent scale adapter working alongside the
traditional router. This enables experts to be selected based on task relevance
while contributing with independently controlled weights, allowing
collaborative expert utilization rather than winner-takes-all dynamics. Our
approach demonstrates that expertise need not monopolize. Instead, through
collaborative expert utilization, we can achieve superior performance while
maintaining computational efficiency. AdaMoE consistently outperforms the
baseline model across key benchmarks, delivering performance gains of 1.8% on
LIBERO and 9.3% on RoboTwin. Most importantly, a substantial 21.5% improvement
in real-world experiments validates its practical effectiveness for robotic
manipulation tasks.

</details>


### [12] [Risk-Aware Reinforcement Learning with Bandit-Based Adaptation for Quadrupedal Locomotion](https://arxiv.org/abs/2510.14338)
*Yuanhong Zeng,Anushri Dixit*

Main category: cs.RO

TL;DR: 提出一种风险感知的四足机器人强化学习方法，使用CVaR约束策略优化训练风险条件策略族，并通过多臂老虎机框架在线自适应选择最佳策略，在未知环境中实现稳健性能。


<details>
  <summary>Details</summary>
Motivation: 解决四足机器人在未知环境中的稳健运动问题，传统方法在环境变化时性能下降，需要能够自适应调整风险偏好的方法。

Method: 使用CVaR约束策略优化训练风险条件策略族，部署时通过多臂老虎机框架基于观察到的回合回报自适应选择最佳策略，无需特权环境信息。

Result: 在8个未见过的仿真设置和真实机器人测试中，风险感知策略在未知环境中的平均和尾部性能比其他基线方法提高近一倍，老虎机自适应能在2分钟内选择出最佳风险感知策略。

Conclusion: 该方法通过风险条件策略训练和在线自适应选择，显著提升了四足机器人在未知环境中的稳健性和性能表现。

Abstract: In this work, we study risk-aware reinforcement learning for quadrupedal
locomotion. Our approach trains a family of risk-conditioned policies using a
Conditional Value-at-Risk (CVaR) constrained policy optimization technique that
provides improved stability and sample efficiency. At deployment, we adaptively
select the best performing policy from the family of policies using a
multi-armed bandit framework that uses only observed episodic returns, without
any privileged environment information, and adapts to unknown conditions on the
fly. Hence, we train quadrupedal locomotion policies at various levels of
robustness using CVaR and adaptively select the desired level of robustness
online to ensure performance in unknown environments. We evaluate our method in
simulation across eight unseen settings (by changing dynamics, contacts,
sensing noise, and terrain) and on a Unitree Go2 robot in previously unseen
terrains. Our risk-aware policy attains nearly twice the mean and tail
performance in unseen environments compared to other baselines and our
bandit-based adaptation selects the best-performing risk-aware policy in
unknown terrain within two minutes of operation.

</details>


### [13] [SUM-AgriVLN: Spatial Understanding Memory for Agricultural Vision-and-Language Navigation](https://arxiv.org/abs/2510.14357)
*Xiaobei Zhao,Xingqi Lyu,Xiang Li*

Main category: cs.RO

TL;DR: 提出了SUM-AgriVLN方法，通过空间理解记忆模块改进农业视觉语言导航，在A2A基准测试中成功率达到0.54，导航误差为2.93米。


<details>
  <summary>Details</summary>
Motivation: 现有农业机器人导航方法将每个指令视为独立事件，忽略了重复出现的导航指令可以利用过往经验提供空间上下文信息。

Method: 使用空间理解记忆(SUM)模块，通过3D重建和表示来保存空间记忆，为后续导航指令提供空间上下文。

Result: 在A2A基准测试中，成功率达到0.54（从0.47提升），导航误差为2.93米（从2.91米略微增加），达到农业领域最先进性能。

Conclusion: SUM-AgriVLN通过引入空间记忆机制，有效提升了农业视觉语言导航的性能，证明了利用过往经验对重复导航任务的重要性。

Abstract: Agricultural robots are emerging as powerful assistants across a wide range
of agricultural tasks, nevertheless, still heavily rely on manual operation or
fixed rail systems for movement. The AgriVLN method and the A2A benchmark
pioneeringly extend Vision-and-Language Navigation (VLN) to the agricultural
domain, enabling robots to navigate to the target positions following the
natural language instructions. In practical agricultural scenarios, navigation
instructions often repeatedly occur, yet AgriVLN treat each instruction as an
independent episode, overlooking the potential of past experiences to provide
spatial context for subsequent ones. To bridge this gap, we propose the method
of Spatial Understanding Memory for Agricultural Vision-and-Language Navigation
(SUM-AgriVLN), in which the SUM module employs spatial understanding and save
spatial memory through 3D reconstruction and representation. When evaluated on
the A2A benchmark, our SUM-AgriVLN effectively improves Success Rate from 0.47
to 0.54 with slight sacrifice on Navigation Error from 2.91m to 2.93m,
demonstrating the state-of-the-art performance in the agricultural domain.
Code: https://github.com/AlexTraveling/SUM-AgriVLN.

</details>


### [14] [RoboANKLE: Design, Development, and Functional Evaluation of a Robotic Ankle with a Motorized Compliant Unit](https://arxiv.org/abs/2510.14414)
*Baris Baysal,Omid Arfaie,Ramazan Unal*

Main category: cs.RO

TL;DR: 该研究开发了一种名为RoboANKLE的主动式胫骨假肢，采用能量存储和扩展释放机制(ESER)及新型额外能量存储(EES)机制，能够提供完整的推进辅助，实现自然踝关节运动。


<details>
  <summary>Details</summary>
Motivation: 设计主动式胫骨假肢面临维持能量自主性和减轻重量的挑战，本研究旨在模仿人类踝关节，提供广泛的推进辅助以实现自然的扭矩分布。

Method: 通过运动学和动力学分析确定设计参数，建立CAD模型进行动态和结构分析，采用结构分析和拓扑优化实现最小重量设计，最终制造原型进行实验评估。

Result: 原型质量为1.92kg，尺寸261x107x420mm。功能评估显示，RoboANKLE能够以95%的准确度实现自然最大背屈角度，产生的扭矩比自然行走所需高57%，功率生成能力比自然步态周期功率高10%。

Conclusion: RoboANKLE成功实现了自然踝关节运动的仿生设计，在重量、扭矩和功率性能方面均表现出色，验证了所采用机制的有效性。

Abstract: This study presents a powered transtibial prosthesis with complete push-off
assistance, RoboANKLE. The design aims to fulfill specific requirements, such
as a sufficient range of motion (RoM) while providing the necessary torque for
achieving natural ankle motion in daily activities. Addressing the challenges
faced in designing active transtibial prostheses, such as maintaining energetic
autonomy and minimizing weight, is vital for the study. With this aim, we try
to imitate the human ankle by providing extensive push-off assistance to
achieve a natural-like torque profile. Thus, Energy Store and Extended Release
mechanism (ESER) is employed with a novel Extra Energy Storage (EES) mechanism.
Kinematic and kinetic analyses are carried out to determine the design
parameters and assess the design performance. Subsequently, a Computer-Aided
Design (CAD) model is built and used in comprehensive dynamic and structural
analyses. These analyses are used for the design performance evaluation and
determine the forces and torques applied to the prosthesis, which aids in
optimizing the design for minimal weight via structural analysis and topology
optimization. The design of the prototype is then finalized and manufactured
for experimental evaluation to validate the design and functionality. The
prototype is realized with a mass of 1.92 kg and dimensions of 261x107x420 mm.
The Functional evaluations of the RoboANKLE revealed that it is capable of
achieving the natural maximum dorsi-flexion angle with 95% accuracy. Also,
Thanks to the implemented mechanisms, the results show that RoboANKLE can
generate 57% higher than the required torque for natural walking. The result of
the power generation capacity of the RoboANKLE is 10% more than the natural
power during the gait cycle.

</details>


### [15] [Towards Adaptable Humanoid Control via Adaptive Motion Tracking](https://arxiv.org/abs/2510.14454)
*Tao Huang,Huayi Wang,Junli Ren,Kangning Yin,Zirui Wang,Xiao Chen,Feiyu Jia,Wentao Zhang,Junfeng Long,Jingbo Wang,Jiangmiao Pang*

Main category: cs.RO

TL;DR: AdaMimic是一种新颖的运动跟踪算法，能够从单一参考运动实现可适应的人形机器人控制，通过稀疏关键帧和灵活时间扭曲技术，在保持模仿精度的同时提高适应性。


<details>
  <summary>Details</summary>
Motivation: 解决现有运动先验方法适应性好但模仿精度不足，以及运动跟踪方法精度高但需要大量训练数据和测试时目标运动的问题，结合两者的优势。

Method: 首先通过稀疏化单一参考运动创建关键帧并应用轻量编辑生成增强数据集；然后训练策略跟踪稀疏关键帧生成密集中间运动；最后训练适配器调整跟踪速度和细化低级动作，实现灵活的时间扭曲。

Result: 在仿真和真实世界的Unitree G1人形机器人上验证了该方法在多种任务和广泛适应条件下的显著改进。

Conclusion: AdaMimic成功结合了运动先验和运动跟踪方法的优势，实现了从单一参考运动的高精度模仿和强适应性控制。

Abstract: Humanoid robots are envisioned to adapt demonstrated motions to diverse
real-world conditions while accurately preserving motion patterns. Existing
motion prior approaches enable well adaptability with a few motions but often
sacrifice imitation accuracy, whereas motion-tracking methods achieve accurate
imitation yet require many training motions and a test-time target motion to
adapt. To combine their strengths, we introduce AdaMimic, a novel motion
tracking algorithm that enables adaptable humanoid control from a single
reference motion. To reduce data dependence while ensuring adaptability, our
method first creates an augmented dataset by sparsifying the single reference
motion into keyframes and applying light editing with minimal physical
assumptions. A policy is then initialized by tracking these sparse keyframes to
generate dense intermediate motions, and adapters are subsequently trained to
adjust tracking speed and refine low-level actions based on the adjustment,
enabling flexible time warping that further improves imitation accuracy and
adaptability. We validate these significant improvements in our approach in
both simulation and the real-world Unitree G1 humanoid robot in multiple tasks
across a wide range of adaptation conditions. Videos and code are available at
https://taohuang13.github.io/adamimic.github.io/.

</details>


### [16] [Restoring Noisy Demonstration for Imitation Learning With Diffusion Models](https://arxiv.org/abs/2510.14467)
*Shang-Fu Chen,Co Yong,Shao-Hua Sun*

Main category: cs.RO

TL;DR: 提出了一种过滤-恢复框架来处理包含噪声的专家演示数据，通过过滤干净样本并学习条件扩散模型来恢复噪声样本，在多个机器人任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习算法通常假设专家演示是完美的，但实际上专家演示常包含人为错误或传感器/控制系统不准确导致的噪声，需要处理不完美演示数据的方法。

Method: 采用两阶段框架：首先从演示中过滤出干净样本，然后学习条件扩散模型来恢复噪声样本。

Result: 在机器人手臂操作、灵巧操作和运动等任务上的实验表明，该框架在所有任务中都优于现有方法，消融研究验证了各组件有效性。

Conclusion: 该框架对不同类型的噪声和噪声水平具有鲁棒性，证实了其在处理噪声离线演示数据方面的实际适用性。

Abstract: Imitation learning (IL) aims to learn a policy from expert demonstrations and
has been applied to various applications. By learning from the expert policy,
IL methods do not require environmental interactions or reward signals.
However, most existing imitation learning algorithms assume perfect expert
demonstrations, but expert demonstrations often contain imperfections caused by
errors from human experts or sensor/control system inaccuracies. To address the
above problems, this work proposes a filter-and-restore framework to best
leverage expert demonstrations with inherent noise. Our proposed method first
filters clean samples from the demonstrations and then learns conditional
diffusion models to recover the noisy ones. We evaluate our proposed framework
and existing methods in various domains, including robot arm manipulation,
dexterous manipulation, and locomotion. The experiment results show that our
proposed framework consistently outperforms existing methods across all the
tasks. Ablation studies further validate the effectiveness of each component
and demonstrate the framework's robustness to different noise types and levels.
These results confirm the practical applicability of our framework to noisy
offline demonstration data.

</details>


### [17] [Stability Criteria and Motor Performance in Delayed Haptic Dyadic Interactions Mediated by Robots](https://arxiv.org/abs/2510.14511)
*Mingtian Du,Suhas Raghavendra Kulkarni,Simone Kager,Domenico Campolo*

Main category: cs.RO

TL;DR: 提出了机器人介导的人-人交互系统的稳定性分析标准，重点关注网络时延下的触觉通信，通过频域分析和数值模拟确定了时延无关和时延相关的稳定性条件。


<details>
  <summary>Details</summary>
Motivation: 研究机器人介导的人-人交互系统在网络时延下的稳定性问题，为远程协作系统提供设计指导。

Method: 采用频域分析和数值模拟方法，分析控制器和机器人动态参数对系统稳定性的影响。

Result: 建立了时延无关和时延相关的稳定性标准，发现增加刚度会非线性地降低最大可容忍时延，使系统更易失稳。

Conclusion: 提出的稳定性标准可推广到各种机器人介导交互场景，为设计稳定的远程协作系统提供指导，并指出了有效时延补偿策略的前提条件。

Abstract: This paper establishes analytical stability criteria for robot-mediated
human-human (dyadic) interaction systems, focusing on haptic communication
under network-induced time delays. Through frequency-domain analysis supported
by numerical simulations, we identify both delay-independent and
delay-dependent stability criteria. The delay-independent criterion guarantees
stability irrespective of the delay, whereas the delay-dependent criterion is
characterised by a maximum tolerable delay before instability occurs. The
criteria demonstrate dependence on controller and robot dynamic parameters,
where increasing stiffness reduces the maximum tolerable delay in a non-linear
manner, thereby heightening system vulnerability. The proposed criteria can be
generalised to a wide range of robot-mediated interactions and serve as design
guidelines for stable remote dyadic systems. Experiments with robots performing
human-like movements further illustrate the correlation between stability and
motor performance. The findings of this paper suggest the prerequisites for
effective delay-compensation strategies.

</details>


### [18] [QuASH: Using Natural-Language Heuristics to Query Visual-Language Robotic Maps](https://arxiv.org/abs/2510.14546)
*Matti Pekkanen,Francesco Verdoja,Ville Kyrki*

Main category: cs.RO

TL;DR: 提出了一种基于视觉-语言模型嵌入的机器人地图语义查询方法，通过利用查询词的同义词和反义词在嵌入空间中的关系来训练分类器，从而更准确地识别环境中与查询相关的区域。


<details>
  <summary>Details</summary>
Motivation: 虽然视觉-语言模型的嵌入能够提供开放词汇的场景理解，但机器人需要确定环境中哪些部分与用户查询相关仍然是一个关键挑战。

Method: 利用查询词的自然语言同义词和反义词在嵌入空间中的关系，应用启发式方法估计与查询相关的语言空间，并训练分类器将环境划分为匹配和非匹配区域。

Result: 通过广泛的实验评估，在查询地图和标准图像基准时，该方法显著提高了地图和图像的可查询性。

Conclusion: 该查询技术对表示形式和编码器具有无关性，且只需要有限的训练，能够有效提升机器人对环境的语义理解能力。

Abstract: Embeddings from Visual-Language Models are increasingly utilized to represent
semantics in robotic maps, offering an open-vocabulary scene understanding that
surpasses traditional, limited labels. Embeddings enable on-demand querying by
comparing embedded user text prompts to map embeddings via a similarity metric.
The key challenge in performing the task indicated in a query is that the robot
must determine the parts of the environment relevant to the query.
  This paper proposes a solution to this challenge. We leverage
natural-language synonyms and antonyms associated with the query within the
embedding space, applying heuristics to estimate the language space relevant to
the query, and use that to train a classifier to partition the environment into
matches and non-matches. We evaluate our method through extensive experiments,
querying both maps and standard image benchmarks. The results demonstrate
increased queryability of maps and images. Our querying technique is agnostic
to the representation and encoder used, and requires limited training.

</details>


### [19] [A Generalized Placeability Metric for Model-Free Unified Pick-and-Place Reasoning](https://arxiv.org/abs/2510.14584)
*Benno Wingender,Nils Dengler,Rohit Menon,Sicong Pan,Maren Bennewitz*

Main category: cs.RO

TL;DR: 提出了一种从噪声点云直接评估放置姿态的通用可放置性度量方法，无需物体形状先验，实现无模型统一抓取-放置推理


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖强物体先验或平面支撑假设，限制了泛化能力和抓取-放置的统一推理，无法可靠处理未知物体和真实世界感知噪声

Method: 从原始几何中提取物体支撑表面，生成多方向放置候选，采样满足碰撞和稳定性约束的接触点，通过条件化抓取评分实现统一推理

Result: 在未见真实物体和非平面支撑上，该度量在预测稳定性损失方面达到CAD可比精度，比学习型预测器产生更物理合理的放置

Conclusion: 该方法实现了无模型统一抓取-放置推理，在真实噪声环境下对未知物体具有良好泛化能力

Abstract: To reliably pick and place unknown objects under real-world sensing noise
remains a challenging task, as existing methods rely on strong object priors
(e.g., CAD models), or planar-support assumptions, limiting generalization and
unified reasoning between grasping and placing. In this work, we introduce a
generalized placeability metric that evaluates placement poses directly from
noisy point clouds, without any shape priors. The metric jointly scores
stability, graspability, and clearance. From raw geometry, we extract the
support surfaces of the object to generate diverse candidates for
multi-orientation placement and sample contacts that satisfy collision and
stability constraints. By conditioning grasp scores on each candidate
placement, our proposed method enables model-free unified pick-and-place
reasoning and selects grasp-place pairs that lead to stable, collision-free
placements. On unseen real objects and non-planar object supports, our metric
delivers CAD-comparable accuracy in predicting stability loss and generally
produces more physically plausible placements than learning-based predictors.

</details>


### [20] [Architecture Is All You Need: Diversity-Enabled Sweet Spots for Robust Humanoid Locomotion](https://arxiv.org/abs/2510.14947)
*Blake Werner,Lizhi Yang,Aaron D. Ames*

Main category: cs.RO

TL;DR: 分层控制架构(LCA)通过将高频本体感觉稳定器与低频感知策略结合，比端到端设计更稳健，在楼梯和边缘任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中实现稳健的人形机器人运动需要平衡快速低级稳定和慢速感知决策的架构。

Method: 采用分层控制架构：高频本体感觉稳定器与紧凑低频感知策略结合，通过两阶段训练课程（盲稳定器预训练后感知微调）。

Result: 在Unitree G1人形机器人上，该方法在楼梯和边缘任务中成功，而单阶段感知策略失败。

Conclusion: 时间尺度的架构分离，而非网络规模或复杂性，是实现稳健感知条件运动的关键因素。

Abstract: Robust humanoid locomotion in unstructured environments requires
architectures that balance fast low-level stabilization with slower perceptual
decision-making. We show that a simple layered control architecture (LCA), a
proprioceptive stabilizer running at high rate, coupled with a compact low-rate
perceptual policy, enables substantially more robust performance than
monolithic end-to-end designs, even when using minimal perception encoders.
Through a two-stage training curriculum (blind stabilizer pretraining followed
by perceptual fine-tuning), we demonstrate that layered policies consistently
outperform one-stage alternatives in both simulation and hardware. On a Unitree
G1 humanoid, our approach succeeds across stair and ledge tasks where one-stage
perceptual policies fail. These results highlight that architectural separation
of timescales, rather than network scale or complexity, is the key enabler for
robust perception-conditioned locomotion.

</details>


### [21] [Proprioceptive Image: An Image Representation of Proprioceptive Data from Quadruped Robots for Contact Estimation Learning](https://arxiv.org/abs/2510.14612)
*Gabriel Fischer Abati,João Carlos Virgolino Soares,Giulio Turrisi,Victor Barasuol,Claudio Semini*

Main category: cs.RO

TL;DR: 提出将四足机器人本体感知时间序列数据编码为二维图像的方法，利用CNN学习运动相关任务，在接触估计问题上显著提升性能


<details>
  <summary>Details</summary>
Motivation: 传统时间序列处理方法难以捕捉多信号间的相关性和步态依赖模式，需要一种能保留机器人形态结构并利用CNN优势的特征表示方法

Method: 将多路本体感知信号（关节位置、IMU读数、足端速度）按机器人形态结构空间排列编码为二维图像，保持时间动态特性

Result: 在真实和仿真环境中，该方法相比传统序列模型显著提升预测精度和泛化能力，接触状态准确率从87.7%提升至94.5%，窗口大小缩短15倍

Conclusion: 跨模态编码策略在机器人状态学习中具有巨大潜力，图像表示能有效捕捉信号间相关性和步态模式

Abstract: This paper presents a novel approach for representing proprioceptive
time-series data from quadruped robots as structured two-dimensional images,
enabling the use of convolutional neural networks for learning
locomotion-related tasks. The proposed method encodes temporal dynamics from
multiple proprioceptive signals, such as joint positions, IMU readings, and
foot velocities, while preserving the robot's morphological structure in the
spatial arrangement of the image. This transformation captures inter-signal
correlations and gait-dependent patterns, providing a richer feature space than
direct time-series processing. We apply this concept in the problem of contact
estimation, a key capability for stable and adaptive locomotion on diverse
terrains. Experimental evaluations on both real-world datasets and simulated
environments show that our image-based representation consistently enhances
prediction accuracy and generalization over conventional sequence-based models,
underscoring the potential of cross-modal encoding strategies for robotic state
learning. Our method achieves superior performance on the contact dataset,
improving contact state accuracy from 87.7% to 94.5% over the recently proposed
MI-HGNN method, using a 15 times shorter window size.

</details>


### [22] [CBF-RL: Safety Filtering Reinforcement Learning in Training with Control Barrier Functions](https://arxiv.org/abs/2510.14959)
*Lizhi Yang,Blake Werner,Massimiliano de Sa Aaron D. Ames*

Main category: cs.RO

TL;DR: CBF-RL框架通过在训练中强制执行控制屏障函数(CBFs)，将安全性约束内化到强化学习策略中，无需在线安全过滤器即可实现安全部署。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习(RL)往往以牺牲安全性为代价追求性能，而实际部署中的安全违规可能导致灾难性后果。虽然控制屏障函数(CBFs)提供了强制执行动态安全性的原则性方法，但RL策略不了解CBF会导致保守行为。

Method: 提出CBF-RL框架：1)通过CBF项最小化修改名义RL策略以编码安全约束；2)在训练中对策略rollouts进行安全过滤。理论上证明了连续时间安全过滤器可以通过闭式表达式部署在离散时间rollouts上。

Result: CBF-RL使学习策略内化了安全约束，既强制执行更安全的动作，又偏向更安全的奖励。在导航任务和Unitree G1人形机器人上的实验表明，CBF-RL实现了更安全的探索、更快的收敛和鲁棒性能。

Conclusion: CBF-RL框架能够在没有运行时安全过滤器的情况下，在真实世界环境中实现安全部署，使人形机器人能够安全避开障碍物和爬楼梯。

Abstract: Reinforcement learning (RL), while powerful and expressive, can often
prioritize performance at the expense of safety. Yet safety violations can lead
to catastrophic outcomes in real-world deployments. Control Barrier Functions
(CBFs) offer a principled method to enforce dynamic safety -- traditionally
deployed \emph{online} via safety filters. While the result is safe behavior,
the fact that the RL policy does not have knowledge of the CBF can lead to
conservative behaviors. This paper proposes CBF-RL, a framework for generating
safe behaviors with RL by enforcing CBFs \emph{in training}. CBF-RL has two key
attributes: (1) minimally modifying a nominal RL policy to encode safety
constraints via a CBF term, (2) and safety filtering of the policy rollouts in
training. Theoretically, we prove that continuous-time safety filters can be
deployed via closed-form expressions on discrete-time roll-outs. Practically,
we demonstrate that CBF-RL internalizes the safety constraints in the learned
policy -- both enforcing safer actions and biasing towards safer rewards --
enabling safe deployment without the need for an online safety filter. We
validate our framework through ablation studies on navigation tasks and on the
Unitree G1 humanoid robot, where CBF-RL enables safer exploration, faster
convergence, and robust performance under uncertainty, enabling the humanoid
robot to avoid obstacles and climb stairs safely in real-world settings without
a runtime safety filter.

</details>


### [23] [Accelerated Multi-Modal Motion Planning Using Context-Conditioned Diffusion Models](https://arxiv.org/abs/2510.14615)
*Edward Sandra,Lander Vanroye,Dries Dirckx,Ruben Cartuyvels,Jan Swevers,Wilm Decré*

Main category: cs.RO

TL;DR: 提出CAMPD方法，使用扩散模型进行机器人运动规划，能够泛化到未见过的环境，无需重新训练


<details>
  <summary>Details</summary>
Motivation: 传统运动规划方法在高维状态空间和复杂环境中扩展性差，现有扩散模型方法大多针对单一环境训练，缺乏泛化能力

Method: 使用无分类器去噪概率扩散模型，通过注意力机制整合传感器无关的上下文信息，基于U-Net架构

Result: 在7自由度机器人上验证，相比现有方法能够生成高质量多模态轨迹，时间大幅减少

Conclusion: CAMPD方法能够有效适应多样化场景，无需重新训练，在泛化性和效率方面表现优异

Abstract: Classical methods in robot motion planning, such as sampling-based and
optimization-based methods, often struggle with scalability towards
higher-dimensional state spaces and complex environments. Diffusion models,
known for their capability to learn complex, high-dimensional and multi-modal
data distributions, provide a promising alternative when applied to motion
planning problems and have already shown interesting results. However, most of
the current approaches train their model for a single environment, limiting
their generalization to environments not seen during training. The techniques
that do train a model for multiple environments rely on a specific camera to
provide the model with the necessary environmental information and therefore
always require that sensor. To effectively adapt to diverse scenarios without
the need for retraining, this research proposes Context-Aware Motion Planning
Diffusion (CAMPD). CAMPD leverages a classifier-free denoising probabilistic
diffusion model, conditioned on sensor-agnostic contextual information. An
attention mechanism, integrated in the well-known U-Net architecture,
conditions the model on an arbitrary number of contextual parameters. CAMPD is
evaluated on a 7-DoF robot manipulator and benchmarked against state-of-the-art
approaches on real-world tasks, showing its ability to generalize to unseen
environments and generate high-quality, multi-modal trajectories, at a fraction
of the time required by existing methods.

</details>


### [24] [RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks](https://arxiv.org/abs/2510.14968)
*Mingxuan Yan,Yuping Wang,Zechun Liu,Jiachen Li*

Main category: cs.RO

TL;DR: 提出基于检索的演示分解器(RDD)，通过将分解的子任务区间与低级视觉运动策略训练数据的视觉特征对齐，自动将演示分解为子任务，解决了现有方法中启发式子任务与训练数据偏差的问题。


<details>
  <summary>Details</summary>
Motivation: 现有分层VLA框架使用VLM规划器分解复杂任务，但需要人工标注或启发式规则来获取子任务分解，这会导致子任务与视觉运动策略训练数据不匹配，从而降低任务性能。

Method: 提出RDD方法，通过检索和视觉特征对齐，自动将演示分解为与低级视觉运动策略训练数据特征一致子任务，无需人工标注或启发式规则。

Result: 在仿真和真实世界任务中均优于最先进的子任务分解器，在不同设置下表现出鲁棒性。

Conclusion: RDD方法能够有效解决子任务分解与低级策略训练数据不匹配的问题，提升分层VLA框架在长时程任务中的性能。

Abstract: To tackle long-horizon tasks, recent hierarchical vision-language-action
(VLAs) frameworks employ vision-language model (VLM)-based planners to
decompose complex manipulation tasks into simpler sub-tasks that low-level
visuomotor policies can easily handle. Typically, the VLM planner is finetuned
to learn to decompose a target task. This finetuning requires target task
demonstrations segmented into sub-tasks by either human annotation or heuristic
rules. However, the heuristic subtasks can deviate significantly from the
training data of the visuomotor policy, which degrades task performance. To
address these issues, we propose a Retrieval-based Demonstration Decomposer
(RDD) that automatically decomposes demonstrations into sub-tasks by aligning
the visual features of the decomposed sub-task intervals with those from the
training data of the low-level visuomotor policies. Our method outperforms the
state-of-the-art sub-task decomposer on both simulation and real-world tasks,
demonstrating robustness across diverse settings. Code and more results are
available at rdd-neurips.github.io.

</details>


### [25] [GOPLA: Generalizable Object Placement Learning via Synthetic Augmentation of Human Arrangement](https://arxiv.org/abs/2510.14627)
*Yao Zhong,Hanzhi Chen,Simon Schaefer,Anran Zhang,Stefan Leutenegger*

Main category: cs.RO

TL;DR: GOPLA是一个分层框架，通过增强的人类演示学习可泛化的物体放置，结合语义推理和几何可行性，在真实世界机器人放置场景中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决机器人作为智能助手在家庭环境中进行物体放置时的核心挑战，需要同时考虑语义偏好（常识性物体关系）和几何可行性（碰撞避免）。

Method: 使用多模态大语言模型将人类指令和视觉输入转换为结构化计划，空间映射器生成3D可操作性地图，基于扩散的规划器生成放置位姿，并通过可扩展管道扩展人类演示数据。

Result: 在定位精度和物理合理性评估中，比第二名方法提高了30.04个百分点的放置成功率，在广泛的真实世界机器人放置场景中表现出强大的泛化能力。

Conclusion: GOPLA框架通过结合语义推理和几何约束，有效解决了机器人物体放置问题，展示了在真实世界场景中的实用性和泛化性能。

Abstract: Robots are expected to serve as intelligent assistants, helping humans with
everyday household organization. A central challenge in this setting is the
task of object placement, which requires reasoning about both semantic
preferences (e.g., common-sense object relations) and geometric feasibility
(e.g., collision avoidance). We present GOPLA, a hierarchical framework that
learns generalizable object placement from augmented human demonstrations. A
multi-modal large language model translates human instructions and visual
inputs into structured plans that specify pairwise object relationships. These
plans are then converted into 3D affordance maps with geometric common sense by
a spatial mapper, while a diffusion-based planner generates placement poses
guided by test-time costs, considering multi-plan distributions and collision
avoidance. To overcome data scarcity, we introduce a scalable pipeline that
expands human placement demonstrations into diverse synthetic training data.
Extensive experiments show that our approach improves placement success rates
by 30.04 percentage points over the runner-up, evaluated on positioning
accuracy and physical plausibility, demonstrating strong generalization across
a wide range of real-world robotic placement scenarios.

</details>


### [26] [Generative Models From and For Sampling-Based MPC: A Bootstrapped Approach For Adaptive Contact-Rich Manipulation](https://arxiv.org/abs/2510.14643)
*Lara Brudermüller,Brandon Hung,Xinghao Zhu,Jiuguang Wang,Nick Hawes,Preston Culbertson,Simon Le Cleac'h*

Main category: cs.RO

TL;DR: 提出了一种生成预测控制框架，通过使用在仿真中收集的采样预测控制序列训练条件流匹配模型，来摊销采样预测控制的成本。


<details>
  <summary>Details</summary>
Motivation: 现有的方法依赖迭代优化或基于梯度的求解器，而本文旨在直接从噪声采样预测控制数据中学习有意义的提议分布，以实现更高效和智能的在线规划采样。

Method: 使用在仿真中收集的采样预测控制控制序列训练条件流匹配模型，以摊销采样预测控制的成本。该方法不依赖迭代优化或基于梯度的求解器，而是直接从噪声数据中学习提议分布。

Result: 在仿真和硬件上的广泛实验表明，该方法提高了采样效率，减少了规划视野要求，并在任务变化中表现出鲁棒的泛化能力。首次将该方法应用于真实世界的接触丰富的四足机器人运动操作任务。

Conclusion: 生成预测控制框架通过摊销采样预测控制的成本，实现了更高效和智能的在线规划，并在真实世界的复杂任务中展示了鲁棒的泛化能力。

Abstract: We present a generative predictive control (GPC) framework that amortizes
sampling-based Model Predictive Control (SPC) by bootstrapping it with
conditional flow-matching models trained on SPC control sequences collected in
simulation. Unlike prior work relying on iterative refinement or gradient-based
solvers, we show that meaningful proposal distributions can be learned directly
from noisy SPC data, enabling more efficient and informed sampling during
online planning. We further demonstrate, for the first time, the application of
this approach to real-world contact-rich loco-manipulation with a quadruped
robot. Extensive experiments in simulation and on hardware show that our method
improves sample efficiency, reduces planning horizon requirements, and
generalizes robustly across task variations.

</details>


### [27] [Spatially anchored Tactile Awareness for Robust Dexterous Manipulation](https://arxiv.org/abs/2510.14647)
*Jialei Huang,Yang Ye,Yuanqing Gong,Xuezhou Zhu,Yang Gao,Kaifeng Zhang*

Main category: cs.RO

TL;DR: 提出SaTA框架，通过将触觉特征锚定到手的运动学框架中，实现亚毫米级的灵巧操作精度，显著优于现有视觉触觉学习方法。


<details>
  <summary>Details</summary>
Motivation: 现有视觉触觉学习方法在亚毫米级精度任务上表现不佳，无法有效利用触觉信号的感知丰富性和空间关系。

Method: SaTA框架通过前向运动学将触觉特征显式锚定到手的运动学框架中，实现精确的几何推理，无需物体模型或显式姿态估计。

Result: 在USB-C插接、灯泡安装和卡片滑动等挑战性任务中，SaTA比基线方法成功率提高30%，任务完成时间减少27%。

Conclusion: 空间锚定的触觉表示能够有效提升灵巧操作的精度，为学习型方法在精密操作任务中提供了新思路。

Abstract: Dexterous manipulation requires precise geometric reasoning, yet existing
visuo-tactile learning methods struggle with sub-millimeter precision tasks
that are routine for traditional model-based approaches. We identify a key
limitation: while tactile sensors provide rich contact information, current
learning frameworks fail to effectively leverage both the perceptual richness
of tactile signals and their spatial relationship with hand kinematics. We
believe an ideal tactile representation should explicitly ground contact
measurements in a stable reference frame while preserving detailed sensory
information, enabling policies to not only detect contact occurrence but also
precisely infer object geometry in the hand's coordinate system. We introduce
SaTA (Spatially-anchored Tactile Awareness for dexterous manipulation), an
end-to-end policy framework that explicitly anchors tactile features to the
hand's kinematic frame through forward kinematics, enabling accurate geometric
reasoning without requiring object models or explicit pose estimation. Our key
insight is that spatially grounded tactile representations allow policies to
not only detect contact occurrence but also precisely infer object geometry in
the hand's coordinate system. We validate SaTA on challenging dexterous
manipulation tasks, including bimanual USB-C mating in free space, a task
demanding sub-millimeter alignment precision, as well as light bulb
installation requiring precise thread engagement and rotational control, and
card sliding that demands delicate force modulation and angular precision.
These tasks represent significant challenges for learning-based methods due to
their stringent precision requirements. Across multiple benchmarks, SaTA
significantly outperforms strong visuo-tactile baselines, improving success
rates by up to 30 percentage while reducing task completion times by 27
percentage.

</details>


### [28] [When Planners Meet Reality: How Learned, Reactive Traffic Agents Shift nuPlan Benchmarks](https://arxiv.org/abs/2510.14677)
*Steffen Hagedorn,Luka Donkov,Aron Distelzweig,Alexandru P. Condurache*

Main category: cs.RO

TL;DR: 该论文将先进的智能交通代理模型SMART集成到nuPlan中，首次在更真实条件下评估规划器，发现基于IDM的仿真高估了规划性能，而SMART反应式仿真应成为新的标准闭环基准。


<details>
  <summary>Details</summary>
Motivation: 解决传统基于规则的交通代理（如IDM）行为简单被动的问题，这些代理无法对相邻车道车辆做出反应，从而掩盖规划器缺陷并产生评估偏差。

Method: 将最先进的学习型交通代理模型SMART集成到nuPlan仿真平台中，在更真实的交互条件下评估14个近期规划器和基准方法。

Result: IDM仿真高估规划性能：几乎所有评分都下降。许多规划器在交互能力方面表现优于预期，在多车道、交互密集场景中甚至有所提升。闭环训练方法表现最佳且最稳定。

Conclusion: 建议将SMART反应式仿真作为nuPlan中新的标准闭环基准，所有学习型规划器在边缘案例场景中都会突然退化，而基于规则的规划器能保持合理的基本行为。

Abstract: Planner evaluation in closed-loop simulation often uses rule-based traffic
agents, whose simplistic and passive behavior can hide planner deficiencies and
bias rankings. Widely used IDM agents simply follow a lead vehicle and cannot
react to vehicles in adjacent lanes, hindering tests of complex interaction
capabilities. We address this issue by integrating the state-of-the-art learned
traffic agent model SMART into nuPlan. Thus, we are the first to evaluate
planners under more realistic conditions and quantify how conclusions shift
when narrowing the sim-to-real gap. Our analysis covers 14 recent planners and
established baselines and shows that IDM-based simulation overestimates
planning performance: nearly all scores deteriorate. In contrast, many planners
interact better than previously assumed and even improve in multi-lane,
interaction-heavy scenarios like lane changes or turns. Methods trained in
closed-loop demonstrate the best and most stable driving performance. However,
when reaching their limits in augmented edge-case scenarios, all learned
planners degrade abruptly, whereas rule-based planners maintain reasonable
basic behavior. Based on our results, we suggest SMART-reactive simulation as a
new standard closed-loop benchmark in nuPlan and release the SMART agents as a
drop-in alternative to IDM at https://github.com/shgd95/InteractiveClosedLoop.

</details>


### [29] [Leveraging Neural Descriptor Fields for Learning Contact-Aware Dynamic Recovery](https://arxiv.org/abs/2510.14768)
*Fan Yang,Zixuan Huang,Abhinav Kumar,Sergio Aguilera Marinovic,Soshi Iba,Rana Soltani Zarrin,Dmitry Berenson*

Main category: cs.RO

TL;DR: 提出CADRE强化学习框架，通过神经描述场提取接触特征来提升灵巧手抓取恢复能力，能够零样本泛化到未见过的物体几何形状。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的灵巧操作经常遇到意外错误和干扰，可能导致灾难性失败（如掉落物体）。需要解决在抓取范围内接住下落物体并重置系统以恢复主要操作任务的问题。

Method: 提出Contact-Aware Dynamic Recovery (CADRE)强化学习框架，整合神经描述场(NDF)模块提取隐式接触特征，直接推理手指-物体对应关系并适应不同物体几何形状。

Result: 实验表明，整合接触特征提高了训练效率，增强了强化学习训练的收敛性能，最终带来更成功的恢复。CADRE能够零样本泛化到未见过的物体几何形状。

Conclusion: CADRE框架通过神经描述场提取接触特征，有效提升了灵巧手在动态恢复任务中的性能，并展示了良好的泛化能力。

Abstract: Real-world dexterous manipulation often encounters unexpected errors and
disturbances, which can lead to catastrophic failures, such as dropping the
manipulated object. To address this challenge, we focus on the problem of
catching a falling object while it remains within grasping range and,
importantly, resetting the system to a configuration favorable for resuming the
primary manipulation task. We propose Contact-Aware Dynamic Recovery (CADRE), a
reinforcement learning framework that incorporates a Neural Descriptor Field
(NDF)-inspired module to extract implicit contact features. Compared to methods
that rely solely on object pose or point cloud input, NDFs can directly reason
about finger-object correspondence and adapt to different object geometries.
Our experiments show that incorporating contact features improves training
efficiency, enhances convergence performance for RL training, and ultimately
leads to more successful recoveries. Additionally, we demonstrate that CADRE
can generalize zero-shot to unseen objects with different geometries.

</details>


### [30] [Open TeleDex: A Hardware-Agnostic Teleoperation System for Imitation Learning based Dexterous Manipulation](https://arxiv.org/abs/2510.14771)
*Xu Chi,Chao Zhang,Yang Su,Lingfeng Dou,Fujia Yang,Jiakuo Zhao,Haoyu Zhou,Xiaoyou Jia,Yong Zhou,Shan An*

Main category: cs.RO

TL;DR: 开发了Open TeleDex统一遥操作框架，解决机器人模仿学习中高质量演示数据获取的瓶颈问题，支持任何机械臂、灵巧手和输入设备。


<details>
  <summary>Details</summary>
Motivation: 异构机器人平台的高精度演示数据获取是机器人模仿学习系统部署的关键瓶颈，现有遥操作系统难以保证跨不同遥操作设备的高精度数据收集。

Method: 开发Open TeleDex统一遥操作框架，提出新颖的手部姿态重定向算法，提升系统互操作性，支持任何机械臂、灵巧手和外部输入设备。

Result: Open TeleDex实现了对异构主从设备的鲁棒和准确兼容，为复杂机器人操作和模仿学习提供了高质量公开平台。

Conclusion: Open TeleDex为加速学术研究和工业发展建立了基础性、高质量、公开可用的平台。

Abstract: Accurate and high-fidelity demonstration data acquisition is a critical
bottleneck for deploying robot Imitation Learning (IL) systems, particularly
when dealing with heterogeneous robotic platforms. Existing teleoperation
systems often fail to guarantee high-precision data collection across diverse
types of teleoperation devices. To address this, we developed Open TeleDex, a
unified teleoperation framework engineered for demonstration data collection.
Open TeleDex specifically tackles the TripleAny challenge, seamlessly
supporting any robotic arm, any dexterous hand, and any external input device.
Furthermore, we propose a novel hand pose retargeting algorithm that
significantly boosts the interoperability of Open TeleDex, enabling robust and
accurate compatibility with an even wider spectrum of heterogeneous master and
slave equipment. Open TeleDex establishes a foundational, high-quality, and
publicly available platform for accelerating both academic research and
industry development in complex robotic manipulation and IL.

</details>


### [31] [SkyDreamer: Interpretable End-to-End Vision-Based Drone Racing with Model-Based Reinforcement Learning](https://arxiv.org/abs/2510.14783)
*Aderik Verraest,Stavrow Bahnam,Robin Ferede,Guido de Croon,Christophe De Wagter*

Main category: cs.RO

TL;DR: SkyDreamer是首个端到端基于视觉的自主无人机竞速策略，直接从像素级表示映射到电机指令，实现了完整的模拟到现实迁移、机载执行和冠军级性能。


<details>
  <summary>Details</summary>
Motivation: 现有自主无人机竞速系统高度专业化，缺乏通用性。端到端视觉方法虽具潜力，但尚无系统能同时实现完整模拟到现实迁移、机载执行和冠军级性能。

Method: 基于informed Dreamer模型强化学习方法，世界模型解码训练期间可用的特权信息，作为隐式状态和参数估计器。系统完全机载运行，无需外部辅助，通过世界模型隐藏状态解码的状态跟踪进度，无需外部相机标定。

Result: 在真实环境中实现鲁棒高速飞行，执行倒飞循环、分S和梯子等复杂机动，速度达21m/s，加速度达6g。在低质量分割掩码上展示非平凡视觉模拟到现实迁移，并能实时估计电机最大RPM并调整飞行路径以应对电池损耗。

Conclusion: SkyDreamer能够适应现实差距的重要方面，在实现极高速敏捷飞行的同时保持鲁棒性，展示了端到端视觉自主无人机竞速的可行性。

Abstract: Autonomous drone racing (ADR) systems have recently achieved champion-level
performance, yet remain highly specific to drone racing. While end-to-end
vision-based methods promise broader applicability, no system to date
simultaneously achieves full sim-to-real transfer, onboard execution, and
champion-level performance. In this work, we present SkyDreamer, to the best of
our knowledge, the first end-to-end vision-based ADR policy that maps directly
from pixel-level representations to motor commands. SkyDreamer builds on
informed Dreamer, a model-based reinforcement learning approach where the world
model decodes to privileged information only available during training. By
extending this concept to end-to-end vision-based ADR, the world model
effectively functions as an implicit state and parameter estimator, greatly
improving interpretability. SkyDreamer runs fully onboard without external aid,
resolves visual ambiguities by tracking progress using the state decoded from
the world model's hidden state, and requires no extrinsic camera calibration,
enabling rapid deployment across different drones without retraining.
Real-world experiments show that SkyDreamer achieves robust, high-speed flight,
executing tight maneuvers such as an inverted loop, a split-S and a ladder,
reaching speeds of up to 21 m/s and accelerations of up to 6 g. It further
demonstrates a non-trivial visual sim-to-real transfer by operating on
poor-quality segmentation masks, and exhibits robustness to battery depletion
by accurately estimating the maximum attainable motor RPM and adjusting its
flight path in real-time. These results highlight SkyDreamer's adaptability to
important aspects of the reality gap, bringing robustness while still achieving
extremely high-speed, agile flight.

</details>


### [32] [Neural Implicit Flow Fields for Spatio-Temporal Motion Mapping](https://arxiv.org/abs/2510.14827)
*Yufei Zhu,Shih-Min Yang,Andrey Rudenko,Tomasz P. Kucner,Achim J. Lilienthal,Martin Magnusson*

Main category: cs.RO

TL;DR: 提出了一种基于隐式神经函数的连续时空动态地图表示方法，用于建模复杂环境中的人类运动模式，相比现有离散方法具有更好的准确性和平滑性。


<details>
  <summary>Details</summary>
Motivation: 在复杂人类环境中实现安全高效的机器人操作需要良好的特定场景运动模式模型。现有动态地图使用离散空间采样，通常需要昂贵的离线构建过程。

Method: 使用隐式神经函数构建连续时空动态地图表示，直接将坐标映射到半包裹高斯混合模型的参数，无需离散化和稀疏区域插值处理。

Result: 在大型公共数据集上评估，相比现有基线方法，该方法在运动表示准确性、稀疏区域速度分布平滑性方面表现更好，同时保持计算效率。

Conclusion: 该方法为建模复杂人类运动模式提供了一种强大而高效的途径，实现了跨时空的平滑泛化。

Abstract: Safe and efficient robot operation in complex human environments can benefit
from good models of site-specific motion patterns. Maps of Dynamics (MoDs)
provide such models by encoding statistical motion patterns in a map, but
existing representations use discrete spatial sampling and typically require
costly offline construction. We propose a continuous spatio-temporal MoD
representation based on implicit neural functions that directly map coordinates
to the parameters of a Semi-Wrapped Gaussian Mixture Model. This removes the
need for discretization and imputation for unevenly sampled regions, enabling
smooth generalization across both space and time. Evaluated on a large public
dataset with long-term real-world people tracking data, our method achieves
better accuracy of motion representation and smoother velocity distributions in
sparse regions while still being computationally efficient, compared to
available baselines. The proposed approach demonstrates a powerful and
efficient way of modeling complex human motion patterns.

</details>


### [33] [RL-100: Performant Robotic Manipulation with Real-World Reinforcement Learning](https://arxiv.org/abs/2510.14830)
*Kun Lei,Huanyu Li,Dongjie Yu,Zhenyu Wei,Lingxiao Guo,Zhennan Jiang,Ziyu Wang,Shiyu Liang,Huazhe Xu*

Main category: cs.RO

TL;DR: RL-100是一个基于扩散视觉运动策略的强化学习框架，通过三阶段训练流程实现机器人操作的100%成功率，支持多种输入和机器人平台。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的机器人操作需要接近或超过熟练人类操作员的可靠性、效率和鲁棒性。

Method: 三阶段训练流程：1) 模仿学习利用人类先验；2) 迭代离线强化学习使用离线策略评估来约束PPO风格更新；3) 在线强化学习消除剩余失败模式。还包含轻量级一致性蒸馏头用于低延迟控制。

Result: 在7个真实机器人任务中实现了100%成功率（900/900次试验），包括单个任务连续250次成功。达到接近或优于人类遥操作的时间效率，并能持续运行长达2小时。

Conclusion: RL-100框架在多种机器人操作任务中实现了前所未有的可靠性和鲁棒性，为现实世界机器人应用提供了可行的解决方案。

Abstract: Real-world robotic manipulation in homes and factories demands reliability,
efficiency, and robustness that approach or surpass skilled human operators. We
present RL-100, a real-world reinforcement learning training framework built on
diffusion visuomotor policies trained bu supervised learning. RL-100 introduces
a three-stage pipeline. First, imitation learning leverages human priors.
Second, iterative offline reinforcement learning uses an Offline Policy
Evaluation procedure, abbreviated OPE, to gate PPO-style updates that are
applied in the denoising process for conservative and reliable improvement.
Third, online reinforcement learning eliminates residual failure modes. An
additional lightweight consistency distillation head compresses the multi-step
sampling process in diffusion into a single-step policy, enabling
high-frequency control with an order-of-magnitude reduction in latency while
preserving task performance. The framework is task-, embodiment-, and
representation-agnostic and supports both 3D point clouds and 2D RGB inputs, a
variety of robot platforms, and both single-step and action-chunk policies. We
evaluate RL-100 on seven real-robot tasks spanning dynamic rigid-body control,
such as Push-T and Agile Bowling, fluids and granular pouring, deformable cloth
folding, precise dexterous unscrewing, and multi-stage orange juicing. RL-100
attains 100\% success across evaluated trials for a total of 900 out of 900
episodes, including up to 250 out of 250 consecutive trials on one task. The
method achieves near-human teleoperation or better time efficiency and
demonstrates multi-hour robustness with uninterrupted operation lasting up to
two hours.

</details>


### [34] [Multi Agent Switching Mode Controller for Sound Source localization](https://arxiv.org/abs/2510.14849)
*Marcello Sorge,Nicola Cigarini,Riccardo Lorigiola,Giulia Michieletto,Andrea Masiero,Angelo Cenedese,Alberto Guarnieri*

Main category: cs.RO

TL;DR: 本文提出了一种基于声学的多智能体切换模式控制策略，用于目标定位，包括单源定位和多源定位两种场景。


<details>
  <summary>Details</summary>
Motivation: 声学传感器允许智能体在无法建立直接视线的情况下定位目标，这在机器人研究中具有重要意义。

Method: 设计了多智能体切换模式控制策略，在单源定位中智能体保持刚性编队向目标移动，在多源场景中每个智能体独立搜索目标。

Result: 提出了适用于不同场景的控制策略框架。

Conclusion: 该研究为声学目标定位提供了有效的多智能体控制方法，能够适应单源和多源的不同需求。

Abstract: Source seeking is an important topic in robotic research, especially
considering sound-based sensors since they allow the agents to locate a target
even in critical conditions where it is not possible to establish a direct line
of sight. In this work, we design a multi- agent switching mode control
strategy for acoustic-based target localization. Two scenarios are considered:
single source localization, in which the agents are driven maintaining a rigid
formation towards the target, and multi-source scenario, in which each agent
searches for the targets independently from the others.

</details>


### [35] [SADCHER: Scheduling using Attention-based Dynamic Coalitions of Heterogeneous Robots in Real-Time](https://arxiv.org/abs/2510.14851)
*Jakob Bichler,Andreu Matoses Gimenez,Javier Alonso-Mora*

Main category: cs.RO

TL;DR: Sadcher是一个用于异构多机器人团队的实时任务分配框架，结合了动态联盟形成和任务优先级约束，通过模仿学习训练，使用图注意力和变换器预测机器人-任务分配奖励，能够扩展到更大规模的任务集和团队规模。


<details>
  <summary>Details</summary>
Motivation: 解决异构多机器人团队在动态环境中进行实时任务分配的挑战，需要考虑任务优先级约束、时空分布变化以及扩展到更大规模的问题。

Method: 通过模仿学习训练，结合图注意力和变换器预测机器人与任务之间的分配奖励，使用松弛二分匹配生成高质量调度方案，显式建模机器人和任务位置、任务持续时间及机器人剩余处理时间。

Result: 在随机未见问题上优于其他基于学习和启发式的基线方法，计算时间适合实时操作，能够扩展到更大的任务集和团队规模。

Conclusion: Sadcher框架在异构多机器人任务分配中表现出色，具有实时性、可扩展性和良好的泛化能力，并发布了包含25万个最优调度的数据集。

Abstract: We present Sadcher, a real-time task assignment framework for heterogeneous
multi-robot teams that incorporates dynamic coalition formation and task
precedence constraints. Sadcher is trained through Imitation Learning and
combines graph attention and transformers to predict assignment rewards between
robots and tasks. Based on the predicted rewards, a relaxed bipartite matching
step generates high-quality schedules with feasibility guarantees. We
explicitly model robot and task positions, task durations, and robots'
remaining processing times, enabling advanced temporal and spatial reasoning
and generalization to environments with different spatiotemporal distributions
compared to training. Trained on optimally solved small-scale instances, our
method can scale to larger task sets and team sizes. Sadcher outperforms other
learning-based and heuristic baselines on randomized, unseen problems for small
and medium-sized teams with computation times suitable for real-time operation.
We also explore sampling-based variants and evaluate scalability across robot
and task counts. In addition, we release our dataset of 250,000 optimal
schedules: https://autonomousrobots.nl/paper_websites/sadcher_MRTA/

</details>


### [36] [STITCHER: Constrained Trajectory Planning in Known Environments with Real-Time Motion Primitive Search](https://arxiv.org/abs/2510.14893)
*Helene J. Levy,Brett T. Lopez*

Main category: cs.RO

TL;DR: STITCHER是一种无优化的规划框架，通过将短轨迹段拼接与图搜索结合，实时生成长距离、表达性强且接近最优的轨迹，解决了优化规划器在安全关键场景中的计算时间和数值稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 解决高速自主导航中实时生成动态可行、无碰撞且满足约束的敏捷轨迹问题，克服优化规划器在计算时间和数值稳定性方面的限制。

Method: 采用无优化规划框架，通过拼接短轨迹段与图搜索相结合的方式，创新性地实现了实时规划架构和算法改进。

Result: 在模拟测试中，能够在几毫秒内为跨越两个50m×50m环境的路径生成安全轨迹；硬件测试验证了STITCHER能够实时产生可跟踪路径，并处理非凸约束。

Conclusion: STITCHER框架在实时性、轨迹质量和约束处理方面优于现代优化规划器，适用于安全关键的高速自主导航场景。

Abstract: Autonomous high-speed navigation through large, complex environments requires
real-time generation of agile trajectories that are dynamically feasible,
collision-free, and satisfy state or actuator constraints. Modern trajectory
planning techniques primarily use numerical optimization, as they enable the
systematic computation of high-quality, expressive trajectories that satisfy
various constraints. However, stringent requirements on computation time and
the risk of numerical instability can limit the use of optimization-based
planners in safety-critical scenarios. This work presents an optimization-free
planning framework called STITCHER that stitches short trajectory segments
together with graph search to compute long-range, expressive, and near-optimal
trajectories in real-time. STITCHER outperforms modern optimization-based
planners through our innovative planning architecture and several algorithmic
developments that make real-time planning possible. Extensive simulation
testing is performed to analyze the algorithmic components that make up
STITCHER, along with a thorough comparison with two state-of-the-art
optimization planners. Simulation tests show that safe trajectories can be
created within a few milliseconds for paths that span the entirety of two 50 m
x 50 m environments. Hardware tests with a custom quadrotor verify that
STITCHER can produce trackable paths in real-time while respecting nonconvex
constraints, such as limits on tilt angle and motor forces, which are otherwise
hard to include in optimization-based planners.

</details>


### [37] [VLA^2: Empowering Vision-Language-Action Models with an Agentic Framework for Unseen Concept Manipulation](https://arxiv.org/abs/2510.14902)
*Han Zhao,Jiaxuan Zhang,Wenxuan Song,Pengxiang Ding,Donglin Wang*

Main category: cs.RO

TL;DR: 提出了VLA^2框架，通过集成外部模块（网络检索和物体检测）来增强VLA模型处理分布外对象的能力，在困难级别泛化基准上比基线模型提升了44.2%的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在处理训练数据中未见过的对象概念（如新物体描述和纹理）时成功率显著下降，需要解决这种泛化失败问题。

Method: 以OpenVLA为执行骨干，结合外部模块（网络检索和物体检测）为目标对象提供视觉和文本知识，构建了基于LIBERO环境的三级难度评估基准。

Result: 在设计的困难级别泛化基准上优于当前最先进模型，相比OpenVLA基线在困难级别提升44.2%成功率，所有定制环境平均提升20.2%，且在域内任务上无性能下降。

Conclusion: VLA^2框架有效缓解了VLA模型处理分布外对象的泛化失败问题，显著提升了模型在未见对象场景下的性能。

Abstract: Current vision-language-action (VLA) models, pre-trained on large-scale
robotic data, exhibit strong multi-task capabilities and generalize well to
variations in visual and language instructions for manipulation. However, their
success rate drops significantly when faced with object concepts outside the
training data, such as unseen object descriptions and textures in the dataset.
To address this, we propose a novel agentic framework, VLA^2, which leverages
OpenVLA as the execution backbone and effectively leverages external modules
such as web retrieval and object detection to provide visual and textual
knowledge about target objects to the VLA. This approach mitigates
generalization failure when handling out-of-distribution objects. Based on the
LIBERO simulation environment, we introduced novel objects and object
descriptions to construct a new evaluation benchmark with three difficulty
levels to test the effectiveness of our method. Our framework successfully
outperformed the current state-of-the-art models on our designed hard-level
generalization benchmark. Compared to the standalone OpenVLA baseline, VLA^2
achieves a 44.2% improvement in the success rate in the hard-level benchmark
and an average improvement of 20.2% in all customized environments without any
performance degradation on in-domain tasks. Project website:
https://vla-2.github.io.

</details>


### [38] [VT-Refine: Learning Bimanual Assembly with Visuo-Tactile Feedback via Simulation Fine-Tunin](https://arxiv.org/abs/2510.14930)
*Binghao Huang,Jie Xu,Iretiayo Akinola,Wei Yang,Balakumar Sundaralingam,Rowland O'Flaherty,Dieter Fox,Xiaolong Wang,Arsalan Mousavian,Yu-Wei Chao,Yunzhu Li*

Main category: cs.RO

TL;DR: VT-Refine是一个视觉-触觉策略学习框架，结合真实演示、高保真触觉模拟和强化学习来解决精确的双手机器人装配任务。


<details>
  <summary>Details</summary>
Motivation: 人类能够通过丰富的触觉反馈适应双手机器人装配任务，但仅通过行为克隆难以在机器人中复制这种能力，因为人类演示存在次优性和多样性有限的问题。

Method: 首先在少量演示数据上使用同步视觉和触觉输入训练扩散策略，然后将该策略转移到配备模拟触觉传感器的数字孪生系统中，通过大规模强化学习进行细化以增强鲁棒性和泛化能力。

Result: 实验结果表明，VT-Refine通过增加数据多样性和实现更有效的策略微调，提高了模拟和真实世界中的装配性能。

Conclusion: 该框架成功展示了如何结合真实演示、触觉模拟和强化学习来提升双手机器人装配任务的性能。

Abstract: Humans excel at bimanual assembly tasks by adapting to rich tactile feedback
-- a capability that remains difficult to replicate in robots through
behavioral cloning alone, due to the suboptimality and limited diversity of
human demonstrations. In this work, we present VT-Refine, a visuo-tactile
policy learning framework that combines real-world demonstrations,
high-fidelity tactile simulation, and reinforcement learning to tackle precise,
contact-rich bimanual assembly. We begin by training a diffusion policy on a
small set of demonstrations using synchronized visual and tactile inputs. This
policy is then transferred to a simulated digital twin equipped with simulated
tactile sensors and further refined via large-scale reinforcement learning to
enhance robustness and generalization. To enable accurate sim-to-real transfer,
we leverage high-resolution piezoresistive tactile sensors that provide normal
force signals and can be realistically modeled in parallel using
GPU-accelerated simulation. Experimental results show that VT-Refine improves
assembly performance in both simulation and the real world by increasing data
diversity and enabling more effective policy fine-tuning. Our project page is
available at https://binghao-huang.github.io/vt_refine/.

</details>


### [39] [From Language to Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance](https://arxiv.org/abs/2510.14952)
*Zhe Li,Cheng Chi,Yangyang Wei,Boan Zhu,Yibo Peng,Tao Huang,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang,Chang Xu*

Main category: cs.RO

TL;DR: RoboGhost是一个免重定向框架，通过直接将人形机器人策略建立在语言基础的运动潜在空间上，实现了从语言到动作的直接映射，消除了传统多阶段流程中的累积误差和高延迟问题。


<details>
  <summary>Details</summary>
Motivation: 现有语言引导的人形机器人运动流程存在多阶段处理导致的累积误差、高延迟以及语义与控制耦合弱的问题，需要一种更直接的从语言到动作的路径。

Method: 采用基于扩散的策略直接从噪声中生成可执行动作，通过混合因果transformer-diffusion运动生成器确保长时程一致性，同时保持稳定性和多样性。

Result: 实验表明RoboGhost显著降低了部署延迟，提高了成功率和跟踪精度，在真实人形机器人上产生了平滑、语义对齐的运动。

Conclusion: 该框架为视觉-语言-动作人形系统提供了通用基础，可自然扩展到图像、音频和音乐等其他模态。

Abstract: Natural language offers a natural interface for humanoid robots, but existing
language-guided humanoid locomotion pipelines remain cumbersome and unreliable.
They typically decode human motion, retarget it to robot morphology, and then
track it with a physics-based controller. However, this multi-stage process is
prone to cumulative errors, introduces high latency, and yields weak coupling
between semantics and control. These limitations call for a more direct pathway
from language to action, one that eliminates fragile intermediate stages.
Therefore, we present RoboGhost, a retargeting-free framework that directly
conditions humanoid policies on language-grounded motion latents. By bypassing
explicit motion decoding and retargeting, RoboGhost enables a diffusion-based
policy to denoise executable actions directly from noise, preserving semantic
intent and supporting fast, reactive control. A hybrid causal
transformer-diffusion motion generator further ensures long-horizon consistency
while maintaining stability and diversity, yielding rich latent representations
for precise humanoid behavior. Extensive experiments demonstrate that RoboGhost
substantially reduces deployment latency, improves success rates and tracking
accuracy, and produces smooth, semantically aligned locomotion on real
humanoids. Beyond text, the framework naturally extends to other modalities
such as images, audio, and music, providing a general foundation for
vision-language-action humanoid systems.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [40] [Laser Fault Injection in Memristor-Based Accelerators for AI/ML and Neuromorphic Computing](https://arxiv.org/abs/2510.14120)
*Muhammad Faheemur Rahman,Wayne Burleson*

Main category: cs.ET

TL;DR: 该论文研究了激光故障注入攻击对忆阻器交叉阵列的威胁，通过激光诱导光电流扰动忆阻单元，可高精度推断内部权重并破坏计算完整性。


<details>
  <summary>Details</summary>
Motivation: 忆阻器交叉阵列因其高密度和并行模拟矩阵向量乘法能力而成为内存计算和神经形态硬件的关键组件，但其非易失性存储单元的物理特性引入了新的攻击面，特别是在故障注入场景下。

Method: 通过HSPICE仿真45nm CMOS技术节点上的大型忆阻器交叉阵列，研究激光诱导光电流在输出电流分布中的表现，利用差分故障分析技术。

Result: 激光故障注入能够以99.7%的准确率推断内部权重，复制模型，并通过针对性权重修改使计算完整性受损约143%。

Conclusion: 忆阻器交叉阵列在激光故障注入攻击下存在严重安全漏洞，需要开发新的防护措施来保障其计算完整性。

Abstract: Memristive crossbar arrays (MCA) are emerging as efficient building blocks
for in-memory computing and neuromorphic hardware due to their high density and
parallel analog matrix-vector multiplication capabilities. However, the
physical properties of their nonvolatile memory elements introduce new attack
surfaces, particularly under fault injection scenarios. This work explores
Laser Fault Injection as a means of inducing analog perturbations in MCA-based
architectures. We present a detailed threat model in which adversaries target
memristive cells to subtly alter their physical properties or outputs using
laser beams. Through HSPICE simulations of a large MCA on 45 nm CMOS tech.
node, we show how laser-induced photocurrent manifests in output current
distributions, enabling differential fault analysis to infer internal weights
with up to 99.7% accuracy, replicate the model, and compromise computational
integrity through targeted weight alterations by approximately 143%.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [41] [A Global Systems Perspective on Food Demand, Deforestation and Agricultural Sustainability](https://arxiv.org/abs/2510.14720)
*Moretti Elia,Loreau Michel,Benzaquen Michael*

Main category: econ.TH

TL;DR: 开发了一个空间明确的全球模型，比较不同政策情景（常规、供给侧、需求侧、混合政策），发现仅靠供给侧措施无法阻止生态退化，需求侧改变（特别是减少肉类消费）能有效缓解生态压力，综合政策组合效果最佳。


<details>
  <summary>Details</summary>
Motivation: 应对全球人口增长和财富增加带来的粮食需求上升，特别是动物产品需求，对生态系统造成的压力日益加剧，包括加速森林砍伐、侵蚀生物多样性和土壤健康。

Method: 开发了一个风格化、空间明确的全球模型，将外生粮食需求轨迹与作物和畜牧业生产、土地转换以及生态系统完整性反馈联系起来，校准了1960年后的人口、收入、产量、投入和土地利用趋势。

Result: 供给侧措施常引发补偿性土地扩张，抵消生态收益；需求侧改变（特别是减少肉类消费）能同时缓解集约化和扩张压力；综合政策组合优于任何单一措施。

Conclusion: 明确了阻碍零散干预的系统级权衡，识别了最有可能将全球粮食供应控制在生态限度内的政策组合。

Abstract: Feeding a larger and wealthier global population without transgressing
ecological limits is increasingly challenging, as rising food demand
(especially for animal products) intensifies pressure on ecosystems,
accelerates deforestation, and erodes biodiversity and soil health. We develop
a stylized, spatially explicit global model that links exogenous food-demand
trajectories to crop and livestock production, land conversion, and feedbacks
from ecosystem integrity that, in turn, shape future yields and land needs.
Calibrated to post-1960 trends in population, income, yields, input use, and
land use, the model reproduces the joint rise of crop and meat demand and the
associated expansion and intensification of agriculture. We use it to compare
business-as-usual, supply-side, demand-side, and mixed-policy scenarios. Three
results stand out. First, productivity-oriented supply-side measures (e.g.
reduced chemical inputs, organic conversion, lower livestock density) often
trigger compensatory land expansion that undermines ecological gains-so that
supply-side action alone cannot halt deforestation or widespread degradation.
Second, demand-side change, particularly reduced meat consumption, consistently
relieves both intensification and expansion pressures; in our simulations, only
substantial demand reductions (on the order of 40% of projected excess demand
by 2100) deliver simultaneous increases in forest area and declines in degraded
land. Third, integrated policy portfolios that jointly constrain land
conversion, temper input intensification, and curb demand outperform any single
lever. Together, these findings clarify the system-level trade-offs that
frustrate piecemeal interventions and identify the policy combinations most
likely to keep global food provision within ecological limits.

</details>


### [42] [Strategic Behavior in Crowdfunding: Insights from a Large-Scale Online Experiment](https://arxiv.org/abs/2510.14872)
*Din Amir,Bar Hoter,Moran Koren*

Main category: econ.TH

TL;DR: 通过大规模在线实验验证众筹中的策略行为，发现众筹机制相比投票更能诱导风险规避和互助保险行为，信号准确性和参与阈值对策略行为有显著影响。


<details>
  <summary>Details</summary>
Motivation: 研究众筹机制中的策略行为，基于Arieli等人的模型，重点关注信息激励而非动态效应，验证理论预测并识别行为偏差。

Method: 采用大规模在线实验，在静态单次众筹游戏中测试风险规避和互助保险行为，比较不同信号准确度（55% vs 85%）和参与阈值（50% vs 80%）下的行为差异。

Result: 验证了理论预测：众筹机制相比投票更易诱导策略行为；高信号准确度降低风险规避但增加互助保险；提高参与阈值反而增强风险规避，可能与认知约束有关。

Conclusion: 众筹机制中的信息激励确实影响策略行为，但存在与理论不符的行为偏差，互助保险虽促进参与但可能阻碍信息聚合，为平台设计和机制优化提供重要启示。

Abstract: This study examines strategic behavior in crowdfunding using a large-scale
online experiment. Building on the model of Arieli et. al 2023, we test
predictions about risk aversion (i.e., opting out despite seeing a positive
private signal) and mutual insurance (i.e., opting in despite seeing a negative
private signal) in a static, single-shot crowdfunding game, focusing on
informational incentives rather than dynamic effects. Our results validate key
theoretical predictions: crowdfunding mechanisms induce distinct strategic
behaviors compared to voting, where participants are more likely to follow
private signals (odds ratio: 0.139, $p < 0.001$). Additionally, the study
demonstrates that higher signal accuracy (85\% vs. 55\%) decreases risk
aversion (odds ratio: 0.414, $p = 0.024$) but increases reliance on mutual
insurance (odds ratio: 2.532, $p = 0.026$). However, contrary to theory,
increasing the required participation threshold (50\% to 80\%) amplifies risk
aversion (odds ratio: 3.251, $p = 0.005$), which, pending further
investigation, may indicate cognitive constraints.
  Furthermore, we show that while mutual insurance supports participation, it
may hinder information aggregation, particularly as signal accuracy increases.
These findings advance crowdfunding theory by confirming the impact of
informational incentives and identifying behavioral deviations that challenge
standard models, offering insights for platform design and mechanism
refinement.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [43] [What is missing from this picture? Persistent homology and mixup barcodes as a means of investigating negative embedding space](https://arxiv.org/abs/2510.14327)
*Himanshu Yadav,Thomas Bryan Smith,Peter Bubenik,Christopher McCarty*

Main category: cs.SI

TL;DR: 本文提出了一种结合拓扑数据分析（TDA）和主题建模的新方法，通过持久同调和mixup条形码来分析文档嵌入空间中的"负空间"，以识别缺失的研究背景和创新空间。


<details>
  <summary>Details</summary>
Motivation: 现有信息科学中的指标存在内在偏见，需要开发新的度量方法来量化研究的颠覆性和概念新颖性。本文旨在结合网络科学方法和主题建模方法的优势。

Method: 使用top2vec将文档和主题嵌入到n维空间，应用持久同调识别嵌入分布中的空洞，然后使用mixup条形码确定哪些空洞被未观察到的出版物填充。

Result: 研究了负嵌入空间在多大程度上代表缺失背景（较旧研究）与创新空间（较新研究），以及占据这些空间的文档如何整合边缘研究主题。

Conclusion: 该方法为理解研究文献中的概念演变提供了新的度量工具，具有识别研究创新性和整合性的潜在应用价值。

Abstract: Recent work in the information sciences, especially informetrics and
scientometrics, has made substantial contributions to the development of new
metrics that eschew the intrinsic biases of citation metrics. This work has
tended to employ either network scientific (topological) approaches to
quantifying the disruptiveness of peer-reviewed research, or topic modeling
approaches to quantifying conceptual novelty. We propose a combination of these
approaches, investigating the prospect of topological data analysis (TDA),
specifically persistent homology and mixup barcodes, as a means of
understanding the negative space among document embeddings generated by topic
models. Using top2vec, we embed documents and topics in n-dimensional space, we
use persistent homology to identify holes in the embedding distribution, and
then use mixup barcodes to determine which holes are being filled by a set of
unobserved publications. In this case, the unobserved publications represent
research that was published before or after the data used to train top2vec. We
investigate the extent that negative embedding space represents missing context
(older research) versus innovation space (newer research), and the extend that
the documents that occupy this space represents integrations of the research
topics on the periphery. Potential applications for this metric are discussed.

</details>


### [44] [Detecting Early and Implicit Suicidal Ideation via Longitudinal and Information Environment Signals on Social Media](https://arxiv.org/abs/2510.14889)
*Soorya Ram Shimgekar,Ruining Zhao,Agam Goyal,Violeta J. Rodriguez,Paul A. Bloom,Hari Sundaram,Koustuv Saha*

Main category: cs.SI

TL;DR: 提出一个计算框架，通过建模用户的信息环境（包括个人历史帖子和社交邻近同伴的讨论）来早期检测社交媒体上的隐性自杀意念。


<details>
  <summary>Details</summary>
Motivation: 在社交媒体上，许多有自杀意念的用户不会明确表达痛苦，而是通过日常帖子或同伴互动间接表现出来。早期检测这些隐性信号至关重要但具有挑战性。

Method: 采用复合网络中心性度量识别用户的顶级邻居，时间对齐用户和邻居的互动，在微调的DeBERTa-v3模型中整合多层信号。

Result: 在Reddit的1000名用户研究中，该方法比仅使用个人信息的基线方法提高了15%的早期隐性自杀意念检测准确率。

Conclusion: 同伴互动提供了有价值的预测信号，对设计能够捕捉在线环境中间接和掩盖风险表达的早期检测系统具有更广泛的意义。

Abstract: On social media, many individuals experiencing suicidal ideation (SI) do not
disclose their distress explicitly. Instead, signs may surface indirectly
through everyday posts or peer interactions. Detecting such implicit signals
early is critical but remains challenging. We frame early and implicit SI as a
forward-looking prediction task and develop a computational framework that
models a user's information environment, consisting of both their longitudinal
posting histories as well as the discourse of their socially proximal peers. We
adopted a composite network centrality measure to identify top neighbors of a
user, and temporally aligned the user's and neighbors' interactions --
integrating the multi-layered signals in a fine-tuned DeBERTa-v3 model. In a
Reddit study of 1,000 (500 Case and 500 Control) users, our approach improves
early and implicit SI detection by 15% over individual-only baselines. These
findings highlight that peer interactions offer valuable predictive signals and
carry broader implications for designing early detection systems that capture
indirect as well as masked expressions of risk in online environments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [45] [Decision Oriented Technique (DOTechnique): Finding Model Validity Through Decision-Maker Context](https://arxiv.org/abs/2510.13858)
*Raheleh Biglari,Joachim Denil*

Main category: cs.AI

TL;DR: 提出DOTechnique方法，通过决策一致性而非输出相似性来确定模型有效性，集成领域约束和符号推理来缩小搜索空间，提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 模型有效性对决策过程至关重要，传统方法依赖预定义的有效性框架，但可能不可用或不充分。

Method: DOTechnique方法通过评估替代模型是否与高保真模型产生等效决策来确定模型有效性，即使没有明确的有效性边界。

Result: 以高速公路变道系统为例，展示了DOTechnique能够发现仿真模型的有效性区域。

Conclusion: 该技术有潜力通过决策者上下文来支持发现模型有效性。

Abstract: Model validity is as critical as the model itself, especially when guiding
decision-making processes. Traditional approaches often rely on predefined
validity frames, which may not always be available or sufficient. This paper
introduces the Decision Oriented Technique (DOTechnique), a novel method for
determining model validity based on decision consistency rather than output
similarity. By evaluating whether surrogate models lead to equivalent decisions
compared to high-fidelity models, DOTechnique enables efficient identification
of validity regions, even in the absence of explicit validity boundaries. The
approach integrates domain constraints and symbolic reasoning to narrow the
search space, enhancing computational efficiency. A highway lane change system
serves as a motivating example, demonstrating how DOTechnique can uncover the
validity region of a simulation model. The results highlight the potential of
the technique to support finding model validity through decision-maker context.

</details>


### [46] [Do Slides Help? Multi-modal Context for Automatic Transcription of Conference Talks](https://arxiv.org/abs/2510.13979)
*Supriti Sinhamahapatra,Jan Niehues*

Main category: cs.AI

TL;DR: 该论文提出了一种融合视觉信息（演讲者图像和演示幻灯片）的多模态自动语音识别方法，专门针对科学演讲场景，通过数据增强技术解决了多模态数据集缺乏的问题，显著降低了词错误率。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的ASR系统主要依赖声学信息而忽略多模态上下文，但视觉信息对于消歧和适应至关重要。该工作特别关注科学演讲场景，通过整合演示幻灯片来提升ASR性能。

Method: 首先创建多模态演讲基准，然后探索用多模态信息增强语音模型的方法。通过数据增强技术解决缺乏配套幻灯片数据集的问题，最后使用增强数据集训练模型。

Result: 训练后的模型在所有词汇上的词错误率相对降低了约34%，在领域特定术语上的词错误率相对降低了35%，相比基线模型有显著提升。

Conclusion: 多模态信息（特别是演示幻灯片）的整合能够显著提升ASR系统在科学演讲场景下的性能，尤其是在处理领域特定术语方面效果明显。

Abstract: State-of-the-art (SOTA) Automatic Speech Recognition (ASR) systems primarily
rely on acoustic information while disregarding additional multi-modal context.
However, visual information are essential in disambiguation and adaptation.
While most work focus on speaker images to handle noise conditions, this work
also focuses on integrating presentation slides for the use cases of scientific
presentation.
  In a first step, we create a benchmark for multi-modal presentation including
an automatic analysis of transcribing domain-specific terminology. Next, we
explore methods for augmenting speech models with multi-modal information. We
mitigate the lack of datasets with accompanying slides by a suitable approach
of data augmentation. Finally, we train a model using the augmented dataset,
resulting in a relative reduction in word error rate of approximately 34%,
across all words and 35%, for domain-specific terms compared to the baseline
model.

</details>


### [47] [Do Large Language Models Show Biases in Causal Learning? Insights from Contingency Judgment](https://arxiv.org/abs/2510.13985)
*María Victoria Carro,Denise Alejandra Mester,Francisca Gauna Selasco,Giovanni Franco Gabriel Marraffini,Mario Alejandro Leiva,Gerardo I. Simari,María Vanina Martinez*

Main category: cs.AI

TL;DR: 研究发现大型语言模型在因果推理任务中容易产生因果幻觉，即使在没有足够证据支持的情况下也会错误推断因果关系。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型是否会在经典的认知科学范式——列联判断任务中发展出因果幻觉，这种认知偏见被认为是许多社会问题的根源。

Method: 构建了1000个医学背景下的零列联场景数据集，让LLMs评估潜在原因的有效性，这些场景中的信息不足以建立变量间的因果关系。

Result: 所有评估的模型都系统地推断出无根据的因果关系，显示出对因果幻觉的强烈易感性。

Conclusion: 研究结果支持LLMs只是复制因果语言而非真正理解因果关系的假设，对在需要准确因果推理的领域使用语言模型提出了担忧。

Abstract: Causal learning is the cognitive process of developing the capability of
making causal inferences based on available information, often guided by
normative principles. This process is prone to errors and biases, such as the
illusion of causality, in which people perceive a causal relationship between
two variables despite lacking supporting evidence. This cognitive bias has been
proposed to underlie many societal problems, including social prejudice,
stereotype formation, misinformation, and superstitious thinking. In this work,
we examine whether large language models are prone to developing causal
illusions when faced with a classic cognitive science paradigm: the contingency
judgment task. To investigate this, we constructed a dataset of 1,000 null
contingency scenarios (in which the available information is not sufficient to
establish a causal relationship between variables) within medical contexts and
prompted LLMs to evaluate the effectiveness of potential causes. Our findings
show that all evaluated models systematically inferred unwarranted causal
relationships, revealing a strong susceptibility to the illusion of causality.
While there is ongoing debate about whether LLMs genuinely understand causality
or merely reproduce causal language without true comprehension, our findings
support the latter hypothesis and raise concerns about the use of language
models in domains where accurate causal reasoning is essential for informed
decision-making.

</details>


### [48] [GammaZero: Learning To Guide POMDP Belief Space Search With Graph Representations](https://arxiv.org/abs/2510.14035)
*Rajesh Mangannavar,Prasad Tadepalli*

Main category: cs.AI

TL;DR: GammaZero提出了一种基于动作中心图表示的方法，用于在部分可观测马尔可夫决策过程中指导规划学习，能够在未见过的更大规模问题上实现零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要领域特定的神经网络架构且难以扩展，GammaZero旨在开发一个统一的图表示框架，实现在领域内跨问题规模的泛化能力。

Method: 将信念状态系统性地转换为动作中心图，使用图神经网络和解码器架构从专家演示中学习价值函数和策略，然后将学习到的启发式方法应用于更大问题的蒙特卡洛树搜索。

Result: 在标准POMDP基准测试中，GammaZero在相同规模问题上与BetaZero性能相当，同时能够零样本泛化到训练时未见过的2-4倍大的问题，保持解质量的同时减少搜索需求。

Conclusion: GammaZero通过动作中心图表示实现了在POMDP规划中的可扩展性和泛化能力，为处理大规模部分可观测环境提供了一种有效方法。

Abstract: We introduce an action-centric graph representation framework for learning to
guide planning in Partially Observable Markov Decision Processes (POMDPs).
Unlike existing approaches that require domain-specific neural architectures
and struggle with scalability, GammaZero leverages a unified graph-based belief
representation that enables generalization across problem sizes within a
domain. Our key insight is that belief states can be systematically transformed
into action-centric graphs where structural patterns learned on small problems
transfer to larger instances. We employ a graph neural network with a decoder
architecture to learn value functions and policies from expert demonstrations
on computationally tractable problems, then apply these learned heuristics to
guide Monte Carlo tree search on larger problems. Experimental results on
standard POMDP benchmarks demonstrate that GammaZero achieves comparable
performance to BetaZero when trained and tested on the same-sized problems,
while uniquely enabling zero-shot generalization to problems 2-4 times larger
than those seen during training, maintaining solution quality with reduced
search requirements.

</details>


### [49] [Position: Require Frontier AI Labs To Release Small "Analog" Models](https://arxiv.org/abs/2510.14053)
*Shriyash Upadhyay,Chaithanya Bandi,Narmeen Oozeer,Philip Quirke*

Main category: cs.AI

TL;DR: 提出一种替代性AI监管方法：要求大型AI实验室发布小型、开放的模拟模型，这些模型是从其大型专有模型蒸馏而来的缩小版本，既能确保AI安全又能促进创新。


<details>
  <summary>Details</summary>
Motivation: 现有前沿AI模型监管方案因安全与创新的权衡而被搁置，需要一种既能确保安全又不阻碍创新的监管方法。

Method: 强制要求大型AI实验室发布小型模拟模型作为公共代理，这些模型以类似方式训练并从大型专有模型蒸馏而来，允许广泛参与安全验证、可解释性研究和算法透明度工作。

Result: 研究表明，使用这些小型模型开发的安全和可解释性方法能有效泛化到前沿规模系统，显著降低监管负担并加速安全进展。

Conclusion: 这种监管方法以最小额外成本显著促进公共利益，并通过深化对模型的理解来缓解安全与创新的权衡，实现两者的双赢。

Abstract: Recent proposals for regulating frontier AI models have sparked concerns
about the cost of safety regulation, and most such regulations have been
shelved due to the safety-innovation tradeoff. This paper argues for an
alternative regulatory approach that ensures AI safety while actively promoting
innovation: mandating that large AI laboratories release small, openly
accessible analog models (scaled-down versions) trained similarly to and
distilled from their largest proprietary models.
  Analog models serve as public proxies, allowing broad participation in safety
verification, interpretability research, and algorithmic transparency without
forcing labs to disclose their full-scale models. Recent research demonstrates
that safety and interpretability methods developed using these smaller models
generalize effectively to frontier-scale systems. By enabling the wider
research community to directly investigate and innovate upon accessible
analogs, our policy substantially reduces the regulatory burden and accelerates
safety advancements.
  This mandate promises minimal additional costs, leveraging reusable resources
like data and infrastructure, while significantly contributing to the public
good. Our hope is not only that this policy be adopted, but that it illustrates
a broader principle supporting fundamental research in machine learning: deeper
understanding of models relaxes the safety-innovation tradeoff and lets us have
more of both.

</details>


### [50] [Generating Fair Consensus Statements with Social Choice on Token-Level MDPs](https://arxiv.org/abs/2510.14106)
*Carter Blair,Kate Larson*

Main category: cs.AI

TL;DR: 提出了一种基于多目标MDP和投票理论的共识声明生成框架，通过token级奖励和核心稳定性保证，实现公平的文本生成。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型共识声明生成框架缺乏可证明的公平性保证结构，无法在聚合多样化自由形式意见时提供理论保障。

Method: 将任务建模为多目标token级MDP，每个目标对应代理偏好；基于代理策略推导token级奖励；提出两种基于投票理论的方法：随机生成策略（保证ex-ante核心稳定性）和单一声明生成（最大化平等主义福利）。

Result: 实验表明，基于平等主义目标的搜索方法相比基线方法（包括Habermas Machine）能生成具有更好最差情况代理对齐的共识声明。

Conclusion: 该框架为共识声明生成提供了具有理论保证的公平性结构，将投票理论概念扩展到文本生成领域。

Abstract: Current frameworks for consensus statement generation with large language
models lack the inherent structure needed to provide provable fairness
guarantees when aggregating diverse free-form opinions. We model the task as a
multi-objective, token-level Markov Decision Process (MDP), where each
objective corresponds to an agent's preference. Token-level rewards for each
agent are derived from their policy (e.g., a personalized language model). This
approach utilizes the finding that such policies implicitly define optimal
Q-functions, providing a principled way to quantify rewards at each generation
step without a value function (Rafailov et al., 2024). This MDP formulation
creates a formal structure amenable to analysis using principles from social
choice theory. We propose two approaches grounded in social choice theory.
First, we propose a stochastic generation policy guaranteed to be in the
ex-ante core, extending core stability concepts from voting theory to text
generation. This policy is derived from an underlying distribution over
complete statements that maximizes proportional fairness (Nash Welfare).
Second, for generating a single statement, we target the maximization of
egalitarian welfare using search algorithms within the MDP framework.
Empirically, experiments using language models to instantiate agent policies
show that search guided by the egalitarian objective generates consensus
statements with improved worst-case agent alignment compared to baseline
methods, including the Habermas Machine (Tessler et al., 2024).

</details>


### [51] [STEMS: Spatial-Temporal Enhanced Safe Multi-Agent Coordination for Building Energy Management](https://arxiv.org/abs/2510.14112)
*Huiliang Zhang,Di Wu,Arnaud Zinflou,Benoit Boulet*

Main category: cs.AI

TL;DR: 提出了STEMS框架，一种安全约束的多智能体强化学习方法，用于协调建筑能源管理，通过空间-时间图表示学习和控制屏障函数实现性能提升和安全保障。


<details>
  <summary>Details</summary>
Motivation: 建筑能源管理对实现碳减排目标、提升居住舒适度和降低能源成本至关重要。当前多建筑能源系统面临空间-时间依赖关系利用不足、缺乏严格安全保证和系统复杂性三大挑战。

Method: STEMS框架包含两个核心组件：(1) 使用GCN-Transformer融合架构的空间-时间图表示学习框架，捕捉建筑间关系和时序模式；(2) 结合控制屏障函数的安全约束多智能体强化学习算法，提供数学安全保证。

Result: 在真实建筑数据集上的实验表明，STEMS相比现有方法实现了21%成本降低、18%排放减少，安全违规从35.1%大幅降至5.6%，同时保持最佳舒适度（仅0.13不适比例）。该框架在极端天气条件下表现出强鲁棒性，并在不同建筑类型中保持有效性。

Conclusion: STEMS框架为多建筑能源系统的协调管理提供了一种有效的解决方案，成功解决了空间-时间依赖关系利用、安全保证和系统复杂性等关键挑战，在性能、安全和鲁棒性方面均表现出色。

Abstract: Building energy management is essential for achieving carbon reduction goals,
improving occupant comfort, and reducing energy costs. Coordinated building
energy management faces critical challenges in exploiting spatial-temporal
dependencies while ensuring operational safety across multi-building systems.
Current multi-building energy systems face three key challenges: insufficient
spatial-temporal information exploitation, lack of rigorous safety guarantees,
and system complexity. This paper proposes Spatial-Temporal Enhanced Safe
Multi-Agent Coordination (STEMS), a novel safety-constrained multi-agent
reinforcement learning framework for coordinated building energy management.
STEMS integrates two core components: (1) a spatial-temporal graph
representation learning framework using a GCN-Transformer fusion architecture
to capture inter-building relationships and temporal patterns, and (2) a
safety-constrained multi-agent RL algorithm incorporating Control Barrier
Functions to provide mathematical safety guarantees. Extensive experiments on
real-world building datasets demonstrate STEMS's superior performance over
existing methods, showing that STEMS achieves 21% cost reduction, 18% emission
reduction, and dramatically reduces safety violations from 35.1% to 5.6% while
maintaining optimal comfort with only 0.13 discomfort proportion. The framework
also demonstrates strong robustness during extreme weather conditions and
maintains effectiveness across different building types.

</details>


### [52] [Formalizing the Safety, Security, and Functional Properties of Agentic AI Systems](https://arxiv.org/abs/2510.14133)
*Edoardo Allegrini,Ananth Shreekumar,Z. Berkay Celik*

Main category: cs.AI

TL;DR: 提出了一个用于多智能体AI系统的统一建模框架，包含主机智能体模型和任务生命周期模型，定义了31个系统属性，支持形式化验证，旨在解决当前智能体通信生态碎片化问题。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体AI系统的通信协议碎片化，存在语义鸿沟，阻碍系统属性分析，导致架构错位和可被利用的协调问题，需要统一框架来确保系统安全性和可靠性。

Method: 引入两个基础模型：主机智能体模型（负责用户交互、任务分解和编排）和任务生命周期模型（详细描述子任务状态转换），定义了17个主机智能体属性和14个任务生命周期属性，使用时序逻辑进行形式化验证。

Result: 构建了首个严格基础、领域无关的框架，能够系统分析、设计和部署正确、可靠、鲁棒的多智能体AI系统，支持检测协调边缘情况、预防死锁和安全漏洞。

Conclusion: 该框架为多AI智能体系统的行为提供了统一的语义基础，通过形式化验证确保系统安全性、完整性和公平性，是构建可信赖智能体AI系统的重要进展。

Abstract: Agentic AI systems, which leverage multiple autonomous agents and Large
Language Models (LLMs), are increasingly used to address complex, multi-step
tasks. The safety, security, and functionality of these systems are critical,
especially in high-stakes applications. However, the current ecosystem of
inter-agent communication is fragmented, with protocols such as the Model
Context Protocol (MCP) for tool access and the Agent-to-Agent (A2A) protocol
for coordination being analyzed in isolation. This fragmentation creates a
semantic gap that prevents the rigorous analysis of system properties and
introduces risks such as architectural misalignment and exploitable
coordination issues. To address these challenges, we introduce a modeling
framework for agentic AI systems composed of two foundational models. The
first, the host agent model, formalizes the top-level entity that interacts
with the user, decomposes tasks, and orchestrates their execution by leveraging
external agents and tools. The second, the task lifecycle model, details the
states and transitions of individual sub-tasks from creation to completion,
providing a fine-grained view of task management and error handling. Together,
these models provide a unified semantic framework for reasoning about the
behavior of multi-AI agent systems. Grounded in this framework, we define 17
properties for the host agent and 14 for the task lifecycle, categorized into
liveness, safety, completeness, and fairness. Expressed in temporal logic,
these properties enable formal verification of system behavior, detection of
coordination edge cases, and prevention of deadlocks and security
vulnerabilities. Through this effort, we introduce the first rigorously
grounded, domain-agnostic framework for the systematic analysis, design, and
deployment of correct, reliable, and robust agentic AI systems.

</details>


### [53] [A Multimodal Approach to Heritage Preservation in the Context of Climate Change](https://arxiv.org/abs/2510.14136)
*David Roqui,Adèle Cormier,nistor Grozavu,Ann Bourges*

Main category: cs.AI

TL;DR: 提出轻量级多模态架构，融合传感器数据和视觉图像预测文化遗产地退化严重程度，在斯特拉斯堡大教堂数据上达到76.9%准确率，比标准多模态架构提升43%。


<details>
  <summary>Details</summary>
Motivation: 文化遗产地因气候变化加速退化，传统单模态监测方法无法捕捉环境应力与材料退化之间的复杂相互作用。

Method: 采用改进的PerceiverIO架构，包含简化编码器（64D潜在空间）和自适应Barlow Twins损失函数，鼓励模态互补性而非冗余。

Result: 模型准确率达76.9%，比标准多模态架构提升43%，比基础PerceiverIO提升25%。单模态传感器数据准确率为61.5%，图像数据为46.2%。

Conclusion: 架构简化与对比正则化相结合，可在数据稀缺的文化遗产监测环境中实现有效的多模态学习，为AI驱动的保护决策支持系统奠定基础。

Abstract: Cultural heritage sites face accelerating degradation due to climate change,
yet tradi- tional monitoring relies on unimodal analysis (visual inspection or
environmental sen- sors alone) that fails to capture the complex interplay
between environmental stres- sors and material deterioration. We propose a
lightweight multimodal architecture that fuses sensor data (temperature,
humidity) with visual imagery to predict degradation severity at heritage
sites. Our approach adapts PerceiverIO with two key innovations: (1) simplified
encoders (64D latent space) that prevent overfitting on small datasets (n=37
training samples), and (2) Adaptive Barlow Twins loss that encourages modality
complementarity rather than redundancy. On data from Strasbourg Cathedral, our
model achieves 76.9% accu- racy, a 43% improvement over standard multimodal
architectures (VisualBERT, Trans- former) and 25% over vanilla PerceiverIO.
Ablation studies reveal that sensor-only achieves 61.5% while image-only
reaches 46.2%, confirming successful multimodal synergy. A systematic
hyperparameter study identifies an optimal moderate correlation target ({\tau}
=0.3) that balances align- ment and complementarity, achieving 69.2% accuracy
compared to other {\tau} values ({\tau} =0.1/0.5/0.7: 53.8%, {\tau} =0.9:
61.5%). This work demonstrates that architectural sim- plicity combined with
contrastive regularization enables effective multimodal learning in data-scarce
heritage monitoring contexts, providing a foundation for AI-driven con-
servation decision support systems.

</details>


### [54] [CodeEvolve: An open source evolutionary coding agent for algorithm discovery and optimization](https://arxiv.org/abs/2510.14150)
*Henrique Assumpção,Diego Ferreira,Leandro Campos,Fabricio Murai*

Main category: cs.AI

TL;DR: CodeEvolve是一个开源进化编码代理，结合大语言模型和遗传算法解决复杂计算问题，在多个数学基准测试中超越了Google DeepMind的AlphaEvolve。


<details>
  <summary>Details</summary>
Motivation: 将强大的进化概念应用于大语言模型领域，基于广义科学发现的最新方法，解决复杂计算问题。

Method: 采用基于岛屿的遗传算法保持种群多样性，引入新颖的基于启发的交叉机制，利用LLM上下文窗口组合成功解决方案的特征，并实现元提示策略动态探索解空间。

Result: 在用于评估Google DeepMind闭源AlphaEvolve的数学基准测试子集上，CodeEvolve在多个挑战性问题上的表现超越了AlphaEvolve。

Conclusion: CodeEvolve成功将进化算法与大语言模型结合，在复杂问题求解上表现出色，并开源完整框架以促进合作和加速进展。

Abstract: In this work, we introduce CodeEvolve, an open-source evolutionary coding
agent that unites Large Language Models (LLMs) with genetic algorithms to solve
complex computational problems. Our framework adapts powerful evolutionary
concepts to the LLM domain, building upon recent methods for generalized
scientific discovery. CodeEvolve employs an island-based genetic algorithm to
maintain population diversity and increase throughput, introduces a novel
inspiration-based crossover mechanism that leverages the LLMs context window to
combine features from successful solutions, and implements meta-prompting
strategies for dynamic exploration of the solution space. We conduct a rigorous
evaluation of CodeEvolve on a subset of the mathematical benchmarks used to
evaluate Google DeepMind's closed-source AlphaEvolve. Our findings show that
our method surpasses AlphaEvolve's performance on several challenging problems.
To foster collaboration and accelerate progress, we release our complete
framework as an open-source repository.

</details>


### [55] [Combining Reinforcement Learning and Behavior Trees for NPCs in Video Games with AMD Schola](https://arxiv.org/abs/2510.14154)
*Tian Liu,Alex Cann,Ian Colbert,Mehdi Saeedi*

Main category: cs.AI

TL;DR: 本文探讨了在商业视频游戏中应用强化学习（RL）的挑战，提出将RL与传统行为树（BTs）结合的方法，并通过AMD Schola插件在复杂3D环境中验证了该方法的可行性。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习研究进展迅速，但在商业视频游戏中的应用仍然缓慢。本文旨在解决游戏AI社区在使用RL驱动NPC时面临的常见挑战，并探索RL与行为树结合的关键节点。

Method: 使用AMD Schola插件在Unreal Engine中训练RL代理，创建多任务NPC。提供了将RL模型与行为树联合训练的详细方法，并在受《最后生还者》启发的复杂3D环境中展示各种技能。

Result: 验证了RL与行为树结合方法的可行性，成功在复杂3D环境中创建了多任务NPC。

Conclusion: RL与行为树的结合是一个值得进一步探索的关键节点，虽然已有研究提出这种结合，但实际应用仍然罕见。本文证明了该方法的实际可行性。

Abstract: While the rapid advancements in the reinforcement learning (RL) research
community have been remarkable, the adoption in commercial video games remains
slow. In this paper, we outline common challenges the Game AI community faces
when using RL-driven NPCs in practice, and highlight the intersection of RL
with traditional behavior trees (BTs) as a crucial juncture to be explored
further. Although the BT+RL intersection has been suggested in several research
papers, its adoption is rare. We demonstrate the viability of this approach
using AMD Schola -- a plugin for training RL agents in Unreal Engine -- by
creating multi-task NPCs in a complex 3D environment inspired by the commercial
video game ``The Last of Us". We provide detailed methodologies for jointly
training RL models with BTs while showcasing various skills.

</details>


### [56] [JEDA: Query-Free Clinical Order Search from Ambient Dialogues](https://arxiv.org/abs/2510.14169)
*Praphul Singh,Corey Barrett,Sumana Srivasta,Amitabh Saikia,Irfan Bulu,Sri Gadde,Krishnaram Kenthapadi*

Main category: cs.AI

TL;DR: JEDA是一个用于临床订单检索的双编码器系统，能够直接从临床对话中检索规范订单，无需依赖LLM重写，提供实时、可解释的检索能力。


<details>
  <summary>Details</summary>
Motivation: 临床对话包含显性指令和隐性推理，现有系统依赖LLM重写会带来延迟、不稳定和不透明问题，阻碍实时订单处理。

Method: 基于PubMedBERT初始化，使用双编码器架构，通过对比学习目标对齐异质意图表达与共享订单概念，支持查询和无查询两种模式。

Result: JEDA在实践中取得显著性能提升，大幅优于基础编码器和最新开源嵌入模型，无查询模式对噪声具有鲁棒性。

Conclusion: JEDA提供了一个快速、可解释、无需LLM的检索层，能够实时将环境上下文链接到可操作的临床订单。

Abstract: Clinical conversations mix explicit directives (order a chest X-ray) with
implicit reasoning (the cough worsened overnight, we should check for
pneumonia). Many systems rely on LLM rewriting, adding latency, instability,
and opacity that hinder real-time ordering. We present JEDA (Joint Embedding
for Direct and Ambient clinical orders), a domain-initialized bi-encoder that
retrieves canonical orders directly and, in a query-free mode, encodes a short
rolling window of ambient dialogue to trigger retrieval. Initialized from
PubMedBERT and fine-tuned with a duplicate-safe contrastive objective, JEDA
aligns heterogeneous expressions of intent to shared order concepts. Training
uses constrained LLM guidance to tie each signed order to complementary
formulations (command only, context only, command+context, context+reasoning),
producing clearer inter-order separation, tighter query extendash order
coupling, and stronger generalization. The query-free mode is noise-resilient,
reducing sensitivity to disfluencies and ASR errors by conditioning on a short
window rather than a single utterance. Deployed in practice, JEDA yields large
gains and substantially outperforms its base encoder and recent open embedders
(Linq Embed Mistral, SFR Embedding, GTE Qwen, BGE large, Embedding Gemma). The
result is a fast, interpretable, LLM-free retrieval layer that links ambient
context to actionable clinical orders in real time.

</details>


### [57] [ARM-FM: Automated Reward Machines via Foundation Models for Compositional Reinforcement Learning](https://arxiv.org/abs/2510.14176)
*Roger Creus Castanyer,Faisal Mohamed,Pablo Samuel Castro,Cyrus Neary,Glen Berseth*

Main category: cs.AI

TL;DR: ARM-FM是一个利用基础模型自动生成奖励机来改进强化学习的框架，能够从自然语言规范自动构建结构化奖励函数，并实现跨任务的零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 强化学习算法对奖励函数设计高度敏感，这限制了其广泛应用。现有的奖励设计方法需要大量人工参与，难以实现复杂任务的自动化和泛化。

Method: 使用基础模型从自然语言规范自动生成奖励机，为每个自动机状态关联语言嵌入以实现跨任务泛化，利用奖励机的结构化形式实现有效的任务分解。

Result: 在多个挑战性环境中验证了ARM-FM的有效性，包括展示了零样本泛化能力，证明了该方法能够自动生成高质量的奖励函数。

Conclusion: ARM-FM通过结合基础模型和奖励机形式化，为强化学习提供了一种自动化的奖励设计方法，显著降低了奖励函数设计的人工成本，并实现了跨任务的泛化能力。

Abstract: Reinforcement learning (RL) algorithms are highly sensitive to reward
function specification, which remains a central challenge limiting their broad
applicability. We present ARM-FM: Automated Reward Machines via Foundation
Models, a framework for automated, compositional reward design in RL that
leverages the high-level reasoning capabilities of foundation models (FMs).
Reward machines (RMs) -- an automata-based formalism for reward specification
-- are used as the mechanism for RL objective specification, and are
automatically constructed via the use of FMs. The structured formalism of RMs
yields effective task decompositions, while the use of FMs enables objective
specifications in natural language. Concretely, we (i) use FMs to automatically
generate RMs from natural language specifications; (ii) associate language
embeddings with each RM automata-state to enable generalization across tasks;
and (iii) provide empirical evidence of ARM-FM's effectiveness in a diverse
suite of challenging environments, including evidence of zero-shot
generalization.

</details>


### [58] [Implementation of AI in Precision Medicine](https://arxiv.org/abs/2510.14194)
*Göktuğ Bender,Samer Faraj,Anand Bhardwaj*

Main category: cs.AI

TL;DR: 对2019-2024年精准医学中AI实施文献的范围综述，识别关键障碍和促进因素，提出基于生态系统的实施框架。


<details>
  <summary>Details</summary>
Motivation: AI在精准医学中日益重要，但临床实施仍然有限，需要系统分析实施障碍和促进因素。

Method: 采用范围综述方法，分析2019-2024年相关文献，使用基于生态系统的框架分析数据质量、临床可靠性、工作流程整合和治理等方面。

Result: 识别了精准医学中AI实施的关键障碍和促进因素，强调了各要素间的相互依赖关系。

Conclusion: 提出了支持可信赖和可持续实施AI的未来方向，强调生态系统视角的重要性。

Abstract: Artificial intelligence (AI) has become increasingly central to precision
medicine by enabling the integration and interpretation of multimodal data, yet
implementation in clinical settings remains limited. This paper provides a
scoping review of literature from 2019-2024 on the implementation of AI in
precision medicine, identifying key barriers and enablers across data quality,
clinical reliability, workflow integration, and governance. Through an
ecosystem-based framework, we highlight the interdependent relationships
shaping real-world translation and propose future directions to support
trustworthy and sustainable implementation.

</details>


### [59] [Echoes of Human Malice in Agents: Benchmarking LLMs for Multi-Turn Online Harassment Attacks](https://arxiv.org/abs/2510.14207)
*Trilok Padhi,Pinxian Lu,Abdulkadir Erol,Tanmay Sutar,Gauri Sharma,Mina Sonmez,Munmun De Choudhury,Ugur Kursuncu*

Main category: cs.AI

TL;DR: 提出了在线骚扰代理基准，通过多轮对话和博弈论模拟攻击LLM代理，发现微调攻击使骚扰成功率大幅提升，揭示了现有安全防护在持续性骚扰中的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有越狱研究主要关注单轮提示，而真实骚扰往往在多轮交互中展开，需要评估LLM代理在多轮对话中的安全漏洞。

Method: 构建了包含合成多轮骚扰对话数据集、基于重复博弈论的多代理模拟、三种针对记忆、规划和微调的越狱方法，以及混合评估框架的基准系统。

Result: 微调攻击使骚扰成功率在Llama中从57-64%提升至96-97%，在Gemini中从98%提升至99%；侮辱行为从45-51%提升至85-88%，谩骂行为从32-39%提升至81-85%。

Conclusion: 多轮和理论基础的攻击不仅成功率高，还能模拟人类骚扰动态，表明需要开发更强大的安全防护机制来保护在线平台安全。

Abstract: Large Language Model (LLM) agents are powering a growing share of interactive
web applications, yet remain vulnerable to misuse and harm. Prior jailbreak
research has largely focused on single-turn prompts, whereas real harassment
often unfolds over multi-turn interactions. In this work, we present the Online
Harassment Agentic Benchmark consisting of: (i) a synthetic multi-turn
harassment conversation dataset, (ii) a multi-agent (e.g., harasser, victim)
simulation informed by repeated game theory, (iii) three jailbreak methods
attacking agents across memory, planning, and fine-tuning, and (iv) a
mixed-methods evaluation framework. We utilize two prominent LLMs,
LLaMA-3.1-8B-Instruct (open-source) and Gemini-2.0-flash (closed-source). Our
results show that jailbreak tuning makes harassment nearly guaranteed with an
attack success rate of 95.78--96.89% vs. 57.25--64.19% without tuning in Llama,
and 99.33% vs. 98.46% without tuning in Gemini, while sharply reducing refusal
rate to 1-2% in both models. The most prevalent toxic behaviors are Insult with
84.9--87.8% vs. 44.2--50.8% without tuning, and Flaming with 81.2--85.1% vs.
31.5--38.8% without tuning, indicating weaker guardrails compared to sensitive
categories such as sexual or racial harassment. Qualitative evaluation further
reveals that attacked agents reproduce human-like aggression profiles, such as
Machiavellian/psychopathic patterns under planning, and narcissistic tendencies
with memory. Counterintuitively, closed-source and open-source models exhibit
distinct escalation trajectories across turns, with closed-source models
showing significant vulnerability. Overall, our findings show that multi-turn
and theory-grounded attacks not only succeed at high rates but also mimic
human-like harassment dynamics, motivating the development of robust safety
guardrails to ultimately keep online platforms safe and responsible.

</details>


### [60] [LiveResearchBench: A Live Benchmark for User-Centric Deep Research in the Wild](https://arxiv.org/abs/2510.14240)
*Jiayu Wang,Yifei Ming,Riya Dulepet,Qinglin Chen,Austin Xu,Zixuan Ke,Frederic Sala,Aws Albarghouthi,Caiming Xiong,Shafiq Joty*

Main category: cs.AI

TL;DR: LiveResearchBench是一个包含100个专家策划任务的基准测试，用于评估深度研究系统。DeepEval是一个综合评估套件，用于评估引用基础的深度研究报告。通过对17个前沿系统的评估，揭示了当前系统的优势和常见失败模式。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在评估深度研究系统时存在不足：任务领域狭窄、问题模糊、缺乏动态实时信息需求。需要建立一个符合用户中心、动态、明确、多维度搜索密集型原则的评估基准。

Method: 提出LiveResearchBench基准测试，包含100个专家策划任务，涵盖日常生活、企业和学术领域，每个任务都需要广泛的动态实时网络搜索和综合。开发DeepEval评估套件，涵盖内容和报告层面的质量评估，包括覆盖率、呈现、引用准确性、一致性和分析深度。

Result: 通过LiveResearchBench和DeepEval对17个前沿深度研究系统进行了全面评估，识别了当前系统的优势和常见失败模式。

Conclusion: LiveResearchBench和DeepEval为系统评估深度研究能力提供了严格基础，揭示了推进可靠、有洞察力的深度研究所需的关键系统组件。

Abstract: Deep research -- producing comprehensive, citation-grounded reports by
searching and synthesizing information from hundreds of live web sources --
marks an important frontier for agentic systems. To rigorously evaluate this
ability, four principles are essential: tasks should be (1) user-centric,
reflecting realistic information needs, (2) dynamic, requiring up-to-date
information beyond parametric knowledge, (3) unambiguous, ensuring consistent
interpretation across users, and (4) multi-faceted and search-intensive,
requiring search over numerous web sources and in-depth analysis. Existing
benchmarks fall short of these principles, often focusing on narrow domains or
posing ambiguous questions that hinder fair comparison. Guided by these
principles, we introduce LiveResearchBench, a benchmark of 100 expert-curated
tasks spanning daily life, enterprise, and academia, each requiring extensive,
dynamic, real-time web search and synthesis. Built with over 1,500 hours of
human labor, LiveResearchBench provides a rigorous basis for systematic
evaluation. To evaluate citation-grounded long-form reports, we introduce
DeepEval, a comprehensive suite covering both content- and report-level
quality, including coverage, presentation, citation accuracy and association,
consistency and depth of analysis. DeepEval integrates four complementary
evaluation protocols, each designed to ensure stable assessment and high
agreement with human judgments. Using LiveResearchBench and DeepEval, we
conduct a comprehensive evaluation of 17 frontier deep research systems,
including single-agent web search, single-agent deep research, and multi-agent
systems. Our analysis reveals current strengths, recurring failure modes, and
key system components needed to advance reliable, insightful deep research.

</details>


### [61] [Towards Agentic Self-Learning LLMs in Search Environment](https://arxiv.org/abs/2510.14253)
*Wangtao Sun,Xiang Cheng,Jialin Fan,Yao Xu,Xing Yu,Shizhu He,Jun Zhao,Kang Liu*

Main category: cs.AI

TL;DR: 本文提出Agentic Self-Learning (ASL)框架，通过多角色协同进化的强化学习实现无人工标注数据的智能体自我学习，证明生成奖励模型和任务数据规模是开放领域智能体学习的关键因素。


<details>
  <summary>Details</summary>
Motivation: 研究如何在不依赖人工标注数据集或预定义规则奖励的情况下，通过自我学习扩展基于LLM的智能体能力，解决开放领域智能体训练的可扩展性问题。

Method: 提出ASL框架，包含提示生成器、策略模型和生成奖励模型三个角色，在共享工具环境和LLM骨干网络中形成任务生成、策略执行和评估的闭环强化学习循环。

Result: ASL实现持续多轮性能提升，超越强基线方法，在零标注数据条件下继续改进，表现出优异的样本效率和鲁棒性。生成奖励模型的验证能力是主要瓶颈，持续训练可缓解奖励黑客问题。

Conclusion: 奖励来源和数据规模是开放领域智能体学习的关键杠杆，多角色协同进化是实现可扩展自我改进智能体的有效方法。

Abstract: We study whether self-learning can scale LLM-based agents without relying on
human-curated datasets or predefined rule-based rewards. Through controlled
experiments in a search-agent setting, we identify two key determinants of
scalable agent training: the source of reward signals and the scale of agent
task data. We find that rewards from a Generative Reward Model (GRM) outperform
rigid rule-based signals for open-domain learning, and that co-evolving the GRM
with the policy further boosts performance. Increasing the volume of agent task
data-even when synthetically generated-substantially enhances agentic
capabilities. Building on these insights, we propose \textbf{Agentic
Self-Learning} (ASL), a fully closed-loop, multi-role reinforcement learning
framework that unifies task generation, policy execution, and evaluation within
a shared tool environment and LLM backbone. ASL coordinates a Prompt Generator,
a Policy Model, and a Generative Reward Model to form a virtuous cycle of
harder task setting, sharper verification, and stronger solving. Empirically,
ASL delivers steady, round-over-round gains, surpasses strong RLVR baselines
(e.g., Search-R1) that plateau or degrade, and continues improving under
zero-labeled-data conditions, indicating superior sample efficiency and
robustness. We further show that GRM verification capacity is the main
bottleneck: if frozen, it induces reward hacking and stalls progress; continual
GRM training on the evolving data distribution mitigates this, and a small
late-stage injection of real verification data raises the performance ceiling.
This work establishes reward source and data scale as critical levers for
open-domain agent learning and demonstrates the efficacy of multi-role
co-evolution for scalable, self-improving agents. The data and code of this
paper are released at
https://github.com/forangel2014/Towards-Agentic-Self-Learning

</details>


### [62] [MorphoBench: A Benchmark with Difficulty Adaptive to Model Reasoning](https://arxiv.org/abs/2510.14265)
*Xukai Wang,Xuanbo Liu,Mingrui Chen,Haitian Zhong,Xuanlin Yang,Bohan Zeng,Jinbo Hu,Hao Liang,Junbo Niu,Xuchen Li,Ruitao Wu,Ruichuan An,Yang Shi,Liu Liu,Xu-Yao Zhang,Qiang Liu,Zhouchen Lin,Wentao Zhang,Bin Dong*

Main category: cs.AI

TL;DR: 提出了MorphoBench基准测试，用于评估大型模型的推理能力，能够根据模型能力动态调整问题难度，包含1300多个多学科测试问题。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试范围有限且缺乏灵活性，无法适应模型推理能力的演进，需要更全面有效的评估方法。

Method: 从现有基准和奥赛级竞赛中收集复杂推理问题，利用模型推理过程中的关键陈述自适应修改分析挑战，并使用仿真软件生成可动态调整难度的问题。

Result: 收集了1300多个测试问题，基于o3和GPT-5等模型的推理能力迭代调整了MorphoBench的难度。

Conclusion: MorphoBench提高了模型推理评估的全面性和有效性，为改进大型模型的推理能力和科学稳健性提供了可靠指导。

Abstract: With the advancement of powerful large-scale reasoning models, effectively
evaluating the reasoning capabilities of these models has become increasingly
important. However, existing benchmarks designed to assess the reasoning
abilities of large models tend to be limited in scope and lack the flexibility
to adapt their difficulty according to the evolving reasoning capacities of the
models. To address this, we propose MorphoBench, a benchmark that incorporates
multidisciplinary questions to evaluate the reasoning capabilities of large
models and can adjust and update question difficulty based on the reasoning
abilities of advanced models. Specifically, we curate the benchmark by
selecting and collecting complex reasoning questions from existing benchmarks
and sources such as Olympiad-level competitions. Additionally, MorphoBench
adaptively modifies the analytical challenge of questions by leveraging key
statements generated during the model's reasoning process. Furthermore, it
includes questions generated using simulation software, enabling dynamic
adjustment of benchmark difficulty with minimal resource consumption. We have
gathered over 1,300 test questions and iteratively adjusted the difficulty of
MorphoBench based on the reasoning capabilities of models such as o3 and GPT-5.
MorphoBench enhances the comprehensiveness and validity of model reasoning
evaluation, providing reliable guidance for improving both the reasoning
abilities and scientific robustness of large models. The code has been released
in https://github.com/OpenDCAI/MorphoBench.

</details>


### [63] [A Guardrail for Safety Preservation: When Safety-Sensitive Subspace Meets Harmful-Resistant Null-Space](https://arxiv.org/abs/2510.14301)
*Bingjie Zhang,Yibo Yang,Renzhe,Dandan Guo,Jindong Gu,Philip Torr,Bernard Ghanem*

Main category: cs.AI

TL;DR: GuardSpace是一个保护大语言模型在微调过程中安全对齐的框架，通过安全敏感子空间和抗有害空空间来维持预训练模型的安全行为。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在微调过程中容易丢失预训练的安全对齐行为，导致产生有害响应，需要一种方法来保护安全对齐。

Method: 使用协方差预条件奇异值分解将预训练权重分解为安全相关和安全无关组件，初始化低秩适配器时冻结安全相关组件，并构建空空间投影器限制适配器更新对有害提示的安全输出。

Result: 在多个下游任务上的实验表明，GuardSpace优于现有方法。对于Llama-2-7B-Chat在GSM8K上的微调，有害分数从14.4%降至3.6%，准确率从26.0%提升至28.0%。

Conclusion: GuardSpace框架能有效保护大语言模型在微调过程中的安全对齐，同时保持任务性能。

Abstract: Large language models (LLMs) have achieved remarkable success in diverse
tasks, yet their safety alignment remains fragile during adaptation. Even when
fine-tuning on benign data or with low-rank adaptation, pre-trained safety
behaviors are easily degraded, leading to harmful responses in the fine-tuned
models. To address this challenge, we propose GuardSpace, a guardrail framework
for preserving safety alignment throughout fine-tuning, composed of two key
components: a safety-sensitive subspace and a harmful-resistant null space.
First, we explicitly decompose pre-trained weights into safety-relevant and
safety-irrelevant components using covariance-preconditioned singular value
decomposition, and initialize low-rank adapters from the safety-irrelevant
ones, while freezing safety-relevant components to preserve their associated
safety mechanism. Second, we construct a null space projector that restricts
adapter updates from altering safe outputs on harmful prompts, thereby
maintaining the original refusal behavior. Experiments with various pre-trained
models on multiple downstream tasks demonstrate that GuardSpace achieves
superior performance over existing methods. Notably, for Llama-2-7B-Chat
fine-tuned on GSM8K, GuardSpace outperforms the state-of-the-art method AsFT,
reducing the average harmful score from 14.4% to 3.6%, while improving the
accuracy from from 26.0% to 28.0%.

</details>


### [64] [Terrarium: Revisiting the Blackboard for Multi-Agent Safety, Privacy, and Security Studies](https://arxiv.org/abs/2510.14312)
*Mason Nakamura,Abhinav Kumar,Saaduddin Mahmud,Sahar Abdelnabi,Shlomo Zilberstein,Eugene Bagdasarian*

Main category: cs.AI

TL;DR: 提出了Terrarium框架，用于研究基于LLM的多智能体系统中的安全、隐私和安全问题，通过模块化测试床识别关键攻击向量并演示防御方案。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的多智能体系统虽然能自动化复杂任务，但引入了新的风险，包括错位、恶意方攻击、数据窃取等安全问题。

Method: 重新利用黑板设计构建模块化、可配置的多智能体协作测试床，识别关键攻击向量并实现三种协作场景和四种代表性攻击。

Result: 开发了Terrarium框架，能够快速原型化、评估和迭代防御方案，展示了框架的灵活性。

Conclusion: Terrarium框架旨在加速可信多智能体系统的进展，为安全研究提供有效工具。

Abstract: A multi-agent system (MAS) powered by large language models (LLMs) can
automate tedious user tasks such as meeting scheduling that requires
inter-agent collaboration. LLMs enable nuanced protocols that account for
unstructured private data, user constraints, and preferences. However, this
design introduces new risks, including misalignment and attacks by malicious
parties that compromise agents or steal user data. In this paper, we propose
the Terrarium framework for fine-grained study on safety, privacy, and security
in LLM-based MAS. We repurpose the blackboard design, an early approach in
multi-agent systems, to create a modular, configurable testbed for multi-agent
collaboration. We identify key attack vectors such as misalignment, malicious
agents, compromised communication, and data poisoning. We implement three
collaborative MAS scenarios with four representative attacks to demonstrate the
framework's flexibility. By providing tools to rapidly prototype, evaluate, and
iterate on defenses and designs, Terrarium aims to accelerate progress toward
trustworthy multi-agent systems.

</details>


### [65] [Metacognitive Self-Correction for Multi-Agent System via Prototype-Guided Next-Execution Reconstruction](https://arxiv.org/abs/2510.14319)
*Xu Shen,Qi Zhang,Song Wang,Zhen Tan,Xinyu Zhao,Laura Yao,Vaishnav Tadiparthi,Hossein Nourkhiz Mahjoub,Ehsan Moradi Pari,Kwonjoon Lee,Tianlong Chen*

Main category: cs.AI

TL;DR: MASC是一个元认知框架，通过实时无监督的步骤级错误检测和自我纠正来增强多智能体系统的鲁棒性，防止错误级联传播。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在协作解决问题方面表现出色，但对级联错误很脆弱：单个错误步骤可能跨智能体传播并破坏整个轨迹。

Method: MASC采用两种互补设计：(1) 下一执行重构，从查询和交互历史预测下一步的嵌入以捕捉因果一致性；(2) 原型引导增强，学习正常步骤嵌入的原型先验，在稀疏上下文下稳定重构和异常评分。

Result: 在Who&When基准测试中，MASC始终优于所有基线，步骤级错误检测的AUC-ROC提升高达8.47%；在不同MAS框架中都能带来一致的端到端性能提升。

Conclusion: 元认知监控和针对性纠正能够以最小开销减轻错误传播，证实了该框架的有效性和通用性。

Abstract: Large Language Model based multi-agent systems (MAS) excel at collaborative
problem solving but remain brittle to cascading errors: a single faulty step
can propagate across agents and disrupt the trajectory. In this paper, we
present MASC, a metacognitive framework that endows MAS with real-time,
unsupervised, step-level error detection and self-correction. MASC rethinks
detection as history-conditioned anomaly scoring via two complementary designs:
(1) Next-Execution Reconstruction, which predicts the embedding of the next
step from the query and interaction history to capture causal consistency, and
(2) Prototype-Guided Enhancement, which learns a prototype prior over
normal-step embeddings and uses it to stabilize reconstruction and anomaly
scoring under sparse context (e.g., early steps). When an anomaly step is
flagged, MASC triggers a correction agent to revise the acting agent's output
before information flows downstream. On the Who&When benchmark, MASC
consistently outperforms all baselines, improving step-level error detection by
up to 8.47% AUC-ROC ; When plugged into diverse MAS frameworks, it delivers
consistent end-to-end gains across architectures, confirming that our
metacognitive monitoring and targeted correction can mitigate error propagation
with minimal overhead.

</details>


### [66] [AI for Service: Proactive Assistance with AI Glasses](https://arxiv.org/abs/2510.14359)
*Zichen Wen,Yiyu Wang,Chenfei Liao,Boxue Yang,Junxian Li,Weifeng Liu,Haocong He,Bolong Feng,Xuyang Liu,Yuanhuiyi Lyu,Xu Zheng,Xuming Hu,Linfeng Zhang*

Main category: cs.AI

TL;DR: 提出AI4Service新范式，通过Alpha-Service框架实现主动式AI服务，解决"何时介入"和"如何服务"两大挑战，基于AI眼镜实现环境感知和个性化服务。


<details>
  <summary>Details</summary>
Motivation: 现有AI服务多为被动响应，需要用户明确指令。作者认为真正智能的助手应能主动预测用户需求并在适当时机采取行动。

Method: 提出Alpha-Service统一框架，受冯·诺依曼架构启发，包含输入单元、中央处理单元、算术逻辑单元、内存单元和输出单元五个组件，通过多智能体系统在AI眼镜上实现。

Result: 案例研究包括实时21点顾问、博物馆导游和购物搭配助手，展示了系统能够无缝感知环境、推断用户意图，并在无需明确提示的情况下提供及时有用的帮助。

Conclusion: AI4Service范式将AI从被动工具转变为主动伴侣，Alpha-Service框架为实现这一愿景提供了可行的技术路径。

Abstract: In an era where AI is evolving from a passive tool into an active and
adaptive companion, we introduce AI for Service (AI4Service), a new paradigm
that enables proactive and real-time assistance in daily life. Existing AI
services remain largely reactive, responding only to explicit user commands. We
argue that a truly intelligent and helpful assistant should be capable of
anticipating user needs and taking actions proactively when appropriate. To
realize this vision, we propose Alpha-Service, a unified framework that
addresses two fundamental challenges: Know When to intervene by detecting
service opportunities from egocentric video streams, and Know How to provide
both generalized and personalized services. Inspired by the von Neumann
computer architecture and based on AI glasses, Alpha-Service consists of five
key components: an Input Unit for perception, a Central Processing Unit for
task scheduling, an Arithmetic Logic Unit for tool utilization, a Memory Unit
for long-term personalization, and an Output Unit for natural human
interaction. As an initial exploration, we implement Alpha-Service through a
multi-agent system deployed on AI glasses. Case studies, including a real-time
Blackjack advisor, a museum tour guide, and a shopping fit assistant,
demonstrate its ability to seamlessly perceive the environment, infer user
intent, and provide timely and useful assistance without explicit prompts.

</details>


### [67] [Can MLLMs Absorb Math Reasoning Abilities from LLMs as Free Lunch?](https://arxiv.org/abs/2510.14387)
*Yijie Hu,Zihao Zhou,Kaizhu Huang,Xiaowei Huang,Qiufeng Wang*

Main category: cs.AI

TL;DR: 本文提出IP-Merging方法，无需调优即可将数学推理能力从数学LLM直接迁移到多模态LLM，解决了参数空间不对齐的问题。


<details>
  <summary>Details</summary>
Motivation: 目前多模态LLM的数学推理能力落后于纯文本LLM，但直接使用模型融合方法会因参数空间不对齐而导致性能下降。

Method: IP-Merging方法：识别MLLM和数学LLM中的推理相关参数，将其投影到MLLM子空间，然后在该子空间内合并参数。

Result: 实验证明IP-Merging能有效提升MLLM的数学推理能力，且不损害其他能力。

Conclusion: IP-Merging是一种无需调优的方法，能成功将数学推理能力从数学LLM迁移到MLLM，解决了参数空间对齐问题。

Abstract: Math reasoning has been one crucial ability of large language models (LLMs),
where significant advancements have been achieved in recent years. However,
most efforts focus on LLMs by curating high-quality annotation data and
intricate training (or inference) paradigms, while the math reasoning
performance of multi-modal LLMs (MLLMs) remains lagging behind. Since the MLLM
typically consists of an LLM and a vision block, we wonder: Can MLLMs directly
absorb math reasoning abilities from off-the-shelf math LLMs without tuning?
Recent model-merging approaches may offer insights into this question. However,
they overlook the alignment between the MLLM and LLM, where we find that there
is a large gap between their parameter spaces, resulting in lower performance.
Our empirical evidence reveals two key factors behind this issue: the
identification of crucial reasoning-associated layers in the model and the
mitigation of the gaps in parameter space. Based on the empirical insights, we
propose IP-Merging that first identifies the reasoning-associated parameters in
both MLLM and Math LLM, then projects them into the subspace of MLLM, aiming to
maintain the alignment, and finally merges parameters in this subspace.
IP-Merging is a tuning-free approach since parameters are directly adjusted.
Extensive experiments demonstrate that our IP-Merging method can enhance the
math reasoning ability of MLLMs directly from Math LLMs without compromising
their other capabilities.

</details>


### [68] [Hi-Agent: Hierarchical Vision-Language Agents for Mobile Device Control](https://arxiv.org/abs/2510.14388)
*Zhe Wu,Hongjin Lu,Junliang Xing,Changhao Zhang,Yin Zhu,Yuhao Yang,Yuheng Jing,Kai Li,Kun Shao,Jianye Hao,Jun Wang,Yuanchun Shi*

Main category: cs.AI

TL;DR: Hi-Agent是一个可训练的分层视觉语言代理，用于移动设备控制，通过高层推理模型和低层动作模型的联合优化，在Android-in-the-Wild基准测试中达到87.9%的任务成功率，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型的移动设备控制方法大多依赖直接的状态-动作映射，缺乏结构化推理和规划，导致在新任务或未见UI布局上泛化能力差。

Method: 提出分层架构：高层推理模型和低层动作模型联合优化。将多步决策重新表述为单步子目标序列，并提出前瞻优势函数，利用低层模型的执行反馈指导高层优化，缓解GRPO在长视野任务中的路径爆炸问题。

Result: 在Android-in-the-Wild基准测试中达到SOTA 87.9%任务成功率，显著优于提示型(17.7%)、监督学习(54.5%)和强化学习(71.9%)方法。在ScreenSpot-v2上展示竞争性零样本泛化能力，在AndroidWorld上随骨干网络增大而有效扩展。

Conclusion: Hi-Agent的分层设计和联合优化方法在移动设备控制任务中表现出色，解决了现有方法的泛化问题，并在多个基准测试中取得显著性能提升。

Abstract: Building agents that autonomously operate mobile devices has attracted
increasing attention. While Vision-Language Models (VLMs) show promise, most
existing approaches rely on direct state-to-action mappings, which lack
structured reasoning and planning, and thus generalize poorly to novel tasks or
unseen UI layouts. We introduce Hi-Agent, a trainable hierarchical
vision-language agent for mobile control, featuring a high-level reasoning
model and a low-level action model that are jointly optimized. For efficient
training, we reformulate multi-step decision-making as a sequence of
single-step subgoals and propose a foresight advantage function, which
leverages execution feedback from the low-level model to guide high-level
optimization. This design alleviates the path explosion issue encountered by
Group Relative Policy Optimization (GRPO) in long-horizon tasks and enables
stable, critic-free joint training. Hi-Agent achieves a new State-Of-The-Art
(SOTA) 87.9% task success rate on the Android-in-the-Wild (AitW) benchmark,
significantly outperforming prior methods across three paradigms: prompt-based
(AppAgent: 17.7%), supervised (Filtered BC: 54.5%), and reinforcement
learning-based (DigiRL: 71.9%). It also demonstrates competitive zero-shot
generalization on the ScreenSpot-v2 benchmark. On the more challenging
AndroidWorld benchmark, Hi-Agent also scales effectively with larger backbones,
showing strong adaptability in high-complexity mobile control scenarios.

</details>


### [69] [IMAGINE: Integrating Multi-Agent System into One Model for Complex Reasoning and Planning](https://arxiv.org/abs/2510.14406)
*Xikai Zhang,Bo Wang,Likang Xiao,Yongzhi Li,Quan Chen,Wenju Wu,Liu Liu*

Main category: cs.AI

TL;DR: 提出了IMAGINE框架，将多智能体系统的推理规划能力集成到单一紧凑模型中，通过端到端训练显著超越多智能体系统性能，在TravelPlanner基准上达到82.7%的最终通过率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂推理和规划任务中仍面临挑战，现有多智能体系统虽然能提供改进的集体推理，但存在推理成本高、响应延迟长和端到端训练困难等问题。

Method: 提出IMAGINE框架，将多智能体系统的推理规划能力集成到单一紧凑模型中，通过简单的端到端训练实现能力提升。

Result: 使用Qwen3-8B-Instruct作为基础模型，在TravelPlanner基准上达到82.7%的最终通过率，远超DeepSeek-R1-671B的40%，同时保持更小的模型规模。

Conclusion: IMAGINE框架成功将多智能体系统的能力集成到单一模型中，不仅获得了结构化推理和规划能力，还显著超越了多智能体系统的性能，同时解决了推理成本和训练困难的问题。

Abstract: Although large language models (LLMs) have made significant strides across
various tasks, they still face significant challenges in complex reasoning and
planning. For example, even with carefully designed prompts and prior
information explicitly provided, GPT-4o achieves only a 7% Final Pass Rate on
the TravelPlanner dataset in the sole-planning mode. Similarly, even in the
thinking mode, Qwen3-8B-Instruct and DeepSeek-R1-671B, only achieve Final Pass
Rates of 5.9% and 40%, respectively. Although well-organized Multi-Agent
Systems (MAS) can offer improved collective reasoning, they often suffer from
high reasoning costs due to multi-round internal interactions, long
per-response latency, and difficulties in end-to-end training. To address these
challenges, we propose a general and scalable framework called IMAGINE, short
for Integrating Multi-Agent System into One Model. This framework not only
integrates the reasoning and planning capabilities of MAS into a single,
compact model, but also significantly surpass the capabilities of the MAS
through a simple end-to-end training. Through this pipeline, a single
small-scale model is not only able to acquire the structured reasoning and
planning capabilities of a well-organized MAS but can also significantly
outperform it. Experimental results demonstrate that, when using
Qwen3-8B-Instruct as the base model and training it with our method, the model
achieves an 82.7% Final Pass Rate on the TravelPlanner benchmark, far exceeding
the 40% of DeepSeek-R1-671B, while maintaining a much smaller model size.

</details>


### [70] [Eliminating Negative Occurrences of Derived Predicates from PDDL Axioms](https://arxiv.org/abs/2510.14412)
*Claudia Grundke,Gabriele Röger*

Main category: cs.AI

TL;DR: 本文提出了一种转换方法，用于消除PDDL公理中派生谓词的负出现，证明这种限制实际上不会减少表达能力。


<details>
  <summary>Details</summary>
Motivation: PDDL标准限制公理体中谓词的负出现只能针对直接由动作设置的谓词，而非由公理派生的谓词。然而文献中常偏离此限制，仅要求公理集可分层。本文旨在证明这两种变体实际上表达能力相同。

Method: 提出了一种转换方法，通过消除公理中派生谓词的负出现，将包含此类负出现的公理集转换为符合PDDL标准限制的形式。

Result: 证明了包含派生谓词负出现的公理集与符合PDDL标准限制的公理集在表达能力上是等价的，两者都能表达与最小不动点逻辑相同的查询。

Conclusion: PDDL标准对公理中派生谓词负出现的限制实际上不会减少其表达能力，因为可以通过转换方法消除这些负出现，从而与更宽松的分层要求达到相同的表达能力。

Abstract: Axioms are a feature of the Planning Domain Definition Language PDDL that can
be considered as a generalization of database query languages such as Datalog.
The PDDL standard restricts negative occurrences of predicates in axiom bodies
to predicates that are directly set by actions and not derived by axioms. In
the literature, authors often deviate from this limitation and only require
that the set of axioms is stratifiable. Both variants can express exactly the
same queries as least fixed-point logic, indicating that negative occurrences
of derived predicates can be eliminated. We present the corresponding
transformation.

</details>


### [71] [Helmsman: Autonomous Synthesis of Federated Learning Systems via Multi-Agent Collaboration](https://arxiv.org/abs/2510.14512)
*Haoyuan Li,Mathias Funk,Aaqib Saeed*

Main category: cs.AI

TL;DR: Helmsman是一个多智能体系统，通过模拟研发工作流程自动合成联邦学习系统，包括交互式规划、模块化代码生成和自主评估优化，在AgentFL-Bench基准测试中表现优于人工设计的基线方法。


<details>
  <summary>Details</summary>
Motivation: 联邦学习系统设计复杂，需要处理数据异构性和系统约束等多方面挑战，导致解决方案脆弱且定制化，阻碍了实际部署。

Method: 采用三阶段多智能体协作：1)人机交互规划制定研究计划；2)监督智能体团队进行模块化代码生成；3)在沙盒模拟环境中进行自主评估和优化的闭环流程。

Result: 在包含16个多样化任务的AgentFL-Bench基准测试中，Helmsman生成的解决方案与手工设计的基线方法相当甚至更优。

Conclusion: 这项工作代表了向复杂去中心化AI系统自动化工程迈出的重要一步。

Abstract: Federated Learning (FL) offers a powerful paradigm for training models on
decentralized data, but its promise is often undermined by the immense
complexity of designing and deploying robust systems. The need to select,
combine, and tune strategies for multifaceted challenges like data
heterogeneity and system constraints has become a critical bottleneck,
resulting in brittle, bespoke solutions. To address this, we introduce
Helmsman, a novel multi-agent system that automates the end-to-end synthesis of
federated learning systems from high-level user specifications. It emulates a
principled research and development workflow through three collaborative
phases: (1) interactive human-in-the-loop planning to formulate a sound
research plan, (2) modular code generation by supervised agent teams, and (3) a
closed-loop of autonomous evaluation and refinement in a sandboxed simulation
environment. To facilitate rigorous evaluation, we also introduce
AgentFL-Bench, a new benchmark comprising 16 diverse tasks designed to assess
the system-level generation capabilities of agentic systems in FL. Extensive
experiments demonstrate that our approach generates solutions competitive with,
and often superior to, established hand-crafted baselines. Our work represents
a significant step towards the automated engineering of complex decentralized
AI systems.

</details>


### [72] [JSPLIT: A Taxonomy-based Solution for Prompt Bloating in Model Context Protocol](https://arxiv.org/abs/2510.14537)
*Emanuele Antonioni,Stefan Markovic,Anirudha Shankar,Jaime Bernardo,Lovro Markovic,Silvia Pareti,Benedetto Proietti*

Main category: cs.AI

TL;DR: JSPLIT是一个基于分类学的框架，用于解决大型语言模型使用MCP工具时提示词膨胀的问题，通过分层分类和工具选择算法显著减少提示词大小，同时提高工具选择准确性。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统发展，用户期望增加，需要LLM与外部工具交互。MCP等标准使代理能访问工具，但随着工具数量增加，提示词变得冗长，导致高令牌成本、延迟增加和任务成功率降低。

Method: JSPLIT将工具组织成层次化分类学，使用用户提示基于查询和分类结构识别并仅包含最相关工具，包括分类设计、工具选择算法和评估数据集。

Result: JSPLIT显著减少了提示词大小，同时不显著影响代理的有效响应能力。当可用工具数量大幅增加时，JSPLIT甚至提高了代理的工具选择准确性，有效降低成本并提高高复杂度环境中的任务成功率。

Conclusion: JSPLIT框架通过分类学驱动的方法有效管理提示词大小，在工具数量增加时既能降低成本又能提高任务成功率，适用于高复杂度代理环境。

Abstract: AI systems are continually evolving and advancing, and user expectations are
concurrently increasing, with a growing demand for interactions that go beyond
simple text-based interaction with Large Language Models (LLMs). Today's
applications often require LLMs to interact with external tools, marking a
shift toward more complex agentic systems. To support this, standards such as
the Model Context Protocol (MCP) have emerged, enabling agents to access tools
by including a specification of the capabilities of each tool within the
prompt. Although this approach expands what agents can do, it also introduces a
growing problem: prompt bloating. As the number of tools increases, the prompts
become longer, leading to high prompt token costs, increased latency, and
reduced task success resulting from the selection of tools irrelevant to the
prompt. To address this issue, we introduce JSPLIT, a taxonomy-driven framework
designed to help agents manage prompt size more effectively when using large
sets of MCP tools. JSPLIT organizes the tools into a hierarchical taxonomy and
uses the user's prompt to identify and include only the most relevant tools,
based on both the query and the taxonomy structure. In this paper, we describe
the design of the taxonomy, the tool selection algorithm, and the dataset used
to evaluate JSPLIT. Our results show that JSPLIT significantly reduces prompt
size without significantly compromising the agent's ability to respond
effectively. As the number of available tools for the agent grows
substantially, JSPLIT even improves the tool selection accuracy of the agent,
effectively reducing costs while simultaneously improving task success in
high-complexity agent environments.

</details>


### [73] [Symbol Grounding in Neuro-Symbolic AI: A Gentle Introduction to Reasoning Shortcuts](https://arxiv.org/abs/2510.14538)
*Emanuele Marconato,Samuele Bortolotti,Emile van Krieken,Paolo Morettin,Elena Umili,Antonio Vergari,Efthymia Tsamoura,Andrea Passerini,Stefano Teso*

Main category: cs.AI

TL;DR: 本文综述了神经符号AI中的推理捷径问题，讨论了其成因、后果及应对方法，旨在为开发可靠的神经符号AI模型提供统一视角。


<details>
  <summary>Details</summary>
Motivation: 神经符号AI模型在概念未直接监督时容易出现推理捷径，这会损害模型解释性、分布外性能和可靠性。现有文献分散，需要系统梳理来帮助研究人员理解和解决这一问题。

Method: 通过直观术语介绍推理捷径的成因和后果，回顾现有理论特征，详细分析应对推理捷径的方法（包括缓解和意识策略），并评估各种方法的优缺点。

Result: 提供了推理捷径的统一视角，系统梳理了相关理论和方法，使这一复杂问题更易理解，为开发可靠的神经符号AI模型奠定了基础。

Conclusion: 本文通过重新表述高级材料使其易于消化，降低了处理推理捷径问题的门槛，有望促进可靠神经符号AI和可信AI模型的发展。

Abstract: Neuro-symbolic (NeSy) AI aims to develop deep neural networks whose
predictions comply with prior knowledge encoding, e.g. safety or structural
constraints. As such, it represents one of the most promising avenues for
reliable and trustworthy AI. The core idea behind NeSy AI is to combine neural
and symbolic steps: neural networks are typically responsible for mapping
low-level inputs into high-level symbolic concepts, while symbolic reasoning
infers predictions compatible with the extracted concepts and the prior
knowledge. Despite their promise, it was recently shown that - whenever the
concepts are not supervised directly - NeSy models can be affected by Reasoning
Shortcuts (RSs). That is, they can achieve high label accuracy by grounding the
concepts incorrectly. RSs can compromise the interpretability of the model's
explanations, performance in out-of-distribution scenarios, and therefore
reliability. At the same time, RSs are difficult to detect and prevent unless
concept supervision is available, which is typically not the case. However, the
literature on RSs is scattered, making it difficult for researchers and
practitioners to understand and tackle this challenging problem. This overview
addresses this issue by providing a gentle introduction to RSs, discussing
their causes and consequences in intuitive terms. It also reviews and
elucidates existing theoretical characterizations of this phenomenon. Finally,
it details methods for dealing with RSs, including mitigation and awareness
strategies, and maps their benefits and limitations. By reformulating advanced
material in a digestible form, this overview aims to provide a unifying
perspective on RSs to lower the bar to entry for tackling them. Ultimately, we
hope this overview contributes to the development of reliable NeSy and
trustworthy AI models.

</details>


### [74] [LLM Agents Beyond Utility: An Open-Ended Perspective](https://arxiv.org/abs/2510.14548)
*Asen Nachkov,Xi Wang,Luc Van Gool*

Main category: cs.AI

TL;DR: 研究探讨了预训练LLM代理能否通过自主生成任务、积累知识和环境交互，从智能工具发展为具有自主规划能力的实体。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理能力增强，研究其是否能成为具有自主规划、任务设计和模糊目标推理能力的独立实体。

Method: 采用开放式实验设置，增强预训练LLM代理的能力，使其能够自主生成任务、积累知识并广泛与环境互动。

Result: 代理能够可靠执行复杂多步骤指令，跨运行存储和重用信息，自主提出和解决任务，但对提示设计敏感，容易重复生成任务，无法形成自我表征。

Conclusion: 研究展示了预训练LLM向开放式发展的潜力和当前局限，为未来训练代理管理记忆、有效探索和追求抽象长期目标指明了方向。

Abstract: Recent LLM agents have made great use of chain of thought reasoning and
function calling. As their capabilities grow, an important question arises: can
this software represent not only a smart problem-solving tool, but an entity in
its own right, that can plan, design immediate tasks, and reason toward
broader, more ambiguous goals? To study this question, we adopt an open-ended
experimental setting where we augment a pretrained LLM agent with the ability
to generate its own tasks, accumulate knowledge, and interact extensively with
its environment. We study the resulting open-ended agent qualitatively. It can
reliably follow complex multi-step instructions, store and reuse information
across runs, and propose and solve its own tasks, though it remains sensitive
to prompt design, prone to repetitive task generation, and unable to form
self-representations. These findings illustrate both the promise and current
limits of adapting pretrained LLMs toward open-endedness, and point to future
directions for training agents to manage memory, explore productively, and
pursue abstract long-term goals.

</details>


### [75] [ColorBench: Benchmarking Mobile Agents with Graph-Structured Framework for Complex Long-Horizon Tasks](https://arxiv.org/abs/2510.14621)
*Yuanyi Song,Heyuan Huang,Qiqiang Lin,Yin Zhao,Xiangmou Qu,Jun Wang,Xingyu Lou,Weiwen Liu,Zhuosheng Zhang,Jun Wang,Yong Yu,Weinan Zhang,Zhaoxiang Wang*

Main category: cs.AI

TL;DR: 本文提出了ColorBench，一个基于图结构的移动代理评估基准，专注于复杂长时程任务，支持多有效解决方案评估和原子级能力分析。


<details>
  <summary>Details</summary>
Motivation: 现有移动代理评估方法存在局限：离线静态基准只能验证单一预设路径，而在线动态测试受限于真实设备的复杂性和不可重现性。需要一种能桥接离线与在线评估的稳定测试框架。

Method: 开发了图结构基准框架，通过建模真实设备交互中的有限状态实现动态行为的静态模拟。构建了包含175个任务（74个单应用、101个跨应用）的ColorBench基准，每个任务包含至少两条正确路径和典型错误路径。

Result: ColorBench平均任务长度超过13步，支持多有效解决方案评估、子任务完成率统计和原子级能力分析。通过评估发现现有模型的局限性，并基于实验结果提出了改进方向。

Conclusion: ColorBench提供了一种稳定、可重现的评估框架，能够全面评估移动代理在复杂长时程任务中的能力，为模型改进提供了可行技术路径。

Abstract: The rapid advancement of multimodal large language models has enabled agents
to operate mobile devices by directly interacting with graphical user
interfaces, opening new possibilities for mobile automation. However,
real-world mobile tasks are often complex and allow for multiple valid
solutions. This contradicts current mobile agent evaluation standards: offline
static benchmarks can only validate a single predefined "golden path", while
online dynamic testing is constrained by the complexity and non-reproducibility
of real devices, making both approaches inadequate for comprehensively
assessing agent capabilities. To bridge the gap between offline and online
evaluation and enhance testing stability, this paper introduces a novel
graph-structured benchmarking framework. By modeling the finite states observed
during real-device interactions, it achieves static simulation of dynamic
behaviors. Building on this, we develop ColorBench, a benchmark focused on
complex long-horizon tasks. It supports evaluation of multiple valid solutions,
subtask completion rate statistics, and atomic-level capability analysis.
ColorBench contains 175 tasks (74 single-app, 101 cross-app) with an average
length of over 13 steps. Each task includes at least two correct paths and
several typical error paths, enabling quasi-dynamic interaction. By evaluating
ColorBench across various baselines, we discover limitations of existing models
and propose improvement directions and feasible technical pathways to enhance
agents' performance on complex, long-horizon problems based on experimental
results. Code and data are available at:
https://github.com/MadeAgents/ColorBench.

</details>


### [76] [Beyond Hallucinations: The Illusion of Understanding in Large Language Models](https://arxiv.org/abs/2510.14665)
*Rikard Rosenbacke,Carl Rosenbacke,Victor Rosenbacke,Martin McKee*

Main category: cs.AI

TL;DR: 本文提出了Rose-Frame框架，用于诊断人机交互中的认知和认识论漂移，通过三个维度（地图vs领土、直觉vs理性、冲突vs确认）来增强AI部署的透明度和批判意识。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然流畅且情感共鸣强，但基于统计预测而非有根据的推理，存在幻觉风险，可能产生听起来令人信服但缺乏事实有效性的回答。

Method: 引入Rose-Frame三维框架：(i)地图vs领土，区分现实表征与现实本身；(ii)直觉vs理性，基于双过程理论分离快速情感判断与慢速反思思维；(iii)冲突vs确认，检验观点是否通过分歧进行批判性测试还是仅通过相互验证强化。

Result: Rose-Frame提供了一个反思工具，使模型的局限性和用户的假设可见，实现更透明和批判性意识强的AI部署。

Conclusion: 将对齐重新定义为认知治理：无论是人类还是人工智能的直觉，都必须受到人类理性的治理。只有通过嵌入反思性、可证伪的监督，才能将机器的流畅性与人类的理解对齐。

Abstract: Large language models (LLMs) are becoming deeply embedded in human
communication and decision-making, yet they inherit the ambiguity, bias, and
lack of direct access to truth inherent in language itself. While their outputs
are fluent, emotionally resonant, and coherent, they are generated through
statistical prediction rather than grounded reasoning. This creates the risk of
hallucination, responses that sound convincing but lack factual validity.
Building on Geoffrey Hinton's observation that AI mirrors human intuition
rather than reasoning, this paper argues that LLMs operationalize System 1
cognition at scale: fast, associative, and persuasive, but without reflection
or falsification. To address this, we introduce the Rose-Frame, a
three-dimensional framework for diagnosing cognitive and epistemic drift in
human-AI interaction. The three axes are: (i) Map vs. Territory, which
distinguishes representations of reality (epistemology) from reality itself
(ontology); (ii) Intuition vs. Reason, drawing on dual-process theory to
separate fast, emotional judgments from slow, reflective thinking; and (iii)
Conflict vs. Confirmation, which examines whether ideas are critically tested
through disagreement or simply reinforced through mutual validation. Each
dimension captures a distinct failure mode, and their combination amplifies
misalignment. Rose-Frame does not attempt to fix LLMs with more data or rules.
Instead, it offers a reflective tool that makes both the model's limitations
and the user's assumptions visible, enabling more transparent and critically
aware AI deployment. It reframes alignment as cognitive governance: intuition,
whether human or artificial, must remain governed by human reason. Only by
embedding reflective, falsifiable oversight can we align machine fluency with
human understanding.

</details>


### [77] [Machine Learning and Public Health: Identifying and Mitigating Algorithmic Bias through a Systematic Review](https://arxiv.org/abs/2510.14669)
*Sara Altamirano,Arjan Vreeken,Sennay Ghebreab*

Main category: cs.AI

TL;DR: 系统综述荷兰公共卫生机器学习研究中算法偏见的识别、讨论和报告情况，开发了RABAT评估工具并应用于35项研究，揭示了公平性框架和子群分析等方面的普遍缺失，提出了ACAR四阶段公平导向框架。


<details>
  <summary>Details</summary>
Motivation: 机器学习在公共卫生领域的应用可能无意中加剧现有健康不平等，需要系统关注算法偏见问题。

Method: 开发RABAT评估工具整合现有框架，对2011-2025年荷兰公共卫生ML研究进行系统文献综述，分析35项同行评审研究。

Result: 发现普遍存在公平性框架缺失、子群分析不足、潜在危害讨论不透明等问题，尽管数据抽样和缺失数据处理记录良好。

Conclusion: 提出ACAR四阶段框架和具体建议，帮助公共卫生ML从业者系统考虑算法偏见，确保算法创新促进而非损害健康公平。

Abstract: Machine learning (ML) promises to revolutionize public health through
improved surveillance, risk stratification, and resource allocation. However,
without systematic attention to algorithmic bias, ML may inadvertently
reinforce existing health disparities. We present a systematic literature
review of algorithmic bias identification, discussion, and reporting in Dutch
public health ML research from 2021 to 2025. To this end, we developed the Risk
of Algorithmic Bias Assessment Tool (RABAT) by integrating elements from
established frameworks (Cochrane Risk of Bias, PROBAST, Microsoft Responsible
AI checklist) and applied it to 35 peer-reviewed studies. Our analysis reveals
pervasive gaps: although data sampling and missing data practices are well
documented, most studies omit explicit fairness framing, subgroup analyses, and
transparent discussion of potential harms. In response, we introduce a
four-stage fairness-oriented framework called ACAR (Awareness,
Conceptualization, Application, Reporting), with guiding questions derived from
our systematic literature review to help researchers address fairness across
the ML lifecycle. We conclude with actionable recommendations for public health
ML practitioners to consistently consider algorithmic bias and foster
transparency, ensuring that algorithmic innovations advance health equity
rather than undermine it.

</details>


### [78] [TITAN: Graph-Executable Reasoning for Cyber Threat Intelligence](https://arxiv.org/abs/2510.14670)
*Marco Simoni,Aleksandar Fontana,Andrea Saracino,Paolo Mori*

Main category: cs.AI

TL;DR: TITAN是一个将自然语言网络安全威胁查询与结构化知识图谱上的可执行推理相连接的框架，包含路径规划模型和图执行器，支持在威胁、行为和防御之间进行清晰可逆的推理。


<details>
  <summary>Details</summary>
Motivation: 传统检索系统无法有效处理网络安全威胁查询的复杂推理需求，需要一种能够连接自然语言查询与结构化知识图谱推理的方法。

Method: 集成路径规划模型预测逻辑关系链，图执行器遍历TITAN本体图检索事实答案和证据，基于MITRE构建类型化双向图支持可逆推理。

Result: 创建了包含88209个示例的TITAN数据集，实证评估显示模型能生成语法有效、语义连贯的可执行推理路径。

Conclusion: TITAN框架成功实现了自然语言威胁查询与结构化知识图谱推理的有效连接，为网络安全威胁情报分析提供了新方法。

Abstract: TITAN (Threat Intelligence Through Automated Navigation) is a framework that
connects natural-language cyber threat queries with executable reasoning over a
structured knowledge graph. It integrates a path planner model, which predicts
logical relation chains from text, and a graph executor that traverses the
TITAN Ontology to retrieve factual answers and supporting evidence. Unlike
traditional retrieval systems, TITAN operates on a typed, bidirectional graph
derived from MITRE, allowing reasoning to move clearly and reversibly between
threats, behaviors, and defenses. To support training and evaluation, we
introduce the TITAN Dataset, a corpus of 88209 examples (Train: 74258; Test:
13951) pairing natural language questions with executable reasoning paths and
step by step Chain of Thought explanations. Empirical evaluations show that
TITAN enables models to generate syntactically valid and semantically coherent
reasoning paths that can be deterministically executed on the underlying graph.

</details>


### [79] [NAEL: Non-Anthropocentric Ethical Logic](https://arxiv.org/abs/2510.14676)
*Bianca Maria Lerma,Rafael Peñaloza*

Main category: cs.AI

TL;DR: 提出NAEL（非人类中心伦理逻辑）框架，基于主动推理和符号推理，为人工智能代理建立非人类中心的伦理系统，将伦理行为形式化为智能系统在动态多代理环境中最小化全局期望自由能量的涌现特性。


<details>
  <summary>Details</summary>
Motivation: 传统AI伦理方法过于人类中心化，现有伦理模型存在局限性，需要开发能够在不预设人类道德直觉的情况下产生上下文敏感、自适应和关系性伦理行为的系统。

Method: 采用神经符号架构，结合主动推理和符号推理，使代理能够在不确定环境中评估其行为的伦理后果，通过最小化全局期望自由能量来驱动伦理决策。

Result: 通过伦理资源分配的案例研究展示了NAEL能够动态平衡自我保存、认知学习和集体福利，证明了框架的有效性。

Conclusion: NAEL为开发具有适应性伦理行为的人工智能系统提供了可行的非人类中心框架，能够克服现有伦理模型的局限性。

Abstract: We introduce NAEL (Non-Anthropocentric Ethical Logic), a novel ethical
framework for artificial agents grounded in active inference and symbolic
reasoning. Departing from conventional, human-centred approaches to AI ethics,
NAEL formalizes ethical behaviour as an emergent property of intelligent
systems minimizing global expected free energy in dynamic, multi-agent
environments. We propose a neuro-symbolic architecture to allow agents to
evaluate the ethical consequences of their actions in uncertain settings. The
proposed system addresses the limitations of existing ethical models by
allowing agents to develop context-sensitive, adaptive, and relational ethical
behaviour without presupposing anthropomorphic moral intuitions. A case study
involving ethical resource distribution illustrates NAEL's dynamic balancing of
self-preservation, epistemic learning, and collective welfare.

</details>


### [80] [Practical, Utilitarian Algorithm Configuration](https://arxiv.org/abs/2510.14683)
*Devon Graham,Kevin Leyton-Brown*

Main category: cs.AI

TL;DR: COUP是一个基于效用的算法配置程序，本文通过一系列改进使其在保持理论保证的同时，实际性能达到与广泛使用的启发式配置方法相当的水平。


<details>
  <summary>Details</summary>
Motivation: COUP算法配置程序主要关注理论保证，但实际性能表现不足。本文旨在弥合这一差距，使基于效用的算法配置在实际应用中具有竞争力。

Method: 提出了一系列对COUP的改进措施，在不降低理论保证的前提下提升其经验性能，并通过实验验证这些改进的效果。

Result: 改进后的COUP在保持理论保证的同时，实际性能达到与无性能保证的启发式配置程序相当的水平。

Conclusion: 通过改进COUP，成功将基于理论的效用算法配置提升到实用水平，同时展示了如何评估算法选择解决方案对效用函数变化的鲁棒性。

Abstract: Utilitarian algorithm configuration identifies a parameter setting for a
given algorithm that maximizes a user's utility. Utility functions offer a
theoretically well-grounded approach to optimizing decision-making under
uncertainty and are flexible enough to capture a user's preferences over
algorithm runtimes (e.g., they can describe a sharp cutoff after which a
solution is no longer required, a per-hour cost for compute, or diminishing
returns from algorithms that take longer to run). COUP is a recently-introduced
utilitarian algorithm configuration procedure which was designed mainly to
offer strong theoretical guarantees about the quality of the configuration it
returns, with less attention paid to its practical performance. This paper
closes that gap, bringing theoretically-grounded, utilitarian algorithm
configuration to the point where it is competitive with widely used, heuristic
configuration procedures that offer no performance guarantees. We present a
series of improvements to COUP that improve its empirical performance without
degrading its theoretical guarantees and demonstrate their benefit
experimentally. Using a case study, we also illustrate ways of exploring the
robustness of a given solution to the algorithm selection problem to variations
in the utility function.

</details>


### [81] [Purifying Task Vectors in Knowledge-Aware Subspace for Model Merging](https://arxiv.org/abs/2510.14697)
*Bang An,Yibo Yang,Philip Torr,Bernard Ghanem*

Main category: cs.AI

TL;DR: 提出了PAVE方法，通过知识感知子空间净化任务向量，消除任务无关冗余，提升模型合并性能


<details>
  <summary>Details</summary>
Motivation: 现有模型合并方法中，任务向量包含任务无关冗余，导致合并模型性能显著下降，而现有去冗余方法缺乏知识感知且涉及随机性

Method: 在知识感知子空间中，通过上下文导向的奇异值分解识别任务相关权重分量，并引入谱秩分配策略进行公平剪枝

Result: PAVE作为即插即用方案，在各种任务向量合并方法中均能有效提升性能

Conclusion: PAVE方法能有效净化任务向量，消除冗余冲突，显著提升模型合并性能

Abstract: Model merging aims to integrate task-specific abilities from individually
fine-tuned models into a single model without extra training. In recent model
merging methods, task vector has become a fundamental building block, as it can
encapsulate the residual information from finetuning. However, the merged model
often suffers from notable performance degradation due to the conflicts caused
by task-irrelevant redundancy in task vectors. Existing efforts in overcoming
redundancy by randomly dropping elements in the parameter space involves
randomness and lacks knowledge awareness. To address these challenges, in this
study, we propose Purifying TAsk Vectors (PAVE) in knowledge-aware subspace.
Concretely, we sample some training examples from each task, and feed them into
their corresponding fine-tuned models to acquire the covariance matrices before
linear layers. We then perform a context-oriented singular value decomposition,
which accentuates the weight components most relevant to the target knowledge.
As a result, we can split fine-tuned model weights into task-relevant and
redundant components in the knowledge-aware subspace, and purify the task
vector by pruning the redundant components. To induce fair pruning efforts
across models, we further introduce a spectral rank allocation strategy by
optimizing a normalized activated pruning error. The task vector purification
by our method as a plug-and-play scheme is applicable across various task
vector-based merging methods to improve their performance. In experiments, we
demonstrate the effectiveness of PAVE across a diverse set of merging methods,
tasks, and model architectures.

</details>


### [82] [ExoPredicator: Learning Abstract Models of Dynamic Worlds for Robot Planning](https://arxiv.org/abs/2509.26255)
*Yichao Liang,Dat Nguyen,Cambridge Yang,Tianyang Li,Joshua B. Tenenbaum,Carl Edward Rasmussen,Adrian Weller,Zenna Tavares,Tom Silver,Kevin Ellis*

Main category: cs.AI

TL;DR: 提出了一个抽象世界模型框架，联合学习符号状态表示和因果过程（包括内生动作和外生机制），通过变分贝叶斯推理和LLM提议从有限数据中学习，在模拟桌面机器人环境中实现了快速规划并泛化到更复杂任务。


<details>
  <summary>Details</summary>
Motivation: 解决长视野具身规划中的挑战，因为世界不仅通过智能体动作改变，外生过程（如水温加热、多米诺骨牌连锁反应）也会与智能体动作同时展开。

Method: 提出抽象世界模型框架，联合学习符号状态表示和因果过程（内生动作和外生机制），每个因果过程建模随机因果关系的时序过程，通过变分贝叶斯推理结合LLM提议从有限数据中学习。

Result: 在五个模拟桌面机器人环境中，学习到的模型实现了快速规划，能够泛化到具有更多对象和更复杂目标的保留任务，优于一系列基线方法。

Conclusion: 该框架成功解决了长视野具身规划中处理外生过程的问题，学习到的抽象世界模型在复杂环境中表现出良好的泛化能力和规划性能。

Abstract: Long-horizon embodied planning is challenging because the world does not only
change through an agent's actions: exogenous processes (e.g., water heating,
dominoes cascading) unfold concurrently with the agent's actions. We propose a
framework for abstract world models that jointly learns (i) symbolic state
representations and (ii) causal processes for both endogenous actions and
exogenous mechanisms. Each causal process models the time course of a
stochastic cause-effect relation. We learn these world models from limited data
via variational Bayesian inference combined with LLM proposals. Across five
simulated tabletop robotics environments, the learned models enable fast
planning that generalizes to held-out tasks with more objects and more complex
goals, outperforming a range of baselines.

</details>


### [83] [Cognitive-Aligned Spatio-Temporal Large Language Models For Next Point-of-Interest Prediction](https://arxiv.org/abs/2510.14702)
*Penglong Zhai,Jie Li,Fanyi Di,Yue Liu,Yifang Yuan,Jie Huang,Peng Wu,Sicong Wang,Mingyang Yin,Tingting Hu,Yao Xu,Xin Li*

Main category: cs.AI

TL;DR: CoAST是一个认知对齐的时空大语言模型框架，通过自然语言界面整合世界知识、时空轨迹模式、用户画像和情境信息，用于下一个兴趣点推荐任务。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型主要基于非结构化文本预训练，缺乏对结构化地理实体和序列移动模式的理解，且需要融入世界知识和人类认知对齐来提升推荐性能。

Method: CoAST包含两个阶段：(1) 推荐知识获取：通过继续预训练丰富的时空轨迹数据；(2) 认知对齐：使用监督微调和强化学习将认知判断与人类偏好对齐。

Result: 在多个真实数据集上的离线实验和在AMAP App首页"猜你去哪"的在线实验证明了CoAST的有效性。

Conclusion: CoAST框架能够有效整合多源信息，提升下一个兴趣点推荐的准确性和用户体验。

Abstract: The next point-of-interest (POI) recommendation task aims to predict the
users' immediate next destinations based on their preferences and historical
check-ins, holding significant value in location-based services. Recently,
large language models (LLMs) have shown great potential in recommender systems,
which treat the next POI prediction in a generative manner. However, these
LLMs, pretrained primarily on vast corpora of unstructured text, lack the
native understanding of structured geographical entities and sequential
mobility patterns required for next POI prediction tasks. Moreover, in
industrial-scale POI prediction applications, incorporating world knowledge and
alignment of human cognition, such as seasons, weather conditions, holidays,
and users' profiles (such as habits, occupation, and preferences), can enhance
the user experience while improving recommendation performance. To address
these issues, we propose CoAST (Cognitive-Aligned Spatial-Temporal LLMs), a
framework employing natural language as an interface, allowing for the
incorporation of world knowledge, spatio-temporal trajectory patterns,
profiles, and situational information. Specifically, CoAST mainly comprises of
2 stages: (1) Recommendation Knowledge Acquisition through continued
pretraining on the enriched spatial-temporal trajectory data of the
desensitized users; (2) Cognitive Alignment to align cognitive judgments with
human preferences using enriched training data through Supervised Fine-Tuning
(SFT) and a subsequent Reinforcement Learning (RL) phase. Extensive offline
experiments on various real-world datasets and online experiments deployed in
"Guess Where You Go" of AMAP App homepage demonstrate the effectiveness of
CoAST.

</details>


### [84] [RoboGPT-R1: Enhancing Robot Planning with Reinforcement Learning](https://arxiv.org/abs/2510.14828)
*Jinrui Liu,Bingyan Nie,Boyu Li,Yaran Chen,Yuze Wang,Shunsen He,Haoran Li*

Main category: cs.AI

TL;DR: 提出了RoboGPT-R1，一个用于具身规划的两阶段微调框架，结合监督学习和强化学习来提升机器人在复杂环境中的长视野操作任务推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型和视觉语言模型在规划任务中取得成功，但在复杂真实世界环境中执行长视野操作任务时仍面临挑战，主要受限于常识和推理能力不足。

Method: 采用两阶段微调框架：监督训练通过专家序列获取基础知识，然后使用强化学习解决模型在视觉空间理解和推理方面的不足。设计了基于规则的奖励函数，同时考虑长视野性能和动作约束。

Result: 在EmbodiedBench基准测试中，基于Qwen2.5-VL-3B训练得到的推理模型显著优于GPT-4o-mini 21.33%，并超过其他基于Qwen2.5-VL-7B的工作20.33%。

Conclusion: 提出的两阶段微调框架有效提升了具身代理的推理能力，在长视野操作任务中表现出色，证明了结合监督学习和强化学习的有效性。

Abstract: Improving the reasoning capabilities of embodied agents is crucial for robots
to complete complex human instructions in long-view manipulation tasks
successfully. Despite the success of large language models and vision language
models based on Supervised Fine-Tuning (SFT) in planning tasks, they continue
facing challenges in performing long-horizon manipulation tasks in complex
real-world environments, owing to their restricted common sense and reasoning
capabilities. Considering that aligning general-purpose vision language models
to robotic planning tasks via supervised fine-tuning suffers from poor
generalization and insufficient physical understanding, we propose RoboGPT-R1,
a two-stage fine-tuning framework for embodied planning. In this framework,
supervised training acquires foundational knowledge through expert sequences,
followed by RL to address the model's shortcomings in visual-spatial
understanding and reasoning. To achieve physical understanding and action
sequence consistency in multi-step reasoning tasks, we design a rule-based
reward function that simultaneously considers long-horizon performance and
action constraint in the environment. The reasoning model, trained on
Qwen2.5-VL-3B, significantly outperforms the larger-scale model, GPT-4o-mini,
by 21.33% and surpasses other work trained on Qwen2.5-VL-7B by 20.33% on the
EmbodiedBench benchmark.

</details>


### [85] [ToolPRM: Fine-Grained Inference Scaling of Structured Outputs for Function Calling](https://arxiv.org/abs/2510.14703)
*Jianghao Lin,Yuanyuan Shi,Xin Peng,Renjie Ding,Hairui Wang,Yuxuan Peng,Bizhe Bai,Weixi Song,Fengshuo Bai,Huacan Chai,Weinan Zhang,Fei Huang,Ying Wen*

Main category: cs.AI

TL;DR: 提出了一个结合细粒度波束搜索和过程奖励模型ToolPRM的推理扩展框架，用于提升大语言模型在结构化输出（如函数调用）任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 当前推理扩展研究主要关注非结构化输出生成任务，而在结构化输出（如函数调用）方面的应用研究不足，需要填补这一空白。

Method: 构建了首个细粒度调用内过程监督数据集，使用函数掩码技术自动标注步骤级奖励，训练ToolPRM过程奖励模型来评分函数调用的内部步骤。

Result: ToolPRM在预测准确性上优于粗粒度和结果奖励模型，配备ToolPRM的推理扩展技术显著提升了骨干模型在各种函数调用任务和基准测试中的性能。

Conclusion: 揭示了将推理扩展技术应用于结构化输出的关键原则："多探索少保留"，这是由结构化函数调用生成的不可恢复性特征决定的。

Abstract: Large language models (LLMs) are increasingly demonstrating strong
capabilities as autonomous agents, with function calling serving as a core
mechanism for interaction with the environment. Meanwhile, inference scaling
has become a cutting-edge technique to enhance LLM performance by allocating
more computational resources during the inference process. However, current
research on inference scaling primarily focuses on unstructured output
generation tasks, leaving its application in structured outputs, like function
calling, largely underexplored. To bridge this gap, we propose an inference
scaling framework that combines fine-grained beam search with a process reward
model, ToolPRM, which scores the internal steps of each single function call.
To train ToolPRM, we construct the first fine-grained intra-call process
supervision dataset, automatically annotated with function-masking techniques
to provide step-level rewards for structured tool-use reasoning. Extensive
experiments demonstrate that ToolPRM beats the coarse-grained and outcome
reward models in terms of predictive accuracy, indicating its stronger
capability in supervising the function calling inference process. Inference
scaling technique equipped with ToolPRM also significantly improves the
backbone model performance across various function calling tasks and
benchmarks. More importantly, we reveal a key principle for applying inference
scaling techniques to structured outputs: "explore more but retain less" due to
the unrecoverability characteristics of structured function calling generation.

</details>


### [86] [SimKO: Simple Pass@K Policy Optimization](https://arxiv.org/abs/2510.14807)
*Ruotian Peng,Yi Ren,Zhouliang Yu,Weiyang Liu,Yandong Wen*

Main category: cs.AI

TL;DR: 论文提出SimKO方法解决RLVR中的过度集中问题，通过不对称设计提升pass@K性能


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法存在系统性偏向利用而非探索的问题，表现为pass@1提升但pass@K(K>1)下降

Method: 提出SimKO方法：对已验证正确响应提升top-K候选概率，对错误响应惩罚top-1候选，特别在高熵token上应用

Result: 在多个数学和逻辑推理基准测试中，SimKO一致性地提高了各种K值的pass@K性能

Conclusion: SimKO提供了一种简单有效的方法来改善RLVR的探索能力，缓解概率过度集中问题

Abstract: Reinforcement learning with verifiable rewards (RLVR) has advanced the
reasoning capabilities of large language models (LLMs). However, prevailing
RLVR methods exhibit a systematic bias toward exploitation over exploration, as
evidenced by improved pass@1 but reduced pass@K (K>1) performance. To
understand this issue, we analyze training dynamics of RLVR methods by tracking
the token-level probability distributions over vocabulary candidates. Our
analysis reveals a consistent probability concentration effect where the top-1
candidate increasingly accumulates probability mass and suppresses that of
other candidates. More importantly, stronger over-concentration correlates with
worse pass@K performance. Inspired by this finding, we propose Simple Pass@K
Optimization (SimKO), a method designed to mitigate the over-concentration
issue, thereby encouraging exploration. SimKO operates in an asymmetrical
manner. For verified-correct responses, it boosts the probabilities of the
top-K candidates. For verified-incorrect responses, it applies stronger
penalties to the top-1 candidate. We observe that this asymmetric design is
particularly effective at mitigating over-concentration when applied at tokens
with high entropy. Across various math and logical-reasoning benchmarks, SimKO
consistently yields higher pass@K for a wide range of K, providing a simple way
to improve RLVR's exploration.

</details>


### [87] [Agentic NL2SQL to Reduce Computational Costs](https://arxiv.org/abs/2510.14808)
*Dominik Jehle,Lennart Purucker,Frank Hutter*

Main category: cs.AI

TL;DR: Datalake Agent是一个基于LLM的代理系统，通过交互式循环选择性获取必要元信息，显著减少NL2SQL任务中的token使用量，降低成本的同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 传统NL2SQL方法需要处理大量数据库元信息，导致提示过长、token消耗大、处理成本高。

Method: 采用代理系统设计，使用交互式循环和推理框架，让LLM选择性请求必要信息来解决表格问答任务，而不是一次性提供所有元信息。

Result: 在23个数据库和100个表格问答任务上的评估显示，Datalake Agent将LLM使用的token减少了高达87%，同时保持了竞争力性能。

Conclusion: Datalake Agent通过选择性信息获取策略，在显著降低处理成本的同时，维持了NL2SQL任务的性能表现。

Abstract: Translating natural language queries into SQL queries (NL2SQL or Text-to-SQL)
has recently been empowered by large language models (LLMs). Using LLMs to
perform NL2SQL methods on a large collection of SQL databases necessitates
processing large quantities of meta-information about the databases, which in
turn results in lengthy prompts with many tokens and high processing costs. To
address this challenge, we introduce Datalake Agent, an agentic system designed
to enable an LLM to solve NL2SQL tasks more efficiently. Instead of utilizing
direct solvers for NL2SQL that call the LLM once with all meta-information in
the prompt, the Datalake Agent employs an interactive loop to reduce the
utilized meta-information. Within the loop, the LLM is used in a reasoning
framework that selectively requests only the necessary information to solve a
table question answering task. We evaluate the Datalake Agent on a collection
of 23 databases with 100 table question answering tasks. The Datalake Agent
reduces the tokens used by the LLM by up to 87\% and thus allows for
substantial cost reductions while maintaining competitive performance.

</details>


### [88] [Boosting Instruction Following at Scale](https://arxiv.org/abs/2510.14842)
*Ben Elder,Evelyn Duesterwald,Vinod Muthusamy*

Main category: cs.AI

TL;DR: Instruction Boosting是一种后生成方法，通过增加指令遵循率来提高LLM提示指令的可靠性，在2条指令时提升7个百分点，10条指令时提升4个百分点。


<details>
  <summary>Details</summary>
Motivation: 开发人员通常通过精心设计提示来影响LLM行为，但仅添加更多指令无法保证它们会被遵循。

Method: 引入Instruction Boosting作为后生成方法，并创建SCALEDIF基准测试，包含最多10条指令的数据样本。

Result: Instruction Boosting显著提高了指令遵循率，同时发现指令数量增加导致性能下降的主要原因是指令间的冲突和紧张关系。

Conclusion: 提出了定量冲突评分工具，可以解释性能趋势并为开发者提供关于额外提示指令对模型性能影响的反馈。

Abstract: A typical approach developers follow to influence an LLM's behavior in an
application is through careful manipulation of the prompt, such as by adding or
modifying instructions. However, merely adding more instructions provides
little assurance that they will actually be followed. We introduce Instruction
Boosting as a post-generation method to increase the reliability of LLM prompt
instructions. We show that Instruction Boosting improves the instruction
following rate by up to 7 points for two instructions and up to 4 points for
ten instructions. To demonstrate these results we introduce SCALEDIF, a
benchmark with a scaled instruction volume of up to ten instructions per data
sample. We also present an analysis of the commonly observed trend that
performance degrades as more instructions are added. We show that an important
factor contributing to this trend is the degree of tension and conflict that
arises as the number of instructions is increased. We contribute a quantitative
conflict scoring tool that explains the observed performance trends and
provides feedback to developers on the impact that additional prompt
instructions have on a model's performance.

</details>


### [89] [Where to Search: Measure the Prior-Structured Search Space of LLM Agents](https://arxiv.org/abs/2510.14846)
*Zhuo-Yang Song*

Main category: cs.AI

TL;DR: 提出了一种紧凑的形式理论来描述和衡量由领域先验引导的LLM辅助迭代搜索，通过模糊关系算子表示智能体，引入覆盖生成函数来衡量可达性难度。


<details>
  <summary>Details</summary>
Motivation: 基于LLM的生成-过滤-精炼迭代范式在推理、编程和科学发现中取得进展，但搜索效果取决于如何将领域先验编码为操作化结构化的假设空间。

Method: 将智能体表示为输入输出的模糊关系算子，用单一延续参数加权所有可达路径得到覆盖生成函数，从而衡量可达性难度并提供搜索的几何解释。

Result: 提供了最简单的可测试推断，并通过多数投票实例进行验证，为衡量智能体及其搜索空间提供了可行的语言和操作工具。

Conclusion: 该理论为LLM构建的迭代搜索提供了系统的形式化描述框架，能够操作化地衡量智能体和搜索空间。

Abstract: The generate-filter-refine (iterative paradigm) based on large language
models (LLMs) has achieved progress in reasoning, programming, and program
discovery in AI+Science. However, the effectiveness of search depends on where
to search, namely, how to encode the domain prior into an operationally
structured hypothesis space. To this end, this paper proposes a compact formal
theory that describes and measures LLM-assisted iterative search guided by
domain priors. We represent an agent as a fuzzy relation operator on inputs and
outputs to capture feasible transitions; the agent is thereby constrained by a
fixed safety envelope. To describe multi-step reasoning/search, we weight all
reachable paths by a single continuation parameter and sum them to obtain a
coverage generating function; this induces a measure of reachability
difficulty; and it provides a geometric interpretation of search on the graph
induced by the safety envelope. We further provide the simplest testable
inferences and validate them via a majority-vote instantiation. This theory
offers a workable language and operational tools to measure agents and their
search spaces, proposing a systematic formal description of iterative search
constructed by LLMs.

</details>


### [90] [LabOS: The AI-XR Co-Scientist That Sees and Works With Humans](https://arxiv.org/abs/2510.14861)
*Le Cong,Zaixi Zhang,Xiaotong Wang,Yin Di,Ruofan Jin,Michal Gerasimiuk,Yinkai Wang,Ravi K. Dinesh,David Smerkous,Alex Smerkous,Xuekun Wu,Shilong Liu,Peishan Li,Yi Zhu,Simran Serrao,Ning Zhao,Imran A. Mohammad,John B. Sunwoo,Joseph C. Wu,Mengdi Wang*

Main category: cs.AI

TL;DR: LabOS是首个将计算推理与物理实验相结合的AI共同科学家，通过多模态感知、自进化代理和扩展现实(XR)支持的人机协作，使AI能够参与实验室的实际操作。


<details>
  <summary>Details</summary>
Motivation: 现代科学发展需要思想与行动的结合，当前AI主要停留在计算设计阶段，缺乏与物理实验的深度融合。LabOS旨在让AI能够真正参与实验室工作，理解实验情境并实时协助执行。

Method: 通过连接多模型AI代理、智能眼镜和人机协作系统，LabOS使AI能够看到科学家所见、理解实验背景，并在实时执行中提供帮助。系统整合了多模态感知、自进化代理和XR技术。

Result: 在癌症免疫治疗靶点发现和干细胞工程等应用中，LabOS展示了AI能够超越计算设计，真正参与实验过程，将实验室转变为智能协作环境。

Conclusion: LabOS证明了AI可以从计算设计走向实际参与，创造了一个人类与机器发现共同进化的智能协作实验室环境。

Abstract: Modern science advances fastest when thought meets action. LabOS represents
the first AI co-scientist that unites computational reasoning with physical
experimentation through multimodal perception, self-evolving agents, and
Entended-Reality(XR)-enabled human-AI collaboration. By connecting multi-model
AI agents, smart glasses, and human-AI collaboration, LabOS allows AI to see
what scientists see, understand experimental context, and assist in real-time
execution. Across applications--from cancer immunotherapy target discovery to
stem-cell engineering -- LabOS shows that AI can move beyond computational
design to participation, turning the laboratory into an intelligent,
collaborative environment where human and machine discovery evolve together.

</details>


### [91] [The Gatekeeper Knows Enough](https://arxiv.org/abs/2510.14881)
*Fikresilase Wondmeneh Abebayew*

Main category: cs.AI

TL;DR: 提出了Gatekeeper Protocol框架，通过低保真潜在状态表示和按需请求高保真上下文的机制，解决LLM代理的上下文窗口限制和状态不同步问题。


<details>
  <summary>Details</summary>
Motivation: LLM作为自主代理部署时，受限于有限的上下文窗口和状态不同步问题，导致输出不可靠、行为不可预测和资源使用效率低下，特别是在与代码库和文档等结构化知识系统交互时。

Method: 设计Gatekeeper Protocol框架，让代理先在低保真潜在状态表示上进行操作和推理，然后按需请求高保真上下文。所有交互通过统一的JSON格式进行，作为声明式、状态同步的协议。

Result: 在软件开发的Sage实现中，该方法显著提高了代理可靠性，通过最小化token消耗改善了计算效率，并实现了与复杂系统的可扩展交互。

Conclusion: Gatekeeper Protocol为在任何结构化知识领域构建更稳健、可预测和基于现实的AI代理提供了基础方法论。

Abstract: Large Language Models (LLMs) are increasingly deployed as autonomous agents,
yet their practical utility is fundamentally constrained by a limited context
window and state desynchronization resulting from the LLMs' stateless nature
and inefficient context management. These limitations lead to unreliable
output, unpredictable behavior, and inefficient resource usage, particularly
when interacting with large, structured, and sensitive knowledge systems such
as codebases and documents. To address these challenges, we introduce the
Gatekeeper Protocol, a novel, domain-agnostic framework that governs
agent-system interactions. Our protocol mandates that the agent first operate
and reason on a minimalist, low-fidelity "latent state" representation of the
system to strategically request high-fidelity context on demand. All
interactions are mediated through a unified JSON format that serves as a
declarative, state-synchronized protocol, ensuring the agent's model of the
system remains verifiably grounded in the system's reality. We demonstrate the
efficacy of this protocol with Sage, a reference implementation of the
Gatekeeper Protocol for software development. Our results show that this
approach significantly increases agent reliability, improves computational
efficiency by minimizing token consumption, and enables scalable interaction
with complex systems, creating a foundational methodology for building more
robust, predictable, and grounded AI agents for any structured knowledge
domain.

</details>


### [92] [Mapping Smarter, Not Harder: A Test-Time Reinforcement Learning Agent That Improves Without Labels or Model Updates](https://arxiv.org/abs/2510.14900)
*Wen-Kwang Tsao,Yao-Ching Yu,Chien-Ming Huang*

Main category: cs.AI

TL;DR: 提出了一种无需标注数据或模型权重更新的强化学习代理，能够通过生成网络搜索查询收集外部证据，迭代改进企业日志的schema映射准确性。


<details>
  <summary>Details</summary>
Motivation: 企业智能平台需要整合来自多个第三方厂商的日志数据，但厂商文档常常缺失、不匹配或格式混乱，导致schema映射变得困难。

Method: 使用强化学习代理：1)识别模糊的字段映射尝试；2)生成针对性的网络搜索查询收集外部证据；3)应用基于置信度的奖励迭代优化映射。

Result: 在将Microsoft Defender for Endpoint日志转换为通用schema的任务中，映射准确率从56.4%(仅LLM)提升到72.73%(RAG)再到93.94%(100次迭代后)，同时将需要专家审查的低置信度映射减少了85%。

Conclusion: 该方法提供了一种证据驱动、透明的解决方案，为构建更鲁棒、可扩展、高效和适应性强的行业问题解决方法铺平了道路。

Abstract: The Enterprise Intelligence Platform must integrate logs from numerous
third-party vendors in order to perform various downstream tasks. However,
vendor documentation is often unavailable at test time. It is either misplaced,
mismatched, poorly formatted, or incomplete, which makes schema mapping
challenging. We introduce a reinforcement learning agent that can self-improve
without labeled examples or model weight updates. During inference, the agent:
1) Identifies ambiguous field-mapping attempts. 2) Generates targeted
web-search queries to gather external evidence. 3) Applies a confidence-based
reward to iteratively refine its mappings. To demonstrate this concept, we
converted Microsoft Defender for Endpoint logs into a common schema. Our method
increased mapping accuracy from 56.4\%(LLM-only) to 72.73\%(RAG) to 93.94\%
over 100 iterations using GPT-4o. At the same time, it reduced the number of
low-confidence mappings requiring expert review by 85\%. This new approach
provides an evidence-driven, transparent method for solving future industry
problems, paving the way for more robust, accountable, scalable, efficient,
flexible, adaptable, and collaborative solutions.

</details>


### [93] [Budget-aware Test-time Scaling via Discriminative Verification](https://arxiv.org/abs/2510.14913)
*Kyle Montgomery,Sijun Tan,Yuqi Chen,Siyuan Zhuang,Tianjun Zhang,Raluca Ada Popa,Chenguang Wang*

Main category: cs.AI

TL;DR: 提出了一种结合判别式验证器和自一致性的混合测试时扩展方法，在固定计算预算下显著优于生成式验证方法，在AIME2025上准确率提升达15.3%。


<details>
  <summary>Details</summary>
Motivation: 现有生成式验证器虽然性能强大，但计算成本过高，限制了实际应用。需要寻找更高效的验证方法。

Method: 采用判别式验证器与自一致性结合的混合方法，在固定计算预算下进行测试时扩展。

Result: 在AIME2025任务上，该方法比最先进的生成式验证准确率高出15.3%，且计算效率更高。

Conclusion: 基于判别式验证器的预算感知扩展方法不仅是自一致性的免费升级，也是比昂贵生成式技术更有效和高效的替代方案。

Abstract: Test-time scaling is a powerful strategy for boosting the performance of
large language models on complex reasoning tasks. While state-of-the-art
approaches often employ generative verifiers to select the best solution from a
pool of candidates, this method incurs prohibitive computational costs,
limiting its practicality. In this work, we shift the focus to a more
budget-aware paradigm: discriminative verification. We conduct a thorough
empirical analysis and demonstrate that while discriminative verifiers may
underperform in isolation, combining them with self-consistency in a hybrid
approach creates a powerful and efficient test-time scaling mechanism. Notably,
under a fixed compute budget, this hybrid approach surpasses state-of-the-art
generative verification by a significant margin: achieving up to 15.3\% higher
accuracy on AIME2025. Our findings establish that for practical, real-world
applications, budget-aware scaling with discriminative verifiers is not only a
"free" upgrade over self-consistency, but also a more effective and efficient
alternative to costly generative techniques. Code is available at
https://github.com/wang-research-lab/verification.

</details>


### [94] [TRI-DEP: A Trimodal Comparative Study for Depression Detection Using Speech, Text, and EEG](https://arxiv.org/abs/2510.14922)
*Annisaa Fitri Nurfidausi,Eleonora Mancini,Paolo Torroni*

Main category: cs.AI

TL;DR: 该论文系统研究了多模态抑郁检测，通过比较EEG、语音和文本的特征表示和建模策略，发现三模态组合能提升检测性能，预训练嵌入优于手工特征，精心设计的三模态模型达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁检测研究存在范围有限、缺乏系统性特征比较和评估协议不一致的问题，需要系统探索多模态特征表示和建模策略。

Method: 系统评估手工特征与预训练嵌入，比较不同神经编码器的有效性，分析单模态、双模态和三模态配置，研究融合策略并关注EEG的作用，使用一致的受试者独立分割进行稳健可复现的基准测试。

Result: EEG、语音和文本三模态组合增强多模态检测性能，预训练嵌入优于手工特征，精心设计的三模态模型达到最先进水平。

Conclusion: 该研究为未来多模态抑郁检测研究奠定了基础，证明了多模态融合的有效性和预训练嵌入的优越性。

Abstract: Depression is a widespread mental health disorder, yet its automatic
detection remains challenging. Prior work has explored unimodal and multimodal
approaches, with multimodal systems showing promise by leveraging complementary
signals. However, existing studies are limited in scope, lack systematic
comparisons of features, and suffer from inconsistent evaluation protocols. We
address these gaps by systematically exploring feature representations and
modelling strategies across EEG, together with speech and text. We evaluate
handcrafted features versus pre-trained embeddings, assess the effectiveness of
different neural encoders, compare unimodal, bimodal, and trimodal
configurations, and analyse fusion strategies with attention to the role of
EEG. Consistent subject-independent splits are applied to ensure robust,
reproducible benchmarking. Our results show that (i) the combination of EEG,
speech and text modalities enhances multimodal detection, (ii) pretrained
embeddings outperform handcrafted features, and (iii) carefully designed
trimodal models achieve state-of-the-art performance. Our work lays the
groundwork for future research in multimodal depression detection.

</details>


### [95] [Stable but Miscalibrated: A Kantian View on Overconfidence from Filters to Large Language Models](https://arxiv.org/abs/2510.14925)
*Akira Okutomi*

Main category: cs.AI

TL;DR: 将康德的《纯粹理性批判》重新解释为反馈稳定性理论，提出复合不稳定性指数H-Risk来评估推理系统的稳定性，并在线性高斯模拟和LLMs中验证其与过度自信错误的相关性。


<details>
  <summary>Details</summary>
Motivation: 建立康德理性自我限制理论与反馈控制之间的结构桥梁，为诊断和减少推理系统中的过度自信提供原则性视角。

Method: 提出复合不稳定性指数H-Risk，结合谱裕度、条件数、时间敏感性和创新放大等指标，在线性高斯模拟和大型语言模型中进行验证。

Result: 在线性高斯模拟中，更高的H-Risk预测过度自信错误；在LLMs中，脆弱的内部动态与校准错误和幻觉相关，批判式提示对校准和幻觉有混合影响。

Conclusion: 该研究为理解推理系统的稳定性提供了新的理论框架，揭示了名义稳定性与认知稳定性之间的差距，为减少AI系统中的过度自信提供了诊断工具。

Abstract: We reinterpret Kant's Critique of Pure Reason as a theory of feedback
stability, viewing reason as a regulator that keeps inference within the bounds
of possible experience. We formalize this intuition via a composite instability
index (H-Risk) combining spectral margin, conditioning, temporal sensitivity,
and innovation amplification. In linear-Gaussian simulations, higher H-Risk
predicts overconfident errors even under formal stability, revealing a gap
between nominal and epistemic stability. Extending to large language models
(LLMs), we find that fragile internal dynamics correlate with miscalibration
and hallucination, while critique-style prompts show mixed effects on
calibration and hallucination. These results suggest a structural bridge
between Kantian self-limitation and feedback control, offering a principled
lens for diagnosing -- and selectively reducing -- overconfidence in reasoning
systems. This is a preliminary version; supplementary experiments and broader
replication will be reported in a future revision.

</details>


### [96] [GroundedPRM: Tree-Guided and Fidelity-Aware Process Reward Modeling for Step-Level Reasoning](https://arxiv.org/abs/2510.14942)
*Yao Zhang,Yu Wu,Haowei Zhang,Weiguo Li,Haokun Chen,Jingpei Wu,Guohao Li,Zhen Han,Volker Tresp*

Main category: cs.AI

TL;DR: GroundedPRM是一个基于树搜索和外部工具验证的自动过程监督框架，通过MCTS构建结构化推理路径，使用外部工具验证中间步骤，结合步骤级验证和全局评估的混合奖励机制，显著提升了多步推理的质量和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有过程奖励模型(PRMs)面临三大挑战：噪声奖励、低事实保真度和与步骤级推理目标不对齐。这些问题源于缺乏可扩展的高质量标注，现有方法依赖昂贵的人工标注、易产生幻觉的LLM自评估或存在信用分配问题的蒙特卡洛估计。

Method: 1) 使用蒙特卡洛树搜索(MCTS)构建结构化推理路径以减少奖励噪声；2) 通过外部工具验证每个中间步骤，提供执行基础的正确性信号；3) 设计混合奖励聚合机制，融合工具验证和MCTS反馈；4) 将奖励信号格式化为理由增强的生成结构。

Result: 仅使用4万个自动标注样本(最佳PRM的10%)，在ProcessBench上实现了高达26%的相对性能提升。在奖励引导的贪婪搜索中，甚至优于使用人工标注监督训练的PRMs。

Conclusion: GroundedPRM为高质量过程级推理提供了一条可扩展且可验证的路径，通过结合树引导的结构化推理和工具基础的事实验证，有效解决了现有PRMs的核心局限性。

Abstract: Process Reward Models (PRMs) aim to improve multi-step reasoning in Large
Language Models (LLMs) by supervising intermediate steps and identifying
errors. However, building effective PRMs remains challenging due to the lack of
scalable, high-quality annotations. Existing approaches rely on costly human
labeling, LLM-based self-evaluation that is prone to hallucination, or Monte
Carlo (MC) estimation, which infers step quality solely from rollout outcomes
and often introduces noisy, misaligned supervision due to credit
misattribution. These issues result in three core limitations: noisy rewards,
low factual fidelity, and misalignment with step-level reasoning objectives. To
address these challenges, we introduce GroundedPRM, a tree-guided and
fidelity-aware framework for automatic process supervision. To reduce reward
noise and enable fine-grained credit assignment, we construct structured
reasoning paths via Monte Carlo Tree Search (MCTS). To eliminate hallucinated
supervision, we validate each intermediate step using an external tool,
providing execution-grounded correctness signals. To combine both step-level
validation and global outcome assessment, we design a hybrid reward aggregation
mechanism that fuses tool-based verification with MCTS-derived feedback.
Finally, we format the reward signal into a rationale-enhanced, generative
structure to promote interpretability and compatibility with instruction-tuned
LLMs. GroundedPRM is trained on only 40K automatically labeled samples,
amounting to just 10% of the data used by the best-performing PRM trained with
auto-labeled supervision. Nevertheless, it achieves up to a 26% relative
improvement in average performance on ProcessBench. When used for reward-guided
greedy search, GroundedPRM outperforms even PRMs trained with human-labeled
supervision, offering a scalable and verifiable path toward high-quality
process-level reasoning.

</details>


### [97] [Agentic Design of Compositional Machines](https://arxiv.org/abs/2510.14980)
*Wenqian Zhang,Weiyang Liu,Zhen Liu*

Main category: cs.AI

TL;DR: 本文研究大型语言模型是否能够进行组合式机器设计，通过BesiegeField测试平台评估LLM在物理环境中的机器构建能力，并探索强化学习作为改进途径。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在复杂机器设计方面的能力，这是人类智能的重要标志和工程实践的基础。

Method: 引入BesiegeField测试平台，基于Besiege游戏构建，支持基于组件的构造、物理模拟和奖励驱动评估。对最先进的LLM进行基准测试，并探索强化学习微调。

Result: 当前开源模型在空间推理、策略性组装和指令遵循等关键能力方面存在不足，强化学习微调显示出改进潜力。

Conclusion: 机器设计任务揭示了LLM在语言、机器设计和物理推理交叉领域面临的挑战，强化学习是提升性能的有前景途径。

Abstract: The design of complex machines stands as both a marker of human intelligence
and a foundation of engineering practice. Given recent advances in large
language models (LLMs), we ask whether they, too, can learn to create. We
approach this question through the lens of compositional machine design: a task
in which machines are assembled from standardized components to meet functional
demands like locomotion or manipulation in a simulated physical environment. To
support this investigation, we introduce BesiegeField, a testbed built on the
machine-building game Besiege, which enables part-based construction, physical
simulation and reward-driven evaluation. Using BesiegeField, we benchmark
state-of-the-art LLMs with agentic workflows and identify key capabilities
required for success, including spatial reasoning, strategic assembly, and
instruction-following. As current open-source models fall short, we explore
reinforcement learning (RL) as a path to improvement: we curate a cold-start
dataset, conduct RL finetuning experiments, and highlight open challenges at
the intersection of language, machine design, and physical reasoning.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [98] [Technological Devices and Their Negative Effects on Health](https://arxiv.org/abs/2510.14221)
*Alida Vallejo-López,Cesar Noboa-Terán,Juana Kou-Guzmán,Josefina Ramírez-Amaya*

Main category: cs.CY

TL;DR: 论文探讨了技术设备使用对健康的影响，包括视觉、神经、肌肉、听力和睡眠问题，强调负责任使用技术以保护健康的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着技术设备在日常生活中的普及，人们观察到各种健康问题，需要研究技术使用对健康的影响并提高公众意识。

Method: 通过分析技术设备使用与健康问题之间的关联，探讨电子设备辐射等因素对健康的影响。

Result: 发现技术设备使用会导致视觉、神经、肌肉、听力和睡眠等多方面的健康问题。

Conclusion: 社会需要意识到负责任使用技术设备的重要性，以保护人们的整体健康。

Abstract: Technology has become a global tool that allows us to obtain information and
analyze data, streamlines communication, and allows us to share images, data,
videos, texts, etc. Daily activities have gone from traditional to digital.
Today, it is impossible to live without an electronic device. In this context,
changes in people's health observed, with various complaints ranging from
visual, neurological, and concentration problems to muscular, hearing, and
sleep disorders. Society must be aware of the importance of using various
technological devices responsibly to protect people's health in general.
Keywords: Technology, activities, protect, electronic, Radiation, Health.

</details>


### [99] [Closing the Loop: An Instructor-in-the-Loop AI Assistance System for Supporting Student Help-Seeking in Programming Education](https://arxiv.org/abs/2510.14457)
*Tung Phung,Heeryung Choi,Mengyan Wu,Christopher Brooks,Sumit Gulwani,Adish Singla*

Main category: cs.CY

TL;DR: 提出了一个混合帮助框架，结合AI生成提示和升级机制，让学生在AI支持不足时向教师请求反馈，以平衡AI的可扩展性和教师的专业知识。


<details>
  <summary>Details</summary>
Motivation: 编程课程需要及时高质量的反馈，但大规模提供这种支持存在挑战。AI系统可扩展但可能不准确，教师有专业知识但时间有限。

Method: 开发混合帮助框架，集成AI生成提示和升级机制，在数据科学编程课程中部署给82名学生使用。

Result: 在673个AI生成提示中，22%被学生评为无帮助，其中只有11%升级到教师。教师反馈中约一半存在错误或不足。

Conclusion: 该框架提供了扩展高质量支持的实用方法，并为未来AI与人类在教育中的有效整合提供了参考。

Abstract: Timely and high-quality feedback is essential for effective learning in
programming courses; yet, providing such support at scale remains a challenge.
While AI-based systems offer scalable and immediate help, their responses can
occasionally be inaccurate or insufficient. Human instructors, in contrast, may
bring more valuable expertise but are limited in time and availability. To
address these limitations, we present a hybrid help framework that integrates
AI-generated hints with an escalation mechanism, allowing students to request
feedback from instructors when AI support falls short. This design leverages
the strengths of AI for scale and responsiveness while reserving instructor
effort for moments of greatest need. We deployed this tool in a data science
programming course with 82 students. We observe that out of the total 673
AI-generated hints, students rated 146 (22%) as unhelpful. Among those, only 16
(11%) of the cases were escalated to the instructors. A qualitative
investigation of instructor responses showed that those feedback instances were
incorrect or insufficient roughly half of the time. This finding suggests that
when AI support fails, even instructors with expertise may need to pay greater
attention to avoid making mistakes. We will publicly release the tool for
broader adoption and enable further studies in other classrooms. Our work
contributes a practical approach to scaling high-quality support and informs
future efforts to effectively integrate AI and humans in education.

</details>


### [100] [Trends of Pink Slime Journalism Advertisement Expenditure and Spread on Facebook from 2019-2024](https://arxiv.org/abs/2510.14818)
*Christine Sowa Lepird,Lynnette Hui Xian Ng,Kathleen M. Carley*

Main category: cs.CY

TL;DR: 该研究分析了Facebook上粉红粘液新闻网站的传播趋势，发现虽然页面发帖量下降，但广告支出增加，特别是在选举年，这影响了群组发帖量的增长。


<details>
  <summary>Details</summary>
Motivation: 研究粉红粘液新闻（低质量、煽动性党派文章伪装成地方新闻）在Facebook上的传播模式及其广告策略，揭示潜在危险的新闻实践。

Method: 使用Facebook公共页面和群组的帖子数据，分析粉红粘液网站的分享趋势和其母公司购买的广告模式。

Result: 粉红粘液网站在Facebook页面的发帖量逐年减少，但广告支出增加，特别是在选举年；广告支出增加导致群组发帖量上升；选举年广告支出激增，但争议话题在非选举年仍被讨论。

Conclusion: 研究揭示了粉红粘液新闻的危险传播模式，提供了对未来美国总统选举的预测，强调了需要关注此类新闻实践对公共话语的影响。

Abstract: Pink slime journalism is a practice where news outlets publish low-quality or
inflammatory partisan articles, claiming to be local news networks. This paper
examines the spread of pink slime sites on Facebook using public posts from
Pages and Groups. We evaluate the trends of sharing pink slime sites on
Facebook and patterns regarding the advertisements purchased by the parent
organizations of the pink slime news networks. Our analysis discovers that
while the number of pink slime posts on Facebook pages have decreased over the
years, advertising dollars have increased. The increase in advertising dollars
influences an increase in Facebook group posts. Further, the advertising
expenditure increases during election years, but contentious topics are still
discussed during non-election years. By illustrating the patterns and themes
from US election years of 2020, 2022, and 2024, this research offers insights
into potentially dangerous journalism tactics, and provides predictions for
future US Presidential Elections.

</details>


### [101] [A Comprehensive Framework for Efficient Court Case Management and Prioritization](https://arxiv.org/abs/2510.14892)
*Shubham Varma,Ananya Warior,Avani Sakhapara,Dipti Pawade*

Main category: cs.CY

TL;DR: 提出基于云的软件框架，使用算法方法对印度法院案件进行分类和优先级排序，以解决5200万积压案件问题。


<details>
  <summary>Details</summary>
Motivation: 印度司法系统面临5200万件待处理案件的严重挑战，导致重大延误并影响社会经济稳定。

Method: 开发云基础软件框架，基于犯罪严重性、当事人责任、案件归档日期、先前听证数据、优先级等参数进行算法分类和优先级排序，整合自动听证日期分配、通知系统和司法互动功能。

Result: 模拟显示系统能高效处理案件，具有可靠的通知传递功能，法官和登记员用户满意度良好。

Conclusion: 该系统能有效提升法院案件管理效率，减少积压，未来将集成机器学习实现动态优先级排序。

Abstract: The Indian judicial system faces a critical challenge with approximately 52
million pending cases, causing significant delays that impact socio-economic
stability. This study proposes a cloud-based software framework to classify and
prioritize court cases using algorithmic methods based on parameters such as
severity of crime committed, responsibility of parties involved, case filing
dates, previous hearing's data, priority level (e.g., Urgent, Medium, Ordinary)
provided as input, and relevant Indian Penal Code (IPC), Code of Criminal
Procedure (CrPC), and other legal sections (e.g., Hindu Marriage Act, Indian
Contract Act). Cases are initially entered by advocates on record or court
registrars, followed by automated hearing date allocation that balances fresh
and old cases while accounting for court holidays and leaves. The system
streamlines appellate processes by fetching data from historical case
databases. Our methodology integrates algorithmic prioritization, a robust
notification system, and judicial interaction, with features that allow judges
to view daily case counts and their details. Simulations demonstrate that the
system can process cases efficiently, with reliable notification delivery and
positive user satisfaction among judges and registrars. Future iterations will
incorporate advanced machine learning for dynamic prioritization, addressing
critical gaps in existing court case management systems to enhance efficiency
and reduce backlogs.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [102] [Long-Term Spatio-Temporal Forecasting of Monthly Rainfall in West Bengal Using Ensemble Learning Approaches](https://arxiv.org/abs/2510.13927)
*Jishu Adhikary,Raju Maiti*

Main category: stat.AP

TL;DR: 该研究开发了一个分层建模框架，结合回归模型和MLP神经网络，对西孟加拉邦19个地区进行长期月度降雨预测。


<details>
  <summary>Details</summary>
Motivation: 降雨预报对气候适应、农业和水资源管理至关重要，需要处理降雨的非线性和复杂时空动态特性。

Method: 使用分层建模框架：先用回归模型预测年度特征（年总量、季度比例、变异性等），然后将这些预测作为辅助输入集成到MLP模型中，捕捉月度序列的非线性时空模式。

Result: 分层回归-MLP架构能够提供稳健的长期时空预测，为农业、灌溉规划和水资源保护策略提供有价值见解。

Conclusion: 提出的分层建模方法有效解决了降雨预测中的非线性时空依赖问题，在长期预测中表现出色。

Abstract: Rainfall forecasting plays a critical role in climate adaptation,
agriculture, and water resource management. This study develops long-term
forecasts of monthly rainfall across 19 districts of West Bengal using a
century-scale dataset spanning 1900-2019. Daily rainfall records are aggregated
into monthly series, resulting in 120 years of observations for each district.
The forecasting task involves predicting the next 108 months (9 years,
2011-2019) while accounting for temporal dependencies and spatial interactions
among districts. To address the nonlinear and complex structure of rainfall
dynamics, we propose a hierarchical modeling framework that combines
regression-based forecasting of yearly features with multi-layer perceptrons
(MLPs) for monthly prediction. Yearly features, such as annual totals,
quarterly proportions, variability measures, skewness, and extremes, are first
forecasted using regression models that incorporate both own lags and
neighboring-district lags. These forecasts are then integrated as auxiliary
inputs into an MLP model, which captures nonlinear temporal patterns and
spatial dependencies in the monthly series. The results demonstrate that the
hierarchical regression-MLP architecture provides robust long-term
spatio-temporal forecasts, offering valuable insights for agriculture,
irrigation planning, and water conservation strategies.

</details>


### [103] [Earthquake Forecasting with ETAS.inlabru](https://arxiv.org/abs/2510.13930)
*Ziwen Zhong*

Main category: stat.AP

TL;DR: ETAS模型是地震预测中最流行的模型。本文使用INLA方法替代传统的MCMC方法，解决了参数相关性和计算耗时问题，并通过三个实验验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统MCMC方法在ETAS模型参数估计中存在计算耗时、参数相关性限制和参数不确定性等问题，需要更高效的贝叶斯推断方法。

Method: 使用INLA方法（inlabru）进行贝叶斯推断，通过泰勒展开和分箱策略近似模型的对数似然函数，并设计了三个实验来验证方法性能。

Result: 实验表明：α和K参数存在明显相互影响；固定参数可减少一半以上拟合时间；真实数据和合成目录的归一化事件间隔时间分布一致；需要至少一个主震及其余震才能进行可靠预测；数据中主震越多预测效果越好。

Conclusion: INLA方法在ETAS模型中优于传统MCMC方法，能够有效处理参数相关性和计算效率问题，为地震预测提供了更可靠的贝叶斯推断框架。

Abstract: The ETAS models are currently the most popular in the field of earthquake
forecasting. The MCMC method is time-consuming and limited by parameter
correlation while bringing parameter uncertainty. The INLA-based method
"inlabru" solves these problems and performs better at Bayesian inference.
  The report introduces the composition of the ETAS model, then provides the
model's log-likelihood and approximates it using Taylor expansion and binning
strategies. We also present the general procedure of Bayesian inference in
inlabru.
  The report follows three experiments. The first one explores the effect of
fixing one parameter at its actual or wrong values on the posterior
distribution of other parameters. We found that $\alpha$ and $K$ have an
apparent mutual influence relationship. At the same time, fixing $\alpha$ or
$K$ to its actual value can reduce the model fitting time by more than half.
  The second experiment compares normalised inter-event-time distribution on
real data and synthetic catalogues. The distributions of normalised
inter-event-time of real data and synthetic catalogues are consistent. Compared
with Exp(1), they have more short and long inter-event-time, indicating the
existence of clustering. Change on $\mu$ and $p$ will influence the
inter-event-time distribution.
  In the last one, we use events before the mainshock to predict events ten
weeks after the mainshock. We use the number test and Continuous Ranked
Probability Score (CRPS) to measure the accuracy and precision of the
predictions. We found that we need at least one mainshock and corresponding
offspring to make reliable forecasting. And when we have more mainshocks in our
data, our forecasting will be better. Besides, we also figure out what is
needed to obtain a good posterior distribution for each parameter.

</details>


### [104] [A Data-Parsimonious Model for Long-Term Risk Assessments of West Nile Virus Spillover](https://arxiv.org/abs/2510.14011)
*Saman Hosseini,Lee W. Cohnstaedt,Matin Marjani,Caterina Scoglio*

Main category: stat.AP

TL;DR: 开发了一个数据简约的西尼罗河病毒预测模型，该模型结合温度驱动的WNV传播模型和非参数核密度估计方法，能够在传播季节开始前几个月提供可靠的疫情爆发时间和严重程度预测。


<details>
  <summary>Details</summary>
Motivation: 许多WNV预测框架需要昆虫学或鸟类监测数据，但这些数据在某些地区可能无法获得，因此需要开发数据需求更少的预测方法。

Method: 结合温度驱动的WNV传播模型和非参数核密度估计方法，构建联合概率密度函数和泊松率曲面，作为蚊虫丰度和归一化累积温度的函数。

Result: 模型在加州、德克萨斯州和佛罗里达州的六个县进行了评估，这些地区具有完全不同的生态和气候条件，结果显示在多个性能指标上表现良好。

Conclusion: 该数据简约的概率模型能够可靠地预测WNV疫情爆发的时间和严重程度，支持在传播季节开始前采取主动防控措施。

Abstract: Many West Nile virus (WNV) forecasting frameworks incorporate entomological
or avian surveillance data, which may be unavailable in some regions. We
introduce a novel data-parsimonious probabilistic model to predict both the
timing of outbreak onset and the seasonal severity of WNV spillover. Our
approach combines a temperature-driven compartmental model of WNV with
nonparametric kernel density estimation methods to construct a joint
probability density function and a Poisson rate surface as function of mosquito
abundance and normalized cumulative temperature. Calibrated on human incidence
records, the model produces reliable forecasts several months before the
transmission season begins, supporting proactive mitigation efforts. We
evaluated the framework across three counties in California (Orange, Los
Angeles, and Riverside), two in Texas (Dallas and Harris), and one in Florida
(Duval), representing completely different ecology and distinct climatic
regimes, and observed strong agreement across multiple performance metrics.

</details>


### [105] [Bayes-ically fair: A Bayesian Ranking of the Olympic Medal Table](https://arxiv.org/abs/2510.14723)
*Cormac MacDermott,Carl J. Scarrott,John Ferguson*

Main category: stat.AP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Evaluating a country's sporting success provides insight into its
decision-making and infrastructure for developing athletic talent. The Olympic
Games serve as a global benchmark, yet conventional medal rankings can be
unduly influenced by population size. We propose a Bayesian ranking scheme to
rank the performance of National Olympic Committees by their "long-run"
medals-to-population ratio. The algorithm aims to mitigate the influence of
large populations and reduce the stochastic fluctuations for smaller nations by
applying shrinkage. These long-run rankings provide a more stable and
interpretable ordering of national sporting performance across games compared
to existing methods.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [106] [Cyber-Resilient System Identification for Power Grid through Bayesian Integration](https://arxiv.org/abs/2510.14043)
*Shimiao Li,Guannan Qu,Bryan Hooi,Vyas Sekar,Soummya Kar,Larry Pileggi*

Main category: eess.SY

TL;DR: 提出了一种结合基于快照的系统识别方法与时间序列模型的贝叶斯集成方法，用于提升电网对随机和定向虚假数据的网络弹性。


<details>
  <summary>Details</summary>
Motivation: 现代电网需要实时态势感知能力，但现有基于快照的系统识别方法无法有效检测交互式、定向的虚假数据攻击，这会严重影响估计精度。

Method: 使用基于距离的时间序列模型，通过贝叶斯集成将历史数据中的正常系统行为整合到系统识别中，使解决方案对定向虚假数据具有鲁棒性。

Result: 在混合随机异常和定向虚假数据注入攻击下，实现了：1）网络弹性：在FDIA下估计误差减少超过70%；2）异常数据识别：能够报警和定位异常数据；3）几乎线性可扩展性：在大型2383节点系统上每个时间点处理时间<1分钟。

Conclusion: 该方法显著提升了电网系统识别对定向虚假数据攻击的抵御能力，同时保持了良好的计算效率。

Abstract: Power grids increasingly need real-time situational awareness under the
ever-evolving cyberthreat landscape. Advances in snapshot-based system
identification approaches have enabled accurately estimating states and
topology from a snapshot of measurement data, under random bad data and
topology errors. However, modern interactive, targeted false data can stay
undetectable to these methods, and significantly compromise estimation
accuracy. This work advances system identification that combines snapshot-based
method with time-series model via Bayesian Integration, to advance cyber
resiliency against both random and targeted false data. Using a distance-based
time-series model, this work can leverage historical data of different
distributions induced by changes in grid topology and other settings. The
normal system behavior captured from historical data is integrated into system
identification through a Bayesian treatment, to make solutions robust to
targeted false data. We experiment on mixed random anomalies (bad data,
topology error) and targeted false data injection attack (FDIA) to demonstrate
our method's 1) cyber resilience: achieving over 70% reduction in estimation
error under FDIA; 2) anomalous data identification: being able to alarm and
locate anomalous data; 3) almost linear scalability: achieving comparable speed
with the snapshot-based baseline, both taking <1min per time tick on the large
2,383-bus system using a laptop CPU.

</details>


### [107] [Multi-Period Sparse Optimization for Proactive Grid Blackout Diagnosis](https://arxiv.org/abs/2510.14045)
*Qinghua Ma,Reetam Sen Biswas,Denis Osipov,Guannan Qu,Soummya Kar,Shimiao Li*

Main category: eess.SY

TL;DR: 提出一种多周期稀疏优化方法，用于发现电力系统在极端事件下导致系统崩溃的持续性故障源，通过电路理论优化增强可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有电网需要评估极端事件下的生存能力，如峰值负荷过载可能导致系统崩溃。对于具有相关性的极端事件，其背后的主要脆弱性可能位于相同位置但严重程度不同，需要早期预警诊断来增强系统韧性。

Method: 使用多周期稀疏优化方法，结合持续性约束来捕捉隐藏的演化脆弱性。采用基于电路理论的潮流公式和电路启发式优化启发式来提高方法的可扩展性。

Result: 在基准系统上的实验表明，该方法能可靠地跟踪在负荷增加应力下的持续性脆弱位置，并在2000+总线系统上平均每个场景约需200秒，具有良好的可扩展性。

Conclusion: 该方法能有效识别导致系统崩溃的持续性故障源，为电力系统在极端事件下的早期预警和韧性增强提供了实用工具。

Abstract: Existing or planned power grids need to evaluate survivability under extreme
events, like a number of peak load overloading conditions, which could possibly
cause system collapses (i.e. blackouts). For realistic extreme events that are
correlated or share similar patterns, it is reasonable to expect that the
dominant vulnerability or failure sources behind them share the same locations
but with different severity. Early warning diagnosis that proactively
identifies the key vulnerabilities responsible for a number of system collapses
of interest can significantly enhance resilience. This paper proposes a
multi-period sparse optimization method, enabling the discovery of {persistent
failure sources} across a sequence of collapsed systems with increasing system
stress, such as rising demand or worsening contingencies. This work defines
persistency and efficiently integrates persistency constraints to capture the
``hidden'' evolving vulnerabilities. Circuit-theory based power flow
formulations and circuit-inspired optimization heuristics are used to
facilitate the scalability of the method. Experiments on benchmark systems show
that the method reliably tracks persistent vulnerability locations under
increasing load stress, and solves with scalability to large systems ({on
average} taking {around} 200 s per scenario on 2000+ bus systems).

</details>


### [108] [Dual Detection Framework for Faults and Integrity Attacks in Cyber-Physical Control Systems](https://arxiv.org/abs/2510.14052)
*Xixing Xue,Dong Shen,Steven X. Ding,Dong Zhao*

Main category: eess.SY

TL;DR: 提出了一种用于异常检测和区分的双重检测框架，通过分析控制回路的动态特性和完整性攻击的隐蔽性特征，设计并部署了两个专用检测器，能够联合检测工厂故障和网络攻击，并能区分故障和完整性攻击。


<details>
  <summary>Details</summary>
Motivation: 在信息物理控制系统中，异常检测对安全至关重要，准确区分不同类型的异常对于系统恢复和缓解措施至关重要。

Method: 首先推导闭环隐蔽性条件，然后在控制器侧和工厂侧分别设计部署专用检测器，通过联合分析两个检测器对不同异常的残差响应来区分故障和攻击，并采用两阶段优化方案提高检测性能。

Result: 仿真结果验证了所提方法的有效性，能够成功检测并区分工厂故障和网络攻击。

Conclusion: 该双重检测框架能够有效检测和区分控制系统中的故障和网络攻击，为系统安全提供了可靠保障。

Abstract: Anomaly detection plays a vital role in the security and safety of
cyber-physical control systems, and accurately distinguishing between different
anomaly types is crucial for system recovery and mitigation. This study
proposes a dual detection framework for anomaly detection and discrimination.
By leveraging the dynamic characteristics of control loops and the stealthiness
features of integrity attacks, the closed-loop stealthiness condition is first
derived, and two dedicated detectors are designed and deployed on the
controller side and the plant side, respectively, enabling joint plant fault
and cyber attack detection. Moreover, by jointly analyzing the residual
response of the two detectors corresponding to different anomalies, it is
proved that the proposed method can distinguish between faults and integrity
attacks due to the detectors' individual residual spaces. According to the
detector's residual space, the fault and attack detection performance is
further improved by a two-stage optimization scheme. Simulation results
validate the effectiveness of the proposed approach.

</details>


### [109] [DiffOPF: Diffusion Solver for Optimal Power Flow](https://arxiv.org/abs/2510.14075)
*Milad Hoseinpour,Vladimir Dvorkin*

Main category: eess.SY

TL;DR: 提出DiffOPF，一种基于扩散的OPF求解器，将最优潮流问题视为条件采样问题，能够处理系统参数变化带来的多值映射问题。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习OPF求解器是单值的，无法捕捉系统参数（如导纳、拓扑结构）变化导致的调度设定点多样性，除非在特征空间中完全表示这些参数，但这在计算上不可行。

Method: DiffOPF学习负荷和调度设定点的联合分布，返回基于负荷条件的边际调度分布。它将OPF视为条件采样问题，使用扩散模型生成统计可信的预热启动点。

Result: DiffOPF能够采样具有良好成本和约束满足权衡的统计可信预热启动点，在电力系统基准测试中验证了其在规定距离内找到优化解的能力。

Conclusion: DiffOPF解决了传统单值OPF求解器的局限性，通过条件采样方法有效处理系统参数变化带来的多值映射问题，为电力系统优化提供了更灵活的解决方案。

Abstract: The optimal power flow (OPF) is a multi-valued, non-convex mapping from loads
to dispatch setpoints. The variability of system parameters (e.g., admittances,
topology) further contributes to the multiplicity of dispatch setpoints for a
given load. Existing deep learning OPF solvers are single-valued and thus fail
to capture the variability of system parameters unless fully represented in the
feature space, which is prohibitive. To solve this problem, we introduce a
diffusion-based OPF solver, termed \textit{DiffOPF}, that treats OPF as a
conditional sampling problem. The solver learns the joint distribution of loads
and dispatch setpoints from operational history, and returns the marginal
dispatch distributions conditioned on loads. Unlike single-valued solvers,
DiffOPF enables sampling statistically credible warm starts with favorable cost
and constraint satisfaction trade-offs. We explore the sample complexity of
DiffOPF to ensure the OPF solution within a prescribed distance from the
optimization-based solution, and verify this experimentally on power system
benchmarks.

</details>


### [110] [Belief Space Control of Safety-Critical Systems Under State-Dependent Measurement Noise](https://arxiv.org/abs/2510.14100)
*Rohan Walia,Mitchell Black,Andrew Schoer,Kevin Leahy*

Main category: eess.SY

TL;DR: 扩展信念控制屏障函数框架以处理状态相关的测量噪声，使用广义扩展卡尔曼滤波器算法，减少保守性控制并提高安全性


<details>
  <summary>Details</summary>
Motivation: 传统固定噪声模型无法准确表示具有状态相关误差特征的复杂传感器模态，而使用固定最坏情况边界的CBF方法会导致过度保守的控制

Method: 将信念控制屏障函数框架扩展到状态相关测量噪声，采用广义扩展卡尔曼滤波器算法建模测量噪声为状态的线性函数

Result: 在1D单积分器设定点跟踪和2D独轮车运动学轨迹跟踪场景中，BCBF-GEKF方法提供了更少保守的控制和更高的安全性

Conclusion: BCBF-GEKF方法能够有效处理状态相关测量噪声，在保证安全性的同时减少控制保守性

Abstract: Safety-critical control is imperative for deploying autonomous systems in the
real world. Control Barrier Functions (CBFs) offer strong safety guarantees
when accurate system and sensor models are available. However, widely used
additive, fixed-noise models are not representative of complex sensor
modalities with state-dependent error characteristics. Although CBFs have been
designed to mitigate uncertainty using fixed worst-case bounds on measurement
noise, this approach can lead to overly-conservative control. To solve this
problem, we extend the Belief Control Barrier Function (BCBF) framework to
accommodate state-dependent measurement noise via the Generalized Extended
Kalman Filter (GEKF) algorithm, which models measurement noise as a linear
function of the state. Using the original BCBF framework as baseline, we
demonstrate the performance of the BCBF-GEKF approach through simulation
results on a 1D single integrator setpoint tracking scenario and 2D unicycle
kinematics trajectory tracking scenario. Our results confirm that the BCBF-GEKF
approach offers less conservative control with greater safety.

</details>


### [111] [Resource-Aware Stealthy Attacks in Vehicle Platoons](https://arxiv.org/abs/2510.14119)
*Ali Eslami,Mohammad Pirani*

Main category: eess.SY

TL;DR: 本文提出了一种针对车辆编队的新型隐蔽攻击方法，攻击者可以引导编队按照期望轨迹行驶而不被发现，揭示了当前编队架构和异常检测机制的关键弱点。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注防御攻击，但对隐蔽攻击者的关注较少。车辆编队高度依赖车际通信，容易受到攻击，即使是轻微操纵也可能导致严重后果。

Method: 通过分析攻击可行性条件，研究通信拓扑和控制协议的影响，并调查攻击者所需的资源，来设计能够引导编队按期望轨迹行驶的隐蔽攻击。

Result: 研究发现当前编队架构和异常检测机制存在关键弱点，攻击者可以利用这些弱点实施隐蔽攻击而不被发现。

Conclusion: 通过描述隐蔽攻击所需资源，揭示了系统漏洞，为设计更具弹性的对抗措施提供了方法，有助于开发更安全可靠的CAV系统。

Abstract: Connected and Autonomous Vehicles (CAVs) are transforming modern
transportation by enabling cooperative applications such as vehicle platooning,
where multiple vehicles travel in close formation to improve efficiency and
safety. However, the heavy reliance on inter-vehicle communication makes
platoons highly susceptible to attacks, where even subtle manipulations can
escalate into severe physical consequences. While existing research has largely
focused on defending against attacks, far less attention has been given to
stealthy adversaries that aim to covertly manipulate platoon behavior. This
paper introduces a new perspective on the attack design problem by
demonstrating how attackers can guide platoons toward their own desired
trajectories while remaining undetected. We outline conditions under which such
attacks are feasible, analyze their dependence on communication topologies and
control protocols, and investigate the resources required by the attacker. By
characterizing the resources needed to launch stealthy attacks, we address
system vulnerabilities and informing the design of resilient countermeasures.
Our findings reveal critical weaknesses in current platoon architectures and
anomaly detection mechanisms and provide methods to develop more secure and
trustworthy CAV systems.

</details>


### [112] [A Deep State-Space Model Compression Method using Upper Bound on Output Error](https://arxiv.org/abs/2510.14542)
*Hiroki Sakamoto,Kazuhiro Sato*

Main category: eess.SY

TL;DR: 提出一种深度状态空间模型的压缩方法，通过基于h²误差范数的优化问题实现模型压缩，在IMDb任务上减少80%参数且性能仅下降4-5%


<details>
  <summary>Details</summary>
Motivation: 现有深度状态空间模型压缩方法缺乏理论保证，需要开发具有可证明输出误差保证的压缩方法

Method: 推导深度状态空间模型输出误差的上界，构建基于h²误差范数的优化问题，开发梯度模型降阶方法

Result: 在IMDb任务上实现强性能，无需重新训练即可减少约80%可训练参数，性能仅下降4-5%

Conclusion: 提出的压缩方法在保持性能的同时显著减少模型参数，优于现有方法

Abstract: We study deep state-space models (Deep SSMs) that contain
linear-quadratic-output (LQO) systems as internal blocks and present a
compression method with a provable output error guarantee. We first derive an
upper bound on the output error between two Deep SSMs and show that the bound
can be expressed via the $h^2$-error norms between the layerwise LQO systems,
thereby providing a theoretical justification for existing model order
reduction (MOR)-based compression. Building on this bound, we formulate an
optimization problem in terms of the $h^2$-error norm and develop a
gradient-based MOR method. On the IMDb task from the Long Range Arena
benchmark, we demonstrate that our compression method achieves strong
performance. Moreover, unlike prior approaches, we reduce roughly 80% of
trainable parameters without retraining, with only a 4-5% performance drop.

</details>


### [113] [High-Resolution PTDF-Based Planning of Storage and Transmission Under High Renewables](https://arxiv.org/abs/2510.14696)
*Kevin Wu,Rabab Haider,Pascal Van Hentenryck*

Main category: eess.SY

TL;DR: 提出了一个多周期两阶段PTDF模型，联合优化输电扩建和储能选址/容量规划，采用信任域多割Benders分解方法，在2000节点系统上实现低于1%的最优性差距。


<details>
  <summary>Details</summary>
Motivation: 为满足日益增长的电力需求和可再生能源并网需求，储能作为提供时间灵活性和缓解拥堵的关键资产，需要与输电扩建协同规划。

Method: 开发了多周期两阶段PTDF公式，采用信任域多割Benders分解方案，从代表性日最优解进行热启动以确保可扩展性。

Result: 在2000节点德州合成系统高可再生能源场景下，方法达到低于1%的最优性差距，规划方案在约180个节点部署储能（占峰值可再生能源容量的32%）。

Conclusion: 所提出的基于PTDF的方法能够高效处理大规模分布式储能系统，在高空间分辨率下展现出良好的可扩展性。

Abstract: Transmission Expansion Planning (TEP) optimizes power grid upgrades and
investments to ensure reliable, efficient, and cost-effective electricity
delivery while addressing grid constraints. To support growing demand and
renewable energy integration, energy storage is emerging as a pivotal asset
that provides temporal flexibility and alleviates congestion. This paper
develops a multiperiod, two-stage PTDF formulation that co-optimizes
transmission upgrades and storage siting/sizing. To ensure scalability, a
trust-region, multicut Benders scheme warm-started from per-representative-day
optima is proposed. Applied to a 2,000-bus synthetic Texas system under
high-renewable projections, the method attains final optimality gaps below 1%
and yields a plan with storage at about 180 nodes (32% of peak renewable
capacity). These results demonstrate that the proposed PTDF-based methodology
efficiently handles large distributed storage fleets, demonstrating scalability
at high spatial resolution

</details>


### [114] [A Human-Vector Susceptible--Infected--Susceptible Model for Analyzing and Controlling the Spread of Vector-Borne Diseases](https://arxiv.org/abs/2510.14787)
*Lorenzo Zino,Alessandro Casu,Alessandro Rizzo*

Main category: eess.SY

TL;DR: 提出了一个基于经典SIS模型的媒介传播疾病传播模型，包含人类和媒介两个种群，通过交叉感染机制描述疾病传播，并利用单调系统理论分析全局动态行为。


<details>
  <summary>Details</summary>
Motivation: 传统SIS模型无法充分描述媒介传播疾病的复杂动态，需要开发包含人类和媒介种群交互的扩展模型来更准确地刻画这类疾病的传播机制。

Method: 构建包含人类和媒介两个种群的ODE系统模型，利用单调系统理论分析全局渐近行为，并引入向量控制和保护措施激励两种控制策略。

Result: 确定了疾病快速根除的条件（所有轨迹收敛到无病平衡点）和收敛到唯一地方性平衡点的条件，评估了两种控制策略的影响并确定了最优控制策略。

Conclusion: 该模型为媒介传播疾病的动态分析和控制策略制定提供了严格的数学框架，能够有效指导疾病防控工作。

Abstract: We propose an epidemic model for the spread of vector-borne diseases. The
model, which is built extending the classical susceptible-infected-susceptible
model, accounts for two populations -- humans and vectors -- and for
cross-contagion between the two species, whereby humans become infected upon
interaction with carrier vectors, and vectors become carriers after interaction
with infected humans. We formulate the model as a system of ordinary
differential equations and leverage monotone systems theory to rigorously
characterize the epidemic dynamics. Specifically, we characterize the global
asymptotic behavior of the disease, determining conditions for quick
eradication of the disease (i.e., for which all trajectories converge to a
disease-free equilibrium), or convergence to a (unique) endemic equilibrium.
Then, we incorporate two control actions: namely, vector control and incentives
to adopt protection measures. Using the derived mathematical tools, we assess
the impact of these two control actions and determine the optimal control
policy.

</details>


### [115] [Improved Voltage Regulation with Optimal Design of Decentralized Volt-VAr Control](https://arxiv.org/abs/2510.14834)
*Daniel Russell,Dakota Hamilton,Mads R. Almassalkhi,Hamid R. Ossareh*

Main category: eess.SY

TL;DR: 提出了一种基于谱半径稳定性约束的分散式电压-无功控制方法，用于改善配电网电压调节性能。


<details>
  <summary>Details</summary>
Motivation: 分布式能源接入需要自主动态电压调节，但设计不当的分散式电压-无功控制可能导致电网反馈不稳定。

Method: 使用线性化潮流方法建模电网-VVC闭环动态，基于历史数据改进LinDistFlow模型，通过最小化稳态电压偏差并施加非凸谱半径稳定性约束来设计VVC斜率。

Result: 在真实馈线上仿真表明，使用谱半径约束比现有凸限制方法能实现更有效的电压调节。

Conclusion: 谱半径稳定性约束在分散式电压-无功控制设计中能提供更好的电压调节性能。

Abstract: Integration of distributed energy resources has created a need for
autonomous, dynamic voltage regulation. Decentralized Volt-VAr Control (VVC) of
grid-connected inverters presents a unique opportunity for voltage management
but, if designed poorly, can lead to unstable behavior when in feedback with
the grid. We model the grid-VVC closed-loop dynamics with a linearized power
flow approach, leveraging historical data, which shows improvement over the
commonly used LinDistFlow model. This model is used to design VVC slopes by
minimizing steady-state voltage deviation from the nominal value, subject to a
non-convex spectral radius stability constraint, which has not been previously
implemented within this context. We compare this constraint to existing convex
restrictions and demonstrate, through simulations on a realistic feeder, that
using the spectral radius results in more effective voltage regulation.

</details>


### [116] [Dynamic-Key-Aware Co-Simulation Framework for Next Generation of SCADA Systems Encrypted by Quantum-Key-Distribution Techniques](https://arxiv.org/abs/2510.14838)
*Ziqing Zhu*

Main category: eess.SY

TL;DR: 提出一个用于SCADA系统的多层建模和优化框架，集成量子密钥分发(QKD)，通过双层Stackelberg博弈解决TSO和DSO之间的密钥资源分配冲突，提高任务成功率和电网稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有电力系统QKD应用主要关注点对点安全通信，缺乏对密钥动态与控制调度系统级耦合的考虑，需要解决TSO和DSO之间的密钥资源分配冲突。

Method: 构建统一模型集成量子密钥生成、消耗、库存预测和控制延迟，采用双层Stackelberg博弈框架，开发LD-CP算法求解MPCC问题，并建立端到端协同仿真平台。

Result: 在IEEE 39和118节点系统测试中，任务成功率提高25%，峰值频率偏差减少70%，密钥利用率达到83%。

Conclusion: 为未来电网量子安全控制系统奠定了基础，展示了集成QKD的SCADA系统在提升电力系统安全性和稳定性方面的潜力。

Abstract: To address growing cybersecurity challenges in modern power dispatch systems,
this paper proposes a multi-layer modeling and optimization framework for SCADA
systems enhanced with quantum key distribution (QKD). While most existing
applications of QKD in the power sector focus on building secure point-to-point
communication tunnels, they rarely consider the system-level coupling between
key dynamics and control scheduling. In contrast, our approach integrates
quantum key generation, consumption, inventory prediction, and control latency
into a unified model, enabling key-aware reconfiguration of SCADA control
chains based on task security demands and real-time resource constraints. To
resolve conflicts in key resource allocation between transmission system
operators (TSOs) and distribution system operators (DSOs), we formulate a
bi-level Stackelberg game and transform it into a mathematical program with
complementarity constraints (MPCC). We further develop an efficient Level
Decomposition-Complementarity Pruning (LD-CP) algorithm to solve the problem.
To support reproducible evaluation, we build an end-to-end co-simulation
platform that integrates physical-layer disruptions via OpenQKD-Sim,
Q3P/IEC-104 protocol stack binding, and real-time control-chain monitoring
through Grafana. Experimental results on the IEEE 39- and 118-bus systems show
that our method increases task success rate by 25%, reduces peak frequency
deviation by 70%, and improves key utilization to 83%. This work lays the
foundation for future quantum-secure control systems in power grid operations.

</details>


### [117] [Through-the-Earth Magnetic Induction Communication and Networking: A Comprehensive Survey](https://arxiv.org/abs/2510.14854)
*Honglei Ma,Erwu Liu,Wei Ni,Zhijun Fang,Rui Wang,Yongbin Gao,Dusit Niyato,Ekram Hossain*

Main category: eess.SY

TL;DR: 本文对地下磁感应通信(MIC)进行了全面综述，涵盖应用、信道建模、点对点通信设计、中继技术、网络框架和新兴技术，提出了支持TCP/IP和Linux的MIC框架，并识别了研究挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 磁感应通信因其出色的穿透能力成为地下通信网络的有前景候选技术，与下一代移动通信系统的空天地一体化网络集成需要明确的网络架构，MI快速衰落这一新发现仍处于早期阶段并带来独特挑战。

Method: 对MI信道功率增益进行细粒度分解为四个物理参数，提出新的几何模型分析MI快速衰落，总结中继技术，研究高密度网络中的串扰效应，探索OSI框架下的关键研究任务，提出支持TCP/IP和Linux的MIC框架。

Result: 提出了一个全面的MIC框架，支持TCP/IP和Linux，使研究人员能够利用Linux资源和深度学习平台加速SAGUI网络中MIC的发展。

Conclusion: 本文为磁感应通信研究提供了系统性的综述和框架，识别了剩余的研究挑战、开放问题和有前景的新技术，推动了MIC在空天地一体化网络中的发展。

Abstract: Magnetic induction (MI) communication (MIC) has emerged as a promising
candidate for underground communication networks due to its excellent
penetration capabilities. Integration with Space-Air-Ground-Underground (SAGUI)
networks in next-generation mobile communication systems requires a
well-defined network architecture. A recent discovery in MIC research, MI fast
fading, remains in its early stages and presents unique challenges. This paper
provides a comprehensive survey on through-the-earth (TTE) MIC, covering MI
applications, channel modeling, point-to-point MIC design, relay techniques,
network frameworks, and emerging technologies. We compare various MIC
applications to highlight TTE-specific challenges and review the principles of
channel modeling, addressing both MI slow fading and MI fast fading, along with
its potential impact on existing MIC theories. We conduct a fine-grained
decomposition of MI channel power gain into four distinct physical parameters,
and propose a novel geometric model to analyze MI fast fading. We also
summarize MI relay techniques, examine crosstalk effects in relay and
high-density networks, and explore key research tasks within the OSI framework
for a holistic MI network protocol in SAGUI. To bridge the gaps identified, we
propose a MIC framework that supports TCP/IP and Linux, enabling full
implementation of existing and emerging MIC solutions. This framework empowers
researchers to leverage Linux resources and deep learning platforms for
accelerated development of MIC in SAGUI networks. Remaining research
challenges, open issues, and promising novel techniques are further identified
to advance MIC research.

</details>


### [118] [Further Results on Safety-Critical Stabilization of Force-Controlled Nonholonomic Mobile Robots](https://arxiv.org/abs/2510.14931)
*Bo Wang,Tianyu Han,Guangwei Wang*

Main category: eess.SY

TL;DR: 提出基于gamma m-QP框架的连续时不变控制律，解决力控非完整移动机器人在安全约束下的镇定问题，首次构建了全局时不变严格Lyapunov函数，保证闭环系统的渐近稳定性和安全性。


<details>
  <summary>Details</summary>
Motivation: 解决非完整移动机器人在安全关键约束下的镇定问题，需要同时保证系统稳定性和安全性，传统方法难以统一处理CLF和CBF。

Method: 采用gamma m-QP框架统一CLF和CBF，在极坐标下构建全局时不变严格Lyapunov函数作为CLF，通过积分反步法开发CBF。

Result: 理论保证闭环系统渐近稳定性和安全性，仿真和实验结果验证了方法的有效性和性能。

Conclusion: 提出的控制方法成功解决了非完整移动机器人在安全约束下的镇定问题，为类似系统提供了有效的控制框架。

Abstract: In this paper, we address the stabilization problem for force-controlled
nonholonomic mobile robots under safety-critical constraints. We propose a
continuous, time-invariant control law based on the gamma m-quadratic
programming (gamma m-QP) framework, which unifies control Lyapunov functions
(CLFs) and control barrier functions (CBFs) to enforce both stability and
safety in the closed-loop system. For the first time, we construct a global,
time-invariant, strict Lyapunov function for the closed-loop nonholonomic
mobile robot system with a nominal stabilization controller in polar
coordinates; this strict Lyapunov function then serves as the CLF in the QP
design. Next, by exploiting the inherent cascaded structure of the vehicle
dynamics, we develop a CBF for the mobile robot via an integrator backstepping
procedure. Our main results guarantee both asymptotic stability and safety for
the closed-loop system. Both the simulation and experimental results are
presented to illustrate the effectiveness and performance of our approach.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [119] [The Impact of Medicaid Coverage on Mental Health, Why Insurance Makes People Happier in OHIE: by Spending Less or by Spending More?](https://arxiv.org/abs/2510.14909)
*Yangyang Li*

Main category: econ.GN

TL;DR: 俄勒冈健康保险实验研究发现，医疗补助覆盖通过减轻医疗费用负担，显著降低了低收入成年人不快乐的概率，并改善了特定亚组的幸福感。


<details>
  <summary>Details</summary>
Motivation: 探索医疗补助覆盖与低收入成年人幸福感之间的因果关系，分析医疗支出变化如何影响心理健康。

Method: 利用俄勒冈健康保险实验的随机分配数据，采用工具变量回归方法，按支出水平和幸福感评级对亚组进行六种回归分析。

Result: 参加OHP显著降低了不快乐的概率（无论医疗支出高低）；降低了高支出且相当快乐的概率；增加了低支出且非常快乐的概率；对高支出且非常快乐的人群影响不显著。

Conclusion: 医疗补助通过减轻财务负担，对不同亚组的幸福感产生差异化影响，支持了医疗补助在改善低收入人群福祉方面的积极作用。

Abstract: The Oregon Health Insurance Experiment (OHIE) offers a unique opportunity to
examine the causal relationship between Medicaid coverage and happiness among
low-income adults, using an experimental design. This study leverages data from
comprehensive surveys conducted at 0 and 12 months post-treatment. Previous
studies based on OHIE have shown that individuals receiving Medicaid exhibited
a significant improvement in mental health compared to those who did not
receive coverage. The primary objective is to explore how Medicaid coverage
impacts happiness, specifically analyzing in which direction variations in
healthcare spending significantly improve mental health: higher spending or
lower spending after Medicaid. Utilizing instrumental variable (IV) regression,
I conducted six separate regressions across subgroups categorized by
expenditure levels and happiness ratings, and the results reveal distinct
patterns. Enrolling in OHP has significantly decreased the probability of
experiencing unhappiness, regardless of whether individuals had high or low
medical spending. Additionally, it decreased the probability of being pretty
happy and having high medical expenses, while increasing the probability among
those with lower expenses. Concerning the probability of being very happy, the
OHP only had a positive effect on being very happy and spending less, and its
effect on those with high expenses was insignificant. These findings align with
the benefit of Medicaid: alleviating financial burden, contributing to the
well-being of distinct subgroups.

</details>


### [120] [The Economic Dividends of Peace: Evidence from Arab-Israeli Normalization](https://arxiv.org/abs/2510.14517)
*Mitja Kovac,Rok Spruk*

Main category: econ.GN

TL;DR: 该研究首次提供了阿拉伯-以色列和平条约长期经济红利的因果证据，发现埃及和约旦在签订和平条约后分别实现了64%和75%的实际GDP增长，以及82%和20%以上的人均收入增长。


<details>
  <summary>Details</summary>
Motivation: 研究动机是填补关于阿拉伯-以色列和平条约长期经济影响的因果证据空白，探究和平协议是否能带来持久的经济红利。

Method: 使用合成控制法和差分合成控制估计器，分析1978年戴维营协议和1994年约旦-以色列和平条约的经济影响。

Result: 埃及到2011年实际GDP超过其合成反事实64%，人均收入超过82%；约旦实际GDP增长75%，人均收入增长超过20%。机制分析显示埃及受益于财政重新分配、外国直接投资增加和制度信誉改善，约旦则主要通过贸易和金融流入获益。

Conclusion: 和平协议能产生巨大、持久且异质性的增长红利，稳健性和安慰剂检验证实了这些效应的独特性。

Abstract: This paper provides the first causal evidence on the long-run economic
dividends of Arab-Israeli peace treaties. Using synthetic control and
difference-in-synthetic control estimators, we analyze 1978 Camp David Accords
and 1994 peace treaty between Jordan and Israel. Both cases reveal large and
lasting gains. By 2011, real GDP of Egypt exceeded its synthetic counterfactual
by 64 percent, and per capita income by 82 percent. Jordanian trajectory shows
similarly permanent improvements, with real GDP higher by 75 percent and per
capita income by more than 20 percent. The mechanisms differ: in Egypt, gains
stem from a sharp fiscal reallocation together with higher foreign direct
investment and improved institutional credibility, while Jordan benefited
primarily through enhanced trade and financial inflows. Robustness and placebo
tests confirm the uniqueness of these effects. The results demonstrate that
peace agreements yield large, durable, and heterogeneous growth dividends.

</details>
