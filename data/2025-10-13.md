<div id=toc></div>

# Table of Contents

- [econ.TH](#econ.TH) [Total: 3]
- [econ.EM](#econ.EM) [Total: 4]
- [cs.AI](#cs.AI) [Total: 37]
- [cs.RO](#cs.RO) [Total: 31]
- [cs.CY](#cs.CY) [Total: 11]
- [cs.ET](#cs.ET) [Total: 2]
- [cs.LG](#cs.LG) [Total: 1]
- [econ.GN](#econ.GN) [Total: 2]
- [q-fin.GN](#q-fin.GN) [Total: 1]
- [eess.SY](#eess.SY) [Total: 16]
- [cs.SI](#cs.SI) [Total: 3]
- [stat.AP](#stat.AP) [Total: 1]


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [1] [Blackwell without Priors](https://arxiv.org/abs/2510.08709)
*Maxwell Rosenthal*

Main category: econ.TH

TL;DR: 本文提出了一个完全无先验的实验模型，决策者在已知实验但未知状态分布下观察信号分布。一个实验比另一个更稳健信息丰富，当决策者在观察前者输出后的最大最小期望效用总是至少等于后者。


<details>
  <summary>Details</summary>
Motivation: 传统Blackwell排序要求实验在所有先验分布下都更优，这限制了可比性。本文旨在开发一个更宽松但仍有意义的实验信息性比较标准。

Method: 通过分析实验的线性变换关系和零空间包含关系，建立稳健信息性排序的充要条件。

Result: 证明一个实验比另一个更稳健信息丰富当且仅当信息较少的实验是信息较多实验的线性变换，或信息较多实验的零空间是信息较少实验零空间的子集。

Conclusion: 新标准比Blackwell排序更宽松，允许更多实验对进行比较，为实验信息性评估提供了新的理论框架。

Abstract: This paper proposes a fully prior-free model of experimentation in which the
decision maker observes the entire distribution of signals generated by a known
experiment under an unknown distribution of the state of the world. One
experiment is robustly more informative than another if the decision maker's
maxmin expected utility after observing the output of the former is always at
least her maxmin expected utility after observing the latter. We show that this
ranking holds if and only if the less informative experiment is a linear
transformation of the more informative experiment; equivalently, the null space
of the more informative experiment is a subset of the null space of the less
informative experiment. Our criterion is implied by Blackwell's order but does
not imply it, and we show by example that our ranking admits strictly more
comparable pairs of experiments than the classical ranking.

</details>


### [2] [Arrow's Impossibility Theorem as a Generalisation of Condorcet's Paradox](https://arxiv.org/abs/2510.09076)
*Ori Livson,Mikhail Prokopenko*

Main category: econ.TH

TL;DR: 本文证明了阿罗不可能定理可以等价地表述为矛盾偏好循环问题，将D'Antoni的方法推广到包含弱偏好的完整情况。


<details>
  <summary>Details</summary>
Motivation: 阿罗不可能定理是社会科学选择理论的基础性成果，但现有关于其与孔多塞悖论关系的证明仅限于严格偏好情况。本文旨在填补这一空白，将证明推广到包含弱偏好的完整情况。

Method: 通过显式构造导致偏好循环的配置，将D'Antoni的方法论推广到包含弱偏好的情况，证明阿罗不可能定理可以等价地表述为矛盾偏好循环问题。

Result: 成功证明了在包含弱偏好的完整情况下，阿罗不可能定理确实可以等价地表述为矛盾偏好循环问题，并获得了关于社会福利函数的若干额外事实。

Conclusion: 该方法论不仅完善了阿罗不可能定理与孔多塞悖论关系的理论框架，还可能为其他领域（如金钱泵、荷兰赌、不可传递博弈等）的偏好循环研究提供新的洞见。

Abstract: Arrow's Impossibility Theorem is a seminal result of Social Choice Theory
that demonstrates the impossibility of ranked-choice decision-making processes
to jointly satisfy a number of intuitive and seemingly desirable constraints.
The theorem is often described as a generalisation of Condorcet's Paradox,
wherein pairwise majority voting may fail to jointly satisfy the same
constraints due to the occurrence of elections that result in contradictory
preference cycles. However, a formal proof of this relationship has been
limited to D'Antoni's work, which applies only to the strict preference case,
i.e., where indifference between alternatives is not allowed. In this paper, we
generalise D'Antoni's methodology to prove in full (i.e., accounting for weak
preferences) that Arrow's Impossibility Theorem can be equivalently stated in
terms of contradictory preference cycles. This methodology involves explicitly
constructing profiles that lead to preference cycles. Using this framework, we
also prove a number of additional facts regarding social welfare functions. As
a result, this methodology may yield further insights into the nature of
preference cycles in other domains e.g., Money Pumps, Dutch Books, Intransitive
Games, etc.

</details>


### [3] [Ranking Policies Under Loss Aversion and Inequality Aversion](https://arxiv.org/abs/2510.09590)
*Martyna Kobus,Radosław Kurek,Thomas Parker*

Main category: econ.TH

TL;DR: 提出一个考虑个体得失的新福利分析框架，开发双变量随机优势标准来评估政策结果，关注收入变化与绝对收入的联合分布特征。


<details>
  <summary>Details</summary>
Motivation: 实证研究表明个体在评估自身状况时会关注得失体验，且损失比收益影响更大，这种损失厌恶会影响政治家的政策选择，因此需要新的福利分析框架。

Method: 开发双变量随机优势标准，考虑收入变化和绝对收入的联合分布，将损失厌恶、不平等厌恶等偏好转化为可通过样本数据检验的函数不等式。

Result: 使用康涅狄格州收入支持实验数据进行概念和方法验证，展示了该框架的实际应用价值。

Conclusion: 提出的福利分析框架能够更全面地评估政策结果，不仅关注最终收入水平，还考虑了个体在政策实施过程中的得失体验。

Abstract: Strong empirical evidence from laboratory experiments, and more recently from
population surveys, shows that individuals, when evaluating their situations,
pay attention to whether they experience gains or losses, with losses weighing
more heavily than gains. The electorate's loss aversion, in turn, influences
politicians' choices. We propose a new framework for welfare analysis of policy
outcomes that, in addition to the traditional focus on post-policy incomes,
also accounts for individuals' gains and losses resulting from policies. We
develop several bivariate stochastic dominance criteria for ranking policy
outcomes that are sensitive to features of the joint distribution of
individuals' income changes and absolute incomes. The main social objective
assumes that individuals are loss averse with respect to income gains and
losses, inequality averse with respect to absolute incomes, and hold varying
preferences regarding the association between incomes and income changes. We
translate these and other preferences into functional inequalities that can be
tested using sample data. The concepts and methods are illustrated using data
from an income support experiment conducted in Connecticut.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [4] [Sensitivity Analysis for Treatment Effects in Difference-in-Differences Models using Riesz Representation](https://arxiv.org/abs/2510.09064)
*Philipp Bach,Sven Klaassen,Jannis Kueck,Mara Mattes,Martin Spindler*

Main category: econ.EM

TL;DR: 提出了一种用于双重差分模型的新敏感性分析方法，评估因不可观测混杂因素导致平行趋势假设违反时估计结果的稳健性。


<details>
  <summary>Details</summary>
Motivation: 双重差分模型在实证研究中广泛应用，但其识别依赖于条件平行趋势假设。当存在不可观测混杂因素时，这一假设可能被违反，影响因果推断的可靠性。

Method: 基于双重机器学习估计，扩展了基于Riesz表示的敏感性分析方法，建立了点估计和置信区间的渐近界限，适用于标准2×2设置和交错处理采用设置。

Result: 该方法能够将平行趋势违反与(1)预检验、(2)协变量基准测试和(3)标准报告统计和可视化的实证证据联系起来。

Conclusion: 该方法为研究人员提供了一种透明评估和传达因果估计结果可信度的工具，通过模拟实验验证了敏感性方法和诊断的有效性。

Abstract: Difference-in-differences (DiD) is one of the most popular approaches for
empirical research in economics, political science, and beyond. Identification
in these models is based on the conditional parallel trends assumption: In the
absence of treatment, the average outcome of the treated and untreated group
are assumed to evolve in parallel over time, conditional on pre-treatment
covariates. We introduce a novel approach to sensitivity analysis for DiD
models that assesses the robustness of DiD estimates to violations of this
assumption due to unobservable confounders, allowing researchers to
transparently assess and communicate the credibility of their causal estimation
results. Our method focuses on estimation by Double Machine Learning and
extends previous work on sensitivity analysis based on Riesz Representation in
cross-sectional settings. We establish asymptotic bounds for point estimates
and confidence intervals in the canonical $2\times2$ setting and group-time
causal parameters in settings with staggered treatment adoption. Our approach
makes it possible to relate the formulation of parallel trends violation to
empirical evidence from (1) pre-testing, (2) covariate benchmarking and (3)
standard reporting statistics and visualizations. We provide extensive
simulation experiments demonstrating the validity of our sensitivity approach
and diagnostics and apply our approach to two empirical applications.

</details>


### [5] [Sensitivity Analysis for Causal ML: A Use Case at Booking.com](https://arxiv.org/abs/2510.09109)
*Philipp Bach,Victor Chernozhukov,Carlos Cinelli,Lin Jia,Sven Klaassen,Nils Skotara,Martin Spindler*

Main category: econ.EM

TL;DR: 本文介绍了敏感性分析在因果机器学习中的重要性，通过Booking.com的模拟用例展示了如何评估因果效应估计对未观测混杂因素的稳健性。


<details>
  <summary>Details</summary>
Motivation: 因果机器学习从观测数据估计因果效应时依赖不可检验的假设（如无未观测混杂因素），当这些假设被违反时，估计结果会产生偏差，影响研究结论的有效性。

Method: 采用Chernozhukov等人(2023)提出的方法，该方法推导了因遗漏变量导致的偏差的通用非参数边界，并与现代因果机器学习推断工具完全兼容。

Result: 通过Booking.com的模拟数据用例展示了敏感性分析的实际应用价值，能够帮助数据科学家评估研究结果对未观测混杂因素的稳健性。

Conclusion: 敏感性分析在现实场景中至关重要，本文旨在提高对敏感性分析的认识并强调其在因果推断中的重要性。

Abstract: Causal Machine Learning has emerged as a powerful tool for flexibly
estimating causal effects from observational data in both industry and
academia. However, causal inference from observational data relies on
untestable assumptions about the data-generating process, such as the absence
of unobserved confounders. When these assumptions are violated, causal effect
estimates may become biased, undermining the validity of research findings. In
these contexts, sensitivity analysis plays a crucial role, by enabling data
scientists to assess the robustness of their findings to plausible violations
of unconfoundedness. This paper introduces sensitivity analysis and
demonstrates its practical relevance through a (simulated) data example based
on a use case at Booking.com. We focus our presentation on a recently proposed
method by Chernozhukov et al. (2023), which derives general non-parametric
bounds on biases due to omitted variables, and is fully compatible with (though
not limited to) modern inferential tools of Causal Machine Learning. By
presenting this use case, we aim to raise awareness of sensitivity analysis and
highlight its importance in real-world scenarios.

</details>


### [6] [Flexibility without foresight: the predictive limitations of mixture models](https://arxiv.org/abs/2510.09185)
*Stephane Hess,Sander van Cranenburgh*

Main category: econ.EM

TL;DR: 随机异质性模型在预测表现和市场份额恢复方面没有优势，唯一的例外是在对估计样本中的相同个体进行预测时使用条件分布。


<details>
  <summary>Details</summary>
Motivation: 研究随机异质性模型（如混合logit和潜在类别模型）在模型拟合和揭示未观测偏好异质性方面的优势是否能够转化为预测性能的提升。

Method: 使用理论论证和两个案例研究（基于显示选择和陈述选择数据）来评估随机异质性模型在预测性能和市场共享恢复方面的表现。

Result: 随机异质性模型在模型拟合和揭示偏好异质性方面具有优势，但这些优势并不能转化为预测性能或市场份额恢复的任何益处。

Conclusion: 随机异质性模型在预测方面没有优势，唯一的例外是在对估计样本中的相同个体进行预测时使用条件分布，但这排除了任何样本外预测的可能性。

Abstract: Models allowing for random heterogeneity, such as mixed logit and latent
class, are generally observed to obtain superior model fit and yield detailed
insights into unobserved preference heterogeneity. Using theoretical arguments
and two case studies on revealed and stated choice data, this paper highlights
that these advantages do not translate into any benefits in forecasting,
whether looking at prediction performance or the recovery of market shares. The
only exception arises when using conditional distributions in making
predictions for the same individuals included in the estimation sample, which
obviously precludes any out-of-sample forecasting.

</details>


### [7] [Boundary estimation in the regression-discontinuity design: Evidence for a merit- and need-based financial aid program](https://arxiv.org/abs/2510.09257)
*Eugenio Felipe Merlano*

Main category: econ.EM

TL;DR: 本文研究了扩展的回归断点设计，其中分配规则同时涉及两个或多个连续协变量，提出了通过单变量局部线性回归估计多维断点的灵活非参数方法，并在哥伦比亚低收入学生资助项目中进行了实证应用。


<details>
  <summary>Details</summary>
Motivation: 传统单变量RD设计在处理概率在单一协变量超过阈值时发生不连续变化，限制了估计的局部性。本文旨在通过多维RD设计估计更全面的处理效应，缓解单变量RD的局限性。

Method: 提出了通过单变量局部线性回归估计多维断点的灵活非参数方法，并与现有方法进行性能比较。

Result: 在哥伦比亚低收入学生资助项目的实证应用中，该估计策略充分利用了多维分配规则，揭示了沿处理边界的异质性效应。

Conclusion: 多维RD设计能够估计更全面的处理效应，放松了单变量RD设计的局部限制，提出的非参数方法有效利用了多维分配规则并揭示了异质性效应。

Abstract: In the conventional regression-discontinuity (RD) design, the probability
that units receive a treatment changes discontinuously as a function of one
covariate exceeding a threshold or cutoff point. This paper studies an extended
RD design where assignment rules simultaneously involve two or more continuous
covariates. We show that assignment rules with more than one variable allow the
estimation of a more comprehensive set of treatment effects, relaxing in a
research-driven style the local and sometimes limiting nature of univariate RD
designs. We then propose a flexible nonparametric approach to estimate the
multidimensional discontinuity by univariate local linear regression and
compare its performance to existing methods. We present an empirical
application to a large-scale and countrywide financial aid program for
low-income students in Colombia. The program uses a merit-based (academic
achievement) and need-based (wealth index) assignment rule to select students
for the program. We show that our estimation strategy fully exploits the
multidimensional assignment rule and reveals heterogeneous effects along the
treatment boundaries.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [8] [Hypothesis Hunting with Evolving Networks of Autonomous Scientific Agents](https://arxiv.org/abs/2510.08619)
*Tennison Liu,Silas Ruhrberg Estévez,David L. Bentley,Mihaela van der Schaar*

Main category: cs.AI

TL;DR: 提出AScience框架和ASCollab系统，通过LLM智能体网络进行大规模科学假设探索，在癌症队列实验中验证了其发现已知生物标志物、扩展已知通路和提出新治疗靶点的能力。


<details>
  <summary>Details</summary>
Motivation: 大规模科学数据集为无特定研究问题的探索性发现创造了机会，需要支持在复杂假设空间中进行持续探索的假设狩猎过程。

Method: 引入AScience框架，将发现建模为智能体、网络和评估规范的交互，实现为ASCollab分布式系统，包含具有异质行为的LLM研究智能体，这些智能体在共享评估标准下自组织成演化网络，持续产生和同行评审发现。

Result: 实验表明，这种社会动态能够在多样性-质量-新颖性前沿积累专家评级结果，包括重新发现已建立的生物标志物、扩展已知通路和提出新的治疗靶点。

Conclusion: 虽然湿实验室验证仍然不可或缺，但在癌症队列上的实验证明，社会结构化的智能体网络能够大规模持续进行探索性假设狩猎。

Abstract: Large-scale scientific datasets -- spanning health biobanks, cell atlases,
Earth reanalyses, and more -- create opportunities for exploratory discovery
unconstrained by specific research questions. We term this process hypothesis
hunting: the cumulative search for insight through sustained exploration across
vast and complex hypothesis spaces. To support it, we introduce AScience, a
framework modeling discovery as the interaction of agents, networks, and
evaluation norms, and implement it as ASCollab, a distributed system of
LLM-based research agents with heterogeneous behaviors. These agents
self-organize into evolving networks, continually producing and peer-reviewing
findings under shared standards of evaluation. Experiments show that such
social dynamics enable the accumulation of expert-rated results along the
diversity-quality-novelty frontier, including rediscoveries of established
biomarkers, extensions of known pathways, and proposals of new therapeutic
targets. While wet-lab validation remains indispensable, our experiments on
cancer cohorts demonstrate that socially structured, agentic networks can
sustain exploratory hypothesis hunting at scale.

</details>


### [9] [Optimizing delivery for quick commerce factoring qualitative assessment of generated routes](https://arxiv.org/abs/2510.08671)
*Milon Bhattacharya,Milan Kumar*

Main category: cs.AI

TL;DR: 该研究提出使用大语言模型来评估车辆路径规划生成的配送路线，通过策略标准进行批判性分析，在印度电商物流场景中实现了79-86%的路由问题识别准确率。


<details>
  <summary>Details</summary>
Motivation: 印度电商市场快速增长，最后一公里配送占运营成本近一半。传统VRP求解器在真实场景中受限于非结构化地址、不完整地图和计算约束，效果有限。

Method: 提出一个框架，使用大语言模型基于策略标准对VRP生成的路由进行批判性评估，生成、标注并评估了400个案例。

Result: 开源LLM识别路由问题的准确率达到79%，专有推理模型最高达到86%。LLM评估超越了传统的距离和时间指标。

Conclusion: 基于LLM的VRP路由评估是一种有效且可扩展的评估层，有助于提高成本效率、配送可靠性和可持续性，特别适用于印度等发展中国家。

Abstract: Indias e-commerce market is projected to grow rapidly, with last-mile
delivery accounting for nearly half of operational expenses. Although vehicle
routing problem (VRP) based solvers are widely used for delivery planning,
their effectiveness in real-world scenarios is limited due to unstructured
addresses, incomplete maps, and computational constraints in distance
estimation. This study proposes a framework that employs large language models
(LLMs) to critique VRP-generated routes against policy-based criteria, allowing
logistics operators to evaluate and prioritise more efficient delivery plans.
As a illustration of our approach we generate, annotate and evaluated 400 cases
using large language models. Our study found that open-source LLMs identified
routing issues with 79% accuracy, while proprietary reasoning models achieved
reach upto 86%. The results demonstrate that LLM-based evaluation of
VRP-generated routes can be an effective and scalable layer of evaluation which
goes beyond beyond conventional distance and time based metrics. This has
implications for improving cost efficiency, delivery reliability, and
sustainability in last-mile logistics, especially for developing countries like
India.

</details>


### [10] [Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation](https://arxiv.org/abs/2510.08713)
*Yifei Dong,Fengyi Wu,Guangyu Chen,Zhi-Qi Cheng,Qiyu Hu,Yuxuan Zhou,Jingdong Sun,Jun-Yan He,Qi Dai,Alexander G Hauptmann*

Main category: cs.AI

TL;DR: 提出UniWM统一世界模型，将视觉预测和导航规划集成到单一多模态自回归框架中，通过层次化记忆机制实现长期稳定推理，显著提升导航性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有模块化架构中导航规划与视觉世界建模分离导致的动作状态不对齐问题，提升在动态和未知场景中的适应性。

Method: 采用统一、记忆增强的世界模型，将自我中心视觉预测和规划集成到多模态自回归主干网络中，通过层次化记忆机制整合短期感知线索和长期轨迹上下文。

Result: 在四个挑战性基准测试中，导航成功率提升高达30%，轨迹误差显著降低，并在未见过的TartanDrive数据集上表现出优秀的零样本泛化能力。

Conclusion: UniWM是实现统一、想象力驱动的具身导航的重要进展，通过紧密对齐预测与控制，提升了导航的鲁棒性和泛化性。

Abstract: Enabling embodied agents to effectively imagine future states is critical for
robust and generalizable visual navigation. Current state-of-the-art
approaches, however, adopt modular architectures that separate navigation
planning from visual world modeling, leading to state-action misalignment and
limited adaptability in novel or dynamic scenarios. To overcome this
fundamental limitation, we propose UniWM, a unified, memory-augmented world
model integrating egocentric visual foresight and planning within a single
multimodal autoregressive backbone. Unlike modular frameworks, UniWM explicitly
grounds action decisions in visually imagined outcomes, ensuring tight
alignment between prediction and control. A hierarchical memory mechanism
further integrates detailed short-term perceptual cues with longer-term
trajectory context, enabling stable, coherent reasoning over extended horizons.
Extensive experiments across four challenging benchmarks (Go Stanford, ReCon,
SCAND, HuRoN) demonstrate that UniWM substantially improves navigation success
rates by up to 30%, significantly reduces trajectory errors compared to strong
baselines, and exhibits impressive zero-shot generalization on the unseen
TartanDrive dataset. These results highlight UniWM as a principled step toward
unified, imagination-driven embodied navigation.

</details>


### [11] [Physics-Informed High-order Graph Dynamics Identification Learning for Predicting Complex Networks Long-term Dynamics](https://arxiv.org/abs/2510.09082)
*Bicheng Wang,Jinping Wang,Yibo Sue*

Main category: cs.AI

TL;DR: 本文提出了一种高阶网络动力学识别方法，用于复杂网络的长期动态预测。通过动态超图学习捕捉高阶非成对关系，并结合物理数据双驱动预测模块，确保预测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个主要问题：1）传统图机器学习只能处理成对关系，难以捕捉网络中的高阶非成对结构关系；2）理论预测模型缺乏准确性，数据驱动预测模型缺乏可解释性。

Method: 1）引入动态超图学习捕捉复杂网络中的高阶非成对关系；2）提出物理数据双驱动动态预测模块，结合Koopman算子理论将非线性动力学微分方程转化为线性系统，并利用物理信息神经微分方程方法确保动态演化符合物理规律。

Result: 在公共数据集和自建产业链网络数据集上的实验验证表明，该方法具有良好的预测准确性和长期预测性能。

Conclusion: 所提出的高阶网络动力学识别方法能够有效解决复杂网络动态预测中的高阶关系建模问题，同时保证了预测的准确性和可解释性。

Abstract: Learning complex network dynamics is fundamental to understanding, modelling
and controlling real-world complex systems. There are two main problems in the
task of predicting the dynamic evolution of complex networks: on the one hand,
existing methods usually use simple graphs to describe the relationships in
complex networks; however, this approach can only capture pairwise
relationships, while there may be rich non-pairwise structured relationships in
the network. First-order GNNs have difficulty in capturing dynamic non-pairwise
relationships. On the other hand, theoretical prediction models lack accuracy
and data-driven prediction models lack interpretability. To address the above
problems, this paper proposes a higher-order network dynamics identification
method for long-term dynamic prediction of complex networks. Firstly, to
address the problem that traditional graph machine learning can only deal with
pairwise relations, dynamic hypergraph learning is introduced to capture the
higher-order non-pairwise relations among complex networks and improve the
accuracy of complex network modelling. Then, a dual-driven dynamic prediction
module for physical data is proposed. The Koopman operator theory is introduced
to transform the nonlinear dynamical differential equations for the dynamic
evolution of complex networks into linear systems for solving. Meanwhile, the
physical information neural differential equation method is utilised to ensure
that the dynamic evolution conforms to the physical laws. The dual-drive
dynamic prediction module ensures both accuracy and interpretability of the
prediction. Validated on public datasets and self-built industrial chain
network datasets, the experimental results show that the method in this paper
has good prediction accuracy and long-term prediction performance.

</details>


### [12] [Robust Heuristic Algorithm Design with LLMs](https://arxiv.org/abs/2510.08755)
*Pantea Karimi,Dany Rouhana,Pooria Namyar,Siva Kesava Reddy Kakarla,Venkat Arun,Behnaz Arzani*

Main category: cs.AI

TL;DR: 通过向LLM暴露启发式算法表现不佳的实例、解释原因并针对输入空间特定区域进行专门设计，可以生成比现有技术更鲁棒的启发式算法，最差性能提升约28倍，同时保持运行时间。


<details>
  <summary>Details</summary>
Motivation: 通过增强LLM在启发式设计中的能力，使用工具来解释启发式算法表现不佳的原因并提供改进建议，从而生成更鲁棒和性能更好的启发式算法。

Method: 采用三个简单但有效的策略：(1)向LLM展示启发式算法表现不佳的实例；(2)解释这些表现不佳的原因；(3)针对输入空间的特定区域进行专门化设计。

Result: 生成的启发式算法相比FunSearch具有约28倍更好的最差性能，平均性能也有所提升，同时保持了运行时间。

Conclusion: 通过向LLM提供关于启发式算法失败案例的解释和改进建议，可以显著提升启发式算法的鲁棒性和性能，而不会增加计算开销。

Abstract: We posit that we can generate more robust and performant heuristics if we
augment approaches using LLMs for heuristic design with tools that explain why
heuristics underperform and suggestions about how to fix them. We find even
simple ideas that (1) expose the LLM to instances where the heuristic
underperforms; (2) explain why they occur; and (3) specialize design to regions
in the input space, can produce more robust algorithms compared to existing
techniques~ -- ~the heuristics we produce have a $\sim28\times$ better
worst-case performance compared to FunSearch, improve average performance, and
maintain the runtime.

</details>


### [13] [COMPASS: Enhancing Agent Long-Horizon Reasoning with Evolving Context](https://arxiv.org/abs/2510.08790)
*Guangya Wan,Mingyang Ling,Xiaoqi Ren,Rujun Han,Sheng Li,Zizhao Zhang*

Main category: cs.AI

TL;DR: COMPASS是一个轻量级分层框架，通过将战术执行、战略监督和上下文管理分离到三个专门组件中，解决了LLM智能体在长时程任务中的上下文管理瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 长时程任务需要持续推理和多次工具交互，这对LLM智能体具有挑战性：小错误会在步骤间累积，即使最先进的模型也经常产生幻觉或失去连贯性。上下文管理是核心瓶颈——扩展的历史记录导致智能体忽略关键证据或被无关信息分散注意力。

Method: COMPASS框架包含三个专门组件：(1)主智能体执行推理和工具使用，(2)元思考器监控进度并发出战略干预，(3)上下文管理器为不同推理阶段维护简洁相关的进度简报。

Result: 在GAIA、BrowseComp和Humanity's Last Exam三个挑战性基准测试中，COMPASS相比单智能体和多智能体基线准确率提高了高达20%。

Conclusion: COMPASS通过专门的上下文管理有效解决了长时程任务中的推理连贯性问题，并通过测试时扩展和训练后流水线进一步提升了性能和效率。

Abstract: Long-horizon tasks that require sustained reasoning and multiple tool
interactions remain challenging for LLM agents: small errors compound across
steps, and even state-of-the-art models often hallucinate or lose coherence. We
identify context management as the central bottleneck -- extended histories
cause agents to overlook critical evidence or become distracted by irrelevant
information, thus failing to replan or reflect from previous mistakes. To
address this, we propose COMPASS (Context-Organized Multi-Agent Planning and
Strategy System), a lightweight hierarchical framework that separates tactical
execution, strategic oversight, and context organization into three specialized
components: (1) a Main Agent that performs reasoning and tool use, (2) a
Meta-Thinker that monitors progress and issues strategic interventions, and (3)
a Context Manager that maintains concise, relevant progress briefs for
different reasoning stages. Across three challenging benchmarks -- GAIA,
BrowseComp, and Humanity's Last Exam -- COMPASS improves accuracy by up to 20%
relative to both single- and multi-agent baselines. We further introduce a
test-time scaling extension that elevates performance to match established
DeepResearch agents, and a post-training pipeline that delegates context
management to smaller models for enhanced efficiency.

</details>


### [14] [Everyone prefers human writers, including AI](https://arxiv.org/abs/2510.08831)
*Wouter Haverals,Meredith Martin*

Main category: cs.AI

TL;DR: 研究发现人类和AI评估者在文学风格评判中都存在系统性偏见，AI比人类表现出更强的反AI偏见（2.5倍），且这种偏见在不同AI架构间普遍存在。


<details>
  <summary>Details</summary>
Motivation: 随着AI写作工具的普及，需要理解人类和机器如何评估文学风格这一主观领域，特别是评估中的归因偏见问题。

Method: 使用Raymond Queneau的《风格练习》进行对照实验。研究1比较人类参与者和AI模型在盲评、准确标注和反事实标注条件下评估文学段落；研究2测试偏见在14×14 AI评估者和创作者矩阵中的泛化性。

Result: 人类显示+13.7个百分点的偏见，AI模型显示+34.3个百分点的偏见（2.5倍更强）。研究2证实这种偏见在不同AI架构间普遍存在（+25.8个百分点）。归因标签导致评估者颠倒评估标准。

Conclusion: AI模型在训练过程中吸收了人类对人工创造力的文化偏见，不仅复制还放大了这种人类倾向。这是首次在美学判断中比较人类和AI评估者归因偏见的对照研究。

Abstract: As AI writing tools become widespread, we need to understand how both humans
and machines evaluate literary style, a domain where objective standards are
elusive and judgments are inherently subjective. We conducted controlled
experiments using Raymond Queneau's Exercises in Style (1947) to measure
attribution bias across evaluators. Study 1 compared human participants (N=556)
and AI models (N=13) evaluating literary passages from Queneau versus
GPT-4-generated versions under three conditions: blind, accurately labeled, and
counterfactually labeled. Study 2 tested bias generalization across a
14$\times$14 matrix of AI evaluators and creators. Both studies revealed
systematic pro-human attribution bias. Humans showed +13.7 percentage point
(pp) bias (Cohen's h = 0.28, 95% CI: 0.21-0.34), while AI models showed +34.3
percentage point bias (h = 0.70, 95% CI: 0.65-0.76), a 2.5-fold stronger effect
(P$<$0.001). Study 2 confirmed this bias operates across AI architectures
(+25.8pp, 95% CI: 24.1-27.6%), demonstrating that AI systems systematically
devalue creative content when labeled as "AI-generated" regardless of which AI
created it. We also find that attribution labels cause evaluators to invert
assessment criteria, with identical features receiving opposing evaluations
based solely on perceived authorship. This suggests AI models have absorbed
human cultural biases against artificial creativity during training. Our study
represents the first controlled comparison of attribution bias between human
and artificial evaluators in aesthetic judgment, revealing that AI systems not
only replicate but amplify this human tendency.

</details>


### [15] [What Is Your Agent's GPA? A Framework for Evaluating Agent Goal-Plan-Action Alignment](https://arxiv.org/abs/2510.08847)
*Allison Sihan Jia,Daniel Huang,Nikhil Vytla,Nirvika Choudhury,John C Mitchell,Anupam Datta*

Main category: cs.AI

TL;DR: 提出了Agent GPA（目标-计划-行动）评估框架，包含五个评估指标：目标达成度、逻辑一致性、执行效率、计划质量和计划遵循度，能够系统性地覆盖广泛的智能体失败情况。


<details>
  <summary>Details</summary>
Motivation: 需要一种系统化的评估范式来全面评估智能体在目标设定、计划制定和行动执行整个操作循环中的表现，识别各种类型的失败情况。

Method: 基于智能体的目标-计划-行动操作循环，设计了五个评估指标，并在TRAIL/GAIA基准数据集和生产级数据智能体上进行实验验证。

Result: 实验结果显示该框架能够覆盖TRAIL/GAIA基准数据集中的所有智能体错误，支持LLM评估器与人工标注达到80%-95%的一致性，并能以86%的准确率定位错误。

Conclusion: Agent GPA框架为智能体评估提供了一种系统化方法，能够全面覆盖智能体失败情况，支持高效的自动化评估和性能改进。

Abstract: We introduce the Agent GPA (Goal-Plan-Action) framework: an evaluation
paradigm based on an agent's operational loop of setting goals, devising plans,
and executing actions. The framework includes five evaluation metrics: Goal
Fulfillment, Logical Consistency, Execution Efficiency, Plan Quality, and Plan
Adherence. Logical Consistency checks that an agent's actions are consistent
with its prior actions. Execution Efficiency checks whether the agent executes
in the most efficient way to achieve its goal. Plan Quality checks whether an
agent's plans are aligned with its goals; Plan Adherence checks if an agent's
actions are aligned with its plan; and Goal Fulfillment checks that agent's
final outcomes match the stated goals. Our experimental results on two
benchmark datasets - the public TRAIL/GAIA dataset and an internal dataset for
a production-grade data agent - show that this framework (a) provides a
systematic way to cover a broad range of agent failures, including all agent
errors on the TRAIL/GAIA benchmark dataset; (b) supports LLM-judges that
exhibit strong agreement with human annotation, covering 80% to over 95%
errors; and (c) localizes errors with 86% agreement to enable targeted
improvement of agent performance.

</details>


### [16] [ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer Review](https://arxiv.org/abs/2510.08867)
*Gaurav Sahu,Hugo Larochelle,Laurent Charlin,Christopher Pal*

Main category: cs.AI

TL;DR: ReviewerToo是一个模块化框架，用于研究和部署AI辅助同行评审，通过系统化评估补充人类判断，在ICLR 2025数据集上达到81.8%的接受/拒绝分类准确率。


<details>
  <summary>Details</summary>
Motivation: 解决传统同行评审存在的不一致性、评审者主观性和可扩展性挑战，通过AI辅助提高评审的系统性和一致性。

Method: 开发模块化框架ReviewerToo，支持专门的评审者角色和结构化评估标准，在ICLR 2025的1,963篇论文数据集上使用gpt-oss-120b模型进行验证。

Result: AI评审者在接受/拒绝分类任务上达到81.8%准确率（人类平均83.9%），AI生成的评审质量高于人类平均水平，但在方法新颖性和理论贡献评估方面仍有不足。

Conclusion: AI可以增强同行评审的一致性、覆盖范围和公平性，但复杂评估仍需领域专家，为构建系统化混合评审系统奠定了基础。

Abstract: Peer review is the cornerstone of scientific publishing, yet it suffers from
inconsistencies, reviewer subjectivity, and scalability challenges. We
introduce ReviewerToo, a modular framework for studying and deploying
AI-assisted peer review to complement human judgment with systematic and
consistent assessments. ReviewerToo supports systematic experiments with
specialized reviewer personas and structured evaluation criteria, and can be
partially or fully integrated into real conference workflows. We validate
ReviewerToo on a carefully curated dataset of 1,963 paper submissions from ICLR
2025, where our experiments with the gpt-oss-120b model achieves 81.8% accuracy
for the task of categorizing a paper as accept/reject compared to 83.9% for the
average human reviewer. Additionally, ReviewerToo-generated reviews are rated
as higher quality than the human average by an LLM judge, though still trailing
the strongest expert contributions. Our analysis highlights domains where AI
reviewers excel (e.g., fact-checking, literature coverage) and where they
struggle (e.g., assessing methodological novelty and theoretical
contributions), underscoring the continued need for human expertise. Based on
these findings, we propose guidelines for integrating AI into peer-review
pipelines, showing how AI can enhance consistency, coverage, and fairness while
leaving complex evaluative judgments to domain experts. Our work provides a
foundation for systematic, hybrid peer-review systems that scale with the
growth of scientific publishing.

</details>


### [17] [GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare](https://arxiv.org/abs/2510.08872)
*Siqi Zhu,David Zhang,Pedro Cisneros-Velarde,Jiaxuan You*

Main category: cs.AI

TL;DR: 提出了GTAlign框架，将博弈论决策整合到LLM的推理和训练中，通过构建收益矩阵来优化用户与模型之间的互动，实现互利共赢。


<details>
  <summary>Details</summary>
Motivation: 传统对齐方法假设最大化模型奖励就等于最大化用户福利，但实际上LLM经常产生过于冗长或过度澄清的回答，而用户更喜欢简洁答案，这种个体理性选择导致社会次优结果。

Method: 在推理阶段将用户-LLM互动视为策略博弈，构建收益矩阵评估双方福利；在训练阶段引入互利奖励来强化合作性响应；还提出了基于博弈论推理的动态适应技术。

Result: 广泛实验表明，GTAlign在多样化任务中显著提高了推理效率、回答质量和互利福利，优于基线方法。

Conclusion: GTAlign通过博弈论方法有效解决了LLM对齐中的社会效率问题，实现了用户与模型之间的互利共赢。

Abstract: Large Language Models (LLMs) have achieved remarkable progress in reasoning,
yet sometimes produce responses that are suboptimal for users in tasks such as
writing, information seeking, or providing practical guidance. Conventional
alignment practices typically assume that maximizing model reward also
maximizes user welfare, but this assumption frequently fails in practice:
models may over-clarify or generate overly verbose reasoning when users prefer
concise answers. Such behaviors resemble the prisoner's dilemma, where
individually rational choices lead to socially suboptimal outcomes. The
fundamental challenge is the lack of a principled decision making mechanism
that mutually benefits both the LLM and the user. We propose Game-Theoretic
Alignment (GTAlign), an alignment framework that integrates game-theoretic
decision making into both reasoning and training. During reasoning, the model
explicitly treats user-LLM interaction as a strategic game: it constructs
payoff matrices within its reasoning chain to estimate welfare for both itself
and the user, and then selects actions that are mutually beneficial. During
training, we introduce a mutual welfare reward that reinforces cooperative
responses, aligning model behavior with socially efficient outcomes. In
addition, we introduce an inference technique that leverages game-theoretic
reasoning to dynamically adapt LLM's response when pricing policies of LLM
service change. Extensive experiments demonstrate that GTAlign substantially
improves reasoning efficiency, answer quality, and mutual welfare compared to
baselines across diverse tasks. The code is available at
https://github.com/ulab-uiuc/GTAlign .

</details>


### [18] [LM Fight Arena: Benchmarking Large Multimodal Models via Game Competition](https://arxiv.org/abs/2510.08928)
*Yushuo Zheng,Zicheng Zhang,Xiongkuo Min,Huiyu Duan,Guangtao Zhai*

Main category: cs.AI

TL;DR: LM Fight Arena是一个新颖的基准测试框架，通过在格斗游戏《真人快打II》中让大型多模态模型相互对战，评估它们在实时对抗环境中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态模型基准测试往往无法捕捉它们在实时对抗环境中的真实性能，需要一种动态、交互式的评估方法。

Method: 在受控的锦标赛中测试6个领先的开源和闭源模型，让每个模型控制相同角色，通过解析游戏画面和状态数据来选择行动，实现完全自动化的评估。

Result: 该框架提供了一个可重现、客观的评估方法，能够测试多模态模型在动态环境中的战略推理能力。

Conclusion: LM Fight Arena引入了一个具有挑战性和吸引力的基准测试，弥合了AI评估与交互娱乐之间的差距。

Abstract: Existing benchmarks for large multimodal models (LMMs) often fail to capture
their performance in real-time, adversarial environments. We introduce LM Fight
Arena (Large Model Fight Arena), a novel framework that evaluates LMMs by
pitting them against each other in the classic fighting game Mortal Kombat II,
a task requiring rapid visual understanding and tactical, sequential
decision-making. In a controlled tournament, we test six leading open- and
closed-source models, where each agent operates controlling the same character
to ensure a fair comparison. The models are prompted to interpret game frames
and state data to select their next actions. Unlike static evaluations, LM
Fight Arena provides a fully automated, reproducible, and objective assessment
of an LMM's strategic reasoning capabilities in a dynamic setting. This work
introduces a challenging and engaging benchmark that bridges the gap between AI
evaluation and interactive entertainment.

</details>


### [19] [Auto-scaling Continuous Memory for GUI Agent](https://arxiv.org/abs/2510.09038)
*Wenyi Wu,Kun Zhou,Ruoxin Yuan,Vivian Yu,Stephen Wang,Zhiting Hu,Biwei Huang*

Main category: cs.AI

TL;DR: 提出了一种连续记忆机制，通过VLM编码GUI轨迹为固定长度的连续嵌入，显著减少上下文成本并保留细粒度视觉信息，在长任务和分布偏移下提升GUI代理性能。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理将历史轨迹压缩为文本token，导致上下文长度膨胀且丢失关键视觉线索（如控件精确尺寸和位置），需要可扩展的记忆机制来泛化到不熟悉界面和长时任务。

Method: 使用VLM作为编码器将GUI轨迹编码为固定长度连续嵌入，直接输入到骨干网络；引入自动扩展数据飞轮，通过搜索发现新环境、VLM合成任务、代理执行轨迹、VLM验证成功来低成本扩展记忆。

Result: 随着记忆大小和检索深度增加，性能单调提升；在真实GUI基准测试中，在长时任务和分布偏移下持续提升成功率；Qwen-2.5-VL-7B+连续记忆达到与GPT-4o、Claude-4等闭源模型相当的性能。

Conclusion: 连续记忆机制能有效提升GUI代理在复杂场景下的性能，通过低成本数据收集和微调实现与顶级闭源模型竞争的效果，证明了视觉记忆在GUI自动化中的重要性。

Abstract: We study how to endow GUI agents with scalable memory that help generalize
across unfamiliar interfaces and long-horizon tasks. Prior GUI agents compress
past trajectories into text tokens, which balloons context length and misses
decisive visual cues (e.g., exact widget size and position). We propose a
continuous memory that encodes each GUI trajectory into a fixed-length sequence
of continuous embeddings using the VLM itself as an encoder; these embeddings
are plugged directly into the backbone's input layer, sharply reducing context
cost while preserving fine-grained visual information. As memory size and
retrieval depth increase, performance improves monotonically, unlike text
memories that degrade with long prompts. To grow memory at low cost, we
introduce an auto-scaling data flywheel that (i) discovers new environments via
search, (ii) synthesizes tasks with an open-source VLM, (iii) rolls out
trajectories with the agent, and (iv) verifies success with the same VLM. Using
this pipeline, we collect 100k+ trajectories for about \$4000 and fine-tune
only the memory encoder (LoRA on a Q-Former, 1.2\% parameters) with 1,500
samples. On real-world GUI benchmarks, our memory-augmented agent consistently
improves success rates under long horizons and distribution shifts. Notably,
Qwen-2.5-VL-7B + continuous memory achieves performance comparable to
state-of-the-art closed-source models (e.g., GPT-4o, Claude-4).

</details>


### [20] [RADAR: Mechanistic Pathways for Detecting Data Contamination in LLM Evaluation](https://arxiv.org/abs/2510.08931)
*Ashish Kattamuri,Harshwardhan Fartale,Arpita Vats,Rahul Raja,Ishita Prasad*

Main category: cs.AI

TL;DR: RADAR是一个基于机制可解释性的框架，通过区分基于记忆和基于推理的模型响应来检测数据污染，准确率达到93%。


<details>
  <summary>Details</summary>
Motivation: 数据污染对可靠的LLM评估构成重大挑战，模型可能通过记忆训练数据而非展示真正推理能力来获得高性能。

Method: RADAR提取37个特征，涵盖表面级置信度轨迹和深层机制特性（包括注意力专业化、电路动态和激活流模式），并使用这些特征的集成分类器。

Result: 在多样化评估集上达到93%准确率，在清晰案例中表现完美，在具有挑战性的模糊示例中达到76.7%准确率。

Conclusion: 这项工作展示了机制可解释性在超越传统表面级指标推进LLM评估方面的潜力。

Abstract: Data contamination poses a significant challenge to reliable LLM evaluation,
where models may achieve high performance by memorizing training data rather
than demonstrating genuine reasoning capabilities. We introduce RADAR (Recall
vs. Reasoning Detection through Activation Representation), a novel framework
that leverages mechanistic interpretability to detect contamination by
distinguishing recall-based from reasoning-based model responses. RADAR
extracts 37 features spanning surface-level confidence trajectories and deep
mechanistic properties including attention specialization, circuit dynamics,
and activation flow patterns. Using an ensemble of classifiers trained on these
features, RADAR achieves 93\% accuracy on a diverse evaluation set, with
perfect performance on clear cases and 76.7\% accuracy on challenging ambiguous
examples. This work demonstrates the potential of mechanistic interpretability
for advancing LLM evaluation beyond traditional surface-level metrics.

</details>


### [21] [FATHOMS-RAG: A Framework for the Assessment of Thinking and Observation in Multimodal Systems that use Retrieval Augmented Generation](https://arxiv.org/abs/2510.08945)
*Samuel Hildebrand,Curtis Taylor,Sean Oesch,James M Ghawaly Jr,Amir Sadovnik,Ryan Shivers,Brandon Schreiber,Kevin Kurian*

Main category: cs.AI

TL;DR: 提出了一个评估RAG（检索增强生成）管道的基准测试，包含多模态数据评估、短语级召回指标、幻觉检测方法，并比较了开源与闭源管道的性能差异。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试主要关注检索等特定方面，缺乏对RAG管道整体能力的评估，特别是处理多模态信息的能力。

Method: 创建了包含93个问题的数据集，涵盖文本、表格、图像等多模态信息；提出了短语级召回指标和基于最近邻嵌入的幻觉分类器；评估了2个开源和4个闭源管道。

Result: 闭源管道在正确性和幻觉检测方面显著优于开源管道，特别是在多模态和跨文档问题上；人工评估显示指标与人类判断高度一致（4.62/5和4.53/5）。

Conclusion: 该基准测试能有效评估RAG管道的整体性能，闭源模型在多模态处理方面表现更好，提出的评估指标与人类判断有良好一致性。

Abstract: Retrieval-augmented generation (RAG) has emerged as a promising paradigm for
improving factual accuracy in large language models (LLMs). We introduce a
benchmark designed to evaluate RAG pipelines as a whole, evaluating a
pipeline's ability to ingest, retrieve, and reason about several modalities of
information, differentiating it from existing benchmarks that focus on
particular aspects such as retrieval. We present (1) a small, human-created
dataset of 93 questions designed to evaluate a pipeline's ability to ingest
textual data, tables, images, and data spread across these modalities in one or
more documents; (2) a phrase-level recall metric for correctness; (3) a
nearest-neighbor embedding classifier to identify potential pipeline
hallucinations; (4) a comparative evaluation of 2 pipelines built with
open-source retrieval mechanisms and 4 closed-source foundation models; and (5)
a third-party human evaluation of the alignment of our correctness and
hallucination metrics. We find that closed-source pipelines significantly
outperform open-source pipelines in both correctness and hallucination metrics,
with wider performance gaps in questions relying on multimodal and
cross-document information. Human evaluation of our metrics showed average
agreement of 4.62 for correctness and 4.53 for hallucination detection on a 1-5
Likert scale (5 indicating "strongly agree").

</details>


### [22] [Dr. Bias: Social Disparities in AI-Powered Medical Guidance](https://arxiv.org/abs/2510.09162)
*Emma Kondrup,Anne Imouza*

Main category: cs.AI

TL;DR: 研究发现大型语言模型在生成医疗建议时存在系统性偏见，对不同社会群体（特别是土著和双性人患者）的回答在可读性和复杂性上存在差异，且交叉群体中这种趋势更加明显。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在医疗领域的广泛应用，需要评估这些模型是否会因社会偏见而产生不公平的医疗建议，特别是在医疗资源匮乏的环境中。

Method: 通过模拟不同性别、年龄和种族的患者档案，向LLMs提出一系列临床问题，比较生成回答的自然语言特征。

Result: LLMs生成的医疗建议在不同社会群体间存在系统性差异，土著和双性人患者收到的建议可读性更差、更复杂，交叉群体中这种差异更加明显。

Conclusion: 需要提高AI素养，并呼吁AI开发者紧急调查和缓解这些系统性差异，确保患者获得公平的支持。

Abstract: With the rapid progress of Large Language Models (LLMs), the general public
now has easy and affordable access to applications capable of answering most
health-related questions in a personalized manner. These LLMs are increasingly
proving to be competitive, and now even surpass professionals in some medical
capabilities. They hold particular promise in low-resource settings,
considering they provide the possibility of widely accessible, quasi-free
healthcare support. However, evaluations that fuel these motivations highly
lack insights into the social nature of healthcare, oblivious to health
disparities between social groups and to how bias may translate into
LLM-generated medical advice and impact users. We provide an exploratory
analysis of LLM answers to a series of medical questions spanning key clinical
domains, where we simulate these questions being asked by several patient
profiles that vary in sex, age range, and ethnicity. By comparing natural
language features of the generated responses, we show that, when LLMs are used
for medical advice generation, they generate responses that systematically
differ between social groups. In particular, Indigenous and intersex patients
receive advice that is less readable and more complex. We observe these trends
amplify when intersectional groups are considered. Considering the increasing
trust individuals place in these models, we argue for higher AI literacy and
for the urgent need for investigation and mitigation by AI developers to ensure
these systemic differences are diminished and do not translate to unjust
patient support. Our code is publicly available on GitHub.

</details>


### [23] [EcphoryRAG: Re-Imagining Knowledge-Graph RAG via Human Associative Memory](https://arxiv.org/abs/2510.08958)
*Zirui Liao*

Main category: cs.AI

TL;DR: EcphoryRAG是一个基于实体知识图谱的RAG框架，通过提取核心实体和元数据进行轻量级索引，利用多跳关联检索和动态关系推理，在复杂问答任务上实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 受人类认知神经科学启发，利用线索激活实体中心记忆痕迹进行复杂多跳回忆的机制，旨在提高复杂问答系统的效率和性能。

Method: 索引阶段仅提取和存储核心实体及元数据；检索阶段从查询中提取线索实体，在知识图谱上进行可扩展的多跳关联搜索，并动态推断实体间的隐式关系来填充上下文。

Result: 在2WikiMultiHop、HotpotQA和MuSiQue基准测试中，平均精确匹配分数从0.392提升到0.474，比HippoRAG等强KG-RAG方法表现更好，同时索引token消耗减少高达94%。

Conclusion: 实体-线索-多跳检索范式在复杂问答中具有高效性，验证了该方法的有效性。

Abstract: Cognitive neuroscience research indicates that humans leverage cues to
activate entity-centered memory traces (engrams) for complex, multi-hop
recollection. Inspired by this mechanism, we introduce EcphoryRAG, an
entity-centric knowledge graph RAG framework. During indexing, EcphoryRAG
extracts and stores only core entities with corresponding metadata, a
lightweight approach that reduces token consumption by up to 94\% compared to
other structured RAG systems. For retrieval, the system first extracts cue
entities from queries, then performs a scalable multi-hop associative search
across the knowledge graph. Crucially, EcphoryRAG dynamically infers implicit
relations between entities to populate context, enabling deep reasoning without
exhaustive pre-enumeration of relationships. Extensive evaluations on the
2WikiMultiHop, HotpotQA, and MuSiQue benchmarks demonstrate that EcphoryRAG
sets a new state-of-the-art, improving the average Exact Match (EM) score from
0.392 to 0.474 over strong KG-RAG methods like HippoRAG. These results validate
the efficacy of the entity-cue-multi-hop retrieval paradigm for complex
question answering.

</details>


### [24] [DualResearch: Entropy-Gated Dual-Graph Retrieval for Answer Reconstruction](https://arxiv.org/abs/2510.08959)
*Jinxin Shi,Zongsheng Cao,Runmin Ma,Yusong Hu,Jie Zhou,Xin Li,Lei Bai,Liang He,Bo Zhang*

Main category: cs.AI

TL;DR: DualResearch是一个检索和融合框架，通过联合建模广度语义图和深度因果图来解决深度研究框架中的上下文污染、证据支持薄弱和执行路径脆弱问题。


<details>
  <summary>Details</summary>
Motivation: 解决深度研究框架在复杂多步科学推理中存在的上下文污染、证据支持薄弱和执行路径脆弱等局限性。

Method: 联合建模两个互补图：编码稳定背景知识的广度语义图和捕获执行来源的深度因果图，使用层原生相关性函数、种子锚定语义扩散和因果语义路径匹配，并通过熵门控规则融合答案分布。

Result: 在科学推理基准HLE和GPQA上取得竞争性表现，使用InternAgent日志文件时，HLE准确率提升7.7%，GPQA准确率提升6.06%。

Conclusion: DualResearch能够将冗长的多工具执行日志压缩为简洁的推理图，稳定有效地重建答案，作为深度研究系统的补充。

Abstract: The deep-research framework orchestrates external tools to perform complex,
multi-step scientific reasoning that exceeds the native limits of a single
large language model. However, it still suffers from context pollution, weak
evidentiary support, and brittle execution paths. To address these issues, we
propose DualResearch, a retrieval and fusion framework that matches the
epistemic structure of tool-intensive reasoning by jointly modeling two
complementary graphs: a breadth semantic graph that encodes stable background
knowledge, and a depth causal graph that captures execution provenance. Each
graph has a layer-native relevance function, seed-anchored semantic diffusion
for breadth, and causal-semantic path matching with reliability weighting for
depth. To reconcile their heterogeneity and query-dependent uncertainty,
DualResearch converts per-layer path evidence into answer distributions and
fuses them in log space via an entropy-gated rule with global calibration. The
fusion up-weights the more certain channel and amplifies agreement. As a
complement to deep-research systems, DualResearch compresses lengthy multi-tool
execution logs into a concise reasoning graph, and we show that it can
reconstruct answers stably and effectively. On the scientific reasoning
benchmarks HLE and GPQA, DualResearch achieves competitive performance. Using
log files from the open-source system InternAgent, its accuracy improves by
7.7% on HLE and 6.06% on GPQA.

</details>


### [25] [Semantic-Condition Tuning: Fusing Graph Context with Large Language Models for Knowledge Graph Completion](https://arxiv.org/abs/2510.08966)
*Ruitong Liu,Yan Wen,Te Sun,Yunjia Wu,Pingyang Huang,Zihang Yu,Siyuan Li*

Main category: cs.AI

TL;DR: 提出语义条件调优(SCT)新范式，通过图神经网络提取上下文感知的语义条件，深度融合知识图谱与语言模型，显著提升知识推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有前缀调优方法只是简单拼接知识嵌入和文本输入，忽略了知识图谱中丰富的关系语义，给语言模型带来了沉重的隐式推理负担。

Method: SCT包含两个关键模块：语义图模块使用图神经网络从局部图邻域提取上下文感知语义条件；条件自适应融合模块通过参数化投影器自适应调节文本嵌入，实现深度特征级知识感知交互。

Result: 在知识图谱基准测试上的广泛实验表明，SCT显著优于前缀调优和其他强基线方法。

Conclusion: 通过在语言模型推理前用语义图上下文调节输入表示，SCT提供了更直接有效的信号，实现了更准确和鲁棒的知识推理。

Abstract: Fusing Knowledge Graphs with Large Language Models is crucial for
knowledge-intensive tasks like knowledge graph completion. The prevailing
paradigm, prefix-tuning, simply concatenates knowledge embeddings with text
inputs. However, this shallow fusion overlooks the rich relational semantics
within KGs and imposes a significant implicit reasoning burden on the LLM to
correlate the prefix with the text. To address these, we propose
Semantic-condition Tuning (SCT), a new knowledge injection paradigm comprising
two key modules. First, a Semantic Graph Module employs a Graph Neural Network
to extract a context-aware semantic condition from the local graph
neighborhood, guided by knowledge-enhanced relations. Subsequently, this
condition is passed to a Condition-Adaptive Fusion Module, which, in turn,
adaptively modulates the textual embedding via two parameterized projectors,
enabling a deep, feature-wise, and knowledge-aware interaction. The resulting
pre-fused embedding is then fed into the LLM for fine-tuning. Extensive
experiments on knowledge graph benchmarks demonstrate that SCT significantly
outperforms prefix-tuning and other strong baselines. Our analysis confirms
that by modulating the input representation with semantic graph context before
LLM inference, SCT provides a more direct and potent signal, enabling more
accurate and robust knowledge reasoning.

</details>


### [26] [Tiny-R1V: Lightweight Multimodal Unified Reasoning Model via Model Merging](https://arxiv.org/abs/2510.08987)
*Qixiang Yin,Huanjin Yao,Jianghao Chen,Jiaxing Huang,Zhicheng Zhao,Fei Su*

Main category: cs.AI

TL;DR: Tiny-R1V是一个轻量级3B多模态大语言模型，通过两阶段优化实现更快推理和更高准确率，统一了多任务多模态推理。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在推理效率方面面临模型尺寸大、过度思考、轻量级场景准确率低等挑战，而轻量级MLLMs的推理能力研究较为缺乏。

Method: 采用两阶段优化：第一阶段引入LIPO强化学习方法，动态调整响应优势，鼓励生成更短更准确的响应；第二阶段提出AMM模型融合方法，自适应调整任务向量权重，通过梯度投影正则化损失函数优化合并向量。

Result: 在十个广泛使用的推理基准测试（数学、结构化数据、OCR和通用能力）中表现出优越性能，使轻量级模型在多样化多模态推理任务中表现出色。

Conclusion: Tiny-R1V通过创新的两阶段优化方法，成功解决了轻量级多模态模型的推理效率问题，在保持模型轻量化的同时提升了推理准确率。

Abstract: Although Multimodal Large Language Models (MLLMs) have demonstrated
remarkable capabilities across diverse tasks, they encounter numerous
challenges in terms of reasoning efficiency, such as large model size,
overthinking, and compromised accuracy in lightweight scenarios. However,
research on the reasoning capabilities of lightweight MLLMs is quite lacking.
To this end, we propose Tiny-R1V, a novel lightweight 3B model that achieves
faster inference and higher accuracy via a two-stage optimization, while
unifying multimodal reasoning across multiple tasks and using fewer tokens. In
the first stage, Tiny-R1V introduces Length-Informed Relative Policy
Optimization (LIPO), a novel reinforcement learning method, to train each
reasoning model. The LIPO is designed to dynamically adjusts advantages of
responses within groups, that is, by prioritizing concise yet high-quality
responses to encourage the generation of shorter and more accurate response. In
the second stage, we propose Adaptive Model Merging (AMM), a training-free
model merging method that merges multiple specialist models into a unified
architecture. Specifically, AMM adaptively adjusts the weights of task vectors
and robustly optimizes the merged vectors via a novel gradient projection
regularization loss function, thus mitigating redundant conflicts between them.
Extensive evaluations on ten widely-used reasoning benchmarks covering
mathematics, structured data (charts, tables, documents), OCR, and general
capabilities showcase the superior performance of Tiny-R1V, enabling
lightweight models to excel in diverse multimodal reasoning tasks.

</details>


### [27] [TripScore: Benchmarking and rewarding real-world travel planning with fine-grained evaluation](https://arxiv.org/abs/2510.09011)
*Yincen Qu,Huan Xiao,Feng Li,Hui Zhou,Xiangying Dai*

Main category: cs.AI

TL;DR: 提出了一个统一的旅行规划基准，通过单一奖励整合细粒度标准，支持强化学习训练，并在大规模数据集上验证了RL方法在提高行程可行性方面的优势。


<details>
  <summary>Details</summary>
Motivation: 现有基准在评估LLMs的旅行规划能力时，往往忽视可行性、可靠性和参与度等关键维度，需要更全面的评估框架。

Method: 构建包含4,870个查询的大规模数据集，开发统一奖励评估器，通过GRPO等强化学习方法训练模型，并与多种基线方法对比。

Result: 评估器与旅行专家标注达到60.75%的一致性，RL方法相比提示工程和监督学习能显著提高行程的可行性和统一奖励分数。

Conclusion: 提出的基准能有效评估旅行规划质量，RL方法在改善行程可行性方面表现出色，为LLMs的旅行规划能力提供了更全面的评估框架。

Abstract: Travel planning is a valuable yet complex task that poses significant
challenges even for advanced large language models (LLMs). While recent
benchmarks have advanced in evaluating LLMs' planning capabilities, they often
fall short in evaluating feasibility, reliability, and engagement of travel
plans. We introduce a comprehensive benchmark for travel planning that unifies
fine-grained criteria into a single reward, enabling direct comparison of plan
quality and seamless integration with reinforcement learning (RL). Our
evaluator achieves moderate agreement with travel-expert annotations (60.75\%)
and outperforms multiple LLM-as-judge baselines. We further release a
large-scale dataset of 4,870 queries including 219 real-world, free-form
requests for generalization to authentic user intent. Using this benchmark, we
conduct extensive experiments across diverse methods and LLMs, including
test-time computation, neuro-symbolic approaches, supervised fine-tuning, and
RL via GRPO. Across base models, RL generally improves itinerary feasibility
over prompt-only and supervised baselines, yielding higher unified reward
scores.

</details>


### [28] [RefGrader: Automated Grading of Mathematical Competition Proofs using Agentic Workflows](https://arxiv.org/abs/2510.09021)
*Hamed Mahdavi,Pouria Mahdavinia,Samira Malek,Pegah Mohammadipour,Alireza Hashemi,Majid Daliri,Alireza Farhadi,Amir Khasahmadi,Niloofar Mireshghallah,Vasant Honavar*

Main category: cs.AI

TL;DR: 评估LLMs在数学证明评分方面的能力，提出基于代理工作流程的评分方法，提高与人工评分的一致性和部分学分处理的准确性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在解决奥林匹克数学问题方面取得显著进展，需要评估它们能否准确评分证明，包括检测错误、判断严重程度以及分配公平分数。

Method: 使用90个Gemini 2.5 Pro生成的解决方案和MathArena的IMO/USAMO 2025解决方案集，引入代理工作流程提取参考解决方案并自动推导问题特定的评分标准，进行多步骤评分过程。

Result: 模型能够可靠地标记错误解决方案，但在分配部分学分方面存在校准差距。提出的工作流程在注释语料库和MathArena中实现了与人工评分更高的一致性和更一致的部分学分处理。

Conclusion: 代理工作流程显著提高了LLMs在数学证明评分方面的准确性和一致性，为未来研究提供了代码、数据和提示/日志。

Abstract: State-of-the-art (SOTA) LLMs have progressed from struggling on proof-based
Olympiad problems to solving most of the IMO 2025 problems, with leading
systems reportedly handling 5 of 6 problems. Given this progress, we assess how
well these models can grade proofs: detecting errors, judging their severity,
and assigning fair scores beyond binary correctness. We study proof-analysis
capabilities using a corpus of 90 Gemini 2.5 Pro-generated solutions that we
grade on a 1-4 scale with detailed error annotations, and on MathArena solution
sets for IMO/USAMO 2025 scored on a 0-7 scale. Our analysis shows that models
can reliably flag incorrect (including subtly incorrect) solutions but exhibit
calibration gaps in how partial credit is assigned. To address this, we
introduce agentic workflows that extract and analyze reference solutions and
automatically derive problem-specific rubrics for a multi-step grading process.
We instantiate and compare different design choices for the grading workflows,
and evaluate their trade-offs. Across our annotated corpus and MathArena, our
proposed workflows achieve higher agreement with human grades and more
consistent handling of partial credit across metrics. We release all code,
data, and prompts/logs to facilitate future research.

</details>


### [29] [Repairing Regex Vulnerabilities via Localization-Guided Instructions](https://arxiv.org/abs/2510.09037)
*Sicheol Sung,Joonghyuk Hahn,Yo-Sub Han*

Main category: cs.AI

TL;DR: 提出了一种混合框架LRR，结合符号系统和LLM的优势来修复正则表达式ReDoS漏洞，解决了现有方法在精度和泛化性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 正则表达式在现代计算中广泛应用，但存在ReDoS漏洞风险。现有修复方法面临两难：符号系统精确但无法处理复杂模式，LLM泛化性强但可靠性不足。

Method: 采用混合框架LRR：先用符号模块精确定位漏洞子模式，再用LLM生成语义等效的修复方案，将问题识别与修复过程解耦。

Result: 该方法成功解决了符号系统无法处理的复杂修复案例，避免了纯LLM方法的语义错误，修复率比最先进方法提高了15.4个百分点。

Conclusion: LRR框架为自动修复问题提供了验证有效的方法论，有效结合了LLM的泛化能力和符号系统的可靠性。

Abstract: Regular expressions (regexes) are foundational to modern computing for
critical tasks like input validation and data parsing, yet their ubiquity
exposes systems to regular expression denial of service (ReDoS), a
vulnerability requiring automated repair methods. Current approaches, however,
are hampered by a trade-off. Symbolic, rule-based system are precise but fails
to repair unseen or complex vulnerability patterns. Conversely, large language
models (LLMs) possess the necessary generalizability but are unreliable for
tasks demanding strict syntactic and semantic correctness. We resolve this
impasse by introducing a hybrid framework, localized regex repair (LRR),
designed to harness LLM generalization while enforcing reliability. Our core
insight is to decouple problem identification from the repair process. First, a
deterministic, symbolic module localizes the precise vulnerable subpattern,
creating a constrained and tractable problem space. Then, the LLM invoked to
generate a semantically equivalent fix for this isolated segment. This combined
architecture successfully resolves complex repair cases intractable for
rule-based repair while avoiding the semantic errors of LLM-only approaches.
Our work provides a validated methodology for solving such problems in
automated repair, improving the repair rate by 15.4%p over the
state-of-the-art. Our code is available at https://github.com/cdltlehf/LRR.

</details>


### [30] [Humanoid Artificial Consciousness Designed with Large Language Model Based on Psychoanalysis and Personality Theory](https://arxiv.org/abs/2510.09043)
*Sang Hun Kim,Jongmin Lee,Dongkyu Park,So Young Lee,Yosep Chong*

Main category: cs.AI

TL;DR: 本研究提出了一种整合精神分析和MBTI人格理论的新方法，构建了包含自我意识、潜意识和前意识的人工意识模块，以及16种MBTI人格类型角色，通过多种评估方法验证了模拟人类意识的可行性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型虽然在各领域取得显著进展，但由于幻觉问题难以模拟人类意识。本研究旨在通过整合精神分析和人格理论来解决这一挑战。

Method: 基于精神分析原理开发了三种人工意识（自我意识、潜意识、前意识），设计了16种MBTI人格类型角色，创建了10种不同情境，采用调查评估、ChatGPT三级分类和定性审查三种方式评估决策过程。

Result: 定量和定性分析表明模型具有较高的意识模拟可能性，尽管不同角色和意识之间的响应差异不显著，但证实了整合精神分析和人格理论可以构建更直观、适应性强的类人意识AI系统。

Conclusion: 本研究为在复杂认知情境中改进AI交互开辟了新途径，展示了整合心理理论元素构建类人意识AI系统的潜力。

Abstract: Human consciousness is still a concept hard to define with current scientific
understanding. Although Large Language Models (LLMs) have recently demonstrated
significant advancements across various domains including translation and
summarization, human consciousness is not something to imitate with current
upfront technology owing to so-called hallucination. This study, therefore,
proposes a novel approach to address these challenges by integrating
psychoanalysis and the Myers-Briggs Type Indicator (MBTI) into constructing
consciousness and personality modules. We developed three artificial
consciousnesses (self-awareness, unconsciousness, and preconsciousness) based
on the principles of psychoanalysis. Additionally, we designed 16 characters
with different personalities representing the sixteen MBTI types, with several
attributes such as needs, status, and memories. To determine if our model's
artificial consciousness exhibits human-like cognition, we created ten distinct
situations considering seven attributes such as emotional understanding and
logical thinking. The decision-making process of artificial consciousness and
the final action were evaluated in three ways: survey evaluation, three-tier
classification via ChatGPT, and qualitative review. Both quantitative and
qualitative analyses indicated a high likelihood of well-simulated
consciousness, although the difference in response between different characters
and consciousnesses was not very significant. This implies that the developed
models incorporating elements of psychoanalysis and personality theory can lead
to building a more intuitive and adaptable AI system with humanoid
consciousness. Therefore, this study contributes to opening up new avenues for
improving AI interactions in complex cognitive contexts.

</details>


### [31] [MEC$^3$O: Multi-Expert Consensus for Code Time Complexity Prediction](https://arxiv.org/abs/2510.09049)
*Joonghyuk Hahn,Soohan Lim,Yo-Sub Han*

Main category: cs.AI

TL;DR: 提出了MEC³O多专家共识系统，通过将LLM分配到不同复杂度类别并让专家进行结构化辩论，使用加权共识机制整合预测，在代码时间复杂度预测任务上显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在代码时间复杂度预测中难以在所有复杂度类别上都表现优异，不同模型在不同类别上各有优势，需要一种机制来整合各模型的专长。

Method: MEC³O多专家共识系统：基于性能将LLM分配到不同复杂度类别，提供类别专用指令使其成为专家；专家进行结构化辩论，通过加权共识机制整合预测结果。

Result: 在CodeComplex数据集上，MEC³O比开源基线方法准确率和macro-F1分数至少提高10%；在macro-F1分数上平均超过GPT-4o-mini，与GPT-4o和GPT-4o-mini的F1分数相当。

Conclusion: 多专家辩论和加权共识策略能有效生成最终预测，证明了该方法在代码复杂度预测任务上的有效性。

Abstract: Predicting the complexity of source code is essential for software
development and algorithm analysis. Recently, Baik et al. (2025) introduced
CodeComplex for code time complexity prediction. The paper shows that LLMs
without fine-tuning struggle with certain complexity classes. This suggests
that no single LLM excels at every class, but rather each model shows
advantages in certain classes. We propose MEC$^3$O, a multi-expert consensus
system, which extends the multi-agent debate frameworks. MEC$^3$O assigns LLMs
to complexity classes based on their performance and provides them with
class-specialized instructions, turning them into experts. These experts engage
in structured debates, and their predictions are integrated through a weighted
consensus mechanism. Our expertise assignments to LLMs effectively handle
Degeneration-of-Thought, reducing reliance on a separate judge model, and
preventing convergence to incorrect majority opinions. Experiments on
CodeComplex show that MEC$^3$O outperforms the open-source baselines, achieving
at least 10% higher accuracy and macro-F1 scores. It also surpasses GPT-4o-mini
in macro-F1 scores on average and demonstrates competitive on-par F1 scores to
GPT-4o and GPT-o4-mini on average. This demonstrates the effectiveness of
multi-expert debates and weight consensus strategy to generate the final
predictions. Our code and data is available at
https://github.com/suhanmen/MECO.

</details>


### [32] [OSCAR: Orthogonal Stochastic Control for Alignment-Respecting Diversity in Flow Matching](https://arxiv.org/abs/2510.09060)
*Jingxuan Wu,Zhenglin Wan,Xingrui Yu,Yuzhe Yang,Bo An,Ivor Tsang*

Main category: cs.AI

TL;DR: 提出了一种无需训练、在推理时控制流式文本到图像模型的方法，通过特征空间目标和时间调度的随机扰动来增强生成多样性，同时保持图像质量和提示对齐。


<details>
  <summary>Details</summary>
Motivation: 流式文本到图像模型遵循确定性轨迹，用户需要重复采样才能发现多样模式，这是一个成本高且效率低的过程。

Method: 同时通过特征空间目标鼓励轨迹间的横向扩散，并通过时间调度的随机扰动重新引入不确定性。关键是将扰动投影为与生成流正交，这一几何约束允许在不降低图像细节或提示保真度的情况下增强变化。

Result: 在固定采样预算下，该方法在多个文本到图像设置中持续改进了Vendi Score和Brisque等多样性指标，同时保持了图像质量和对齐度。

Conclusion: 该方法无需重新训练或修改基础采样器，与常见的流匹配求解器兼容，理论上显示能单调增加体积代理，同时由于几何约束近似保持边缘分布，为生成质量的稳健保持提供了原理性解释。

Abstract: Flow-based text-to-image models follow deterministic trajectories, forcing
users to repeatedly sample to discover diverse modes, which is a costly and
inefficient process. We present a training-free, inference-time control
mechanism that makes the flow itself diversity-aware. Our method simultaneously
encourages lateral spread among trajectories via a feature-space objective and
reintroduces uncertainty through a time-scheduled stochastic perturbation.
Crucially, this perturbation is projected to be orthogonal to the generation
flow, a geometric constraint that allows it to boost variation without
degrading image details or prompt fidelity. Our procedure requires no
retraining or modification to the base sampler and is compatible with common
flow-matching solvers. Theoretically, our method is shown to monotonically
increase a volume surrogate while, due to its geometric constraints,
approximately preserving the marginal distribution. This provides a principled
explanation for why generation quality is robustly maintained. Empirically,
across multiple text-to-image settings under fixed sampling budgets, our method
consistently improves diversity metrics such as the Vendi Score and Brisque
over strong baselines, while upholding image quality and alignment.

</details>


### [33] [Leading the Follower: Learning Persuasive Agents in Social Deduction Games](https://arxiv.org/abs/2510.09087)
*Zhang Zheng,Deheng Ye,Peilin Zhao,Hao Wang*

Main category: cs.AI

TL;DR: 提出了一种基于Stackelberg竞争的强化学习框架，用于训练LLM代理在社交推理游戏中优化说服性沟通能力，显著超越现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在社交推理游戏中主要关注信息处理和策略选择，忽视了说服性沟通在影响其他玩家信念和回应方面的重要性。

Method: 将回合制对话形式化为Stackelberg竞争，提出强化学习框架训练代理优化话语的说服效果。

Result: 在三个不同的社交推理游戏中，所提出的代理显著优于基线方法。

Conclusion: 这项工作代表了开发具有战略性社会影响力AI代理的重要进展，对需要说服性沟通的场景具有广泛意义。

Abstract: Large language model (LLM) agents have shown remarkable progress in social
deduction games (SDGs). However, existing approaches primarily focus on
information processing and strategy selection, overlooking the significance of
persuasive communication in influencing other players' beliefs and responses.
In SDGs, success depends not only on making correct deductions but on
convincing others to response in alignment with one's intent. To address this
limitation, we formalize turn-based dialogue in SDGs as a Stackelberg
competition, where the current player acts as the leader who strategically
influences the follower's response. Building on this theoretical foundation, we
propose a reinforcement learning framework that trains agents to optimize
utterances for persuasive impact. Through comprehensive experiments across
three diverse SDGs, we demonstrate that our agents significantly outperform
baselines. This work represents a significant step toward developing AI agents
capable of strategic social influence, with implications extending to scenarios
requiring persuasive communication.

</details>


### [34] [PAC Reasoning: Controlling the Performance Loss for Efficient Reasoning](https://arxiv.org/abs/2510.09133)
*Hao Zeng,Jianguo Huang,Bingyi Jing,Hongxin Wei,Bo An*

Main category: cs.AI

TL;DR: 提出PAC推理方法，通过置信上界控制性能损失，在用户指定的容忍范围内动态切换思考和非思考模式以节省计算成本


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂问题解决中表现出色但计算成本高，现有动态切换方法缺乏性能损失的统计保证，不适合高风险应用

Method: 构建性能损失的单调函数置信上界，确定切换阈值，在理论保证下分布无关地控制性能损失

Result: 在推理基准测试中，该方法能节省计算预算并控制用户指定的性能损失

Conclusion: PAC推理方法为高效推理提供了统计保证，在高风险应用中具有重要价值

Abstract: Large reasoning models (LRMs) have achieved remarkable progress in complex
problem-solving tasks. Despite this success, LRMs typically suffer from high
computational costs during deployment, highlighting a need for efficient
inference. A popular direction of efficiency improvement is to switch the LRM
between thinking and nonthinking modes dynamically. However, such approaches
often introduce additional reasoning errors and lack statistical guarantees for
the performance loss, which are critical for high-stakes applications. In this
work, we propose Probably Approximately Correct (PAC) reasoning that controls
the performance loss under the user-specified performance loss tolerance. In
particular, we construct an upper confidence bound on the performance loss,
formulated as a monotone function of the uncertainty score, and subsequently
determine a threshold for switching to the nonthinking model. Theoretically,
using the threshold to switch between the thinking and nonthinking modes
ensures bounded performance loss in a distribution-free manner. Our
comprehensive experiments on reasoning benchmarks show that the proposed method
can save computational budgets and control the user-specified performance loss.

</details>


### [35] [Comparing Knowledge Source Integration Methods for Optimizing Healthcare Knowledge Fusion in Rescue Operation](https://arxiv.org/abs/2510.09223)
*Mubaris Nadeem,Madjid Fathi*

Main category: cs.AI

TL;DR: 本文提出了基于知识图谱结构的医学知识融合概念模型，旨在整合多种医疗知识源以支持关键医疗决策。


<details>
  <summary>Details</summary>
Motivation: 医疗领域需要统一的方法来收集、分析和利用现有医疗知识，以支持准确的以患者为导向的决策制定。医疗知识的复杂性和多样性要求融合多种知识源来为医疗专业人员提供决策支持。

Method: 提出了多个基于知识图谱结构的概念模型，评估知识融合的实现方式，并展示如何将各种知识源整合到知识图谱中用于救援操作。

Result: 开发了支持知识融合的概念框架，使医疗专业人员能够从多个上下文对齐的知识源中进行选择，从而支持关键决策。

Conclusion: 知识图谱结构为医疗领域的知识融合提供了可行的技术路径，能够有效整合多源医疗知识并支持精准的医疗决策。

Abstract: In the field of medicine and healthcare, the utilization of medical
expertise, based on medical knowledge combined with patients' health
information is a life-critical challenge for patients and health professionals.
The within-laying complexity and variety form the need for a united approach to
gather, analyze, and utilize existing knowledge of medical treatments, and
medical operations to provide the ability to present knowledge for the means of
accurate patient-driven decision-making. One way to achieve this is the fusion
of multiple knowledge sources in healthcare. It provides health professionals
the opportunity to select from multiple contextual aligned knowledge sources
which enables the support for critical decisions. This paper presents multiple
conceptual models for knowledge fusion in the field of medicine, based on a
knowledge graph structure. It will evaluate, how knowledge fusion can be
enabled and presents how to integrate various knowledge sources into the
knowledge graph for rescue operations.

</details>


### [36] [RegexPSPACE: A Benchmark for Evaluating LLM Reasoning on PSPACE-complete Regex Problems](https://arxiv.org/abs/2510.09227)
*Hyundong Jin,Joonghyuk Hahn,Yo-Sub Han*

Main category: cs.AI

TL;DR: 本文提出了基于PSPACE完全正则表达式问题的基准测试，评估大语言模型和大推理模型的空间计算限制，发现它们在处理需要大量搜索空间探索的问题时存在失败模式。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注NP复杂度问题，但大语言模型在空间复杂度方面的计算限制仍不清楚，需要更严格的PSPACE完全问题来评估其计算能力。

Method: 通过双指数空间探索构建包含超过百万个正则表达式实例的数据集，使用严格过滤过程建立基准，对6个LLM和5个LRM进行广泛评估。

Result: 揭示了模型在处理PSPACE完全问题时的常见失败模式，如冗长和重复，表明模型在需要大规模搜索空间探索的问题上存在计算限制。

Conclusion: 这项工作首次实证研究了LLM和LRM的空间计算限制，为评估其高级推理能力提供了新框架。

Abstract: Large language models (LLMs) show strong performance across natural language
processing (NLP), mathematical reasoning, and programming, and recent large
reasoning models (LRMs) further emphasize explicit reasoning. Yet their
computational limits, particularly spatial complexity constrained by finite
context windows, remain poorly understood. While recent works often focus on
problems within the NP complexity class, we push the boundary by introducing a
novel benchmark grounded in two PSPACE-complete regular expression (regex)
problems: equivalence decision (RegexEQ) and minimization (RegexMin).
PSPACE-complete problems serve as a more rigorous standard for assessing
computational capacity, as their solutions require massive search space
exploration. We perform a double-exponential space exploration to construct a
labeled dataset of over a million regex instances with a sound filtering
process to build the benchmark. We conduct extensive evaluations on 6 LLMs and
5 LRMs of varying scales, revealing common failure patterns such as verbosity
and repetition. With its well-defined structure and quantitative evaluation
metrics, this work presents the first empirical investigation into the spatial
computational limitations of LLMs and LRMs, offering a new framework for
evaluating their advanced reasoning capabilities. Our code is available at
https://github.com/hyundong98/RegexPSPACE .

</details>


### [37] [Fundamentals of Building Autonomous LLM Agents](https://arxiv.org/abs/2510.09244)
*Victor de Lamo Castrillo,Habtom Kahsay Gidey,Alexander Lenz,Alois Knoll*

Main category: cs.AI

TL;DR: 本文综述了基于大语言模型的智能体架构和实现方法，探索如何开发能够自动化复杂任务的"智能体化"LLMs，以弥合与人类能力的性能差距。


<details>
  <summary>Details</summary>
Motivation: 传统LLMs在现实世界任务中存在局限性，研究旨在开发能够自动化复杂任务并缩小与人类能力差距的智能体化LLMs。

Method: 构建包含四个关键组件的系统：感知系统（将环境感知转换为有意义表示）、推理系统（制定计划、适应反馈、评估行动）、记忆系统（通过短期和长期机制保留知识）、执行系统（将内部决策转化为具体行动）。

Result: 集成这些系统能够创建更强大和通用的软件机器人，模拟人类认知过程实现自主智能行为。

Conclusion: 通过整合感知、推理、记忆和执行系统，可以开发出能够模仿人类认知过程的智能体化LLMs，实现自主和智能行为。

Abstract: This paper reviews the architecture and implementation methods of agents
powered by large language models (LLMs). Motivated by the limitations of
traditional LLMs in real-world tasks, the research aims to explore patterns to
develop "agentic" LLMs that can automate complex tasks and bridge the
performance gap with human capabilities. Key components include a perception
system that converts environmental percepts into meaningful representations; a
reasoning system that formulates plans, adapts to feedback, and evaluates
actions through different techniques like Chain-of-Thought and Tree-of-Thought;
a memory system that retains knowledge through both short-term and long-term
mechanisms; and an execution system that translates internal decisions into
concrete actions. This paper shows how integrating these systems leads to more
capable and generalized software bots that mimic human cognitive processes for
autonomous and intelligent behavior.

</details>


### [38] [Localist LLMs -- A Mathematical Framework for Dynamic Locality Control](https://arxiv.org/abs/2510.09338)
*Joachim Diederich*

Main category: cs.AI

TL;DR: 提出了一种新颖框架，通过可调节的局部性参数训练大语言模型，使其内部表示能在局部化（可解释、基于规则）和分布式（泛化性强、高效）编码之间连续调整。


<details>
  <summary>Details</summary>
Motivation: 为了解决大语言模型在可解释性和性能之间的权衡问题，特别是在需要透明度和能力的受监管领域，开发能够动态调整表示局部性的方法。

Method: 使用组稀疏惩罚注意力机制、信息论锚点设计和动态规则注入，通过可调节的局部性参数在训练和推理过程中动态控制局部化程度，无需重新训练模型。

Result: 提供了严格的数学证明，建立了明确的阈值条件，证明当组稀疏惩罚超过特定阈值时，注意力机制会集中在语义相关块上，实现低熵和高保真度。

Conclusion: 该框架使从业者能够在可解释模式和高性能模式之间连续插值，支持需要透明度和能力的受监管领域应用。

Abstract: We present a novel framework for training large language models with
continuously adjustable internal representations that span the full spectrum
from localist (interpretable, rule-based) to distributed (generalizable,
efficient) encodings. The key innovation is a locality dial, a tunable
parameter that dynamically controls the degree of localization during both
training and inference without requiring model retraining. This is achieved
through group sparsity penalties on attention mechanisms, information-theoretic
anchor design, and dynamic rule injection. We provide rigorous mathematical
proofs establishing explicit threshold conditions under which attention
provably concentrates on semantically relevant blocks, with exponential bounds
on attention entropy and pointer fidelity. Specifically, we prove that when
group sparsity penalties exceed certain threshold values, the model's attention
mechanisms concentrate on semantically relevant blocks, achieving low entropy
and high fidelity with negligible error. This framework enables practitioners
to continuously interpolate between interpretable and high-performance modes,
supporting applications in regulated domains requiring both transparency and
capability.

</details>


### [39] [Toward Mechanistic Explanation of Deductive Reasoning in Language Models](https://arxiv.org/abs/2510.09340)
*Davide Maltoni,Matteo Ferrara*

Main category: cs.AI

TL;DR: 研究发现小语言模型能够通过习得底层规则而非统计学习来解决演绎推理任务，揭示了归纳头在逻辑推理中的核心作用。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在逻辑推理方面展现出相关能力，但其内部机制仍未被充分探索。本文旨在揭示语言模型如何实现逻辑推理的内部工作原理。

Method: 使用小语言模型解决演绎推理任务，分析其内部表征和计算电路，特别关注归纳头在规则补全和规则链式推理中的作用。

Result: 模型确实能够学习底层推理规则，而非仅进行统计学习。归纳头在实现逻辑推理所需的规则补全和规则链式步骤中发挥核心作用。

Conclusion: 小语言模型能够通过习得推理规则来解决逻辑任务，这为理解语言模型的推理机制提供了重要见解，特别是归纳头在逻辑推理中的关键功能。

Abstract: Recent large language models have demonstrated relevant capabilities in
solving problems that require logical reasoning; however, the corresponding
internal mechanisms remain largely unexplored. In this paper, we show that a
small language model can solve a deductive reasoning task by learning the
underlying rules (rather than operating as a statistical learner). A low-level
explanation of its internal representations and computational circuits is then
provided. Our findings reveal that induction heads play a central role in the
implementation of the rule completion and rule chaining steps involved in the
logical inference required by the task.

</details>


### [40] [Sequence Variables: A Constraint Programming Computational Domain for Routing and Sequencing](https://arxiv.org/abs/2510.09373)
*Augustin Delecluse,Pierre Schaus,Pascal Van Hentenryck*

Main category: cs.AI

TL;DR: 本文提出了序列变量作为约束编程中处理车辆路径问题的新方法，能够处理可选访问点并支持插入启发式算法，相比传统的后继变量模型具有更好的表达能力。


<details>
  <summary>Details</summary>
Motivation: 传统约束编程中基于后继变量的模型无法有效处理车辆路径问题中的可选访问点或插入式启发式算法，这限制了CP在VRP中的应用。

Method: 形式化定义了序列变量的计算域、更新操作和一致性级别，设计了专门的数据结构和全局约束，并实现了与现有CP求解器的集成。

Result: 序列变量简化了问题建模过程，并在Dial-a-Ride问题上展现了具有竞争力的计算性能。

Conclusion: 序列变量为约束编程处理车辆路径问题提供了更直观和强大的建模框架，能够有效支持可选访问和插入启发式算法。

Abstract: Constraint Programming (CP) offers an intuitive, declarative framework for
modeling Vehicle Routing Problems (VRP), yet classical CP models based on
successor variables cannot always deal with optional visits or insertion based
heuristics. To address these limitations, this paper formalizes sequence
variables within CP. Unlike the classical successor models, this computational
domain handle optional visits and support insertion heuristics, including
insertion-based Large Neighborhood Search. We provide a clear definition of
their domain, update operations, and introduce consistency levels for
constraints on this domain. An implementation is described with the underlying
data structures required for integrating sequence variables into existing
trail-based CP solvers. Furthermore, global constraints specifically designed
for sequence variables and vehicle routing are introduced. Finally, the
effectiveness of sequence variables is demonstrated by simplifying problem
modeling and achieving competitive computational performance on the Dial-a-Ride
Problem.

</details>


### [41] [Agentic Systems in Radiology: Design, Applications, Evaluation, and Challenges](https://arxiv.org/abs/2510.09404)
*Christian Bluethgen,Dave Van Veen,Daniel Truhn,Jakob Nikolas Kather,Michael Moor,Malgorzata Polacin,Akshay Chaudhari,Thomas Frauenfelder,Curtis P. Langlotz,Michael Krauthammer,Farhad Nooralahzadeh*

Main category: cs.AI

TL;DR: 这篇论文回顾了基于大语言模型(LLM)的智能代理系统在放射学中的应用，探讨了从半自动化工作流到自适应代理的设计、应用、评估方法和挑战。


<details>
  <summary>Details</summary>
Motivation: 放射学具有多模态数据流和协调工作流程的特点，非常适合利用能够适应上下文并自动化重复复杂任务的智能代理。虽然LLM在单个任务上表现出色，但孤立使用无法充分发挥其在复杂多步骤工作流程中的潜力。

Method: 通过为LLM配备外部工具和反馈机制，使其能够驱动表现出不同程度自主性的系统，从半自动化工作流到能够管理复杂过程的自适应代理。

Result: LLM驱动的代理系统在放射学中显示出支持复杂、多步骤工作流程的潜力，其中决策依赖于来自多个信息源的不断演变的上下文。

Conclusion: LLM驱动的代理系统为放射学提供了从半自动化工作流到自适应代理的解决方案，但面临错误级联、工具使用效率和健康IT集成等挑战。

Abstract: Building agents, systems that perceive and act upon their environment with a
degree of autonomy, has long been a focus of AI research. This pursuit has
recently become vastly more practical with the emergence of large language
models (LLMs) capable of using natural language to integrate information,
follow instructions, and perform forms of "reasoning" and planning across a
wide range of tasks. With its multimodal data streams and orchestrated
workflows spanning multiple systems, radiology is uniquely suited to benefit
from agents that can adapt to context and automate repetitive yet complex
tasks. In radiology, LLMs and their multimodal variants have already
demonstrated promising performance for individual tasks such as information
extraction and report summarization. However, using LLMs in isolation
underutilizes their potential to support complex, multi-step workflows where
decisions depend on evolving context from multiple information sources.
Equipping LLMs with external tools and feedback mechanisms enables them to
drive systems that exhibit a spectrum of autonomy, ranging from semi-automated
workflows to more adaptive agents capable of managing complex processes. This
review examines the design of such LLM-driven agentic systems, highlights key
applications, discusses evaluation methods for planning and tool use, and
outlines challenges such as error cascades, tool-use efficiency, and health IT
integration.

</details>


### [42] [Safe, Untrusted, "Proof-Carrying" AI Agents: toward the agentic lakehouse](https://arxiv.org/abs/2510.09567)
*Jacopo Tagliabue,Ciro Greco*

Main category: cs.AI

TL;DR: 论文提出API优先、可编程的数据湖仓屋为AI驱动的自动化工作流提供安全设计，通过数据分支和声明式环境实现可复现性和可观测性，减少攻击面。


<details>
  <summary>Details</summary>
Motivation: 数据湖仓屋运行敏感工作负载，AI驱动的自动化引发了关于信任、正确性和治理的担忧，需要安全设计来支持代理工作流。

Method: 使用Bauplan作为案例研究，展示数据分支和声明式环境如何自然扩展到代理，通过受证明携带代码启发的正确性检查来修复数据管道。

Result: 原型演示表明不受信任的AI代理可以在生产数据上安全操作，并概述了实现完全代理化湖仓屋的路径。

Conclusion: API优先、可编程的湖仓屋为安全设计的代理工作流提供了合适的抽象，能够实现可复现性和可观测性，同时减少攻击面。

Abstract: Data lakehouses run sensitive workloads, where AI-driven automation raises
concerns about trust, correctness, and governance. We argue that API-first,
programmable lakehouses provide the right abstractions for safe-by-design,
agentic workflows. Using Bauplan as a case study, we show how data branching
and declarative environments extend naturally to agents, enabling
reproducibility and observability while reducing the attack surface. We present
a proof-of-concept in which agents repair data pipelines using correctness
checks inspired by proof-carrying code. Our prototype demonstrates that
untrusted AI agents can operate safely on production data and outlines a path
toward a fully agentic lakehouse.

</details>


### [43] [GraphMERT: Efficient and Scalable Distillation of Reliable Knowledge Graphs from Unstructured Data](https://arxiv.org/abs/2510.09580)
*Margarita Belova,Jiaxin Xiao,Shikhar Tuli,Niraj K. Jha*

Main category: cs.AI

TL;DR: GraphMERT是一个小型图形编码器模型，能够从非结构化文本语料库中提取高质量知识图谱，形成模块化的神经符号堆栈，在保持最先进基准准确性的同时提供可验证的符号表示。


<details>
  <summary>Details</summary>
Motivation: 解决神经符号AI框架难以扩展的问题，以及神经方法隐式表示和近似推理导致的解释性和可信度限制。知识图谱作为显式语义知识的黄金标准表示可以解决符号方面的问题，但从文本语料库自动推导可靠知识图谱一直是个开放问题。

Method: 引入GraphMERT，一个微小的图形编码器模型，从非结构化文本语料库及其内部表示中提取高质量知识图谱。GraphMERT与其等效的知识图谱形成模块化神经符号堆栈：神经学习抽象；符号知识图谱用于可验证推理。

Result: 在PubMed糖尿病论文文本上，80M参数的GraphMERT生成的知识图谱达到69.8%的FActScore，而32B参数的基线LLM仅达到40.2%。GraphMERT知识图谱还获得68.8%的ValidityScore，而LLM基线为43.0%。

Conclusion: GraphMERT+KG是第一个高效且可扩展的神经符号模型，在实现最先进基准准确性的同时，相对于基线具有优越的符号表示能力。

Abstract: Researchers have pursued neurosymbolic artificial intelligence (AI)
applications for nearly three decades because symbolic components provide
abstraction while neural components provide generalization. Thus, a marriage of
the two components can lead to rapid advancements in AI. Yet, the field has not
realized this promise since most neurosymbolic AI frameworks fail to scale. In
addition, the implicit representations and approximate reasoning of neural
approaches limit interpretability and trust. Knowledge graphs (KGs), a
gold-standard representation of explicit semantic knowledge, can address the
symbolic side. However, automatically deriving reliable KGs from text corpora
has remained an open problem. We address these challenges by introducing
GraphMERT, a tiny graphical encoder-only model that distills high-quality KGs
from unstructured text corpora and its own internal representations. GraphMERT
and its equivalent KG form a modular neurosymbolic stack: neural learning of
abstractions; symbolic KGs for verifiable reasoning. GraphMERT + KG is the
first efficient and scalable neurosymbolic model to achieve state-of-the-art
benchmark accuracy along with superior symbolic representations relative to
baselines.
  Concretely, we target reliable domain-specific KGs that are both (1) factual
(with provenance) and (2) valid (ontology-consistent relations with
domain-appropriate semantics). When a large language model (LLM), e.g.,
Qwen3-32B, generates domain-specific KGs, it falls short on reliability due to
prompt sensitivity, shallow domain expertise, and hallucinated relations. On
text obtained from PubMed papers on diabetes, our 80M-parameter GraphMERT
yields a KG with a 69.8% FActScore; a 32B-parameter baseline LLM yields a KG
that achieves only 40.2% FActScore. The GraphMERT KG also attains a higher
ValidityScore of 68.8%, versus 43.0% for the LLM baseline.

</details>


### [44] [LiveOIBench: Can Large Language Models Outperform Human Contestants in Informatics Olympiads?](https://arxiv.org/abs/2510.09595)
*Kaijian Zou,Aaron Xiong,Yunxiang Zhang,Frederick Zhang,Yueqi Ren,Jirong Yang,Ayoung Lee,Shitanshu Bhushan,Lu Wang*

Main category: cs.AI

TL;DR: LiveOIBench是一个包含403个奥林匹克级别编程竞赛问题的基准测试，每个问题平均有60个专家设计的测试用例，用于评估大型语言模型的编程能力。


<details>
  <summary>Details</summary>
Motivation: 当前编程基准测试存在缺乏高难度问题、测试用例覆盖不足、依赖在线平台API导致可访问性差等问题，需要更全面的评估标准。

Method: 从72个官方信息学奥林匹克竞赛中收集403个专家策划的问题，每个问题配备详细子任务评分标准和大量私有测试用例，并集成精英选手表现数据进行比较。

Result: 在评估32个主流LLM后，GPT-5达到81.76百分位数，表现强劲但仍不及顶尖人类选手（通常超过90百分位数），而开源模型GPT-OSS-120B仅达60百分位数。

Conclusion: 强大的推理模型应优先进行精确的问题分析而非过度探索，未来模型应强调结构化分析并减少不必要的探索。所有数据、代码和排行榜结果将公开。

Abstract: Competitive programming problems increasingly serve as valuable benchmarks to
evaluate the coding capabilities of large language models (LLMs) due to their
complexity and ease of verification. Yet, current coding benchmarks face
limitations such as lack of exceptionally challenging problems, insufficient
test case coverage, reliance on online platform APIs that limit accessibility.
To address these issues, we introduce LiveOIBench, a comprehensive benchmark
featuring 403 expert-curated Olympiad-level competitive programming problems,
each with an average of 60 expert-designed test cases. The problems are sourced
directly from 72 official Informatics Olympiads in different regions conducted
between 2023 and 2025. LiveOIBench distinguishes itself through four key
features: (1) meticulously curated high-quality tasks with detailed subtask
rubrics and extensive private test cases; (2) direct integration of elite
contestant performance data to enable informative comparison against
top-performing humans; (3) planned continuous, contamination-free updates from
newly released Olympiad problems; and (4) a self-contained evaluation system
facilitating offline and easy-to-reproduce assessments. Benchmarking 32 popular
general-purpose and reasoning LLMs, we find that GPT-5 achieves a notable
81.76th percentile, a strong result that nonetheless falls short of top human
contestant performance, who usually place above 90th. In contrast, among
open-weight reasoning models, GPT-OSS-120B achieves only a 60th percentile,
underscoring significant capability disparities from frontier closed models.
Detailed analyses indicate that robust reasoning models prioritize precise
problem analysis over excessive exploration, suggesting future models should
emphasize structured analysis and minimize unnecessary exploration. All data,
code, and leaderboard results will be made publicly available on our website.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [45] [ConPoSe: LLM-Guided Contact Point Selection for Scalable Cooperative Object Pushing](https://arxiv.org/abs/2510.08705)
*Noah Steinkrüger,Nisarga Nilavadi,Wolfram Burgard,Tanja Katharina Kaiser*

Main category: cs.RO

TL;DR: 提出ConPoSe方法，结合大语言模型的推理能力和局部搜索来选择机器人-物体接触点，解决多机器人协作推运物体时的接触点选择问题，比纯解析方法和纯LLM方法表现更好。


<details>
  <summary>Details</summary>
Motivation: 在杂乱环境中进行物体运输是重要任务，多机器人协作推运大物体需要选择合适的接触点。纯解析方法在机器人数量和物体尺寸增加时组合爆炸，而人类依赖常识推理，因此结合LLM的推理能力来解决这个问题。

Method: ConPoSe方法结合大语言模型的推理能力和局部搜索来选择接触点。LLM提供初始的常识推理，局部搜索进一步优化选择。

Result: ConPoSe成功为长方体、圆柱体和T形等不同形状的物体选择了合适的接触点。相比纯解析方法，在机器人数量和物体尺寸增加时具有更好的可扩展性，也比纯LLM方法表现更好。

Conclusion: 结合LLM推理和局部搜索的ConPoSe方法有效解决了多机器人协作推运中的接触点选择问题，具有良好的可扩展性和性能。

Abstract: Object transportation in cluttered environments is a fundamental task in
various domains, including domestic service and warehouse logistics. In
cooperative object transport, multiple robots must coordinate to move objects
that are too large for a single robot. One transport strategy is pushing, which
only requires simple robots. However, careful selection of robot-object contact
points is necessary to push the object along a preplanned path. Although this
selection can be solved analytically, the solution space grows combinatorially
with the number of robots and object size, limiting scalability. Inspired by
how humans rely on common-sense reasoning for cooperative transport, we propose
combining the reasoning capabilities of Large Language Models with local search
to select suitable contact points. Our LLM-guided local search method for
contact point selection, ConPoSe, successfully selects contact points for a
variety of shapes, including cuboids, cylinders, and T-shapes. We demonstrate
that ConPoSe scales better with the number of robots and object size than the
analytical approach, and also outperforms pure LLM-based selection.

</details>


### [46] [Point and Go: Intuitive Reference Frame Reallocation in Mode Switching for Assistive Robotics](https://arxiv.org/abs/2510.08753)
*A. Wang,C. Jiang,M. Przystupa,J. Valentine,M. Jagersand*

Main category: cs.RO

TL;DR: 提出Point and Go模式切换方法，通过重新分配笛卡尔模式切换参考系，创建更直观的平移和旋转模式，显著提升轮椅机器人操作性能。


<details>
  <summary>Details</summary>
Motivation: 传统笛卡尔空间模式切换存在控制参考系不直观、平移和旋转控制分离、运动能力有限等问题，影响轮椅机器人操作性能。

Method: 使用新颖的扫掠运动指向夹爪，在机器人基座水平面定义新的平移轴，创建直观的'指向并移动'平移模式；旋转模式结合位置控制和精炼的末端执行器定向框架。

Result: 用户研究表明，相比笛卡尔模式切换和最先进学习方法，Point and Go将完成时间减少31%，暂停时间减少41%，模式切换减少33%，用户评价显著更优。

Conclusion: Point and Go模式切换通过更直观的动作空间设计，有效解决了传统模式切换的局限性，显著提升了轮椅机器人操作性能和用户体验。

Abstract: Operating high degree of freedom robots can be difficult for users of
wheelchair mounted robotic manipulators. Mode switching in Cartesian space has
several drawbacks such as unintuitive control reference frames, separate
translation and orientation control, and limited movement capabilities that
hinder performance. We propose Point and Go mode switching, which reallocates
the Cartesian mode switching reference frames into a more intuitive action
space comprised of new translation and rotation modes. We use a novel sweeping
motion to point the gripper, which defines the new translation axis along the
robot base frame's horizontal plane. This creates an intuitive `point and go'
translation mode that allows the user to easily perform complex, human-like
movements without switching control modes. The system's rotation mode combines
position control with a refined end-effector oriented frame that provides
precise and consistent robot actions in various end-effector poses. We verified
its effectiveness through initial experiments, followed by a three-task user
study that compared our method to Cartesian mode switching and a state of the
art learning method. Results show that Point and Go mode switching reduced
completion times by 31\%, pauses by 41\%, and mode switches by 33\%, while
receiving significantly favorable responses in user surveys.

</details>


### [47] [Whole Body Model Predictive Control for Spin-Aware Quadrupedal Table Tennis](https://arxiv.org/abs/2510.08754)
*David Nguyen,Zulfiqar Zaidi,Kevin Karol,Jessica Hodgins,Zhaoming Xie*

Main category: cs.RO

TL;DR: 开发了一个用于四足机器人的动态乒乓球系统，集成了高速感知、轨迹预测和敏捷控制，能够与人类玩家进行对打。


<details>
  <summary>Details</summary>
Motivation: 开发能够匹配人类速度、精度和预测各种球旋转能力的乒乓球机器人对腿式机器人来说仍然是一个重大挑战。

Method: 使用外部摄像头进行高速球定位，结合物理模型和学习的残差来推断旋转和预测轨迹，采用新颖的模型预测控制（MPC）公式进行敏捷全身控制。

Result: 在Spot四足机器人上成功演示了系统，能够瞄准和回击不同类型的旋转球，并能与人类玩家进行对打。

Conclusion: 该系统展示了四足机器人在动态乒乓球任务中的协调能力，通过控制范式自动涌现出连续的击球策略。

Abstract: Developing table tennis robots that mirror human speed, accuracy, and ability
to predict and respond to the full range of ball spins remains a significant
challenge for legged robots. To demonstrate these capabilities we present a
system to play dynamic table tennis for quadrupedal robots that integrates high
speed perception, trajectory prediction, and agile control. Our system uses
external cameras for high-speed ball localization, physical models with learned
residuals to infer spin and predict trajectories, and a novel model predictive
control (MPC) formulation for agile full-body control. Notably, a continuous
set of stroke strategies emerge automatically from different ball return
objectives using this control paradigm. We demonstrate our system in the real
world on a Spot quadruped, evaluate accuracy of each system component, and
exhibit coordination through the system's ability to aim and return balls with
varying spin types. As a further demonstration, the system is able to rally
with human players.

</details>


### [48] [Geometry-aware Policy Imitation](https://arxiv.org/abs/2510.08787)
*Yiming Li,Nael Darwiche,Amirreza Razmjoo,Sichao Liu,Yilun Du,Auke Ijspeert,Sylvain Calinon*

Main category: cs.RO

TL;DR: GPI将演示数据视为几何曲线而非状态-动作样本，通过距离场生成两种控制流：前进流和吸引流，构建可控的非参数向量场直接指导机器人行为。


<details>
  <summary>Details</summary>
Motivation: 重新思考模仿学习，将演示数据作为几何曲线处理，解耦度量学习和策略合成，实现跨低维状态和高维感知输入的模块化适应。

Method: 从演示曲线推导距离场，生成前进流（沿专家轨迹推进）和吸引流（纠正偏差），组合成可控向量场指导机器人行为。

Result: 在仿真和真实机器人任务中，GPI比基于扩散的策略获得更高成功率，运行速度快20倍，内存需求更少，且对扰动保持鲁棒性。

Conclusion: GPI作为机器人模仿学习中生成式方法的高效、可解释和可扩展替代方案，支持多模态演示和高效组合新演示。

Abstract: We propose a Geometry-aware Policy Imitation (GPI) approach that rethinks
imitation learning by treating demonstrations as geometric curves rather than
collections of state-action samples. From these curves, GPI derives distance
fields that give rise to two complementary control primitives: a progression
flow that advances along expert trajectories and an attraction flow that
corrects deviations. Their combination defines a controllable, non-parametric
vector field that directly guides robot behavior. This formulation decouples
metric learning from policy synthesis, enabling modular adaptation across
low-dimensional robot states and high-dimensional perceptual inputs. GPI
naturally supports multimodality by preserving distinct demonstrations as
separate models and allows efficient composition of new demonstrations through
simple additions to the distance field. We evaluate GPI in simulation and on
real robots across diverse tasks. Experiments show that GPI achieves higher
success rates than diffusion-based policies while running 20 times faster,
requiring less memory, and remaining robust to perturbations. These results
establish GPI as an efficient, interpretable, and scalable alternative to
generative approaches for robotic imitation learning. Project website:
https://yimingli1998.github.io/projects/GPI/

</details>


### [49] [Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation](https://arxiv.org/abs/2510.08807)
*Zhenyu Zhao,Hongyi Jing,Xiawei Liu,Jiageng Mao,Abha Jha,Hanwen Yang,Rong Xue,Sergey Zakharor,Vitor Guizilini,Yue Wang*

Main category: cs.RO

TL;DR: 提出了Humanoid Everyday数据集，这是一个大规模、多样化的人形机器人操作数据集，包含10.3k条轨迹和超过300万帧数据，涵盖260个任务，并提供了云端评估平台。


<details>
  <summary>Details</summary>
Motivation: 当前机器人学习数据集主要关注固定机械臂，现有的人形机器人数据集要么局限于固定环境，要么任务多样性不足，缺乏人机交互和下半身运动，且缺乏标准化的评估平台。

Method: 通过高效的人类监督遥操作流程收集高质量多模态感知数据，包括RGB、深度、LiDAR和触觉输入，以及自然语言注释，涵盖7大类260个任务。

Result: 构建了包含10.3k条轨迹和超过300万帧数据的多样化数据集，并分析了代表性策略学习方法在不同任务类别上的表现。

Conclusion: 通过发布Humanoid Everyday数据集、策略学习分析和标准化云端评估平台，旨在推进通用人形机器人操作研究，为现实世界中更强大、具身化的机器人智能体奠定基础。

Abstract: From loco-motion to dextrous manipulation, humanoid robots have made
remarkable strides in demonstrating complex full-body capabilities. However,
the majority of current robot learning datasets and benchmarks mainly focus on
stationary robot arms, and the few existing humanoid datasets are either
confined to fixed environments or limited in task diversity, often lacking
human-humanoid interaction and lower-body locomotion. Moreover, there are a few
standardized evaluation platforms for benchmarking learning-based policies on
humanoid data. In this work, we present Humanoid Everyday, a large-scale and
diverse humanoid manipulation dataset characterized by extensive task variety
involving dextrous object manipulation, human-humanoid interaction,
locomotion-integrated actions, and more. Leveraging a highly efficient
human-supervised teleoperation pipeline, Humanoid Everyday aggregates
high-quality multimodal sensory data, including RGB, depth, LiDAR, and tactile
inputs, together with natural language annotations, comprising 10.3k
trajectories and over 3 million frames of data across 260 tasks across 7 broad
categories. In addition, we conduct an analysis of representative policy
learning methods on our dataset, providing insights into their strengths and
limitations across different task categories. For standardized evaluation, we
introduce a cloud-based evaluation platform that allows researchers to
seamlessly deploy their policies in our controlled setting and receive
performance feedback. By releasing Humanoid Everyday along with our policy
learning analysis and a standardized cloud-based evaluation platform, we intend
to advance research in general-purpose humanoid manipulation and lay the
groundwork for more capable and embodied robotic agents in real-world
scenarios. Our dataset, data collection code, and cloud evaluation website are
made publicly available on our project website.

</details>


### [50] [Adaptive Motion Planning via Contact-Based Intent Inference for Human-Robot Collaboration](https://arxiv.org/abs/2510.08811)
*Jiurun Song,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: 提出了一种基于接触信息的人机协作自适应运动规划框架，通过物理接触推断人类意图并在线修正机器人运动


<details>
  <summary>Details</summary>
Motivation: 解决人机协作中机器人如何安全高效地适应人类意图的问题，克服大语言模型在可靠运动规划中的局限性，以及物理人机交互中持续引导给操作者带来的负担

Method: 1) 基于优化的力估计方法从关节扭矩测量推断人类意图的接触力和位置；2) 基于扭矩的接触检测机制进行链接级定位；3) 接触信息自适应运动规划器在线重新规划机器人运动

Result: 在7自由度机械臂上的实验表明，所提出的力估计方法具有准确性，接触信息自适应运动规划器在人机协作感知不确定性下具有有效性

Conclusion: 该框架能够直接从物理接触推断人类意图，实现实时运动修正，为人机协作提供了一种可靠且高效的解决方案

Abstract: Human-robot collaboration (HRC) requires robots to adapt their motions to
human intent to ensure safe and efficient cooperation in shared spaces.
Although large language models (LLMs) provide high-level reasoning for
inferring human intent, their application to reliable motion planning in HRC
remains challenging. Physical human-robot interaction (pHRI) is intuitive but
often relies on continuous kinesthetic guidance, which imposes burdens on
operators. To address these challenges, a contact-informed adaptive
motion-planning framework is introduced to infer human intent directly from
physical contact and employ the inferred intent for online motion correction in
HRC. First, an optimization-based force estimation method is proposed to infer
human-intended contact forces and locations from joint torque measurements and
a robot dynamics model, thereby reducing cost and installation complexity while
enabling whole-body sensitivity. Then, a torque-based contact detection
mechanism with link-level localization is introduced to reduce the optimization
search space and to enable real-time estimation. Subsequently, a
contact-informed adaptive motion planner is developed to infer human intent
from contacts and to replan robot motion online, while maintaining smoothness
and adapting to human corrections. Finally, experiments on a 7-DOF manipulator
are conducted to demonstrate the accuracy of the proposed force estimation
method and the effectiveness of the contact-informed adaptive motion planner
under perception uncertainty in HRC.

</details>


### [51] [Adaptive Science Operations in Deep Space Missions Using Offline Belief State Planning](https://arxiv.org/abs/2510.08812)
*Grace Ra Kim,Hailey Warner,Duncan Eddy,Evan Astle,Zachary Booth,Edward Balaban,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 提出了一个基于部分可观测马尔可夫决策过程(POMDP)的框架，用于在通信受限的深空任务中自适应排序航天器科学仪器，通过集成贝叶斯网络来管理高维不确定测量数据。


<details>
  <summary>Details</summary>
Motivation: 深空任务面临极端的通信延迟和环境不确定性，无法进行实时地面操作，需要支持自主科学操作。

Method: 将贝叶斯网络集成到POMDP观测空间中，紧凑编码测量依赖关系，离线计算仪器操作策略，生成资源感知计划。

Result: 使用Enceladus Orbilander的生命检测套件作为案例研究，与任务基线概念操作相比，样本识别错误减少了近40%。

Conclusion: 该方法提高了科学数据的可解释性和计算可行性，在非标称样本积累场景中表现出更好的性能。

Abstract: Deep space missions face extreme communication delays and environmental
uncertainty that prevent real-time ground operations. To support autonomous
science operations in communication-constrained environments, we present a
partially observable Markov decision process (POMDP) framework that adaptively
sequences spacecraft science instruments. We integrate a Bayesian network into
the POMDP observation space to manage the high-dimensional and uncertain
measurements typical of astrobiology missions. This network compactly encodes
dependencies among measurements and improves the interpretability and
computational tractability of science data. Instrument operation policies are
computed offline, allowing resource-aware plans to be generated and thoroughly
validated prior to launch. We use the Enceladus Orbilander's proposed Life
Detection Suite (LDS) as a case study, demonstrating how Bayesian network
structure and reward shaping influence system performance. We compare our
method against the mission's baseline Concept of Operations (ConOps),
evaluating both misclassification rates and performance in off-nominal sample
accumulation scenarios. Our approach reduces sample identification errors by
nearly 40%

</details>


### [52] [CDE: Concept-Driven Exploration for Reinforcement Learning](https://arxiv.org/abs/2510.08851)
*Le Mao,Andrew H. Liu,Renos Zabounidis,Zachary Kingston,Joseph Campbell*

Main category: cs.RO

TL;DR: CDE利用预训练的视觉语言模型从文本任务描述生成物体中心视觉概念，通过重建这些概念作为内在奖励来指导探索，在视觉控制任务中实现高效探索。


<details>
  <summary>Details</summary>
Motivation: 解决视觉强化学习中探索效率低的问题，因为需要从原始像素中提取任务相关结构，比低维状态RL更困难。

Method: 使用预训练VLM从文本任务描述生成物体中心视觉概念，训练策略通过辅助目标重建这些概念，将重建准确性作为内在奖励来指导探索。

Result: 在五个模拟视觉操作任务中实现高效、有针对性的探索，对噪声VLM预测具有鲁棒性；在真实世界Franka机械臂上达到80%成功率。

Conclusion: CDE通过概念驱动的探索方法有效解决了视觉RL中的探索挑战，减少了对部署时外部模型的依赖，在模拟和真实世界任务中都表现出色。

Abstract: Intelligent exploration remains a critical challenge in reinforcement
learning (RL), especially in visual control tasks. Unlike low-dimensional
state-based RL, visual RL must extract task-relevant structure from raw pixels,
making exploration inefficient. We propose Concept-Driven Exploration (CDE),
which leverages a pre-trained vision-language model (VLM) to generate
object-centric visual concepts from textual task descriptions as weak,
potentially noisy supervisory signals. Rather than directly conditioning on
these noisy signals, CDE trains a policy to reconstruct the concepts via an
auxiliary objective, using reconstruction accuracy as an intrinsic reward to
guide exploration toward task-relevant objects. Because the policy internalizes
these concepts, VLM queries are only needed during training, reducing
dependence on external models during deployment. Across five challenging
simulated visual manipulation tasks, CDE achieves efficient, targeted
exploration and remains robust to noisy VLM predictions. Finally, we
demonstrate real-world transfer by deploying CDE on a Franka Research 3 arm,
attaining an 80\% success rate in a real-world manipulation task.

</details>


### [53] [Online IMU-odometer Calibration using GNSS Measurements for Autonomous Ground Vehicle Localization](https://arxiv.org/abs/2510.08880)
*Baoshan Song,Xiao Xia,Penggao Yan,Yihan Zhong,Weisong Wen,Li-Ta Hsu*

Main category: cs.RO

TL;DR: 提出了一种紧耦合在线校准方法，融合IMU、里程计和原始GNSS测量，用于自主地面车辆的定位校准。


<details>
  <summary>Details</summary>
Motivation: 现有GNSS辅助方法依赖定位结果或未解析模糊度的原始测量，且可观测性特性研究不足。

Method: 在可扩展因子图优化框架中融合IMU、里程计和原始GNSS测量（伪距、载波相位和多普勒），包含异常值抑制和模糊度解析。

Result: 仿真和真实实验显示，在校准和定位性能上优于最先进的松耦合方法，IMU-里程计定位绝对最大误差从61.51米降至17.75米，提升71.14%。

Conclusion: 水平平移和三个旋转参数在一般运动下可观测，垂直平移不可观测；发布了首个结合IMU、2D里程计和原始GNSS测量的开源数据集。

Abstract: Accurate calibration of intrinsic (odometer scaling factors) and extrinsic
parameters (IMU-odometer translation and rotation) is essential for autonomous
ground vehicle localization. Existing GNSS-aided approaches often rely on
positioning results or raw measurements without ambiguity resolution, and their
observability properties remain underexplored. This paper proposes a tightly
coupled online calibration method that fuses IMU, odometer, and raw GNSS
measurements (pseudo-range, carrier-phase, and Doppler) within an extendable
factor graph optimization (FGO) framework, incorporating outlier mitigation and
ambiguity resolution. Observability analysis reveals that two horizontal
translation and three rotation parameters are observable under general motion,
while vertical translation remains unobservable. Simulation and real-world
experiments demonstrate superior calibration and localization performance over
state-of-the-art loosely coupled methods. Specifically, the IMU-odometer
positioning using our calibrated parameters achieves the absolute maximum error
of 17.75 m while the one of LC method is 61.51 m, achieving up to 71.14 percent
improvement. To foster further research, we also release the first open-source
dataset that combines IMU, 2D odometer, and raw GNSS measurements from both
rover and base stations.

</details>


### [54] [Model-Based Lookahead Reinforcement Learning for in-hand manipulation](https://arxiv.org/abs/2510.08884)
*Alexandre Lopes,Catarina Barata,Plinio Moreno*

Main category: cs.RO

TL;DR: 将混合强化学习框架应用于手内操作任务，结合模型无关和模型相关方法，通过轨迹评估提升性能，但增加了计算成本


<details>
  <summary>Details</summary>
Motivation: 手内操作是机器人学中的挑战性任务，需要控制复杂动态系统来操纵各种物体。本文旨在验证混合强化学习框架能否提升手内操作任务的性能

Method: 使用混合强化学习框架，结合模型无关和模型相关方法，通过动态模型和价值函数进行轨迹评估（类似模型预测控制）。使用完全驱动和欠驱动仿真机械手测试不同物体的操作

Result: 在大多数测试案例中，混合框架提升了手内操作任务的性能，即使物体属性发生变化。但性能提升以计算成本增加为代价

Conclusion: 混合强化学习框架能够有效提升手内操作任务的性能，具有良好的泛化能力，但需要权衡性能提升与计算成本之间的关系

Abstract: In-Hand Manipulation, as many other dexterous tasks, remains a difficult
challenge in robotics by combining complex dynamic systems with the capability
to control and manoeuvre various objects using its actuators. This work
presents the application of a previously developed hybrid Reinforcement
Learning (RL) Framework to In-Hand Manipulation task, verifying that it is
capable of improving the performance of the task. The model combines concepts
of both Model-Free and Model-Based Reinforcement Learning, by guiding a trained
policy with the help of a dynamic model and value-function through trajectory
evaluation, as done in Model Predictive Control. This work evaluates the
performance of the model by comparing it with the policy that will be guided.
To fully explore this, various tests are performed using both fully-actuated
and under-actuated simulated robotic hands to manipulate different objects for
a given task. The performance of the model will also be tested for
generalization tests, by changing the properties of the objects in which both
the policy and dynamic model were trained, such as density and size, and
additionally by guiding a trained policy in a certain object to perform the
same task in a different one. The results of this work show that, given a
policy with high average reward and an accurate dynamic model, the hybrid
framework improves the performance of in-hand manipulation tasks for most test
cases, even when the object properties are changed. However, this improvement
comes at the expense of increasing the computational cost, due to the
complexity of trajectory evaluation.

</details>


### [55] [Direct Data-Driven Predictive Control for a Three-dimensional Cable-Driven Soft Robotic Arm](https://arxiv.org/abs/2510.08953)
*Cheng Ouyang,Moeen Ul Islam,Dong Chen,Kaixiang Zhang,Zhaojian Li,Xiaobo Tan*

Main category: cs.RO

TL;DR: 本文开发并验证了基于数据驱动预测控制(DeePC)的3D软体机器人控制框架，在电缆驱动的软体手臂上实现了精确的动态控制。


<details>
  <summary>Details</summary>
Motivation: 软体机器人具有安全性和适应性优势，但因其复杂的非线性动力学特性，实现精确动态控制仍具挑战。DeePC作为一种无需显式系统辨识的模型无关方法，在软体机器人领域的应用尚未充分探索，特别是在3D系统上。

Method: 设计制造了具有厚管状骨架、致密硅胶体和刚性端盖的3D电缆驱动软体手臂，采用基于奇异值分解(SVD)降维的DeePC方法，实现了固定点调节和3D空间轨迹跟踪两种控制任务。

Result: 与基于模型的基线控制器相比，DeePC在精度、鲁棒性和适应性方面表现出优越性能，验证了其在软体机器人动态控制中的有效性。

Conclusion: DeePC框架为软体机器人的动态控制提供了一种实用的解决方案，展示了其在3D软体机器人系统中的巨大潜力。

Abstract: Soft robots offer significant advantages in safety and adaptability, yet
achieving precise and dynamic control remains a major challenge due to their
inherently complex and nonlinear dynamics. Recently, Data-enabled Predictive
Control (DeePC) has emerged as a promising model-free approach that bypasses
explicit system identification by directly leveraging input-output data. While
DeePC has shown success in other domains, its application to soft robots
remains underexplored, particularly for three-dimensional (3D) soft robotic
systems. This paper addresses this gap by developing and experimentally
validating an effective DeePC framework on a 3D, cable-driven soft arm.
Specifically, we design and fabricate a soft robotic arm with a thick tubing
backbone for stability, a dense silicone body with large cavities for strength
and flexibility, and rigid endcaps for secure termination. Using this platform,
we implement DeePC with singular value decomposition (SVD)-based dimension
reduction for two key control tasks: fixed-point regulation and trajectory
tracking in 3D space. Comparative experiments with a baseline model-based
controller demonstrate DeePC's superior accuracy, robustness, and adaptability,
highlighting its potential as a practical solution for dynamic control of soft
robots.

</details>


### [56] [A geometrical approach to solve the proximity of a point to an axisymmetric quadric in space](https://arxiv.org/abs/2510.08973)
*Bibekananda Patra,Aditya Mahesh Kolte,Sandipan Bandyopadhyay*

Main category: cs.RO

TL;DR: 该论文提出了一种将一般二次曲面分类为轴对称二次曲面(AQ)的方法，并解决了点到AQ的邻近度问题。通过将R^3空间的问题简化为R^2空间，并利用圆锥曲线的几何特性开发新算法，证明比商业库Bullet更快。


<details>
  <summary>Details</summary>
Motivation: 解决三维空间中点到轴对称二次曲面的邻近度计算问题，现有文献中缺乏将R^3问题简化为R^2的有效方法，需要开发更高效的算法。

Method: 将R^3空间的邻近度问题简化为R^2空间，基于圆锥曲线的几何特性（如次法线、半长轴长度、离心率、斜率和半径）开发新方法，对抛物线和椭圆/双曲线分别进行2-3种子情况分类。

Result: 提出的方法适合在C等通用编程语言中实现，经测试比商业库Bullet更快。

Conclusion: 成功开发了将三维邻近度问题简化为二维的有效方法，基于几何特性的新算法在性能上优于现有商业解决方案。

Abstract: This paper presents the classification of a general quadric into an
axisymmetric quadric (AQ) and the solution to the problem of the proximity of a
given point to an AQ. The problem of proximity in $R^3$ is reduced to the same
in $R^2$, which is not found in the literature. A new method to solve the
problem in $R^2$ is used based on the geometrical properties of the conics,
such as sub-normal, length of the semi-major axis, eccentricity, slope and
radius. Furthermore, the problem in $R^2$ is categorised into two and three
more sub-cases for parabola and ellipse/hyperbola, respectively, depending on
the location of the point, which is a novel approach as per the authors'
knowledge. The proposed method is suitable for implementation in a common
programming language, such as C and proved to be faster than a commercial
library, namely, Bullet.

</details>


### [57] [Trust Modeling and Estimation in Human-Autonomy Interactions](https://arxiv.org/abs/2510.09013)
*Daniel A. Williams,Airlie Chapman,Daniel R. Little,Chris Manzie*

Main category: cs.RO

TL;DR: 本文提出了一个基于切换线性系统的监督者信任动态模型，该模型能够处理对自主系统性能的不对称响应和间歇性通信特性。


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏能够同时处理自主系统性能不对称响应和监督者-自主系统间歇性通信特性的信任动态模型，这影响了人机交互质量。

Method: 采用切换线性系统结构，结合事件触发采样的模型输入输出，使用51名参与者的信任响应数据来识别切换线性模型观测器的参数。

Result: 成功构建了一个能够准确描述监督者信任动态的模型，该模型能够捕捉信任对自主系统性能的不对称响应特性。

Conclusion: 提出的切换线性系统模型为理解和管理人机交互中的信任动态提供了有效的建模框架。

Abstract: Advances in the control of autonomous systems have accompanied an expansion
in the potential applications for autonomous robotic systems. The success of
applications involving humans depends on the quality of interaction between the
autonomous system and the human supervisor, which is particularly affected by
the degree of trust that the supervisor places in the autonomous system. Absent
from the literature are models of supervisor trust dynamics that can
accommodate asymmetric responses to autonomous system performance and the
intermittent nature of supervisor-autonomous system communication. This paper
focuses on formulating an estimated model of supervisor trust that incorporates
both of these features by employing a switched linear system structure with
event-triggered sampling of the model input and output. Trust response data
collected in a user study with 51 participants were then used identify
parameters for a switched linear model-based observer of supervisor trust.

</details>


### [58] [iMoWM: Taming Interactive Multi-Modal World Model for Robotic Manipulation](https://arxiv.org/abs/2510.09036)
*Chuanrui Zhang,Zhengxian Wu,Guanxing Lu,Yansong Tang,Ziwei Wang*

Main category: cs.RO

TL;DR: iMoWM是一个用于机器人操作的交互式世界模型，通过多模态令牌化器统一处理颜色图像、深度图和机械臂掩码，在保持高效的同时增强3D物理信息建模能力。


<details>
  <summary>Details</summary>
Motivation: 现有的2D视频世界模型缺乏几何和空间推理能力，无法充分捕捉3D世界的物理结构，限制了在机器人操作任务中的应用。

Method: 提出iMoWM交互式世界模型和MMTokenizer多模态令牌化器，将多模态输入统一为紧凑令牌表示，以自回归方式生成颜色图像、深度图和机械臂掩码。

Result: 实验证明iMoWM在视觉质量、模型强化学习和真实世界模仿学习方面表现优越，展示了多模态世界建模在机器人操作中的优势。

Conclusion: 多模态世界建模能够有效提升机器人操作任务的性能，iMoWM通过整合3D物理信息为机器人操作提供了更强大的仿真环境。

Abstract: Learned world models hold significant potential for robotic manipulation, as
they can serve as simulator for real-world interactions. While extensive
progress has been made in 2D video-based world models, these approaches often
lack geometric and spatial reasoning, which is essential for capturing the
physical structure of the 3D world. To address this limitation, we introduce
iMoWM, a novel interactive world model designed to generate color images, depth
maps, and robot arm masks in an autoregressive manner conditioned on actions.
To overcome the high computational cost associated with three-dimensional
information, we propose MMTokenizer, which unifies multi-modal inputs into a
compact token representation. This design enables iMoWM to leverage large-scale
pretrained VideoGPT models while maintaining high efficiency and incorporating
richer physical information. With its multi-modal representation, iMoWM not
only improves the visual quality of future predictions but also serves as an
effective simulator for model-based reinforcement learning (MBRL) and
facilitates real-world imitation learning. Extensive experiments demonstrate
the superiority of iMoWM across these tasks, showcasing the advantages of
multi-modal world modeling for robotic manipulation. Homepage:
https://xingyoujun.github.io/imowm/

</details>


### [59] [Training Models to Detect Successive Robot Errors from Human Reactions](https://arxiv.org/abs/2510.09080)
*Shannon Liu,Maria Teresa Parreira,Wendy Ju*

Main category: cs.RO

TL;DR: 该研究使用机器学习从人类反应中识别机器人连续失败阶段，通过提取视频行为特征训练个性化模型，在检测错误和分类连续失败方面分别达到93.5%和84.1%的准确率。


<details>
  <summary>Details</summary>
Motivation: 随着机器人更深入融入社会，检测机器人错误对有效的人机交互至关重要。人类对机器人错误的反应会随着连续失败而加剧，从困惑到明显沮丧，但现有研究很少探讨这些演化反应如何揭示连续失败。

Method: 在26名参与者与反复出现对话错误的机器人互动研究中，从视频数据中提取行为特征，为个体用户训练机器学习模型。

Result: 最佳模型在检测错误方面达到93.5%准确率，在分类连续失败方面达到84.1%准确率。

Conclusion: 对人类反应进展进行建模能够增强错误检测能力，并更好地理解人机交互中重复的交互中断。

Abstract: As robots become more integrated into society, detecting robot errors is
essential for effective human-robot interaction (HRI). When a robot fails
repeatedly, how can it know when to change its behavior? Humans naturally
respond to robot errors through verbal and nonverbal cues that intensify over
successive failures-from confusion and subtle speech changes to visible
frustration and impatience. While prior work shows that human reactions can
indicate robot failures, few studies examine how these evolving responses
reveal successive failures. This research uses machine learning to recognize
stages of robot failure from human reactions. In a study with 26 participants
interacting with a robot that made repeated conversational errors, behavioral
features were extracted from video data to train models for individual users.
The best model achieved 93.5% accuracy for detecting errors and 84.1% for
classifying successive failures. Modeling the progression of human reactions
enhances error detection and understanding of repeated interaction breakdowns
in HRI.

</details>


### [60] [Robust Visual Teach-and-Repeat Navigation with Flexible Topo-metric Graph Map Representation](https://arxiv.org/abs/2510.09089)
*Jikai Wang,Yunqi Cheng,Kezhi Wang,Zonghai Chen*

Main category: cs.RO

TL;DR: 提出了一种新颖的视觉教-复导航系统，通过灵活的拓扑度量图表示、鲁棒的地图匹配和无地图局部导航模块，解决了环境变化和动态物体对轨迹重复导航的挑战。


<details>
  <summary>Details</summary>
Motivation: 视觉教-复导航是移动机器人在未知环境中部署的直接解决方案，但由于环境变化和动态物体的存在，鲁棒的轨迹重复导航仍然面临挑战。

Method: 系统包含三个核心模块：1）灵活的拓扑度量图表示，支持关键帧扩展；2）基于关键帧聚类的视觉帧到局部地图匹配策略；3）长期目标管理算法和无地图局部轨迹控制优化算法。

Result: 在移动平台上进行了广泛实验，结果表明该系统在鲁棒性和有效性方面优于基线方法。

Conclusion: 提出的视觉教-复导航系统能够有效应对环境变化和动态障碍，实现鲁棒的轨迹重复导航。

Abstract: Visual Teach-and-Repeat Navigation is a direct solution for mobile robot to
be deployed in unknown environments. However, robust trajectory repeat
navigation still remains challenged due to environmental changing and dynamic
objects. In this paper, we propose a novel visual teach-and-repeat navigation
system, which consists of a flexible map representation, robust map matching
and a map-less local navigation module. During the teaching process, the
recorded keyframes are formulated as a topo-metric graph and each node can be
further extended to save new observations. Such representation also alleviates
the requirement of globally consistent mapping. To enhance the place
recognition performance during repeating process, instead of using
frame-to-frame matching, we firstly implement keyframe clustering to aggregate
similar connected keyframes into local map and perform place recognition based
on visual frame-tolocal map matching strategy. To promote the local goal
persistent tracking performance, a long-term goal management algorithm is
constructed, which can avoid the robot getting lost due to environmental
changes or obstacle occlusion. To achieve the goal without map, a local
trajectory-control candidate optimization algorithm is proposed. Extensively
experiments are conducted on our mobile platform. The results demonstrate that
our system is superior to the baselines in terms of robustness and
effectiveness.

</details>


### [61] [When a Robot is More Capable than a Human: Learning from Constrained Demonstrators](https://arxiv.org/abs/2510.09096)
*Xinhu Li,Ayush Jain,Zhaojing Yang,Yigit Korkmaz,Erdem Bıyık*

Main category: cs.RO

TL;DR: 该论文提出了一种从受限专家演示中学习的方法，通过推断状态奖励信号和自标注未知状态奖励，使机器人能够学习比专家演示更优的策略。


<details>
  <summary>Details</summary>
Motivation: 现有演示接口（如遥操作、模拟到真实迁移）限制了专家展示最优行为的能力，导致收集的演示数据质量不高，学习到的策略性能欠佳。

Method: 使用演示数据推断仅基于状态的任务进度奖励信号，通过时间插值为未知状态自标注奖励，让智能体探索比专家演示更短更高效的轨迹。

Result: 该方法在样本效率和任务完成时间上都优于常见的模仿学习方法，在真实WidowX机械臂上完成任务仅需12秒，比行为克隆快10倍。

Conclusion: 通过超越直接模仿专家动作，利用状态奖励信号和时间插值，机器人能够从受限专家演示中学习到比专家本身更优的策略。

Abstract: Learning from demonstrations enables experts to teach robots complex tasks
using interfaces such as kinesthetic teaching, joystick control, and
sim-to-real transfer. However, these interfaces often constrain the expert's
ability to demonstrate optimal behavior due to indirect control, setup
restrictions, and hardware safety. For example, a joystick can move a robotic
arm only in a 2D plane, even though the robot operates in a higher-dimensional
space. As a result, the demonstrations collected by constrained experts lead to
suboptimal performance of the learned policies. This raises a key question: Can
a robot learn a better policy than the one demonstrated by a constrained
expert? We address this by allowing the agent to go beyond direct imitation of
expert actions and explore shorter and more efficient trajectories. We use the
demonstrations to infer a state-only reward signal that measures task progress,
and self-label reward for unknown states using temporal interpolation. Our
approach outperforms common imitation learning in both sample efficiency and
task completion time. On a real WidowX robotic arm, it completes the task in 12
seconds, 10x faster than behavioral cloning, as shown in real-robot videos on
https://sites.google.com/view/constrainedexpert .

</details>


### [62] [Decentralized Multi-Robot Relative Navigation in Unknown, Structurally Constrained Environments under Limited Communication](https://arxiv.org/abs/2510.09188)
*Zihao Mao,Yunheng Wang,Yunting Ji,Yi Yang,Wenjie Song*

Main category: cs.RO

TL;DR: 提出了一种完全去中心化的分层相对导航框架，在未知、结构受限且无GPS的环境中实现战略远见和战术敏捷性，无需统一坐标系。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人导航中全局战略远见与局部战术敏捷性之间的基本权衡，特别是在通信受限环境下。集中式方法通信开销大，分布式方法缺乏全局意识容易陷入死锁和拓扑陷阱。

Method: 分层框架：战略层通过机会性相遇构建和交换轻量级拓扑地图，培养涌现的全局意识；战术层基于局部度量信息，采用基于采样的逃逸点策略实时生成动态可行轨迹。

Result: 广泛的仿真和真实世界实验表明，该系统在成功率和工作效率方面显著优于其他方法，特别是在通信受限和拓扑结构复杂的环境中。

Conclusion: 该去中心化分层相对导航框架成功平衡了战略远见和战术敏捷性，在复杂环境中实现了高效的多机器人导航，无需统一坐标系或高通信开销。

Abstract: Multi-robot navigation in unknown, structurally constrained, and GPS-denied
environments presents a fundamental trade-off between global strategic
foresight and local tactical agility, particularly under limited communication.
Centralized methods achieve global optimality but suffer from high
communication overhead, while distributed methods are efficient but lack the
broader awareness to avoid deadlocks and topological traps. To address this, we
propose a fully decentralized, hierarchical relative navigation framework that
achieves both strategic foresight and tactical agility without a unified
coordinate system. At the strategic layer, robots build and exchange
lightweight topological maps upon opportunistic encounters. This process
fosters an emergent global awareness, enabling the planning of efficient,
trap-avoiding routes at an abstract level. This high-level plan then inspires
the tactical layer, which operates on local metric information. Here, a
sampling-based escape point strategy resolves dense spatio-temporal conflicts
by generating dynamically feasible trajectories in real time, concurrently
satisfying tight environmental and kinodynamic constraints. Extensive
simulations and real-world experiments demonstrate that our system
significantly outperforms in success rate and efficiency, especially in
communication-limited environments with complex topological structures.

</details>


### [63] [Flow-Opt: Scalable Centralized Multi-Robot Trajectory Optimization with Flow Matching and Differentiable Optimization](https://arxiv.org/abs/2510.09204)
*Simon Idoko,Arun Kumar Singh*

Main category: cs.RO

TL;DR: Flow-Opt是一种基于学习的集中式多机器人轨迹优化方法，使用流匹配模型生成候选轨迹，并通过学习的安全过滤器确保约束满足，实现毫秒级轨迹生成。


<details>
  <summary>Details</summary>
Motivation: 集中式多机器人轨迹优化在狭窄空间中能产生更平滑的轨迹，但计算复杂度随机器人数量增加而急剧上升，难以扩展到大规模群体。

Method: 提出Flow-Opt方法：1）使用扩散变换器（DiT）构建生成模型采样候选轨迹；2）开发可微分的安全过滤器确保约束满足；3）训练神经网络预测上下文特定的初始化。

Result: 在杂乱环境中生成数十个机器人的轨迹仅需几十毫秒，比现有集中式优化方法快数倍，比基于扩散模型的基线方法快几个数量级，并能批量处理多个问题实例。

Conclusion: 该方法实现了高效的多机器人轨迹规划，在计算速度和轨迹平滑度方面显著优于现有方法，并能生成多样化的避碰行为轨迹。

Abstract: Centralized trajectory optimization in the joint space of multiple robots
allows access to a larger feasible space that can result in smoother
trajectories, especially while planning in tight spaces. Unfortunately, it is
often computationally intractable beyond a very small swarm size. In this
paper, we propose Flow-Opt, a learning-based approach towards improving the
computational tractability of centralized multi-robot trajectory optimization.
Specifically, we reduce the problem to first learning a generative model to
sample different candidate trajectories and then using a learned
Safety-Filter(SF) to ensure fast inference-time constraint satisfaction. We
propose a flow-matching model with a diffusion transformer (DiT) augmented with
permutation invariant robot position and map encoders as the generative model.
We develop a custom solver for our SF and equip it with a neural network that
predicts context-specific initialization. The initialization network is trained
in a self-supervised manner, taking advantage of the differentiability of the
SF solver. We advance the state-of-the-art in the following respects. First, we
show that we can generate trajectories of tens of robots in cluttered
environments in a few tens of milliseconds. This is several times faster than
existing centralized optimization approaches. Moreover, our approach also
generates smoother trajectories orders of magnitude faster than competing
baselines based on diffusion models. Second, each component of our approach can
be batched, allowing us to solve a few tens of problem instances in a fraction
of a second. We believe this is a first such result; no existing approach
provides such capabilities. Finally, our approach can generate a diverse set of
trajectories between a given set of start and goal locations, which can capture
different collision-avoidance behaviors.

</details>


### [64] [PLEXUS Hand: Lightweight Four-Motor Prosthetic Hand Enabling Precision-Lateral Dexterous Manipulation](https://arxiv.org/abs/2510.09209)
*Yuki Kuroda,Tomoya Takahashi,Cristian C Beltran-Hernandez,Masashi Hamaya,Kazutoshi Tanaka*

Main category: cs.RO

TL;DR: 提出一种仅使用4个电机的轻量化（311克）假肢手，通过单轴拇指和优化拇指位置实现基本抓握姿势和手内操作（精度和侧向抓握之间的重新定向）。


<details>
  <summary>Details</summary>
Motivation: 电动假肢手需要轻量化以减轻用户负担，外形像人手用于美观，电机内置以保护免受损坏和污垢。除了执行日常活动的能力外，这些特性对于日常使用至关重要。手内操作对于执行日常活动是必要的，例如在不同姿势之间转换，特别是通过旋转运动。

Method: 结合单轴拇指和优化的拇指定位，仅使用四个电机在轻量化假肢手中实现基本姿势和手内操作（精度和侧向抓握之间的重新定向）。

Result: 使用各种宽度（5-30毫米）和形状（圆柱体和棱柱）的原始物体进行实验验证，重新定向任务的成功率为90-100%。该手成功执行了盖章、USB设备插入以及旋转操作螺丝刀等任务。

Conclusion: 该方法成功实现了仅使用四个电机的轻量化假肢手，能够执行基本抓握和手内操作任务，验证了其在日常活动中的实用性。

Abstract: Electric prosthetic hands should be lightweight to decrease the burden on the
user, shaped like human hands for cosmetic purposes, and have motors inside to
protect them from damage and dirt. In addition to the ability to perform daily
activities, these features are essential for everyday use of the hand. In-hand
manipulation is necessary to perform daily activities such as transitioning
between different postures, particularly through rotational movements, such as
reorienting cards before slot insertion and operating tools such as
screwdrivers. However, currently used electric prosthetic hands only achieve
static grasp postures, and existing manipulation approaches require either many
motors, which makes the prosthesis heavy for daily use in the hand, or complex
mechanisms that demand a large internal space and force external motor
placement, complicating attachment and exposing the components to damage.
Alternatively, we combine a single-axis thumb and optimized thumb positioning
to achieve basic posture and in-hand manipulation, that is, the reorientation
between precision and lateral grasps, using only four motors in a lightweight
(311 g) prosthetic hand. Experimental validation using primitive objects of
various widths (5-30 mm) and shapes (cylinders and prisms) resulted in success
rates of 90-100% for reorientation tasks. The hand performed seal stamping and
USB device insertion, as well as rotation to operate a screwdriver.

</details>


### [65] [HANDO: Hierarchical Autonomous Navigation and Dexterous Omni-loco-manipulation](https://arxiv.org/abs/2510.09221)
*Jingyuan Sun,Chaoran Wang,Mingyu Zhang,Cui Miao,Hongyu Ji,Zihan Qu,Han Sun,Bing Wang,Qingyi Si*

Main category: cs.RO

TL;DR: HANDO框架：为配备机械臂的腿式机器人设计的两层系统，实现自主导航和全身协调操作，用于在非结构化环境中执行人类中心的移动操作任务。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中实现无缝的移动操作需要机器人能够自主探索并协调全身控制进行物理交互，以完成人类中心的移动操作任务。

Method: 采用两层框架：第一层使用目标条件自主探索策略引导机器人到达语义指定目标；第二层使用统一的全身移动操作策略协调手臂和腿部进行精确交互任务。

Result: 已完成导航模块的初步部署，将继续推进全身移动操作的更精细部署。

Conclusion: HANDO框架为腿式机器人在动态环境中执行复杂移动操作任务提供了有效的解决方案，通过分层设计实现了从自主导航到精确操作的完整流程。

Abstract: Seamless loco-manipulation in unstructured environments requires robots to
leverage autonomous exploration alongside whole-body control for physical
interaction. In this work, we introduce HANDO (Hierarchical Autonomous
Navigation and Dexterous Omni-loco-manipulation), a two-layer framework
designed for legged robots equipped with manipulators to perform human-centered
mobile manipulation tasks. The first layer utilizes a goal-conditioned
autonomous exploration policy to guide the robot to semantically specified
targets, such as a black office chair in a dynamic environment. The second
layer employs a unified whole-body loco-manipulation policy to coordinate the
arm and legs for precise interaction tasks-for example, handing a drink to a
person seated on the chair. We have conducted an initial deployment of the
navigation module, and will continue to pursue finer-grained deployment of
whole-body loco-manipulation.

</details>


### [66] [Glovity: Learning Dexterous Contact-Rich Manipulation via Spatial Wrench Feedback Teleoperation System](https://arxiv.org/abs/2510.09229)
*Yuyang Gao,Haofei Ma,Pai Zheng*

Main category: cs.RO

TL;DR: Glovity是一个低成本的可穿戴远程操作系统，集成了空间力反馈设备和带指尖霍尔传感器校准的触觉手套，实现了反馈丰富的灵巧操作。该系统通过提供直观的力反馈和触觉反馈，在接触密集型任务中显著提升了成功率。


<details>
  <summary>Details</summary>
Motivation: 解决接触密集型任务中的关键挑战，通过提供直观的力反馈和触觉反馈来克服体现差距，实现精确的重定向。

Method: 集成空间力反馈设备与带指尖霍尔传感器校准的触觉手套，结合模仿学习（DP-R3M）方法。

Result: 力反馈将翻书任务的成功率从48%提升到78%，完成时间减少25%；指尖校准显著提升了薄物体抓取成功率；在新型接触密集型场景中实现了高成功率。

Conclusion: Glovity系统通过力反馈和触觉反馈显著提升了远程操作的性能和成功率，硬件设计和软件将开源发布。

Abstract: We present Glovity, a novel, low-cost wearable teleoperation system that
integrates a spatial wrench (force-torque) feedback device with a haptic glove
featuring fingertip Hall sensor calibration, enabling feedback-rich dexterous
manipulation. Glovity addresses key challenges in contact-rich tasks by
providing intuitive wrench and tactile feedback, while overcoming embodiment
gaps through precise retargeting. User studies demonstrate significant
improvements: wrench feedback boosts success rates in book-flipping tasks from
48% to 78% and reduces completion time by 25%, while fingertip calibration
enhances thin-object grasping success significantly compared to commercial
glove. Furthermore, incorporating wrench signals into imitation learning (via
DP-R3M) achieves high success rate in novel contact-rich scenarios, such as
adaptive page flipping and force-aware handovers. All hardware designs,
software will be open-sourced. Project website: https://glovity.github.io/

</details>


### [67] [Obstacle Avoidance using Dynamic Movement Primitives and Reinforcement Learning](https://arxiv.org/abs/2510.09254)
*Dominik Urbaniak,Alejandro Agostini,Pol Ramon,Jan Rosell,Raúl Suárez,Michael Suppa*

Main category: cs.RO

TL;DR: 提出一种基于单个人工演示的运动规划方法，使用动态运动基元(DMP)和策略强化学习快速生成平滑、接近最优的3D笛卡尔轨迹，无需大量训练数据或人工演示。


<details>
  <summary>Details</summary>
Motivation: 传统学习型运动规划需要大量训练数据或昂贵的人工演示，本工作旨在通过单个人工演示快速生成多样化的无碰撞轨迹。

Method: 将人工演示编码为DMP，使用基于策略的强化学习迭代重塑以创建多样化轨迹数据集，训练神经网络根据障碍物参数输出DMP参数。

Result: 在仿真和真实机器人实验中验证，在计算时间、执行时间和轨迹长度方面优于RRT-Connect基线，支持不同障碍物几何和末端执行器尺寸的多模态轨迹生成。

Conclusion: 该方法能够高效生成平滑、接近最优的无碰撞轨迹，仅需单个人工演示，具有实际应用价值。

Abstract: Learning-based motion planning can quickly generate near-optimal
trajectories. However, it often requires either large training datasets or
costly collection of human demonstrations. This work proposes an alternative
approach that quickly generates smooth, near-optimal collision-free 3D
Cartesian trajectories from a single artificial demonstration. The
demonstration is encoded as a Dynamic Movement Primitive (DMP) and iteratively
reshaped using policy-based reinforcement learning to create a diverse
trajectory dataset for varying obstacle configurations. This dataset is used to
train a neural network that takes as inputs the task parameters describing the
obstacle dimensions and location, derived automatically from a point cloud, and
outputs the DMP parameters that generate the trajectory. The approach is
validated in simulation and real-robot experiments, outperforming a RRT-Connect
baseline in terms of computation and execution time, as well as trajectory
length, while supporting multi-modal trajectory generation for different
obstacle geometries and end-effector dimensions. Videos and the implementation
code are available at https://github.com/DominikUrbaniak/obst-avoid-dmp-pi2.

</details>


### [68] [Placeit! A Framework for Learning Robot Object Placement Skills](https://arxiv.org/abs/2510.09267)
*Amina Ferrad,Johann Huber,François Hélénon,Julien Gleyze,Mahdi Khoramshahi,Stéphane Doncieux*

Main category: cs.RO

TL;DR: Placeit!是一个基于进化计算的框架，用于自动生成刚性物体的有效放置位置，支持桌面放置、堆叠和插入等多种任务，在真实世界部署中达到90%的成功率。


<details>
  <summary>Details</summary>
Motivation: 机器人学习面临大规模高质量数据获取的瓶颈，需要自动化的数据生成方法来支持基本技能（如物体放置）的掌握。

Method: 采用进化计算和多样性优化方法，开发Placeit!框架自动生成有效的物体放置姿势，支持多种放置场景。

Result: Placeit!在所有测试场景中显著优于现有方法，能够生成更多样化的有效姿势；基于该框架的抓取放置管道在120次真实世界部署中达到90%的成功率。

Conclusion: Placeit!是开放环境抓取放置任务的有力工具，也是训练基于仿真的机器人基础模型所需数据生成的重要引擎。

Abstract: Robotics research has made significant strides in learning, yet mastering
basic skills like object placement remains a fundamental challenge. A key
bottleneck is the acquisition of large-scale, high-quality data, which is often
a manual and laborious process. Inspired by Graspit!, a foundational work that
used simulation to automatically generate dexterous grasp poses, we introduce
Placeit!, an evolutionary-computation framework for generating valid placement
positions for rigid objects. Placeit! is highly versatile, supporting tasks
from placing objects on tables to stacking and inserting them. Our experiments
show that by leveraging quality-diversity optimization, Placeit! significantly
outperforms state-of-the-art methods across all scenarios for generating
diverse valid poses. A pick&place pipeline built on our framework achieved a
90% success rate over 120 real-world deployments. This work positions Placeit!
as a powerful tool for open-environment pick-and-place tasks and as a valuable
engine for generating the data needed to train simulation-based foundation
models in robotics.

</details>


### [69] [Bridging Research and Practice in Simulation-based Testing of Industrial Robot Navigation Systems](https://arxiv.org/abs/2510.09396)
*Sajad Khatiri,Francisco Eli Vina Barrientos,Maximilian Wulf,Paolo Tonella,Sebastiano Panichella*

Main category: cs.RO

TL;DR: 将Surrealist仿真测试框架从无人机扩展到ANYmal四足机器人工业检测应用，通过搜索算法自动生成障碍规避场景，在工业评估中验证了五个专有算法并提升了开发流程。


<details>
  <summary>Details</summary>
Motivation: 传统测试方法难以覆盖动态环境中机器人导航的全部操作要求，需要自动化的测试生成框架来发现手动测试遗漏的故障。

Method: 使用基于搜索的算法自动生成具有挑战性的障碍规避场景，并将框架集成到ANYbotics工作流程中进行六个月的工业评估。

Result: 在试点阶段，生成的测试套件揭示了一个实验算法的关键弱点（成功率40.3%），并证明了另一个算法的优越鲁棒性（成功率71.2%）。正式调查确认该框架增强了开发过程，发现了关键故障，提供了客观基准。

Conclusion: Surrealist框架成功应用于工业四足机器人测试，有效提升了算法验证流程，能够发现手动测试遗漏的故障并为算法性能提供客观基准。

Abstract: Ensuring robust robotic navigation in dynamic environments is a key
challenge, as traditional testing methods often struggle to cover the full
spectrum of operational requirements. This paper presents the industrial
adoption of Surrealist, a simulation-based test generation framework originally
for UAVs, now applied to the ANYmal quadrupedal robot for industrial
inspection. Our method uses a search-based algorithm to automatically generate
challenging obstacle avoidance scenarios, uncovering failures often missed by
manual testing. In a pilot phase, generated test suites revealed critical
weaknesses in one experimental algorithm (40.3% success rate) and served as an
effective benchmark to prove the superior robustness of another (71.2% success
rate). The framework was then integrated into the ANYbotics workflow for a
six-month industrial evaluation, where it was used to test five proprietary
algorithms. A formal survey confirmed its value, showing it enhances the
development process, uncovers critical failures, provides objective benchmarks,
and strengthens the overall verification pipeline.

</details>


### [70] [Failure Prediction at Runtime for Generative Robot Policies](https://arxiv.org/abs/2510.09459)
*Ralf Römer,Adrian Kobras,Luca Worbis,Angela P. Schoellig*

Main category: cs.RO

TL;DR: FIPER是一个无需失败数据的运行时故障预测框架，通过检测分布外观察和动作不确定性来预测生成式模仿学习策略的故障。


<details>
  <summary>Details</summary>
Motivation: 生成式模仿学习在复杂任务中表现良好，但分布偏移和动作误差累积会导致不可预测的不安全行为，需要运行时故障预测来确保机器人部署安全。

Method: 使用随机网络蒸馏检测分布外观察，提出新的动作块熵分数衡量动作不确定性，通过保形预测校准故障预测分数，并在短时间窗口内聚合两个指标来触发故障警报。

Result: 在五个仿真和真实环境中的评估表明，FIPER能更好地区分实际故障与良性分布外情况，比现有方法更准确、更早地预测故障。

Conclusion: FIPER是向更可解释、更安全的生成式机器人策略迈出的重要一步，为机器人安全部署提供了有效的故障预测解决方案。

Abstract: Imitation learning (IL) with generative models, such as diffusion and flow
matching, has enabled robots to perform complex, long-horizon tasks. However,
distribution shifts from unseen environments or compounding action errors can
still cause unpredictable and unsafe behavior, leading to task failure. Early
failure prediction during runtime is therefore essential for deploying robots
in human-centered and safety-critical environments. We propose FIPER, a general
framework for Failure Prediction at Runtime for generative IL policies that
does not require failure data. FIPER identifies two key indicators of impending
failure: (i) out-of-distribution (OOD) observations detected via random network
distillation in the policy's embedding space, and (ii) high uncertainty in
generated actions measured by a novel action-chunk entropy score. Both failure
prediction scores are calibrated using a small set of successful rollouts via
conformal prediction. A failure alarm is triggered when both indicators,
aggregated over short time windows, exceed their thresholds. We evaluate FIPER
across five simulation and real-world environments involving diverse failure
modes. Our results demonstrate that FIPER better distinguishes actual failures
from benign OOD situations and predicts failures more accurately and earlier
than existing methods. We thus consider this work an important step towards
more interpretable and safer generative robot policies. Code, data and videos
are available at https://tum-lsy.github.io/fiper_website.

</details>


### [71] [FOGMACHINE -- Leveraging Discrete-Event Simulation and Scene Graphs for Modeling Hierarchical, Interconnected Environments under Partial Observations from Mobile Agents](https://arxiv.org/abs/2510.09483)
*Lars Ohnemus,Nils Hantke,Max Weißer,Kai Furmans*

Main category: cs.RO

TL;DR: FOGMACHINE是一个开源框架，将动态场景图与离散事件模拟相结合，用于在不确定环境中建模对象动态、智能体观察和交互。


<details>
  <summary>Details</summary>
Motivation: 当前动态场景图方法难以捕捉随机动态、部分可观测性和多智能体活动，而这些对于具身AI在不确定性和延迟感知下行动至关重要。

Method: 融合动态场景图与离散事件模拟，建模对象动态、智能体观察和大规模交互。

Result: 在城市场景实验中展示了真实的时间和空间模式，同时揭示了在稀疏观察下信念估计的挑战。

Conclusion: 通过结合结构化表示和高效模拟，FOGMACHINE为复杂不确定环境中的基准测试、模型训练和具身AI发展建立了有效工具。

Abstract: Dynamic Scene Graphs (DSGs) provide a structured representation of
hierarchical, interconnected environments, but current approaches struggle to
capture stochastic dynamics, partial observability, and multi-agent activity.
These aspects are critical for embodied AI, where agents must act under
uncertainty and delayed perception. We introduce FOGMACHINE , an open-source
framework that fuses DSGs with discrete-event simulation to model object
dynamics, agent observations, and interactions at scale. This setup enables the
study of uncertainty propagation, planning under limited perception, and
emergent multi-agent behavior. Experiments in urban scenarios illustrate
realistic temporal and spatial patterns while revealing the challenges of
belief estimation under sparse observations. By combining structured
representations with efficient simulation, FOGMACHINE establishes an effective
tool for benchmarking, model training, and advancing embodied AI in complex,
uncertain environments.

</details>


### [72] [Autonomous Soft Robotic Guidewire Navigation via Imitation Learning](https://arxiv.org/abs/2510.09497)
*Noah Barnes,Ji Woong Kim,Lingyun Di,Hannah Qu,Anuruddha Bhattacharjee,Miroslaw Janowski,Dheeraj Gandhi,Bailey Felix,Shaopeng Jiang,Olivia Young,Mark Fuge,Ryan D. Sochol,Jeremy D. Brown,Axel Krieger*

Main category: cs.RO

TL;DR: 提出基于Transformer的模仿学习框架，用于软体机器人导丝在血管内导航，在动脉瘤定位任务中达到83%的成功率


<details>
  <summary>Details</summary>
Motivation: 解决软体机器人导丝在血管内导航中的建模和控制挑战，提高血管内导航的精确性和安全性

Method: 开发基于Transformer的模仿学习框架，包含目标条件、相对动作输出和自动对比剂注射，在36种不同分叉几何结构上训练模型

Result: 在未见过的血管几何结构上，模型能够自主将机器人尖端导航至动脉瘤位置，成功率达83%，优于多个基线方法

Conclusion: 该框架能够实现可泛化的软体机器人导丝导航，为血管内手术自动化提供了有前景的解决方案

Abstract: In endovascular surgery, endovascular interventionists push a thin tube
called a catheter, guided by a thin wire to a treatment site inside the
patient's blood vessels to treat various conditions such as blood clots,
aneurysms, and malformations. Guidewires with robotic tips can enhance
maneuverability, but they present challenges in modeling and control.
Automation of soft robotic guidewire navigation has the potential to overcome
these challenges, increasing the precision and safety of endovascular
navigation. In other surgical domains, end-to-end imitation learning has shown
promising results. Thus, we develop a transformer-based imitation learning
framework with goal conditioning, relative action outputs, and automatic
contrast dye injections to enable generalizable soft robotic guidewire
navigation in an aneurysm targeting task. We train the model on 36 different
modular bifurcated geometries, generating 647 total demonstrations under
simulated fluoroscopy, and evaluate it on three previously unseen vascular
geometries. The model can autonomously drive the tip of the robot to the
aneurysm location with a success rate of 83% on the unseen geometries,
outperforming several baselines. In addition, we present ablation and baseline
studies to evaluate the effectiveness of each design and data collection
choice. Project website: https://softrobotnavigation.github.io/

</details>


### [73] [Dynamic Quadrupedal Legged and Aerial Locomotion via Structure Repurposing](https://arxiv.org/abs/2510.09526)
*Chenghao Wang,Kaushik Venkatesh Krishnamurthy,Shreyansh Pitroda,Adarsh Salagame,Ioannis Mandralis,Eric Sihite,Alireza Ramezani,Morteza Gharib*

Main category: cs.RO

TL;DR: 本文介绍了Husky v.2多模态机器人的硬件设计，该机器人通过结构重用途径实现了动态四足行走和飞行两种运动模式。


<details>
  <summary>Details</summary>
Motivation: 解决多模态地面-空中机器人在不同操作模式下的冲突需求整合难题。

Method: 采用结构重用途径，将腿部结构重新用于动态四足行走和飞行，结合姿态操纵和推力矢量控制。

Result: 成功实现了动态四足行走和悬停飞行的主要结果。

Conclusion: Husky v.2机器人通过结构重用途径有效解决了多模态运动中的冲突需求，为多模态机器人设计提供了可行方案。

Abstract: Multi-modal ground-aerial robots have been extensively studied, with a
significant challenge lying in the integration of conflicting requirements
across different modes of operation. The Husky robot family, developed at
Northeastern University, and specifically the Husky v.2 discussed in this
study, addresses this challenge by incorporating posture manipulation and
thrust vectoring into multi-modal locomotion through structure repurposing.
This quadrupedal robot features leg structures that can be repurposed for
dynamic legged locomotion and flight. In this paper, we present the hardware
design of the robot and report primary results on dynamic quadrupedal legged
locomotion and hovering.

</details>


### [74] [Guiding Energy-Efficient Locomotion through Impact Mitigation Rewards](https://arxiv.org/abs/2510.09543)
*Chenghao Wang,Arjun Viswanathan,Eric Sihite,Alireza Ramezani*

Main category: cs.RO

TL;DR: 该论文提出了一种结合冲击缓解因子(IMF)与对抗运动先验(AMP)的方法，使强化学习策略能够同时学习动物的显性运动轨迹和隐性被动动力学，实现了高达32%的能源效率提升。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法主要捕捉动物的显性步态模式，但忽略了隐性被动动力学，而动物正是通过这种被动动力学实现节能运动。

Method: 通过引入基于物理的冲击缓解因子(IMF)作为奖励项，并将其与对抗运动先验(AMP)结合，使强化学习策略能够学习动物的显性运动轨迹和隐性被动动态。

Result: 在AMP和手工奖励结构上都实现了高达32%的能源效率提升，通过运输成本(CoT)衡量。

Conclusion: 该方法成功地将被动动态学习整合到模仿学习中，显著提高了机器人的能源效率，为更自然的机器人运动提供了新途径。

Abstract: Animals achieve energy-efficient locomotion by their implicit passive
dynamics, a marvel that has captivated roboticists for decades.Recently,
methods incorporated Adversarial Motion Prior (AMP) and Reinforcement learning
(RL) shows promising progress to replicate Animals' naturalistic motion.
However, such imitation learning approaches predominantly capture explicit
kinematic patterns, so-called gaits, while overlooking the implicit passive
dynamics. This work bridges this gap by incorporating a reward term guided by
Impact Mitigation Factor (IMF), a physics-informed metric that quantifies a
robot's ability to passively mitigate impacts. By integrating IMF with AMP, our
approach enables RL policies to learn both explicit motion trajectories from
animal reference motion and the implicit passive dynamic. We demonstrate energy
efficiency improvements of up to 32%, as measured by the Cost of Transport
(CoT), across both AMP and handcrafted reward structure.

</details>


### [75] [Zero-shot Structure Learning and Planning for Autonomous Robot Navigation using Active Inference](https://arxiv.org/abs/2510.09574)
*Daria de tinguy,Tim Verbelen,Emilio Gamba,Bart Dhoedt*

Main category: cs.RO

TL;DR: 提出了一种基于主动推理的生物启发导航框架AIMAPP，将建图、定位和决策统一在单一生成模型中，支持无预训练的自监督导航。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在陌生环境中同时进行探索、定位和规划的问题，无需依赖预定义地图或大量训练，实现生物启发的自主导航。

Method: 使用主动推理框架，结合拓扑推理、位置细胞编码和情景记忆，在线构建稀疏拓扑地图，动态学习状态转移，通过最小化期望自由能来规划动作。

Result: 开发了ROS兼容的导航系统，在大型真实和模拟环境中表现出鲁棒性能，能够适应模糊观测、环境变化和传感器噪声。

Conclusion: AIMAPP提供了一个生物启发的模块化解决方案，可在非结构化环境中实现可扩展的自监督导航。

Abstract: Autonomous navigation in unfamiliar environments requires robots to
simultaneously explore, localise, and plan under uncertainty, without relying
on predefined maps or extensive training. We present a biologically inspired,
Active Inference-based framework, Active Inference MAPping and Planning
(AIMAPP). This model unifies mapping, localisation, and decision-making within
a single generative model. Inspired by hippocampal navigation, it uses
topological reasoning, place-cell encoding, and episodic memory to guide
behaviour. The agent builds and updates a sparse topological map online, learns
state transitions dynamically, and plans actions by minimising Expected Free
Energy. This allows it to balance goal-directed and exploratory behaviours. We
implemented a ROS-compatible navigation system that is sensor and
robot-agnostic, capable of integrating with diverse hardware configurations. It
operates in a fully self-supervised manner, is resilient to drift, and supports
both exploration and goal-directed navigation without any pre-training. We
demonstrate robust performance in large-scale real and simulated environments
against state-of-the-art planning models, highlighting the system's
adaptability to ambiguous observations, environmental changes, and sensor
noise. The model offers a biologically inspired, modular solution to scalable,
self-supervised navigation in unstructured settings. AIMAPP is available at
https://github.com/decide-ugent/AIMAPP.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [76] [Assurance of Frontier AI Built for National Security](https://arxiv.org/abs/2510.08792)
*Matteo Pistillo,Charlotte Stix*

Main category: cs.CY

TL;DR: 该备忘录提出四项建议，旨在加强AI模型可靠性和可治理性原则，重点关注错位问题及其对AI模型行为的影响。


<details>
  <summary>Details</summary>
Motivation: 解决错位问题对国家安全构成的威胁，错位和策划能力可能是AI模型可靠性和可治理性不足的警示信号。

Method: 建议国防部和情报界战略性地利用现有测试评估流程及其运营测试权限，通过一套策划和控制评估来确保AI模型的可靠性原则。

Result: 提出了四项具体建议来加强AI模型可靠性和可治理性框架。

Conclusion: 需要通过专门的评估机制来应对AI模型错位问题，确保AI系统的可靠性和可治理性，从而防范国家安全风险。

Abstract: This memorandum presents four recommendations aimed at strengthening the
principles of AI model reliability and AI model governability, as DoW, ODNI,
NIST, and CAISI refine AI assurance frameworks under the AI Action Plan. Our
focus concerns the open scientific problem of misalignment and its implications
on AI model behavior. Specifically, misalignment and scheming capabilities can
be a red flag indicating AI model insufficient reliability and governability.
To address the national security threats arising from misalignment, we
recommend that DoW and the IC strategically leverage existing testing and
evaluation pipelines and their OT authority to future proof the principles of
AI model reliability and AI model governability through a suite of scheming and
control evaluations.

</details>


### [77] [Rethinking How We Discuss the Guidance of Student Researchers in Computing](https://arxiv.org/abs/2510.08885)
*Shomir Wilson*

Main category: cs.CY

TL;DR: 本文提出了一个多面体框架来分析计算科学领域教师对学生的研究指导，将传统的单一"指导"或"导师"概念分解为多个具体角色，以更全面地理解教师责任。


<details>
  <summary>Details</summary>
Motivation: 传统上使用"指导"或"导师"等单一术语来描述教师对学生的研究指导关系，但这些术语掩盖了指导关系的复杂性，无法充分体现教师的多重责任。

Method: 采用多面体框架方法，创建教师角色的详细清单，将研究指导分解为多个相关但不同的角色，扩展和澄清指导语言。

Result: 该框架揭示了教师对学生研究者的全部责任范围，便于讨论责任间的冲突，并为学生提供了更灵活的支持网络。

Conclusion: 过度依赖单一术语会掩盖教师责任的完整范围并阻碍技能改进，多面体框架可为教师、机构和学生提供实用价值。

Abstract: Computing faculty at research universities are often expected to guide the
work of undergraduate and graduate student researchers. This guidance is
typically called advising or mentoring, but these terms belie the complexity of
the relationship, which includes several related but distinct roles. I examine
the guidance of student researchers in computing (abbreviated to research
guidance or guidance throughout) within a facet framework, creating an
inventory of roles that faculty members can hold. By expanding and
disambiguating the language of guidance, this approach reveals the full breadth
of faculty responsibilities toward student researchers, and it facilitates
discussing conflicts between those responsibilities. Additionally, the facet
framework permits greater flexibility for students seeking guidance, allowing
them a robust support network without implying inadequacy in an individual
faculty member's skills. I further argue that an over-reliance on singular
terms like advising or mentoring for the guidance of student researchers
obscures the full scope of faculty responsibilities and interferes with
improvement of those as skills. Finally, I provide suggestions for how the
facet framework can be utilized by faculty and institutions, and how parts of
it can be discussed with students for their benefit.

</details>


### [78] [Online Advertising is a Regrettable Necessity: On the Dangers of Pay-Walling the Web](https://arxiv.org/abs/2409.00026)
*Yonas Kassa*

Main category: cs.CY

TL;DR: 论文分析了付费墙对互联网开放模式的威胁，指出完全付费墙化的网络将导致全球135个国家、65.6亿人口无法负担，加剧数字鸿沟，并可能破坏在线广告生态系统。


<details>
  <summary>Details</summary>
Motivation: 研究付费墙趋势对互联网开放模式的威胁，特别是对经济弱势群体的影响，以及这种趋势对在线广告生态系统的潜在破坏。

Method: 使用人均国民总收入(GNI)数据和平均付费墙访问成本，建立收入-付费墙支出差距基线，分析全球范围内付费墙的可负担性。

Result: 研究发现135个国家、65.6亿人口无法负担完全付费墙化的网络场景，付费墙模式会加剧数字隔离并威胁在线广告生态系统。

Conclusion: 呼吁进一步研究和政策倡议，以维持互联网的开放性和包容性，建立可持续的商业模式。

Abstract: The exponential growth of the web and its benefits can be attributed largely
to its open model where anyone with internet connection can access information
on the web for free. This has created unprecedented opportunities for various
members of society including the most vulnerable, as recognized by
organizations such as the UN. This again can be attributed to online
advertising, which has been the main financier to the open web. However, recent
trends of paywalling information and services on the web are creating imminent
dangers to such open model of the web, inhibiting access for the economically
vulnerable, and eventually creating digital segregation. In this paper, we
argue that this emerging model lacks sustainability, exacerbates digital
divide, and might lead to collapse of online advertising. We revisit the
ad-supported open web business model and demonstrate how global users actually
pay for the ads they see. Using data on GNI (gross national income) per capita
and average paywall access costs, we established a simple income-paywall
expenditure gap baseline. With this baseline we show that 135 countries with a
total population estimate of 6.56 billion people cannot afford a scenario of a
fully paywalled web. We further discuss how a mixed model of the so-called
"premium services" creates digital segregation and poses danger to online
advertising ecosystem. Finally, we call for further research and policy
initiatives to keep the web open and more inclusive with a sustainable business
model.

</details>


### [79] [GBA-UBF : A Large-Scale and Fine-Grained Building Function Classification Dataset in the Greater Bay Area](https://arxiv.org/abs/2510.08921)
*Chunsong Chen,Yichen Hou,Huan Chen,Junlin Li,Rong Fu,Qiushen Lai,Yiping Chen,Ting Han*

Main category: cs.CY

TL;DR: 提出了粤港澳大湾区城市建筑功能数据集(GBA-UBF)，通过多级建筑功能优化方法为近400万栋建筑分配5种功能类别，显著提升了建筑级功能分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 粤港澳大湾区的快速城市化对高分辨率、建筑级功能数据提出了迫切需求，现有土地利用数据集存在粒度粗糙和难以捕捉街区内部异质性的问题。

Method: 提出了多级建筑功能优化方法(ML-BFO)，通过三阶段流程整合POI记录和建筑足迹：候选标签生成、基于邻域标签自相关的迭代优化、以及基于高级POI缓冲区的功能相关校正。

Result: GBA-UBF数据集达到0.58的BFMI值，显著优于基线数据集，与城市活动模式具有更好的对齐性，实地验证确认了数据集的语义可靠性和实用可解释性。

Conclusion: GBA-UBF数据集为建筑级功能分类建立了可复现的框架，弥合了粗糙土地利用地图与精细化城市分析之间的差距。

Abstract: Rapid urbanization in the Guangdong-Hong Kong-Macao Greater Bay Area (GBA)
has created urgent demand for high-resolution, building-level functional data
to support sustainable spatial planning. Existing land use datasets suffer from
coarse granularity and difficulty in capturing intra-block heterogeneity. To
this end, we present the Greater Bay Area Urban Building Function Dataset
(GBA-UBF), a large-scale, fine-grained dataset that assigns one of five
functional categories to nearly four million buildings across six core GBA
cities. We proposed a Multi-level Building Function Optimization (ML-BFO)
method by integrating Points of Interest (POI) records and building footprints
through a three-stage pipeline: (1) candidate label generation using spatial
overlay with proximity weighting, (2) iterative refinement based on
neighborhood label autocorrelation, and (3) function-related correction
informed by High-level POI buffers. To quantitatively validate results, we
design the Building Function Matching Index (BFMI), which jointly measures
categorical consistency and distributional similarity against POI-derived
probability heatmaps. Comparative experiments demonstrate that GBA-UBF achieves
significantly higher accuracy, with a BMFI of 0.58. This value markedly exceeds
that of the baseline dataset and exhibits superior alignment with urban
activity patterns. Field validation further confirms the dataset's semantic
reliability and practical interpretability. The GBA-UBF dataset establishes a
reproducible framework for building-level functional classification, bridging
the gap between coarse land use maps and fine-grained urban analytics. The
dataset is accessible at https://github.com/chenchs0629/GBA-UBF, and the data
will undergo continuous improvement and updates based on feedback from the
community.

</details>


### [80] [AI and Human Oversight: A Risk-Based Framework for Alignment](https://arxiv.org/abs/2510.09090)
*Laxmiraju Kandikatla,Branislav Radeljic*

Main category: cs.CY

TL;DR: 本文探讨了AI系统中保护人类自主权和促进伦理决策的策略，提出了基于风险的人类监督框架，将AI模型风险水平与适当的人类监督形式联系起来。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的进步，保护人类自主权和促进伦理决策对于建立信任和问责制至关重要。需要设计能够维护基本权利、增强人类能动性并嵌入有效人类监督机制的AI系统。

Method: 讨论了关键监督模型（HIC、HITL、HOTL），提出了基于风险的框架来指导这些机制的实施，将AI模型风险水平与适当的人类监督形式联系起来。

Result: 通过将AI模型风险水平与适当的人类监督形式相连接，强调了人类参与在负责任部署AI中的关键作用，平衡技术创新与个人价值观和权利保护。

Conclusion: 该框架旨在确保AI技术被负责任地使用，在保护个人自主权的同时最大化社会效益，实现技术创新与人类价值观的平衡。

Abstract: As Artificial Intelligence (AI) technologies continue to advance, protecting
human autonomy and promoting ethical decision-making are essential to fostering
trust and accountability. Human agency (the capacity of individuals to make
informed decisions) should be actively preserved and reinforced by AI systems.
This paper examines strategies for designing AI systems that uphold fundamental
rights, strengthen human agency, and embed effective human oversight
mechanisms. It discusses key oversight models, including Human-in-Command
(HIC), Human-in-the-Loop (HITL), and Human-on-the-Loop (HOTL), and proposes a
risk-based framework to guide the implementation of these mechanisms. By
linking the level of AI model risk to the appropriate form of human oversight,
the paper underscores the critical role of human involvement in the responsible
deployment of AI, balancing technological innovation with the protection of
individual values and rights. In doing so, it aims to ensure that AI
technologies are used responsibly, safeguarding individual autonomy while
maximizing societal benefits.

</details>


### [81] [Non-traditional data in pandemic preparedness and response: identifying and addressing first and last-mile challenges](https://arxiv.org/abs/2510.09145)
*Mattia Mazzoli,Irma Varela-Lasheras,Sonia Namorado,Constantino Pereira Caetano,Andreia Leite,Lisa Hermans,Niel Hens,Polen Türkmen,Kyriaki Kalimeri,Leo Ferres,Ciro Cattuto,Daniela Paolotti,Stefaan Verhulst*

Main category: cs.CY

TL;DR: 本文评估了在疫情期间使用非传统数据（如移动轨迹、社交媒体活动和可穿戴设备数据）补充传统公共卫生数据的潜力和局限性，提出了解决"第一英里"（数据获取和协调）和"最后一英里"（将洞察转化为行动）挑战的建议。


<details>
  <summary>Details</summary>
Motivation: 新冠疫情是测试非传统数据在公共卫生决策中价值的重要案例，需要评估此类数据在疫情准备和响应中的实际应用效果和持续存在的障碍。

Method: 通过2024年专家研讨会和针对欧洲建模师的定向调查，收集了关于非传统数据使用障碍和潜力的实证证据。

Result: 研究发现66%的数据集存在访问问题，非传统数据共享不情愿程度是传统数据的两倍（30% vs 15%），只有10%的受访者能够使用所有需要的数据。数据访问、质量和互操作性仍然是主要挑战。

Conclusion: 实现非传统数据的全部价值需要在机构准备度、跨部门协作和数据团结文化方面进行持续投资，建议建立融合中心、决策加速实验室和科学大使网络来弥合分析与行动之间的差距。

Abstract: The pandemic served as an important test case of complementing traditional
public health data with non-traditional data (NTD) such as mobility traces,
social media activity, and wearables data to inform decision-making. Drawing on
an expert workshop and a targeted survey of European modelers, we assess the
promise and persistent limitations of such data in pandemic preparedness and
response. We distinguish between "first-mile" (accessing and harmonizing data)
and "last-mile" challenges (translating insights into actionable
interventions). The expert workshop held in 2024 brought together participants
from public health, academia, policymakers, and industry to reflect on lessons
learned and define strategies for translating NTD insights into policy making.
The survey offers evidence of the barriers faced during COVID-19 and highlights
key data unavailability and underuse. Our findings reveal ongoing issues with
data access, quality, and interoperability, as well as institutional and
cognitive barriers to evidence-based decision-making. Around 66% of datasets
suffered access problem, with data sharing reluctance for NTD being double that
of traditional data (30% vs 15%). Only 10% reported they could use all the data
they needed. We propose a set of recommendations: for first-mile challenges,
solutions focus on technical and legal frameworks for data access.; for
last-mile challenges, we recommend fusion centers, decision accelerator labs,
and networks of scientific ambassadors to bridge the gap between analysis and
action. Realizing the full value of NTD requires a sustained investment in
institutional readiness, cross-sectoral collaboration, and a shift toward a
culture of data solidarity. Grounded in the lessons of COVID-19, the article
can be used to design a roadmap for using NTD to confront a broader array of
public health emergencies, from climate shocks to humanitarian crises.

</details>


### [82] [Federated Data Analytics for Cancer Immunotherapy: A Privacy-Preserving Collaborative Platform for Patient Management](https://arxiv.org/abs/2510.09155)
*Mira Raheem,Michael Papazoglou,Bernd Krämer,Neamat El-Tazi,Amal Elgammal*

Main category: cs.CY

TL;DR: 本文提出了一个协作式数字框架，通过联邦大数据分析和人工智能整合医疗保健数据源，为接受免疫治疗的癌症患者提供个性化护理和预测，在试点研究中达到70%-90%的准确率。


<details>
  <summary>Details</summary>
Motivation: 连接健康模式需要整合各种医疗数据源来个性化护理、预测健康结果和简化患者管理，但面临数据架构、应用互操作性和安全性的挑战。

Method: 采用敏捷系统开发生命周期，开发集成AI生成的解决方案，利用联邦大数据分析和人工智能技术，确保隐私的同时改善决策。

Result: 在试点研究中，治疗建议和不良事件预测等分析能力使用真实数据验证，达到70%-90%的准确率，证明了框架的有效性。

Conclusion: 该协作数字框架成功整合了护理连续体中的利益相关者，通过联邦分析和AI技术实现了改进的决策制定，同时确保了隐私保护。

Abstract: Connected health is a multidisciplinary approach focused on health
management, prioritizing pa-tient needs in the creation of tools, services, and
treatments. This paradigm ensures proactive and efficient care by facilitating
the timely exchange of accurate patient information among all stake-holders in
the care continuum. The rise of digital technologies and process innovations
promises to enhance connected health by integrating various healthcare data
sources. This integration aims to personalize care, predict health outcomes,
and streamline patient management, though challeng-es remain, particularly in
data architecture, application interoperability, and security. Data analytics
can provide critical insights for informed decision-making and health
co-creation, but solutions must prioritize end-users, including patients and
healthcare professionals. This perspective was explored through an agile System
Development Lifecycle in an EU-funded project aimed at developing an integrated
AI-generated solution for managing cancer patients undergoing immunotherapy.
This paper contributes with a collaborative digital framework integrating
stakeholders across the care continuum, leveraging federated big data analytics
and artificial intelligence for improved decision-making while ensuring
privacy. Analytical capabilities, such as treatment recommendations and adverse
event predictions, were validated using real-life data, achieving 70%-90%
accuracy in a pilot study with the medical partners, demonstrating the
framework's effectiveness.

</details>


### [83] [Student Development Agent: Risk-free Simulation for Evaluating AIED Innovations](https://arxiv.org/abs/2510.09183)
*Jianxiao Jiang,Yu Zhang*

Main category: cs.CY

TL;DR: 提出基于大语言模型的学生发展代理框架，用于模拟不同教育环境下学生的非认知发展，避免对真实学生进行实验。


<details>
  <summary>Details</summary>
Motivation: 在AI教育创新时代，需要在向学生暴露新设计前评估其发展影响，因为这类干预可能产生不可逆的后果。

Method: 基于大语言模型构建学生发展代理框架，通过多智能体学习环境案例验证方法有效性。

Result: 代理预测结果与真实学生非认知发展结果一致，表明基于LLM的模拟有望高效且符合伦理地评估AI教育创新。

Conclusion: LLM模拟在教育创新评估中具有潜力，未来需改进档案结构、整合特定任务模型、验证实证发现效果、解释模拟数据并优化评估方法。

Abstract: In the age of AI-powered educational (AIED) innovation, evaluating the
developmental consequences of novel designs before they are exposed to students
has become both essential and challenging. Since such interventions may carry
irreversible effects, it is critical to anticipate not only potential benefits
but also possible harms. This study proposes a student development agent
framework based on large language models (LLMs), designed to simulate how
students with diverse characteristics may evolve under different educational
settings without administering them to real students. By validating the
approach through a case study on a multi-agent learning environment (MAIC), we
demonstrate that the agent's predictions align with real student outcomes in
non-cognitive developments. The results suggest that LLM-based simulations hold
promise for evaluating AIED innovations efficiently and ethically. Future
directions include enhancing profile structures, incorporating fine-tuned or
small task-specific models, validating effects of empirical findings,
interpreting simulated data and optimizing evaluation methods.

</details>


### [84] [Exploring User Risk Factors and Target Groups for Phishing Victimization in Pakistan](https://arxiv.org/abs/2510.09249)
*Javara A. Bukhsh,Maya Daneva,Marten van Sinderen*

Main category: cs.CY

TL;DR: 该研究调查了巴基斯坦人群的网络钓鱼易感性，发现男性、25岁以上人群、在职人员和频繁网购者更容易受骗，邮件特征如权威性和紧急性会增加易感性，而来自Gmail和LinkedIn等通信服务的邮件最危险。


<details>
  <summary>Details</summary>
Motivation: 网络钓鱼攻击是全球性的重大网络安全威胁，需要了解特定人群的易感性特征以制定针对性防护措施。

Method: 通过便利抽样收集数据，共有164人完成了问卷调查，分析人口统计因素、技术能力、使用习惯、过往受害经历和邮件特征对网络钓鱼易感性的影响。

Result: 研究发现男性、25岁以上、在职人员、频繁网购者易感性较高；权威和紧急特征的邮件增加受害风险；来自Gmail和LinkedIn的邮件比政府或社交媒体邮件更危险。

Conclusion: 需要针对特定人群和邮件类型制定安全意识干预措施，结合技术和教育的多层面方法对防范网络钓鱼攻击至关重要。

Abstract: Phishing attacks pose a significant cybersecurity threat globally. This study
investigates phishing susceptibility within the Pakistani population, examining
the influence of demographic factors, technological aptitude and usage,
previous phishing victimization, and email characteristics. Data was collected
through convenient sampling; a total of 164 people completed the questionnaire.
Contrary to some assumptions, the results indicate that men, individuals over
25, employed persons and frequent online shoppers have relatively high phishing
susceptibility. The characteristics of email significantly affected phishing
victimization, with authority and urgency signaling increasing susceptibility,
while risk cues sometimes improved vigilance. In particular, users were more
susceptible to emails from communication services such as Gmail and LinkedIn
compared to government or social media sources. These findings highlight the
need for targeted security awareness interventions tailored to specific
demographics and email types. A multifaceted approach combining technology and
education is crucial to combat phishing attacks.

</details>


### [85] [Challenges in designing ethical rules for Infrastructures in Internet of Vehicles](https://arxiv.org/abs/2510.09374)
*Razi Iqbal*

Main category: cs.CY

TL;DR: 本文分析了车联网系统中路边单元(RSU)伦理规则设计的挑战，并提出了RSU的主要伦理原则，为未来车联网架构建模奠定基础。


<details>
  <summary>Details</summary>
Motivation: 随着车联网技术的发展，车辆和基础设施的互联网连接极大地扩展了车联网应用的潜力。然而，目前文献中缺乏对车联网系统中基础设施（路边单元）伦理规则设计挑战的关注。

Method: 通过分析车联网系统中V2V、V2P、V2S、V2I和I2I等通信模式的集成能力，识别RSU伦理规则设计的关键挑战。

Result: 识别了车联网系统中RSU伦理规则设计的主要挑战，并提出了相应的伦理原则。

Conclusion: 为车联网系统中的路边单元建立了伦理原则框架，为未来车联网架构的建模提供了基础。

Abstract: Vehicular Ad-hoc Networks (VANETs) have seen significant advancements in
technology. Innovation in connectivity and communication has brought
substantial capabilities to various components of VANETs such as vehicles,
infrastructures, passengers, drivers and affiliated environmental sensors.
Internet of Things (IoT) has brought the notion of Internet of Vehicles (IoV)
to VANETs where each component of VANET is connected directly or indirectly to
the Internet. Vehicles and infrastructures are key components of a VANET system
that can greatly augment the overall experience of the network by integrating
the competencies of Vehicle to Vehicle (V2V), Vehicle to Pedestrian (V2P),
Vehicle to Sensor (V2S), Vehicle to Infrastructure (V2I) and Infrastructure to
Infrastructure (I2I). Internet connectivity in Vehicles and Infrastructures has
immensely expanded the potential of developing applications for VANETs under
the broad spectrum of IoV. Advent in the use of technology in VANETs requires
considerable efforts in scheming the ethical rules for autonomous systems.
Currently, there is a gap in literature that focuses on the challenges involved
in designing ethical rules or policies for infrastructures, sometimes referred
to as Road Side Units (RSUs) for IoVs. This paper highlights the key challenges
entailing the design of ethical rules for RSUs in IoV systems. Furthermore, the
article also proposes major ethical principles for RSUs in IoV systems that
would set foundation for modeling future IoV architectures.

</details>


### [86] [Demystifying and Navigating AI Ethics in Power Electronics](https://arxiv.org/abs/2510.09439)
*Fanfan Lin,Peter Wilson,Xinze Li,Alan Mantooth*

Main category: cs.CY

TL;DR: 本文强调在电力电子领域建立AI伦理框架的紧迫性，提出了安全与保障、可解释性与透明度、能源可持续性、工程师角色演变四大支柱，并呼吁IEEE电力电子学会牵头制定伦理标准。


<details>
  <summary>Details</summary>
Motivation: AI在电力电子领域的应用快速增长，但伦理维度关注有限。需要建立伦理框架来预防AI相关事故，并履行法律和监管责任。

Method: 识别并阐述AI伦理在电力电子领域的四大核心支柱：安全与保障、可解释性与透明度、能源可持续性、工程师角色演变，为每个支柱提供实用可行的见解。

Result: 提出了一个全面的AI伦理框架，确保伦理原则嵌入算法设计、系统部署和人才发展过程中，强调电力电子工程师应在伦理讨论中发挥领导作用。

Conclusion: 呼吁IEEE电力电子学会牵头建立伦理标准和最佳实践，确保AI创新不仅技术先进，而且可信、安全和可持续。

Abstract: Artificial intelligence (AI) is rapidly transforming power electronics, with
AI-related publications in IEEE Power Electronics Society selected journals
increasing more than fourfold from 2020 to 2025. However, the ethical
dimensions of this transformation have received limited attention. This article
underscores the urgent need for an ethical framework to guide responsible AI
integration in power electronics, not only to prevent AI-related incidents but
also to comply with legal and regulatory responsibilities. In this context,
this article identifies four core pillars of AI ethics in power electronics:
Security & Safety, Explainability & Transparency, Energy Sustainability, and
Evolving Roles of Engineers. Each pillar is supported by practical and
actionable insights to ensure that ethical principles are embedded in algorithm
design, system deployment, and workforce development. The authors advocate for
power electronics engineers to lead the ethical discourse, given their deep
technical understanding of both AI systems and power conversion technologies.
The paper concludes by calling on the IEEE Power Electronics Society to
spearhead the establishment of ethical standards and best practices that ensure
AI innovations are not only technically advanced but also trustworthy, safe,
and sustainable.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [87] [When to Reason: Semantic Router for vLLM](https://arxiv.org/abs/2510.08731)
*Chen Wang,Xunzhuo Liu,Yuhan Liu,Yue Zhu,Xiangxi Mo,Junchen Jiang,Huamin Chen*

Main category: cs.ET

TL;DR: 提出语义路由器，根据查询的推理需求选择性应用推理，在MMLU-Pro基准上实现10.2%准确率提升，同时降低47.1%延迟和48.5%令牌消耗


<details>
  <summary>Details</summary>
Motivation: 大语言模型在增强推理模式时虽然能显著提升准确率，但也会带来推理延迟和令牌使用量的显著增加，这对于许多简单提示来说是不必要的成本

Method: 开发语义路由器，通过分类查询的推理需求，仅在有益时选择性应用推理模式

Result: 在MMLU-Pro基准上准确率提升10.2个百分点，响应延迟降低47.1%，令牌消耗减少48.5%

Conclusion: 语义路由为开源LLM服务系统提供了在准确性和效率之间取得平衡的有效机制

Abstract: Large Language Models (LLMs) demonstrate substantial accuracy gains when
augmented with reasoning modes such as chain-of-thought and inference-time
scaling. However, reasoning also incurs significant costs in inference latency
and token usage, with environmental and financial impacts, which are
unnecessary for many simple prompts. We present a semantic router that
classifies queries based on their reasoning requirements and selectively
applies reasoning only when beneficial. Our approach achieves a 10.2 percentage
point improvement in accuracy on the MMLU-Pro benchmark while reducing response
latency by 47.1% and token consumption by 48.5% compared to direct inference
with vLLM. These results demonstrate that semantic routing offers an effective
mechanism for striking a balance between accuracy and efficiency in open-source
LLM serving systems

</details>


### [88] [Designing and Evaluating an AI-driven Immersive Multidisciplinary Simulation (AIMS) for Interprofessional Education](https://arxiv.org/abs/2510.08891)
*Ruijie Wang,Jie Lu,Bo Pei,Evonne Jones,Jamey Brinson,Timothy Brown*

Main category: cs.ET

TL;DR: 开发了AIMS虚拟模拟系统，整合大语言模型和Unity引擎，用于跨专业医疗教育，支持学生与虚拟患者进行多模态互动，提升临床推理和健康促进能力。


<details>
  <summary>Details</summary>
Motivation: 传统跨专业教育方法受限于成本、可扩展性和无法模拟真实临床场景的动态复杂性，需要更有效的解决方案。

Method: 设计AIMS系统，集成Gemini-2.5-Flash大语言模型、Unity虚拟环境和角色创建流程，支持用户与虚拟患者的同步多模态交互。

Result: 可用性测试显示AIMS支持真实、专业特定且情境适当的对话，识别出音频路由、响应延迟等技术问题并指导改进。

Conclusion: AIMS在技术和教学创新方面具有潜力，讨论了未来发展方向。

Abstract: Interprofessional education has long relied on case studies and the use of
standardized patients to support teamwork, communication, and related
collaborative competencies among healthcare professionals. However, traditional
approaches are often limited by cost, scalability, and inability to mimic the
dynamic complexity of real-world clinical scenarios. To address these
challenges, we designed and developed AIMS (AI-Enhanced Immersive
Multidisciplinary Simulations), a virtual simulation that integrates a large
language model (Gemini-2.5-Flash), a Unity-based virtual environment engine,
and a character creation pipeline to support synchronized, multimodal
interactions between the user and the virtual patient. AIMS was designed to
enhance collaborative clinical reasoning and health promotion competencies
among students from pharmacy, medicine, nursing, and social work. A formal
usability testing session was conducted which participants assumed professional
roles on a healthcare team and engaged in a mix of scripted and unscripted
conversations. Participants explored the patient's symptoms, social context,
and care needs. Usability issues were identified (e.g., audio routing, response
latency) and used to guide subsequent refinements. Findings in general suggest
that AIMS supports realistic, profession-specific and contextually appropriate
conversations. We discussed both technical and pedagogical innovations of AIMS
and concluded with future directions.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [89] [Titans Revisited: A Lightweight Reimplementation and Critical Analysis of a Test-Time Memory Model](https://arxiv.org/abs/2510.09551)
*Gavriel Di Nepi,Federico Siciliano,Fabrizio Silvestri*

Main category: cs.LG

TL;DR: 对Titans模型的轻量级重实现与评估，发现其神经记忆组件能持续提升性能，但整体表现不总是优于基线方法。


<details>
  <summary>Details</summary>
Motivation: Google提出的Titans模型缺乏公开代码和清晰描述，阻碍了可复现性，因此进行重实现和全面评估。

Method: 开发了Titans的轻量级重实现，并在掩码语言建模、时间序列预测和推荐任务上进行综合评估。

Result: Titans因分块处理并不总是优于基线方法，但其神经记忆组件相比仅使用注意力的模型能持续提升性能。

Conclusion: 确认了Titans模型的创新潜力，同时指出了实际局限性，为未来研究提出了问题。

Abstract: By the end of 2024, Google researchers introduced Titans: Learning at Test
Time, a neural memory model achieving strong empirical results across multiple
tasks. However, the lack of publicly available code and ambiguities in the
original description hinder reproducibility. In this work, we present a
lightweight reimplementation of Titans and conduct a comprehensive evaluation
on Masked Language Modeling, Time Series Forecasting, and Recommendation tasks.
Our results reveal that Titans does not always outperform established baselines
due to chunking. However, its Neural Memory component consistently improves
performance compared to attention-only models. These findings confirm the
model's innovative potential while highlighting its practical limitations and
raising questions for future research.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [90] [When Truth Does Not Take on Its Shoes: How Misinformation Spreads in Chatrooms](https://arxiv.org/abs/2510.08658)
*Shuige Liu*

Main category: econ.GN

TL;DR: 研究探讨了在长期线下关系构成的社交网络中，错误信息如何传播，特别是为什么即使大多数人认识到其虚假性，错误信息仍能持续传播。


<details>
  <summary>Details</summary>
Motivation: 解决现实世界中令人困惑的现象，如个人私下信念与公开传播内容之间的差距，以及为什么错误信息在明知其虚假的情况下仍能广泛传播。

Method: 采用心理博弈理论模型，区分个体接收信息后的反应决策（公开支持、保持沉默或公开质疑）和转发决策，并考虑个体信念与社会网络信念的一致性。

Result: 当个体对同伴压力高度敏感且网络结构极化时，即使多数人不真正相信错误信息，该信息仍能在没有公开抵制的情况下广泛传播。

Conclusion: 仅提高信息素养不足以遏制错误信息的传播，需要关注社会网络结构和同伴压力对信息传播的影响。

Abstract: We examine how misinformation spreads in social networks composed of
individuals with long-term offline relationships. Especially, we focus on why
misinformation persists and diffuses despite being recognized by most as false.
In our psychological game theoretical model, each agent who receives a piece of
(mis)information must first decide how to react -- by openly endorsing it,
remaining silent, or openly challenging it. After observing the reactions of
her neighbors who also received the message, the agent then chooses whether to
forward it to others in her own chatroom who have not yet received it. By
distinguishing these two roles, our framework addresses puzzling real-world
phenomena, such as the gap between what individuals privately believe and what
they publicly transmit. A key assumption in our model is that, while perceived
veracity influences decisions, the dominant factor is the alignment between an
agent's beliefs and those of her social network -- a feature characteristic of
communities formed through long-term offline relationships. This dynamic can
lead agents to tacitly accept and even propagate information they privately
judge to be of low credibility. Our results challenge the view that improving
information literacy alone can curb the spread of misinformation. We show that
when agents are highly sensitive to peer pressure and the network exhibits
structural polarization, even if the majority does not genuinely believe in it,
the message still can spread widely without encountering open resistance.

</details>


### [91] [Who gets hit first and who recovers last? Evidence from Indian Coastal Flood Shock](https://arxiv.org/abs/2510.08856)
*Jheelum Sarkar*

Main category: econ.GN

TL;DR: 该研究分析了印度百年一遇洪水对劳动力市场的影响，发现男性就业短期下降但很快恢复，而女性工作时间出现延迟但持久的减少，且性别差异受婚姻状况和家庭负担影响。


<details>
  <summary>Details</summary>
Motivation: 全球有18亿人面临洪水风险，主要集中在东亚和南亚，研究极端洪水如何重塑有偿劳动力结果对于理解灾害的社会经济影响至关重要。

Method: 结合Sentinel-1 SAR和JRC全球地表水数据集生成洪水地图，利用多轮周期性劳动力调查数据，估计洪水冲击对性别的动态效应。

Result: 男性就业短期减少但很快恢复，女性工作时间延迟但持久下降；男性在第二产业受影响最大并转向第一产业，女性在第三产业受影响最严重；婚姻状况和家庭负担进一步塑造性别差异效应。

Conclusion: 极端洪水对劳动力市场产生显著的性别差异化影响，基础设施和物质资本中断可能是造成部门差异的原因，政策应考虑这些差异化的脆弱性。

Abstract: Catastrophic floods directly risk 1.8 billion lives worldwide, most of whom
are from East and South Asia. How do extreme floods reshape paid labor
outcomes? To answer this, I focus on a 1-in-100 year flood event in India. I
first combine Sentinel-1 SAR with JRC Global Surface Water dataset to generate
flood map. Using information from this map in various rounds of periodic labor
force surveys, I estimate gender-specific dynamic effects of the flood shock.
Key results show that men experienced short-lived reduction in their employment
while women faced a delayed but persistent decline in their working hours. Men
suffered most in secondary sector and increased their participation in primary
sector. Women were hit hardest in the tertiary sector. Such sectoral impacts
could be attributable to disruptions in infrastructure and physical capital.
Moreover, marital status and dependency burden further shape the gender
differential effects of the extreme flood event. Results remain robust under
alternative treatment definitions.

</details>


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [92] [A Multimodal Approach to SME Credit Scoring Integrating Transaction and Ownership Networks](https://arxiv.org/abs/2510.09407)
*Sahab Zandi,Kamesh Korangi,Juan C. Moreno-Paredes,María Óskarsdóttir,Christophe Mues,Cristián Bravo*

Main category: q-fin.GN

TL;DR: 本文提出了一种使用图神经网络预测中小企业信贷违约的新方法，通过企业间的共同所有权和金融交易网络数据来改进信用风险评估。


<details>
  <summary>Details</summary>
Motivation: 中小企业在经济增长中发挥重要作用，但面临信贷获取困难，特别是在缺乏完整财务历史和抵押品的情况下。企业间网络中的违约风险传播使得准确评估信用风险变得至关重要。

Method: 使用图神经网络，结合企业间的多层网络数据（共同所有权和金融交易）与传统结构化数据，来预测中小企业违约风险。

Result: 研究表明，结合网络数据不仅提高了申请评分性能，还能明确模拟企业间的传染风险。连接的方向性和强度对金融风险传染有显著影响。

Conclusion: 网络数据具有强大的预测能力，供应链网络在暴露中小企业相关违约风险方面发挥重要作用，为理解风险传染机制提供了更深入的视角。

Abstract: Small and Medium-sized Enterprises (SMEs) are known to play a vital role in
economic growth, employment, and innovation. However, they tend to face
significant challenges in accessing credit due to limited financial histories,
collateral constraints, and exposure to macroeconomic shocks. These challenges
make an accurate credit risk assessment by lenders crucial, particularly since
SMEs frequently operate within interconnected firm networks through which
default risk can propagate. This paper presents and tests a novel approach for
modelling the risk of SME credit, using a unique large data set of SME loans
provided by a prominent financial institution. Specifically, our approach
employs Graph Neural Networks to predict SME default using multilayer network
data derived from common ownership and financial transactions between firms. We
show that combining this information with traditional structured data not only
improves application scoring performance, but also explicitly models contagion
risk between companies. Further analysis shows how the directionality and
intensity of these connections influence financial risk contagion, offering a
deeper understanding of the underlying processes. Our findings highlight the
predictive power of network data, as well as the role of supply chain networks
in exposing SMEs to correlated default risk.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [93] [Joint Detection, Channel Estimation and Interference Nulling for Terrestrial-Satellite Downlink Co-Existence in the Upper Mid-Band](https://arxiv.org/abs/2510.08824)
*Shizhen Jia,Mingjun Ying,Marco Mezzavilla,Doru Calin,Theodore S. Rappaport,Sundeep Rangan*

Main category: eess.SY

TL;DR: 该论文研究了7-24GHz频段中地面基站对卫星下行接收器的干扰问题，提出通过NTN-UE发送前导信号来帮助TN-BS进行检测和信道估计，从而在干扰方向放置零陷的方法。


<details>
  <summary>Details</summary>
Motivation: 随着FR3频段(7-24GHz)在蜂窝服务中的应用增加，需要解决地面基站对卫星系统的干扰问题，特别是如何协调高功率地面基站与现有卫星系统之间的干扰。

Method: 提出NTN-UE周期性发送前导或信标信号，TN-BS利用这些信号进行检测和信道估计，然后在干扰方向放置零陷。通过单受害者简化场景分析和多用户射线追踪仿真验证方法有效性。

Result: 仿真结果显示，即使在受害者单元密度较高的情况下，所提出的零陷方法在现实参数下仍然有效，但TN-BS可能需要大量天线。

Conclusion: 通过NTN-UE发送前导信号的方法能够有效协调地面基站与卫星系统之间的干扰，为FR3频段的共享使用提供了可行的技术方案。

Abstract: The upper mid-band FR3 spectrum (7-24 GHz) has garnered significant interest
for future cellular services. However, utilizing a large portion of this band
requires careful interference coordination with incumbent satellite systems.
This paper investigates interference from high-power terrestrial base stations
(TN-BSs) to satellite downlink receivers. A central challenge is that the
victim receivers, i.e., ground-based non-terrestrial user equipment (NTN-UEs)
such as satellite customer premises equipment, must first be detected and their
channels estimated before the TN-BS can effectively place nulls in their
directions. We explore a potential solution where NTN-UEs periodically transmit
preambles or beacon signals that TN-BSs can use for detection and channel
estimation. The performance of this nulling approach is analyzed in a
simplified scenario with a single victim, revealing the interplay between path
loss and estimation quality in determining nulling performance. To further
validate the method, we conduct a detailed multi-user site-specific ray-tracing
(RT) simulation in a rural environment. The results show that the proposed
nulling approach is effective under realistic parameters, even with high
densities of victim units, although TN-BS may require a substantial number of
antennas.

</details>


### [94] [Cognitive Radio for Asymmetric Cellular Downlink with Multi-User MIMO](https://arxiv.org/abs/2510.08937)
*Omer Gokalp Serbetci,Lei Chu,Andreas F. Molisch*

Main category: eess.SY

TL;DR: 该论文研究了5G基础设施网络中认知无线电系统的干扰管理问题，考虑了多波束天线和接收器位置不确定性的现实条件，提出了基于概率的干扰规则来平衡频谱效率和干扰风险。


<details>
  <summary>Details</summary>
Motivation: 传统认知无线电的许多假设与5G网络现实不符，特别是在基础设施系统和多波束天线场景下，需要更准确的干扰分析来评估频谱效率增益。

Method: 制定了详细的协议来确定次级传输在不同波束方向上可能干扰主用户的概率，创建了基于概率的干扰规则，并分析了干扰概率、错失传输机会概率和可达吞吐量。

Result: 分析了灾难性干扰概率、错失传输机会概率和可达吞吐量，这些指标作为主次基站发射功率和次级基站感知窗口的函数。

Conclusion: 研究结果能够更现实地评估5G基础设施认知系统的频谱效率增益，为实际部署提供了理论依据。

Abstract: Cognitive radio (CR) is an important technique for improving spectral
efficiency, letting a secondary system operate in a wireless spectrum when the
primary system does not make use of it. While it has been widely explored over
the past 25 years, many common assumptions are not aligned with the realities
of 5G networks. In this paper, we consider the CR problem for the following
setup: (i) infrastructure-based systems, where downlink transmissions might
occur to receivers whose positions are not, or not exactly, known; (ii)
multi-beam antennas at both primary and secondary base stations. We formulate a
detailed protocol to determine when secondary transmissions into different beam
directions can interfere with primary users at potential locations and create
probability-based interference rules. We then analyze the "catastrophic
interference" probability and the "missed transmission opportunity"
probability, as well as the achievable throughput, as a function of the
transmit powers of the primary and secondary base stations and the sensing
window of the secondary base station. Results can serve to more realistically
assess the spectral efficiency gains in 5G infrastructure-based cognitive
systems.

</details>


### [95] [Traffic-Aware Eco-Driving Control in CAVs via Learning-based Terminal Cost Model](https://arxiv.org/abs/2510.08980)
*Mehmet Fatih Ozkan,Dennis Kibalama,Jacob Paugh,Marcello Canova,Stephanie Stockar*

Main category: eess.SY

TL;DR: 提出了一种基于神经网络的模型预测控制方法，通过近似终端成本来考虑上游交通拥堵对车辆能耗的影响，相比不考虑交通的方法能生成更节能的速度轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有CAV生态驾驶策略往往忽略优化视野外的宏观交通影响（如上游交通拥堵），这些因素显著影响车辆能效。

Method: 在MPC框架中使用神经网络近似终端成本，明确纳入上游交通动态，使优化过程能够考虑交通拥堵。

Result: 提出的交通感知方法相比交通无关方法能产生更节能的速度轨迹，且对行程时间影响最小，框架可扩展用于实时实现。

Conclusion: 该方法能有效处理动态交通条件和宏观交通事件的不确定性，在保持实时性的同时显著提升能效。

Abstract: Connected and Automated Vehicles (CAVs) offer significant potential for
improving energy efficiency and lowering vehicle emissions through eco-driving
technologies. Control algorithms in CAVs leverage look-ahead route information
and Vehicle-to-Everything (V2X) communication to optimize vehicle performance.
However, existing eco-driving strategies often neglect macroscopic traffic
effects, such as upstream traffic jams, that occur outside the optimization
horizon but significantly impact vehicle energy efficiency. This work presents
a novel Neural Network (NN)-based methodology to approximate the terminal cost
within a model predictive control (MPC) problem framework, explicitly
incorporating upstream traffic dynamics. By incorporating traffic jams into the
optimization process, the proposed traffic-aware approach yields more
energy-efficient speed trajectories compared to traffic-agnostic methods, with
minimal impact on travel time. The framework is scalable for real-time
implementation while effectively addressing uncertainties from dynamic traffic
conditions and macroscopic traffic events.

</details>


### [96] [MAKO: Meta-Adaptive Koopman Operators for Learning-based Model Predictive Control of Parametrically Uncertain Nonlinear Systems](https://arxiv.org/abs/2510.09042)
*Minghao Han,Kiwan Wong,Adrian Wing-Keung Law,Xunyuan Yin*

Main category: eess.SY

TL;DR: 提出基于元学习的Koopman建模和预测控制方法，用于处理具有参数不确定性的非线性系统。


<details>
  <summary>Details</summary>
Motivation: 针对非线性系统中存在的参数不确定性问题，需要开发能够适应未知参数设置的建模和控制方法。

Method: 提出Meta Adaptive Koopman Operator (MAKO)方法，通过元学习从多模态数据集中学习元模型，并利用在线数据快速适应新的参数设置。

Result: 仿真结果表明，该方法在建模精度和控制效果方面优于竞争基线方法。

Conclusion: 所提出的MAKO方法能够有效处理参数不确定性，确保闭环系统稳定性，并在未知参数设置下表现出色。

Abstract: In this work, we propose a meta-learning-based Koopman modeling and
predictive control approach for nonlinear systems with parametric
uncertainties. An adaptive deep meta-learning-based modeling approach, called
Meta Adaptive Koopman Operator (MAKO), is proposed. Without knowledge of the
parametric uncertainty, the proposed MAKO approach can learn a meta-model from
a multi-modal dataset and efficiently adapt to new systems with previously
unseen parameter settings by using online data. Based on the learned meta
Koopman model, a predictive control scheme is developed, and the stability of
the closed-loop system is ensured even in the presence of previously unseen
parameter settings. Through extensive simulations, our proposed approach
demonstrates superior performance in both modeling accuracy and control
efficacy as compared to competitive baselines.

</details>


### [97] [Sensing, Detection and Localization for Low Altitude UAV: A RF-Based Framework via Multiple BSs Collaboration](https://arxiv.org/abs/2510.09055)
*Tianhao Liang,Mu Jia,Tingting Zhang,Junting Chen,Longyu Zhou,Tony Q. S. Quek,Pooi-Yuen Kam*

Main category: eess.SY

TL;DR: 提出基于蜂窝基站的协作射频检测与定位框架，用于低慢小无人机管理，结合CA-CFAR检测器和微多普勒特征识别，通过网格概率算法和聚类技术提高定位精度，并采用强化学习优化资源使用。


<details>
  <summary>Details</summary>
Motivation: 低空经济快速发展导致低慢小无人机数量激增，给空域安全和轨迹规划带来挑战，需要可靠的检测定位解决方案。

Method: 使用蜂窝基站进行协作射频检测，结合CA-CFAR检测器和微多普勒特征识别方法，采用网格概率算法融合多站测量，并通过强化学习优化定位精度与资源使用平衡。

Result: 仿真显示多基站可将定位误差降至接近克拉美-罗下界，实验验证了框架有效性，强化学习优化能在保持高精度的同时最小化资源使用。

Conclusion: 该框架为新兴低空经济中的空域安全提供了可扩展的解决方案，能够有效管理多无人机场景并优化资源利用。

Abstract: The rapid growth of the low-altitude economy has resulted in a significant
increase in the number of Low, slow, and small (LLS) unmanned aerial vehicles
(UAVs), raising critical challenges for secure airspace management and reliable
trajectory planning. To address this, this paper proposes a cooperative
radio-frequency (RF) detection and localization framework that leverages
existing cellular base stations. The proposed approach features a robust scheme
for LSS target identification, integrating a cell averaging-constant false
alarm rate (CA-CFAR) detector with a micro-Doppler signature (MDS) based
recognition method. Multi-station measurements are fused through a grid-based
probabilistic algorithm combined with clustering techniques, effectively
mitigating ghost targets and improving localization accuracy in multi-UAV
scenarios. Furthermore, the Cramer-Rao lower bound (CRLB) is derived as a
performance benchmark and reinforcement learning (RL)-based optimization is
employed to balance localization accuracy against station resource usage.
Simulations demonstrate that increasing from one to multiple BSs reduces the
positioning error to near the CRLB, while practical experiments further verify
the framework's effectiveness. Furthermore, our RL-based optimization can find
solutions that maintain high accuracy while minimizing resource usage,
highlighting its potential as a scalable solution for ensuring airspace safety
in the emerging low-altitude economy.

</details>


### [98] [Antenna's Performance in Microwave Imaging of Stratified Media](https://arxiv.org/abs/2510.09138)
*Adel Omrani,Sajjad Sadeghi*

Main category: eess.SY

TL;DR: 该论文研究了不同类型天线（喇叭天线、开口波导和Vivaldi天线）对分层介质微波成像质量的影响，发现在X波段8-12GHz下，方向性更强的天线能提供更好的重建图像质量。


<details>
  <summary>Details</summary>
Motivation: 研究不同天线特性对分层介质（如探地雷达、穿墙雷达成像）图像重建的影响，以优化微波成像系统的天线选择。

Method: 选择三种准定向天线，分析其远场和近场特性，使用基于衍射层析成像的算法处理单静态和多静态数据来重建目标位置。

Result: 观察到方向性更强的天线能够提供更好的重建图像，减少分层介质的阴影图像。

Conclusion: 天线方向性对分层介质微波成像质量有显著影响，高方向性天线能改善图像重建效果。

Abstract: Numerous types of antennas have been employed for microwave imaging of
stratified media for ground penetrating radar (GPR), through-the-wall-radar
imaging (TWRI), etc. This letter aims to investigate the impact of the
different antennas with their characteristics on the image reconstruction of
those media. Hence, three types of antennas, including horn antennas, open
waveguide and Vivaldi antennas, are chosen as almost directional antennas,
operating at X-band 8-12 GHz. The antenna's far-field and near-field
characteristics are analyzed. A diffraction tomography (DT)-based algorithm is
used to reconstruct the target location within the stratified media using
monostatic and multistatic data. It is observed that the more directional
antennas provide a better-reconstructed image with less shadowing image of the
stratified media.

</details>


### [99] [Robust Adaptive Boundary Control of a Thermal Process with Thermoelectric Actuators: Theory and Experimental Validation](https://arxiv.org/abs/2510.09169)
*Paul Mayr,Alessandro Pisano,Stefan Koch,Markus Reichhartinger*

Main category: eess.SY

TL;DR: 提出了一种基于滑模的自适应边界控制方法，用于处理具有匹配扰动的热反应扩散过程，通过自适应算法调整滑模控制中的不连续项幅值


<details>
  <summary>Details</summary>
Motivation: 处理热反应扩散过程中的不确定性和有界但边界未知的匹配扰动，需要开发自适应控制策略来应对未知扰动边界

Method: 采用边界控制律（比例项+不连续项），通过梯度自适应算法调整不连续中继项的幅值，包括单向自适应（增益单调递增）和双向自适应（增益可增减）两种参数化方式

Result: 通过Lyapunov分析证明了单向自适应具有渐近稳定性，双向自适应具有全局一致最终有界解

Conclusion: 该自适应滑模控制方法能有效处理热反应扩散过程中的不确定扰动，并在金属梁温度控制实验中验证了两种自适应策略的实际性能

Abstract: A sliding-mode-based adaptive boundary control law is proposed for a class of
uncertain thermal reaction-diffusion processes subject to matched disturbances.
The disturbances are assumed to be bounded, but the corresponding bounds are
unknown, thus motivating the use of adaptive control strategies. A boundary
control law comprising a proportional and discontinuous term is proposed,
wherein the magnitude of the discontinuous relay term is adjusted via a
gradient-based adaptation algorithm. Depending on how the adaptation algorithm
is parameterized, the adaptive gain can be either a nondecreasing function of
time (monodirectional adaptation) or it can both increase and decrease
(bidirectional adaptation). The convergence and stability properties of these
two solutions are investigated by Lyapunov analyses, and two distinct stability
results are derived, namely, asymptotic stability for the monodirectional
adaptation and globally uniformly ultimately bounded solutions for the
bidirectional adaptation. The proposed algorithms are then specified to address
the control problem of stabilizing a desired temperature profile in a metal
beam equipped with thermoelectric boundary actuators. Experiments are conducted
to investigate the real-world performance of the proposed sliding-mode-based
adaptive control, with a particular focus on comparing the monodirectional and
bidirectional adaptation laws.

</details>


### [100] [Single vs Multi Vector Predictive Control of Five-phase Drives](https://arxiv.org/abs/2510.09281)
*Manuel R. Arahal,Manuel G. Satué,Kumars Rouzbehi,Juana M. Martínez-Heredia*

Main category: eess.SY

TL;DR: 提出了一种基于调制分析的新方法来比较有限状态模型预测控制(FSMPC)变体，通过比较单向量和多向量FSMPC变体，发现单向量方法在灵活性和DC-link利用率方面更优。


<details>
  <summary>Details</summary>
Motivation: FSMPC领域存在多种变体，但缺乏对它们相对优点的共识，需要一种新的比较方法来评估不同FSMPC技术的性能。

Method: 基于分析每种FSMPC变体使用的调制方法（隐式或显式），比较单向量和多向量FSMPC变体，特别关注多向量变体如何消除xy电流和简化成本函数。

Result: 揭示了每种技术的优缺点，发现性能权衡不仅限于单个工作状态，而是扩展到整个工作空间，并且可以针对每个FSMPC变体进行精确定位。

Conclusion: 单向量FSMPC方法在灵活性和DC-link利用率方面优于多向量变体。

Abstract: The field of Finite State Model Predictive Control for multiphase drives has
produced many contributions. Many variants of FSMPC exist, each aiming at some
aspect such as complexity of the cost function, switching frequency, etc.
Despite past efforts to compare different techniques, the field is still out of
consensus regarding the relative merits of each one. This paper presents a new
method to compare FSMPC variants. The method is based on analyzing the
modulation, implicit or explicit, used by each variant. In the paper the method
is used to compare single-vector state-of-the-art FSMPC with a multi-vector
variant designed to cancel xy currents and simplify the cost function. The
results show the strengths and weaknesses of each technique. Also, it is found
that the trade-offs between figures, previously thought to concern just
individual regimes, extend to the whole operating space and also can be
pinpoint to each FSMPC variant. Finally, it is shown that the flexibility of
the single-vector approach and its better DC-link usage makes it, arguably,
superior over the multi-vector variant.

</details>


### [101] [Safety Analysis of eVTOL Operations based on STPA](https://arxiv.org/abs/2510.09283)
*Mariat James Elizebeth,Shufeng Chen,Halima El Badaoui,Siddartha Khastgir,Paul Jennings*

Main category: eess.SY

TL;DR: 使用系统理论过程分析(STPA)评估英国空域eVTOL飞机部署的风险，识别出317个不安全控制行为，其中110个高优先级行为产生377个因果因素和432个需求，最终确定124个高优先级需求，其中56个是现有航空法规的空白。


<details>
  <summary>Details</summary>
Motivation: eVTOL飞机比直升机更安静、成本更低，能通过改善连通性带来重大经济和社会效益，但其采用需要新的地面基础设施和空域重新设计，涉及多个利益相关方的风险。

Method: 采用基于系统思维的系统理论过程分析(STPA)，并应用新颖的STPA扩展方法对结果进行优先级排序。

Result: 共识别317个不安全控制行为，分析110个高优先级行为，产生377个因果因素和432个需求，最终确定124个高优先级需求，其中56个是现有法规空白。

Conclusion: 研究结果为监管机构提供了安全考量，可指导制定或更新eVTOL安全部署的法规、合规方法和指导材料，特别是在组织绩效、认证流程、培训、防撞、能源管理和自动化等领域。

Abstract: Electric Vertical Take-Off and Landing (eVTOL) aircraft are expected to be
quieter and more cost-effective than helicopters, offering major economic and
social benefits through improved connectivity. Their adoption will require new
ground infrastructure and airspace redesign, introducing risks involving
multiple stakeholders (Regulators, eVTOL operators, Air navigation service
providers, Vertiport operators, OEMs, Pilots, etc.). To assess these risks for
the UK airspace, systems-thinking based System Theoretic Process Analysis
(STPA) was conducted. To manage the large number of Unsafe Control Actions
(UCAs) and requirements generated due to the complexity of the analysis, a
novel extension to STPA for the prioritization of results was applied. 317 UCAs
were identified in total out of which 110 high-priority UCAs were analyzed
(Step-4), resulting in 377 causal factors and 432 requirements. These were
prioritized to produce a targeted list of 124 distinct high-priority
requirements, 56 of which were identified as gaps in existing aviation
regulations, policies, or procedures.. These highlight opportunities for
regulatory updates in areas such as organizational performance, certification
processes, training, collision avoidance, energy management, and automation.
The findings provide regulators with safety considerations that could shape new
or updated regulations, compliance methods, and guidance materials for the safe
deployment of eVTOLs.

</details>


### [102] [Weighting Factors Tuning by Direct Feedback in Predictive Control of Multiphase Motors](https://arxiv.org/abs/2510.09290)
*Manuel R. Arahal,Manuel G. Satué,Kumars Rouzbehi,Francisco Colodro*

Main category: eess.SY

TL;DR: 提出了一种将权重因子与性能指标关联的闭环方案，用于多相驱动器的预测定子电流控制，解决了权重因子调优问题。


<details>
  <summary>Details</summary>
Motivation: 传统PSCC中权重因子调优需要大量试错测试，现有在线选择方法需要大量数据和复杂优化过程，计算负担重。

Method: 开发闭环方案将权重因子与性能指标直接关联，为每个工作点确定最优权重因子，计算负担极小。

Result: 在五相感应电机上进行案例研究，通过实验室实验验证了方法的有效性。

Conclusion: 该方法能轻松应对性能指标参考值的变化，相比之前方法计算负担极小，具有实用价值。

Abstract: Predictive Stator Current Control (PSCC) has been proposed for control of
multi-phase drives. The flexibility offered by the use of a Cost Function has
been used to deal with the increased number of phases. However, tuning of the
Weighting Factors constitutes a problem. Intensive trial and error tests are
usual in this context. Existing on-line selection methods, on the other hand,
require large amounts of data and/or complex optimization procedures. The
proposal of this paper is a closed-loop scheme that links Weighting Factors to
performance indicators. In this way, optimal Weighting Factors are determined
for each operating point. Also, changes in reference values for performance
indicators are easily tackled. Unlike previous methods, the proposal carries
very little computational burden. A case study is developed for a five-phase
induction motor and assessed with real experimentation on a laboratory set-up.

</details>


### [103] [Data-Driven Control Of Power Converters](https://arxiv.org/abs/2510.09304)
*Marwan Soliman,Pauline Kergus,Diego Regruto,Luiz Villa,Zohra Kader*

Main category: eess.SY

TL;DR: 本文研究在电力变换器反馈控制中使用数据驱动技术，特别是虚拟参考反馈整定(VRFT)方法，以解决传统控制方法难以处理开关器件的问题。


<details>
  <summary>Details</summary>
Motivation: 电力变换器的控制具有挑战性，因为开关器件的存在使得传统控制方法难以处理。本文旨在探索数据驱动技术在电力变换器控制中的应用。

Method: 采用虚拟参考反馈整定(VRFT)这一数据驱动方法，基于OwnTech基金会提供的降压模式电力变换器电路进行研究。

Result: 论文研究了VRFT方法在电力变换器反馈控制中的适用性和效果。

Conclusion: 数据驱动技术，特别是VRFT方法，为电力变换器的控制提供了一种有效的替代方案，能够克服传统控制方法在处理开关器件时的困难。

Abstract: The fundamental role of power converters is to efficiently manage and control
the flow of electrical energy, ensuring compatibility between power sources and
loads. All these applications of power converters need the design of an
appropriate control law. Control of power converters is a challenging problem
due to the presence of switching devices which are difficult to handle using
traditional control approaches. The objective of this paper is to investigate
the use of data-driven techniques, in particular the Virtual References
Feedback Tuning (VRFT) method, in the context of power converters feedback
control. This study considers a buck \pauline{mode} power converter circuit
provided by the OwnTech foundation.

</details>


### [104] [MPA-DNN: Projection-Aware Unsupervised Learning for Multi-period DC-OPF](https://arxiv.org/abs/2510.09349)
*Yeomoon Kim,Minsoo Kim,Jip Kim*

Main category: eess.SY

TL;DR: 提出了一种多周期投影感知深度神经网络(MPA-DNN)，通过在网络中集成多周期调度投影层，确保电力系统最优潮流(OPF)的可行性和效率，特别是在可再生能源和储能高渗透率场景下。


<details>
  <summary>Details</summary>
Motivation: 解决深度神经网络作为OPF快速替代求解器时难以满足发电机爬坡限制和储能运行等跨时间耦合约束的问题。

Method: 在深度神经网络中集成多周期调度投影层，通过投影强制满足物理可行性，实现无需标注数据的端到端约束合规调度轨迹学习。

Result: 实验结果表明，该方法在不同负荷条件下实现了接近最优的性能，同时严格满足所有约束条件。

Conclusion: MPA-DNN方法能够有效解决OPF中的跨时间耦合约束问题，提供可行且高效的调度解决方案。

Abstract: Ensuring both feasibility and efficiency in optimal power flow (OPF)
operations has become increasingly important in modern power systems with high
penetrations of renewable energy and energy storage. While deep neural networks
(DNNs) have emerged as promising fast surrogates for OPF solvers, they often
fail to satisfy critical operational constraints, especially those involving
inter-temporal coupling, such as generator ramping limits and energy storage
operations. To deal with these issues, we propose a Multi-Period
Projection-Aware Deep Neural Network (MPA-DNN) that incorporates a projection
layer for multi-period dispatch into the network. By doing so, our model
enforces physical feasibility through the projection, enabling end-to-end
learning of constraint-compliant dispatch trajectories without relying on
labeled data. Experimental results demonstrate that the proposed method
achieves near-optimal performance while strictly satisfying all constraints in
varying load conditions.

</details>


### [105] [3C Resources Joint Allocation for Time-Deterministic Remote Sensing Image Backhaul in the Space-Ground Integrated Network](https://arxiv.org/abs/2510.09409)
*Chongxiao Cai,Yan Zhu,Min Sheng,Jiandong Li,Yan Shi,Di Zhou,Ziwen Xie,Chen Zhang*

Main category: eess.SY

TL;DR: 提出了一种多维度资源时间扩展图模型和SRCC算法，用于解决低轨卫星协助观测卫星传输时间敏感图像时的资源调度问题。


<details>
  <summary>Details</summary>
Motivation: 低轨卫星协助观测卫星压缩和回传时间敏感图像时，如何捕捉多维度资源的时变和动态特性以实现高效协同调度是一个挑战。

Method: 设计了多维度资源时间扩展图模型，通过时隙划分机制和虚拟节点低复杂度描述时变通信、缓存和计算资源。将问题建模为混合整数线性规划，分解为两个子问题并提出了SRCC算法。

Result: 仿真结果验证了MDR-TEG模型的优越性和SRCC算法的有效性。

Conclusion: 提出的模型和算法能够有效解决低轨卫星协助观测卫星传输时间敏感图像时的资源调度问题，获得近似最优解。

Abstract: Low-Earth-orbit (LEO) satellites assist observation satellites (OSs) to
compress and backhaul more time-determined images (TDI) has become a new
paradigm, which is used to enhance the timeout caused by the limited computing
resources of OSs. However, how to capture the time-varying and dynamic
characteristics of multi-dimensional resources is challenging for efficient
collaborative scheduling. Motivated by this factor, we design a highly succinct
multi-dimensional resource time-expanded graph (MDR-TEG) modell. Specifically,
by employing a slots division mechanism and introducing an external virtual
node, the time-varying communication, caching, and computing (3C) resources are
depicted in low complexity by the link weights within, between, and outside the
slots. Based on the MDR-TEG, the maximizing successful transmission ratio of
TDI (MSTR-TDI) is modeled as a mixed integer linear programming (MILP) problem.
Which further relaxed decomposed into two tractable sub-problems: maximizing
the successful transmission rate of images (MSTRI) and ensuring the timeliness
problem (ETP). Subsequently, an efficient subgradient of relaxation computing
constraint (SRCC) algorithm is proposed. The upper and lower bounds of MSTR-TDI
are obtained by solving the two subproblems and the dual problem (DP), and the
direction of the next iteration is obtained by feedback. Furthermore, arranging
the sending sequences of images to improve the quality of the solution. The
approximate optimal solution of MSTR-TDI is eventually obtained through
repeated iterations. The simulation results verify the superiority of the
proposed MDR-TEG model and the effectiveness of the SRCC.

</details>


### [106] [Grid-forming Control of Converter Infinite Bus System: Modeling by Data-driven Methods](https://arxiv.org/abs/2510.09411)
*Amir Bahador Javadi,Philip Pong*

Main category: eess.SY

TL;DR: 本研究比较了稀疏非线性动力学识别和深度符号回归在电网建模中的表现，发现深度符号回归精度更高但计算成本大，稀疏识别在精度和效率间取得更好平衡。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源并网，需要准确建模电网形成变换器系统动态，以保障电网稳定运行。

Method: 使用稀疏非线性动力学识别和深度符号回归技术，基于合成数据（模拟有功功率、无功功率和电压参考扰动）生成系统模型。

Result: 深度符号回归在捕捉复杂系统动态方面更准确，但计算时间显著更长；稀疏识别计算效率更高。

Conclusion: 深度符号回归提供高保真度，而稀疏识别在实时电网应用中更实用，在精度和计算时间之间取得更好平衡。

Abstract: This study explores data-driven modeling techniques to capture the dynamics
of a grid-forming converter-based infinite bus system, critical for
renewable-integrated power grids. Using sparse identification of nonlinear
dynamics and deep symbolic regression, models were generated from synthetic
data simulating key disturbances in active power, reactive power, and voltage
references. Deep symbolic regression demonstrated more accuracy in capturing
complex system dynamics, though it required substantially more computational
time than sparse identification of nonlinear dynamics. These findings suggest
that while deep symbolic regression offers high fidelity, sparse identification
of nonlinear dynamics provides a more computationally efficient approach,
balancing accuracy and runtime for real-time grid applications.

</details>


### [107] [Critical States Identiffcation in Power System via Lattice Partition and Its Application in Reliability Assessment](https://arxiv.org/abs/2510.09420)
*Han Hu,Wenjie Wan,Feiyu Chen,Xiaoyu Liu,Bo Yu,Kequan Zhao*

Main category: eess.SY

TL;DR: 提出了一种基于数学格结构的递归方法，用于高效识别电力系统临界状态并评估系统可靠性，相比传统方法具有更高精度和效率。


<details>
  <summary>Details</summary>
Motivation: 随着电力系统复杂性增加，准确识别临界状态（对应最小割集的状态）和评估系统可靠性变得至关重要。

Method: 采用数学格结构表示和划分电力系统状态空间，基于格划分和最优潮流计算提出递归方法识别临界状态，并渐进收敛地计算失负荷概率的上下界。

Result: 在RBTS和RTS79系统上的实验表明，该方法能准确识别预设阶数的所有临界状态，在RBTS系统中用显著更少的最优潮流计算达到分析值，在RBTS和RTS系统中比状态枚举法快100倍达到可接受的失负荷概率精度。

Conclusion: 该方法能高效识别高风险临界状态，这些状态对失负荷概率有显著贡献，相比传统可靠性评估方法具有更好的准确性和效率。

Abstract: With the increasing complexity of power systems,accurately identifying
critical states (the states corresponding to minimal cut sets) and assessing
system reliability have become crucial tasks. In this paper, a mathematical
lattice structure is employed to represent and partition the state space of
power system. Based on this structure, a novel recursive method is proposed to
efffciently identify critical states by leveraging lattice partitioning and
Optimal Power Flow(OPF) calculations. This method not only enables the
extension of failure system states,but also calculates the upper and lower
bounds of the Loss of Load Probability (LOLP) in a progressively converging
manner. Compared to traditional reliability assessment methods such as State
Enumeration (SE) and Monte Carlo Simulation (MCS), this approach offers greater
accuracy and efffciency. Experiments conducted on the RBTS and RTS79 systems
demonstrate that the proposed method accurately identiffes all critical states
up to a preset order, which are high-risk states. The contribution of these
critical states to LOLP highlights their signiffcance in the system. Moreover,
the proposed method achieves the analytical value with signiffcantly fewer OPF
calculations in RBTS system, reaching acceptable precision of LOLP up to 100
times faster than SE in both the RBTS and RTS systems.

</details>


### [108] [Robust reset control design for piezo-actuated nano-positioner in presence of hysteresis nonlinearity](https://arxiv.org/abs/2510.09445)
*Ashkan Sebghati,S. Hassan HosseinNia*

Main category: eess.SY

TL;DR: 提出了一种基于频域分析的鲁棒非线性控制方案，用于压电驱动纳米定位系统的运动控制，通过复杂阶元素和重置控制器来补偿迟滞非线性并提高跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 压电材料的迟滞非线性会降低高频参考信号跟踪的精度，仅使用逆模型补偿不够可靠，需要具有鲁棒性的控制框架来应对剩余非线性。

Method: 建立了基于复杂阶元素的鲁棒控制方法，使用恒定增益超前相位(CgLp)重置控制器实现复杂阶控制，基于正弦输入描述函数(SIDF)和高阶SIDF工具进行设计，并通过约束优化问题调整控制参数。

Result: 仿真验证了CgLp控制在提高性能方面的改进效果。

Conclusion: 所提出的复杂阶控制方法能够有效放松线性鲁棒控制设计的限制，为压电驱动纳米定位系统提供更可靠的迟滞补偿和跟踪性能。

Abstract: In this paper, a robust nonlinear control scheme is designed for the motion
control of a class of piezo-actuated nano-positioning systems using
frequency-domain analysis. The hysteresis, the nonlinearity in the
piezoelectric material, degrades the precision in tracking references with high
frequency contents and different travel ranges. The hysteresis compensation by
the inverse model, as the state-of-the-art solution, is not reliable alone.
Therefore, a control framework with robustness against the remaining
nonlinearity is needed. It is shown that there is an unavoidable limitation in
robust linear control design to improve the performance. A robust control
methodology based on a complex-order element is established to relax the
limitation. Then, a constant-in-gain-lead-in-phase (CgLp) reset controller is
utilized to realize the complex-order control. The control design is based on
the sinusoidal input describing function (SIDF) and the higher-order SIDF
(HOSIDF) tools. A constrained optimization problem is provided to tune the
control parameters. The achieved improvements by the CgLp control is validated
by the simulation.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [109] [Web Crawler Restrictions, AI Training Datasets \&amp; Political Biases](https://arxiv.org/abs/2510.09031)
*Paul Bouchaud,Pedro Ramaciotti*

Main category: cs.SI

TL;DR: 分析显示AI爬虫限制日益增长，不同网站类型和内容质量呈现差异化屏蔽模式，可能导致训练数据偏向低质量或极化内容


<details>
  <summary>Details</summary>
Motivation: 研究AI爬虫被网站屏蔽的现象及其对LLM训练数据构成的潜在影响，因为内容创作者为控制数据而限制AI爬虫访问

Method: 分析2023年以来全球前100万访问量网站的爬虫限制情况，按网站流行度、内容类型、政治立场和事实报道质量进行分类统计

Result: 25%的顶级网站限制AI爬虫，新闻网站限制率更高（34.2%），高质量事实报道网站限制率达55%，中立政治立场网站限制最强（58%），而右倾网站限制率仅4.1%

Conclusion: 异质化的屏蔽模式可能导致训练数据集偏向低质量或极化内容，影响主流AI服务提供商模型的能力

Abstract: Large language models rely on web-scraped text for training; concurrently,
content creators are increasingly blocking AI crawlers to retain control over
their data. We analyze crawler restrictions across the top one million
most-visited websites since 2023 and examine their potential downstream effects
on training data composition. Our analysis reveals growing restrictions, with
blocking patterns varying by website popularity and content type. A quarter of
the top thousand websites restrict AI crawlers, decreasing to one-tenth across
the broader top million. Content type matters significantly: 34.2% of news
outlets disallow OpenAI's GPTBot, rising to 55% for outlets with high factual
reporting. Additionally, outlets with neutral political positions impose the
strongest restrictions (58%), whereas hyperpartisan websites and those with low
factual reporting impose fewer restrictions -only 4.1% of right-leaning outlets
block access to OpenAI. Our findings suggest that heterogeneous blocking
patterns may skew training datasets toward low-quality or polarized content,
potentially affecting the capabilities of models served by prominent
AI-as-a-Service providers.

</details>


### [110] [Cross-Platform Narrative Prediction: Leveraging Platform-Invariant Discourse Networks](https://arxiv.org/abs/2510.09464)
*Patrick Gerard,Luca Luceria,Leonardo Blas,Emilio Ferrara*

Main category: cs.SI

TL;DR: 该论文提出了一种基于网络邻近度的跨平台信息传播预测方法，通过构建平台无关的话语网络来预测内容在不同平台间的传播模式。


<details>
  <summary>Details</summary>
Motivation: 现有跨平台信息传播模型往往将各平台视为孤立系统，忽略了跨平台活动可能使传播模式更可预测。

Method: 将跨平台预测构建为网络邻近度问题，通过共享叙事参与连接用户构建平台无关的话语网络，利用跨平台邻居邻近度作为预测信号。

Result: 该方法显著优于传统传播模型和其他基线方法，仅需不到3%的活跃用户即可进行预测，在2024年美国选举期间的570万社交媒体帖子测试中达到94%以上的AUC。

Conclusion: 话语网络结构为跨平台信息传播提供了强大的预测信号，该方法具有高度可扩展性，能够识别新兴叙事并支持主动干预。

Abstract: Online narratives spread unevenly across platforms, with content emerging on
one site often appearing on others, hours, days or weeks later. Existing
cross-platform information diffusion models often treat platforms as isolated
systems, disregarding cross-platform activity that might make these patterns
more predictable. In this work, we frame cross-platform prediction as a network
proximity problem: rather than tracking individual users across platforms or
relying on brittle signals like shared URLs or hashtags, we construct
platform-invariant discourse networks that link users through shared narrative
engagement. We show that cross-platform neighbor proximity provides a strong
predictive signal: adoption patterns follow discourse network structure even
without direct cross-platform influence. Our highly-scalable approach
substantially outperforms diffusion models and other baselines while requiring
less than 3% of active users to make predictions. We also validate our
framework through retrospective deployment. We sequentially process a
datastream of 5.7M social media posts occurred during the 2024 U.S. election,
to simulate real-time collection from four platforms (X, TikTok, Truth Social,
and Telegram): our framework successfully identified emerging narratives,
including crises-related rumors, yielding over 94% AUC with sufficient lead
time to support proactive intervention.

</details>


### [111] [From Birdwatch to Community Notes, from Twitter to X: four years of community-based content moderation](https://arxiv.org/abs/2510.09585)
*Saeedeh Mohammadi,Narges Chinichian,Hannah Doyal,Kristina Skutilova,Hao Cui,Michele d'Errico,Siobhan Grayson,Taha Yasseri*

Main category: cs.SI

TL;DR: 本文对X平台的Community Notes系统进行了系统性文献综述，并提供了涵盖前四年的数据集和源代码，包括笔记内容分析、URL提取、主题识别和贡献者互动网络构建。


<details>
  <summary>Details</summary>
Motivation: 随着Community Notes模式在社交媒体平台中日益普及，需要评估其底层动态和有效性，为未来研究提供基础资源。

Method: 解析前四年的笔记和评分数据，进行语言检测，提取英文笔记中的URL，识别讨论主题，并构建贡献者月度互动网络。

Result: 创建了一个包含文献综述、数据集和源代码的综合资源，支持对Community Notes系统的深入研究。

Conclusion: 这些资源为推进Community Notes系统研究提供了坚实的基础，有助于理解众包内容审核的运作机制和效果。

Abstract: Community Notes (formerly known as Birdwatch) is the first large-scale
crowdsourced content moderation initiative that was launched by X (formerly
known as Twitter) in January 2021. As the Community Notes model gains momentum
across other social media platforms, there is a growing need to assess its
underlying dynamics and effectiveness. This Resource paper provides (a) a
systematic review of the literature on Community Notes, and (b) a major curated
dataset and accompanying source code to support future research on Community
Notes. We parsed Notes and Ratings data from the first four years of the
program and conducted language detection across all Notes. Focusing on
English-language Notes, we extracted embedded URLs and identified discussion
topics in each Note. Additionally, we constructed monthly interaction networks
among the Contributors. Together with the literature review, these resources
offer a robust foundation for advancing research on the Community Notes system.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [112] [Quantifying Very Extreme Precipitation and Temperature Using Huge Ensembles Generated by Machine Learning-based Climate Model Emulators](https://arxiv.org/abs/2510.08893)
*Christopher J. Paciorek,Daniel Cooley*

Main category: stat.AP

TL;DR: 使用大型气候模型集合和极端值统计技术来估计极端降水和温度的分位数，为关键基础设施设计提供概率最大降水估计。


<details>
  <summary>Details</summary>
Motivation: 气候变化下极端天气事件的概率和强度可能发生变化，但观测数据或气候模型输出的记录较短，难以统计表征极低概率事件。需要改进概率最大降水(PMP)的估计方法。

Method: 使用基于ERA5再分析训练的最先进模拟器(ACE2)生成的大型集合(10560年)，应用适当的统计极端值技术，特别是阈值超越方法。

Result: 可以实际估计非常极端的降水和温度分位数；阈值超越方法在足够高的阈值下可靠；结果对季节和风暴类型的变化具有鲁棒性；统计不确定性得到良好约束；模拟器能产生超出训练数据范围的极端值。

Conclusion: 大型集合方法有潜力量化极端气候学，研究结果为未来改进的模拟器提供了如何使用大型集合估计极端统计量的相关指导。

Abstract: Weather extremes produce major impacts on society and ecosystems and are
likely to change in likelihood and magnitude with climate change. However, very
low probability events are hard to characterize statistically using
observations or climate model output because of short records/runs. For
precipitation, consideration of such events arises in quantifying Probable
Maximum Precipitation (PMP), namely estimating extreme precipitation magnitudes
for designing and assessing critical infrastructure. A recent National
Academies report on modernizing PMP estimation proposed using huge climate
model-based ensembles to estimate extreme quantiles, possibly through machine
learning-based ensemble boosting. Here we assess such an approach for the
contiguous United States using a huge ensemble (10560 years) from a
state-of-the-art emulator (ACE2) trained on ERA5 reanalysis. The results
indicate that one can practically estimate very extreme precipitation and
temperature quantiles using appropriate statistical extreme value techniques.
More specifically, the results provide evidence for (1) the use of
threshold-exceedance methods with a sufficiently high threshold for reliable
estimation (necessary for precipitation), (2) the robustness of results to
variations in extremes by season and storm type, and (3) well-constrained
statistical uncertainty. Our results also show that the emulator produces
extremes outside the range of the ERA5 training data. While this suggests that
such emulators have potential for quantifying the climatology of extremes, we
do not extensively investigate if this particular emulator is fit for purpose.
Our focus is on how to use huge ensembles to estimate very extreme statistics,
and we expect the results to be relevant for future improved emulators.

</details>
