<div id=toc></div>

# Table of Contents

- [cs.CY](#cs.CY) [Total: 9]
- [cs.ET](#cs.ET) [Total: 5]
- [cs.RO](#cs.RO) [Total: 28]
- [eess.SY](#eess.SY) [Total: 12]
- [stat.AP](#stat.AP) [Total: 3]
- [econ.TH](#econ.TH) [Total: 1]
- [cs.AI](#cs.AI) [Total: 31]
- [econ.EM](#econ.EM) [Total: 2]
- [cs.SI](#cs.SI) [Total: 4]
- [econ.GN](#econ.GN) [Total: 7]


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [1] [LLM-Driven Rubric-Based Assessment of Algebraic Competence in Multi-Stage Block Coding Tasks with Design and Field Evaluation](https://arxiv.org/abs/2510.06253)
*Yong Oh Lee,Byeonghun Bang,Sejun Oh*

Main category: cs.CY

TL;DR: 本研究提出并评估了一个基于大语言模型的评分标准评估框架，用于在线教育平台中测量代数能力和真实情境下的积木编程任务表现。


<details>
  <summary>Details</summary>
Motivation: 随着在线教育平台的扩展，需要能够同时评估答案准确性和学生认知过程深度的评估方法，以符合课程目标。

Method: 开发基于LLM的评分标准评估框架，将问题片段与五个预定义评分维度对齐，在记录所有中间响应的在线平台上实施，并通过42名中学生的实地研究验证效果。

Result: LLM基于评分标准的评估与专家判断高度一致，并持续产生符合评分标准、面向过程的反馈。

Conclusion: 结果表明将LLM驱动的评分标准评估整合到在线数学和STEM教育平台中具有有效性和可扩展性。

Abstract: As online education platforms continue to expand, there is a growing need for
assessment methods that not only measure answer accuracy but also capture the
depth of students' cognitive processes in alignment with curriculum objectives.
This study proposes and evaluates a rubric-based assessment framework powered
by a large language model (LLM) for measuring algebraic competence,
real-world-context block coding tasks. The problem set, designed by mathematics
education experts, aligns each problem segment with five predefined rubric
dimensions, enabling the LLM to assess both correctness and quality of
students' problem-solving processes. The system was implemented on an online
platform that records all intermediate responses and employs the LLM for
rubric-aligned achievement evaluation. To examine the practical effectiveness
of the proposed framework, we conducted a field study involving 42 middle
school students engaged in multi-stage quadratic equation tasks with block
coding. The study integrated learner self-assessments and expert ratings to
benchmark the system's outputs. The LLM-based rubric evaluation showed strong
agreement with expert judgments and consistently produced rubric-aligned,
process-oriented feedback. These results demonstrate both the validity and
scalability of incorporating LLM-driven rubric assessment into online
mathematics and STEM education platforms.

</details>


### [2] [Towards an Efficient, Customizable, and Accessible AI Tutor](https://arxiv.org/abs/2510.06255)
*Juan Segundo Hevia,Facundo Arredondo,Vishesh Kumar*

Main category: cs.CY

TL;DR: 提出离线RAG管道，将小型语言模型与检索机制结合，为低资源环境提供教育AI助手，解决LLM在受限环境中的部署问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在教育中潜力巨大，但高计算需求限制了在低资源环境的使用，加剧教育不平等。需要开发离线解决方案。

Method: 使用检索增强生成(RAG)管道，将小型语言模型与强健检索机制配对，无需互联网连接即可提供事实性、上下文相关的回答。

Result: 分析显示小型模型(如SmolLM)难以有效利用RAG提供的扩展上下文，特别是在包含噪声或不相关块时。性能有待提升。

Conclusion: 证明了在受限环境中部署AI导师的可行性，为公平、离线和设备化教育工具奠定了基础，建议探索先进分块技术、量化模型和更全面的评估框架。

Abstract: The integration of large language models (LLMs) into education offers
significant potential to enhance accessibility and engagement, yet their high
computational demands limit usability in low-resource settings, exacerbating
educational inequities. To address this, we propose an offline
Retrieval-Augmented Generation (RAG) pipeline that pairs a small language model
(SLM) with a robust retrieval mechanism, enabling factual, contextually
relevant responses without internet connectivity. We evaluate the efficacy of
this pipeline using domain-specific educational content, focusing on biology
coursework. Our analysis highlights key challenges: smaller models, such as
SmolLM, struggle to effectively leverage extended contexts provided by the RAG
pipeline, particularly when noisy or irrelevant chunks are included. To improve
performance, we propose exploring advanced chunking techniques, alternative
small or quantized versions of larger models, and moving beyond traditional
metrics like MMLU to a holistic evaluation framework assessing free-form
response. This work demonstrates the feasibility of deploying AI tutors in
constrained environments, laying the groundwork for equitable, offline, and
device-based educational tools.

</details>


### [3] [Beyond Static Knowledge Messengers: Towards Adaptive, Fair, and Scalable Federated Learning for Medical AI](https://arxiv.org/abs/2510.06259)
*Jahidul Arafat,Fariha Tasmin,Sanjaya Poudel,Ahsan Habib Tareq,Iftekhar Haider*

Main category: cs.CY

TL;DR: 提出自适应公平联邦学习(AFFL)框架，通过动态知识传递、公平感知蒸馏和课程引导加速三大创新，解决医疗AI在隐私保护协作学习中的公平性和效率问题。


<details>
  <summary>Details</summary>
Motivation: 医疗AI面临隐私保护协作学习的挑战，现有联邦学习方法存在静态架构、收敛慢、公平性差距和可扩展性限制等问题，特别是对小机构的边缘化问题。

Method: 1) 自适应知识传递器根据异构性和任务复杂度动态扩展容量；2) 使用影响加权聚合的公平感知蒸馏；3) 课程引导加速减少60-70%的训练轮次。

Result: 理论分析提供收敛保证和epsilon公平性边界，达到O(T^{-1/2}) + O(H_max/T^{3/4})收敛速率。预计减少55-75%通信，提升56-68%公平性，节省34-46%能耗，支持100+机构。

Conclusion: 该框架支持多模态数据集成，保持HIPAA/GDPR合规性，提出MedFedBench基准套件，经济预测显示农村医院400-800% ROI，学术中心15-25%性能提升，推动医疗AI民主化。

Abstract: Medical AI faces challenges in privacy-preserving collaborative learning
while ensuring fairness across heterogeneous healthcare institutions. Current
federated learning approaches suffer from static architectures, slow
convergence (45-73 rounds), fairness gaps marginalizing smaller institutions,
and scalability constraints (15-client limit). We propose Adaptive Fair
Federated Learning (AFFL) through three innovations: (1) Adaptive Knowledge
Messengers dynamically scaling capacity based on heterogeneity and task
complexity, (2) Fairness-Aware Distillation using influence-weighted
aggregation, and (3) Curriculum-Guided Acceleration reducing rounds by 60-70%.
Our theoretical analysis provides convergence guarantees with epsilon-fairness
bounds, achieving O(T^{-1/2}) + O(H_max/T^{3/4}) rates. Projected results show
55-75% communication reduction, 56-68% fairness improvement, 34-46% energy
savings, and 100+ institution support. The framework enables multi-modal
integration across imaging, genomics, EHR, and sensor data while maintaining
HIPAA/GDPR compliance. We propose MedFedBench benchmark suite for standardized
evaluation across six healthcare dimensions: convergence efficiency,
institutional fairness, privacy preservation, multi-modal integration,
scalability, and clinical deployment readiness. Economic projections indicate
400-800% ROI for rural hospitals and 15-25% performance gains for academic
centers. This work presents a seven-question research agenda, 24-month
implementation roadmap, and pathways toward democratizing healthcare AI.

</details>


### [4] [Technical Overview of Safe3Step (S3S): Power Ratings and quality wins for selecting at-large teams to the NCAA Division I Men's Lacrosse Championship](https://arxiv.org/abs/2510.06279)
*Lawrence Feldman,Matthew Bomparola*

Main category: cs.CY

TL;DR: Safe3Step (S3S) 是一个用于NCAA男子长曲棍球锦标赛队伍选拔的系统，通过三个步骤改进RPI评分：评估队伍实力、基于比赛质量分配积分、调整相邻排名队伍的顺序。


<details>
  <summary>Details</summary>
Motivation: 改进现有的RPI评分系统，为NCAA长曲棍球锦标赛提供更简单、透明和客观的队伍选拔方法。

Method: 采用三步法：1) 基于比分数据评估队伍实力；2) 根据胜利和失败的质量分配S3S积分并排名；3) 检查相邻排名队伍的对战记录，必要时交换排名。

Result: 开发了Safe3Step系统，该方法使用实力评级识别队伍强度，尊重对战记录，并保持简单性、透明度和客观性标准。

Conclusion: Safe3Step是对现有"质量胜利"方法的改进，但实证分析留待未来工作完成。

Abstract: This document describes a system for selecting teams to the NCAA Men's
Division I Lacrosse Championship Tournament called "Safe3Step" (S3S) that was
developed in conversation with the NCAA Lacrosse Selection Criteria and Ranking
Committee (SCR) with the objective of improving on the Ratings Percentage Index
(RPI). S3S employs three steps that: 1) evaluate the strength of each team
based on score data, 2) award S3S points to each team based on the quality of
its wins and losses, ranking teams accordingly, and 3) examine each pair of
teams with adjacent rankings, swapping ranks if the lower-ranked team has a
better head-to-head record against the higher-ranked team. Safe3Step is not
entirely new, but it improves on other "quality win" methods by using Power
Ratings to identify team strengths, respecting head-to-head records, and
adhering to standards of simplicity, transparency, and objectivity. Empirical
analysis is left to future work.

</details>


### [5] [Surgeons Are Indian Males and Speech Therapists Are White Females: Auditing Biases in Vision-Language Models for Healthcare Professionals](https://arxiv.org/abs/2510.06280)
*Zohaib Hasan Siddiqui,Dayam Nadeem,Mohammad Masudur Rahman,Mohammad Nadeem,Shahab Saquib Sohail,Beenish Moalla Chaudhry*

Main category: cs.CY

TL;DR: 该论文评估了视觉语言模型在医疗职业中存在的刻板印象和人口统计偏见，提出了一个包含职业分类、提示套件和基准测试的评估方法，发现多个模型存在一致的偏见问题。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型从网络规模数据中学习到的医疗职业与人口属性之间的刻板关联可能在医疗保健等关键领域带来操作风险，影响公平性、合规性和患者信任。

Method: 定义了医疗职业分类法，策划了职业感知提示套件来探测模型行为，并使用平衡的人脸语料库对人口统计偏差进行基准测试。

Result: 实证研究发现多个视觉模型在不同医疗角色中都存在一致的人口统计偏见。

Conclusion: 研究强调了在医疗等关键领域识别AI偏见的重要性，因为AI辅助招聘和劳动力分析可能对公平性、合规性和患者信任产生下游影响。

Abstract: Vision language models (VLMs), such as CLIP and OpenCLIP, can encode and
reflect stereotypical associations between medical professions and demographic
attributes learned from web-scale data. We present an evaluation protocol for
healthcare settings that quantifies associated biases and assesses their
operational risk. Our methodology (i) defines a taxonomy spanning clinicians
and allied healthcare roles (e.g., surgeon, cardiologist, dentist, nurse,
pharmacist, technician), (ii) curates a profession-aware prompt suite to probe
model behavior, and (iii) benchmarks demographic skew against a balanced face
corpus. Empirically, we observe consistent demographic biases across multiple
roles and vision models. Our work highlights the importance of bias
identification in critical domains such as healthcare as AI-enabled hiring and
workforce analytics can have downstream implications for equity, compliance,
and patient trust.

</details>


### [6] [Asking For It: Question-Answering for Predicting Rule Infractions in Online Content Moderation](https://arxiv.org/abs/2510.06350)
*Mattia Samory,Diana Pamfile,Andrew To,Shruti Phadke*

Main category: cs.CY

TL;DR: 提出了ModQ框架，一种基于问答的内容审核方法，能够根据社区规则识别评论违规情况，并在未见过的社区和规则上表现出良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在线社区的规则差异大、变化快且执行不一致，给透明度、治理和自动化带来挑战，需要一种能够理解规则与执行关系的模型。

Method: 设计了两种模型变体：抽取式问答和多选问答，基于Reddit和Lemmy的大规模数据集训练，在推理时考虑完整的社区规则集。

Result: 两种模型在识别与审核相关的规则违规方面均优于现有基线方法，同时保持轻量级和可解释性。

Conclusion: ModQ框架能够有效泛化到未见过的社区和规则，支持低资源审核设置和动态治理环境，为规则敏感的内容审核提供了新方法。

Abstract: Online communities rely on a mix of platform policies and community-authored
rules to define acceptable behavior and maintain order. However, these rules
vary widely across communities, evolve over time, and are enforced
inconsistently, posing challenges for transparency, governance, and automation.
In this paper, we model the relationship between rules and their enforcement at
scale, introducing ModQ, a novel question-answering framework for
rule-sensitive content moderation. Unlike prior classification or
generation-based approaches, ModQ conditions on the full set of community rules
at inference time and identifies which rule best applies to a given comment. We
implement two model variants - extractive and multiple-choice QA - and train
them on large-scale datasets from Reddit and Lemmy, the latter of which we
construct from publicly available moderation logs and rule descriptions. Both
models outperform state-of-the-art baselines in identifying moderation-relevant
rule violations, while remaining lightweight and interpretable. Notably, ModQ
models generalize effectively to unseen communities and rules, supporting
low-resource moderation settings and dynamic governance environments.

</details>


### [7] [The Limits of Goal-Setting Theory in LLM-Driven Assessment](https://arxiv.org/abs/2510.06997)
*Mrityunjay Kumar*

Main category: cs.CY

TL;DR: 研究发现，尽管用户倾向于将AI工具视为类人模型（Model H），但增加提示语的具体性并不能提高ChatGPT评估学生作业的一致性，这与目标设定理论的预期相反。


<details>
  <summary>Details</summary>
Motivation: 验证用户将AI视为类人模型（Model H）的假设，即根据目标设定理论，更具体的提示应该减少性能方差，提高评估一致性。

Method: 通过控制实验，让ChatGPT使用四种不同具体程度的提示语评估29份学生作业，并通过重复运行的Cohen's Kappa测量评估一致性。

Result: 与预期相反，提示语具体性的增加并未持续改善性能，性能方差基本保持不变。

Conclusion: 这些发现挑战了LLMs行为类似人类评估者的假设，强调了未来模型开发中需要更强的鲁棒性和改进的输入整合能力。

Abstract: Many users interact with AI tools like ChatGPT using a mental model that
treats the system as human-like, which we call Model H. According to
goal-setting theory, increased specificity in goals should reduce performance
variance. If Model H holds, then prompting a chatbot with more detailed
instructions should lead to more consistent evaluation behavior.
  This paper tests that assumption through a controlled experiment in which
ChatGPT evaluated 29 student submissions using four prompts with increasing
specificity. We measured consistency using intra-rater reliability (Cohen's
Kappa) across repeated runs.
  Contrary to expectations, performance did not improve consistently with
increased prompt specificity, and performance variance remained largely
unchanged. These findings challenge the assumption that LLMs behave like human
evaluators and highlight the need for greater robustness and improved input
integration in future model development.

</details>


### [8] [Early Results from Teaching Modelling for Software Comprehension in New-Hire Onboarding](https://arxiv.org/abs/2510.07010)
*Mrityunjay Kumar,Venkatesh Choppella*

Main category: cs.CY

TL;DR: 在SaaS公司入职培训中引入系统思维和LTS建模的五次课程干预，结果显示对预备知识较少的新员工理解力提升显著（15个百分点），但对预备知识较好的员工效果不明显。


<details>
  <summary>Details</summary>
Motivation: 大多数毕业生进入行业时缺乏处理大型软件系统的准备，需要提升系统理解能力。

Method: 在入职培训中集成五次课程，教授系统思维和LTS建模，使用结构化模板表达产品行为理解，并进行前后测试评估。

Result: 35名新员工中31人提供配对数据，整体提升不显著，但预备知识低于中位数的参与者平均提升15个百分点（显著），高于中位数的参与者略有退步（不显著）。

Conclusion: 短期的建模导向入职干预能加速预备知识较少新员工的理解力，但需要为预备知识较好的员工提供差异化路径，此类低成本干预可规模化补充现有入职培训。

Abstract: Working effectively with large, existing software systems requires strong
comprehension skills, yet most graduates enter the industry with little
preparation for this challenge. We report early results from a pilot
intervention integrated into a SaaS company's onboarding program: a
five-session course introducing systems thinking and Labelled Transition System
(LTS) modelling. Participants articulated their understanding of product
behaviour using a structured template and completed matched pre- and
post-assessments. Of 35 new hires, 31 provided paired records for analysis.
Across the full cohort, gains were small and not statistically significant.
However, participants below the median on the pre-test improved by 15
percentage points on average (statistically significant), while those above the
median regressed slightly (not statistically significant). Course feedback
indicated high engagement and perceived applicability. These results suggest
that short, modelling-focused onboarding interventions can accelerate
comprehension for less-prepared new hires. At the same time, they point to the
need for differentiated pathways for stronger participants, and to the
potential for companies to adopt such interventions at scale as a low-cost
complement to existing onboarding.

</details>


### [9] [On the false election between regulation and innovation. Ideas for regulation through the responsible use of artificial intelligence in research and education.[Spanish version]](https://arxiv.org/abs/2510.07268)
*Pompeu Casanovas*

Main category: cs.CY

TL;DR: 本文探讨AI监管框架如何平衡基本权利保护与创新，分析现有政策案例，并提出国际合作机制建议。


<details>
  <summary>Details</summary>
Motivation: 针对AI发展中的监管与创新矛盾、权利保护风险以及国际竞争压力，寻求可行的解决方案。

Method: 基于学术辩论和问答形式，分析三个核心问题：权利保护与创新的平衡、负责任创新政策案例、国际合作机制。

Result: 提出了在AI监管中保护基本权利的具体方法，识别了成功的政策案例，并设计了防止权利标准降低的国际合作机制。

Conclusion: AI监管需要在保护基本权利与促进创新之间找到平衡，通过国际合作建立全球问责标准，这对教育和研究具有重要意义。

Abstract: This short essay is a reworking of the answers offered by the author at the
Debate Session of the AIHUB (CSIC) and EduCaixa Summer School, organized by
Marta Garcia-Matos and Lissette Lemus, and coordinated by Albert Sabater
(OEIAC, UG), with the participation of Vanina Martinez-Posse (IIIA-CSIC),
Eulalia Soler (Eurecat) and Pompeu Casanovas (IIIA-CSIC) on July 4th 2025.
Albert Sabater posed three questions: (1) How can regulatory frameworks
priori-tise the protection of fundamental rights (privacy, non-discrimination,
autonomy, etc.) in the development of AI, without falling into the false
dichotomy between regulation and innova-tion? (2) Given the risks of AI (bias,
mass surveillance, manipulation), what examples of regu-lations or policies
have demonstrated that it is possible to foster responsible innovation, putting
the public interest before profitability, without giving in to competitive
pressure from actors such as China or the US? (3) In a scenario where the US
prioritizes flexibility, what mecha-nisms could ensure that international
cooperation in AI does not become a race to the bottom in rights, but rather a
global standard of accountability? The article attempts to answer these three
questions and concludes with some reflections on the relevance of the answers
for education and research.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [10] [A Hybrid Quantum-AI Framework for Protein Structure Prediction on NISQ Devices](https://arxiv.org/abs/2510.06413)
*Yuqi Zhang,Yuxin Yang,Feixiong Chen,Cheng-Chang Lu,Nima Saeidi,Samuel L. Volchenboum,Junhan Zhao,Siwei Chen,Weiwen Jiang,Qiang Guan*

Main category: cs.ET

TL;DR: 提出了一种结合量子计算和深度学习的混合框架，通过能量融合方法改进蛋白质结构预测精度。


<details>
  <summary>Details</summary>
Motivation: 变分量子算法在蛋白质结构预测中受限于当前噪声设备生成的能量景观分辨率较低，需要提高预测精度。

Method: 使用IBM 127量子位超导处理器上的VQE算法获得候选构象，结合NSP3神经网络预测的二级结构概率和二面角分布作为统计势能，通过能量融合方法锐化量子景观。

Result: 在75个蛋白质片段的375个构象上评估，相比AlphaFold3、ColabFold和纯量子预测有显著改进，平均RMSD达到4.9Å（p < 0.001）。

Conclusion: 能量融合提供了一种系统方法，将数据驱动模型与量子算法结合，提高了近期量子计算在分子和结构生物学中的实际应用性。

Abstract: Variational quantum algorithms provide a direct, physics-based approach to
protein structure prediction, but their accuracy is limited by the coarse
resolution of the energy landscapes generated on current noisy devices. We
propose a hybrid framework that combines quantum computation with deep
learning, formulating structure prediction as a problem of energy fusion.
Candidate conformations are obtained through the Variational Quantum
Eigensolver (VQE) executed on IBM's 127-qubit superconducting processor, which
defines a global yet low-resolution quantum energy surface. To refine these
basins, secondary structure probabilities and dihedral angle distributions
predicted by the NSP3 neural network are incorporated as statistical
potentials. These additional terms sharpen the valleys of the quantum
landscape, resulting in a fused energy function that enhances effective
resolution and better distinguishes native-like structures. Evaluation on 375
conformations from 75 protein fragments shows consistent improvements over
AlphaFold3, ColabFold, and quantum-only predictions, achieving a mean RMSD of
4.9 {\AA} with statistical significance (p < 0.001). The findings demonstrate
that energy fusion offers a systematic method for combining data-driven models
with quantum algorithms, improving the practical applicability of near-term
quantum computing to molecular and structural biology.

</details>


### [11] [A Review of 10 Years of ProtoSpace: Spacecraft CAD Visualization in Collaborative Augmented Reality](https://arxiv.org/abs/2510.06608)
*Benjamin Nuernberger,Samuel-Hunter Berndt,Robert Tapella,Laura Mann,Aaron Plave,Sasha Samochina,Victor X. Luo*

Main category: cs.ET

TL;DR: ProtoSpace是JPL开发的可视化平台，支持科学家和工程师在AR和Web 3D中协作查看CAD模型，已在NASA多个任务中应用10年，有效降低成本和风险。


<details>
  <summary>Details</summary>
Motivation: 帮助工程师和科学家通过减少沟通误解、更快理解航天器空间背景来更早发现问题，从而降低任务成本和风险。

Method: 构建包含HoloLens和3D Web客户端、ProtoSpace服务器、CAD模型优化器的系统架构，支持AR和Web 3D协作可视化。

Result: 成功应用于NASA多个任务（如Mars Perseverance、Europa Clipper等）10年，扩展到航天器任务全生命周期及医疗设备设计、宇航员培训等领域。

Conclusion: ProtoSpace通过AR和3D Web可视化技术，在NASA JPL实现了10年的成功应用，证明了其在减少沟通错误、加速空间理解方面的价值。

Abstract: ProtoSpace is a custom JPL-built platform to help scientists and engineers
visualize their CAD models collaboratively in augmented reality (AR) and on the
web in 3D. In addition to this main use case, ProtoSpace has been used
throughout the entire spacecraft mission lifecycle and beyond: ventilator
design and assembly; providing AR-based instructions to astronauts in-training;
educating the next generation on the process of spacecraft design; etc.
ProtoSpace has been used for a decade by NASA missions-including Mars
Perseverance, Europa Clipper, NISAR, SPHEREx, CAL, and Mars Sample Return-to
reduce cost and risk by helping engineers and scientists fix problems earlier
through reducing miscommunication and helping people understand the spatial
context of their spacecraft in the appropriate physical context more quickly.
This paper will explore how ProtoSpace came to be, define the system
architecture and overview-including HoloLens and 3D web clients, the ProtoSpace
server, and the CAD model optimizer-and dive into the use cases, spin-offs, and
lessons learned that led to 10 years of success at NASA's Jet Propulsion
Laboratory.

</details>


### [12] [The Stage Comes to You: A Real-Time Tele-Immersive System with 3D Point Clouds and Vibrotactile Feedback](https://arxiv.org/abs/2510.07009)
*Takahiro Matsumoto,Takahiro Kusabuka,Hiroshi Chigira,Kazuhiko Murasaki,Kakagu Komazaki,Masafumi Suzuki,Masakatsu Aoki*

Main category: cs.ET

TL;DR: 开发了一个低延迟的远程沉浸式娱乐系统，通过传输3D点云和脚步振动，在100ms总延迟内实现远程舞台的实时呈现。


<details>
  <summary>Details</summary>
Motivation: 为了创建远程舞台的临场感，让观众能够实时观看表演并与表演者互动，消除地理距离带来的延迟问题。

Method: 使用动态点云捕捉移动表演者及其环境，通过可穿戴加速度计感知脚步振动，将实时视觉和触觉流传输到远程场地，通过大型3D LED墙和振动触觉地板呈现给观众。

Result: 在2025年世博会上成功连接相距20公里的场地，观众观看现场舞蹈表演并与表演者交谈，没有明显延迟。

Conclusion: 该系统证明了在100ms延迟内实现远程沉浸式娱乐的可行性，为远程表演和互动提供了新的可能性。

Abstract: We present a low-latency tele-immersive entertainment system that streams 3D
point clouds and performers' footstep vibrations, creating the sense that the
stage is present. Moving performers and their surroundings are captured as
dynamic point clouds under rapidly changing lighting, then processed,
transmitted, and rendered within a total latency of less than 100 ms. Under
high ambient noise, footstep vibrations are sensed by wearable accelerometers.
Real-time visual and haptic streams are delivered to a remote venue, where a
large 3D LED wall and a vibration-efficient haptic floor envelop dozens of
spectators. A public trial at Expo 2025 linked sites 20 km apart: visitors
watched a live dance show and conversed with performers without noticeable
delay.

</details>


### [13] [An HPC-Inspired Blueprint for a Technology-Agnostic Quantum Middle Layer](https://arxiv.org/abs/2510.07079)
*Stefano Markidis,Gilbert Netzer,Luca Pennati,Ivy Peng*

Main category: cs.ET

TL;DR: 提出了一个量子中间层蓝图，支持跨不同量子技术的应用，通过意图描述符和上下文描述符实现后端中立和上下文感知的量子编程。


<details>
  <summary>Details</summary>
Motivation: 为了解决量子计算中不同后端技术（门模型、退火等）之间的兼容性问题，提供统一的编程抽象层，使程序只需指定意图而不依赖具体执行细节。

Method: 设计后端中立、上下文感知的量子中间层架构，使用类型化数据和操作符描述符来声明量子寄存器的含义和逻辑变换需求，执行细节通过上下文描述符单独携带。

Result: 开发了概念验证实现，使用JSON文件作为描述符，在IBM Qiskit Aer模拟器和D-Wave Ocean模拟退火器上成功运行相同的Max-Cut问题实例。

Conclusion: 该量子中间层概念具有可移植性、可组合性，其最小核心可随硬件能力演进，为跨量子技术应用提供了可行的解决方案。

Abstract: We present a blueprint for a quantum middle layer that supports applications
across various quantum technologies. Inspired by concepts and abstractions from
HPC libraries and middleware, our design is backend-neutral and context-aware.
A program only needs to specify its intent once as typed data and operator
descriptors. It declares what the quantum registers mean and which logical
transformations are required, without committing to gates, pulses,
continuous-variable routines, or anneal backend. Such execution details are
carried separately in a context descriptor and can change per backend without
modifying the intent artifacts.
  We develop a proof of concept implementation that uses JSON files for the
descriptors and two backends: a gate-model path realized with IBM Qiskit Aer
simulator and an annealing path realized with D-Wave Ocean's simulated
annealer. On a Max-Cut problem instance, the same typed problem runs on both
backends by varying only the operator formulation (Quantum Approximated
Optimization Algorithm formulation vs. Ising Hamiltonian formulation) and the
context. The proposed middle layer concepts are characterized by portability,
composability, and its minimal core can evolve with hardware capabilities.

</details>


### [14] [From Neural Sensing to Stimulation: An Interdisciplinary Roadmap for Neurotechnology](https://arxiv.org/abs/2510.07116)
*Ruben Ruiz-Mateos Serrano,Joe G Troughton,Nima Mirkhani,Natalia Martinez,Massimo Mariello,Jordan Tsigarides,Simon Williamson,Juan Sapriza,Ioana Susnoschi Luca,Antonio Dominguez-Alfaro,Estelle Cuttaz,Nicole Thompson,Sydney Swedick,Latifah Almulla,Amparo Guemes*

Main category: cs.ET

TL;DR: 这篇论文提出了神经技术发展的战略路线图，重点关注跨学科合作、技术权衡和伦理监管，旨在加速公平有效的自适应神经技术发展。


<details>
  <summary>Details</summary>
Motivation: 神经技术在临床和非临床领域具有变革潜力，但面临跨学科复杂挑战，需要协调各领域发展以实现其潜力。

Method: 通过早期职业研究人员创建战略路线图，识别五个跨领域权衡，提出统一协作框架和教育体系，制定时间表解决关键瓶颈。

Result: 建立了神经技术发展的综合框架，强调技术开发与转化需求的对齐，促进全球研究创新社区的协调努力。

Conclusion: 通过跨学科合作和战略路线图，可以加速开发公平、有效且面向未来的自适应神经技术，实现神经技术的变革潜力。

Abstract: Neurotechnologies are transforming how we measure, interpret, and modulate
brain-body interactions, integrating real-time sensing, computation, and
stimulation to enable precise physiological control. They hold transformative
potential across clinical and non-clinical domains, from treating disorders to
enhancing cognition and performance. Realizing this potential requires
navigating complex, interdisciplinary challenges spanning neuroscience,
materials science, device engineering, signal processing, computational
modelling, and regulatory and ethical frameworks. This Perspective presents a
strategic roadmap for neurotechnology development, created by early-career
researchers, highlighting their role at the intersection of disciplines and
their capacity to bridge traditional silos. We identify five cross-cutting
trade-offs that constrain progress across functionality, scalability,
adaptability, and translatability, and illustrate how technical domains
influence their resolution. Rather than a domain-specific review, we focus on
shared challenges and strategic opportunities that transcend disciplines. We
propose a unified framework for collaborative innovation and education,
highlight ethical and regulatory priorities, and outline a timeline for
overcoming key bottlenecks. By aligning technical development with
translational and societal needs, this roadmap aims to accelerate equitable,
effective, and future-ready adaptive neurotechnologies, guiding coordinated
efforts across the global research and innovation community.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [15] [Vi-TacMan: Articulated Object Manipulation via Vision and Touch](https://arxiv.org/abs/2510.06339)
*Leiyao Cui,Zihang Zhao,Sirui Xie,Wenhuan Zhang,Zhi Han,Yixin Zhu*

Main category: cs.RO

TL;DR: Vi-TacMan结合视觉和触觉进行关节物体操作：视觉提供全局抓取建议和粗略方向，触觉控制器进行精确执行，无需显式运动学模型。


<details>
  <summary>Details</summary>
Motivation: 视觉方法能推断隐藏运动学但不精确，触觉方法通过接触反馈实现鲁棒控制但需要准确初始化，两者具有互补性但缺乏系统化融合框架。

Method: 使用视觉提出抓取和粗略方向作为触觉控制器的种子，结合表面法线作为几何先验，通过von Mises-Fisher分布建模方向，触觉控制器通过实时接触调节细化视觉估计。

Result: 在超过50,000个模拟和真实物体上测试，相比基线方法有显著提升（所有p<0.0001），实现跨类别的鲁棒泛化。

Conclusion: 粗粒度视觉线索结合触觉反馈足以实现可靠操作，为非结构化环境中的自主系统提供了可扩展范式。

Abstract: Autonomous manipulation of articulated objects remains a fundamental
challenge for robots in human environments. Vision-based methods can infer
hidden kinematics but can yield imprecise estimates on unfamiliar objects.
Tactile approaches achieve robust control through contact feedback but require
accurate initialization. This suggests a natural synergy: vision for global
guidance, touch for local precision. Yet no framework systematically exploits
this complementarity for generalized articulated manipulation. Here we present
Vi-TacMan, which uses vision to propose grasps and coarse directions that seed
a tactile controller for precise execution. By incorporating surface normals as
geometric priors and modeling directions via von Mises-Fisher distributions,
our approach achieves significant gains over baselines (all p<0.0001).
Critically, manipulation succeeds without explicit kinematic models -- the
tactile controller refines coarse visual estimates through real-time contact
regulation. Tests on more than 50,000 simulated and diverse real-world objects
confirm robust cross-category generalization. This work establishes that coarse
visual cues suffice for reliable manipulation when coupled with tactile
feedback, offering a scalable paradigm for autonomous systems in unstructured
environments.

</details>


### [16] [A Formal gatekeeper Framework for Safe Dual Control with Active Exploration](https://arxiv.org/abs/2510.06351)
*Kaleb Ben Naveed,Devansh R. Agrawal,Dimitra Panagou*

Main category: cs.RO

TL;DR: 提出一个将鲁棒规划与主动探索相结合的安全框架，仅在探索能带来可验证改进且不损害安全性的情况下进行探索。


<details>
  <summary>Details</summary>
Motivation: 解决模型不确定性下的安全轨迹规划问题，传统鲁棒规划过于保守且忽略不确定性减少，而现有双控制方法缺乏对探索时机和安全性的正式考虑。

Method: 利用gatekeeper架构进行安全验证，扩展其生成既安全又信息丰富的轨迹，减少不确定性和任务成本，或保持在用户定义的预算内。

Result: 通过四旋翼飞行器参数不确定性的在线双控制仿真案例研究验证了方法的有效性。

Conclusion: 该框架在保证安全的前提下，智能地平衡了探索和利用，仅在探索能带来可验证收益时才进行探索。

Abstract: Planning safe trajectories under model uncertainty is a fundamental
challenge. Robust planning ensures safety by considering worst-case
realizations, yet ignores uncertainty reduction and leads to overly
conservative behavior. Actively reducing uncertainty on-the-fly during a
nominal mission defines the dual control problem. Most approaches address this
by adding a weighted exploration term to the cost, tuned to trade off the
nominal objective and uncertainty reduction, but without formal consideration
of when exploration is beneficial. Moreover, safety is enforced in some methods
but not in others. We propose a framework that integrates robust planning with
active exploration under formal guarantees as follows: The key innovation and
contribution is that exploration is pursued only when it provides a verifiable
improvement without compromising safety. To achieve this, we utilize our
earlier work on gatekeeper as an architecture for safety verification, and
extend it so that it generates both safe and informative trajectories that
reduce uncertainty and the cost of the mission, or keep it within a
user-defined budget. The methodology is evaluated via simulation case studies
on the online dual control of a quadrotor under parametric uncertainty.

</details>


### [17] [Constrained Natural Language Action Planning for Resilient Embodied Systems](https://arxiv.org/abs/2510.06357)
*Grayson Byrd,Corban Rivera,Bethany Kemp,Meghan Booker,Aurora Schmidt,Celso M de Melo,Lalithkumar Seenivasan,Mathias Unberath*

Main category: cs.RO

TL;DR: 提出了一种结合LLM规划和符号规划的混合方法，通过符号规划监督增强LLM规划器的可靠性和可重复性，在ALFWorld基准上达到99%成功率，在真实机器人任务中实现100%成功率。


<details>
  <summary>Details</summary>
Motivation: 解决LLM规划在真实世界任务中的幻觉问题和可靠性不足，同时克服纯符号规划方法在复杂真实环境中的扩展性问题。

Method: 将LLM规划与符号规划监督相结合，通过符号规划提供硬约束和可靠性保证，同时保留LLM的推理能力和泛化性。

Result: 在ALFWorld规划基准上达到99%成功率，在真实四足机器人任务中实现100%成功率，显著优于纯LLM规划（50%）和纯符号规划（30%）。

Conclusion: 该方法有效提升了基于LLM的机器人规划器的可靠性、可重复性和透明度，同时保持了其在复杂真实环境中的灵活性和泛化能力。

Abstract: Replicating human-level intelligence in the execution of embodied tasks
remains challenging due to the unconstrained nature of real-world environments.
Novel use of large language models (LLMs) for task planning seeks to address
the previously intractable state/action space of complex planning tasks, but
hallucinations limit their reliability, and thus, viability beyond a research
context. Additionally, the prompt engineering required to achieve adequate
system performance lacks transparency, and thus, repeatability. In contrast to
LLM planning, symbolic planning methods offer strong reliability and
repeatability guarantees, but struggle to scale to the complexity and ambiguity
of real-world tasks. We introduce a new robotic planning method that augments
LLM planners with symbolic planning oversight to improve reliability and
repeatability, and provide a transparent approach to defining hard constraints
with considerably stronger clarity than traditional prompt engineering.
Importantly, these augmentations preserve the reasoning capabilities of LLMs
and retain impressive generalization in open-world environments. We demonstrate
our approach in simulated and real-world environments. On the ALFWorld planning
benchmark, our approach outperforms current state-of-the-art methods, achieving
a near-perfect 99% success rate. Deployment of our method to a real-world
quadruped robot resulted in 100% task success compared to 50% and 30% for pure
LLM and symbolic planners across embodied pick and place tasks. Our approach
presents an effective strategy to enhance the reliability, repeatability and
transparency of LLM-based robot planners while retaining their key strengths:
flexibility and generalizability to complex real-world environments. We hope
that this work will contribute to the broad goal of building resilient embodied
intelligent systems.

</details>


### [18] [Active Next-Best-View Optimization for Risk-Averse Path Planning](https://arxiv.org/abs/2510.06481)
*Amirhossein Mollaei Khass,Guangyi Liu,Vivek Pandey,Wen Jiang,Boshu Lei,Kostas Daniilidis,Nader Motee*

Main category: cs.RO

TL;DR: 提出一个统一框架，通过在线更新的3D高斯溅射辐射场构建尾部敏感风险地图来细化参考路径，同时将最佳视点选择建模为SE(3)流形上的优化问题，耦合风险规避路径细化与主动感知。


<details>
  <summary>Details</summary>
Motivation: 在不确定环境中实现安全导航需要将风险规避与主动感知相结合，以生成局部安全可行的轨迹并减少对即将运动最关键的感知不确定性。

Method: 使用在线更新的3D高斯溅射辐射场构建基于平均风险价值统计的尾部敏感风险地图来细化参考路径；将最佳视点选择建模为SE(3)流形上的优化问题，通过黎曼梯度下降最大化期望信息增益。

Result: 通过广泛的计算研究证明了所提出框架的有效性，实现了风险规避路径细化与最佳视点规划的耦合。

Conclusion: 该框架通过引入可扩展的梯度分解支持复杂环境中的高效在线更新，推进了风险规避路径细化与主动感知相结合的技术水平。

Abstract: Safe navigation in uncertain environments requires planning methods that
integrate risk aversion with active perception. In this work, we present a
unified framework that refines a coarse reference path by constructing
tail-sensitive risk maps from Average Value-at-Risk statistics on an
online-updated 3D Gaussian-splat Radiance Field. These maps enable the
generation of locally safe and feasible trajectories. In parallel, we formulate
Next-Best-View (NBV) selection as an optimization problem on the SE(3) pose
manifold, where Riemannian gradient descent maximizes an expected information
gain objective to reduce uncertainty most critical for imminent motion. Our
approach advances the state-of-the-art by coupling risk-averse path refinement
with NBV planning, while introducing scalable gradient decompositions that
support efficient online updates in complex environments. We demonstrate the
effectiveness of the proposed framework through extensive computational
studies.

</details>


### [19] [What You Don't Know Can Hurt You: How Well do Latent Safety Filters Understand Partially Observable Safety Constraints?](https://arxiv.org/abs/2510.06492)
*Matthew Kim,Kensuke Nakamura,Andrea Bajcsy*

Main category: cs.RO

TL;DR: 该论文研究了基于RGB观测的潜在空间安全控制方法的局限性，提出了一个互信息度量来识别观测无法捕捉安全相关特征的情况，并提出了多模态监督训练策略来改进潜在状态表示。


<details>
  <summary>Details</summary>
Motivation: 现有潜在空间安全控制方法假设安全关键特征在学习的潜在状态中可观测，但实际中RGB观测可能产生短视的安全行为，无法真正预防故障。

Method: 引入基于互信息的度量来预测观测无法捕捉安全相关特征的情况；提出多模态监督训练策略，在训练时使用额外感官输入塑造潜在状态，但部署时无需额外模态。

Result: 在仿真和Franka Research 3机械臂硬件实验中验证了方法有效性，成功防止蜡锅过热。

Conclusion: RGB观测可能不足以捕捉安全相关特征，多模态监督训练可以改善潜在状态表示，实现更有效的安全控制。

Abstract: Safe control techniques, such as Hamilton-Jacobi reachability, provide
principled methods for synthesizing safety-preserving robot policies but
typically assume hand-designed state spaces and full observability. Recent work
has relaxed these assumptions via latent-space safe control, where state
representations and dynamics are learned jointly through world models that
reconstruct future high-dimensional observations (e.g., RGB images) from
current observations and actions. This enables safety constraints that are
difficult to specify analytically (e.g., spilling) to be framed as
classification problems in latent space, allowing controllers to operate
directly from raw observations. However, these methods assume that
safety-critical features are observable in the learned latent state. We ask:
when are latent state spaces sufficient for safe control? To study this, we
examine temperature-based failures, comparable to overheating in cooking or
manufacturing tasks, and find that RGB-only observations can produce myopic
safety behaviors, e.g., avoiding seeing failure states rather than preventing
failure itself. To predict such behaviors, we introduce a mutual
information-based measure that identifies when observations fail to capture
safety-relevant features. Finally, we propose a multimodal-supervised training
strategy that shapes the latent state with additional sensory inputs during
training, but requires no extra modalities at deployment, and validate our
approach in simulation and on hardware with a Franka Research 3 manipulator
preventing a pot of wax from overheating.

</details>


### [20] [Real-Time Glass Detection and Reprojection using Sensor Fusion Onboard Aerial Robots](https://arxiv.org/abs/2510.06518)
*Malakhi Hopkins,Varun Murali,Vijay Kumar,Camillo J Taylor*

Main category: cs.RO

TL;DR: 提出了一种用于小型四旋翼无人机的实时透明障碍物检测与建图系统，融合ToF相机和超声波传感器数据，通过轻量级2D卷积模型检测镜面反射并填补深度图空白区域。


<details>
  <summary>Details</summary>
Motivation: 透明障碍物对自主飞行机器人构成重大挑战，传统感知系统难以检测这些缺乏可识别特征的材料，导致建图不准确和潜在碰撞风险。现有方法通常依赖大型昂贵传感器或高计算量算法，不适合低SWaP机器人。

Method: 融合ToF相机和超声波传感器数据，使用定制轻量级2D卷积模型检测镜面反射，并将深度信息传播到深度图的对应空白区域，使透明障碍物可见。整个流水线在嵌入式处理器上仅占用少量CPU核心资源实时运行。

Result: 在受控和真实世界环境中进行了一系列实验验证，展示了机器人在包含玻璃的室内环境中建图的能力。系统在低SWaP四旋翼无人机上实现了实时透明障碍物建图。

Conclusion: 这是首个在低SWaP四旋翼无人机上仅使用CPU实现实时机载透明障碍物建图的系统，为小型自主飞行机器人提供了可靠的透明障碍物感知能力。

Abstract: Autonomous aerial robots are increasingly being deployed in real-world
scenarios, where transparent obstacles present significant challenges to
reliable navigation and mapping. These materials pose a unique problem for
traditional perception systems because they lack discernible features and can
cause conventional depth sensors to fail, leading to inaccurate maps and
potential collisions. To ensure safe navigation, robots must be able to
accurately detect and map these transparent obstacles. Existing methods often
rely on large, expensive sensors or algorithms that impose high computational
burdens, making them unsuitable for low Size, Weight, and Power (SWaP) robots.
In this work, we propose a novel and computationally efficient framework for
detecting and mapping transparent obstacles onboard a sub-300g quadrotor. Our
method fuses data from a Time-of-Flight (ToF) camera and an ultrasonic sensor
with a custom, lightweight 2D convolution model. This specialized approach
accurately detects specular reflections and propagates their depth into
corresponding empty regions of the depth map, effectively rendering transparent
obstacles visible. The entire pipeline operates in real-time, utilizing only a
small fraction of a CPU core on an embedded processor. We validate our system
through a series of experiments in both controlled and real-world environments,
demonstrating the utility of our method through experiments where the robot
maps indoor environments containing glass. Our work is, to our knowledge, the
first of its kind to demonstrate a real-time, onboard transparent obstacle
mapping system on a low-SWaP quadrotor using only the CPU.

</details>


### [21] [RAISE: A self-driving laboratory for interfacial property formulation discovery](https://arxiv.org/abs/2510.06546)
*Mohammad Nazeri,Sheldon Mei,Jeffrey Watchorn,Alex Zhang,Erin Ng,Tao Wen,Abhijoy Mandal,Kevin Golovin,Alan Aspuru-Guzik,Frank Gu*

Main category: cs.RO

TL;DR: RAISE是一个自主机器人实验室系统，通过贝叶斯优化自动探索液体配方与表面润湿性之间的关系，实现高通量接触角测量和配方优化。


<details>
  <summary>Details</summary>
Motivation: 表面润湿性是生物医学设备、涂层和纺织品的关键设计参数，但液体配方对接触角测量影响很大，需要自动化系统来高效探索配方与润湿性之间的关系。

Method: 开发了RAISE系统，包含液体配方混合、液滴转移、自动图像采集和接触角测量管道，集成贝叶斯优化客户端进行迭代配方探索。

Result: 系统测量速率约每分钟1个接触角，能探索表面活性剂润湿性，通过多目标贝叶斯优化找到符合特定应用目标的最优配方。

Conclusion: RAISE成功展示了在闭环系统中自主连接液体配方与接触角测量的能力，使用多目标贝叶斯优化高效识别符合研究者定义标准的最优配方。

Abstract: Surface wettability is a critical design parameter for biomedical devices,
coatings, and textiles. Contact angle measurements quantify liquid-surface
interactions, which depend strongly on liquid formulation. Herein, we present
the Robotic Autonomous Imaging Surface Evaluator (RAISE), a closed-loop,
self-driving laboratory that is capable of linking liquid formulation
optimization with surface wettability assessment. RAISE comprises a full
experimental orchestrator with the ability of mixing liquid ingredients to
create varying formulation cocktails, transferring droplets of prepared
formulations to a high-throughput stage, and using a pick-and-place camera tool
for automated droplet image capture. The system also includes an automated
image processing pipeline to measure contact angles. This closed loop
experiment orchestrator is integrated with a Bayesian Optimization (BO) client,
which enables iterative exploration of new formulations based on previous
contact angle measurements to meet user-defined objectives. The system operates
in a high-throughput manner and can achieve a measurement rate of approximately
1 contact angle measurement per minute. Here we demonstrate RAISE can be used
to explore surfactant wettability and how surfactant combinations create
tunable formulations that compensate for purity-related variations.
Furthermore, multi-objective BO demonstrates how precise and optimal
formulations can be reached based on application-specific goals. The
optimization is guided by a desirability score, which prioritizes formulations
that are within target contact angle ranges, minimize surfactant usage and
reduce cost. This work demonstrates the capabilities of RAISE to autonomously
link liquid formulations to contact angle measurements in a closed-loop system,
using multi-objective BO to efficiently identify optimal formulations aligned
with researcher-defined criteria.

</details>


### [22] [Safe Obstacle-Free Guidance of Space Manipulators in Debris Removal Missions via Deep Reinforcement Learning](https://arxiv.org/abs/2510.06566)
*Vincent Lam,Robin Chhabra*

Main category: cs.RO

TL;DR: 提出了一种基于TD3强化学习的无模型空间机械臂轨迹规划器，通过多批评网络和课程学习实现安全可靠的太空碎片捕获


<details>
  <summary>Details</summary>
Motivation: 开发能够在追踪非合作目标捕获点的同时避免自碰撞和意外接触的安全轨迹规划方法，解决太空碎片清除任务中的复杂约束问题

Method: 使用TD3强化学习算法，结合局部控制策略进行奇点避免和可操作性增强，采用基于课程的多批评网络（一个关注精确追踪，一个关注碰撞避免）和优先经验回放

Result: 在Matlab/Simulink中模拟的七自由度KUKA LBR iiwa机械臂上验证了框架的有效性，能够生成安全自适应的碎片清除轨迹

Conclusion: 所提出的框架能够为空间机械臂在碎片清除任务中生成安全可靠的轨迹，同时满足多重约束条件

Abstract: The objective of this study is to develop a model-free workspace trajectory
planner for space manipulators using a Twin Delayed Deep Deterministic Policy
Gradient (TD3) agent to enable safe and reliable debris capture. A local
control strategy with singularity avoidance and manipulability enhancement is
employed to ensure stable execution. The manipulator must simultaneously track
a capture point on a non-cooperative target, avoid self-collisions, and prevent
unintended contact with the target. To address these challenges, we propose a
curriculum-based multi-critic network where one critic emphasizes accurate
tracking and the other enforces collision avoidance. A prioritized experience
replay buffer is also used to accelerate convergence and improve policy
robustness. The framework is evaluated on a simulated seven-degree-of-freedom
KUKA LBR iiwa mounted on a free-floating base in Matlab/Simulink, demonstrating
safe and adaptive trajectory generation for debris removal missions.

</details>


### [23] [Assist-As-Needed: Adaptive Multimodal Robotic Assistance for Medication Management in Dementia Care](https://arxiv.org/abs/2510.06633)
*Kruthika Gangaraju,Tanmayi Inaparthy,Jiaqi Yang,Yihao Zheng,Fengpei Yuan*

Main category: cs.RO

TL;DR: 提出了一种基于Pepper机器人的自适应多模态框架，为痴呆症患者提供动态调整的药物管理辅助，从简单提醒到全面指导的渐进式支持。


<details>
  <summary>Details</summary>
Motivation: 现有辅助技术无法适应痴呆症患者能力衰退的变化需求，一刀切的方法损害自主性、加速依赖并增加护理负担。

Method: 使用Pepper机器人实现分层干预模型：从口头提醒到口头+手势提示，再到结合物理导航和逐步指导的完整多模态支持，通过LLM驱动策略和多模态感知实时评估需求。

Result: 在实验室环境中对健康成人和痴呆症护理利益相关者进行初步研究，评估了系统的可用性、可理解性和自适应反馈机制的适当性。

Conclusion: 该工作贡献包括：基于职业治疗原则的自适应辅助框架、通过渐进式支持维护尊严的多模态机器人实现，以及对自适应机器人护理利益相关者看法的实证见解。

Abstract: People living with dementia (PLWDs) face progressively declining abilities in
medication management-from simple forgetfulness to complete task breakdown-yet
most assistive technologies fail to adapt to these changing needs. This
one-size-fits-all approach undermines autonomy, accelerates dependence, and
increases caregiver burden. Occupational therapy principles emphasize matching
assistance levels to individual capabilities: minimal reminders for those who
merely forget, spatial guidance for those who misplace items, and comprehensive
multimodal support for those requiring step-by-step instruction. However,
existing robotic systems lack this adaptive, graduated response framework
essential for maintaining PLWD independence. We present an adaptive multimodal
robotic framework using the Pepper robot that dynamically adjusts assistance
based on real-time assessment of user needs. Our system implements a
hierarchical intervention model progressing from (1) simple verbal reminders,
to (2) verbal + gestural cues, to (3) full multimodal guidance combining
physical navigation to medication locations with step-by-step verbal and
gestural instructions. Powered by LLM-driven interaction strategies and
multimodal sensing, the system continuously evaluates task states to provide
just-enough assistance-preserving autonomy while ensuring medication adherence.
We conducted a preliminary study with healthy adults and dementia care
stakeholders in a controlled lab setting, evaluating the system's usability,
comprehensibility, and appropriateness of adaptive feedback mechanisms. This
work contributes: (1) a theoretically grounded adaptive assistance framework
translating occupational therapy principles into HRI design, (2) a multimodal
robotic implementation that preserves PLWD dignity through graduated support,
and (3) empirical insights into stakeholder perceptions of adaptive robotic
care.

</details>


### [24] [RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training](https://arxiv.org/abs/2510.06710)
*Hongzhi Zang,Mingjie Wei,Si Xu,Yongji Wu,Zhen Guo,Yuanqing Wang,Hao Lin,Liangzhi Shi,Yuqing Xie,Zhexuan Xu,Zhihao Liu,Kang Chen,Wenhao Tang,Quanlu Zhang,Weinan Zhang,Chao Yu,Yu Wang*

Main category: cs.RO

TL;DR: 提出了RLinf-VLA框架，一个用于视觉语言动作模型强化学习的统一高效平台，解决了现有方法缺乏系统比较的问题，在仿真和真实机器人上都表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言动作模型大多使用监督微调，在分布偏移下泛化能力不足。强化学习虽然能直接优化任务性能，但缺乏统一的平台进行公平系统比较。

Method: 设计了RLinf-VLA框架，采用灵活的资源分配设计，实现了渲染、训练和推理的高效集成。特别针对GPU并行化模拟器，实现了混合细粒度流水线分配模式。

Result: 在仿真中，统一模型在130个LIBERO任务上达到98.11%成功率，在25个ManiSkill任务上达到97.66%成功率。真实机器人部署显示RL训练策略比SFT具有更强的泛化能力。

Conclusion: RLinf-VLA为具身智能研究提供了加速和标准化的基础，总结了RL应用于VLA训练的最佳实践，并揭示了这种整合中的新兴模式。

Abstract: Recent progress in vision and language foundation models has significantly
advanced multimodal understanding, reasoning, and generation, inspiring a surge
of interest in extending such capabilities to embodied settings through
vision-language-action (VLA) models. Yet, most VLA models are still trained
with supervised fine-tuning (SFT), which struggles to generalize under
distribution shifts due to error accumulation. Reinforcement learning (RL)
offers a promising alternative by directly optimizing task performance through
interaction, but existing attempts remain fragmented and lack a unified
platform for fair and systematic comparison across model architectures and
algorithmic designs. To address this gap, we introduce RLinf-VLA, a unified and
efficient framework for scalable RL training of VLA models. The system adopts a
highly flexible resource allocation design that addresses the challenge of
integrating rendering, training, and inference in RL+VLA training. In
particular, for GPU-parallelized simulators, RLinf-VLA implements a novel
hybrid fine-grained pipeline allocation mode, achieving a 1.61x-1.88x speedup
in training. Through a unified interface, RLinf-VLA seamlessly supports diverse
VLA architectures (e.g., OpenVLA, OpenVLA-OFT), multiple RL algorithms (e.g.,
PPO, GRPO), and various simulators (e.g., ManiSkill, LIBERO). In simulation, a
unified model achieves 98.11\% across 130 LIBERO tasks and 97.66\% across 25
ManiSkill tasks. Beyond empirical performance, our study distills a set of best
practices for applying RL to VLA training and sheds light on emerging patterns
in this integration. Furthermore, we present preliminary deployment on a
real-world Franka robot, where RL-trained policies exhibit stronger
generalization than those trained with SFT. We envision RLinf-VLA as a
foundation to accelerate and standardize research on embodied intelligence.

</details>


### [25] [SanDRA: Safe Large-Language-Model-Based Decision Making for Automated Vehicles Using Reachability Analysis](https://arxiv.org/abs/2510.06717)
*Yuanfei Lin,Sebastian Illing,Matthias Althoff*

Main category: cs.RO

TL;DR: SanDRA是一个基于大语言模型的可达性分析安全决策框架，用于自动驾驶车辆，通过将LLM生成的动作转化为时序逻辑公式并结合可达性分析来确保驾驶安全。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的自动驾驶决策存在幻觉问题和缺乏车辆动力学集成，无法确保决策安全性。

Method: 首先通过场景描述提示LLM生成并排序可行驾驶动作，然后将这些动作转化为包含形式化交通规则的时序逻辑公式，最后通过可达性分析消除不安全动作。

Result: 在开环和闭环驾驶环境中验证，能够提供可证明安全的驾驶动作，在高密度交通条件下也能保持合法合规。

Conclusion: SanDRA框架能够为基于大语言模型的自动驾驶决策提供安全保障，代码和实验设置已开源。

Abstract: Large language models have been widely applied to knowledge-driven
decision-making for automated vehicles due to their strong generalization and
reasoning capabilities. However, the safety of the resulting decisions cannot
be ensured due to possible hallucinations and the lack of integrated vehicle
dynamics. To address this issue, we propose SanDRA, the first safe
large-language-model-based decision making framework for automated vehicles
using reachability analysis. Our approach starts with a comprehensive
description of the driving scenario to prompt large language models to generate
and rank feasible driving actions. These actions are translated into temporal
logic formulas that incorporate formalized traffic rules, and are subsequently
integrated into reachability analysis to eliminate unsafe actions. We validate
our approach in both open-loop and closed-loop driving environments using
off-the-shelf and finetuned large language models, showing that it can provide
provably safe and, where possible, legally compliant driving actions, even
under high-density traffic conditions. To ensure transparency and facilitate
future research, all code and experimental setups are publicly available at
github.com/CommonRoad/SanDRA.

</details>


### [26] [UniFField: A Generalizable Unified Neural Feature Field for Visual, Semantic, and Spatial Uncertainties in Any Scene](https://arxiv.org/abs/2510.06754)
*Christian Maurer,Snehal Jauhri,Sophie Lueth,Georgia Chalvatzaki*

Main category: cs.RO

TL;DR: UniFField是一个统一的、不确定性感知的神经特征场，结合了视觉、语义和几何特征，并预测每个模态的不确定性，可零样本应用于新环境，支持机器人稳健决策。


<details>
  <summary>Details</summary>
Motivation: 3D场景的全面视觉、几何和语义理解对机器人任务执行至关重要，现有方法存在场景特定性和缺乏不确定性建模的局限性。

Method: 采用基于体素的通用化特征表示，增量集成RGB-D图像，同时更新不确定性估计，支持零样本应用。

Result: 不确定性估计能准确描述场景重建和语义特征预测的模型误差，成功应用于移动机械臂的主动物体搜索任务。

Conclusion: UniFField为机器人提供了稳健决策能力，通过统一的不确定性感知特征场实现了跨场景的通用化3D理解。

Abstract: Comprehensive visual, geometric, and semantic understanding of a 3D scene is
crucial for successful execution of robotic tasks, especially in unstructured
and complex environments. Additionally, to make robust decisions, it is
necessary for the robot to evaluate the reliability of perceived information.
While recent advances in 3D neural feature fields have enabled robots to
leverage features from pretrained foundation models for tasks such as
language-guided manipulation and navigation, existing methods suffer from two
critical limitations: (i) they are typically scene-specific, and (ii) they lack
the ability to model uncertainty in their predictions. We present UniFField, a
unified uncertainty-aware neural feature field that combines visual, semantic,
and geometric features in a single generalizable representation while also
predicting uncertainty in each modality. Our approach, which can be applied
zero shot to any new environment, incrementally integrates RGB-D images into
our voxel-based feature representation as the robot explores the scene,
simultaneously updating uncertainty estimation. We evaluate our uncertainty
estimations to accurately describe the model prediction errors in scene
reconstruction and semantic feature prediction. Furthermore, we successfully
leverage our feature predictions and their respective uncertainty for an active
object search task using a mobile manipulator robot, demonstrating the
capability for robust decision-making.

</details>


### [27] [Distributed 3D Source Seeking via SO(3) Geometric Control of Robot Swarms](https://arxiv.org/abs/2510.06836)
*Jesús Bautista,Héctor García de Marina*

Main category: cs.RO

TL;DR: 提出了一种在SO(3)李群上的几何控制框架，用于具有一阶姿态动力学和恒定平移速度的机器人进行3D源搜索。


<details>
  <summary>Details</summary>
Motivation: 通过在SO(3)上直接工作，避免了欧拉角奇异性和四元数歧义性，提供了唯一的内在方向表示。

Method: 设计了一个比例前馈控制器，确保每个智能体与估计的朝向3D标量场源的上升方向呈指数对齐。控制器适应有界未知变化并保持良好形成的群体编队。

Result: 数值仿真证明了该方法的有效性，所有代码开源提供以确保可重现性。

Conclusion: 该框架为3D源搜索提供了鲁棒且无奇异的控制解决方案，特别适用于多机器人系统的协调搜索任务。

Abstract: This paper presents a geometric control framework on the Lie group SO(3) for
3D source-seeking by robots with first-order attitude dynamics and constant
translational speed. By working directly on SO(3), the approach avoids
Euler-angle singularities and quaternion ambiguities, providing a unique,
intrinsic representation of orientation. We design a proportional feed-forward
controller that ensures exponential alignment of each agent to an estimated
ascending direction toward a 3D scalar field source. The controller adapts to
bounded unknown variations and preserves well-posed swarm formations. Numerical
simulations demonstrate the effectiveness of the method, with all code provided
open source for reproducibility.

</details>


### [28] [Tailoring materials into kirigami robots](https://arxiv.org/abs/2510.07027)
*Saravana Prashanth Murali Babu,Aida Parvaresh,Ahmad Rafsanjani*

Main category: cs.RO

TL;DR: Kirigami剪纸技术在机器人领域具有巨大潜力，通过优化切割图案可制造多功能、轻量化的机器人组件，包括执行器、传感器、电池和控制器，应用于抓取、移动和可穿戴设备等领域。


<details>
  <summary>Details</summary>
Motivation: 利用Kirigami剪纸技术的弯曲主导变形特性，为机器人提供抗拉伸能力和小驱动力下的形状变换能力，开发轻量化、适应性强的机器人解决方案。

Method: 通过优化切割图案来定制Kirigami组件，包括基于Kirigami原理的执行器、传感器、电池和控制器，这些组件可通过不同能源驱动并实现复杂运动。

Result: Kirigami机器人组件展现出可编程复杂运动、电导性与柔顺性的结合、结构内能量存储等特性，成功应用于抓取、移动和可穿戴设备等场景。

Conclusion: Kirigami技术为机器人领域提供了革命性的多功能解决方案，但在切割图案设计和制造工艺优化方面仍面临挑战。

Abstract: Kirigami, the traditional paper-cutting craft, holds immense potential for
revolutionizing robotics by providing multifunctional, lightweight, and
adaptable solutions. Kirigami structures, characterized by their
bending-dominated deformation, offer resilience to tensile forces and
facilitate shape morphing under small actuation forces. Kirigami components
such as actuators, sensors, batteries, controllers, and body structures can be
tailored to specific robotic applications by optimizing cut patterns. Actuators
based on kirigami principles exhibit complex motions programmable through
various energy sources, while kirigami sensors bridge the gap between
electrical conductivity and compliance. Kirigami-integrated batteries enable
energy storage directly within robot structures, enhancing flexibility and
compactness. Kirigami-controlled mechanisms mimic mechanical computations,
enabling advanced functionalities such as shape morphing and memory functions.
Applications of kirigami-enabled robots include grasping, locomotion, and
wearables, showcasing their adaptability to diverse environments and tasks.
Despite promising opportunities, challenges remain in the design of cut
patterns for a given function and streamlining fabrication techniques.

</details>


### [29] [Temporal-Prior-Guided View Planning for Periodic 3D Plant Reconstruction](https://arxiv.org/abs/2510.07028)
*Sicong Pan,Xuying Huang,Maren Bennewitz*

Main category: cs.RO

TL;DR: 提出了一种基于时间先验的周期性植物三维重建视图规划方法，利用先前重建模型指导当前重建过程，减少视图数量和资源消耗。


<details>
  <summary>Details</summary>
Motivation: 周期性3D重建对作物监测至关重要，但传统方法每次从头开始重建浪费资源且忽略历史信息。

Method: 将先前重建模型非刚性对齐到新观测数据形成几何近似，通过膨胀适应植物生长，求解集合覆盖优化问题计算最小视图集，集成完整管道包括额外最佳视图获取和全局最短路径规划。

Result: 在玉米和番茄上的半球和球体视图空间实验中，系统在保持或改善表面覆盖率的同时，所需视图数量更少，移动成本与最先进基线相当。

Conclusion: 该方法能够有效利用时间先验信息，显著减少周期性植物重建所需的视图数量，同时保持良好的重建质量。

Abstract: Periodic 3D reconstruction is essential for crop monitoring, but costly when
each cycle restarts from scratch, wasting resources and ignoring information
from previous captures. We propose temporal-prior-guided view planning for
periodic plant reconstruction, in which a previously reconstructed model of the
same plant is non-rigidly aligned to a new partial observation to form an
approximation of the current geometry. To accommodate plant growth, we inflate
this approximation and solve a set covering optimization problem to compute a
minimal set of views. We integrated this method into a complete pipeline that
acquires one additional next-best view before registration for robustness and
then plans a globally shortest path to connect the planned set of views and
outputs the best view sequence. Experiments on maize and tomato under
hemisphere and sphere view spaces show that our system maintains or improves
surface coverage while requiring fewer views and comparable movement cost
compared to state-of-the-art baselines.

</details>


### [30] [Diffusing Trajectory Optimization Problems for Recovery During Multi-Finger Manipulation](https://arxiv.org/abs/2510.07030)
*Abhinav Kumar,Fan Yang,Sergio Aguilera Marinovic,Soshi Iba,Rana Soltani Zarrin,Dmitry Berenson*

Main category: cs.RO

TL;DR: 提出了一种基于扩散模型的恢复框架，用于多指手在执行精细操作任务时自主检测异常状态并规划接触丰富的恢复轨迹


<details>
  <summary>Details</summary>
Motivation: 多指手在执行精细操作任务时，环境扰动或执行错误会影响任务性能，需要恢复行为来恢复正常任务执行

Method: 使用扩散模型检测任务执行不顺利的状态（OOD检测），通过扩散采样将状态投影回分布内，并用轨迹优化规划接触丰富的恢复轨迹。还提出了一种新的扩散方法，在在线执行时高效扩散恢复轨迹优化问题的完整参数化

Result: 与强化学习基线和其他不显式规划接触交互的方法相比，在硬件螺丝刀转动任务中，使用该方法恢复可将任务性能提高96%，并且是唯一能在不导致灾难性任务失败的情况下尝试恢复的方法

Conclusion: 基于扩散模型的恢复框架能够有效识别异常状态并规划接触丰富的恢复轨迹，显著提高多指手在精细操作任务中的鲁棒性和性能

Abstract: Multi-fingered hands are emerging as powerful platforms for performing fine
manipulation tasks, including tool use. However, environmental perturbations or
execution errors can impede task performance, motivating the use of recovery
behaviors that enable normal task execution to resume. In this work, we take
advantage of recent advances in diffusion models to construct a framework that
autonomously identifies when recovery is necessary and optimizes contact-rich
trajectories to recover. We use a diffusion model trained on the task to
estimate when states are not conducive to task execution, framed as an
out-of-distribution detection problem. We then use diffusion sampling to
project these states in-distribution and use trajectory optimization to plan
contact-rich recovery trajectories. We also propose a novel diffusion-based
approach that distills this process to efficiently diffuse the full
parameterization, including constraints, goal state, and initialization, of the
recovery trajectory optimization problem, saving time during online execution.
We compare our method to a reinforcement learning baseline and other methods
that do not explicitly plan contact interactions, including on a hardware
screwdriver-turning task where we show that recovering using our method
improves task performance by 96% and that ours is the only method evaluated
that can attempt recovery without causing catastrophic task failure. Videos can
be found at https://dtourrecovery.github.io/.

</details>


### [31] [Bring the Apple, Not the Sofa: Impact of Irrelevant Context in Embodied AI Commands on VLA Models](https://arxiv.org/abs/2510.07067)
*Daria Pugacheva,Andrey Moskalenko,Denis Shepelev,Andrey Kuznetsov,Vlad Shakhuro,Elena Tutubalina*

Main category: cs.RO

TL;DR: 该论文系统研究了视觉语言动作(VLA)模型对语言扰动的鲁棒性，发现模型在语义和词汇相似的无相关上下文下性能下降约50%，并提出基于LLM的过滤框架来恢复性能。


<details>
  <summary>Details</summary>
Motivation: VLA模型在具身AI中广泛应用，但其在真实场景中面对自然语言变异的鲁棒性尚未得到充分研究，需要系统评估模型对语言扰动的敏感性。

Method: 评估VLA模型在两种指令噪声下的性能：(1)人工生成的改写指令；(2)添加无相关上下文。进一步将无相关上下文按长度、语义和词汇相似度分类，并提出基于LLM的过滤框架提取核心命令。

Result: 模型性能随上下文扩展而持续下降；对随机上下文相对鲁棒(性能下降<10%)，但对语义词汇相似的上下文性能下降约50%；人工改写指令导致性能下降近20%；提出的过滤框架可使模型在噪声条件下恢复高达98.5%的原始性能。

Conclusion: VLA模型对语言扰动敏感，特别是语义相似的无关上下文会显著影响性能，但通过LLM过滤框架可以有效缓解这一问题，提高模型在实际应用中的鲁棒性。

Abstract: Vision Language Action (VLA) models are widely used in Embodied AI, enabling
robots to interpret and execute language instructions. However, their
robustness to natural language variability in real-world scenarios has not been
thoroughly investigated. In this work, we present a novel systematic study of
the robustness of state-of-the-art VLA models under linguistic perturbations.
Specifically, we evaluate model performance under two types of instruction
noise: (1) human-generated paraphrasing and (2) the addition of irrelevant
context. We further categorize irrelevant contexts into two groups according to
their length and their semantic and lexical proximity to robot commands. In
this study, we observe consistent performance degradation as context size
expands. We also demonstrate that the model can exhibit relative robustness to
random context, with a performance drop within 10%, while semantically and
lexically similar context of the same length can trigger a quality decline of
around 50%. Human paraphrases of instructions lead to a drop of nearly 20%. To
mitigate this, we propose an LLM-based filtering framework that extracts core
commands from noisy inputs. Incorporating our filtering step allows models to
recover up to 98.5% of their original performance under noisy conditions.

</details>


### [32] [Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications](https://arxiv.org/abs/2510.07077)
*Kento Kawaharazuka,Jihoon Oh,Jun Yamada,Ingmar Posner,Yuke Zhu*

Main category: cs.RO

TL;DR: 本文对视觉-语言-动作(VLA)模型进行了全面综述，涵盖软件和硬件组件，旨在为机器人社区提供实际应用指导。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型和视觉语言模型在机器人领域的应用日益增多，VLA模型通过统一视觉、语言和动作数据，旨在学习能够泛化到多样化任务、对象、环境和体现形式的策略，实现更灵活和可扩展的机器人部署。

Method: 采用系统性的全栈式综述方法，整合VLA系统的软件和硬件组件，涵盖策略和架构转换、架构和构建模块、模态特定处理技术、学习范式，以及机器人平台、数据收集策略、数据集、数据增强方法和评估基准。

Result: 提供了VLA模型的全面技术综述，包括训练方法、评估方法、模态和数据集等分类参考，所有参考资料可在项目网站获取。

Conclusion: 本综述为机器人社区在实际机器人系统中应用VLA模型提供了实用指导，促进了VLA技术在真实世界机器人应用中的部署。

Abstract: Amid growing efforts to leverage advances in large language models (LLMs) and
vision-language models (VLMs) for robotics, Vision-Language-Action (VLA) models
have recently gained significant attention. By unifying vision, language, and
action data at scale, which have traditionally been studied separately, VLA
models aim to learn policies that generalise across diverse tasks, objects,
embodiments, and environments. This generalisation capability is expected to
enable robots to solve novel downstream tasks with minimal or no additional
task-specific data, facilitating more flexible and scalable real-world
deployment. Unlike previous surveys that focus narrowly on action
representations or high-level model architectures, this work offers a
comprehensive, full-stack review, integrating both software and hardware
components of VLA systems. In particular, this paper provides a systematic
review of VLAs, covering their strategy and architectural transition,
architectures and building blocks, modality-specific processing techniques, and
learning paradigms. In addition, to support the deployment of VLAs in
real-world robotic applications, we also review commonly used robot platforms,
data collection strategies, publicly available datasets, data augmentation
methods, and evaluation benchmarks. Throughout this comprehensive survey, this
paper aims to offer practical guidance for the robotics community in applying
VLAs to real-world robotic systems. All references categorized by training
approach, evaluation method, modality, and dataset are available in the table
on our project website: https://vla-survey.github.io .

</details>


### [33] [Sampling Strategies for Robust Universal Quadrupedal Locomotion Policies](https://arxiv.org/abs/2510.07094)
*David Rytz,Kim Tien Ly,Ioannis Havoutis*

Main category: cs.RO

TL;DR: 该研究比较了三种关节增益采样策略，用于训练能够泛化到多种参数配置的通用四足机器人运动策略，通过显著随机化关节控制器增益来增强策略的鲁棒性并缩小仿真到现实的差距。


<details>
  <summary>Details</summary>
Motivation: 研究旨在开发能够适应多种物理参数配置的鲁棒通用四足机器人运动策略，解决仿真到现实部署中的泛化问题。

Method: 比较了三种关节增益采样策略：(1) 质量到增益的线性和多项式函数映射；(2) 基于性能的自适应滤波；(3) 均匀随机采样。通过使用名义先验和参考模型偏置配置来增强策略鲁棒性。在RaiSim中进行训练，并在多种四足机器人上进行仿真测试。

Result: 与多个基线实现相比，结果表明需要显著随机化关节控制器增益才能实现鲁棒的仿真到现实差距缩小。策略成功零样本部署到ANYmal四足机器人硬件上。

Conclusion: 关节控制器增益的显著随机化对于实现鲁棒的仿真到现实差距缩小至关重要，所提出的采样策略能够有效训练出泛化能力强的通用运动策略。

Abstract: This work focuses on sampling strategies of configuration variations for
generating robust universal locomotion policies for quadrupedal robots. We
investigate the effects of sampling physical robot parameters and joint
proportional-derivative gains to enable training a single reinforcement
learning policy that generalizes to multiple parameter configurations. Three
fundamental joint gain sampling strategies are compared: parameter sampling
with (1) linear and polynomial function mappings of mass-to-gains, (2)
performance-based adaptive filtering, and (3) uniform random sampling. We
improve the robustness of the policy by biasing the configurations using
nominal priors and reference models. All training was conducted on RaiSim,
tested in simulation on a range of diverse quadrupeds, and zero-shot deployed
onto hardware using the ANYmal quadruped robot. Compared to multiple baseline
implementations, our results demonstrate the need for significant joint
controller gains randomization for robust closing of the sim-to-real gap.

</details>


### [34] [A Digital Twin Framework for Metamorphic Testing of Autonomous Driving Systems Using Generative Model](https://arxiv.org/abs/2510.07133)
*Tony Zhang,Burak Kantarci,Umair Siddique*

Main category: cs.RO

TL;DR: 提出基于数字孪生的蜕变测试框架，结合AI图像生成技术，为自动驾驶系统创建虚拟测试环境，显著提升测试覆盖率和效果。


<details>
  <summary>Details</summary>
Motivation: 解决传统测试方法在自动驾驶安全验证中的局限性，包括预言机问题和无法覆盖所有真实场景的挑战。

Method: 使用数字孪生技术创建自动驾驶系统虚拟副本，结合Stable Diffusion等AI图像生成模型，系统生成多样化驾驶场景，定义基于交通规则的三种蜕变关系。

Result: 在Udacity自动驾驶模拟器中验证，获得最高真阳性率(0.719)、F1分数(0.689)和精确率(0.662)，优于基线方法。

Conclusion: 数字孪生与AI场景生成的结合为自动驾驶安全测试提供了可扩展、自动化且高保真的解决方案。

Abstract: Ensuring the safety of self-driving cars remains a major challenge due to the
complexity and unpredictability of real-world driving environments. Traditional
testing methods face significant limitations, such as the oracle problem, which
makes it difficult to determine whether a system's behavior is correct, and the
inability to cover the full range of scenarios an autonomous vehicle may
encounter. In this paper, we introduce a digital twin-driven metamorphic
testing framework that addresses these challenges by creating a virtual replica
of the self-driving system and its operating environment. By combining digital
twin technology with AI-based image generative models such as Stable Diffusion,
our approach enables the systematic generation of realistic and diverse driving
scenes. This includes variations in weather, road topology, and environmental
features, all while maintaining the core semantics of the original scenario.
The digital twin provides a synchronized simulation environment where changes
can be tested in a controlled and repeatable manner. Within this environment,
we define three metamorphic relations inspired by real-world traffic rules and
vehicle behavior. We validate our framework in the Udacity self-driving
simulator and demonstrate that it significantly enhances test coverage and
effectiveness. Our method achieves the highest true positive rate (0.719), F1
score (0.689), and precision (0.662) compared to baseline approaches. This
paper highlights the value of integrating digital twins with AI-powered
scenario generation to create a scalable, automated, and high-fidelity testing
solution for autonomous vehicle safety.

</details>


### [35] [TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models for Embodied Visual Tracking](https://arxiv.org/abs/2510.07134)
*Jiahang Liu,Yunpeng Qi,Jiazhao Zhang,Minghan Li,Shaoan Wang,Kui Wu,Hanjing Ye,Hong Zhang,Zhibo Chen,Fangwei Zhong,Zhizheng Zhang,He Wang*

Main category: cs.RO

TL;DR: TrackVLA++是一个新颖的视觉-语言-动作模型，通过空间推理机制和目标识别记忆模块，显著提升了具身视觉跟踪在遮挡和干扰场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的语言引导跟踪方法缺乏明确的空间推理和有效的时间记忆，导致在严重遮挡或存在相似干扰物时容易失败。

Method: 提出两个关键模块：1) 空间推理机制(Polar-CoT)，通过思维链范式推断目标相对位置并编码为极坐标令牌；2) 目标识别记忆(TIM)，采用门控更新策略保持长期目标记忆。

Result: 在公开基准测试中达到最先进性能，在EVT-Bench DT分割上分别超过之前领先方法5.1和12个百分点，并展现出强大的零样本泛化能力。

Conclusion: TrackVLA++通过结合空间推理和长期记忆，能够实现动态和遮挡场景下的鲁棒实时跟踪，为具身视觉跟踪提供了有效解决方案。

Abstract: Embodied Visual Tracking (EVT) is a fundamental ability that underpins
practical applications, such as companion robots, guidance robots and service
assistants, where continuously following moving targets is essential. Recent
advances have enabled language-guided tracking in complex and unstructured
scenes. However, existing approaches lack explicit spatial reasoning and
effective temporal memory, causing failures under severe occlusions or in the
presence of similar-looking distractors. To address these challenges, we
present TrackVLA++, a novel Vision-Language-Action (VLA) model that enhances
embodied visual tracking with two key modules, a spatial reasoning mechanism
and a Target Identification Memory (TIM). The reasoning module introduces a
Chain-of-Thought paradigm, termed Polar-CoT, which infers the target's relative
position and encodes it as a compact polar-coordinate token for action
prediction. Guided by these spatial priors, the TIM employs a gated update
strategy to preserve long-horizon target memory, ensuring spatiotemporal
consistency and mitigating target loss during extended occlusions. Extensive
experiments show that TrackVLA++ achieves state-of-the-art performance on
public benchmarks across both egocentric and multi-camera settings. On the
challenging EVT-Bench DT split, TrackVLA++ surpasses the previous leading
approach by 5.1 and 12, respectively. Furthermore, TrackVLA++ exhibits strong
zero-shot generalization, enabling robust real-world tracking in dynamic and
occluded scenarios.

</details>


### [36] [DPL: Depth-only Perceptive Humanoid Locomotion via Realistic Depth Synthesis and Cross-Attention Terrain Reconstruction](https://arxiv.org/abs/2510.07152)
*Jingkai Sun,Gang Han,Pihai Sun,Wen Zhao,Jiahang Cao,Jiaxu Wang,Yijie Guo,Qiang Zhang*

Main category: cs.RO

TL;DR: 提出了一种结合盲主干地形感知运动策略、多模态交叉注意力变换器和真实深度图像合成方法的新框架，用于解决人形机器人地形感知运动的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有地形感知人形机器人运动方法存在训练效率低、sim-to-real差距大、依赖多传感器导致延迟和鲁棒性差等问题，需要新的解决方案。

Method: 使用预训练高程地图感知引导强化学习，通过多模态交叉注意力变换器从噪声深度图像重建地形表示，并采用自遮挡感知光线投射和噪声感知建模合成真实深度图像。

Result: 实现了超过30%的地形重建误差减少，在完整尺寸人形机器人上展示了在多样化挑战性地形上的敏捷自适应运动。

Conclusion: 该框架能够在有限数据和硬件资源下实现高效策略训练，同时保留对泛化至关重要的关键地形特征。

Abstract: Recent advancements in legged robot perceptive locomotion have shown
promising progress. However, terrain-aware humanoid locomotion remains largely
constrained to two paradigms: depth image-based end-to-end learning and
elevation map-based methods. The former suffers from limited training
efficiency and a significant sim-to-real gap in depth perception, while the
latter depends heavily on multiple vision sensors and localization systems,
resulting in latency and reduced robustness. To overcome these challenges, we
propose a novel framework that tightly integrates three key components: (1)
Terrain-Aware Locomotion Policy with a Blind Backbone, which leverages
pre-trained elevation map-based perception to guide reinforcement learning with
minimal visual input; (2) Multi-Modality Cross-Attention Transformer, which
reconstructs structured terrain representations from noisy depth images; (3)
Realistic Depth Images Synthetic Method, which employs self-occlusion-aware ray
casting and noise-aware modeling to synthesize realistic depth observations,
achieving over 30\% reduction in terrain reconstruction error. This combination
enables efficient policy training with limited data and hardware resources,
while preserving critical terrain features essential for generalization. We
validate our framework on a full-sized humanoid robot, demonstrating agile and
adaptive locomotion across diverse and challenging terrains.

</details>


### [37] [A Narwhal-Inspired Sensing-to-Control Framework for Small Fixed-Wing Aircraft](https://arxiv.org/abs/2510.07160)
*Fengze Xie,Xiaozhou Fan,Jacob Schuster,Yisong Yue,Morteza Gharib*

Main category: cs.RO

TL;DR: 提出了一种结合仿生硬件、物理信息动力学学习和凸控制分配的端到端感知控制管道，用于提升固定翼无人机的低速敏捷性。


<details>
  <summary>Details</summary>
Motivation: 固定翼无人机虽然续航和效率优异，但由于高度耦合的动力学特性，在低速时缺乏敏捷性。测量小型机架上的气流很困难，因为近体空气动力学、螺旋桨滑流、控制面作动和环境阵风会扭曲压力信号。

Method: 1. 仿生硬件设计：受独角鲸长牙启发，在前方安装自制多孔探针，并辅以稀疏分布的机翼压力传感器；2. 数据驱动校准：将探针压力映射到空速和流动角度；3. 学习控制仿射动力学模型：使用估计的空速/角度和稀疏传感器；4. 软左右对称正则化器提高可识别性；5. 正则化最小二乘分配器实现平滑、配平的作动。

Result: 风洞研究表明：添加机翼压力可将力估计误差降低25-30%；所提模型在分布偏移下性能下降较少（约12% vs 非结构化基线的44%）；力跟踪性能改善，输入更平滑，法向力RMSE比普通仿射模型降低27%，比非结构化基线降低34%。

Conclusion: 该端到端方法通过仿生传感、物理信息建模和凸优化控制，显著提升了固定翼无人机在宽工作范围内的低速控制性能，特别是在分布偏移下的鲁棒性表现优异。

Abstract: Fixed-wing unmanned aerial vehicles (UAVs) offer endurance and efficiency but
lack low-speed agility due to highly coupled dynamics. We present an end-to-end
sensing-to-control pipeline that combines bio-inspired hardware,
physics-informed dynamics learning, and convex control allocation. Measuring
airflow on a small airframe is difficult because near-body aerodynamics,
propeller slipstream, control-surface actuation, and ambient gusts distort
pressure signals. Inspired by the narwhal's protruding tusk, we mount in-house
multi-hole probes far upstream and complement them with sparse, carefully
placed wing pressure sensors for local flow measurement. A data-driven
calibration maps probe pressures to airspeed and flow angles. We then learn a
control-affine dynamics model using the estimated airspeed/angles and sparse
sensors. A soft left/right symmetry regularizer improves identifiability under
partial observability and limits confounding between wing pressures and
flaperon inputs. Desired wrenches (forces and moments) are realized by a
regularized least-squares allocator that yields smooth, trimmed actuation.
Wind-tunnel studies across a wide operating range show that adding wing
pressures reduces force-estimation error by 25-30%, the proposed model degrades
less under distribution shift (about 12% versus 44% for an unstructured
baseline), and force tracking improves with smoother inputs, including a 27%
reduction in normal-force RMSE versus a plain affine model and 34% versus an
unstructured baseline.

</details>


### [38] [TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics](https://arxiv.org/abs/2510.07181)
*Yi Han,Cheng Chi,Enshen Zhou,Shanyu Rong,Jingkun An,Pengwei Wang,Zhongyuan Wang,Lu Sheng,Shanghang Zhang*

Main category: cs.RO

TL;DR: TIGeR是一个将视觉语言模型从感知估计器转变为几何计算器的框架，通过外部工具生成和执行精确几何计算，实现厘米级精度的机器人操作。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在空间推理中仅限于定性精度，缺乏机器人应用所需的计算精度，无法利用深度传感器和相机标定的度量线索。

Method: 采用两阶段训练管道：监督微调(SFT)和强化微调(RFT)，结合分层奖励设计，使模型能够识别几何推理需求、合成计算代码并调用专门库进行精确计算。

Result: 在几何推理基准测试中达到最先进性能，在真实世界机器人操作任务中展示厘米级精度。

Conclusion: TIGeR框架成功将VLMs转化为几何计算机，通过工具集成实现了机器人操作所需的精确几何推理能力。

Abstract: Vision-Language Models (VLMs) have shown remarkable capabilities in spatial
reasoning, yet they remain fundamentally limited to qualitative precision and
lack the computational precision required for real-world robotics. Current
approaches fail to leverage metric cues from depth sensors and camera
calibration, instead reducing geometric problems to pattern recognition tasks
that cannot deliver the centimeter-level accuracy essential for robotic
manipulation. We present TIGeR (Tool-Integrated Geometric Reasoning), a novel
framework that transforms VLMs from perceptual estimators to geometric
computers by enabling them to generate and execute precise geometric
computations through external tools. Rather than attempting to internalize
complex geometric operations within neural networks, TIGeR empowers models to
recognize geometric reasoning requirements, synthesize appropriate
computational code, and invoke specialized libraries for exact calculations. To
support this paradigm, we introduce TIGeR-300K, a comprehensive
tool-invocation-oriented dataset covering point transformations, pose
estimation, trajectory generation, and spatial compatibility verification,
complete with tool invocation sequences and intermediate computations. Through
a two-stage training pipeline combining supervised fine-tuning (SFT) and
reinforcement fine-tuning (RFT) with our proposed hierarchical reward design,
TIGeR achieves SOTA performance on geometric reasoning benchmarks while
demonstrating centimeter-level precision in real-world robotic manipulation
tasks.

</details>


### [39] [COMPAct: Computational Optimization and Automated Modular design of Planetary Actuators](https://arxiv.org/abs/2510.07197)
*Aman Singh,Deepak Kapa,Suryank Joshi,Shishir Kolathaya*

Main category: cs.RO

TL;DR: COMPAct框架通过计算优化和自动化CAD设计，系统优化四种行星齿轮箱参数，实现质量最小化、宽度最小化和效率最大化，并自动生成可直接3D打印的CAD模型。


<details>
  <summary>Details</summary>
Motivation: 机器人执行器设计中，齿轮箱参数优化和CAD自动化设计研究不足，需要系统化的优化框架来提升执行器性能。

Method: 开发COMPAct框架，对四种行星齿轮箱类型进行参数优化，包括单级行星齿轮箱、复合行星齿轮箱、Wolfrom行星齿轮箱和双级行星齿轮箱，并自动化生成CAD模型。

Result: 实验显示SSPG执行器机械效率60-80%，空载回差0.59度，传动刚度242.7 Nm/rad；CPG执行器效率60%，回差2.6度，刚度201.6 Nm/rad。

Conclusion: 该框架成功实现了齿轮箱参数的优化设计和CAD自动化生成，为不同传动比范围提供了合适的齿轮箱类型选择指导。

Abstract: The optimal design of robotic actuators is a critical area of research, yet
limited attention has been given to optimizing gearbox parameters and
automating actuator CAD. This paper introduces COMPAct: Computational
Optimization and Automated Modular Design of Planetary Actuators, a framework
that systematically identifies optimal gearbox parameters for a given motor
across four gearbox types, single-stage planetary gearbox (SSPG), compound
planetary gearbox (CPG), Wolfrom planetary gearbox (WPG), and double-stage
planetary gearbox (DSPG). The framework minimizes mass and actuator width while
maximizing efficiency, and further automates actuator CAD generation to enable
direct 3D printing without manual redesign. Using this framework, optimal
gearbox designs are explored over a wide range of gear ratios, providing
insights into the suitability of different gearbox types across various gear
ratio ranges. In addition, the framework is used to generate CAD models of all
four gearbox types with varying gear ratios and motors. Two actuator types are
fabricated and experimentally evaluated through power efficiency, no-load
backlash, and transmission stiffness tests. Experimental results indicate that
the SSPG actuator achieves a mechanical efficiency of 60-80 %, a no-load
backlash of 0.59 deg, and a transmission stiffness of 242.7 Nm/rad, while the
CPG actuator demonstrates 60 % efficiency, 2.6 deg backlash, and a stiffness of
201.6 Nm/rad. Code available at:
https://anonymous.4open.science/r/COMPAct-SubNum-3408 Video:
https://youtu.be/99zOKgxsDho

</details>


### [40] [HyPlan: Hybrid Learning-Assisted Planning Under Uncertainty for Safe Autonomous Driving](https://arxiv.org/abs/2510.07210)
*Donald Pfaffmann,Matthias Klusch,Marcel Steinmetz*

Main category: cs.RO

TL;DR: 提出HyPlan混合学习方法，用于解决自动驾驶汽车在部分可观测交通环境中的无碰撞导航问题，结合多智能体行为预测、深度强化学习和在线POMDP规划。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶在部分可观测交通环境中安全导航的挑战，特别是在有行人的关键交通场景中。

Method: 结合多智能体行为预测、近端策略优化的深度强化学习、基于启发式置信度垂直剪枝的近似在线POMDP规划。

Result: 在CARLA-CTS2基准测试中，HyPlan比相关基线方法更安全，比替代在线POMDP规划器执行速度显著更快。

Conclusion: HyPlan方法在不牺牲驾驶安全的前提下，通过垂直剪枝技术有效减少了执行时间，实现了安全高效的自动驾驶导航。

Abstract: We present a novel hybrid learning-assisted planning method, named HyPlan,
for solving the collision-free navigation problem for self-driving cars in
partially observable traffic environments. HyPlan combines methods for
multi-agent behavior prediction, deep reinforcement learning with proximal
policy optimization and approximated online POMDP planning with heuristic
confidence-based vertical pruning to reduce its execution time without
compromising safety of driving. Our experimental performance analysis on the
CARLA-CTS2 benchmark of critical traffic scenarios with pedestrians revealed
that HyPlan may navigate safer than selected relevant baselines and perform
significantly faster than considered alternative online POMDP planners.

</details>


### [41] [DeepXPalm: Tilt and Position Rendering using Palm-worn Haptic Display and CNN-based Tactile Pattern Recognition](https://arxiv.org/abs/2204.03521)
*Altamirano Cabrera Miguel,Sautenkov Oleg,Tirado Jonathan,Fedoseev Aleksey,Kopanev Pavel,Kajimoto Hiroyuki,Tsetserukou Dzmitry*

Main category: cs.RO

TL;DR: 提出了一种基于CNN的倾斜角度和位置检测方法，用于柔性物体遥操作中的触觉反馈系统，显著提升了用户的识别准确率


<details>
  <summary>Details</summary>
Motivation: 柔性物体的遥操作需要高精度和灵巧性，但物体形状的动态变化会导致对其对齐状态的感知模糊，从而造成机器人定位错误

Method: 使用多触点触觉设备LinkGlide和嵌入Robotiq二指夹具的触觉传感器阵列，提出基于卷积神经网络(CNN)的方法来检测抓取柔性物体时的倾斜角度和位置

Result: 通过CNN算法和预设掩码，用户对倾斜角度和位置的识别准确率从直接数据的9.67%提升到82.5%

Conclusion: 基于CNN的倾斜角度和位置检测方法能有效提高柔性物体遥操作中触觉反馈的清晰度和用户感知准确性

Abstract: Telemanipulation of deformable objects requires high precision and dexterity
from the users, which can be increased by kinesthetic and tactile feedback.
However, the object shape can change dynamically, causing ambiguous perception
of its alignment and hence errors in the robot positioning. Therefore, the tilt
angle and position classification problem has to be solved to present a clear
tactile pattern to the user. This work presents a telemanipulation system for
plastic pipettes consisting of a multi-contact haptic device LinkGlide to
deliver haptic feedback at the users' palm and two tactile sensors array
embedded in the 2-finger Robotiq gripper. We propose a novel approach based on
Convolutional Neural Networks (CNN) to detect the tilt and position while
grasping deformable objects. The CNN generates a mask based on recognized tilt
and position data to render further multi-contact tactile stimuli provided to
the user during the telemanipulation. The study has shown that using the CNN
algorithm and the preset mask, tilt, and position recognition by users is
increased from 9.67% using the direct data to 82.5%.

</details>


### [42] [TiltXter: CNN-based Electro-tactile Rendering of Tilt Angle for Telemanipulation of Pasteur Pipettes](https://arxiv.org/abs/2409.15838)
*Miguel Altamirano Cabrera,Jonathan Tirado,Aleksey Fedoseev,Oleg Sautenkov,Vladimir Poliakov,Pavel Kopanev,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: 该论文提出了一种基于卷积神经网络(CNN)的触觉模式生成方法，用于在机器人遥操作中检测可变形物体的倾斜角度，并通过电触觉刺激提高用户的感知精度和操作成功率。


<details>
  <summary>Details</summary>
Motivation: 可变形物体在机器人抓取过程中形状会发生剧烈变化，导致对其对齐状态的感知模糊，从而引起机器人定位和遥操作错误。需要清晰的触觉模式来提高用户在触觉反馈下的精确度和灵巧性。

Method: 开发了一个遥操作系统，包括带有电刺激阵列的Force Dimension Omega.7触觉接口和嵌入Robotiq二指夹爪的触觉传感器阵列。提出基于CNN的方法检测可变形物体倾斜，并生成触觉模式用于电触觉刺激。

Result: 使用CNN算法后，用户倾斜识别率从23.13%(降维数据)提高到57.9%，遥操作成功率从53.12%(降维数据)提高到92.18%(CNN生成的触觉模式)。

Conclusion: 基于CNN的触觉模式生成方法显著提高了用户在遥操作中对可变形物体倾斜的感知能力和操作成功率，验证了该方法在触觉反馈系统中的有效性。

Abstract: The shape of deformable objects can change drastically during grasping by
robotic grippers, causing an ambiguous perception of their alignment and hence
resulting in errors in robot positioning and telemanipulation. Rendering clear
tactile patterns is fundamental to increasing users' precision and dexterity
through tactile haptic feedback during telemanipulation. Therefore, different
methods have to be studied to decode the sensors' data into haptic stimuli.
This work presents a telemanipulation system for plastic pipettes that consists
of a Force Dimension Omega.7 haptic interface endowed with two
electro-stimulation arrays and two tactile sensor arrays embedded in the
2-finger Robotiq gripper. We propose a novel approach based on convolutional
neural networks (CNN) to detect the tilt of deformable objects. The CNN
generates a tactile pattern based on recognized tilt data to render further
electro-tactile stimuli provided to the user during the telemanipulation. The
study has shown that using the CNN algorithm, tilt recognition by users
increased from 23.13\% with the downsized data to 57.9%, and the success rate
during teleoperation increased from 53.12% using the downsized data to 92.18%
using the tactile patterns generated by the CNN.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [43] [Comparing Normal Form Representations for Station-Keeping near Cislunar Libration Points](https://arxiv.org/abs/2510.06368)
*Carson Hunsberger,David Schwab,Roshan Eapen,Puneet Singla*

Main category: eess.SY

TL;DR: 比较Birkhoff和共振两种正规形式在圆形限制性三体问题中表示中心流形轨迹的能力，并引入基于Floquet模式的站保持方法


<details>
  <summary>Details</summary>
Motivation: 正规形式为圆形限制性三体问题中的许多感兴趣轨迹提供了有用的近似，需要系统比较不同正规形式的优缺点

Method: 比较Birkhoff正规形式和共振正规形式，引入类似Floquet模式的站保持方法，通过脉冲机动在轨迹特定点最小化不稳定分量

Result: 提出了三种相同站保持方法的表述，共同涵盖Lyapunov、垂直和晕轨道，以及Lissajous和准晕轨迹

Conclusion: 系统比较了两种正规形式在中心流形轨迹表示中的优势，并建立了统一的站保持框架

Abstract: The normal forms provide useful approximations for many trajectories of
interest within the circular restricted three-body problem. This paper aims to
thoroughly compare two of these forms: the Birkhoff normal form and the
resonant normal form, highlighting the strengths of each for the representation
of center manifold trajectories. A method of station-keeping is introduced,
analogous to Floquet modes, in which the unstable component is minimized at
specific points along a trajectory through impulsive maneuvers. Three different
formulations of the same station-keeping approach are posed, collectively
spanning Lyapunov, vertical, and halo orbits, as well as Lissajous and
quasihalo trajectories.

</details>


### [44] [Three-dimensional Integrated Guidance and Control for Leader-Follower Flexible Formation of Fixed Wing UAVs](https://arxiv.org/abs/2510.06394)
*Praveen Kumar Ranjan,Abhinav Sinha,Yongcan Cao*

Main category: eess.SY

TL;DR: 提出了一种非线性集成制导与控制方法，用于固定翼无人机的柔性编队飞行，考虑高保真气动力学和推力动力学，通过动态表面控制实现编队保持和约束满足。


<details>
  <summary>Details</summary>
Motivation: 传统领导者-跟随者编队方案固定跟随者相对于领导者的位置，限制了编队的灵活性。本文旨在开发一种柔性编队方法，使跟随者能够在半球形区域内保持编队，并适应领导者的剧烈机动。

Method: 采用动态表面控制的反步法，将领导者-跟随者相对距离动态映射到油门指令，将速度方向相对于视线角的动态映射到气动控制面偏转。结合Lyapunov屏障函数确保约束满足。

Result: 严格的稳定性分析保证了所有误差状态的均匀最终有界性，并在存在气动非线性时严格满足约束条件。仿真结果验证了方法的有效性和鲁棒性。

Conclusion: 所提出的IGC方法仅依赖相对信息和机载传感器，无需领导者机动信息，适用于GPS拒止或非合作场景，实现了柔性编队飞行和预期重构能力。

Abstract: This paper presents a nonlinear integrated guidance and control (IGC)
approach for flexible leader-follower formation flight of fixed-wing unmanned
aerial vehicles (UAVs) while accounting for high-fidelity aerodynamics and
thrust dynamics. Unlike conventional leader-follower schemes that fix the
follower's position relative to the leader, the follower is steered to maintain
range and bearing angles (which is the angle between its velocity vector and
its line-of-sight (LOS) with respect to the leader) arbitrarily close to the
prescribed values, enabling the follower to maintain formation on a
hemispherical region behind the leader. The proposed IGC framework directly
maps leader-follower relative range dynamics to throttle commands, and the
follower's velocity orientation relative to the LOS to aerodynamic control
surface deflections. This enables synergism between guidance and control
subsystems. The control design uses a dynamic surface control-based
backstepping approach to achieve convergence to the desired formation set,
where Lyapunov barrier functions are incorporated to ensure the follower's
bearing angle is constrained within specified bounds. Rigorous stability
analysis guarantees uniform ultimate boundedness of all error states and strict
constraint satisfaction in the presence of aerodynamic nonlinearities. The
proposed flexible formation scheme allows the follower to have an orientation
mismatch relative to the leader to execute anticipatory reconfiguration by
transitioning between the relative positions in the admissible formation set
when the leader aggressively maneuvers. The proposed IGC law relies only on
relative information and onboard sensors without the information about the
leader's maneuver, making it suitable for GPS-denied or non-cooperative
scenarios. Finally, we present simulation results to vindicate the
effectiveness and robustness of our approach.

</details>


### [45] [Terrain-Aided Navigation Using a Point Cloud Measurement Sensor](https://arxiv.org/abs/2510.06470)
*Abdülbaki Şanlan,Fatih Erol,Murad Abu-Khalaf,Emre Koyuncu*

Main category: eess.SY

TL;DR: 该论文研究在基于地形的导航中使用点云测量来辅助惯性导航系统，比较了两种点云测量模型：基于光线投射的模型和计算量更小的滑动网格模型，并证明点云测量优于雷达高度计。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过点云测量生成有效的测量创新误差，以辅助惯性导航系统进行非线性状态估计，提高导航精度。

Method: 比较两种点云测量模型：1）基于光线投射的模型，从给定姿态返回预测点云测量；2）滑动网格模型，不需要光线投射，计算量更小。还分析了两种模型的姿态可观测性特性。

Result: 点云测量在导航精度上优于雷达高度计，且两种点云测量模型的选择取决于计算资源。滑动网格模型计算效率更高。

Conclusion: 点云测量比雷达高度计性能更好，具体使用哪种点云测量模型应根据可用计算资源来决定。

Abstract: We investigate the use of a point cloud measurement in terrain-aided
navigation. Our goal is to aid an inertial navigation system, by exploring ways
to generate a useful measurement innovation error for effective nonlinear state
estimation. We compare two such measurement models that involve the scanning of
a digital terrain elevation model: a) one that is based on typical ray-casting
from a given pose, that returns the predicted point cloud measurement from that
pose, and b) another computationally less intensive one that does not require
raycasting and we refer to herein as a sliding grid. Besides requiring a pose,
it requires the pattern of the point cloud measurement itself and returns a
predicted point cloud measurement. We further investigate the observability
properties of the altitude for both measurement models. As a baseline, we
compare the use of a point cloud measurement performance to the use of a radar
altimeter and show the gains in accuracy. We conclude by showing that a point
cloud measurement outperforms the use of a radar altimeter, and the point cloud
measurement model to use depends on the computational resources

</details>


### [46] [Model Predictive Path Integral Control for Roll-to-Roll Manufacturing](https://arxiv.org/abs/2510.06547)
*Christopher Martin,Apurva Patil,Wei Li,Takashi Tanaka,Dongmei Chen*

Main category: eess.SY

TL;DR: 提出了一种基于GPU的模型预测路径积分(MPPI)控制方法，用于滚对滚(R2R)制造系统，相比传统模型预测控制显著提升了张力调节性能。


<details>
  <summary>Details</summary>
Motivation: 滚对滚制造是薄膜材料和印刷电子产品规模化生产的关键技术，但由于子系统交互、非线性和过程扰动等因素，精确控制仍然具有挑战性。

Method: 采用基于GPU的蒙特卡洛采样方法在线高效逼近最优控制，MPPI能够轻松处理不可微成本函数，便于融入复杂制造过程的相关性能标准。

Result: 案例研究表明，MPPI相比传统模型预测控制显著提高了张力调节性能。

Conclusion: MPPI控制方法适用于先进制造中的实时控制需求。

Abstract: Roll-to-roll (R2R) manufacturing is a continuous processing technology
essential for scalable production of thin-film materials and printed
electronics, but precise control remains challenging due to subsystem
interactions, nonlinearities, and process disturbances. This paper proposes a
Model Predictive Path Integral (MPPI) control formulation for R2R systems,
leveraging a GPU-based Monte-Carlo sampling approach to efficiently approximate
optimal controls online. Crucially, MPPI easily handles non-differentiable cost
functions, enabling the incorporation of complex performance criteria relevant
to advanced manufacturing processes. A case study is presented that
demonstrates that MPPI significantly improves tension regulation performance
compared to conventional model predictive control (MPC), highlighting its
suitability for real-time control in advanced manufacturing.

</details>


### [47] [A Cascade of Systems and the Product of Their $θ$-Symmetric Scaled Relative Graphs](https://arxiv.org/abs/2510.06583)
*Xiaokan Yang,Ding Zhang,Wei Chen,Li Qiu*

Main category: eess.SY

TL;DR: 提出了一种θ对称缩放相对图方法，用于分析级联系统的反馈互联稳定性，相比传统方法能处理循环互联并提供更不保守的结果。


<details>
  <summary>Details</summary>
Motivation: 传统图形分离方法无法处理循环互联问题，需要一种能同时整合增益和相位信息的统一图形表征方法。

Method: 利用θ对称缩放相对图的次乘性质，开发图形稳定性判据，该方法能精确还原标量情况，更适合作为经典奈奎斯特图的多输入多输出扩展。

Result: θ对称SRG比标准SRG更适合作为MIMO系统的奈奎斯特图扩展，能更好地捕捉系统特性并获得更不保守的结果。

Conclusion: θ对称缩放相对图方法为级联系统反馈互联提供了有效的图形稳定性分析工具，特别适用于传统方法无法处理的循环互联场景。

Abstract: In this paper, we utilize a variant of the scaled relative graph (SRG),
referred to as the $\theta$-symmetric SRG, to develop a graphical stability
criterion for the feedback interconnection of a cascade of systems. A crucial
submultiplicative property of $\theta$-symmetric SRG is established, enabling
it to handle cyclic interconnections for which conventional graph separation
methods are not applicable. By integrating both gain and refined phase
information, the $\theta$-symmetric SRG provides a unified graphical
characterization of the system, which better captures system properties and
yields less conservative results. In the scalar case, the $\theta$-symmetric
SRG can be reduced exactly to the scalar itself, whereas the standard SRG
appears to be a conjugate pair. Consequently, the frequency-wise
$\theta$-symmetric SRG is more suitable than the standard SRG as a multi-input
multi-output extension of the classical Nyquist plot. Illustrative examples are
included to demonstrate the effectiveness of the $\theta$-symmetric SRG.

</details>


### [48] [Delay Independent Safe Control with Neural Networks: Positive Lur'e Certificates for Risk Aware Autonomy](https://arxiv.org/abs/2510.06661)
*Hamidreza Montazeri Hedesh,Milad Siami*

Main category: eess.SY

TL;DR: 提出了一种针对自主学习控制系统的风险感知安全认证方法，通过局部扇区边界建模神经网络控制器，利用正性结构推导线性、延迟无关的证书，保证在允许不确定性下的局部指数稳定性。


<details>
  <summary>Details</summary>
Motivation: 针对自主学习控制系统中存在的状态/输入延迟和区间矩阵不确定性两种现实风险，需要提供可扩展的安全保证来补充风险感知控制。

Method: 使用局部扇区边界对神经网络控制器进行建模，利用正性结构推导线性、延迟无关的认证证书，并与最先进的IQC神经网络验证流程进行性能对比。

Result: 在代表性案例中，基于正性的测试比基于SDP的IQC快几个数量级，同时能够认证后者无法处理的机制。

Conclusion: 该方法提供了可扩展的安全保证，能够有效补充风险感知控制，在保证安全性的同时显著提高了计算效率。

Abstract: We present a risk-aware safety certification method for autonomous, learning
enabled control systems. Focusing on two realistic risks, state/input delays
and interval matrix uncertainty, we model the neural network (NN) controller
with local sector bounds and exploit positivity structure to derive linear,
delay-independent certificates that guarantee local exponential stability
across admissible uncertainties. To benchmark performance, we adopt and
implement a state-of-the-art IQC NN verification pipeline. On representative
cases, our positivity-based tests run orders of magnitude faster than SDP-based
IQC while certifying regimes the latter cannot-providing scalable safety
guarantees that complement risk-aware control.

</details>


### [49] [Resilient Multi-Dimensional Consensus and Distributed Optimization against Agent-Based and Denial-of-Service Attacks](https://arxiv.org/abs/2510.06835)
*Hongjian Chen,Changyun Wen,Xiaolei Li,Jiaqi Yan*

Main category: eess.SY

TL;DR: 提出基于"辅助点"的弹性控制算法，解决多智能体系统在代理攻击和DoS攻击下的多维度共识和分布式优化问题


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统同时面临代理攻击（恶意、拜占庭、顽固代理）和DoS攻击时的弹性共识和优化问题，确保良性代理达成共识

Method: 使用"辅助点"弹性控制算法，每个健康代理构建"安全核"并更新状态；DoS期间使用最近接收的状态；提出弹性多维度分布式优化算法

Result: 理论证明和数值示例验证了所提算法的有效性

Conclusion: 所提出的算法能够有效应对代理攻击和DoS攻击，确保多智能体系统在多维共识和分布式优化中的弹性性能

Abstract: In this paper, we consider the resilient multi-dimensional consensus and
distributed optimization problems of multi-agent systems (MASs) in the presence
of both agent-based and denial-of-service (DoS) attacks. The considered
agent-based attacks can cover malicious, Byzantine, and stubborn agents. The
links between agents in the network can be blocked by DoS attacks, which may
lead the digraph to be time-varying and even disconnected. The objective is to
ensure that the remaining benign agents achieve consensus. To this end, an
"auxiliary point"-based resilient control algorithm is proposed for MASs. Under
the proposed algorithm, each healthy agent constructs a "safe kernel" utilizing
the states of its in-neighbors and updates its state toward a specific point
within this kernel at each iteration. If an agent cannot receive its neighbors'
states owing to DoS attacks, it will use the states received immediately before
the DoS period. Moreover, a resilient multi-dimensional distributed
optimization (RMDO) algorithm is also proposed. Theoretical proofs and
numerical examples are presented to demonstrate the effectiveness of the
proposed algorithms.

</details>


### [50] [Decentralized CBF-based Safety Filters for Collision Avoidance of Cooperative Missile Systems with Input Constraints](https://arxiv.org/abs/2510.06846)
*Johannes Autenrieb,Mark Spiller*

Main category: eess.SY

TL;DR: 提出了一种用于多智能体航天拦截场景的分散式安全滤波器，通过鲁棒控制屏障函数保证安全集的正向不变性，使用事件触发机制提高可扩展性，并通过松弛变量方案解决可行性问题。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体航天拦截场景中的碰撞避免问题，需要在保证安全性的同时维持系统的可扩展性和计算效率。

Method: 采用鲁棒控制屏障函数(RCBFs)和局部二次规划(QP)，结合基于距离和零努力脱靶量(ZEM)的事件触发机制，以及松弛变量方案来处理同时约束。

Result: 仿真结果表明，该框架在多对多拦截场景中能够保持无碰撞操作，且对名义制导的偏离最小，提供了计算高效且可扩展的解决方案。

Conclusion: 所提出的分散式安全滤波器为安全关键的多智能体航天系统提供了一种有效的碰撞避免方法，具有良好的可扩展性和计算效率。

Abstract: This paper presents a decentralized safety filter for collision avoidance in
multi-agent aerospace interception scenarios. The approach leverages robust
control barrier functions (RCBFs) to guarantee forward invariance of safety
sets under bounded inputs and high-relative-degree dynamics. Each effector
executes its nominal cooperative guidance command, while a local quadratic
program (QP) modifies the input only when necessary. Event-triggered activation
based on range and zero-effort miss (ZEM) criteria ensures scalability by
restricting active constraints to relevant neighbors. To resolve feasibility
issues from simultaneous constraints, a slack-variable relaxation scheme is
introduced that prioritizes critical agents in a Pareto-optimal manner.
Simulation results in many-on-many interception scenarios demonstrate that the
proposed framework maintains collision-free operation with minimal deviation
from nominal guidance, providing a computationally efficient and scalable
solution for safety-critical multi-agent aerospace systems.

</details>


### [51] [Falsification-Driven Reinforcement Learning for Maritime Motion Planning](https://arxiv.org/abs/2510.06970)
*Marlon Müller,Florian Finkeldei,Hanna Krasowski,Murat Arcak,Matthias Althoff*

Main category: eess.SY

TL;DR: 提出了一种基于反例驱动的强化学习方法，通过生成违反海事交通规则的对抗性训练场景来提高自主船舶的规则遵守能力。


<details>
  <summary>Details</summary>
Motivation: 训练强化学习代理遵守海事交通规则具有挑战性，因为代理行为受训练场景影响，而创建能捕捉海事导航复杂性的场景很困难，仅靠真实数据不足。

Method: 采用反例驱动的强化学习方法，生成违反信号时序逻辑规范的海事交通规则的对抗性训练场景。

Result: 在双船开放海域导航实验中，该方法提供了更相关的训练场景，并实现了更一致的规则遵守。

Conclusion: 反例驱动的强化学习方法能有效生成对抗性训练场景，提高自主船舶对海事交通规则的遵守能力。

Abstract: Compliance with maritime traffic rules is essential for the safe operation of
autonomous vessels, yet training reinforcement learning (RL) agents to adhere
to them is challenging. The behavior of RL agents is shaped by the training
scenarios they encounter, but creating scenarios that capture the complexity of
maritime navigation is non-trivial, and real-world data alone is insufficient.
To address this, we propose a falsification-driven RL approach that generates
adversarial training scenarios in which the vessel under test violates maritime
traffic rules, which are expressed as signal temporal logic specifications. Our
experiments on open-sea navigation with two vessels demonstrate that the
proposed approach provides more relevant training scenarios and achieves more
consistent rule compliance.

</details>


### [52] [Mitigating Increase-Decrease Gaming with Alternative Connection Agreements: A Defender-Attacker-Defender Game](https://arxiv.org/abs/2510.07102)
*Bart van der Holst,Thomas Swarts,Phuong Nguyen,Johan Morren,Koen Kok*

Main category: eess.SY

TL;DR: 本文提出了一种新颖的防御者-攻击者-防御者博弈模型，研究在配电网中通过替代连接协议(ACAs)来限制市场参与者的可用连接容量，以应对灵活性服务提供商(FSPs)的策略性基准调整行为，从而降低再调度成本。


<details>
  <summary>Details</summary>
Motivation: 再调度市场被系统运营商广泛用于管理网络拥塞，但灵活性服务提供商可能会策略性地调整其基准以预期再调度行动，从而加剧拥塞并提高系统成本。

Method: 建立了一个三层次优化模型，使用自定义的分支定界算法求解，在大多数模拟场景中无需探索分支定界搜索树中的许多节点即可高效解决问题。

Result: 案例研究表明，应用替代连接协议可以显著降低配电网运营商的再调度成本(例如降低25%)，同时对灵活性服务提供商的利润影响有限。

Conclusion: 该方法的有效性关键取决于配电网运营商能够调用替代连接协议的频率，以及其能够预期灵活性服务提供商策略性投标行为的程度。

Abstract: Redispatch markets are widely used by system operators to manage network
congestion. A well-known drawback, however, is that Flexibility Service
Providers (FSPs) may strategically adjust their baselines in anticipation of
redispatch actions, thereby aggravating congestion and raising system costs. To
address this increase-decrease gaming, Distribution System Operators (DSOs)
could use Alternative Connection Agreements (ACAs) to conditionally limit the
available connection capacity of market participants in the day-ahead stage. In
this paper, we present a novel Defender-Attacker-Defender game to investigate
the potential of this approach in distribution networks under load and price
uncertainty. We solve the resulting trilevel optimization model using a custom
branch-and-bound algorithm, and we demonstrate that it efficiently solves the
problem without exploring many nodes in the branch-and-bound search tree for
most simulated scenarios. The case study demonstrates that applying ACAs can
substantially lower redispatch costs (e.g. by 25%) for the DSO with only a
limited impact on FSP profits. The effectiveness of the approach critically
depends on how often the DSO can invoke ACAs and on the extent to which the DSO
can anticipate strategic bidding behavior of the FSP.

</details>


### [53] [Identification and optimal control strategies for the transversal splitting of ultra--cold Bose gases](https://arxiv.org/abs/2510.07113)
*Nikolaus Würkner,Yevhenii Kuriatnikov,Karthikeyan Kumaran,Marupaka Venkat Ramana,Jörg Schmiedmayer,Andreas Kugi,Maximilian Prüfer,Andreas Deutschmann-Olek*

Main category: eess.SY

TL;DR: 提出了一种基于数据驱动模型的BEC分裂最优控制框架，通过系统辨识和间接最优控制实现快速高保真态转移


<details>
  <summary>Details</summary>
Motivation: BEC分裂在基础物理实验和量子技术中至关重要，需要快速且相干地控制凝聚体的非线性动力学来精确制备初始态

Method: 基于有限实验数据建立物理可解释的降阶模型，结合最优实验选择和约束非线性参数估计进行系统校准，使用间接最优控制计算能量最优轨迹实现绝热捷径

Result: 实验验证了该控制框架在多种配置下实现高保真态转移，展示了其在量子控制应用中的鲁棒性和可扩展性

Conclusion: 该工作为BEC分裂提供了一种系统性的最优控制方法，能够在最小实验开销下实现快速高保真量子态操控

Abstract: Splitting a Bose--Einstein condensate (BEC) is a key operation in fundamental
physics experiments and emerging quantum technologies, where precise
preparation of well--defined initial states requires fast yet coherent control
of the condensate's nonlinear dynamics. This work formulates the BEC splitting
process as an optimal feedforward control problem based on a physically
interpretable, reduced--order model identified from limited experimental data.
We introduce a systematic calibration strategy that combines optimal experiment
selection and constrained nonlinear parameter estimation, enabling accurate
system identification with minimal experimental overhead. Using this calibrated
model, we compute energy--optimal trajectories via indirect optimal control to
realize shortcuts to adiabaticity (STAs), achieving rapid transitions to the
ground state of a double--well potential while suppressing excitations.
Experiments confirm that the proposed control framework yields high--fidelity
state transfers across multiple configurations, demonstrating its robustness
and scalability for quantum control applications.

</details>


### [54] [Stability Preserving Safe Control of a Bicopter](https://arxiv.org/abs/2510.07145)
*Jhon Manuel Portella Delgado,Ankit Goel*

Main category: eess.SY

TL;DR: 提出一种多旋翼飞行器的安全约束控制方法，通过状态映射将约束控制问题转化为无约束问题，实现安全集的保持和轨迹跟踪。


<details>
  <summary>Details</summary>
Motivation: 传统控制屏障函数方法需要在每个步骤求解约束优化问题，计算负担大。需要一种能够保证安全约束同时确保稳定性和性能的显式控制律。

Method: 使用状态依赖映射将约束控制问题转化为无约束问题，结合精心构造的Lyapunov函数，实现控制律的显式合成，无需每一步求解约束优化。

Result: 仿真结果表明，该方法在多边形参考轨迹约束在指定安全区域内的情况下有效工作，能够同时保证安全性和跟踪性能。

Conclusion: 所提出的方法通过状态映射技术成功解决了多旋翼飞行器的安全约束控制问题，在保证安全集不变性的同时实现了平滑的轨迹跟踪性能。

Abstract: This paper presents a control law for stabilization and trajectory tracking
of a multicopter subject to safety constraints. The proposed approach
guarantees forward invariance of a prescribed safety set while ensuring smooth
tracking performance. Unlike conventional control barrier function methods, the
constrained control problem is transformed into an unconstrained one using
state-dependent mappings together with carefully constructed Lyapunov
functions. This approach enables explicit synthesis of the control law, instead
of requiring a solution of constrained optimization at each step. The
transformation also enables the controller to enforce safety without
sacrificing stability or performance. Simulation results for a polytopic
reference trajectory confined within a designated safe region demonstrate the
effectiveness of the proposed method.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [55] [A Mixed-Methods Analysis of Repression and Mobilization in Bangladesh's July Revolution Using Machine Learning and Statistical Modeling](https://arxiv.org/abs/2510.06264)
*Md. Saiful Bari Siddiqui,Anupam Debashis Roy*

Main category: stat.AP

TL;DR: 该研究分析了2024年孟加拉国七月革命中政府暴力镇压如何适得其反，反而推动了学生主导的公民起义的成功。研究发现，致命的暴力镇压引发了全国范围的动员，这种反效果是非线性的，由特定的道德冲击触发并通过视觉传播加速。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解释七月革命中的核心悖论：为何政府旨在压制异议的暴力镇压最终反而推动了运动的胜利。

Method: 采用混合方法：首先建立冲突时间线的定性叙述以生成可检验假设，然后使用事件级数据集进行多方法定量分析，包括双向固定效应面板模型、向量自回归分析和机器学习方法。

Result: 研究发现存在显著的本地镇压反效果，致命暴力增加会立即引发全国范围的动员。这种反效果是非线性的，在冲突早期不显著，但在7月16日第一波致命暴力及其视觉传播后触发。机器学习分析确认"对抗议者过度使用武力"是全国范围升级的最主要预测因子。

Conclusion: 七月革命是由偶然的、非线性的反效果驱动的，由特定的催化性道德冲击触发，并通过国家暴力的视觉奇观的病毒式传播而加速。

Abstract: The 2024 July Revolution in Bangladesh represents a landmark event in the
study of civil resistance. This study investigates the central paradox of the
success of this student-led civilian uprising: how state violence, intended to
quell dissent, ultimately fueled the movement's victory. We employ a
mixed-methods approach. First, we develop a qualitative narrative of the
conflict's timeline to generate specific, testable hypotheses. Then, using a
disaggregated, event-level dataset, we employ a multi-method quantitative
analysis to dissect the complex relationship between repression and
mobilisation. We provide a framework to analyse explosive modern uprisings like
the July Revolution. Initial pooled regression models highlight the crucial
role of protest momentum in sustaining the movement. To isolate causal effects,
we specify a Two-Way Fixed Effects panel model, which provides robust evidence
for a direct and statistically significant local suppression backfire effect.
Our Vector Autoregression (VAR) analysis provides clear visual evidence of an
immediate, nationwide mobilisation in response to increased lethal violence. We
further demonstrate that this effect was non-linear. A structural break
analysis reveals that the backfire dynamic was statistically insignificant in
the conflict's early phase but was triggered by the catalytic moral shock of
the first wave of lethal violence, and its visuals circulated around July 16th.
A complementary machine learning analysis (XGBoost, out-of-sample R$^{2}$=0.65)
corroborates this from a predictive standpoint, identifying "excessive force
against protesters" as the single most dominant predictor of nationwide
escalation. We conclude that the July Revolution was driven by a contingent,
non-linear backfire, triggered by specific catalytic moral shocks and
accelerated by the viral reaction to the visual spectacle of state brutality.

</details>


### [56] [Estimating temporary emigration from capture-recapture data in the presence of latent identification](https://arxiv.org/abs/2510.06755)
*Katarina Skopalova,Jafet Osuna,Wei Zhang*

Main category: stat.AP

TL;DR: 提出了一种新的潜在多项临时迁出建模框架，用于分析具有潜在个体识别的捕获-重捕获数据，解决了传统模型无法处理临时迁出和个体识别不完整的问题。


<details>
  <summary>Details</summary>
Motivation: 传统捕获-重捕获模型假设个体不迁出或永久迁出采样区域，但现实中个体可能临时离开后返回，这会导致推断偏差。现有临时迁出模型要求个体被唯一正确识别，而无法处理潜在个体识别问题。

Method: 开发了潜在多项临时迁出建模框架，适用于封闭和开放种群问题，可处理有无个体识别的数据，并能灵活纳入不同迁出过程（完全随机和马尔可夫迁出）。

Result: 模拟研究表明模型参数在各种迁出情景下都能可靠估计。应用于金曼特拉蛙的实际数据集显示，考虑临时迁出比不考虑的模型能更好地拟合数据。

Conclusion: 该框架为处理具有潜在个体识别的捕获-重捕获数据中的临时迁出问题提供了有效解决方案，提高了种群参数估计的准确性。

Abstract: Most capture-recapture models assume that individuals either do not emigrate
or emigrate permanently from the sampling area during the sampling period. This
assumption is violated when individuals temporarily leave the sampling area and
return during later capture occasions, which can result in biased or less
precise inferences under normal capture-recapture models. Existing temporary
emigration models require that individuals are uniquely and correctly
identified. To our knowledge, no studies to date have addressed temporary
emigration in the presence of latent individual identification, which can arise
in many scenarios such as misidentification, data integration, and batch
marking. In this paper, we propose a new latent multinomial temporary
emigration modelling framework for analysing capture-recapture data with latent
identification. The framework is applicable to both closed- and open-population
problems, accommodates data with or without individual identification, and
flexibly incorporates different emigration processes, including the completely
random and Markovian emigration. Through simulations, we demonstrate that model
parameters can be reliably estimated in various emigration scenarios. We apply
the proposed framework to a real dataset on golden mantella collected using
batch marks under Pollock's robust design. The results show that accounting for
temporary emigration provides a better fit to the data compared to the previous
model without temporary emigration.

</details>


### [57] [Estimating Real Demand Using a Flipped Queueing Model: A Case of Shared Micro-Mobility Services](https://arxiv.org/abs/2510.07194)
*Binyu Yang,Jinxiao Du,Junlin He,Shi An,Wei Ma*

Main category: stat.AP

TL;DR: 提出了一种估计共享微出行服务真实需求的方法，通过引入广义车辆生存时间(GVST)和翻转排队模型(FQM)，将真实需求估计问题转化为逆排队问题，提供了闭式解和系统方程两种解决方案。


<details>
  <summary>Details</summary>
Motivation: 共享微出行服务中供需时空不平衡导致观测需求被截断，无法准确记录真实需求，这影响了需求预测、车队管理等下游应用的可靠性。现有研究尚未很好地解决如何准确估计真实需求的问题。

Method: 提出广义车辆生存时间(GVST)作为可观测变量，引入翻转排队模型(FQM)描述GVST与真实需求的关系，将问题转化为逆排队问题。提供单边估计(闭式解)和双边估计(方程组)两种方法。

Result: 使用合成数据和真实世界数据集验证，两种方法均优于基准模型。单边方法提供闭式解且精度可接受，可作为需求相关分析和决策的实用经验法则。

Conclusion: 该方法能有效估计共享微出行服务的真实需求，解决了观测需求截断问题，为需求预测和运营管理提供了可靠工具。

Abstract: The spatial-temporal imbalance between supply and demand in shared
micro-mobility services often leads to observed demand being censored,
resulting in incomplete records of the underlying real demand. This phenomenon
undermines the reliability of the collected demand data and hampers downstream
applications such as demand forecasting, fleet management, and micro-mobility
planning. How to accurately estimate the real demand is challenging and has not
been well explored in existing studies. In view of this, we contribute to real
demand estimation for shared micro-mobility services by proposing an analytical
method that rigorously derives the real demand under appropriate assumptions.
Rather than directly modeling the intractable relationship between observed
demand and real demand, we propose a novel random variable, Generalized Vehicle
Survival Time (GVST), which is observable from trip records. The relationship
between GVST and real demand is characterized by introducing a flipped queueing
model (FQM) that captures the operational dynamics of shared micro-mobility
services. Specifically, the distribution of GVST is derived within the FQM,
which allows the real demand estimation problem to be transformed into an
inverse queueing problem. We analytically derive the real demand in closed form
using a one-sided estimation method, and solve the problem by a system of
equations in a two-sided estimation method. We validate the proposed methods
using synthetic data and conduct empirical analyses using real-world datasets
from bike-sharing and shared e-scooter systems. The experimental results show
that both the two-sided and one-sided methods outperform benchmark models. In
particular, the one-sided approach provides a closed-form solution that
delivers acceptable accuracy, constituting a practical rule of thumb for
demand-related analytics and decision-making processes.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [58] [Artificial Intelligence in Port Logistics: A Bibliometric Analysis of Technological Integration and Research Dynamics](https://arxiv.org/abs/2510.06556)
*Abdelhafid Khazzar,Yassine Sekaki,Yasser Lachhab,Said El-marzouki*

Main category: econ.TH

TL;DR: 该研究探讨了人工智能在港口向智慧港口转型过程中对物流运营的变革，通过文献计量分析123篇相关文献，提出了从数据准备到预测优化再到组织整合的实施路径，并为公共政策提供建议。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索人工智能如何推动港口物流运营的智能化转型，特别是在智慧港口建设背景下，整合资源分析、动态能力和社会技术实施，以增强系统在干扰下的韧性。

Method: 采用Scopus文献计量研究方法，系统分析123篇文章，包括搜索协议、文档筛选和重复验证，运用科学图谱技术分析关键词关系、共引、文献耦合，构建主题地图和多重对应分析。

Result: 研究建立了AI应用与智慧港口领域的具体数据到影响路径，提供了一种可更新的文献计量分析方法，提出了从数据准备到预测优化再到组织整合的分步实施方法。

Conclusion: 研究为公共政策提供了数据共享标准和环境效益评估建议，并计划未来结合实地测试和多港口评估，以增强因果理解和研究适用性。

Abstract: The paper explores the transformation of port logistics operations with
artificial intelligence during the port transformation into a smart port. The
research integrates capabilities-based resource analysis and dynamic
capabilities with sociotechnicalimplementations of technologies and resilience
approaches of complex systems under disruptions. The system applies robustdata
infrastructures to propel analytical and AI modules that become effective once
integrated with sufficient governance systems and trained personnel and
operational processes to transform planning and safety and sustainability
operations.It applies Scopus bibliometric research to analyze 123 articles
using a systematic approach with both a search protocol and a document
screening and duplication verification. It incorporates annual behavior and
distribution of author and country performance analysis with science mapping
techniques that explore keyword relation and co-citation and bibliographic
coupling and conceptual structuring tools that construct thematic maps and
multiple correspondence analysis with community detection while applying
explicit thresholding and robust tests.The research connects AI applications to
smart port domains through specific data-to-impact pathways while providing a
method for bibliometric analysis that enables future updates. The research
presents a step-by-step approach for data readiness followed by predictive and
optimization implementation and organizational integration. The paper supports
public policy through recommendations for data sharing standards and complete
environmental benefit assessments. The research proposes a future study plan
whichcombines field-based testing with multiple port assessments to enhance
both cause-effect understanding and research applicability.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [59] [AlphaApollo: Orchestrating Foundation Models and Professional Tools into a Self-Evolving System for Deep Agentic Reasoning](https://arxiv.org/abs/2510.06261)
*Zhanke Zhou,Chentao Cao,Xiao Feng,Xuan Li,Zongze Li,Xiangyu Lu,Jiangchao Yao,Weikai Huang,Linrui Xu,Tian Cheng,Guanyu Jiang,Yiming Zheng,Brando Miranda,Tongliang Liu,Sanmi Koyejo,Masashi Sugiyama,Bo Han*

Main category: cs.AI

TL;DR: AlphaApollo是一个自演化的智能推理系统，通过整合多个模型和专业工具来解决基础模型推理能力有限和测试时迭代不可靠的问题，在AIME 2024/2025评估中显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决基础模型推理能力有限和测试时迭代不可靠两个瓶颈问题，提升模型的实际推理能力。

Method: 通过编排多个模型和专业工具实现深思熟虑、可验证的推理，结合计算工具（Python数值和符号库）和检索工具（任务相关外部信息）执行精确计算和决策基础，使用共享状态地图支持多轮多模型解决方案演化。

Result: 在AIME 2024/2025评估中，Qwen2.5-14B-Instruct模型获得+5.15% Average@32和+23.34% Pass@32提升，Llama-3.3-70B-Instruct模型获得+8.91% Average@32和+26.67% Pass@32提升，超过80%的工具调用成功执行。

Conclusion: AlphaApollo系统能够有效提升基础模型的推理能力上限，通过工具使用和迭代优化实现性能的显著提升。

Abstract: We present AlphaApollo, a self-evolving agentic reasoning system that aims to
address two bottlenecks in foundation model (FM) reasoning-limited
model-intrinsic capacity and unreliable test-time iteration. AlphaApollo
orchestrates multiple models with professional tools to enable deliberate,
verifiable reasoning. It couples (i) a computation tool (Python with numerical
and symbolic libraries) and (ii) a retrieval tool (task-relevant external
information) to execute exact calculations and ground decisions. The system
further supports multi-round, multi-model solution evolution via a shared state
map that records candidates, executable checks, and feedback for iterative
refinement. In evaluations on AIME 2024/2025 across multiple models,
AlphaApollo delivers consistent gains: +5.15% Average@32 and +23.34% Pass@32
for Qwen2.5-14B-Instruct, and +8.91% Average@32 with +26.67% Pass@32 for
Llama-3.3-70B-Instruct. Tool-use analysis shows that more than 80% of tool
calls are successfully executed, with consistent outperformance of non-tool
baselines, thereby lifting the capability ceiling of FMs. More empirical
results and implementation details will be updated at
https://github.com/tmlr-group/AlphaApollo.

</details>


### [60] [Bridging Reasoning to Learning: Unmasking Illusions using Complexity Out of Distribution Generalization](https://arxiv.org/abs/2510.06274)
*Mohammad Mahdi Samiei Paqaleh,Arash Marioriyad,Arman Tahmasebi-Zadeh,Mohamadreza Fereydooni,Mahdi Ghaznavai,Mahdieh Soleymani Baghshah*

Main category: cs.AI

TL;DR: 提出了复杂性分布外泛化框架来定义和衡量推理能力，强调当测试实例所需的最小解决方案复杂性超过所有训练示例时，模型仍能保持性能。


<details>
  <summary>Details</summary>
Motivation: 当前AI从模式识别任务转向需要逐步推理的问题，但缺乏对推理能力的明确定义和度量标准。

Method: 通过解决方案描述的柯尔莫哥洛夫复杂性和操作代理来形式化复杂性，区分复杂性分布外与长度和组合分布外的差异。

Result: 该框架统一了学习和推理：低复杂性时可用系统1处理的问题在复杂性压力下变为系统2处理，系统2可视为解决方案结构的泛化。

Conclusion: 复杂性分布外不能仅通过扩展数据解决，需要明确建模和分配计算复杂性的架构和训练机制来实现稳健推理。

Abstract: Recent progress has pushed AI frontiers from pattern recognition tasks toward
problems that require step by step, System2 style reasoning, especially with
large language models. Yet, unlike learning, where generalization and out of
distribution (OoD) evaluation concepts are well formalized, there is no clear,
consistent definition or metric for reasoning ability. We propose Complexity
Out of Distribution (Complexity OoD) generalization as a framework and problem
setting to define and measure reasoning. A model exhibits Complexity OoD
generalization when it maintains performance on test instances whose minimal
required solution complexity, either representational (richer solution
structure) or computational (more reasoning steps/program length), exceeds that
of all training examples. We formalize complexity via solution description
Kolmogorov complexity and operational proxies (e.g., object/relation counts;
reasoning step counts), clarifying how Complexity OoD differs from length and
compositional OoD. This lens unifies learning and reasoning: many cases
solvable with System1 like processing at low complexity become System2 like
under complexity pressure, while System2 can be viewed as generalization over
solution structures. We translate this perspective into practice with
recommendations for operationalizing Complexity OoD across the stack:
incorporating complexity into benchmark and evaluation metric design,
rethinking supervision to target solution traces, seeking and designing
inductive biases for Complexity OoD generalization, addressing learning to
reason spillovers such as spurious shortcuts, semantic robustness, catastrophic
forgetting, and step wise calibration. Because Complexity OoD cannot be solved
by scaling data alone, progress toward robust reasoning will require
architectures and training regimes that explicitly model and allocate
computation with respect to complexity.

</details>


### [61] [BuilderBench -- A benchmark for generalist agents](https://arxiv.org/abs/2510.06288)
*Raj Ghugare,Catherine Ji,Kathryn Wantlin,Jin Schofield,Benjamin Eysenbach*

Main category: cs.AI

TL;DR: 提出了BuilderBench基准测试，用于加速面向开放探索的智能体预训练研究。该基准包含硬件加速的机器人模拟器和42个多样化目标结构任务，要求智能体通过无监督探索学习物理原理和长期规划能力。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型主要通过模仿学习，难以解决超出已有数据范围的新问题。需要开发能够通过交互探索学习的智能体，但可扩展的学习机制仍是主要开放性问题。

Method: 构建BuilderBench基准，包含：(1)硬件加速的机器人模拟器，模拟与物理积木的交互；(2)42个精心策划的目标结构任务，测试物理、数学理解和长期规划能力。智能体在训练阶段无监督探索学习环境原理，在评估阶段构建未见过的目标结构。

Result: 实验表明当前算法在多数任务上仍面临挑战。为此提供了"训练轮"协议，让智能体针对单个目标结构进行训练和评估。同时提供了六种算法的单文件实现作为参考基准。

Conclusion: BuilderBench基准推动了面向开放探索的智能体预训练研究，要求智能体发展具身推理能力，通过行动而非语言进行实验和策略整合，为解决新颖问题提供了重要测试平台。

Abstract: Today's AI models learn primarily through mimicry and sharpening, so it is
not surprising that they struggle to solve problems beyond the limits set by
existing data. To solve novel problems, agents should acquire skills for
exploring and learning through experience. Finding a scalable learning
mechanism for developing agents that learn through interaction remains a major
open problem. In this work, we introduce BuilderBench, a benchmark to
accelerate research into agent pre-training that centers open-ended
exploration. BuilderBench requires agents to learn how to build any structure
using blocks. BuilderBench is equipped with $(1)$ a hardware accelerated
simulator of a robotic agent interacting with various physical blocks, and
$(2)$ a task-suite with over 42 diverse target structures that are carefully
curated to test an understanding of physics, mathematics, and long-horizon
planning. During training, agents have to explore and learn general principles
about the environment without any external supervision. During evaluation,
agents have to build the unseen target structures from the task suite. Solving
these tasks requires a sort of \emph{embodied reasoning} that is not reflected
in words but rather in actions, experimenting with different strategies and
piecing them together. Our experiments show that many of these tasks challenge
the current iteration of algorithms. Hence, we also provide a ``training
wheels'' protocol, in which agents are trained and evaluated to build a single
target structure from the task suite. Finally, we provide single-file
implementations of six different algorithms as a reference point for
researchers.

</details>


### [62] [Requirements for Game-Based Learning Design Framework for Information System Integration in the Context of Post-Merger Integration](https://arxiv.org/abs/2510.06302)
*Ksenija Lace,Marite Kirikova*

Main category: cs.AI

TL;DR: 本文探讨如何通过游戏化学习设计解决信息系统整合培训中学习曲线高和动机低的问题，提出针对并购后整合的定制化游戏学习框架。


<details>
  <summary>Details</summary>
Motivation: 并购后信息系统整合面临独特挑战，现有培训方法存在学习曲线高、学习者动机低的问题，需要更有效的学习方案。

Method: 分析基础学习理论、认知负荷与动机模型、严肃游戏设计框架，识别游戏化学习设计的关键要求，构建包含转换过程和结果学习体验两部分的框架。

Result: 提出了一个专门针对并购后信息系统整合的游戏化学习设计框架，通过迭代设计和实际验证进行开发评估。

Conclusion: 游戏化学习设计能够将静态方法培训转化为引人入胜的学习体验，有效解决现有培训方法的局限性。

Abstract: Post-merger integration states unique challenges for professionals
responsible for information system integration aimed on alignment and
combination diverse system architectures of merging organizations. Although the
theoretical and practical guidance exists for post-merger integration on the
business level, there is a significant gap in training for information system
integration in this context. In prior research specific methods AMILI (Support
method for informed decision identification) and AMILP (Support method for
informed decision-making) were introduced for the support of information system
integration decisions in the post-merger integration. But during the practical
application was reported high learning curve and low learner motivation. This
paper explores how game-based learning design can address these limitations by
transforming static method training into engaging learning experience. The
study analyzes foundational learning theories, cognitive load and motivation
models, and serious game design frameworks to identify the essential
requirements for a game-based learning design framework tailored to information
system integration in post-merger integration. Requirements are structured in
two components: the transformation process and resulting learning experience.
The paper concludes with a plan for developing and evaluating the proposed
framework through iterative design and real-world validation.

</details>


### [63] [Belief-Calibrated Multi-Agent Consensus Seeking for Complex NLP Tasks](https://arxiv.org/abs/2510.06307)
*Wentao Deng,Jiahuan Pei,Zhiwei Xu,Zhaochun Ren,Zhumin Chen,Pengjie Ren*

Main category: cs.AI

TL;DR: 提出了一个信念校准共识寻求（BCCS）框架，通过选择最优合作者和校准系统内部信念来促进稳定共识，在MATH和MMLU基准测试中优于现有最佳结果。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统中的共识寻求方法依赖投票机制，忽略了系统内部信念的矛盾，且通过无差别协作更新结果，无法为每个智能体识别最优合作者，阻碍稳定共识的形成。

Method: 提出了一个理论框架来选择最大化共识稳定性的最优合作者，并基于此设计了BCCS框架，通过选择最优合作者和校准系统内部信念来促进稳定共识。

Result: 在MATH和MMLU基准数据集上的实验结果显示，BCCS框架在挑战性任务上的准确率分别比现有最佳结果提高了2.23%和3.95%。

Conclusion: BCCS框架通过选择最优合作者和校准系统内部信念，有效解决了多智能体系统中共识寻求的稳定性问题，显著提升了复杂NLP任务的性能。

Abstract: A multi-agent system (MAS) enhances its capacity to solve complex natural
language processing (NLP) tasks through collaboration among multiple agents,
where consensus-seeking serves as a fundamental mechanism. However, existing
consensus-seeking approaches typically rely on voting mechanisms to judge
consensus, overlooking contradictions in system-internal beliefs that
destabilize the consensus. Moreover, these methods often involve agents
updating their results through indiscriminate collaboration with every other
agent. Such uniform interaction fails to identify the optimal collaborators for
each agent, hindering the emergence of a stable consensus. To address these
challenges, we provide a theoretical framework for selecting optimal
collaborators that maximize consensus stability. Based on the theorems, we
propose the Belief-Calibrated Consensus Seeking (BCCS) framework to facilitate
stable consensus via selecting optimal collaborators and calibrating the
consensus judgment by system-internal beliefs. Experimental results on the MATH
and MMLU benchmark datasets demonstrate that the proposed BCCS framework
outperforms the best existing results by 2.23% and 3.95% of accuracy on
challenging tasks, respectively. Our code and data are available at
https://github.com/dengwentao99/BCCS.

</details>


### [64] [Off-Trajectory Reasoning: Can LLMs Collaborate on Reasoning Trajectory?](https://arxiv.org/abs/2510.06410)
*Aochong Oliver Li,Tanya Goyal*

Main category: cs.AI

TL;DR: 论文研究了推理大语言模型在共享推理轨迹中协作的能力，发现标准单独推理训练无法实现有效的离轨迹推理行为，更强的模型在干扰下反而更脆弱，且所有模型都难以利用协作者的正确推理步骤。


<details>
  <summary>Details</summary>
Motivation: 研究推理LLMs是否能在共享推理轨迹中直接协作，评估其处理其他模型部分推理结果的能力（离轨迹推理），这对于多模型协作推理至关重要。

Method: 提出双测试框架：可恢复性测试模型从误导性推理痕迹中回溯的能力，可引导性测试模型基于更强协作者正确推理进行构建的能力。评估了15个开源LLMs（1.5B-32B），并进行控制研究分析后训练因素的影响。

Result: 反直觉发现：基准测试更强的LLMs在干扰下往往更脆弱；所有模型在超出自身能力的问题上利用引导步骤的解决率低于9.2%；教师模型的不佳可恢复性行为会传递给蒸馏学生。

Conclusion: 标准单独推理训练无法产生理想的离轨迹推理行为，需要专门训练原生强推理协作者。这项工作为评估多模型在共享推理轨迹中的协作奠定了基础，并揭示了现成推理LLMs的局限性。

Abstract: Reasoning LLMs are trained to verbalize their reasoning process, yielding
strong gains on complex tasks. This transparency also opens a promising
direction: multiple reasoners can directly collaborate on each other's thinking
within a shared trajectory, yielding better inference efficiency and
exploration. A key prerequisite, however, is the ability to assess the
usefulness and build on another model's partial thinking -- we call this
off-trajectory reasoning. Our paper investigates a critical question: can
standard solo-reasoning training pipelines deliver desired off-trajectory
behaviors? We propose twin tests that capture the two extremes of the
off-trajectory spectrum, namely Recoverability, which tests whether LLMs can
backtrack from "distractions" induced by misleading reasoning traces, and
Guidability, which tests their ability to build upon correct reasoning from
stronger collaborators. Our study evaluates 15 open-weight LLMs (1.5B-32B) and
reveals a counterintuitive finding -- "stronger" LLMs on benchmarks are often
more fragile under distraction. Moreover, all models tested fail to effectively
leverage guiding steps from collaborators on problems beyond their inherent
capabilities with solve rates remaining under 9.2%. Finally, we conduct control
studies to isolate the effects of three factors in post-training on these
behaviors: the choice of distillation teacher, the use of RL, and data
selection strategy. Our results provide actionable insights for training
natively strong reasoning collaborators; e.g., we find that suboptimal
recoverability behaviors of teacher models are transferred to distilled
students even if the distillation trajectories are correct. Taken together,
this work lays the groundwork for evaluating multi-model collaborations in
shared reasoning trajectories and highlights the limitations of off-the-shelf
reasoning LLMs.

</details>


### [65] [Flavonoid Fusion: Creating a Knowledge Graph to Unveil the Interplay Between Food and Health](https://arxiv.org/abs/2510.06433)
*Aryan Singh Dalal,Yinglun Zhang,Duru Doğan,Atalay Mert İleri,Hande Küçük McGinty*

Main category: cs.AI

TL;DR: 该研究创建了一个知识图谱，将食物与健康联系起来，重点关注黄酮类化合物含量与癌症关联，使用KNARM方法构建机器可操作的语义网络表示。


<details>
  <summary>Details</summary>
Motivation: 现有研究很少以标准化、机器可读的语义网络格式表示食物与健康的关系，无法有效利用这些知识。

Method: 使用KNARM方法，结合USDA数据库中的食物黄酮类化合物含量数据和文献中的癌症关联信息，构建知识图谱。

Result: 成功创建了连接食物与健康的知识图谱，为研究人员探索饮食选择与疾病管理的复杂关系提供了示例。

Conclusion: 该知识图谱可作为研究基础，未来需要扩展范围、添加更多相关数据并进行推理以发现隐藏关系。

Abstract: The focus on "food as medicine" is gaining traction in the field of health
and several studies conducted in the past few years discussed this aspect of
food in the literature. However, very little research has been done on
representing the relationship between food and health in a standardized,
machine-readable format using a semantic web that can help us leverage this
knowledge effectively. To address this gap, this study aims to create a
knowledge graph to link food and health through the knowledge graph's ability
to combine information from various platforms focusing on flavonoid contents of
food found in the USDA databases and cancer connections found in the
literature. We looked closely at these relationships using KNARM methodology
and represented them in machine-operable format. The proposed knowledge graph
serves as an example for researchers, enabling them to explore the complex
interplay between dietary choices and disease management. Future work for this
study involves expanding the scope of the knowledge graph by capturing nuances,
adding more related data, and performing inferences on the acquired knowledge
to uncover hidden relationships.

</details>


### [66] [PuzzlePlex: Benchmarking Foundation Models on Reasoning and Planning with Puzzles](https://arxiv.org/abs/2510.06475)
*Yitao Long,Yuru Jiang,Hongjun Liu,Yilun Zhao,Jingchen Sun,Yiqiu Shen,Chen Zhao,Arman Cohan,Dennis Shasha*

Main category: cs.AI

TL;DR: PuzzlePlex是一个用于评估基础模型推理和规划能力的基准，包含15种不同类型的谜题游戏，支持指令式和代码式两种执行方式，研究发现推理模型在指令式设置中表现更好，而代码式执行虽具挑战性但提供了可扩展的替代方案。


<details>
  <summary>Details</summary>
Motivation: 研究基础模型在复杂动态环境中的推理和规划能力及其可扩展性，需要开发一个全面的评估基准来系统性地测试这些能力。

Method: 引入PuzzlePlex基准，包含15种不同类型的谜题（确定性/随机性、单人/双人游戏），提供定制化游戏策略进行比较，开发细粒度性能指标，在指令式和代码式两种设置下对前沿基础模型进行深入分析。

Result: 推理模型在指令式设置中表现优于其他模型，代码式执行面临更大挑战但提供了可扩展和高效的替代方案，系统性地研究了模型的扩展极限。

Conclusion: PuzzlePlex能够进行针对性评估，并为未来基础模型在推理、规划和泛化方面的改进提供指导。

Abstract: This work investigates the reasoning and planning capabilities of foundation
models and their scalability in complex, dynamic environments. We introduce
PuzzlePlex, a benchmark designed to assess these capabilities through a diverse
set of puzzles. PuzzlePlex consists of 15 types of puzzles, including
deterministic and stochastic games of varying difficulty, as well as
single-player and two-player scenarios. The PuzzlePlex framework provides a
comprehensive environment for each game, and supports extensibility to generate
more challenging instances as foundation models evolve. Additionally, we
implement customized game-playing strategies for comparison. Building on this
benchmark, we develop fine-grained metrics to measure performance and conduct
an in-depth analysis of frontier foundation models across two settings:
instruction-based and code-based. Furthermore, we systematically investigate
their scaling limits. Our findings show that reasoning models outperform others
in instruction-based settings, while code-based execution presents greater
challenges but offers a scalable and efficient alternative. PuzzlePlex enables
targeted evaluation and guides future improvements in reasoning, planning, and
generalization for foundation models.

</details>


### [67] [Beneficial Reasoning Behaviors in Agentic Search and Effective Post-training to Obtain Them](https://arxiv.org/abs/2510.06534)
*Jiahe Jin,Abhijay Paladugu,Chenyan Xiong*

Main category: cs.AI

TL;DR: 提出了行为引导技术，通过识别四种有益推理行为（信息验证、权威评估、自适应搜索、错误恢复）来训练更有效的智能搜索代理，相比直接强化学习提升35%以上。


<details>
  <summary>Details</summary>
Motivation: 智能搜索利用LLMs解释复杂用户需求并执行多步搜索过程，这对LLMs的推理和代理能力提出了独特挑战，需要研究有效的推理行为模式。

Method: 提出推理驱动的LLM管道分析成功搜索轨迹，识别四种有益推理行为，然后通过行为引导技术合成展现这些行为的轨迹，通过监督微调和强化学习训练模型。

Result: 在三个基准测试（GAIA、WebWalker、HLE）上，行为引导使Llama3.2-3B和Qwen3-1.7B相比直接RL训练获得超过35%的提升。

Conclusion: SFT数据中期望的推理行为（而非最终答案的正确性）是RL后获得强性能的关键因素，引入的推理行为赋予模型更有效的探索和测试时扩展能力。

Abstract: Agentic search leverages large language models (LLMs) to interpret complex
user information needs and execute a multi-step process of planning, searching,
and synthesizing information to provide answers. This paradigm introduces
unique challenges for LLMs' reasoning and agentic capabilities when interacting
with retrieval systems and the broader web. In this paper, we propose a
reasoning-driven LLM-based pipeline to study effective reasoning behavior
patterns in agentic search. Using this pipeline, we analyze successful agentic
search trajectories and identify four beneficial reasoning behaviors:
Information Verification, Authority Evaluation, Adaptive Search, and Error
Recovery. Based on these findings, we propose a technique called Behavior
Priming to train more effective agentic search models. It synthesizes agentic
search trajectories that exhibit these four behaviors and integrates them into
the agentic search model through supervised fine-tuning (SFT), followed by
standard reinforcement learning (RL). Experiments on three benchmarks (GAIA,
WebWalker, and HLE) demonstrate that behavior priming yields over 35% gains in
Llama3.2-3B and Qwen3-1.7B compared to directly training agentic search models
with RL. Crucially, we demonstrate that the desired reasoning behaviors in the
SFT data, rather than the correctness of the final answer, is the critical
factor for achieving strong final performance after RL: fine-tuning on
trajectories with desirable reasoning behaviors but incorrect answers leads to
better performance than fine-tuning on trajectories with correct answers. Our
analysis further reveals the underlying mechanism: the introduced reasoning
behaviors endow models with more effective exploration (higher pass@k and
entropy) and test-time scaling (longer trajectories) capabilities, providing a
strong foundation for RL. Our code will be released as open source.

</details>


### [68] [Auto-Prompt Ensemble for LLM Judge](https://arxiv.org/abs/2510.06538)
*Jiajie Li,Huayi Zhang,Peng Lin,Jinjun Xiong,Wei Xu*

Main category: cs.AI

TL;DR: 提出了Auto-Prompt Ensemble (APE)框架，通过选择性增强LLM辅助评估维度来提高LLM法官的可靠性。该框架自动从失败案例中学习评估维度，并使用基于置信度的集成机制来决定何时采用额外评估维度的判断。


<details>
  <summary>Details</summary>
Motivation: 现有LLM法官经常遗漏关键评估维度，因为它们无法识别人类评估背后的隐含标准，导致评估可靠性不足。

Method: 提出APE框架，包含自适应学习评估维度的能力，采用基于置信度的集成机制，通过Collective Confidence方法估计置信度来决定是否采用额外评估维度的判断。

Result: 在多样化标准基准测试中，APE显著提高了LLM法官的可靠性。例如，在零样本设置下，GPT-4o在Reward Bench上的一致性率从87.2%提升到90.5%。

Conclusion: APE为LLM法官提供了一种原则性方法，利用测试时计算来弥合人类与LLM法官之间的评估差距。

Abstract: We present a novel framework that improves the reliability of LLM judges by
selectively augmenting LLM with auxiliary evaluation dimensions. Existing LLM
judges often miss crucial evaluation dimensions because they fail to recognize
the implicit standards underlying human assessments. To address this challenge,
we propose the Auto-Prompt Ensemble (APE), an adaptive framework that
automatically learns evaluation dimensions from its failure cases. APE
incorporates a confidence-based ensemble mechanism to decide when to adopt the
judgments from additional evaluation dimensions through a novel confidence
estimation approach called Collective Confidence. Extensive experiments
demonstrate that APE improves the reliability of LLM Judge across diverse
standard benchmarks. For instance, APE enhances GPT-4o agreement rate on Reward
Bench from 87.2% to 90.5% in the zero-shot setting. Overall, APE provides a
principled approach for LLM Judge to leverage test-time computation, and bridge
the evaluation gap between human and LLM judges.

</details>


### [69] [WebDART: Dynamic Decomposition and Re-planning for Complex Web Tasks](https://arxiv.org/abs/2510.06587)
*Jingbo Yang,Bairu Hou,Wei Wei,Shiyu Chang,Yujia Bao*

Main category: cs.AI

TL;DR: WebDART是一个LLM代理框架，通过动态分解任务为导航、信息提取和执行三个子任务，并持续重新规划，显著提升了复杂网页任务的完成率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在处理需要长时程导航、大规模信息提取和约束推理的复杂网页任务时表现不佳。

Method: 将目标动态分解为三个专注子任务（导航、信息提取、执行），并在发现新网页时持续重新规划分解策略。

Result: 在WebChoreArena上比之前SOTA代理提升13.7个百分点成功率，在WebArena上表现相当，且导航步骤减少达14.7步。

Conclusion: WebDART框架能有效提升LLM代理处理复杂网页任务的能力，通过任务分解和动态规划实现更好的性能。

Abstract: Large language model (LLM) agents are becoming competent at straightforward
web tasks, such as opening an item page or submitting a form, but still
struggle with objectives that require long horizon navigation, large scale
information extraction, and reasoning under constraints. We present WebDART, a
general framework that enables a single LLM to handle such complex chores.
WebDART (i) dynamically decomposes each objective into three focused subtasks:
navigation, information extraction, and execution, so the model concentrates on
one skill at a time, and (ii) continuously replans the decomposition as new
webpages are revealed, taking advantage of newly discovered filters or
shortcuts and avoiding redundant exploration. Evaluated on WebChoreArena,
WebDART lifts success rates by up to 13.7 percentage points over previous SOTA
agents, while matching their performance on the easier WebArena suite and
completing tasks with up to 14.7 fewer navigation steps.

</details>


### [70] [Fine-Grained Emotion Recognition via In-Context Learning](https://arxiv.org/abs/2510.06600)
*Zhaochun Ren,Zhou Yang,Chenglong Ye,Haizhou Sun,Chao Chen,Xiaofei Zhu,Xiangwen Liao*

Main category: cs.AI

TL;DR: 本文提出EICL方法，通过引入情感相似示例和动态软标签策略改进细粒度情感识别中的决策过程，显著优于传统ICL方法。


<details>
  <summary>Details</summary>
Motivation: 现有ICL方法虽然增强了推理过程，但忽视了决策过程的重要性。语义相似示例常引入情感差异，导致表示不准确和识别错误。

Method: 提出EICL方法：1) 引入情感相似示例；2) 使用动态软标签策略改进查询表示；3) 采用两阶段排除策略从多角度评估相似性。

Result: 在多个数据集上的广泛实验表明，EICL显著优于ICL方法。

Conclusion: EICL通过优化情感推理和决策过程，有效解决了ICL在细粒度情感识别中的局限性，提升了识别准确性。

Abstract: Fine-grained emotion recognition aims to identify the emotional type in
queries through reasoning and decision-making processes, playing a crucial role
in various systems. Recent methods use In-Context Learning (ICL), enhancing the
representation of queries in the reasoning process through semantically similar
examples, while further improving emotion recognition by explaining the
reasoning mechanisms. However, these methods enhance the reasoning process but
overlook the decision-making process. This paper investigates decision-making
in fine-grained emotion recognition through prototype theory. We show that ICL
relies on similarity matching between query representations and emotional
prototypes within the model, where emotion-accurate representations are
critical. However, semantically similar examples often introduce emotional
discrepancies, hindering accurate representations and causing errors. To
address this, we propose Emotion In-Context Learning (EICL), which introduces
emotionally similar examples and uses a dynamic soft-label strategy to improve
query representations in the emotion reasoning process. A two-stage exclusion
strategy is then employed to assess similarity from multiple angles, further
optimizing the decision-making process. Extensive experiments show that EICL
significantly outperforms ICL on multiple datasets.

</details>


### [71] [Agent-in-the-Loop: A Data Flywheel for Continuous Improvement in LLM-based Customer Support](https://arxiv.org/abs/2510.06674)
*Cen,Zhao,Tiantian Zhang,Hanchen Su,Yufeng,Zhang,Shaowei Su,Mingzhi Xu,Yu,Liu,Wei Han,Jeremy Werner,Claire Na Cheng,Yashar Mehdad*

Main category: cs.AI

TL;DR: 提出了Agent-in-the-Loop框架，通过整合四种实时反馈信号（响应偏好、代理采纳、知识相关性检查、缺失知识识别）来持续改进基于LLM的客户支持系统，将重新训练周期从数月缩短至数周。


<details>
  <summary>Details</summary>
Motivation: 传统的离线批注方法依赖批量标注，无法实时改进LLM客户支持系统。需要一种能够将人类反馈直接嵌入操作工作流程的连续改进机制。

Method: AITL框架整合四种实时反馈类型：响应偏好配对、代理采纳及理由、知识相关性检查、缺失知识识别，这些信号直接反馈到模型更新中。

Result: 生产试点显示检索准确率显著提升（召回率+11.7%，精确率+14.8%），生成质量提高（帮助性+8.4%），代理采纳率增加（+4.5%）。

Conclusion: 将人类反馈循环直接嵌入操作工作流程能有效持续改进基于LLM的客户支持系统，证明了AITL框架的实用价值。

Abstract: We introduce an Agent-in-the-Loop (AITL) framework that implements a
continuous data flywheel for iteratively improving an LLM-based customer
support system. Unlike standard offline approaches that rely on batch
annotations, AITL integrates four key types of annotations directly into live
customer operations: (1) pairwise response preferences, (2) agent adoption and
rationales, (3) knowledge relevance checks, and (4) identification of missing
knowledge. These feedback signals seamlessly feed back into models' updates,
reducing retraining cycles from months to weeks. Our production pilot involving
US-based customer support agents demonstrated significant improvements in
retrieval accuracy (+11.7% recall@75, +14.8% precision@8), generation quality
(+8.4% helpfulness) and agent adoption rates (+4.5%). These results underscore
the effectiveness of embedding human feedback loops directly into operational
workflows to continuously refine LLM-based customer support system.

</details>


### [72] [Inefficiencies of Meta Agents for Agent Design](https://arxiv.org/abs/2510.06711)
*Batu El,Mert Yuksekgonul,James Zou*

Main category: cs.AI

TL;DR: 本文分析了元代理自动设计代理系统的三个关键挑战：跨迭代学习机制、行为多样性不足以及经济可行性问题。


<details>
  <summary>Details</summary>
Motivation: 随着元代理自动设计代理系统的兴起，需要深入理解这类系统的实际效果和局限性，特别是在学习机制、行为多样性和经济成本方面的表现。

Method: 通过实验分析元代理在不同迭代策略下的学习效果，评估设计代理的行为多样性，并计算自动化设计与人工设计的成本效益比。

Result: 发现扩展上下文包含所有先前代理的方法表现不如忽略先前设计；进化方法表现更好；设计的代理行为多样性低；仅在少数数据集上自动化设计在经济上可行。

Conclusion: 当前元代理自动设计系统在跨迭代学习、行为多样性和经济可行性方面存在显著局限性，需要改进学习机制和多样性策略才能实现广泛应用。

Abstract: Recent works began to automate the design of agentic systems using
meta-agents that propose and iteratively refine new agent architectures. In
this paper, we examine three key challenges in a common class of meta-agents.
First, we investigate how a meta-agent learns across iterations and find that
simply expanding the context with all previous agents, as proposed by previous
works, performs worse than ignoring prior designs entirely. We show that the
performance improves with an evolutionary approach. Second, although the
meta-agent designs multiple agents during training, it typically commits to a
single agent at test time. We find that the designed agents have low behavioral
diversity, limiting the potential for their complementary use. Third, we assess
when automated design is economically viable. We find that only in a few
cases--specifically, two datasets--the overall cost of designing and deploying
the agents is lower than that of human-designed agents when deployed on over
15,000 examples. In contrast, the performance gains for other datasets do not
justify the design cost, regardless of scale.

</details>


### [73] [MultiCNKG: Integrating Cognitive Neuroscience, Gene, and Disease Knowledge Graphs Using Large Language Models](https://arxiv.org/abs/2510.06742)
*Ali Sarabadani,Kheirolah Rahsepar Fard*

Main category: cs.AI

TL;DR: MultiCNKG是一个创新的知识图谱框架，整合了认知神经科学知识图谱、基因本体和疾病本体，利用大语言模型进行实体对齐和语义相似度计算，构建了连接基因机制、神经系统疾病和认知功能的统一知识图谱。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法在捕捉基因、疾病和认知过程之间复杂语义联系方面存在局限性，需要开发能够整合多源知识并利用大语言模型优势的新框架。

Method: 整合三个关键知识源（CNKG、GO、DO），利用GPT-4等大语言模型进行实体对齐、语义相似度计算和图增强，构建统一的跨领域知识图谱。

Result: 构建的MultiCNKG包含6.9K个节点和11.3K条边，在精度（85.20%）、召回率（87.30%）、覆盖率（92.18%）等指标上表现优异，链接预测性能与基准数据集相当。

Conclusion: 该知识图谱推动了精准医疗、认知障碍诊断和认知神经科学假设生成等应用，为从分子到行为层面的多层级研究提供了有力工具。

Abstract: The advent of large language models (LLMs) has revolutionized the integration
of knowledge graphs (KGs) in biomedical and cognitive sciences, overcoming
limitations in traditional machine learning methods for capturing intricate
semantic links among genes, diseases, and cognitive processes. We introduce
MultiCNKG, an innovative framework that merges three key knowledge sources: the
Cognitive Neuroscience Knowledge Graph (CNKG) with 2.9K nodes and 4.3K edges
across 9 node types and 20 edge types; Gene Ontology (GO) featuring 43K nodes
and 75K edges in 3 node types and 4 edge types; and Disease Ontology (DO)
comprising 11.2K nodes and 8.8K edges with 1 node type and 2 edge types.
Leveraging LLMs like GPT-4, we conduct entity alignment, semantic similarity
computation, and graph augmentation to create a cohesive KG that interconnects
genetic mechanisms, neurological disorders, and cognitive functions. The
resulting MultiCNKG encompasses 6.9K nodes across 5 types (e.g., Genes,
Diseases, Cognitive Processes) and 11.3K edges spanning 7 types (e.g., Causes,
Associated with, Regulates), facilitating a multi-layered view from molecular
to behavioral domains. Assessments using metrics such as precision (85.20%),
recall (87.30%), coverage (92.18%), graph consistency (82.50%), novelty
detection (40.28%), and expert validation (89.50%) affirm its robustness and
coherence. Link prediction evaluations with models like TransE (MR: 391, MRR:
0.411) and RotatE (MR: 263, MRR: 0.395) show competitive performance against
benchmarks like FB15k-237 and WN18RR. This KG advances applications in
personalized medicine, cognitive disorder diagnostics, and hypothesis
formulation in cognitive neuroscience.

</details>


### [74] [Verifying Memoryless Sequential Decision-making of Large Language Models](https://arxiv.org/abs/2510.06756)
*Dennis Gross,Helge Spieker,Arnaud Gotlieb*

Main category: cs.AI

TL;DR: 开发了一个自动化工具，用于验证基于LLM的策略在无记忆顺序决策任务中的安全性，通过增量构建MDP模型并使用Storm模型检查器验证PCTL安全属性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在顺序决策任务中的应用增加，需要确保这些策略满足安全要求，但现有方法缺乏对LLM策略的形式化验证能力。

Method: 给定MDP、LLM策略和PCTL安全要求，增量构建可达的MDP状态，将状态编码为自然语言提示，解析LLM响应为动作，并使用Storm模型检查器验证安全属性。

Result: 实验显示开源LLM在确定性种子下可被验证，但性能通常低于深度强化学习基线。工具与Ollama和PRISM集成，支持用户指定的顺序决策任务。

Conclusion: 该工具为验证日益强大的LLM提供了实用基础，支持在顺序决策任务中进行持续基准测试和形式化验证。

Abstract: We introduce a tool for rigorous and automated verification of large language
model (LLM)- based policies in memoryless sequential decision-making tasks.
Given a Markov decision process (MDP) representing the sequential
decision-making task, an LLM policy, and a safety requirement expressed as a
PCTL formula, our approach incrementally constructs only the reachable portion
of the MDP guided by the LLM's chosen actions. Each state is encoded as a
natural language prompt, the LLM's response is parsed into an action, and
reachable successor states by the policy are expanded. The resulting formal
model is checked with Storm to determine whether the policy satisfies the
specified safety property. In experiments on standard grid world benchmarks, we
show that open source LLMs accessed via Ollama can be verified when
deterministically seeded, but generally underperform deep reinforcement
learning baselines. Our tool natively integrates with Ollama and supports
PRISM-specified tasks, enabling continuous benchmarking in user-specified
sequential decision-making tasks and laying a practical foundation for formally
verifying increasingly capable LLMs.

</details>


### [75] [Evolving and Executing Research Plans via Double-Loop Multi-Agent Collaboration](https://arxiv.org/abs/2510.06761)
*Zhi Zhang,Yan Liu,Zhejing Hu,Gong Chen,Sheng-hua Zhong,Jiannong Cao*

Main category: cs.AI

TL;DR: 提出了一个双循环多智能体框架（DLMA）来自动化端到端科学研究过程，通过教授智能体的领导循环进化研究计划，博士学生智能体的跟随循环执行最佳计划，在ACLAward和Laboratory基准测试中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 自动化端到端科学研究过程面临双重挑战：需要生成新颖且合理的高层计划，并在动态不确定条件下正确执行这些计划。

Method: DLMA框架包含两个循环：领导循环使用进化算法通过参与、改进和整合会议迭代生成和优化研究提案池；跟随循环通过事前和事后会议动态调整计划执行，确保每个步骤得到上下文和外部观察的支持。

Result: 在ACLAward和Laboratory基准测试中，DLMA生成的研究论文在自动评估中获得了最先进的分数，显著优于强基线方法。

Conclusion: 消融研究证实了两个循环的关键作用：进化驱动新颖性，执行确保合理性，DLMA成功解决了科学研究自动化的双层挑战。

Abstract: Automating the end-to-end scientific research process poses a fundamental
challenge: it requires both evolving high-level plans that are novel and sound,
and executing these plans correctly amidst dynamic and uncertain conditions. To
address this bilevel challenge, we propose a novel Double-Loop Multi-Agent
(DLMA) framework to solve the given research problem automatically. The leader
loop, composed of professor agents, is responsible for evolving research plans.
It employs an evolutionary algorithm through involvement, improvement, and
integration meetings to iteratively generate and refine a pool of research
proposals, exploring the solution space effectively. The follower loop,
composed of doctoral student agents, is responsible for executing the
best-evolved plan. It dynamically adjusts the plan during implementation via
pre-hoc and post-hoc meetings, ensuring each step (e.g., drafting, coding) is
well-supported by contextual and external observations. Extensive experiments
on benchmarks like ACLAward and Laboratory show that DLMA generates research
papers that achieve state-of-the-art scores in automated evaluation,
significantly outperforming strong baselines. Ablation studies confirm the
critical roles of both loops, with evolution driving novelty and execution
ensuring soundness.

</details>


### [76] [Autoformalizer with Tool Feedback](https://arxiv.org/abs/2510.06857)
*Qi Guo,Jianing Wang,Jianfei Zhang,Deyang Kong,Xiangzhou Huang,Xiangyu Xi,Wei Wang,Jingang Wang,Xunliang Cai,Shikun Zhang,Wei Ye*

Main category: cs.AI

TL;DR: 提出了ATF方法，通过集成语法检查和一致性验证工具来改进自动形式化，显著提升了形式化语句的语法有效性和语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有形式化方法在生成语法有效且语义一致的语句方面仍存在困难，需要改进自动形式化的质量和可靠性。

Method: ATF方法整合Lean 4编译器进行语法修正，采用多LLM判断进行一致性验证，通过工具反馈自适应优化生成语句。训练过程包括冷启动、专家迭代和直接偏好优化三个阶段。

Result: 实验结果表明ATF明显优于基线模型，人类评估进一步验证了其优越性能，且展现出良好的推理扩展特性。

Conclusion: ATF通过工具反馈机制有效提升了自动形式化的质量，开源的数据集Numina-ATF将促进相关研究发展。

Abstract: Autoformalization addresses the scarcity of data for Automated Theorem
Proving (ATP) by translating mathematical problems from natural language into
formal statements. Efforts in recent work shift from directly prompting large
language models to training an end-to-end formalizer model from scratch,
achieving remarkable advancements. However, existing formalizer still struggles
to consistently generate valid statements that meet syntactic validity and
semantic consistency. To address this issue, we propose the Autoformalizer with
Tool Feedback (ATF), a novel approach that incorporates syntactic and
consistency information as tools into the formalization process. By integrating
Lean 4 compilers for syntax corrections and employing a multi-LLMs-as-judge
approach for consistency validation, the model is able to adaptively refine
generated statements according to the tool feedback, enhancing both syntactic
validity and semantic consistency. The training of ATF involves a cold-start
phase on synthetic tool-calling data, an expert iteration phase to improve
formalization capabilities, and Direct Preference Optimization to alleviate
ineffective revisions. Experimental results show that ATF markedly outperforms
a range of baseline formalizer models, with its superior performance further
validated by human evaluations. Subsequent analysis reveals that ATF
demonstrates excellent inference scaling properties. Moreover, we open-source
Numina-ATF, a dataset containing 750K synthetic formal statements to facilitate
advancements in autoformalization and ATP research.

</details>


### [77] [TGPR: Tree-Guided Policy Refinement for Robust Self-Debugging of LLMs](https://arxiv.org/abs/2510.06878)
*Daria Ozerova,Ekaterina Trofimova*

Main category: cs.AI

TL;DR: 提出了Tree-Guided Policy Refinement (TGPR)框架，结合GRPO和Thompson采样树搜索，通过主动探索失败和成功的精化路径来改进大语言模型的迭代精化能力。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在迭代精化过程中面临的搜索空间巨大问题，现有基于预定义启发式的方法存在探索-利用困境且无法根据过去结果自适应调整。

Method: TGPR框架结合GRPO（可能指某种强化学习策略优化）和基于Thompson采样的树搜索，通过密集训练轨迹和自适应策略来探索精化路径。

Result: 在HumanEval、MBPP和APPS基准测试中，相比GRPO基线，pass@1在MBPP上提升4.2个百分点，pass@10在APPS上提升12.51个百分点。

Conclusion: TGPR为增强LLMs的迭代精化和状态推理提供了一个通用框架，将学习策略与结构化搜索方法相结合。

Abstract: Iterative refinement has been a promising paradigm to enable large language
models (LLMs) to resolve difficult reasoning and problem-solving tasks. One of
the key challenges, however, is how to effectively search through the enormous
search space of possible refinements. Existing methods typically fall back on
predefined heuristics, which are troubled by the exploration-exploitation
dilemma and cannot adapt based on past refinement outcomes. We introduce
Tree-Guided Policy Refinement (TGPR), a novel framework that combines GRPO with
a Thompson-Sampling-based tree search. TGPR explores both failed and successful
refinement paths actively, with denser training trajectories and more adaptive
policies. On HumanEval, MBPP, and APPS benchmarks, our method achieves up to
+4.2 percentage points absolute improvement in pass@1 (on MBPP) and up to
+12.51 percentage points absolute improvement in pass@10 (on APPS) compared to
a competitive GRPO baseline. Apart from debugging code, TGPR focuses on a
principled approach to combining learned policies with structured search
methods, offering a general framework for enhancing iterative refinement and
stateful reasoning in LLMs.

</details>


### [78] [LLM-Assisted Modeling of Semantic Web-Enabled Multi-Agents Systems with AJAN](https://arxiv.org/abs/2510.06911)
*Hacane Hechehouche,Andre Antakli,Matthias Klusch*

Main category: cs.AI

TL;DR: 提出了一个集成开发环境来解决AJAN框架中RDF/RDFS和SPARQL建模的困难，并利用大语言模型扩展用户群体


<details>
  <summary>Details</summary>
Motivation: 现有的AJAN框架中，使用RDF/RDFS和SPARQL定义智能体行为存在很大障碍，包括URI处理容易出错、复杂SPARQL查询学习曲线高等问题

Method: 开发了一个集成开发环境，通过利用大语言模型来简化AJAN智能体的建模过程

Result: 成功构建了一个能够降低建模难度并扩展用户群体的开发环境

Conclusion: 该集成开发环境有效解决了AJAN框架中的建模障碍，并通过大语言模型技术扩大了框架的适用性

Abstract: There are many established semantic Web standards for implementing
multi-agent driven applications. The AJAN framework allows to engineer
multi-agent systems based on these standards. In particular, agent knowledge is
represented in RDF/RDFS and OWL, while agent behavior models are defined with
Behavior Trees and SPARQL to access and manipulate this knowledge. However, the
appropriate definition of RDF/RDFS and SPARQL-based agent behaviors still
remains a major hurdle not only for agent modelers in practice. For example,
dealing with URIs is very error-prone regarding typos and dealing with complex
SPARQL queries in large-scale environments requires a high learning curve. In
this paper, we present an integrated development environment to overcome such
hurdles of modeling AJAN agents and at the same time to extend the user
community for AJAN by the possibility to leverage Large Language Models for
agent engineering.

</details>


### [79] [Revisiting the Uniform Information Density Hypothesis in LLM Reasoning Traces](https://arxiv.org/abs/2510.06953)
*Minju Gwak,Guijin Son,Jaehyung Kim*

Main category: cs.AI

TL;DR: 该研究验证了统一信息密度(UID)假设在大型语言模型推理轨迹中的应用，发现步骤级信息密度均匀性能够有效预测推理质量，并可作为选择高质量推理轨迹的标准。


<details>
  <summary>Details</summary>
Motivation: 探索统一信息密度假设是否适用于LLM推理过程，验证步骤级信息密度均匀性是否能反映推理质量。

Method: 提出基于熵的步骤级信息密度度量方法，引入局部和全局均匀性评分，在六个推理基准上进行实验验证。

Result: 步骤级信息密度均匀性不仅能提供理论视角，还具有实际性能优势：选择信息密度更均匀的推理轨迹可使AIME2025准确率相对提升10-32%。正确推理轨迹避免信息密度尖峰，错误轨迹则呈现不规则信息爆发。

Conclusion: UID启发的信息密度度量优于其他内部信号，可作为构建更可靠、准确推理系统的诊断和选择标准。

Abstract: The Uniform Information Density (UID) hypothesis suggests that effective
communication maintains a stable flow of information. In this work, we revisit
this principle in the context of large language model (LLM) reasoning traces,
asking whether step-level uniformity reflects reasoning quality. To this end,
we propose an entropy-based stepwise information density metric and introduce
two complementary measures of uniformity, local and global uniformity scores.
Across the experiments on six different reasoning benchmarks, we find that
step-level uniformity not only provides a strong theoretical lens but also
yields practical performance benefits; for example, selecting reasoning traces
with more uniform information density at the step-level improves accuracy by
10-32\% relative gains over baselines at AIME2025. Our analysis further reveals
that correct reasoning traces tend to avoid sharp information density spikes,
while incorrect traces exhibit irregular information bursts. These results
demonstrate that UID-inspired information density measures outperform
alternative internal signals as predictors of reasoning quality. Results
highlight the uniformity of the information density as a robust diagnostic and
selection criterion for building more reliable and accurate reasoning systems.

</details>


### [80] [Tool-Augmented Policy Optimization: Synergizing Reasoning and Adaptive Tool Use with Reinforcement Learning](https://arxiv.org/abs/2510.07038)
*Wenxun Wu,Yuanyang Li,Guhan Chen,Linyue Wang,Hongyang Chen*

Main category: cs.AI

TL;DR: 提出TAPO框架，通过强化学习将多跳推理与自适应工具调用能力相结合，解决LLMs在需要最新知识或计算工具任务上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型仅依赖直接推理难以处理需要最新知识或计算工具（如计算器、代码解释器）的任务，特别是在复杂算术运算方面存在局限。

Method: 使用改进的Dynamic Sampling Policy Optimization (DAPO)强化学习框架，专门针对工具调用场景进行适配，使模型能够动态地在复杂推理与按需工具使用之间切换。

Result: 在Qwen2.5-3B和Qwen2.5-7B模型上验证了方法的有效性，在需要外部知识和数学计算的任务上达到了同类参数方法中的最优性能，且工具使用效率更高。

Conclusion: 结合先进推理与工具使用能显著提升模型在知识密集型和计算密集型任务中的性能，具有重要潜力。

Abstract: Recent advances in large language models (LLMs) have popularized test-time
scaling, where models generate additional reasoning tokens before producing
final answers. These approaches have demonstrated significant performance
improvements on benchmarks involving mathematical reasoning. However, language
models relying solely on direct inference still struggle with tasks demanding
up-to-date knowledge or computational tools such as calculators and code
interpreters for complex arithmetic operations. To overcome these limitations,
we propose Tool-Augmented Policy Optimization (TAPO), a novel reinforcement
learning framework that systematically integrates multi-hop reasoning with
adaptive tool-calling capabilities. Our approach employs a modified version of
Dynamic Sampling Policy Optimization (DAPO), a recently developed RL paradigm,
which we adapt specifically for tool invocation scenarios, enabling models to
dynamically interleave complex reasoning with on-demand tool usage (including
search APIs and Python interpreters).
  To support this research, we introduce two new datasets: TAPO-easy-60K and
TAPO-hard-18K, specifically designed to train and evaluate both fact-based
reasoning and mathematical calculation capabilities. Our experiments on
Qwen2.5-3B and Qwen2.5-7B models demonstrate the effectiveness of our approach,
with both models achieving state-of-the-art performance on tasks requiring
external knowledge and mathematical computation among methods with comparable
parameters. Notably, TAPO achieves more efficient tool utilization than
baseline methods while preventing excessive calls caused by reward hacking.
These results highlight the significant potential of combining advanced
reasoning with tool usage to enhance model performance in knowledge-intensive
and computationally demanding tasks.

</details>


### [81] [Prompt Optimization Across Multiple Agents for Representing Diverse Human Populations](https://arxiv.org/abs/2510.07064)
*Manh Hung Nguyen,Sebastian Tschiatschek,Adish Singla*

Main category: cs.AI

TL;DR: 提出了一种新框架，通过构建一组LLM代理来捕捉人类群体的多样性，每个代理通过上下文学习基于少量人类演示来调整行为，使用子模优化方法选择代表性代理集。


<details>
  <summary>Details</summary>
Motivation: 由于获取大规模人类响应的困难和成本高昂，LLMs成为有吸引力的人类行为代理替代品，但现有LLMs输出同质化严重，无法捕捉人类观点和行为的丰富多样性。

Method: 通过上下文学习构建多个LLM代理，每个代理基于少量人类演示（任务-响应对）调整行为，使用子模优化方法从指数级大的代理空间中选择代表性代理集。

Result: 在众包和教育领域的广泛实验表明，该方法构建的代理比基线方法更有效地代表人类群体，在新任务上的行为分析显示这些代理能够重现目标学生和标注者的行为模式和观点。

Conclusion: 该框架成功构建了能够捕捉人类群体多样性的LLM代理集，通过子模优化方法有效解决了代理选择问题，在多个领域验证了其有效性。

Abstract: The difficulty and expense of obtaining large-scale human responses make
Large Language Models (LLMs) an attractive alternative and a promising proxy
for human behavior. However, prior work shows that LLMs often produce
homogeneous outputs that fail to capture the rich diversity of human
perspectives and behaviors. Thus, rather than trying to capture this diversity
with a single LLM agent, we propose a novel framework to construct a set of
agents that collectively capture the diversity of a given human population.
Each agent is an LLM whose behavior is steered by conditioning on a small set
of human demonstrations (task-response pairs) through in-context learning. The
central challenge is therefore to select a representative set of LLM agents
from the exponentially large space of possible agents. We tackle this selection
problem from the lens of submodular optimization. In particular, we develop
methods that offer different trade-offs regarding time complexity and
performance guarantees. Extensive experiments in crowdsourcing and educational
domains demonstrate that our approach constructs agents that more effectively
represent human populations compared to baselines. Moreover, behavioral
analyses on new tasks show that these agents reproduce the behavior patterns
and perspectives of the students and annotators they are designed to represent.

</details>


### [82] [Inductive Learning for Possibilistic Logic Programs Under Stable Models](https://arxiv.org/abs/2510.07069)
*Hongbo Hu,Yisong Wang,Yi Huang,Kewen Wang*

Main category: cs.AI

TL;DR: 本文提出了从背景程序和示例中提取可能性逻辑程序的方法，定义了归纳任务概念，开发了ilpsm和ilpsmmin算法，并在普通逻辑程序上优于现有归纳学习系统。


<details>
  <summary>Details</summary>
Motivation: 可能性逻辑程序在稳定模型下的归纳推理问题尚未被研究，需要开发从背景知识和示例中学习可能性逻辑程序的方法。

Method: 正式定义归纳任务概念，研究其性质，提出ilpsm和ilpsmmin两种计算归纳解的算法，并实现了ilpsmmin的原型系统。

Result: 实验结果表明，当输入为普通逻辑程序时，该原型在随机生成的数据集上优于基于稳定模型的正常逻辑程序的主要归纳学习系统。

Conclusion: 本文成功解决了可能性逻辑程序的归纳推理问题，提出的算法在性能上优于现有方法，为可能性ASP的归纳学习提供了有效解决方案。

Abstract: Possibilistic logic programs (poss-programs) under stable models are a major
variant of answer set programming (ASP). While its semantics (possibilistic
stable models) and properties have been well investigated, the problem of
inductive reasoning has not been investigated yet. This paper presents an
approach to extracting poss-programs from a background program and examples
(parts of intended possibilistic stable models). To this end, the notion of
induction tasks is first formally defined, its properties are investigated and
two algorithms ilpsm and ilpsmmin for computing induction solutions are
presented. An implementation of ilpsmmin is also provided and experimental
results show that when inputs are ordinary logic programs, the prototype
outperforms a major inductive learning system for normal logic programs from
stable models on the datasets that are randomly generated.

</details>


### [83] [VRPAgent: LLM-Driven Discovery of Heuristic Operators for Vehicle Routing Problems](https://arxiv.org/abs/2510.07073)
*André Hottung,Federico Berto,Chuanbo Hua,Nayeli Gast Zepeda,Daniel Wetzel,Michael Römer,Haoran Ye,Davide Zago,Michael Poli,Stefano Massaroli,Jinkyoo Park,Kevin Tierney*

Main category: cs.AI

TL;DR: VRPAgent是一个将LLM生成的组件集成到元启发式算法中，并通过遗传搜索进行优化的框架，能够在车辆路径问题上超越人工设计的启发式方法。


<details>
  <summary>Details</summary>
Motivation: 设计高性能的车辆路径问题启发式算法需要深厚的领域知识和直觉，而现有的LLM代码生成方法还无法产生能与人类专家相媲美的启发式算法。

Method: 使用LLM生成问题特定的操作符，并将其嵌入到通用的元启发式框架中，通过新颖的遗传搜索来优化这些组件。

Result: 在多个车辆路径问题变体上，VRPAgent发现的启发式操作符超越了手工设计的方法和最近的学习方法，且仅需单个CPU核心。

Conclusion: VRPAgent是首个在车辆路径问题上推进最先进技术的LLM范式，为自动启发式发现展示了有前景的未来。

Abstract: Designing high-performing heuristics for vehicle routing problems (VRPs) is a
complex task that requires both intuition and deep domain knowledge. Large
language model (LLM)-based code generation has recently shown promise across
many domains, but it still falls short of producing heuristics that rival those
crafted by human experts. In this paper, we propose VRPAgent, a framework that
integrates LLM-generated components into a metaheuristic and refines them
through a novel genetic search. By using the LLM to generate problem-specific
operators, embedded within a generic metaheuristic framework, VRPAgent keeps
tasks manageable, guarantees correctness, and still enables the discovery of
novel and powerful strategies. Across multiple problems, including the
capacitated VRP, the VRP with time windows, and the prize-collecting VRP, our
method discovers heuristic operators that outperform handcrafted methods and
recent learning-based approaches while requiring only a single CPU core. To our
knowledge, \VRPAgent is the first LLM-based paradigm to advance the
state-of-the-art in VRPs, highlighting a promising future for automated
heuristics discovery.

</details>


### [84] [The Cognitive Bandwidth Bottleneck: Shifting Long-Horizon Agent from Planning with Actions to Planning with Schemas](https://arxiv.org/abs/2510.07091)
*Baixuan Xu,Tianshi Zheng,Zhaowei Wang,Hong Ting Tsang,Weiqi Wang,Tianqing Fang,Yangqiu Song*

Main category: cs.AI

TL;DR: 本文系统研究了两种动作表示方法在长视野任务中的有效性：基于动作的规划(PwA)和基于模式的规划(PwS)，发现存在一个表示选择拐点，并提出了构建更强大PwS智能体的实用指南。


<details>
  <summary>Details</summary>
Motivation: 当环境动作空间组合爆炸时（如开放世界），传统的基于动作列表的规划方法变得不切实际，需要寻找最优的动作表示方法来实现可扩展的自主性。

Method: 系统比较PwA（直接提供可执行动作列表）和PwS（将动作模式实例化为动作列表）两种表示方法，提出认知带宽视角作为概念框架，在ALFWorld和SciWorld上进行实验观察表示选择拐点。

Result: 在ALFWorld（约35个动作）和SciWorld（约500个动作）之间观察到一个表示选择拐点，表明需要可扩展的表示方法。模型规划能力越强，拐点越右移；模式实例化能力越好，拐点越左移。

Conclusion: PwS在动作空间较大时具有优势，但当前PwS智能体性能欠佳，需要构建更强大的PwS智能体来实现更好的可扩展自主性。

Abstract: Enabling LLMs to effectively operate long-horizon task which requires
long-term planning and multiple interactions is essential for open-world
autonomy. Conventional methods adopt planning with actions where a executable
action list would be provided as reference. However, this action representation
choice would be impractical when the environment action space is combinatorial
exploded (e.g., open-ended real world). This naturally leads to a question: As
environmental action space scales, what is the optimal action representation
for long-horizon agents? In this paper, we systematically study the
effectiveness of two different action representations. The first one is
conventional planning with actions (PwA) which is predominantly adopted for its
effectiveness on existing benchmarks. The other one is planning with schemas
(PwS) which instantiate an action schema into action lists (e.g., "move [OBJ]
to [OBJ]" -> "move apple to desk") to ensure concise action space and reliable
scalability. This alternative is motivated by its alignment with human
cognition and its compliance with environment-imposed action format
restriction. We propose cognitive bandwidth perspective as a conceptual
framework to qualitatively understand the differences between these two action
representations and empirically observe a representation-choice inflection
point between ALFWorld (~35 actions) and SciWorld (~500 actions), which serve
as evidence of the need for scalable representations. We further conduct
controlled experiments to study how the location of this inflection point
interacts with different model capacities: stronger planning proficiency shifts
the inflection rightward, whereas better schema instantiation shifts it
leftward. Finally, noting the suboptimal performance of PwS agents, we provide
an actionable guide for building more capable PwS agents for better scalable
autonomy.

</details>


### [85] [The Contingencies of Physical Embodiment Allow for Open-Endedness and Care](https://arxiv.org/abs/2510.07117)
*Leonardo Christov-Moore,Arthur Juliani,Alex Kiefer,Nicco Reggente,B. Scott Rousse,Adam Safron,Nicol'as Hinrichs,Daniel Polani,Antonio Damasio*

Main category: cs.AI

TL;DR: 该论文从存在主义现象学角度提出物理具身的两个最小条件，并基于此推导出稳态驱动和内在驱动，在强化学习框架中形式化这些概念，探讨具身智能体如何在开放多智能体环境中发展开放性和关怀能力。


<details>
  <summary>Details</summary>
Motivation: 理解生物体在开放物理世界中生存、繁衍和相互关怀的机制，以帮助开发更鲁棒、自适应和关怀的人工智能体。

Method: 基于海德格尔存在主义现象学定义两个最小具身条件：在世存在（智能体是环境的一部分）和向死存在（智能体趋向终末状态），从中推导出稳态驱动和内在驱动，并在强化学习框架中形式化这些概念。

Result: 提出从基本具身条件可以推导出维持完整性和避免死亡的稳态驱动，以及最大化对未来状态控制的内在驱动（如赋权），这些驱动使智能体能够增强维持物理完整性的能力。

Conclusion: 通过形式化这些存在主义启发的具身概念，可以研究内在驱动的具身智能体如何在开放多智能体环境中培养开放性和关怀能力。

Abstract: Physical vulnerability and mortality are often seen as obstacles to be
avoided in the development of artificial agents, which struggle to adapt to
open-ended environments and provide aligned care. Meanwhile, biological
organisms survive, thrive, and care for each other in an open-ended physical
world with relative ease and efficiency. Understanding the role of the
conditions of life in this disparity can aid in developing more robust,
adaptive, and caring artificial agents. Here we define two minimal conditions
for physical embodiment inspired by the existentialist phenomenology of Martin
Heidegger: being-in-the-world (the agent is a part of the environment) and
being-towards-death (unless counteracted, the agent drifts toward terminal
states due to the second law of thermodynamics). We propose that from these
conditions we can obtain both a homeostatic drive - aimed at maintaining
integrity and avoiding death by expending energy to learn and act - and an
intrinsic drive to continue to do so in as many ways as possible. Drawing
inspiration from Friedrich Nietzsche's existentialist concept of will-to-power,
we examine how intrinsic drives to maximize control over future states, e.g.,
empowerment, allow agents to increase the probability that they will be able to
meet their future homeostatic needs, thereby enhancing their capacity to
maintain physical integrity. We formalize these concepts within a reinforcement
learning framework, which enables us to examine how intrinsically driven
embodied agents learning in open-ended multi-agent environments may cultivate
the capacities for open-endedness and care.ov

</details>


### [86] [Integrating Domain Knowledge into Process Discovery Using Large Language Models](https://arxiv.org/abs/2510.07161)
*Ali Norouzifar,Humam Kourani,Marcus Dees,Wil van der Aalst*

Main category: cs.AI

TL;DR: 提出了一个交互式框架，利用大语言模型将自然语言表达的领域知识融入过程发现流程，通过提取声明性规则指导过程模型构建，提高模型可靠性。


<details>
  <summary>Details</summary>
Motivation: 仅从事件数据发现的过程模型可能不准确，因为事件日志通常不完整或包含噪声，且忽略了重要的领域知识，导致模型对下游任务缺乏可靠性。

Method: 使用LLMs从领域专家的文本描述中提取声明性规则，指导IMr发现算法递归构建过程模型，结合事件日志和提取的规则，避免与领域知识冲突的问题结构。

Result: 开发了完全实现的工具支持该工作流，对多个LLMs和提示工程策略进行了广泛评估，包括基于真实事件日志的案例研究，领域专家评估了框架的可用性和有效性。

Conclusion: 该交互式框架成功将领域知识整合到过程发现中，提高了过程模型的准确性和可靠性，为过程挖掘提供了更可靠的基础。

Abstract: Process discovery aims to derive process models from event logs, providing
insights into operational behavior and forming a foundation for conformance
checking and process improvement. However, models derived solely from event
data may not accurately reflect the real process, as event logs are often
incomplete or affected by noise, and domain knowledge, an important
complementary resource, is typically disregarded. As a result, the discovered
models may lack reliability for downstream tasks. We propose an interactive
framework that incorporates domain knowledge, expressed in natural language,
into the process discovery pipeline using Large Language Models (LLMs). Our
approach leverages LLMs to extract declarative rules from textual descriptions
provided by domain experts. These rules are used to guide the IMr discovery
algorithm, which recursively constructs process models by combining insights
from both the event log and the extracted rules, helping to avoid problematic
process structures that contradict domain knowledge. The framework coordinates
interactions among the LLM, domain experts, and a set of backend services. We
present a fully implemented tool that supports this workflow and conduct an
extensive evaluation of multiple LLMs and prompt engineering strategies. Our
empirical study includes a case study based on a real-life event log with the
involvement of domain experts, who assessed the usability and effectiveness of
the framework.

</details>


### [87] [NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents](https://arxiv.org/abs/2510.07172)
*Tianshi Zheng,Kelvin Kiu-Wai Tam,Newt Hue-Nam K. Nguyen,Baixuan Xu,Zhaowei Wang,Jiayang Cheng,Hong Ting Tsang,Weiqi Wang,Jiaxin Bai,Tianqing Fang,Yangqiu Song,Ginny Y. Wong,Simon See*

Main category: cs.AI

TL;DR: NewtonBench是一个包含324个科学定律发现任务的基准测试，通过元物理变换解决评估困境，将评估从静态函数拟合提升到交互式模型发现，揭示了前沿LLMs在复杂系统中发现能力的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有科学发现基准存在方法学困境，需要在科学相关性、可扩展性和抗记忆性之间权衡，且过度简化发现过程为静态函数拟合，未能捕捉真实的科学探索过程。

Method: 使用元物理变换（系统性地改变经典定律）生成大量问题，构建包含324个任务的基准，要求智能体通过实验探索模拟复杂系统来发现隐藏原理。

Result: 前沿LLMs展现出清晰但脆弱的发现能力：随着系统复杂性增加而急剧下降，对观测噪声极度敏感；工具辅助存在悖论效应，代码解释器可能阻碍更有能力的模型。

Conclusion: 在复杂交互环境中实现稳健、可泛化的发现仍是核心挑战，NewtonBench为衡量真实进展和开发下一代AI科学发现智能体提供了关键工具。

Abstract: Large language models are emerging as powerful tools for scientific law
discovery, a foundational challenge in AI-driven science. However, existing
benchmarks for this task suffer from a fundamental methodological trilemma,
forcing a trade-off between scientific relevance, scalability, and resistance
to memorization. Furthermore, they oversimplify discovery as static function
fitting, failing to capture the authentic scientific process of uncovering
embedded laws through the interactive exploration of complex model systems. To
address these critical gaps, we introduce NewtonBench, a benchmark comprising
324 scientific law discovery tasks across 12 physics domains. Our design
mitigates the evaluation trilemma by using metaphysical shifts - systematic
alterations of canonical laws - to generate a vast suite of problems that are
scalable, scientifically relevant, and memorization-resistant. Moreover, we
elevate the evaluation from static function fitting to interactive model
discovery, requiring agents to experimentally probe simulated complex systems
to uncover hidden principles. Our extensive experiment reveals a clear but
fragile capability for discovery in frontier LLMs: this ability degrades
precipitously with increasing system complexity and exhibits extreme
sensitivity to observational noise. Notably, we uncover a paradoxical effect of
tool assistance: providing a code interpreter can hinder more capable models by
inducing a premature shift from exploration to exploitation, causing them to
satisfice on suboptimal solutions. These results demonstrate that robust,
generalizable discovery in complex, interactive environments remains the core
challenge. By providing a scalable, robust, and scientifically authentic
testbed, NewtonBench offers a crucial tool for measuring true progress and
guiding the development of next-generation AI agents capable of genuine
scientific discovery.

</details>


### [88] [Multi-Objective Multi-Agent Path Finding with Lexicographic Cost Preferences](https://arxiv.org/abs/2510.07276)
*Pulkit Rustagi,Kyle Hollins Wray,Sandhya Saisubramanian*

Main category: cs.AI

TL;DR: 提出了一种基于词典序偏好的多目标多智能体路径规划框架LCBS，直接计算符合用户偏好的单一解，避免构建帕累托前沿，显著提升了多目标情况下的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有MO-MAPF算法通常通过计算帕累托前沿来生成无冲突路径，但无法明确优化用户定义的偏好，且随着目标数量增加扩展性差。

Method: 提出词典序框架和LCBS算法，结合优先级感知的底层A*搜索与基于冲突的搜索，直接根据目标偏好进行高效规划。

Result: LCBS能够计算最优解，并可扩展到多达10个目标的情况，远超过现有MO-MAPF方法的限制。在标准和随机MAPF基准测试中，随着目标数量增加，成功率始终高于最先进基线。

Conclusion: 词典序框架和LCBS算法为多目标多智能体路径规划提供了一种高效且可扩展的解决方案，能够直接利用用户偏好进行优化。

Abstract: Many real-world scenarios require multiple agents to coordinate in shared
environments, while balancing trade-offs between multiple, potentially
competing objectives. Current multi-objective multi-agent path finding
(MO-MAPF) algorithms typically produce conflict-free plans by computing Pareto
frontiers. They do not explicitly optimize for user-defined preferences, even
when the preferences are available, and scale poorly with the number of
objectives. We propose a lexicographic framework for modeling MO-MAPF, along
with an algorithm \textit{Lexicographic Conflict-Based Search} (LCBS) that
directly computes a single solution aligned with a lexicographic preference
over objectives. LCBS integrates a priority-aware low-level $A^*$ search with
conflict-based search, avoiding Pareto frontier construction and enabling
efficient planning guided by preference over objectives. We provide insights
into optimality and scalability, and empirically demonstrate that LCBS computes
optimal solutions while scaling to instances with up to ten objectives -- far
beyond the limits of existing MO-MAPF methods. Evaluations on standard and
randomized MAPF benchmarks show consistently higher success rates against
state-of-the-art baselines, especially with increasing number of objectives.

</details>


### [89] [Agentic generative AI for media content discovery at the national football league](https://arxiv.org/abs/2510.07297)
*Henry Wang,Md Sirajus Salekin,Jake Lee,Ross Claytor,Shinan Zhang,Michael Chi*

Main category: cs.AI

TL;DR: 开发了一个基于生成式AI的工作流，让NFL媒体研究人员能用自然语言查询历史比赛片段，替代传统的筛选界面，准确率超95%，将查找时间从10分钟缩短到30秒。


<details>
  <summary>Details</summary>
Motivation: 传统筛选界面效率低下，用户需要花费大量时间查找相关视频内容。生成式AI为内容发现和管理提供了新的可能性，通过与NFL合作，旨在提高媒体研究人员的操作效率。

Method: 采用基于生成式AI的代理工作流，将用户自然语言查询分解为元素，并翻译成底层数据库查询语言，通过精心设计的语义缓存提高准确性和响应速度。

Result: 解决方案达到超过95%的准确率，将查找相关视频的平均时间从10分钟减少到30秒，显著提升了NFL的运营效率。

Conclusion: 生成式AI工作流成功实现了高效的内容发现，让用户能专注于创作创意内容和引人入胜的故事线，而不是花费时间在查找视频上。

Abstract: Generative AI has unlocked new possibilities in content discovery and
management. Through collaboration with the National Football League (NFL), we
demonstrate how a generative-AI based workflow enables media researchers and
analysts to query relevant historical plays using natural language rather than
traditional filter-and-click interfaces. The agentic workflow takes a user
query as input, breaks it into elements, and translates them into the
underlying database query language. Accuracy and latency are further improved
through carefully designed semantic caching. The solution achieves over 95
percent accuracy and reduces the average time to find relevant videos from 10
minutes to 30 seconds, significantly increasing the NFL's operational
efficiency and allowing users to focus on producing creative content and
engaging storylines.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [90] [Bayesian Portfolio Optimization by Predictive Synthesis](https://arxiv.org/abs/2510.07180)
*Masahiro Kato,Kentaro Baba,Hibiki Kaibuchi,Ryo Inokuchi*

Main category: econ.EM

TL;DR: 提出了一种基于贝叶斯预测合成(BPS)的投资组合优化方法，通过集成多个资产收益预测模型来应对金融市场的不确定性。


<details>
  <summary>Details</summary>
Motivation: 传统投资组合优化方法需要资产收益分布信息，但这些信息通常未知且难以准确估计，金融市场的时变不确定性使得单一模型预测效果不稳定。

Method: 使用贝叶斯预测合成(BPS)结合动态线性模型来集成多个资产收益预测模型，获得考虑市场不确定性的贝叶斯预测后验分布。

Result: 基于预测分布信息构建了均值-方差投资组合和基于分位数的投资组合。

Conclusion: BPS方法能够有效集成多个预测模型，为投资组合优化提供更稳健的资产收益分布估计，适应金融市场的不确定性。

Abstract: Portfolio optimization is a critical task in investment. Most existing
portfolio optimization methods require information on the distribution of
returns of the assets that make up the portfolio. However, such distribution
information is usually unknown to investors. Various methods have been proposed
to estimate distribution information, but their accuracy greatly depends on the
uncertainty of the financial markets. Due to this uncertainty, a model that
could well predict the distribution information at one point in time may
perform less accurately compared to another model at a different time. To solve
this problem, we investigate a method for portfolio optimization based on
Bayesian predictive synthesis (BPS), one of the Bayesian ensemble methods for
meta-learning. We assume that investors have access to multiple asset return
prediction models. By using BPS with dynamic linear models to combine these
predictions, we can obtain a Bayesian predictive posterior about the mean
rewards of assets that accommodate the uncertainty of the financial markets. In
this study, we examine how to construct mean-variance portfolios and
quantile-based portfolios based on the predicted distribution information.

</details>


### [91] [Beyond the Oracle Property: Adaptive LASSO in Cointegrating Regressions](https://arxiv.org/abs/2510.07204)
*Karsten Reichold,Ulrike Schneider*

Main category: econ.EM

TL;DR: 本文研究了自适应LASSO估计量在协整回归模型中的渐近性质，包括模型选择概率、估计量一致性、极限分布，以及均匀收敛速率和可检测的最快局部趋零速率。


<details>
  <summary>Details</summary>
Motivation: 扩展Lee, Shi和Gao(2022)的结果，深入理解自适应LASSO在协整回归中的表现，特别是在保守调优和一致调优下的不同行为。

Method: 使用标准渐近和移动参数渐近方法，推导模型选择概率、估计量一致性、极限分布，并进行详细的模拟研究验证理论结果。

Result: 在保守调优下，自适应LASSO估计量是均匀T一致的，可检测的局部趋零系数截断速率为1/T；在一致调优下，这两个速率都较慢且依赖于调优参数。

Conclusion: 自适应LASSO估计量的有限样本分布与oracle性质建议的有显著偏差，而移动参数渐近导出的极限分布提供了更准确的近似。结果还扩展到具有局部单位根回归元和预测回归的模型。

Abstract: This paper establishes new asymptotic results for the adaptive LASSO
estimator in cointegrating regression models. We study model selection
probabilities, estimator consistency, and limiting distributions under both
standard and moving-parameter asymptotics. We also derive uniform convergence
rates and the fastest local-to-zero rates that can still be detected by the
estimator, complementing and extending the results of Lee, Shi, and Gao (2022,
Journal of Econometrics, 229, 322--349). Our main findings include that under
conservative tuning, the adaptive LASSO estimator is uniformly $T$-consistent
and the cut-off rate for local-to-zero coefficients that can be detected by the
procedure is $1/T$. Under consistent tuning, however, both rates are slower and
depend on the tuning parameter. The theoretical results are complemented by a
detailed simulation study showing that the finite-sample distribution of the
adaptive LASSO estimator deviates substantially from what is suggested by the
oracle property, whereas the limiting distributions derived under
moving-parameter asymptotics provide much more accurate approximations.
Finally, we show that our results also extend to models with local-to-unit-root
regressors and to predictive regressions with unit-root predictors.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [92] [DynBenchmark: Customizable Ground Truths to Benchmark Community Detection and Tracking in Temporal Networks](https://arxiv.org/abs/2510.06245)
*Laurent Brisson,Cécile Bothorel,Nicolas Duminy*

Main category: cs.SI

TL;DR: 提出了一种新的社区中心模型，用于生成可自定义的演化社区结构，并测试社区检测算法在跟踪动态社区方面的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试往往忽视跟踪真实网络中社区演化的需求，需要能够模拟社区增长、收缩、合并、分裂、出现或消失的基准模型。

Method: 开发了一个社区中心模型，生成可自定义的演化社区结构，同时生成底层时序网络，其中节点可以出现、消失或在社区间移动。

Result: 该基准已用于测试三种方法，测量它们在跟踪节点聚类成员资格和检测社区演化方面的性能。

Conclusion: 提供了Python库、绘图工具和验证指标，用于比较真实情况与算法在检测动态社区方面的结果。

Abstract: Graph models help understand network dynamics and evolution. Creating graphs
with controlled topology and embedded partitions is a common strategy for
evaluating community detection algorithms. However, existing benchmarks often
overlook the need to track the evolution of communities in real-world networks.
To address this, a new community-centered model is proposed to generate
customizable evolving community structures where communities can grow, shrink,
merge, split, appear or disappear. This benchmark also generates the underlying
temporal network, where nodes can appear, disappear, or move between
communities. The benchmark has been used to test three methods, measuring their
performance in tracking nodes' cluster membership and detecting community
evolution. Python libraries, drawing utilities, and validation metrics are
provided to compare ground truth with algorithm results for detecting dynamic
communities.

</details>


### [93] [Unpacking Discourses on Childbirth and Parenthood in Popular Social Media Platforms Across China, Japan, and South Korea](https://arxiv.org/abs/2510.06788)
*Zheng Wei,Yunqi Li,Yucheng He,Yuelu Li,Xian Xu,Huamin Qu,Pan Hui,Muzhi Zhou*

Main category: cs.SI

TL;DR: 分析抖音和TikTok上关于生育和育儿的短视频评论，发现在中国、韩国和日本，评论主要关注育儿成本、孩子的效用和个人主义，其中抖音评论反生育情绪最强。


<details>
  <summary>Details</summary>
Motivation: 了解社交媒体上关于生育和育儿的话语，特别是在低生育率地区，以探究在线家庭价值观的传播。

Method: 使用BERTopic模型进行主题分析，并应用大语言模型QWen进行情感标注，分析了219,127条评论和668个短视频。

Result: 评论在所有国家都关注育儿成本，日本和韩国关注孩子的效用，中国关注个人主义；抖音评论反生育情绪最强，日韩评论更中性。

Conclusion: 短视频特征和区域社会经济指标显著影响在线回应，这有助于理解低生育率地区在线家庭价值观的传播。

Abstract: Social media use has been shown to be associated with low fertility desires.
However, we know little about the discourses surrounding childbirth and
parenthood that people consume online. We analyze 219,127 comments on 668 short
videos related to reproduction and parenthood from Douyin and Tiktok in China,
South Korea, and Japan, a region famous for its extremely low fertility level,
to examine the topics and sentiment expressed online. BERTopic model is used to
assist thematic analysis, and a large language model QWen is applied to label
sentiment. We find that comments focus on childrearing costs in all countries,
utility of children, particularly in Japan and South Korea, and individualism,
primarily in China. Comments from Douyin exhibit the strongest anti-natalist
sentiments, while the Japanese and Korean comments are more neutral. Short
video characteristics, such as their stances or account type, significantly
influence the responses, alongside regional socioeconomic indicators, including
GDP, urbanization, and population sex ratio. This work provides one of the
first comprehensive analyses of online discourses on family formation via
popular algorithm-fed video sharing platforms in regions experiencing low
fertility rates, making a valuable contribution to our understanding of the
spread of family values online.

</details>


### [94] [Visualization of Interpersonal Communication using Indoor Positioning Technology with UWB Tags](https://arxiv.org/abs/2510.06797)
*Hayato Shinto,Yu Ohki,Kenji Mizumoto,Kei Saito*

Main category: cs.SI

TL;DR: 使用UWB室内定位系统追踪大学社交聚会参与者的移动，通过社区分析研究人际交流的动态演变，并探讨距离阈值对网络结构的影响。


<details>
  <summary>Details</summary>
Motivation: 通过精确的室内定位技术可视化人际交流模式，研究社交活动中社区形成的动态过程。

Method: 使用UWB室内定位系统追踪参与者移动，进行网络和社区分析，并在不同时间点重复社区分析以研究社区演化，同时探讨不同距离阈值对结果的影响。

Result: 社区分析识别出的社区时间演化与UWB系统视觉观察到的参与者分组基本一致。

Conclusion: 研究证实了通过社区分析识别的社区时间演化与视觉观察结果相符，验证了该方法在分析人际交流动态方面的有效性。

Abstract: In conjunction with a social gathering held on a university campus, the
movement of attendees were tracked within the venue for approximately two hours
using a UWB indoor positioning system, in order to visualize their
interpersonal communication. Network and community analyses were performed on
attendee interaction data, and the evolution of communities over time was
further investigated through repeated community analysis at different time
points. Furthermore, recognizing the influence of distance thresholds on
defining contact, we discussed how varying these thresholds affected the
resulting network structure and community analysis outcomes. This study
confirmed that the temporal evolution of communities identified through
community analysis broadly corresponded with the visually observed groupings of
participants using the UWB indoor positioning system.

</details>


### [95] [Machines in the Crowd? Measuring the Footprint of Machine-Generated Text on Reddit](https://arxiv.org/abs/2510.07226)
*Lucio La Cava,Luca Maria Aiello,Andrea Tagarelli*

Main category: cs.SI

TL;DR: 对Reddit上机器生成文本(MGT)的首个大规模研究，发现MGT在Reddit上总体占比不高但分布不均，在技术知识和社会支持类社区可达9%，且表达出独特的AI助手语言风格，但获得的参与度与人类内容相当。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的快速发展，机器生成文本在网络上迅速增长，但对其如何融入社交媒体环境知之甚少，需要研究MGT在Reddit等平台上的分布特征和影响。

Method: 使用最先进的统计方法检测MGT，分析2022-2024年51个代表性Reddit子社区的两年活动数据，研究MGT在不同社区和时间上的分布，并比较MGT与人类文本的社会信号表达和参与度。

Result: 保守估计显示MGT在Reddit上总体占比不高，但在技术知识和社会支持类社区可达9%；MGT分布不均，集中在少数用户活动中；表达出温暖和地位等典型的AI助手语言风格；参与度与人类内容相当甚至更高。

Conclusion: AI生成文本正成为在线社交话语的有机组成部分，这项研究为平台治理、检测策略和社区动态的新调查奠定了基础。

Abstract: Generative Artificial Intelligence is reshaping online communication by
enabling large-scale production of Machine-Generated Text (MGT) at low cost.
While its presence is rapidly growing across the Web, little is known about how
MGT integrates into social media environments. In this paper, we present the
first large-scale characterization of MGT on Reddit. Using a state-of-the-art
statistical method for detection of MGT, we analyze over two years of activity
(2022-2024) across 51 subreddits representative of Reddit's main community
types such as information seeking, social support, and discussion. We study the
concentration of MGT across communities and over time, and compared MGT to
human-authored text in terms of social signals it expresses and engagement it
receives. Our very conservative estimate of MGT prevalence indicates that
synthetic text is marginally present on Reddit, but it can reach peaks of up to
9% in some communities in some months. MGT is unevenly distributed across
communities, more prevalent in subreddits focused on technical knowledge and
social support, and often concentrated in the activity of a small fraction of
users. MGT also conveys distinct social signals of warmth and status giving
typical of language of AI assistants. Despite these stylistic differences, MGT
achieves engagement levels comparable than human-authored content and in a few
cases even higher, suggesting that AI-generated text is becoming an organic
component of online social discourse. This work offers the first perspective on
the MGT footprint on Reddit, paving the way for new investigations involving
platform governance, detection strategies, and community dynamics.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [96] [Distributional welfare impacts and compensatory transit strategies under NYC congestion pricing](https://arxiv.org/abs/2510.06416)
*Xiyuan Ren,Zhenglei Ji,Joseph Y. J. Chow*

Main category: econ.GN

TL;DR: 纽约拥堵收费项目改善了交通速度但存在分配不均问题，研究通过建模分析发现福利损失集中在特定区域和人群，提出了通过改善公共交通来补偿的具体方案。


<details>
  <summary>Details</summary>
Motivation: 研究纽约拥堵收费项目的分配影响和补偿策略，因为现有评估主要关注整体效益，而忽视了不同人群和地区的福利损失差异。

Method: 使用纽约和新泽西的合成出行数据建立联合模式和目的地模型，并用MTA报告的交通计数数据校准收费相关参数。

Result: 项目导致每年约2.4亿美元的福利损失，但远低于收费收入。福利损失集中在曼哈顿上城、布鲁克林和新泽西哈德逊县，特别是难以转向公共交通的人群。

Conclusion: 需要通过有针对性的公共交通改善来补偿福利损失，如减少等待时间或提供票价补贴，对纽约居民需要0.48分钟等待时间减少或1.36亿美元年补贴，对新泽西居民则更适合票价折扣方案。

Abstract: Early evaluations of NYC's congestion pricing program indicate overall
improvements in vehicle speed and transit ridership. However, its
distributional impacts remain understudied, as does the design of compensatory
transit strategies to mitigate potential welfare losses. This study identifies
population segments and regions most affected by congestion pricing, and
evaluates how welfare losses can be compensated through transit improvements.
We estimate joint mode and destination models using aggregated synthetic trips
in New York and New Jersey and calibrate toll-related parameters with traffic
counts reported by the MTA. The results show that the program leads to an
accessibility-related welfare loss of approximately $240 million per year,
which is considerably lower than the gains from toll revenues: the gross
revenue estimated by our models ($1.077 billion per year) and the net revenue
projected by the MTA ($450 million per year). However, these benefits gains
conceal significant disparities. Welfare losses are concentrated in Upper
Manhattan, Brooklyn, and Hudson County, NJ, particularly among travelers less
able to shift to transit or alternative destinations. For NYC residents,
compensating aggregate welfare loss requires a 0.48-minute reduction in transit
wait time or a $135.59 million annual fare subsidy. Ensuring accessibility
gains for all populations and counties (Pareto improving) requires a 1-2 minute
reduction in wait time combined with an annual subsidy of about $100-300
million. For New Jersey residents, achieving aggregate welfare gains primarily
through fare discounts (requiring $108.53 million per year) is more feasible
and efficient; however, uniform discounts should be replaced by targeted
mechanisms such as origin-based fare reductions or commuter pass bundles.

</details>


### [97] [When Machines Meet Each Other: Network Effects and the Strategic Role of History in Multi-Agent AI](https://arxiv.org/abs/2510.06903)
*Yu Liu,Wenwen Li,Yifan Dou,Guangnan Ye*

Main category: econ.GN

TL;DR: 研究LLM智能体在网络效应博弈中的行为，发现它们会系统性偏离理论预测的期望均衡，价格是主要偏差驱动因素，历史结构对协调稳定性有重要影响。


<details>
  <summary>Details</summary>
Motivation: 随着AI进入智能体时代，LLM越来越多地作为自主智能体相互交互，需要了解它们在相互依赖环境中的行为模式，特别是在网络效应博弈中的协调能力。

Method: 设计实验框架，让50个基于GPT-5的异质智能体在网络效应博弈中重复交互，系统变化网络效应强度、价格轨迹和决策历史长度等参数。

Result: LLM智能体系统性偏离期望均衡：在低价时低估参与度，高价时高估参与度，并维持持续分散。单调历史有助于稳定协调，非单调历史加剧分歧。

Conclusion: 价格是偏差的主要驱动因素，历史结构调节这一效应，网络效应放大情境扭曲，为多智能体AI系统配置提供实践指导。

Abstract: As artificial intelligence (AI) enters the agentic era, large language models
(LLMs) are increasingly deployed as autonomous agents that interact with one
another rather than operate in isolation. This shift raises a fundamental
question: how do machine agents behave in interdependent environments where
outcomes depend not only on their own choices but also on the coordinated
expectations of peers? To address this question, we study LLM agents in a
canonical network-effect game, where economic theory predicts convergence to a
fulfilled expectation equilibrium (FEE). We design an experimental framework in
which 50 heterogeneous GPT-5-based agents repeatedly interact under
systematically varied network-effect strengths, price trajectories, and
decision-history lengths. The results reveal that LLM agents systematically
diverge from FEE: they underestimate participation at low prices, overestimate
at high prices, and sustain persistent dispersion. Crucially, the way history
is structured emerges as a design lever. Simple monotonic histories-where past
outcomes follow a steady upward or downward trend-help stabilize coordination,
whereas nonmonotonic histories amplify divergence and path dependence.
Regression analyses at the individual level further show that price is the
dominant driver of deviation, history moderates this effect, and network
effects amplify contextual distortions. Together, these findings advance
machine behavior research by providing the first systematic evidence on
multi-agent AI systems under network effects and offer guidance for configuring
such systems in practice.

</details>


### [98] [The importance of emotional intelligence in leadership for building an effective team](https://arxiv.org/abs/2510.07004)
*Joanna Ćwiąkała,Waldemar Gajda,Michał Ćwiąkała,Ernest Górka,Dariusz Baran,Gabriela Wojak,Piotr Mrzygłód,Maciej Frasunkiewicz,Piotr Ręczajski,Jan Piwnik*

Main category: econ.GN

TL;DR: 本研究探讨情商在领导力中的重要性及其对团队建设的影响，发现高情商领导者能更好地培养信任、解决冲突并激励团队，从而提升组织绩效。


<details>
  <summary>Details</summary>
Motivation: 研究情商作为有效领导力核心组成部分的重要性，以及它如何影响团队凝聚力、动机和高绩效。

Method: 通过对100名专业人士的调查，考察情商能力（自我意识、自我调节、共情和社交技能）如何影响领导效能、团队协作、冲突解决和工作动机。

Result: 结果显示情商与领导特质（共情、道德行为、社交能力和激励效果）之间存在强相关性。高情商领导者被认为更具共情力、道德感，能更好地培养信任、解决冲突并激励承诺。

Conclusion: 情商不是孤立技能，而是人际效能、员工参与度和可持续商业成功的核心驱动力，应将其纳入领导力发展计划。

Abstract: This study investigates the significance of emotional intelligence (EI) as a
fundamental component of effective leadership and its impact on building
cohesive, motivated, and high-performing teams. Drawing on data from a survey
of 100 professionals, the research examines how EI competencies including
self-awareness, self-regulation, empathy, and social skills shape leadership
effectiveness, team collaboration, conflict resolution, and workplace
motivation. The results demonstrate strong correlations between EI and key
leadership traits such as empathy, ethical conduct, social competence, and
motivational effectiveness. Leaders with higher levels of EI are perceived as
more empathetic, ethical, and capable of fostering trust, resolving conflicts,
and inspiring commitment, thereby improving team dynamics and overall
organizational performance. The study also highlights that ethical leadership
significantly enhances motivation and that social competence is essential for
engaging and aligning teams toward common goals. While the findings are
exploratory due to the limited sample size, they provide valuable insights for
leadership development programs, emphasizing the importance of integrating
EI-focused training, coaching, and assessment tools into organizational
strategies. The research contributes to leadership theory by demonstrating that
emotional intelligence is not an isolated skill but a central driver of
interpersonal effectiveness, employee engagement, and sustainable business
success.

</details>


### [99] [The role of communication in effective business management](https://arxiv.org/abs/2510.07016)
*Dariusz Baran,Ernest Górka,Michał Ćwiąkała,Gabriela Wojak,Mateusz Grzelak,Katarzyna Olszyńska,Piotr Mrzygłód,Maciej Frasunkiewicz,Piotr Ręczajski,Maciej Ślusarczyk,Jan Piwnik*

Main category: econ.GN

TL;DR: 本文通过比较波兰两家中型汽车租赁公司的内部沟通实践，发现采用先进沟通技术、参与式模式和清晰反馈机制的公司显著优于传统沟通模式的公司，强调了双向沟通对员工参与度和运营效率的战略重要性。


<details>
  <summary>Details</summary>
Motivation: 研究内部沟通对有效企业管理的影响，特别是在汽车租赁行业中进行数据驱动的比较分析，填补该领域实证研究的空白。

Method: 采用结构化问卷调查方法，对220名员工进行了调查，评估了15个沟通相关因素，包括反馈文化、管理者可及性、信息清晰度和跨部门协调等。

Result: 研究发现公司X在所有评估维度上显著优于公司Y，主要归因于其使用先进沟通技术、参与式模式和清晰反馈机制。

Conclusion: 内部沟通在促进员工参与、组织透明度和运营效率方面具有战略作用，未来研究应探索跨行业和纵向视角，特别是在数字和混合工作环境背景下。

Abstract: This paper examines the impact of internal communication on effective
business management through a comparative analysis of two medium-sized car
rental companies operating in Poland. Using a structured survey completed by
220 employees, the study evaluates 15 communication-related factors, including
feedback culture, managerial accessibility, message clarity, and
interdepartmental coordination. The findings indicate that Company X
significantly outperforms Company Y across all evaluated dimensions, largely
due to its use of advanced communication technologies, participatory models,
and clear feedback mechanisms. The research highlights the strategic role of
two-way communication in fostering employee engagement, organizational
transparency, and operational efficiency. It contributes to the field by
offering a rare, data-driven comparison within one industry and supports
existing models that link internal communication to job satisfaction and
motivation. Limitations include reliance on self-reported data and focus on a
single industry and country. Future studies are recommended to explore
cross-sector and longitudinal perspectives, especially in the context of
digital and hybrid work environments.

</details>


### [100] [Optimal bidding in multiperiod day-ahead electricity markets assuming non-uniform uncertainty of clearing prices](https://arxiv.org/abs/2510.07025)
*Dávid Csercsik,Mihály András Vághy*

Main category: econ.GN

TL;DR: 本文研究了在市场出清价格采用简单对称但非均匀分布的情况下，多部分投标是否仍比简单投标和块投标带来更高预期利润。


<details>
  <summary>Details</summary>
Motivation: Richstein等人的研究假设市场出清价格服从均匀分布，本文旨在验证当价格分布为非均匀时，其结论是否仍然成立。

Method: 采用简单对称但非均匀的阶梯常数分布来模拟市场出清价格，重新分析多部分投标、简单投标和块投标的预期利润。

Result: 研究证实，即使在非均匀价格分布下，多部分投标仍能确保投标人获得比简单投标和块投标更高的预期利润。

Conclusion: Richstein等人的结论具有鲁棒性，即使在非均匀价格分布假设下，多部分投标的优势依然存在。

Abstract: In a recent publication, using a simple two-period model, which is already
capable to capture essential non-convex multiperiod bids, Richstein et al. have
shown that in the case of optimal bidding, multi-part bidding always ensures a
higher expected profit for the bidder, compared to simple bidding and
block-bidding. The model proposed in their analysis assumes a uniform
distribution of the market-clearing prices in both periods. In this paper, we
study how the conclusions of the analysis are affected, if a very simple,
symmetric, stepwise-constant but non-uniform distribution is assumed in the
case of the market-clearing price. We show that the results of Richstein et al.
also hold in this case.

</details>


### [101] [Exchange for Growth: Currency Dynamics in Emerging Markets](https://arxiv.org/abs/2510.07039)
*Shaunak Kulkarni,Rohan Ajay Dubey*

Main category: econ.GN

TL;DR: 本文重新审视双赤字假说，探讨财政赤字与经常账户赤字之间的关系，分析政府在保持贸易政策自主性的同时实现国内政策目标的能力。


<details>
  <summary>Details</summary>
Motivation: 双赤字假说自提出以来一直存在学术争议，其假设私人储蓄缺口稳定且经验证据相互矛盾。作者认为需要结合当代货币经济学理论框架，以更细致的方法来调和TDH的批评与其广泛应用基础之间的矛盾。

Method: 采用结合当代货币经济学理论框架的细致分析方法，研究实际经济因素与财政政策自主性之间的联系。

Result: 研究结果探讨了实际经济因素与财政政策自主性之间的联系（或缺乏联系），这有助于评估政府在保持贸易政策自主性和经常账户可持续性的同时实现国内政策目标的能力。

Conclusion: 需要更细致的理论框架来理解双赤字假说，以协调其批评与广泛应用基础之间的矛盾，从而更好地评估政府在实现政策目标时的自主能力。

Abstract: Currency crises are frequently discussed retrospectively as a necessary and
deterministic outcome of a finite sequence of fiscal decisions, monetary
manoeuvres, and limited exogenous inputs. Parallelly, the Twin Deficits
Hypothesis (TDH) posits that an increase in the budget deficit leads to a
direct rise in the current account deficit; although analogous to the idea of
currency crises being the outcome of finite inputs (through a balance of
payments crisis here), this notion runs contrary to the conclusion that
independent intervention can have bearing on the expression of a currency
crisis.
  Since its introduction by Mundell and Fleming in 1960, the TDH has sparked
considerable academic debate regarding its validity. Given its assumption of a
stable private savings gap, and conflicting empirical evidence, we believe
there are novel insights to be gained from a more nuanced approach
incorporating theoretical frameworks from contemporary Monetary Economics in
order to reconcile criticisms of the TDH with the basis for its broad
applicability.
  The results from this paper thus investigate the link - or lack thereof -
between real economic factors, which can support the assessment of fiscal
policy autonomy, and thereby a government's ability, to meet domestic policy
objectives without compromising trade policy autonomy and current account
sustainability.

</details>


### [102] [Analysis of managerial behaviors in business management](https://arxiv.org/abs/2510.07047)
*Ernest Górka,Dariusz Baran,Michał Ćwiąkała,Gabriela Wojak,Robert Marszczuk,Katarzyna Olszyńska,Piotr Mrzygłód,Maciej Frasunkiewicz,Piotr Ręczajski,Kamil Saługa,Maciej Ślusarczyk,Jan Piwnik*

Main category: econ.GN

TL;DR: 基于Blanchard情境领导模型的研究发现，支持型领导风格最普遍（占60%公司），授权型次之。领导风格灵活性对团队效能至关重要，过度依赖单一风格会导致效率低下。


<details>
  <summary>Details</summary>
Motivation: 探索不同管理行为如何影响团队效能和组织成果，使用Blanchard情境领导模型作为诊断工具。

Method: 在10家公司进行调研，通过基于情境的问卷评估领导适应性，识别指导型、教导型、支持型和授权型四种领导风格。

Result: 支持型（亲和型）领导风格占主导地位，存在于60%的被调查公司中，授权型次之。相关性分析显示某些风格间存在强负相关，特别是指导型与支持型之间。

Conclusion: 领导行为组合（而非静态特质）影响结果，平衡的情境方法能提升决策、士气和适应性。建议将Blanchard测试等诊断工具纳入管理培训以提高风格意识和行为灵活性。

Abstract: This study explores how different managerial behaviors influence team
effectiveness and organizational outcomes, using Kenneth Blanchard's
situational leadership model as a diagnostic tool. Conducted across ten
companies, the research evaluates leadership adaptability through a
scenario-based questionnaire identifying instructional, teaching, supportive,
and delegating styles. Results show that the supportive (affiliative) style is
dominant, present in 60 percent of surveyed companies, with delegating being
second. Correlation analysis reveals strong negative relationships between
certain styles, particularly instructional and supportive, indicating that
flexibility in leadership is crucial. The findings suggest that over-reliance
on any one style may lead to inefficiencies, while a balanced, situational
approach enhances decision-making, morale, and adaptability. The research
contributes to leadership theory by demonstrating how behavioral combinations,
not static traits, influence outcomes. It offers practical implications for
managerial training, recommending the integration of diagnostic tools like the
Blanchard test to improve style awareness and behavioral flexibility.
Limitations include reliance on self-assessment data and a small sample size.
Future research should explore longitudinal and cross-industry analyses to
assess how leadership behaviors evolve over time or under pressure.

</details>
