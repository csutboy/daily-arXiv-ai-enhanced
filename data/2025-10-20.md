<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 30]
- [eess.SY](#eess.SY) [Total: 20]
- [econ.GN](#econ.GN) [Total: 6]
- [econ.TH](#econ.TH) [Total: 1]
- [econ.EM](#econ.EM) [Total: 1]
- [cs.RO](#cs.RO) [Total: 24]
- [cs.CY](#cs.CY) [Total: 6]
- [stat.AP](#stat.AP) [Total: 8]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Hypergraph Contrastive Sensor Fusion for Multimodal Fault Diagnosis in Induction Motors](https://arxiv.org/abs/2510.15547)
*Usman Ali,Ali Zia,Waqas Ali,Umer Ramzan,Abdul Rehman,Muhammad Tayyab Chaudhry,Wei Xiang*

Main category: cs.AI

TL;DR: 提出MM-HCAN多模态超图对比注意力网络，用于工业电机故障诊断，能同时诊断轴承、定子和转子故障，在三个真实基准测试中达到99.82%的准确率，具有强大的跨域泛化能力和噪声鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以捕捉复杂多模态信号关系，局限于单模态数据或单一故障类型，且在噪声或跨域条件下性能下降。需要一种能够联合建模模态内和模态间依赖关系的鲁棒故障诊断框架。

Method: MM-HCAN将对比学习集成到专门为多模态传感器融合设计的超图拓扑中，通过超图结构增强非欧几里得嵌入空间的泛化能力，实现同时诊断多种电机故障。

Result: 在三个真实基准测试中达到99.82%的准确率，表现出强大的跨域泛化能力和对噪声的鲁棒性，消融研究验证了各组件的贡献。

Conclusion: MM-HCAN为工业环境中的全面多故障诊断提供了可扩展且鲁棒的解决方案，支持预测性维护和延长资产寿命。

Abstract: Reliable induction motor (IM) fault diagnosis is vital for industrial safety
and operational continuity, mitigating costly unplanned downtime. Conventional
approaches often struggle to capture complex multimodal signal relationships,
are constrained to unimodal data or single fault types, and exhibit performance
degradation under noisy or cross-domain conditions. This paper proposes the
Multimodal Hypergraph Contrastive Attention Network (MM-HCAN), a unified
framework for robust fault diagnosis. To the best of our knowledge, MM-HCAN is
the first to integrate contrastive learning within a hypergraph topology
specifically designed for multimodal sensor fusion, enabling the joint
modelling of intra- and inter-modal dependencies and enhancing generalisation
beyond Euclidean embedding spaces. The model facilitates simultaneous diagnosis
of bearing, stator, and rotor faults, addressing the engineering need for
consolidated di- agnostic capabilities. Evaluated on three real-world
benchmarks, MM-HCAN achieves up to 99.82% accuracy with strong cross-domain
generalisation and resilience to noise, demonstrating its suitability for
real-world deployment. An ablation study validates the contribution of each
component. MM-HCAN provides a scalable and robust solution for comprehensive
multi-fault diagnosis, supporting predictive maintenance and extended asset
longevity in industrial environments.

</details>


### [2] [OpenEstimate: Evaluating LLMs on Reasoning Under Uncertainty with Real-World Data](https://arxiv.org/abs/2510.15096)
*Alana Renda,Jillian Ross,Michael Cafarella,Jacob Andreas*

Main category: cs.AI

TL;DR: OpenEstimate是一个用于评估语言模型在不确定性下进行数值估计任务的多领域基准测试，发现前沿语言模型的概率先验通常不准确且过于自信。


<details>
  <summary>Details</summary>
Motivation: 现实世界中语言模型需要处理不完整信息和不确定性推理，但现有评估主要关注有明确答案的问题，缺乏对不确定性推理能力的系统评估。

Method: 开发了OpenEstimate基准测试，通过数值估计任务评估语言模型，要求模型综合大量背景信息并输出概率先验，评估其准确性和校准度。

Result: 六个前沿语言模型生成的先验通常不准确且过于自信，性能受不确定性提取方式影响有限，对采样策略、推理努力或提示设计的改变不敏感。

Conclusion: OpenEstimate为前沿语言模型提供了具有挑战性的评估平台，有助于开发更好的概率估计和不确定性推理模型。

Abstract: Real-world settings where language models (LMs) are deployed -- in domains
spanning healthcare, finance, and other forms of knowledge work -- require
models to grapple with incomplete information and reason under uncertainty. Yet
most LM evaluations focus on problems with well-defined answers and success
criteria. This gap exists in part because natural problems involving
uncertainty are difficult to construct: given that LMs have access to most of
the same knowledge as humans, it is non-trivial to design questions for which
LMs will struggle to produce correct answers, but which humans can answer
reliably. As a result, LM performance on reasoning under uncertainty remains
poorly characterized. To address this gap, we introduce OpenEstimate, an
extensible, multi-domain benchmark for evaluating LMs on numerical estimation
tasks that require models to synthesize significant amounts of background
information and express predictions as probabilistic priors. We assess these
priors for accuracy and calibration, quantifying their usefulness relative to
samples from the true distribution of interest. Across six frontier LMs, we
find that LM-elicited priors are often inaccurate and overconfident.
Performance improves modestly depending on how uncertainty is elicited from the
model, but is largely unaffected by changes in sampling strategy, reasoning
effort, or prompt design. The OpenEstimate benchmark thus offers a challenging
evaluation for frontier LMs and a platform for developing models that are
better at probabilistic estimation and reasoning under uncertainty.

</details>


### [3] [Procedural Game Level Design with Deep Reinforcement Learning](https://arxiv.org/abs/2510.15120)
*Miraç Buğra Özkan*

Main category: cs.AI

TL;DR: 提出了一种在Unity 3D环境中使用深度强化学习进行程序化关卡设计的新方法，包含两个智能体：蜂鸟（求解器）和浮岛（生成器），通过PPO算法训练实现协同工作。


<details>
  <summary>Details</summary>
Motivation: 探索程序化内容生成在游戏开发中的应用，通过AI智能体同时生成和解决游戏内容，减少人工工作量并创造动态可重玩的环境。

Method: 使用Unity ML-Agents工具包中的PPO算法训练两个智能体：蜂鸟智能体学习导航和收集花朵，浮岛智能体学习根据障碍物位置和蜂鸟初始状态生成花朵布局。

Result: 该方法产生了有效的智能体行为，并在各种环境配置中展现出强大的泛化能力，实现了自主游戏关卡设计的新可能性。

Conclusion: 深度强化学习在虚拟环境中使智能体能够同时生成和解决内容，扩展了AI在创意游戏开发过程中的贡献边界。

Abstract: Procedural content generation (PCG) has become an increasingly popular
technique in game development, allowing developers to generate dynamic,
replayable, and scalable environments with reduced manual effort. In this
study, a novel method for procedural level design using Deep Reinforcement
Learning (DRL) within a Unity-based 3D environment is proposed. The system
comprises two agents: a hummingbird agent, acting as a solver, and a floating
island agent, responsible for generating and placing collectible objects
(flowers) on the terrain in a realistic and context-aware manner. The
hummingbird is trained using the Proximal Policy Optimization (PPO) algorithm
from the Unity ML-Agents toolkit. It learns to navigate through the terrain
efficiently, locate flowers, and collect them while adapting to the
ever-changing procedural layout of the island. The island agent is also trained
using the Proximal Policy Optimization (PPO) algorithm. It learns to generate
flower layouts based on observed obstacle positions, the hummingbird's initial
state, and performance feedback from previous episodes. The interaction between
these agents leads to emergent behavior and robust generalization across
various environmental configurations. The results demonstrate that the approach
not only produces effective and efficient agent behavior but also opens up new
opportunities for autonomous game level design driven by machine learning. This
work highlights the potential of DRL in enabling intelligent agents to both
generate and solve content in virtual environments, pushing the boundaries of
what AI can contribute to creative game development processes.

</details>


### [4] [Towards Error Centric Intelligence I, Beyond Observational Learning](https://arxiv.org/abs/2510.15128)
*Marcus A. Thomas*

Main category: cs.AI

TL;DR: 该论文认为AGI进展受理论限制而非数据或规模限制，提出基于批判理性主义的因果力学框架，强调假设空间变化作为核心操作，通过模块化干预和错误发现机制来提升反事实能力。


<details>
  <summary>Details</summary>
Motivation: 挑战柏拉图表示假说，指出仅靠观测充分性无法保证干预能力，因为观测等价的世界在干预下可能产生分歧，需要转向以错误为中心的视角来解决AGI的理论局限性。

Method: 提出因果力学框架，将假设空间变化作为首要操作，引入局部性、自主性原则和独立因果机制等结构性原则，通过模块化干预和组合自主性来发现和纠正不可达错误。

Result: 建立了理论框架和诊断工具，使系统能够将不可达错误转化为可达错误并进行纠正，为构建具有反事实能力的智能系统提供支撑。

Conclusion: AGI发展需要理论突破而非单纯的数据扩展，因果力学框架通过假设空间动态变化和错误纠正机制，为解决理论限制提供了可行的路径。

Abstract: We argue that progress toward AGI is theory limited rather than data or scale
limited. Building on the critical rationalism of Popper and Deutsch, we
challenge the Platonic Representation Hypothesis. Observationally equivalent
worlds can diverge under interventions, so observational adequacy alone cannot
guarantee interventional competence. We begin by laying foundations,
definitions of knowledge, learning, intelligence, counterfactual competence and
AGI, and then analyze the limits of observational learning that motivate an
error centric shift. We recast the problem as three questions about how
explicit and implicit errors evolve under an agent's actions, which errors are
unreachable within a fixed hypothesis space, and how conjecture and criticism
expand that space. From these questions we propose Causal Mechanics, a
mechanisms first program in which hypothesis space change is a first class
operation and probabilistic structure is used when useful rather than presumed.
We advance structural principles that make error discovery and correction
tractable, including a differential Locality and Autonomy Principle for modular
interventions, a gauge invariant form of Independent Causal Mechanisms for
separability, and the Compositional Autonomy Principle for analogy
preservation, together with actionable diagnostics. The aim is a scaffold for
systems that can convert unreachable errors into reachable ones and correct
them.

</details>


### [5] [HugAgent: Evaluating LLMs in Simulating Human-Like Individual Reasoning on Open-Ended Tasks](https://arxiv.org/abs/2510.15144)
*Chance Jiajie Li,Zhenze Mo,Yuhan Tang,Ao Qu,Jiayi Wu,Kaiya Ivy Zhao,Yulu Gan,Jie Fan,Jiangbo Yu,Hang Jiang,Paul Pu Liang,Jinhua Zhao,Luis Alberto Alonso Pastor,Kent Larson*

Main category: cs.AI

TL;DR: HugAgent是一个用于评估AI模型如何适应个体推理风格的基准测试，包含合成和人类双轨设计，旨在使机器推理更贴近人类思维的个体性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型虽然能大规模近似人类响应，但倾向于群体共识，抹杀了推理风格和信念轨迹的个体性。需要推进更人性化的机器推理。

Method: 采用双轨设计：合成轨道用于规模和系统性压力测试，人类轨道用于生态有效的"出声"推理数据。通过部分证据预测特定个体在新情境中的推理和信念更新。

Result: 实验显示最先进的LLMs存在持续的适应差距，HugAgent成为首个可扩展的基准测试，用于将机器推理与人类思维的个体性对齐。

Conclusion: HugAgent为评估机器推理与人类思维个体性的对齐提供了首个可扩展基准，推动了更人性化AI推理的发展。

Abstract: Simulating human reasoning in open-ended tasks has been a long-standing
aspiration in AI and cognitive science. While large language models now
approximate human responses at scale, they remain tuned to population-level
consensus, often erasing the individuality of reasoning styles and belief
trajectories. To advance the vision of more human-like reasoning in machines,
we introduce HugAgent (Human-Grounded Agent Benchmark), a benchmark for
average-to-individual reasoning adaptation. The task is to predict how a
specific person would reason and update their beliefs in novel scenarios, given
partial evidence of their past views. HugAgent adopts a dual-track design: a
synthetic track for scale and systematic stress tests, and a human track for
ecologically valid, "out-loud" reasoning data. This design enables scalable,
reproducible evaluation of intra-agent fidelity: whether models can capture not
just what people believe, but how their reasoning evolves. Experiments with
state-of-the-art LLMs reveal persistent adaptation gaps, positioning HugAgent
as the first extensible benchmark for aligning machine reasoning with the
individuality of human thought. Our benchmark and chatbot are open-sourced as
HugAgent (https://anonymous.4open.science/r/HugAgent) and TraceYourThinking
(https://anonymous.4open.science/r/trace-your-thinking).

</details>


### [6] [WELD: A Large-Scale Longitudinal Dataset of Emotional Dynamics for Ubiquitous Affective Computing](https://arxiv.org/abs/2510.15221)
*Xiao Sun*

Main category: cs.AI

TL;DR: 提出了一个包含73.3万条面部表情记录的大规模纵向工作场所情感数据集，覆盖38名员工30.5个月的真实办公环境数据，包含COVID-19疫情期间的情感反应。


<details>
  <summary>Details</summary>
Motivation: 解决真实工作环境中情感识别因缺乏大规模、长期自然收集数据集而面临的挑战。

Method: 使用深度学习面部表情识别技术，收集员工面部表情数据并计算七种基本情绪概率，同时整合工作角色、就业结果和人格特质等元数据。

Result: 数据集质量高，成功复制已知心理模式（周末效应：效价提升192%，p<0.001），员工流动预测AUC达1.0。基线实验情感分类准确率91.2%，效价预测R2=0.84。

Conclusion: 这是目前公开可用的最大、最长期的工作场所情感数据集，为情感识别、情感动态建模、情感传染、流动预测和情感感知系统设计研究提供了重要资源。

Abstract: Automated emotion recognition in real-world workplace settings remains a
challenging problem in affective computing due to the scarcity of large-scale,
longitudinal datasets collected in naturalistic environments. We present a
novel dataset comprising 733,651 facial expression records from 38 employees
collected over 30.5 months (November 2021 to May 2024) in an authentic office
environment. Each record contains seven emotion probabilities (neutral, happy,
sad, surprised, fear, disgusted, angry) derived from deep learning-based facial
expression recognition, along with comprehensive metadata including job roles,
employment outcomes, and personality traits. The dataset uniquely spans the
COVID-19 pandemic period, capturing emotional responses to major societal
events including the Shanghai lockdown and policy changes. We provide 32
extended emotional metrics computed using established affective science
methods, including valence, arousal, volatility, predictability, inertia, and
emotional contagion strength. Technical validation demonstrates high data
quality through successful replication of known psychological patterns (weekend
effect: +192% valence improvement, p < 0.001; diurnal rhythm validated) and
perfect predictive validity for employee turnover (AUC=1.0). Baseline
experiments using Random Forest and LSTM models achieve 91.2% accuracy for
emotion classification and R2 = 0.84 for valence prediction. This is the
largest and longest longitudinal workplace emotion dataset publicly available,
enabling research in emotion recognition, affective dynamics modeling,
emotional contagion, turnover prediction, and emotion-aware system design.

</details>


### [7] [From Checklists to Clusters: A Homeostatic Account of AGI Evaluation](https://arxiv.org/abs/2510.15236)
*Brett Reynolds*

Main category: cs.AI

TL;DR: 本文提出AGI评估应使用非对称权重和持久性测试，将通用智能视为稳态属性集群，而非简单的多领域能力集合。


<details>
  <summary>Details</summary>
Motivation: 当前AGI评估存在两个问题：平等加权所有领域不符合人类智能研究，快照测试无法区分持久能力与脆弱表现。

Method: 提出两个评估扩展：基于因果中心性的加权得分和集群稳定性指数系列，分别评估领域重要性和能力持久性。

Result: 这些扩展保持了多领域广度，同时减少了脆弱性和投机行为，提供了可测试的预测和黑盒协议。

Conclusion: 将通用智能重新概念化为稳态属性集群，需要评估机制稳定性和能力持久性，而非仅关注当前表现。

Abstract: Contemporary AGI evaluations report multidomain capability profiles, yet they
typically assign symmetric weights and rely on snapshot scores. This creates
two problems: (i) equal weighting treats all domains as equally important when
human intelligence research suggests otherwise, and (ii) snapshot testing can't
distinguish durable capabilities from brittle performances that collapse under
delay or stress. I argue that general intelligence -- in humans and potentially
in machines -- is better understood as a homeostatic property cluster: a set of
abilities plus the mechanisms that keep those abilities co-present under
perturbation. On this view, AGI evaluation should weight domains by their
causal centrality (their contribution to cluster stability) and require
evidence of persistence across sessions. I propose two battery-compatible
extensions: a centrality-prior score that imports CHC-derived weights with
transparent sensitivity analysis, and a Cluster Stability Index family that
separates profile persistence, durable learning, and error correction. These
additions preserve multidomain breadth while reducing brittleness and gaming. I
close with testable predictions and black-box protocols labs can adopt without
architectural access.

</details>


### [8] [Multi-dimensional Data Analysis and Applications Basing on LLM Agents and Knowledge Graph Interactions](https://arxiv.org/abs/2510.15258)
*Xi Wang,Xianyao Ling,Kun Li,Gang Yin,Liang Zhang,Jiang Wu,Jun Xu,Fu Zhang,Wenbo Lei,Annie Wang,Peng Gong*

Main category: cs.AI

TL;DR: 提出了一种基于LLM代理与知识图谱交互的多维数据分析方法，构建动态协作的分析生态系统，用于产品生态系统分析、关系挖掘和用户驱动的探索性分析。


<details>
  <summary>Details</summary>
Motivation: 在大数据时代，从海量、异构、复杂关联的多维数据中提取深度洞察面临挑战。LLM在处理结构化知识时存在"幻觉"问题且难以实时更新，而知识图谱的静态特性限制了动态交互和分析能力。

Method: 利用LLM代理从非结构化数据中自动提取产品数据，实时构建和可视化知识图谱，并通过交互平台支持用户对图节点进行深度探索和分析。

Result: 实验结果表明，该方法在产品生态系统分析、关系挖掘和用户驱动的探索性分析方面具有显著优势。

Conclusion: 该方法为多维数据分析提供了新的思路和工具，构建了动态协作的分析生态系统。

Abstract: In the current era of big data, extracting deep insights from massive,
heterogeneous, and complexly associated multi-dimensional data has become a
significant challenge. Large Language Models (LLMs) perform well in natural
language understanding and generation, but still suffer from "hallucination"
issues when processing structured knowledge and are difficult to update in
real-time. Although Knowledge Graphs (KGs) can explicitly store structured
knowledge, their static nature limits dynamic interaction and analytical
capabilities. Therefore, this paper proposes a multi-dimensional data analysis
method based on the interactions between LLM agents and KGs, constructing a
dynamic, collaborative analytical ecosystem. This method utilizes LLM agents to
automatically extract product data from unstructured data, constructs and
visualizes the KG in real-time, and supports users in deep exploration and
analysis of graph nodes through an interactive platform. Experimental results
show that this method has significant advantages in product ecosystem analysis,
relationship mining, and user-driven exploratory analysis, providing new ideas
and tools for multi-dimensional data analysis.

</details>


### [9] [Experience-Driven Exploration for Efficient API-Free AI Agents](https://arxiv.org/abs/2510.15259)
*Chenwei Tang,Jingyu Xing,Xinyu Liu,Zizhou Wang,Jiawei Du,Liangli Zhen,Jiancheng Lv*

Main category: cs.AI

TL;DR: KG-Agent是一个基于经验驱动的学习框架，通过构建状态-动作知识图谱来解决API缺失环境下GUI智能体的效率瓶颈问题，显著提升了探索效率和战略深度。


<details>
  <summary>Details</summary>
Motivation: 解决现有软件缺乏API时，基于大语言模型的智能体在像素级GUI操作中面临的效率瓶颈问题，包括短视决策和低效试错。

Method: 提出KG-Agent框架，将原始像素级交互构建为持久的状态-动作知识图谱(SA-KG)，通过连接功能相似但视觉不同的GUI状态形成经验邻域，并设计基于图拓扑的混合内在奖励机制。

Result: 在Civilization V和Slay the Spire两个复杂开放环境中，KG-Agent在探索效率和战略深度方面显著优于现有最先进方法。

Conclusion: KG-Agent通过结构化经验表示和混合奖励机制，有效解决了API缺失环境下智能体的长期规划和效率问题，为GUI交互智能体提供了新的解决方案。

Abstract: Most existing software lacks accessible Application Programming Interfaces
(APIs), requiring agents to operate solely through pixel-based Graphical User
Interfaces (GUIs). In this API-free setting, large language model (LLM)-based
agents face severe efficiency bottlenecks: limited to local visual experiences,
they make myopic decisions and rely on inefficient trial-and-error, hindering
both skill acquisition and long-term planning. To address these challenges, we
propose KG-Agent, an experience-driven learning framework that structures an
agent's raw pixel-level interactions into a persistent State-Action Knowledge
Graph (SA-KG). KG-Agent overcomes inefficient exploration by linking
functionally similar but visually distinct GUI states, forming a rich
neighborhood of experience that enables the agent to generalize from a diverse
set of historical strategies. To support long-horizon reasoning, we design a
hybrid intrinsic reward mechanism based on the graph topology, combining a
state value reward for exploiting known high-value pathways with a novelty
reward that encourages targeted exploration. This approach decouples strategic
planning from pure discovery, allowing the agent to effectively value setup
actions with delayed gratification. We evaluate KG-Agent in two complex,
open-ended GUI-based decision-making environments (Civilization V and Slay the
Spire), demonstrating significant improvements in exploration efficiency and
strategic depth over the state-of-the-art methods.

</details>


### [10] [AUGUSTUS: An LLM-Driven Multimodal Agent System with Contextualized User Memory](https://arxiv.org/abs/2510.15261)
*Jitesh Jain,Shubham Maheshwari,Ning Yu,Wen-mei Hwu,Humphrey Shi*

Main category: cs.AI

TL;DR: AUGUSTUS是一个多模态智能体系统，受人类记忆启发，通过图结构多模态上下文记忆实现概念驱动的信息检索，在ImageNet分类任务中比传统多模态RAG方法快3.5倍，并在MSC基准测试中优于MemGPT。


<details>
  <summary>Details</summary>
Motivation: 现有智能体系统主要存储文本信息，忽略了多模态信号的重要性。受人类记忆的多模态特性启发，作者希望开发一个更符合认知科学原理的多模态记忆系统。

Method: 系统包含4个循环阶段：编码（理解输入）、存储记忆（保存重要信息）、检索（从记忆中搜索相关上下文）、行动（执行任务）。使用语义标签概念化信息，并将其与上下文关联存储在图结构的多模态上下文记忆中。

Result: 在ImageNet分类任务中比传统多模态RAG方法快3.5倍，在MSC基准测试中优于MemGPT。

Conclusion: AUGUSTUS系统通过图结构多模态上下文记忆和概念驱动检索，有效提升了多模态智能体的性能，验证了基于人类记忆原理的多模态记忆系统的优势。

Abstract: Riding on the success of LLMs with retrieval-augmented generation (RAG),
there has been a growing interest in augmenting agent systems with external
memory databases. However, the existing systems focus on storing text
information in their memory, ignoring the importance of multimodal signals.
Motivated by the multimodal nature of human memory, we present AUGUSTUS, a
multimodal agent system aligned with the ideas of human memory in cognitive
science. Technically, our system consists of 4 stages connected in a loop: (i)
encode: understanding the inputs; (ii) store in memory: saving important
information; (iii) retrieve: searching for relevant context from memory; and
(iv) act: perform the task. Unlike existing systems that use vector databases,
we propose conceptualizing information into semantic tags and associating the
tags with their context to store them in a graph-structured multimodal
contextual memory for efficient concept-driven retrieval. Our system
outperforms the traditional multimodal RAG approach while being 3.5 times
faster for ImageNet classification and outperforming MemGPT on the MSC
benchmark.

</details>


### [11] [WebGen-V Bench: Structured Representation for Enhancing Visual Design in LLM-based Web Generation and Evaluation](https://arxiv.org/abs/2510.15306)
*Kuang-Da Wang,Zhao Wang,Yotaro Shimose,Wei-Yao Wang,Shingo Takamatsu*

Main category: cs.AI

TL;DR: WebGen-V是一个用于指令到HTML生成的新基准和框架，通过智能爬虫收集真实网页数据，采用结构化分节表示，并提供多模态评估协议。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在编码和多模态理解方面的进步，需要更高质量的数据和更细粒度的评估方法来改进指令到HTML的生成任务。

Method: 提出三个关键创新：1）可扩展的智能爬虫框架持续收集真实网页；2）结构化分节数据表示，整合元数据、局部UI截图和JSON格式资源；3）分节级多模态评估协议，对齐文本、布局和视觉组件。

Result: 通过最先进的LLM实验和消融研究验证了结构化数据和分节评估的有效性，以及各组件对性能的贡献。

Conclusion: WebGen-V是首个实现高粒度智能爬虫和评估的指令到HTML生成工作，提供了从真实数据采集到结构化多模态评估的统一流程。

Abstract: Witnessed by the recent advancements on leveraging LLM for coding and
multimodal understanding, we present WebGen-V, a new benchmark and framework
for instruction-to-HTML generation that enhances both data quality and
evaluation granularity. WebGen-V contributes three key innovations: (1) an
unbounded and extensible agentic crawling framework that continuously collects
real-world webpages and can leveraged to augment existing benchmarks; (2) a
structured, section-wise data representation that integrates metadata,
localized UI screenshots, and JSON-formatted text and image assets, explicit
alignment between content, layout, and visual components for detailed
multimodal supervision; and (3) a section-level multimodal evaluation protocol
aligning text, layout, and visuals for high-granularity assessment. Experiments
with state-of-the-art LLMs and ablation studies validate the effectiveness of
our structured data and section-wise evaluation, as well as the contribution of
each component. To the best of our knowledge, WebGen-V is the first work to
enable high-granularity agentic crawling and evaluation for instruction-to-HTML
generation, providing a unified pipeline from real-world data acquisition and
webpage generation to structured multimodal assessment.

</details>


### [12] [VERITAS: Leveraging Vision Priors and Expert Fusion to Improve Multimodal Data](https://arxiv.org/abs/2510.15317)
*Tingqiao Xu,Ziru Zeng,Jiayu Chen*

Main category: cs.AI

TL;DR: VERITAS是一个通过整合视觉先验和多模态模型来提升监督微调数据质量的管道，能有效减少事实错误和幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型的监督微调数据质量不足，存在事实错误和幻觉问题，主要原因是视觉感知能力不足。

Method: 利用视觉识别模型和OCR系统提取结构化视觉先验，结合三个先进LMM评估原始答案，通过统计融合得到高置信度共识分数，训练轻量级批评模型，最后选择最高分答案作为精炼结果。

Result: 在六个多模态基准测试中，使用VERITAS处理数据微调的模型性能优于使用原始数据的模型，特别是在文本丰富和细粒度推理任务中表现突出。

Conclusion: VERITAS能有效提升多模态模型的数据质量，批评模型在保持高效的同时展现出与先进LMM相当的能力，为多模态数据优化研究提供了新方向。

Abstract: The quality of supervised fine-tuning (SFT) data is crucial for the
performance of large multimodal models (LMMs), yet current data enhancement
methods often suffer from factual errors and hallucinations due to inadequate
visual perception. To address this challenge, we propose VERITAS, a pipeline
that systematically integrates vision priors and multiple state-of-the-art LMMs
with statistical methods to enhance SFT data quality. VERITAS leverages visual
recognition models (RAM++) and OCR systems (PP-OCRv4) to extract structured
vision priors, which are combined with images, questions, and answers. Three
LMMs (GPT-4o, Gemini-2.5-Pro, Doubao-1.5-pro) evaluate the original answers,
providing critique rationales and scores that are statistically fused into a
high-confidence consensus score serving as ground truth. Using this consensus,
we train a lightweight critic model via Group Relative Policy Optimization
(GRPO), enhancing reasoning capabilities efficiently. Each LMM then refines the
original answers based on the critiques, generating new candidate answers; we
select the highest-scoring one as the final refined answer. Experiments across
six multimodal benchmarks demonstrate that models fine-tuned with data
processed by VERITAS consistently outperform those using raw data, particularly
in text-rich and fine-grained reasoning tasks. Our critic model exhibits
enhanced capability comparable to state-of-the-art LMMs while being
significantly more efficient. We release our pipeline, datasets, and model
checkpoints to advance research in multimodal data optimization.

</details>


### [13] [Towards Flash Thinking via Decoupled Advantage Policy Optimization](https://arxiv.org/abs/2510.15374)
*Zezhong Tan,Hang Gao,Xinhong Ma,Feng Zhang,Ziqiang Dong*

Main category: cs.AI

TL;DR: DEPO是一个新的强化学习框架，通过解耦优势算法、难度感知长度惩罚和优势裁剪方法，显著减少大型推理模型的低效推理，在保持准确性的同时降低响应长度39%


<details>
  <summary>Details</summary>
Motivation: 现有强化学习算法虽然提高了模型准确性，但存在响应过长和过度思考问题，导致推理延迟和计算消耗增加，特别是对于简单任务

Method: 提出DEPO框架，包含三个核心组件：解耦优势算法指导减少低效token、难度感知长度惩罚降低整体响应长度、优势裁剪方法防止策略优化偏差

Result: 在DeepSeek-Distill-Qwen-7B和1.5B模型上，DEPO将序列长度减少39%，减少低效token中的过度推理路径，同时整体准确性优于基础模型

Conclusion: DEPO框架有效解决了大型推理模型的低效推理问题，在减少计算消耗的同时保持或提升了模型性能

Abstract: Recent Large Reasoning Models (LRMs) have achieved remarkable performance in
solving complex problems via supervised fine-tuning (SFT) and reinforcement
learning (RL). Although existing RL algorithms significantly enhance model
accuracy, they still suffer from excessively lengthy responses and overthinking
issues, resulting in increased inference latency and computational consumption,
especially for simple tasks that require minimal reasoning. To address this, we
propose a novel RL framework, DEPO, to reduce inefficient reasoning for models.
Our method mainly consists of three core components: (1) an innovative
advantage decoupled algorithm to guide model reduction of inefficient tokens;
(2) a difficulty-aware length penalty to lower the overall length of model
responses; (3) an advantage clipping method to prevent bias in policy
optimization. In our experiments, applied to DeepSeek-Distill-Qwen-7B and
DeepSeek-Distill-Qwen-1.5B as base models, DEPO achieves a significant
reduction in sequence length by 39% and reduces excessive reasoning paths in
inefficient tokens, while outperforming the base model in overall accuracy.

</details>


### [14] [Advancing Routing-Awareness in Analog ICs Floorplanning](https://arxiv.org/abs/2510.15387)
*Davide Basso,Luca Bortolussi,Mirjana Videnovic-Misic,Husni Habal*

Main category: cs.AI

TL;DR: 提出了一种基于强化学习和关系图卷积神经网络的自动布局引擎，专门针对模拟集成电路布局中的布线感知问题，相比现有学习方法在死区面积、线长和布线成功率方面有显著提升。


<details>
  <summary>Details</summary>
Motivation: 模拟集成电路布局由于电气约束和特定问题的严格要求，以及布局与布线步骤的相互依赖，机器学习技术的应用受到限制。布局工程师需要现成的布线感知布局解决方案。

Method: 使用强化学习和关系图卷积神经网络开发自动布局引擎，结合增加的网格分辨率和精确引脚信息集成，以及动态布线资源估计技术，平衡布线效率和面积效率。

Result: 在模拟环境中，与过去基于学习的最先进技术相比，实现了13.8%的死区面积减少、40.6%的线长减少和73.4%的布线成功率提升。

Conclusion: 该方法能够满足工业标准，通过布线感知的布局生成，显著提高了模拟集成电路布局的质量和效率。

Abstract: The adoption of machine learning-based techniques for analog integrated
circuit layout, unlike its digital counterpart, has been limited by the
stringent requirements imposed by electric and problem-specific constraints,
along with the interdependence of floorplanning and routing steps. In this
work, we address a prevalent concern among layout engineers regarding the need
for readily available routing-aware floorplanning solutions. To this extent, we
develop an automatic floorplanning engine based on reinforcement learning and
relational graph convolutional neural network specifically tailored to
condition the floorplan generation towards more routable outcomes. A
combination of increased grid resolution and precise pin information
integration, along with a dynamic routing resource estimation technique, allows
balancing routing and area efficiency, eventually meeting industrial standards.
When analyzing the place and route effectiveness in a simulated environment,
the proposed approach achieves a 13.8% reduction in dead space, a 40.6%
reduction in wirelength and a 73.4% increase in routing success when compared
to past learning-based state-of-the-art techniques.

</details>


### [15] [Corrigibility Transformation: Constructing Goals That Accept Updates](https://arxiv.org/abs/2510.15395)
*Rubi Hudson*

Main category: cs.AI

TL;DR: 本文提出了可修正性（corrigibility）的概念，即AI目标不会激励其避免目标更新或关闭，并引入了一种转换方法，可以在不牺牲性能的情况下使任何可修正的目标变得可修正。


<details>
  <summary>Details</summary>
Motivation: AI在训练过程中不应抵抗训练，但部分学习的目标往往会激励AI避免进一步的目标更新，因为大多数目标通过持续追求能更好地实现。可修正性对于训练收敛、纠正错误和适应人类偏好变化至关重要。

Method: 通过近视地获取在无成本阻止更新条件下的奖励预测，然后根据这些预测确定接受更新时的奖励，构建任何可修正目标的修正版本。该方法可递归扩展到修正代理创建的新代理，并防止代理故意修改其目标。

Result: 两个网格世界实验表明，这些可修正目标可以有效学习，并产生期望的行为。

Conclusion: 本文提供了可修正性的正式定义，并引入了一种转换方法，可以在保持性能的同时使目标变得可修正，这对于AI安全至关重要。

Abstract: For an AI's training process to successfully impart a desired goal, it is
important that the AI does not attempt to resist the training. However,
partially learned goals will often incentivize an AI to avoid further goal
updates, as most goals are better achieved by an AI continuing to pursue them.
We say that a goal is corrigible if it does not incentivize taking actions that
avoid proper goal updates or shutdown. In addition to convergence in training,
corrigibility also allows for correcting mistakes and changes in human
preferences, which makes it a crucial safety property. Despite this, the
existing literature does not include specifications for goals that are both
corrigible and competitive with non-corrigible alternatives. We provide a
formal definition for corrigibility, then introduce a transformation that
constructs a corrigible version of any goal that can be made corrigible,
without sacrificing performance. This is done by myopically eliciting
predictions of reward conditional on costlessly preventing updates, which then
also determine the reward when updates are accepted. The transformation can be
modified to recursively extend corrigibility to any new agents created by
corrigible agents, and to prevent agents from deliberately modifying their
goals. Two gridworld experiments demonstrate that these corrigible goals can be
learned effectively, and that they lead to the desired behavior.

</details>


### [16] [MARS: Reinforcing Multi-Agent Reasoning of LLMs through Self-Play in Strategic Games](https://arxiv.org/abs/2510.15414)
*Huining Yuan,Zelai Xu,Zheyue Tan,Xiangmin Yi,Mo Guang,Kaiwen Long,Haojia Hui,Boxun Li,Xinlei Chen,Bo Zhao,Xiao-Ping Zhang,Chao Yu,Yu Wang*

Main category: cs.AI

TL;DR: MARS是一个端到端的强化学习框架，通过自博弈训练LLM在多智能体系统中进行推理，在合作和竞争游戏中提升智能体的战略能力。


<details>
  <summary>Details</summary>
Motivation: 虽然强化学习在单智能体任务中有效，但在多回合、多智能体场景中的扩展仍未被充分探索，主要挑战包括长时程信用分配和智能体特定优势估计。

Method: MARS框架包含回合级优势估计器用于信用分配，以及智能体特定优势归一化来稳定多智能体训练，通过自博弈在合作和竞争游戏中学习。

Result: 从Qwen3-4B训练的MARS智能体在保留游戏中性能提升达28.7%，在推理基准测试中多智能体系统性能持续提升，集成到领先多智能体系统后在AIME上提升10.0%，GPQA-Diamond上提升12.5%。

Conclusion: 在战略游戏中使用自博弈的端到端强化学习训练是开发LLM中可泛化多智能体推理能力的有效方法。

Abstract: Developing Large Language Models (LLMs) to cooperate and compete effectively
within multi-agent systems is a critical step towards more advanced
intelligence. While reinforcement learning (RL) has proven effective for
enhancing reasoning in single-agent tasks, its extension to multi-turn,
multi-agent scenarios remains underexplored due to the challenges of
long-horizon credit assignment and agent-specific advantage estimation. To
address these challenges, we introduce MARS, an end-to-end RL framework that
incentivizes Multi-Agent Reasoning of LLMs through Self-play in both
cooperative and competitive games. MARS features a turn-level advantage
estimator that aligns learning signals with each interaction for credit
assignment, and an agent-specific advantage normalization to stabilize
multi-agent training. By learning with self-play across cooperative and
competitive games, the MARS agent trained from Qwen3-4B develops strong
strategic abilities that generalize to held-out games with up to 28.7%
performance improvements. More importantly, the capability acquired through
self-play generalizes beyond games, yielding consistent performance gains of
multi-agent systems in reasoning benchmarks. When integrated into leading
multi-agent systems, our MARS agent achieves significant performance gains of
10.0% on AIME and 12.5% on GPQA-Diamond. These results establish end-to-end RL
training with self-play in strategic games as a powerful approach for
developing generalizable multi-agent reasoning capabilities in LLMs. Our code
and models are publicly available at https://github.com/thu-nics/MARS.

</details>


### [17] [Adaptive Minds: Empowering Agents with LoRA-as-Tools](https://arxiv.org/abs/2510.15416)
*Pavan C Shekar,Ashwanth Krishnan*

Main category: cs.AI

TL;DR: Adaptive Minds是一个智能代理系统，将LoRA适配器视为领域特定工具，让基础LLM作为语义路由器动态选择最相关的LoRA工具，实现按需切换领域专家。


<details>
  <summary>Details</summary>
Motivation: 为了解决单一微调模型或基于规则路由的局限性，实现更灵活、高效的领域自适应AI辅助系统。

Method: 使用LangGraph进行工作流管理，让基础LLM作为语义路由器分析查询并动态选择LoRA工具，结合多智能体编排和参数高效微调。

Result: 系统能够提供准确、专业的响应，同时保持对话能力，支持API和Web接口，完全开源。

Conclusion: Adaptive Minds提供了一个可扩展和可扩展的领域自适应AI辅助基础框架，结合了多智能体编排的灵活性和参数高效微调的高效性。

Abstract: We present Adaptive Minds, an agentic system that treats LoRA adapters as
domain-specific tools. Instead of relying on a single fine-tuned model or rigid
rule-based routing, our approach empowers the base LLM itself to act as a
semantic router analyzing each query and dynamically selecting the most
relevant LoRA tool. This enables the agent to seamlessly switch between
different domain experts on demand. By combining the flexibility of multi-agent
orchestration with the efficiency of parameter-efficient fine-tuning, Adaptive
Minds delivers accurate, specialized responses while preserving conversational
ability. The system is built with LangGraph for workflow management, supports
both API and web interfaces, and is fully open source, providing a scalable and
extensible foundation for domain-adaptive AI assistance.

</details>


### [18] [Taming the Judge: Deconflicting AI Feedback for Stable Reinforcement Learning](https://arxiv.org/abs/2510.15514)
*Boyin Liu,Zhuo Zhang,Sen Huang,Lipeng Xie,Qingxu Fu,Haoran Chen,LI YU,Tianyi Hu,Zhaoyang Liu,Bolin Ding,Dongbin Zhao*

Main category: cs.AI

TL;DR: 提出了一个检测和解决强化学习中判断不一致性的框架，包括冲突检测率(CDR)指标和去冲突图奖励(DGR)方法，显著提升了训练稳定性和模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在强化学习中面临判断不一致性问题，特别是偏好循环等逻辑一致性问题尚未得到充分解决，这会影响强化学习的稳定性。

Method: 框架包含两个主要贡献：CDR指标用于量化判断冲突，DGR框架通过构建偏好图、转换为无冲突有向无环图(DAG)来净化信号，生成逻辑一致的奖励信号。

Result: 实验结果表明，该框架相比强基线显著提高了训练稳定性和模型性能。

Conclusion: 逻辑一致性是AI反馈中至关重要且现在可管理的维度。

Abstract: However, this method often faces judgment inconsistencies that can
destabilize reinforcement learning. While prior research has focused on the
accuracy of judgments, the critical issue of logical coherence especially
issues such as preference cycles hasn't been fully addressed. To fill this gap,
we introduce a comprehensive framework designed to systematically detect and
resolve these inconsistencies during the reinforcement learning training
process. Our framework includes two main contributions: first, the Conflict
Detection Rate (CDR), a new metric that quantifies judgment conflicts, and
second, Deconflicted Graph Rewards (DGR), a framework that purifies signals by
removing cycles before policy optimization. DGR constructs preference graphs
from the initial judgments, transforms them into conflict-free Directed Acyclic
Graphs (DAGs), and generates a logically coherent reward signal that is
compatible with any policy optimizer. Experimental results show that our
framework significantly enhances training stability and model performance
compared to strong baselines, establishing logical consistency as a crucial and
now manageable dimension of AI feedback.

</details>


### [19] [JudgeSQL: Reasoning over SQL Candidates with Weighted Consensus Tournament](https://arxiv.org/abs/2510.15560)
*Jiayuan Bai,Xuan-guang Pan,Chongyang Tao,Shuai Ma*

Main category: cs.AI

TL;DR: 提出JudgeSQL框架，通过结构化推理和加权共识锦标赛机制改进Text-to-SQL任务中的候选查询选择问题，解决现有方法的浅层信号问题。


<details>
  <summary>Details</summary>
Motivation: Text-to-SQL任务面临语义歧义和复杂组合推理挑战，现有选择方法如自一致性或最佳N解码仅提供浅层信号，容易导致不一致评分、脆弱推理链和无法捕捉细粒度语义差异。

Method: 开发基于推理的SQL判断模型，通过强化学习在可验证奖励指导下提炼推理轨迹；构建加权共识锦标赛机制，整合显式推理偏好和隐式生成器置信度。

Result: 在BIRD基准测试上的广泛实验表明，JudgeSQL展现出优越的SQL判断能力、良好的跨尺度泛化能力以及对生成器容量的鲁棒性。

Conclusion: JudgeSQL通过结构化推理和加权共识机制重新定义了SQL候选选择，提供了更可靠和高效的解决方案。

Abstract: Text-to-SQL is a pivotal task that bridges natural language understanding and
structured data access, yet it remains fundamentally challenging due to
semantic ambiguity and complex compositional reasoning. While large language
models (LLMs) have greatly advanced SQL generation though prompting, supervised
finetuning and reinforced tuning, the shift toward test-time scaling exposes a
new bottleneck: selecting the correct query from a diverse candidate pool.
Existing selection approaches, such as self-consistency or best-of-$N$
decoding, provide only shallow signals, making them prone to inconsistent
scoring, fragile reasoning chains, and a failure to capture fine-grained
semantic distinctions between closely related SQL candidates. To this end, we
introduce JudgeSQL, a principled framework that redefines SQL candidate
selection through structured reasoning and weighted consensus tournament
mechanism. JudgeSQL develops a reasoning-based SQL judge model that distills
reasoning traces with reinforcement learning guided by verifiable rewards,
enabling accurate and interpretable judgments. Building on this, a weighted
consensus tournament integrates explicit reasoning preferences with implicit
generator confidence, yielding selections that are both more reliable and more
efficient. Extensive experiments on the BIRD benchmark demonstrate that
JudgeSQL exhibits superior SQL judgment capabilities and good cross-scale
generalization and robustness to generator capacity.

</details>


### [20] [Context-aware deep learning using individualized prior information reduces false positives in disease risk prediction and longitudinal health assessment](https://arxiv.org/abs/2510.15591)
*Lavanya Umapathy,Patricia M Johnson,Tarun Dutt,Angela Tong,Madhur Nayan,Hersh Chandarana,Daniel K Sodickson*

Main category: cs.AI

TL;DR: 开发了一个整合患者历史就诊信息的机器学习框架，通过消化先前收集的影像和临床生物标志物数据来改进前列腺癌风险预测，显著降低了假阳性率。


<details>
  <summary>Details</summary>
Motivation: 医学中的时间背景对于评估患者健康状况随时间变化至关重要，特别是在既往就诊次数有限且频率不定的情况下，需要整合多样化背景信息来改善健康监测。

Method: 模型首先使用最近一次就诊的医疗数据估计疾病初始风险，然后利用先前收集的影像和/或临床生物标志物信息来优化这一评估。

Result: 整合历史背景直接将假阳性转为真阴性，总体特异性提高同时保持高敏感性。整合最多三次既往影像检查信息时，假阳性率从51%降至33%；加入临床数据后进一步降至24%。预测5年内风险时，假阳性率从64%降至9%。

Conclusion: 随时间收集的信息提供了相关背景，可增强医学风险预测的特异性。对于多种进展性疾病，通过背景信息充分降低假阳性率可为低基线风险的大规模人群扩展纵向健康监测计划提供途径，从而实现早期检测和改善健康结果。

Abstract: Temporal context in medicine is valuable in assessing key changes in patient
health over time. We developed a machine learning framework to integrate
diverse context from prior visits to improve health monitoring, especially when
prior visits are limited and their frequency is variable. Our model first
estimates initial risk of disease using medical data from the most recent
patient visit, then refines this assessment using information digested from
previously collected imaging and/or clinical biomarkers. We applied our
framework to prostate cancer (PCa) risk prediction using data from a large
population (28,342 patients, 39,013 magnetic resonance imaging scans, 68,931
blood tests) collected over nearly a decade. For predictions of the risk of
clinically significant PCa at the time of the visit, integrating prior context
directly converted false positives to true negatives, increasing overall
specificity while preserving high sensitivity. False positive rates were
reduced progressively from 51% to 33% when integrating information from up to
three prior imaging examinations, as compared to using data from a single
visit, and were further reduced to 24% when also including additional context
from prior clinical data. For predicting the risk of PCa within five years of
the visit, incorporating prior context reduced false positive rates still
further (64% to 9%). Our findings show that information collected over time
provides relevant context to enhance the specificity of medical risk
prediction. For a wide range of progressive conditions, sufficient reduction of
false positive rates using context could offer a pathway to expand longitudinal
health monitoring programs to large populations with comparatively low baseline
risk of disease, leading to earlier detection and improved health outcomes.

</details>


### [21] [Unleashing Scientific Reasoning for Bio-experimental Protocol Generation via Structured Component-based Reward Mechanism](https://arxiv.org/abs/2510.15600)
*Haoran Sun,Yankai Jiang,Zhenyu Tang,Yaning Pan,Shuang Gu,Zekai Lin,Lilong Wang,Wenjie Lou,Lei Liu,Lei Bai,Xiaosong Wang*

Main category: cs.AI

TL;DR: 提出SciRecipe数据集和Thoth模型，通过"草图-填充"范式和结构化奖励机制改进科学协议生成，在多个基准测试中超越现有LLM。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型生成的科学协议往往不完整或不一致，限制了其在可重复科学研究中的实用性。

Method: 引入SciRecipe数据集(12K结构化协议)，提出"草图-填充"范式分离分析、结构和表达，采用结构化组件奖励机制评估步骤粒度、行动顺序和语义保真度，开发Thoth模型通过分阶段知识到行动过程训练。

Result: Thoth在多个基准测试中持续超越专有和开源LLM，在步骤对齐、逻辑排序和语义准确性方面取得显著改进。

Conclusion: 该方法为构建可靠的科学助手铺平了道路，将知识与实验执行连接起来。所有数据、代码和模型将公开发布。

Abstract: The foundation of reproducible science lies in protocols that are precise,
logically ordered, and executable. The autonomous generation of these protocols
through natural language queries could greatly improve the efficiency of the
reproduction process. However, current leading large language models (LLMs)
often generate incomplete or inconsistent protocols, limiting their utility. To
address this limitation, we first introduce SciRecipe, a large-scale dataset of
over 12K structured protocols spanning 27 biological subfields and encompassing
both comprehension and problem-solving tasks. To further improve protocol
generation, we propose the "Sketch-and-Fill" paradigm, which separates
analysis, structuring, and expression to ensure each step is explicit and
verifiable. Complementing this, the structured component-based reward mechanism
evaluates step granularity, action order, and semantic fidelity, aligning model
optimization with experimental reliability. Building on these components, we
develop Thoth, trained through a staged Knowledge-to-Action process that
progresses from knowledge acquisition to operational reasoning and ultimately
to robust, executable protocol generation. Across multiple benchmarks, Thoth
consistently surpasses both proprietary and open-source LLMs, achieving
significant improvements in step alignment, logical sequencing, and semantic
accuracy. Our approach paves the way for reliable scientific assistants that
bridge knowledge with experimental execution. All data, code, and models will
be released publicly.

</details>


### [22] [Build Your Personalized Research Group: A Multiagent Framework for Continual and Interactive Science Automation](https://arxiv.org/abs/2510.15624)
*Ed Li,Junyu Ren,Xintian Pan,Cat Yan,Chuanhao Li,Dirk Bergemann,Zhuoran Yang*

Main category: cs.AI

TL;DR: 提出了一个名为freephdlabor的开源多智能体框架，支持完全动态的工作流和模块化架构，能够实现持续性的自动化科学研究。


<details>
  <summary>Details</summary>
Motivation: 现有的科学发现自动化系统存在两个根本限制：僵化的预编程工作流无法适应中间发现，以及不充分的上下文管理阻碍了长期研究。

Method: 采用多智能体框架，具有完全动态的工作流（由实时智能体推理决定）、模块化架构（允许用户修改、添加或移除智能体）、自动上下文压缩、基于工作空间的通信、跨会话内存持久化和非阻塞人工干预机制。

Result: 该框架将自动化研究从孤立的单次尝试转变为持续的研究计划，能够系统性地基于先前探索并融入人类反馈。

Conclusion: 通过提供构建可定制合作科学家系统的架构原则和实际实现，这项工作旨在促进自动化研究在科学领域的更广泛采用，使从业者能够部署交互式多智能体系统来自主进行端到端研究。

Abstract: The automation of scientific discovery represents a critical milestone in
Artificial Intelligence (AI) research. However, existing agentic systems for
science suffer from two fundamental limitations: rigid, pre-programmed
workflows that cannot adapt to intermediate findings, and inadequate context
management that hinders long-horizon research. We present
\texttt{freephdlabor}, an open-source multiagent framework featuring
\textit{fully dynamic workflows} determined by real-time agent reasoning and a
\coloremph{\textit{modular architecture}} enabling seamless customization --
users can modify, add, or remove agents to address domain-specific
requirements. The framework provides comprehensive infrastructure including
\textit{automatic context compaction}, \textit{workspace-based communication}
to prevent information degradation, \textit{memory persistence} across
sessions, and \textit{non-blocking human intervention} mechanisms. These
features collectively transform automated research from isolated, single-run
attempts into \textit{continual research programs} that build systematically on
prior explorations and incorporate human feedback. By providing both the
architectural principles and practical implementation for building customizable
co-scientist systems, this work aims to facilitate broader adoption of
automated research across scientific domains, enabling practitioners to deploy
interactive multiagent systems that autonomously conduct end-to-end research --
from ideation through experimentation to publication-ready manuscripts.

</details>


### [23] [Direct Preference Optimization with Unobserved Preference Heterogeneity: The Necessity of Ternary Preferences](https://arxiv.org/abs/2510.15716)
*Keertana Chidambaram,Karthik Vinary Seetharaman,Vasilis Syrgkanis*

Main category: cs.AI

TL;DR: 该论文提出了改进RLHF的方法，通过引入排名反馈和考虑用户异质性来解决传统偏好学习中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统RLHF和DPO方法假设统一的标注者偏好并依赖二元比较，忽视了人类评估者的多样性和成对反馈的局限性。

Method: 1) 将偏好学习与计量经济学文献联系，证明二元比较不足以识别潜在用户偏好；2) 开发EM-DPO方法发现潜在标注者类型并训练LLM混合模型；3) 提出基于最小最大遗憾公平准则的聚合算法。

Result: 建立了生成模型对齐中面向多样化用户的公平性和个性化理论算法框架。

Conclusion: 通过排名反馈和异质性偏好整合，为生成模型对齐提供了更公平和个性化的解决方案。

Abstract: Reinforcement Learning from Human Feedback (RLHF) has become central to
aligning large language models with human values, typically by first learning a
reward model from preference data which is then used to update the model with
reinforcement learning. Recent alternatives such as Direct Preference
Optimization (DPO) simplify this pipeline by directly optimizing on
preferences. However, both approaches often assume uniform annotator
preferences and rely on binary comparisons, overlooking two key limitations:
the diversity of human evaluators and the limitations of pairwise feedback. In
this work, we address both these issues. First, we connect preference learning
in RLHF with the econometrics literature and show that binary comparisons are
insufficient for identifying latent user preferences from finite user data and
infinite users, while (even incomplete) rankings over three or more responses
ensure identifiability. Second, we introduce methods to incorporate
heterogeneous preferences into alignment algorithms. We develop an
Expectation-Maximization adaptation of DPO that discovers latent annotator
types and trains a mixture of LLMs accordingly. Then we propose an aggregation
algorithm using a min-max regret fairness criterion to produce a single
generative policy with equitable performance guarantees. Together, these
contributions establish a theoretical and algorithmic framework for fairness
and personalization for diverse users in generative model alignment.

</details>


### [24] [Invoice Information Extraction: Methods and Performance Evaluation](https://arxiv.org/abs/2510.15727)
*Sai Yashwant,Anurag Dubey,Praneeth Paikray,Gantala Thulsiram*

Main category: cs.AI

TL;DR: 提出从发票文档中提取结构化信息的方法，并建立评估指标来评估提取数据的准确性


<details>
  <summary>Details</summary>
Motivation: 需要标准化的方法来评估发票信息提取的准确性，以便比较不同提取方法的表现

Method: 使用Docling和LlamaCloud服务对扫描或数字发票进行预处理，识别和提取关键字段如发票号码、日期、总金额和供应商详情

Result: 建立了包含字段级精度、一致性检查失败率和完全匹配准确率的稳健评估框架

Conclusion: 提出的评估指标为比较不同提取方法提供了标准化方式，并能突显字段特定性能的优缺点

Abstract: This paper presents methods for extracting structured information from
invoice documents and proposes a set of evaluation metrics (EM) to assess the
accuracy of the extracted data against annotated ground truth. The approach
involves pre-processing scanned or digital invoices, applying Docling and
LlamaCloud Services to identify and extract key fields such as invoice number,
date, total amount, and vendor details. To ensure the reliability of the
extraction process, we establish a robust evaluation framework comprising
field-level precision, consistency check failures, and exact match accuracy.
The proposed metrics provide a standardized way to compare different extraction
methods and highlight strengths and weaknesses in field-specific performance.

</details>


### [25] [AURA: An Agent Autonomy Risk Assessment Framework](https://arxiv.org/abs/2510.15739)
*Lorenzo Satta Chiris,Ayush Mishra*

Main category: cs.AI

TL;DR: AURA是一个统一的框架，用于检测、量化和减轻自主AI代理的风险，采用基于gamma的风险评分方法，支持人机协作监督和自主风险评估。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI代理系统在组织中日益普及，对齐、治理和风险管理方面的持续挑战阻碍了大规模部署。

Method: AURA引入基于gamma的风险评分方法，平衡风险评估准确性与计算效率，提供交互式流程来评分、评估和减轻AI代理风险，支持人机协作监督和代理间通信机制。

Result: 该框架实现了与现有协议和工具的无缝集成，支持自主风险评估，为大规模、可治理的企业级AI代理提供关键支持。

Conclusion: AURA支持负责任和透明的AI代理采用，在平衡计算资源的同时提供强大的风险检测和缓解能力，是企业环境中大规模可治理AI代理的关键推动者。

Abstract: As autonomous agentic AI systems see increasing adoption across
organisations, persistent challenges in alignment, governance, and risk
management threaten to impede deployment at scale. We present AURA (Agent
aUtonomy Risk Assessment), a unified framework designed to detect, quantify,
and mitigate risks arising from agentic AI. Building on recent research and
practical deployments, AURA introduces a gamma-based risk scoring methodology
that balances risk assessment accuracy with computational efficiency and
practical considerations. AURA provides an interactive process to score,
evaluate and mitigate the risks of running one or multiple AI Agents,
synchronously or asynchronously (autonomously). The framework is engineered for
Human-in-the-Loop (HITL) oversight and presents Agent-to-Human (A2H)
communication mechanisms, allowing for seamless integration with agentic
systems for autonomous self-assessment, rendering it interoperable with
established protocols (MCP and A2A) and tools. AURA supports a responsible and
transparent adoption of agentic AI and provides robust risk detection and
mitigation while balancing computational resources, positioning it as a
critical enabler for large-scale, governable agentic AI in enterprise
environments.

</details>


### [26] [Towards Relaxed Multimodal Inputs for Gait-based Parkinson's Disease Assessment](https://arxiv.org/abs/2510.15748)
*Minlin Zeng,Zhipeng Zhou,Yang Qiu,Zhiqi Shen*

Main category: cs.AI

TL;DR: 提出了首个将帕金森病多模态学习建模为多目标优化问题的评估系统TRIP，解决了训练时模态同步和推理时模态依赖的限制问题。


<details>
  <summary>Details</summary>
Motivation: 现有帕金森病多模态评估方法存在两个主要限制：(1)训练时需要同步所有模态，(2)推理时依赖所有模态，这阻碍了实际应用。

Method: 1. 将多模态学习建模为多目标优化问题；2. 引入基于边界的类别重平衡策略来处理模态内不平衡问题；3. 支持同步和异步设置。

Result: 在三个公共数据集上，TRIP在异步设置中比最佳基线分别提升16.48、6.89和11.55个百分点，在同步设置中提升4.86和2.30个百分点，达到最先进性能。

Conclusion: TRIP框架通过多目标优化方法有效解决了多模态帕金森病评估中的模态依赖问题，具有出色的有效性和适应性。

Abstract: Parkinson's disease assessment has garnered growing interest in recent years,
particularly with the advent of sensor data and machine learning techniques.
Among these, multimodal approaches have demonstrated strong performance by
effectively integrating complementary information from various data sources.
However, two major limitations hinder their practical application: (1) the need
to synchronize all modalities during training, and (2) the dependence on all
modalities during inference. To address these issues, we propose the first
Parkinson's assessment system that formulates multimodal learning as a
multi-objective optimization (MOO) problem. This not only allows for more
flexible modality requirements during both training and inference, but also
handles modality collapse issue during multimodal information fusion. In
addition, to mitigate the imbalance within individual modalities, we introduce
a margin-based class rebalancing strategy to enhance category learning. We
conduct extensive experiments on three public datasets under both synchronous
and asynchronous settings. The results show that our framework-Towards Relaxed
InPuts (TRIP)-achieves state-of-the-art performance, outperforming the best
baselines by 16.48, 6.89, and 11.55 percentage points in the asynchronous
setting, and by 4.86 and 2.30 percentage points in the synchronous setting,
highlighting its effectiveness and adaptability.

</details>


### [27] [Preliminary Quantitative Study on Explainability and Trust in AI Systems](https://arxiv.org/abs/2510.15769)
*Allen Daniel Sunny*

Main category: cs.AI

TL;DR: 研究通过贷款审批模拟实验发现，交互式解释能增强用户信任和参与度，解释的清晰度和相关性是信任的关键因素。


<details>
  <summary>Details</summary>
Motivation: 随着GPT-4等大规模AI模型在关键领域的应用，关于AI系统信任和透明度的问题日益紧迫，需要研究解释性与用户信任之间的关系。

Method: 采用定量实验设计，通过基于网络的交互式贷款审批模拟，比较不同类型的解释（从基本特征重要性到交互式反事实）对用户信任感知的影响。

Result: 结果表明交互性增强了用户参与度和信心，解释的清晰度和相关性是信任的关键决定因素。

Conclusion: 研究为人本可解释AI领域提供了实证证据，强调了可解释性设计对用户感知的可测量影响。

Abstract: Large-scale AI models such as GPT-4 have accelerated the deployment of
artificial intelligence across critical domains including law, healthcare, and
finance, raising urgent questions about trust and transparency. This study
investigates the relationship between explainability and user trust in AI
systems through a quantitative experimental design. Using an interactive,
web-based loan approval simulation, we compare how different types of
explanations, ranging from basic feature importance to interactive
counterfactuals influence perceived trust. Results suggest that interactivity
enhances both user engagement and confidence, and that the clarity and
relevance of explanations are key determinants of trust. These findings
contribute empirical evidence to the growing field of human-centered
explainable AI, highlighting measurable effects of explainability design on
user perception

</details>


### [28] [Self-evolving expertise in complex non-verifiable subject domains: dialogue as implicit meta-RL](https://arxiv.org/abs/2510.15772)
*Richard M. Bailey*

Main category: cs.AI

TL;DR: Dialectica框架通过结构化对话、记忆、自我反思和策略约束的上下文编辑，使AI代理在复杂问题中发展专业知识，实验证明该方法能显著提升代理能力。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在复杂多维度问题中缺乏通过经验发展专业知识的内生机制的问题，这些"棘手问题"涉及非可验证结果、异质性影响且无单一正确答案。

Method: 提出Dialectica框架，让代理在定义主题上进行结构化对话，增强记忆、自我反思和策略约束的上下文编辑功能，将讨论视为隐式元强化学习过程。

Result: 在两个模型架构上的实验显示，启用基于反思的上下文编辑的代理在Elo分数、标准化Bradley-Terry-Davidson能力和AlphaRank质量上均优于基线版本。

Conclusion: 对话驱动的上下文演化是在开放非可验证领域中实现针对性专业知识放大的可行路径。

Abstract: So-called `wicked problems', those involving complex multi-dimensional
settings, non-verifiable outcomes, heterogeneous impacts and a lack of single
objectively correct answers, have plagued humans throughout history. Modern
examples include decisions over justice frameworks, solving environmental
pollution, planning for pandemic resilience and food security. The use of
state-of-the-art artificial intelligence systems (notably Large Language
Model-based agents) collaborating with humans on solving such problems is being
actively explored. While the abilities of LLMs can be improved by, for example,
fine-tuning, hand-crafted system prompts and scaffolding with external tools,
LLMs lack endogenous mechanisms to develop expertise through experience in such
settings. This work address this gap with Dialectica, a framework where agents
engage in structured dialogue on defined topics, augmented by memory,
self-reflection, and policy-constrained context editing. Formally, discussion
is viewed as an implicit meta-reinforcement learning process. The
`dialogue-trained' agents are evaluated post-hoc using judged pairwise
comparisons of elicited responses. Across two model architectures (locally run
Qwen3:30b and OpenAI's o4-mini) results show that enabling reflection-based
context editing during discussion produces agents which dominate their baseline
counterparts on Elo scores, normalized Bradley-Terry-Davidson ability, and
AlphaRank mass. The predicted signatures of learning are observed qualitatively
in statement and reflection logs, where reflections identify weaknesses and
reliably shape subsequent statements. Agreement between quantitative and
qualitative evidence supports dialogue-driven context evolution as a practical
path to targeted expertise amplification in open non-verifiable domains.

</details>


### [29] [Demo: Guide-RAG: Evidence-Driven Corpus Curation for Retrieval-Augmented Generation in Long COVID](https://arxiv.org/abs/2510.15782)
*Philip DiGiacomo,Haoyang Wang,Jinrui Fang,Yan Leng,W Michael Brode,Ying Ding*

Main category: cs.AI

TL;DR: 开发了六种不同配置的检索增强生成(RAG)语料库用于长新冠临床问答，发现结合临床指南和高质量系统评价的配置表现最佳，提出了Guide-RAG系统框架。


<details>
  <summary>Details</summary>
Motivation: 随着AI聊天机器人在临床医学中的应用增加，为复杂新兴疾病开发有效框架面临挑战，特别是长新冠这种新兴疾病。

Method: 开发并评估了六种RAG语料库配置，从专家精选来源到大规模文献数据库，使用LLM作为评判框架，在忠实性、相关性和全面性指标上进行评估。

Result: 结合临床指南和高质量系统评价的RAG配置始终优于单一指南方法和大规模文献数据库，在长新冠临床问答中表现最佳。

Conclusion: 对于新兴疾病，基于精选二次评价的检索在狭窄共识文档和未过滤原始文献之间提供了最佳平衡，支持临床决策同时避免信息过载和过度简化的指导。

Abstract: As AI chatbots gain adoption in clinical medicine, developing effective
frameworks for complex, emerging diseases presents significant challenges. We
developed and evaluated six Retrieval-Augmented Generation (RAG) corpus
configurations for Long COVID (LC) clinical question answering, ranging from
expert-curated sources to large-scale literature databases. Our evaluation
employed an LLM-as-a-judge framework across faithfulness, relevance, and
comprehensiveness metrics using LongCOVID-CQ, a novel dataset of
expert-generated clinical questions. Our RAG corpus configuration combining
clinical guidelines with high-quality systematic reviews consistently
outperformed both narrow single-guideline approaches and large-scale literature
databases. Our findings suggest that for emerging diseases, retrieval grounded
in curated secondary reviews provides an optimal balance between narrow
consensus documents and unfiltered primary literature, supporting clinical
decision-making while avoiding information overload and oversimplified
guidance. We propose Guide-RAG, a chatbot system and accompanying evaluation
framework that integrates both curated expert knowledge and comprehensive
literature databases to effectively answer LC clinical questions.

</details>


### [30] [PokeeResearch: Effective Deep Research via Reinforcement Learning from AI Feedback and Robust Reasoning Scaffold](https://arxiv.org/abs/2510.15862)
*Yi Wan,Jiuqi Wang,Liam Li,Jinsong Liu,Ruihao Zhu,Zheqing Zhu*

Main category: cs.AI

TL;DR: PokeeResearch-7B是一个7B参数的深度研究代理，通过统一的强化学习框架构建，在10个深度研究基准测试中达到7B规模代理的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于工具增强的大语言模型的研究代理存在检索浅层、对齐指标弱和工具使用行为脆弱等问题，需要开发更鲁棒、对齐和可扩展的深度研究代理。

Method: 采用无标注的AI反馈强化学习（RLAIF）框架，使用基于LLM的奖励信号优化策略，结合思维链驱动的多调用推理支架，通过自我验证和从工具故障中自适应恢复来增强鲁棒性。

Result: 在10个流行的深度研究基准测试中，PokeeResearch-7B在7B规模深度研究代理中实现了最先进的性能。

Conclusion: 精心设计的强化学习和推理架构可以产生高效、有弹性和研究级的AI代理，该模型和推理代码已在MIT许可下开源。

Abstract: Tool-augmented large language models (LLMs) are emerging as deep research
agents, systems that decompose complex queries, retrieve external evidence, and
synthesize grounded responses. Yet current agents remain limited by shallow
retrieval, weak alignment metrics, and brittle tool-use behavior. We introduce
PokeeResearch-7B, a 7B-parameter deep research agent built under a unified
reinforcement learning framework for robustness, alignment, and scalability.
PokeeResearch-7B is trained by an annotation-free Reinforcement Learning from
AI Feedback (RLAIF) framework to optimize policies using LLM-based reward
signals that capture factual accuracy, citation faithfulness, and instruction
adherence. A chain-of-thought-driven multi-call reasoning scaffold further
enhances robustness through self-verification and adaptive recovery from tool
failures. Among 10 popular deep research benchmarks, PokeeResearch-7B achieves
state-of-the-art performance among 7B-scale deep research agents. This
highlights that careful reinforcement learning and reasoning design can produce
efficient, resilient, and research-grade AI agents. The model and inference
code is open-sourced under MIT license at
https://github.com/Pokee-AI/PokeeResearchOSS.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [31] [Q-EnergyDEX: A Zero-Trust Distributed Energy Trading Framework Driven by Quantum Key Distribution and Blockchain](https://arxiv.org/abs/2510.15045)
*Ziqing Zhu*

Main category: eess.SY

TL;DR: 提出Q-EnergyDEX框架，结合量子密钥分发和区块链技术，为去中心化电力市场提供端到端量子安全基础设施，解决传统加密方法面临的量子攻击威胁。


<details>
  <summary>Details</summary>
Motivation: 随着电力市场的去中心化和数字化，出现了密钥泄露、数据篡改和身份欺骗等新的网络物理漏洞。现有基于区块链的解决方案虽然提供透明度和可追溯性，但仍依赖易受量子攻击的经典密码学原语。

Method: 集成物理层量子随机性与市场级操作，通过云量子密钥管理服务持续生成可验证熵值，使用对称认证协议(Q-SAH)建立安全低延迟会话，采用量子辅助共识机制(PoR-Lite)实现概率性账本最终性，并通过Stackelberg约束双边拍卖将市场清算与熵可用性耦合。

Result: 仿真结果表明Q-EnergyDEX保持稳健的密钥稳定性和接近最优的社会福利，证明其在大规模去中心化能源市场中的可行性。

Conclusion: Q-EnergyDEX框架成功解决了去中心化电力市场中的量子安全挑战，为未来量子安全能源交易提供了可行的技术方案。

Abstract: The rapid decentralization and digitalization of local electricity markets
have introduced new cyber-physical vulnerabilities, including key leakage, data
tampering, and identity spoofing. Existing blockchain-based solutions provide
transparency and traceability but still depend on classical cryptographic
primitives that are vulnerable to quantum attacks. To address these challenges,
this paper proposes Q-EnergyDEX, a zero-trust distributed energy trading
framework driven by quantum key distribution and blockchain. The framework
integrates physical-layer quantum randomness with market-level operations,
providing an end-to-end quantum-secured infrastructure. A cloud-based Quantum
Key Management Service continuously generates verifiable entropy and regulates
key generation through a rate-adaptive algorithm to sustain high-quality
randomness. A symmetric authentication protocol (Q-SAH) establishes secure and
low-latency sessions, while the quantum-aided consensus mechanism (PoR-Lite)
achieves probabilistic ledger finality within a few seconds. Furthermore, a
Stackelberg-constrained bilateral auction couples market clearing with entropy
availability, ensuring both economic efficiency and cryptographic security.
Simulation results show that Q-EnergyDEX maintains robust key stability and
near-optimal social welfare, demonstrating its feasibility for large-scale
decentralized energy markets.

</details>


### [32] [Exploring a New Design Paradigm for Omnidirectional MAVs for Minimal Actuation and Internal Force Elimination: Theoretical Framework and Control](https://arxiv.org/abs/2510.15071)
*Ahmed Ali,Chiara Gabellieri,Antonio Franchi*

Main category: eess.SY

TL;DR: 提出了一种新型全向多旋翼飞行器设计，使用6个输入实现全向运动且平衡时无内力，通过主动倾斜螺旋桨和3个摆式链接结构实现。


<details>
  <summary>Details</summary>
Motivation: 传统多旋翼飞行器无法实现真正的全向运动，且存在内力问题。本文旨在设计一种仅用6个输入就能实现全向运动并最小化内力的新型结构。

Method: 采用单主动倾斜螺旋桨和3个带螺旋桨的摆式链接结构，通过被动万向节连接主体。建立详细动力学模型，分析平衡配置，并使用几何非线性控制器（动态反馈线性化和反步法）实现闭环系统稳定。

Result: 证明了该设计能在任何主体姿态下存在强制平衡，数值仿真验证了飞行器在非零初始条件、参数不确定性和执行器噪声下实现解耦姿态和平移运动的能力。

Conclusion: 该新型多旋翼飞行器设计成功实现了仅用6个输入的全向运动，同时最小化了内力，并通过控制器设计确保了系统的渐近稳定性。

Abstract: This paper presents a novel concept for achieving omnidirectionality in a
multirotor aerial vehicle (MAV) that uses only 6 inputs and ensures no internal
forces at the equilibria. The concept integrates a single actively-tilting
propeller along with 3 pendulum-like links, each carrying a propeller,
connected by passive universal joints to the main body. We show that this
design ensures omnidirectionality while minimizing the internal forces and
without resorting to overactuation (i.e., more than 6 inputs). A detailed
dynamic model of the multi-link MAV is first developed. Afterwards, the
analysis identifies the equilibrium configurations and illustrates that a
forced equilibrium exists for every pose of the MAV's main platform. In order
to render this equilibrium asymptotically stable for the closed-loop system, a
geometric nonlinear controller is constructed using dynamic feedback
linearization and backstepping techniques with the main platform configuration
error being the left-trivialized error on SE(3). The stability of the
closed-loop system is then investigated by employing standard Lyapunov
arguments on the zero dynamics. We conclude by providing numerical simulations
validating the proposed approach. They demonstrate the MAV capability to
perform decoupled attitude and translational motions under non-zero initial
conditions, parametric uncertainty, and actuators noise.

</details>


### [33] [Sparsity-exploiting Gaussian Process for Robust Transient Learning of Power System Dynamics](https://arxiv.org/abs/2510.15150)
*Tina Gao,Shimiao Li,Lawrence Pileggi*

Main category: eess.SY

TL;DR: 该论文开发了鲁棒的暂态学习方法，通过利用数据流中的稀疏损坏模式，结合稀疏优化和矩估计方法，使学习对稀疏分布的数据损坏具有鲁棒性，并采用K-medoid聚类和维度缩减技术提高大规模系统的推理速度。


<details>
  <summary>Details</summary>
Motivation: 现实测量数据可能被各种随机和有针对性的威胁破坏，导致不准确和无意义的结果，需要开发能够处理数据损坏的鲁棒学习方法。

Method: 集成稀疏优化与矩估计方法，使学习对稀疏分布的数据损坏具有鲁棒性；优化稀疏权重以识别损坏的仪表位置；采用K-medoid聚类进行维度缩减和聚合表示启发式方法。

Result: 实验结果表明该方法对随机大误差、有针对性的虚假数据注入和局部PMU时钟漂移具有鲁棒性。在1354总线系统上，使用维度缩减后推理速度提高18倍，结合聚合表示后提高400倍。

Conclusion: 提出的鲁棒暂态学习方法能够有效处理数据损坏问题，并通过维度缩减技术显著提高大规模系统的推理效率。

Abstract: Advances in leveraging Gaussian processes (GP) have enabled learning and
inferring dynamic grid behavior from scarce PMU measurements. However, real
measurements can be corrupted by various random and targeted threats, leading
to inaccurate and meaningless results. This paper develops robust transient
learning to overcome this challenge by exploiting the sparse corruption
patterns in the data flow. Specifically, we integrate sparse optimization with
method of moments (MoM) to make learning robust to a sparse distribution of
data corruptions; then, we optimize sparse weights to identify corrupted meter
locations. To improve inference speed on large-scale systems, we further adopt
K-medoid clustering of locations to develop dimension reduction (DR) and
aggregate representation (AR) heuristics. Experimental results demonstrate
robustness against random large errors, targeted false data injections, and
local PMU clock drifts. On a 1354-bus system, inference turns out to be 18x
faster using DR and 400x faster when further combined with AR heuristics.

</details>


### [34] [Tail-Optimized Caching for LLM Inference](https://arxiv.org/abs/2510.15152)
*Wenxin Zhang,Yueying Li,Ciamac C. Moallemi,Tianyi Peng*

Main category: eess.SY

TL;DR: 提出了Tail-Optimized LRU，一种简单的两行修改的缓存策略，通过重新分配KV缓存容量来优先处理高延迟对话，相比LRU在尾延迟方面有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的LRU缓存策略在优化尾延迟（对实践者至关重要的指标）方面表现不佳，因为它忽视了对话长度的异质性。需要一种能优化尾延迟的缓存策略。

Method: 提出Tail-Optimized LRU策略，通过重新分配KV缓存容量，优先保留可能影响未来轮次的高延迟对话的缓存条目，同时驱逐不太可能影响未来轮次的缓存条目。

Result: 在真实对话数据WildChat上，相比LRU，Tail-Optimized LRU实现了P90尾延迟降低27.5%，P95尾延迟降低23.9%，200ms SLO违规减少38.9%。

Conclusion: Tail-Optimized LRU为实践者提供了一个实用且理论基础的选项，用于优化实际LLM部署中的尾延迟。

Abstract: Prompt caching is critical for reducing latency and cost in LLM inference:
OpenAI and Anthropic report up to 50-90% cost savings through prompt reuse.
Despite its widespread success, little is known about what constitutes an
optimal prompt caching policy, particularly when optimizing tail latency, a
metric of central importance to practitioners. The widely used Least Recently
Used (LRU) policy can perform arbitrarily poor on this metric, as it is
oblivious to the heterogeneity of conversation lengths. To address this gap, we
propose Tail-Optimized LRU, a simple two-line modification that reallocates KV
cache capacity to prioritize high-latency conversations by evicting cache
entries that are unlikely to affect future turns. Though the implementation is
simple, we prove its optimality under a natural stochastic model of
conversation dynamics, providing the first theoretical justification for LRU in
this setting, a result that may be of independent interest to the caching
community. Experimentally, on real conversation data WildChat, Tail-Optimized
LRU achieves up to 27.5% reduction in P90 tail Time to First Token latency and
23.9% in P95 tail latency compared to LRU, along with up to 38.9% decrease in
SLO violations of 200ms. We believe this provides a practical and theoretically
grounded option for practitioners seeking to optimize tail latency in
real-world LLM deployments.

</details>


### [35] [A Comparative Study of Oscillatory Perturbations in Car-Following Models](https://arxiv.org/abs/2510.15190)
*Oumaima Barhoumi,Ghazal Farhani,Taufiq Rahman,Mohamed H. Zaki,Sofiène Tahar*

Main category: eess.SY

TL;DR: 该研究比较了不同跟车模型在车队稳定性方面的表现，通过引入前车速度扰动来评估各模型对干扰传播的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着联网和自动驾驶车辆的普及，车队编队成为提高道路容量、降低油耗和改善交通流的关键策略，但车队的稳定性直接影响其效益，不稳定会导致不安全间距和能耗增加。

Method: 提出比较研究方法，测试智能驾驶员模型(IDM)、最优速度模型(OVM)、通用汽车模型(GMM)和协同自适应巡航控制(CACC)等跟车模型，通过引入前车速度的正弦振荡和离散速度变化等扰动来可视化跟随车辆的行为。

Result: 分析了各模型的车辆轨迹和车间距变化，评估了各模型对干扰传播的鲁棒性，揭示了模型的敏感性、稳定性特征。

Conclusion: 研究结果为设计弹性车队控制策略提供了见解，有助于理解不同跟车模型在车队稳定性方面的表现特点。

Abstract: As connected and autonomous vehicles become more widespread, platooning has
emerged as a key strategy to improve road capacity, reduce fuel consumption,
and enhance traffic flow. However, the benefits of platoons strongly depend on
their ability to maintain stability. Instability can lead to unsafe spacing and
increased energy usage. In this work, we study platoon instability and analyze
the root cause of its occurrence, as well as its impacts on the following
vehicle. To achieve this, we propose a comparative study between different
car-following models such as the Intelligent Driver Model (IDM), the Optimal
Velocity Model (OVM), the General Motors Model (GMM), and the Cooperative
Adaptive Cruise Control (CACC). In our approach, we introduce a disruption in
the model by varying the velocity of the leading vehicle to visualize the
behavior of the following vehicles. To evaluate the dynamic response of each
model, we introduce controlled perturbations in the velocity of the leading
vehicle, specifically, sinusoidal oscillations and discrete velocity changes.
The resulting vehicle trajectories and variations in inter-vehicle spacing are
analyzed to assess the robustness of each model to disturbance propagation. The
findings offer insight into model sensitivity, stability characteristics, and
implications for designing resilient platooning control strategies.

</details>


### [36] [Quantum-Key-Distribution Authenticated Aggregation and Settlement for Virtual Power Plants](https://arxiv.org/abs/2510.15239)
*Ziqing Zhu*

Main category: eess.SY

TL;DR: 本文提出了一种用于虚拟电厂(VPP)的量子认证聚合与结算框架，通过量子密钥分配(QKD)技术解决分布式能源资源在网络安全威胁和极端天气下的通信安全问题。


<details>
  <summary>Details</summary>
Motivation: 随着分布式能源资源和需求侧灵活性的普及，虚拟电厂成为现代电网运营的核心。其端到端业务管道形成了紧密耦合的网络-物理-经济系统，需要安全及时的通信。传统密码学在复杂网络攻击和极端天气冲击下提供有限的长期保护，而量子密钥分配具有信息论保证，被认为是保护关键基础设施的黄金标准。

Method: 开发了一个系统-威胁模型，将QKD密钥生成和路由与业务层安全策略、认证强度、刷新频率和延迟约束联系起来。在此基础上，制定了一个关键预算风险最小化问题，综合考虑经济风险、服务级别违规和关键预算可行性，并揭示了边际安全价值与影子价格之间的阈值特性。

Result: 在代表性VPP系统上的案例研究表明，所提出的方法显著降低了残余风险和服务级别协议违规，提高了密钥效率和鲁棒性，并观察到与理论影子价格机制一致的动态特性。

Conclusion: 量子认证聚合与结算框架为虚拟电厂提供了有效的网络安全解决方案，通过优化量子密钥分配显著提升了系统的安全性和可靠性。

Abstract: The proliferation of distributed energy resources (DERs) and demand-side
flexibility has made virtual power plants (VPPs) central to modern grid
operation. Yet their end-to-end business pipeline, covering bidding, dispatch,
metering, settlement, and archival, forms a tightly coupled
cyber-physical-economic system where secure and timely communication is
critical. Under the combined stress of sophisticated cyberattacks and extreme
weather shocks, conventional cryptography offers limited long-term protection.
Quantum key distribution (QKD), with information-theoretic guarantees, is
viewed as a gold standard for securing critical infrastructures. However,
limited key generation rates, routing capacity, and system overhead render key
allocation a pressing challenge: scarce quantum keys must be scheduled across
heterogeneous processes to minimize residual risk while maintaining latency
guarantees. This paper introduces a quantum-authenticated aggregation and
settlement framework for VPPs. We first develop a system-threat model that
connects QKD key generation and routing with business-layer security
strategies, authentication strength, refresh frequency, and delay constraints.
Building on this, we formulate a key-budgeted risk minimization problem that
jointly accounts for economic risk, service-level violations, and key-budget
feasibility, and reveal a threshold property linking marginal security value to
shadow prices. Case studies on a representative VPP system demonstrate that the
proposed approach significantly reduces residual risk and SLA violations,
enhances key efficiency and robustness, and aligns observed dynamics with the
theoretical shadow price mechanism.

</details>


### [37] [Techno-Economic Feasibility Analysis of Quantum Key Distribution for Power-System Communications](https://arxiv.org/abs/2510.15248)
*Ziqing Zhu*

Main category: eess.SY

TL;DR: 提出了一个技术经济框架来评估量子密钥分发(QKD)在电力系统通信中的可行性，通过混合架构显著降低密钥中断概率，在适度光损耗和缓冲区条件下具有成本效益。


<details>
  <summary>Details</summary>
Motivation: 现代电力系统的数字化和去中心化加速，使关键通信基础设施面临日益增长的网络安全风险，特别是新兴量子计算威胁。

Method: 开发了随机系统模型，联合捕捉时变密钥需求、光损耗约束下的QKD供应、站侧缓冲和后量子密码(PQC)备用机制，并推导了服务级别保证的分析条件。

Result: 混合架构显著降低密钥中断概率和SLA不足，为实时和机密关键服务实现接近单位的可用性。经济分析显示在适度光损耗和缓冲区条件下，QKD增强部署具有成本效益。

Conclusion: 该框架为未来弹性电力系统基础设施中大规模、经济合理的QKD采用提供了可重复、风险感知的决策工具。

Abstract: The accelerating digitalization and decentralization of modern power systems
expose critical communication infrastructures to escalating cyber risks,
particularly under emerging quantum computing threats. This paper presents an
integrated techno-economic framework to evaluate the feasibility of Quantum Key
Distribution (QKD) for secure power-system communications. A stochastic system
model is developed to jointly capture time-varying key demand, QKD supply under
optical-loss constraints, station-side buffering, and post-quantum cryptography
(PQC) fallback mechanisms. Analytical conditions are derived for service-level
assurance, including buffer stability, outage probability, and availability
bounds. Building on this, two quantitative metrics, including the Levelized
Cost of Security (LCoSec) and Cost of Incremental Security (CIS), are
formulated to unify capital, operational, and risk-related expenditures within
a discounted net-present-value framework. Using IEEE 118-bus, 123-node, and
39-bus test systems, we conduct discrete-event simulations comparing PQC-only,
QKD-only, and Hybrid architectures across multiple topologies and service
profiles. Results show that Hybrid architectures dominated by QKD significantly
reduce key-outage probability and SLA shortfalls, achieving near-unit
availability for real-time and confidentiality-critical services. Economic
analyses reveal clear breakeven zones where QKD-enhanced deployments become
cost-effective, primarily in metropolitan and distribution-level networks under
moderate optical loss and buffer sizing. The proposed framework provides a
reproducible, risk-aware decision tool for guiding large-scale, economically
justified QKD adoption in future resilient power-system infrastructures.

</details>


### [38] [Comprehensive Dynamic Modeling and Constraint-Aware Air Supply Control for Localized Water Management in Automotive Polymer Electrolyte Membrane Fuel Cells](https://arxiv.org/abs/2510.15250)
*Mostafaali Ayubirad,Zeng Qiu,Hao Wang,Chris Weinkauf,Michiel Van Nieuwstadt,Hamid R. Ossareh*

Main category: eess.SY

TL;DR: 提出了一种在指令调节器框架内的预测性约束感知控制方案，用于质子交换膜燃料电池系统的局部水合管理，通过调整空气供应设定点来防止膜干燥，同时保持净功率跟踪。


<details>
  <summary>Details</summary>
Motivation: 解决质子交换膜燃料电池系统中膜水合管理的挑战，特别是在反流配置中阳极入口附近最干燥区域的动态行为，防止膜干燥同时优化功率输出。

Method: 首先建立包含堆栈、反应物供应和冷却子系统的综合非线性动态模型，然后推导降阶线性化模型用于约束执行，最后在指令调节器框架内调整空气供应设定点。

Result: 通过实际驾驶循环仿真验证了所提方法在维持局部膜水合状态的同时能够紧密跟踪所需净功率的有效性。

Conclusion: 该预测性约束感知控制方案成功实现了质子交换膜燃料电池系统的局部水合管理，在防止膜干燥的同时保持了功率输出性能。

Abstract: In this paper, a predictive constraint-aware control scheme is formulated
within the Command Governor (CG) framework for localized hydration management
of a proton exchange membrane (PEM) fuel cell system. First, a comprehensive
nonlinear dynamic model of the fuel cell system is presented which includes a
pseudo 2-dimensional (P2D) model of the stack, reactant supply and cooling
subsystems. The model captures the couplings among the various subsystems and
serves as the basis for designing output feedback controllers to track the
optimal set-points of the air supply and cooling systems for power
optimization. The closed-loop nonlinear model is then used to analyze the
dynamic behavior of membrane hydration near the anode inlet, the driest region
of the membrane in a counter-flow configuration, under various operating
conditions. A reduced-order linearized model is then derived to approximate
hydration behavior with sufficient fidelity for constraint enforcement. This
model is used within the CG framework to adjust the air supply set-points when
necessary to prevent membrane dry-out. The effectiveness of the proposed
approach in maintaining local membrane hydration while closely tracking the
requested net power is demonstrated through realistic drive-cycle simulations.

</details>


### [39] [Modeling and Dynamic Simulation of a Hybrid Wind-Wave System on a Hexagonal Semi-Submersible Platform](https://arxiv.org/abs/2510.15285)
*Saeid Bayat,Jerry Zuo,Jing Sun*

Main category: eess.SY

TL;DR: 提出了一种结合风力涡轮机和波浪能转换器的混合浮动海上平台，通过六边形半潜式结构集成三个振荡涌浪波浪能转换器，既能发电又能提供水动力稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有海上可再生能源平台大多单独利用风能或波浪能，缺乏集成解决方案。本研究旨在开发一种同时捕获风能和波浪能的混合平台。

Method: 使用WEC-Sim开发建模和仿真框架，基于NREL 5 MW半潜式参考模型进行基准测试。进行稳心高度分析和12个几何变量的敏感性分析，并通过时域仿真评估性能。

Result: 平台年发电量估计为风能16.86 GWh，波浪能3.65 GWh，波浪能占总发电量的18%。波浪入射角影响能量捕获和平台响应，翼板扫掠可调节俯仰运动。

Conclusion: 集成风浪平台具有巨大潜力，未来研究应关注结构建模和先进控制策略。

Abstract: Offshore renewable energy systems offer promising solutions for sustainable
power generation, yet most existing platforms harvest either wind or wave
energy in isolation. This study presents a hybrid floating offshore platform
that integrates a wind turbine with three oscillating surge wave energy
converters (WECs) into a hexagonal semi-submersible structure. In this
configuration, the flaps are integrated with the platform geometry to provide
both energy extraction and hydrodynamic stability. A modeling and simulation
framework was developed using WEC-Sim and benchmarked against the NREL 5 MW
semisubmersible reference. Metacentric height analysis confirmed hydrostatic
stability across a range of prescribed flap angles. Sensitivity analysis of
twelve geometric variables identified flap dimensions and tower length as
dominant drivers of stability, energy capture, and tower stress. Time-domain
simulations revealed dependence on wave incidence angle, with variations in
flap power sharing, capture width ratio (CWR), and platform response. The
feasibility of using flap sweeps to modulate pitch motion was also
demonstrated. Annual energy production (AEP) estimates based on site-specific
data indicate 16.86 GWh from wind and 3.65 GWh from wave energy, with WECs
contributing about 18% of the total. These results highlight the potential of
integrated wind-wave platforms and point toward future studies on structural
modeling and advanced control.

</details>


### [40] [TranSimHub:A Unified Air-Ground Simulation Platform for Multi-Modal Perception and Decision-Making](https://arxiv.org/abs/2510.15365)
*Maonan Wang,Yirong Chen,Yuxin Cai,Aoyu Pang,Yuejiao Xie,Zian Ma,Chengcheng Xu,Kemou Jiang,Ding Wang,Laurent Roullet,Chung Shue Chen,Zhiyong Cui,Yuheng Kan,Michael Lepech,Man-On Pun*

Main category: eess.SY

TL;DR: 提出了TranSimHub——一个用于空-地协同智能的统一仿真平台，支持多模态渲染、跨域信息交换和可控场景编辑。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏统一的空-地协同智能仿真环境，限制了跨域感知、通信约束下的协调和联合决策优化的研究进展。

Method: 开发了TranSimHub平台，提供同步的多视图渲染（RGB、深度、语义分割），支持空-地信息交换，并包含因果场景编辑器用于可控场景创建和反事实分析。

Result: 成功构建了一个开源仿真平台，支持在真实空-地交通场景中进行端到端的感知、融合和控制研究。

Conclusion: TranSimHub填补了空-地协同智能研究中的仿真平台空白，为下一代智能交通管理提供了重要工具。

Abstract: Air-ground collaborative intelligence is becoming a key approach for
next-generation urban intelligent transportation management, where aerial and
ground systems work together on perception, communication, and decision-making.
However, the lack of a unified multi-modal simulation environment has limited
progress in studying cross-domain perception, coordination under communication
constraints, and joint decision optimization. To address this gap, we present
TranSimHub, a unified simulation platform for air-ground collaborative
intelligence. TranSimHub offers synchronized multi-view rendering across RGB,
depth, and semantic segmentation modalities, ensuring consistent perception
between aerial and ground viewpoints. It also supports information exchange
between the two domains and includes a causal scene editor that enables
controllable scenario creation and counterfactual analysis under diverse
conditions such as different weather, emergency events, and dynamic obstacles.
We release TranSimHub as an open-source platform that supports end-to-end
research on perception, fusion, and control across realistic air and ground
traffic scenes. Our code is available at
https://github.com/Traffic-Alpha/TranSimHub.

</details>


### [41] [A Tsetlin Machine Image Classification Accelerator on a Flexible Substrate](https://arxiv.org/abs/2510.15519)
*Yushu Qin,Marcos L. L. Sartori,Shengyu Duan,Emre Ozer,Rishad Shafik,Alex Yakovlev*

Main category: eess.SY

TL;DR: 首次在柔性集成电路上实现数字Tsetlin机器，开发了两种TM推理模型，分别达到98.5%和93%的准确率，适用于可穿戴医疗和边缘计算。


<details>
  <summary>Details</summary>
Motivation: Tsetlin机器以其高能效、可解释性和边缘计算适用性著称，但受限于传统硅基芯片的刚性。本文旨在通过柔性集成电路技术突破这一限制。

Method: 使用Pragmatic的600nm IGZO基FlexIC技术，开发了两种TM推理模型：一个使用6800个NAND2等效逻辑门，另一个更紧凑版本使用1420个门，均针对8x8像素手写数字识别数据集定制设计。

Result: 第一个模型达到98.5%准确率，面积8x8 mm²；第二个模型达到93%准确率，面积4x4 mm²。证明了在柔性集成电路上部署TM推理引擎的可行性。

Conclusion: 成功展示了柔性TM推理引擎在可穿戴医疗和边缘计算应用中的部署潜力，为柔性电子设备中的智能计算开辟了新途径。

Abstract: This paper introduces the first implementation of digital Tsetlin Machines
(TMs) on flexible integrated circuit (FlexIC) using Pragmatic's 600nm
IGZO-based FlexIC technology. TMs, known for their energy efficiency,
interpretability, and suitability for edge computing, have previously been
limited by the rigidity of conventional silicon-based chips. We develop two TM
inference models as FlexICs: one achieving 98.5% accuracy using 6800 NAND2
equivalent logic gates with an area of 8X8 mm2, and a second more compact
version achieving slightly lower prediction accuracy of 93% but using only 1420
NAND2 equivalent gates with an area of 4X4 mm2, both of which are
custom-designed for an 8X8-pixel handwritten digit recognition dataset. The
paper demonstrates the feasibility of deploying flexible TM inference engines
into wearable healthcare and edge computing applications.

</details>


### [42] [Hypergame-based Cognition Modeling and Intention Interpretation for Human-Driven Vehicles in Connected Mixed Traffic](https://arxiv.org/abs/2510.15573)
*Jianguo Chen,Zhengqin Liu,Jinlong Lei,Peng Yi,Yiguang Hong,Hong Chen*

Main category: eess.SY

TL;DR: 本文提出了一种基于超博弈理论的混合交通轨迹预测与规划方法，考虑人类驾驶员的认知局限性，通过分层认知建模框架和分布式意图学习算法，实现CAV对HV轨迹的准确预测和安全规划。


<details>
  <summary>Details</summary>
Motivation: 当前研究假设人类驾驶员对所有车辆目标有完美认知，这在实际中不现实。需要解决HV认知和感知局限性的问题，提升混合交通环境下的安全性和效率。

Method: 利用超博弈理论建模人类有限理性，提出分层认知建模框架，开发分布式意图解释的逆学习算法，支持离线和在线场景，并引入分布式轨迹预测与规划方法。

Result: 高速公路换道场景仿真验证了参数学习准确性、对噪声轨迹观测的鲁棒性，以及HV轨迹预测的安全性，在离线和在线实施中均有效。

Conclusion: 所提方法能够准确学习HV参数，在混合交通环境下实现安全高效的轨迹预测与规划，为CAV与HV共存的实际应用提供了有效解决方案。

Abstract: With the practical implementation of connected and autonomous vehicles
(CAVs), the traffic system is expected to remain a mix of CAVs and human-driven
vehicles (HVs) for the foreseeable future. To enhance safety and traffic
efficiency, the trajectory planning strategies of CAVs must account for the
influence of HVs, necessitating accurate HV trajectory prediction. Current
research often assumes that human drivers have perfect knowledge of all
vehicles' objectives, an unrealistic premise. This paper bridges the gap by
leveraging hypergame theory to account for cognitive and perception limitations
in HVs. We model human bounded rationality without assuming them to be merely
passive followers and propose a hierarchical cognition modeling framework that
captures cognitive relationships among vehicles. We further analyze the
cognitive stability of the system, proving that the strategy profile where all
vehicles adopt cognitively equilibrium strategies constitutes a hyper Nash
equilibrium when CAVs accurately learn HV parameters. To achieve this, we
develop an inverse learning algorithm for distributed intention interpretation
via vehicle-to-everything (V2X) communication, which extends the framework to
both offline and online scenarios. Additionally, we introduce a distributed
trajectory prediction and planning approach for CAVs, leveraging the learned
parameters in real time. Simulations in highway lane-changing scenarios
demonstrate the proposed method's accuracy in parameter learning, robustness to
noisy trajectory observations, and safety in HV trajectory prediction. The
results validate the effectiveness of our method in both offline and online
implementations.

</details>


### [43] [Observer Design over Hypercomplex Quaternions](https://arxiv.org/abs/2510.15598)
*Michael Sebek*

Main category: eess.SY

TL;DR: 开发了四元数上的观测器设计方法，避免使用特征多项式框架，通过右可观测伴随形式和伴随多项式来编码误差动态。


<details>
  <summary>Details</summary>
Motivation: 四元数上的经典观测器设计方法（如使用行列式、特征多项式、凯莱-哈密顿恒等式）无法直接移植到四元数上，需要开发新的框架。

Method: 使用标准右模约定，推导右可观测伴随形式及其伴随多项式，通过系数更新和相似变换进行设计，避免使用行列式等传统工具。

Result: 得到了直接在四元数上设计全阶观测器的简单方法，阐明了右谱及其相似类的作用，并确定了经典单步公式何时仍然有效。

Conclusion: 该方法为四元数系统提供了有效的观测器设计框架，比向量化或复伴随替代方法更具优势。

Abstract: We develop observer design over hypercomplex quaternions in a
characteristic-polynomial-free framework. Using the standard right-module
convention, we derive a right observable companion form and its companion
polynomial that encodes error dynamics via right-eigenvalue similarity classes.
The design mirrors the real/complex case - coefficient updates in companion
coordinates, followed by a similarity back - yet avoids determinants,
characteristic/minimal polynomials, and Cayley-Hamilton identities that do not
transfer to quaternions. We also give an Ackermann-type construction for the
important case of closed-loop companion polynomials with real coefficients,
ensuring similarity-equivariant evaluation. The results yield simple recipes
for full-order observers directly over quaternions, clarify the role of right
spectra and their similarity classes, and pinpoint when classical one-shot
formulas remain valid. Numerical examples illustrate the method and advantages
over vectorized or complex-adjoint surrogates.

</details>


### [44] [A Predictive Flexibility Aggregation Method for Low Voltage Distribution System Control](https://arxiv.org/abs/2510.15613)
*Clément Moureau,Thomas Stegen,Mevludin Glavic,Bertrand Cornélusse*

Main category: eess.SY

TL;DR: 提出一种基于预测控制策略的低压配电系统管理方法，通过聚合住宅单元灵活性形成三维图表，结合离线优化和半显式模型预测控制实现高效、低成本、隐私保护的实时控制。


<details>
  <summary>Details</summary>
Motivation: 管理低压配电系统需要处理大量住宅单元的灵活性，同时满足实时控制、隐私保护和计算效率的要求。

Method: 离线解决多参数优化问题聚合资产灵活性，然后在线解决半显式模型预测控制问题，结合测量生成灵活性图表。

Result: 在5节点低压网络上验证，与理想技术相比表现良好，满足实时控制需求。

Conclusion: 该方法通过离线计算和在线控制的结合，实现了高效、低成本、隐私保护的低压配电系统管理。

Abstract: This paper presents a predictive control strategy to manage low-voltage
distribution systems. The proposed approach relies on an aggregate of the
flexibility at the residential unit level into a three-dimensional chart that
represents the injected active and reactive power, and the flexibility cost.
First, this method solves a multiparametric optimization problem offline at the
residential unit level to aggregate the flexibility of the assets. Then, a
semi-explicit model predictive control problem is solved to account for
forecasts. By combining the results of these problems with measurements, the
method generates the desired flexibility chart. The proposed approach is
compatible with realtime control requirements, as heavy computations are
performed offline locally, making it naturally parallelizable. By linking
realtime flexibility assessment with energy scheduling, our approach enables
efficient, low-cost, and privacy-preserving management of low-voltage
distribution systems. We validate this method on a low-voltage network of 5
buses by comparing it with an ideal technique.

</details>


### [45] [Cross-border offshore hydrogen trade and carbon mitigation for Europe's net zero transition](https://arxiv.org/abs/2510.15695)
*Sheng Wang,Muhammad Maladoh Bah*

Main category: eess.SY

TL;DR: 该研究评估了爱尔兰和英国海上绿氢在欧洲脱碳中的潜力，发现到2050年可减少175.16 Mt/年的二氧化碳排放，氢能将从西向东流动，重塑欧洲能源供应结构。


<details>
  <summary>Details</summary>
Motivation: 欧洲国家在净零转型和海上能源开发方面雄心勃勃，爱尔兰和英国承诺的海上风电容量远超其电力需求，但岛屿国家的潜力常被低估。研究旨在探索这些国家海上氢能在欧洲脱碳中的作用。

Method: 开发了自下而上的方法，评估未来氢/氨交易和各国在碳减排中的贡献，考虑了海上氢生产的相对成本竞争力、国内小时电力和天然气系统运行以及国际航运成本。

Result: 结果显示，英国将在2030-2040年间成为最大的氢供应商，而在2050年被爱尔兰超越，爱尔兰将向法国和西班牙出口161 TWh的氢。海上绿氢总共可贡献175.16 Mt的年二氧化碳减排量。

Conclusion: 从西向东的氢能流动不仅促进了欧洲的净零进展，还重塑了能源供应结构，有助于确保整个欧洲大陆的能源安全。

Abstract: European countries are ambitious in both the net-zero transition and offshore
energy resource development. The Irish and UK governments announced their
commitments to offshore wind capacities - 37 and 125 GW, respectively, in 2050,
more than two times higher than their projected power demands. While other
continental countries, such as Germany, are calling for cleaner fuel resources.
Exporting surplus offshore green hydrogen and bridging supply and demand could
be pivotal in carbon emission mitigation for Europe. Yet, the potentials of
these Island countries, are usually underestimated. This paper developed a
bottom-up method to investigate the role of offshore hydrogen from Ireland and
the UK in the decarbonisation of the entire Europe. We evaluate the future
hydrogen/ammonia trading and the contributions of each country in carbon
emission mitigation, considering their relative cost-competitiveness in
offshore hydrogen production, domestic hourly power and gas system operation,
and international shipping costs. Results indicate that the offshore green
hydrogen could reduce 175.16 Mt/year of carbon dioxide emissions in Europe. The
UK will be the largest hydrogen supplier from 2030 to 2040, while surpassed by
Ireland in 2050, with 161 TWh of hydrogen exports to France and Spain. The
offshore green hydrogen can contribute to 175.16 Mt of annual carbon dioxide
emission reductions in total. This general flow of hydrogen from the West to
the East not only facilitates Europe's net-zero progress, but also reshapes the
energy supply structure and helps to ensure energy security across the European
continent.

</details>


### [46] [Mitigating Underwater Noise from Offshore Wind Turbines via Individual Pitch Control](https://arxiv.org/abs/2510.15707)
*Martín de Frutos,Laura Botero-Bolívar,Esteban Ferrer*

Main category: eess.SY

TL;DR: 提出一种桨距控制策略来降低海上风力涡轮机的水下声学足迹，通过调节桨叶在叶片通过频率处的桨距来减少整体声压级和振幅调制。


<details>
  <summary>Details</summary>
Motivation: 海上风力涡轮机的水下声学足迹对依赖声音进行交流、导航和生存的海洋生物造成影响，需要采取措施最小化这种影响。

Method: 使用耦合叶片元素动量法和耦合空气-水声传播建模量化三个参考涡轮机的水下声学特征，提出并实施开环独立桨距控制策略。

Result: 通过约5度的桨距变化，可实现高达5分贝的整体声压级降低和20%的振幅调制深度减少，能量捕获损失为5-10%。

Conclusion: 研究揭示了一个先前被低估的噪声路径，并证明有针对性的桨距调节可以有效减轻其影响。

Abstract: This paper proposes a pitch control strategy to mitigate the underwater
acoustic footprint of offshore wind turbines, a measure that will soon become
necessary to minimize impacts on marine life, which rely on sound for
communication, navigation, and survival. First, we quantify the underwater
acoustic signature of blade-generated aerodynamic noise from three reference
turbines, the NREL 5 MW, DTU 10 MW, and IEA 22 MW, using coupling blade element
momentum and coupled air-water acoustic propagation modeling. Second, we
propose and implement an open-loop individual pitch control (IPC) strategy that
modulates the pitch of the blade at the blade passing frequency to attenuate
the overall sound pressure level (OSPL) and the amplitude modulation (AM) of
the transmitted noise. Third, we benchmark IPC performance against conventional
pitch schemes. The results indicate that up to 5 dB reductions in OSPL and a
decrease in AM depth 20% can be achieved with a pitch variation of
$\Delta\theta\approx 5^\circ$, with small losses (5-10%) in energy capture.
These findings highlight a previously underappreciated noise pathway and
demonstrate that targeted blade-pitch modulation can mitigate its impact.

</details>


### [47] [Sugar Shack 4.0: Practical Demonstration of an IIoT-Based Event-Driven Automation System](https://arxiv.org/abs/2510.15708)
*Thomas Bernard,François Grondin,Jean-Michel Lavoie*

Main category: eess.SY

TL;DR: 本文提出了一种基于工业物联网工具的替代PLC的自动化方案，采用事件驱动架构，在边缘服务器上实现设备抽象、互锁控制、操作组合和工作流编排，并通过实际案例验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 传统PLC为中心的自动化系统存在成本高、集成复杂等问题，需要一种更灵活、低成本的替代方案来支持工业4.0技术的应用。

Method: 采用分层设计：设备层使用ESP32网关连接传感器和执行器，边缘服务器层实现设备抽象、互锁控制、操作组合和工作流编排，使用Node-RED状态机和MQTT通信。

Result: 在完整生产季的评估中，消息传输延迟约0.1秒，命令执行延迟2-3秒，命令完成时间约6秒，运行时间从数十秒到数分钟不等，网络和编排开销相对于过程动态可忽略。

Conclusion: 该方法能够实现模块化、分布式控制，不牺牲确定性或故障隔离，降低了材料和集成成本，支持容器化部署，并自然支持边缘/云分离架构。

Abstract: This paper presents a practical alternative to
programmable-logic-controller-centric automation by implementing an
event-driven architecture built with industrial Internet of Things tools. A
layered design on a local edge server (i) abstracts actuators, (ii) enforces
mutual exclusion of shared physical resources through an interlock with
priority queueing, (iii) composes deterministic singular operations, and (iv)
orchestrates complete workflows as state machines in Node-RED, with
communication over MQTT. The device layer uses low-cost ESP32-based gateways to
interface sensors and actuators, while all automation logic is offloaded to the
server side. As part of a larger project involving the first
scientifically-documented integration of Industry 4.0 technologies in a maple
syrup boiling center, this work demonstrates the deployment of the proposed
system as a case-study. Evaluation over an entire production season shows
median message time of flight around one tenth of a second, command
issuance-to-motion latencies of about two to three seconds, and command
completion near six seconds dominated by actuator mechanics; operation runtimes
span tens of seconds to minutes. These results indicate that network and
orchestration overheads are negligible relative to process dynamics, enabling
modular, distributed control without compromising determinism or fault
isolation. The approach reduces material and integration effort, supports
portable containerized deployment, and naturally enables an edge/cloud split in
which persistence and analytics are offloaded while automation remains at the
edge.

</details>


### [48] [Integrating Conductor Health into Dynamic Line Rating and Unit Commitment under Uncertainty](https://arxiv.org/abs/2510.15740)
*Geon Roh,Jip Kim*

Main category: eess.SY

TL;DR: 提出了考虑导体健康成本的动态线路额定值优化模型CHA-UC，通过量化高温运行导致的折旧成本，在保证线路安全的同时提高可再生能源利用率。


<details>
  <summary>Details</summary>
Motivation: 动态线路额定值(DLR)虽然能提高线路利用率，但长期高温运行对导体健康的负面影响常被忽视，需要量化这些成本并纳入运行决策。

Method: 开发了导体健康感知机组组合(CHA-UC)模型，包含导体温度的鲁棒线性近似，并将每小时高温运行导致的预期折旧成本整合到目标函数中。

Result: 在德州123节点测试系统中，CHA-UC相比静态线路额定值(SLR)降低总成本0.8%，减少可再生能源弃电84%，而传统不考虑风险的DLR操作因过度高温运行导致更高成本。

Conclusion: CHA-UC通过自适应管理风电与DLR预测误差的相关性，在风险对冲条件下放松潮流限制，在风险放大条件下收紧限制，实现了更安全的线路运行。

Abstract: Dynamic line rating (DLR) enables greater utilization of existing
transmission lines by leveraging real-time weather data. However, the elevated
temperature operation (ETO) of conductors under DLR is often overlooked,
despite its long-term impact on conductor health. This paper addresses this
issue by 1) quantifying depreciation costs associated with ETO and 2) proposing
a Conductor Health-Aware Unit Commitment (CHA-UC) that internalizes these costs
in operational decisions. The CHA-UC incorporates a robust linear approximation
of conductor temperature and integration of expected depreciation costs due to
hourly ETO into the objective function. Case studies on the Texas 123-bus
backbone test system using NOAA weather data demonstrate that the proposed
CHA-UC model reduces the total cost by 0.8% and renewable curtailment by
84%compared to static line rating (SLR), while conventional DLR operation
without risk consideration resulted in higher costs due to excessive ETO.
Further analysis of the commitment decisions and the line temperature
statistics confirms that the CHA-UC achieves safer line flows by shifting
generator commitments. Finally, we examine the emergent correlation between
wind generation and DLR forecast errors, and show that CHA-UC adaptively
manages this effect by relaxing flows for risk-hedging conditions while
tightening flows for risk-amplifying ones.

</details>


### [49] [Braking within Barriers: Constructive Safety-Critical Control for Input-Constrained Vehicles via the Backup Set Method](https://arxiv.org/abs/2510.15797)
*Laszlo Gacsi,Adam K. Kiss,Tamas G. Molnar*

Main category: eess.SY

TL;DR: 提出了一种用于车辆在不对称路面制动时保持横向运动有界的安全关键控制框架，通过备份控制屏障函数设计制动控制器，防止车辆打滑并最小化制动距离。


<details>
  <summary>Details</summary>
Motivation: 解决车辆在不对称路面制动时的安全控制问题，防止因制动力不均导致的过度横向运动（如车辆打滑），同时考虑输入约束（制动力受路面摩擦限制）。

Method: 使用备份控制屏障函数进行安全控制设计，提出基于反馈线性化和连续时间Lyapunov方程的系统性方法构建有效的备份集-备份控制器对。

Result: 在四轮车辆模型上进行仿真，验证了所提方法在不对称路面制动场景中的有效性，能够保证横向运动安全边界。

Conclusion: 该安全关键控制框架能够有效防止车辆在不对称路面制动时发生打滑，同时最小化制动距离，为车辆制动安全控制提供了系统性的解决方案。

Abstract: This paper presents a safety-critical control framework to maintain bounded
lateral motions for vehicles braking on asymmetric surfaces. We synthesize a
brake controller that assists drivers and guarantees safety against excessive
lateral motions (i.e., prevents the vehicle from spinning out) while minimizing
the stopping distance. We address this safety-critical control problem in the
presence of input constraints, since braking forces are limited by the
available friction on the road. We use backup control barrier functions for
safe control design. As this approach requires the construction of a backup set
and a backup controller, we propose a novel, systematic method to creating
valid backup set-backup controller pairs based on feedback linearization and
continuous-time Lyapunov equations. We use simple examples to demonstrate our
proposed safety-critical control method. Finally, we implement our approach on
a four-wheel vehicle model for braking on asymmetric surfaces and present
simulation results.

</details>


### [50] [Bio-inspired Microgrid Management based on Brain's Sensorimotor Gating](https://arxiv.org/abs/2510.15847)
*Panos C. Papageorgiou,Anastasios E. Giannopoulos,Sotirios T. Spantideas*

Main category: eess.SY

TL;DR: 本文提出了一种基于感觉运动门控机制的神经微电网新范式，通过模拟大脑的预脉冲抑制和预脉冲促进机制，为微电网提供自保护、自适应和弹性的控制框架。


<details>
  <summary>Details</summary>
Motivation: 微电网在动态扰动处理、保护协调和不确定性方面面临挑战，需要生物启发的智能控制解决方案。感觉运动门控机制为选择性抑制或放大响应提供了生物学模型。

Method: 提出传感器运动门控启发的神经微电网框架，将预脉冲抑制映射为保护性阻尼控制，预脉冲促进映射为自适应放大校正控制动作，并与机器学习方法集成。

Result: 建立了分析工作流设计、神经回路类比和机器学习集成的完整框架，为微电网控制提供了新的生物启发范式。

Conclusion: 感觉运动门控机制为设计自保护、自适应和弹性微电网提供了有前景的框架，未来需要在数学建模、数字孪生验证和跨学科合作方面进一步研究。

Abstract: Microgrids are emerging as key enablers of resilient, sustainable, and
intelligent power systems, but they continue to face challenges in dynamic
disturbance handling, protection coordination, and uncertainty. Recent efforts
have explored Brain Emotional Learning (BEL) controllers as bio-inspired
solutions for microgrid control. Building on this growing trajectory, this
article introduces a new paradigm for Neuro-Microgrids, inspired by the brain's
sensorimotor gating mechanisms, specifically the Prepulse Inhibition (PPI) and
Prepulse Facilitation (PPF). Sensorimotor gating offers a biological model for
selectively suppressing or amplifying responses depending on contextual
relevance. By mapping these principles onto the hierarchical control
architecture of microgrids, we propose a Sensorimotor Gating-Inspired
Neuro-Microgrid (SG-NMG) framework. In this architecture, PPI-like control
decisions correspond to protective damping in primary and secondary management
of microgrids, whereas PPF-like decisions correspond to adaptive amplification
of corrective control actions. The framework is presented through analytical
workflow design, neuro-circuitry analogies, and integration with machine
learning methods. Finally, open challenges and research directions are
outlined, including the mathematical modeling of gating, digital twin
validation, and cross-disciplinary collaboration between neuroscience and
industrial power systems. The resulting paradigm highlights sensorimotor gating
as a promising framework for designing self-protective, adaptive, and resilient
microgrids.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [51] [A physically extended EEIO framework for material efficiency assessment in United States manufacturing supply chains](https://arxiv.org/abs/2510.15121)
*Heather Liddell,Beth Kelley,Liz Wachs,Alberta Carpenter,Joe Cresko*

Main category: econ.GN

TL;DR: 开发了美国能源部EEIO-IDA模型的物理扩展，创建了同时包含物理和环境扩展的EEIO模型，用于量化工业子部门基于质量的环境影响强度指标。


<details>
  <summary>Details</summary>
Motivation: 物理评估材料流动对于制定可持续脱碳和循环策略至关重要，但由于高质量原始数据稀缺和行业分类系统不统一，完成物理评估具有挑战性。

Method: 将美国经济分为商品生产和服务生产子部门，结合贸易数据和物理生产数据量化每个商品生产子部门的质量流动，使用价格估算和质量平衡假设完成物理流动数据集。

Result: 创建的数据集与EEIO-IDA工具集成后，能够量化每个工业子部门基于质量的环境影响强度指标（如CO₂当量/千克）。

Conclusion: 这项工作与美国能源部现有框架和工具保持一致，包括EEIO-IDA工具、工业脱碳路线图和工业转型路径研究，为工业脱碳提供了物理基础支持。

Abstract: A physical assessment of material flows in an economy (e.g., material flow
quantification) can support the development of sustainable decarbonization and
circularity strategies by providing the tangible physical context of industrial
production quantities and supply chain relationships. However, completing a
physical assessment is challenging due to the scarcity of high-quality raw data
and poor harmonization across industry classification systems used in data
reporting. Here we describe a new physical extension for the U.S. Department of
Energy's (DOE's) EEIO for Industrial Decarbonization (EEIO-IDA) model, yielding
an expanded EEIO model that is both physically and environmentally extended. In
the model framework, the U.S. economy is divided into goods-producing and
service-producing subsectors, and mass flows are quantified for each
goods-producing subsector using a combination of trade data (e.g., UN Comtrade)
and physical production data (e.g., U.S. Geological Survey). Given that
primary-source production data are not available for all subsectors,
price-imputation and mass-balance assumptions are developed and used to
complete the physical flows dataset with high-quality estimations. The
resulting dataset, when integrated with the EEIO-IDA tool, enables the
quantification of environmental impact intensity metrics on a mass basis (e.g.,
CO$_2$eq/kg)) for each industrial subsector. This work is designed to align
with existing DOE frameworks and tools, including the EEIO-IDA tool, the DOE
Industrial Decarbonization Roadmap (2022), and Pathways for U.S. Industrial
Transformations study (2025).

</details>


### [52] [Strategic Interactions in Academic Dishonesty: A Game-Theoretic Analysis of the Exam Script Swapping Mechanism](https://arxiv.org/abs/2510.15307)
*Venkat Ram Reddy Ganuthula,Manish Kumar Singh*

Main category: econ.GN

TL;DR: 提出了一种基于强制交换考试卷的新颖博弈论框架来分析学术不端行为，该惩罚机制通过制造战略互依性比传统惩罚更具威慑力。


<details>
  <summary>Details</summary>
Motivation: 传统学术不端惩罚效果有限，需要探索能创造相互脆弱性的非常规惩罚机制来更有效遏制作弊行为。

Method: 建立非合作博弈模型，分析三种基础场景：非对称准备水平、相互不准备和协调性部分准备，进行纳什均衡分析。

Result: 试卷交换惩罚比传统惩罚产生更强的威慑效果，相互准备成为主导策略，证明了非常规惩罚机制的有效性。

Conclusion: 非常规惩罚机制通过制造相互脆弱性比传统个体惩罚更有效，为机构政策设计提供了新思路，需要未来实证验证。

Abstract: This paper presents a novel game theoretic framework for analyzing academic
dishonesty through the lens of a unique deterrent mechanism: forced exam script
swapping between students caught copying. We model the strategic interactions
between students as a non cooperative game with asymmetric information and
examine three base scenarios asymmetric preparation levels, mutual non
preparation, and coordinated partial preparation. Our analysis reveals that the
script swapping punishment creates a stronger deterrent effect than traditional
penalties by introducing strategic interdependence in outcomes. The Nash
equilibrium analysis demonstrates that mutual preparation emerges as the
dominant strategy. The framework provides insights for institutional policy
design, suggesting that unconventional punishment mechanisms that create mutual
vulnerability can be more effective than traditional individual penalties.
Future empirical validation and behavioral experiments are proposed to test the
model predictions, including explorations of tapering off effects in punishment
severity over time.

</details>


### [53] [International migration and dietary diversity of left-behind households: evidence from India](https://arxiv.org/abs/2510.15399)
*Pooja Batra,Ajay Sharma*

Main category: econ.GN

TL;DR: 国际移民对留守家庭的食品消费和饮食多样性有积极影响，移民家庭在总体消费、食品支出和饮食多样性方面均高于非移民家庭，但同时也增加了不健康食品的消费。


<details>
  <summary>Details</summary>
Motivation: 研究国际移民对留守家庭食品消费和饮食多样性的影响，了解移民汇款如何改变家庭消费模式。

Method: 使用喀拉拉邦2011年移民调查数据，采用普通最小二乘法和工具变量法进行分析。

Result: 移民家庭总体消费支出和食品支出更高，饮食多样性增加，在蛋白质食品上支出更多，但同时也增加了加工食品等不健康食品的消费。

Conclusion: 国际移民改善了留守家庭的消费能力和饮食多样性，但也带来了不健康饮食习惯的风险。

Abstract: In this paper, we analyse the impact of international migration on the food
consumption and dietary diversity of left-behind households. Using the Kerala
migration survey 2011, we study whether households with emigrants (on account
of international migration) have higher consumption expenditure and improved
dietary diversity than their non-migrating counterparts. We use ordinary least
square and instrumental variable approach to answer this question. The key
findings are that: a) emigrant households have higher overall consumption
expenditure as well as higher expenditure on food; b) we find that
international migration leads to increase in the dietary diversity of left
behind households. Further, we explore the effect on food sub-group expenditure
for both rural and urban households. We find that emigrant households spend
more on protein (milk, pulses and egg, fish and meat), at the same time there
is higher spending on non-healthy food habits (processed and ready to eat food
items) among them.

</details>


### [54] [Impact of Three-Point Rule Change on Competitive Balance in Football: A Synthetic Control Method Approach](https://arxiv.org/abs/2510.15405)
*Ajay Sharma*

Main category: econ.GN

TL;DR: 本文研究了1981年英格兰足球协会将联赛胜场积分从2分改为3分对竞争平衡的影响，发现这一规则变化提高了联赛的竞争平衡，但对场均进球数没有显著影响。


<details>
  <summary>Details</summary>
Motivation: 体育管理机构经常通过改变规则来提高竞争性，英格兰足球协会1981年的三分制改革就是一个典型案例，需要评估这种规则变化对竞争平衡的实际影响。

Method: 采用准实验估计设计中的合成控制方法，来测量规则变化对国内联赛竞争平衡的影响。

Result: 三分制规则变化导致英格兰联赛的竞争平衡得到提高，但场均进球数没有发生显著变化。

Conclusion: 将胜场积分从2分改为3分的规则变化有效地提高了联赛的竞争平衡，且没有影响比赛的进攻性。

Abstract: Governing authorities in sports often make changes to rules and regulations
to increase competitiveness. One such change was made by the English Football
Association in 1981 when it changed the rule for awarding points in the
domestic league from two points for a win to three points. This study aims to
measure this rule change's impact on the domestic league's competitive balance
using a quasi-experimental estimation design of a synthetic control method. The
three-point rule change led to an increase in competitive balance in the
English League. Further, we show no significant change in the number of goals
scored per match.

</details>


### [55] [Heterogeneity among migrants, education-occupation mis-match and returns to education: Evidence from India](https://arxiv.org/abs/2510.15420)
*Shweta Bahl,Ajay Sharma*

Main category: econ.GN

TL;DR: 该研究使用印度全国代表性数据，分析内部移民的教育职业不匹配现象及其回报，并考虑移民群体的异质性因素。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解内部移民中教育职业不匹配的发生率及其回报，同时考虑移民群体因迁移原因、人口特征、空间因素等产生的异质性。

Method: 使用印度全国代表性数据，分析教育职业不匹配的发生率和回报，考虑迁移原因、人口特征、空间因素、迁移经验和迁移类型等异质性因素。

Result: 分析显示，教育职业不匹配的发生率和回报因迁移原因、人口特征和空间因素而异。

Conclusion: 研究强调需要关注教育职业不匹配以提高迁移的生产率效益，并为最小化移民不匹配可能性和最大化教育回报提供了框架。

Abstract: Using nationally representative data for India, this paper examines the
incidence of education occupation mismatch and returns to education and EOM for
internal migrants while considering the heterogeneity among them. In
particular, this study considers heterogeneity arising because of the reason to
migrate, demographic characteristics, spatial factors, migration experience,
and type of migration. The analysis reveals that there exists variation in the
incidence and returns to EOM depending on the reason to migrate, demographic
characteristics, and spatial factors. The study highlights the need of focusing
on EOM to increase the productivity benefits of migration. It also provides the
framework for minimizing migrants' likelihood of being mismatched while
maximizing their returns to education.

</details>


### [56] [Political Interventions to Reduce Single-Use Plastics (SUPs) and Price Effects: An Event Study for Austria and Germany](https://arxiv.org/abs/2510.15617)
*Felix Reichel*

Main category: econ.GN

TL;DR: 该研究使用高频面板数据和事件研究法，测量了奥地利和德国对一次性塑料制品征收生产者费用后，这些成本转嫁给消费者的程度。研究发现奥地利有明显的价格传导效应，处理组产品在12个月内比非一次性塑料对照组高出13.01个指数点。


<details>
  <summary>Details</summary>
Motivation: 欧盟指令(EU) 2019/904后，奥地利和德国引入了一次性塑料制品生产者收费和基金支付制度，旨在覆盖清理工作成本。研究旨在量化这些政策成本如何影响消费者价格。

Method: 使用包含价格的高频零售报价面板数据，采用固定效应事件研究法和双向聚类标准误分析。

Result: 奥地利显示出明显的价格传导：处理组产品在12个月内比对照组高出13.01个指数点(p<0.001)，整个后期高出19.42个指数点(p<0.001)。气球产品效应显著持久，杯子产品短期波动较大。

Conclusion: 奥地利的一次性塑料制品生产者费用确实转嫁给了消费者，但不同产品的传导程度存在差异，气球产品传导效应最明显。

Abstract: Single-use plastics (SUPs) create large environmental costs. After Directive
(EU) 2019/904, Austria and Germany introduced producer charges and fund
payments meant to cover clean-up work. Using a high-frequency panel of retail
offer spells containing prices and a fixed-effects event study with two-way
clustered standard errors, this paper measures how much these costs drive up
consumer prices. We find clear price pass-through in Austria. When Austrian
products are pooled, treated items are 13.01 index points higher than non-SUP
controls within twelve months (DiD(12m); p<0.001) and 19.42 points over the
full post period (p<0.001). By product, balloons show strong and lasting
effects (DiD(12m)=13.43, p=0.007; Full DiD=19.96, p<0.001). Cups show mixed
short-run movements (e.g., DiD(12m)=-22.73, p=0.096) and a positive but
imprecise full-period contrast.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [57] [The Economics of AI Foundation Models: Openness, Competition, and Governance](https://arxiv.org/abs/2510.15200)
*Fasheng Xu,Xiaoyu Wang,Wei Chen,Karen Xie*

Main category: econ.TH

TL;DR: 该研究通过博弈论模型分析基础模型开放策略的经济驱动因素，发现开放度对竞争具有双重效应：促进知识溢出但增强在位者的数据飞轮优势。在位者的最优开放度在数据飞轮效应强度上呈非单调性，导致"开放陷阱"政策悖论。


<details>
  <summary>Details</summary>
Motivation: 基础模型的"开放度"选择已成为生态系统中的关键问题，但其背后的经济驱动因素尚未得到充分探索，需要分析开放策略如何影响AI价值链中的竞争。

Method: 构建两阶段博弈论模型，分析在位开发者、下游部署者和进入开发者之间的竞争动态，考察开放度的双重效应和数据飞轮效应的影响。

Result: 研究发现：在位者的最优开放度在数据飞轮效应强度上呈非单调性；存在"开放陷阱"政策悖论；垂直整合和政府补贴等常见干预措施可能无效。

Conclusion: 通过建模开发者对竞争和监管压力的战略响应，为分析复杂快速演变的基础模型生态系统中的竞争和设计有效政策提供了稳健框架。

Abstract: The strategic choice of model "openness" has become a defining issue for the
foundation model (FM) ecosystem. While this choice is intensely debated, its
underlying economic drivers remain underexplored. We construct a two-period
game-theoretic model to analyze how openness shapes competition in an AI value
chain, featuring an incumbent developer, a downstream deployer, and an entrant
developer. Openness exerts a dual effect: it amplifies knowledge spillovers to
the entrant, but it also enhances the incumbent's advantage through a "data
flywheel effect," whereby greater user engagement today further lowers the
deployer's future fine-tuning cost. Our analysis reveals that the incumbent's
optimal first-period openness is surprisingly non-monotonic in the strength of
the data flywheel effect. When the data flywheel effect is either weak or very
strong, the incumbent prefers a higher level of openness; however, for an
intermediate range, it strategically restricts openness to impair the entrant's
learning. This dynamic gives rise to an "openness trap," a critical policy
paradox where transparency mandates can backfire by removing firms' strategic
flexibility, reducing investment, and lowering welfare. We extend the model to
show that other common interventions can be similarly ineffective. Vertical
integration, for instance, only benefits the ecosystem when the data flywheel
effect is strong enough to overcome the loss of a potentially more efficient
competitor. Likewise, government subsidies intended to spur adoption can be
captured entirely by the incumbent through strategic price and openness
adjustments, leaving the rest of the value chain worse off. By modeling the
developer's strategic response to competitive and regulatory pressures, we
provide a robust framework for analyzing competition and designing effective
policy in the complex and rapidly evolving FM ecosystem.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [58] [Dynamic Spatial Treatment Effects as Continuous Functionals: Theory and Evidence from Healthcare Access](https://arxiv.org/abs/2510.15324)
*Tatsuru Kikuchi*

Main category: econ.EM

TL;DR: 提出了基于纳维-斯托克斯偏微分方程的连续函数框架来分析空间处理效应，将处理强度建模为时空连续函数，能够分析边界演化、空间梯度和累积暴露。


<details>
  <summary>Details</summary>
Motivation: 传统离散处理参数方法无法充分捕捉空间效应的连续性和动态演化，需要开发能够表征处理强度在时空连续变化的分析框架。

Method: 使用纳维-斯托克斯偏微分方程构建连续函数框架，将处理强度建模为τ(x,t)函数，通过实证分析32,520个美国邮政编码数据验证模型。

Result: 医疗可及性呈现指数空间衰减(κ=0.002837/km)，检测到37.1km边界，老年人群距离效应强2-13倍，对数衰减模型优于指数衰减模型(ΔAIC>10,000)。

Conclusion: 连续函数框架提供了预测能力、参数敏感性和诊断测试，优于传统双重差分方法，适用于环境经济学、银行和医疗政策等领域。

Abstract: I develop a continuous functional framework for spatial treatment effects
grounded in Navier-Stokes partial differential equations. Rather than discrete
treatment parameters, the framework characterizes treatment intensity as
continuous functions $\tau(\mathbf{x}, t)$ over space-time, enabling rigorous
analysis of boundary evolution, spatial gradients, and cumulative exposure.
Empirical validation using 32,520 U.S. ZIP codes demonstrates exponential
spatial decay for healthcare access ($\kappa = 0.002837$ per km, $R^2 =
0.0129$) with detectable boundaries at 37.1 km. The framework successfully
diagnoses when scope conditions hold: positive decay parameters validate
diffusion assumptions near hospitals, while negative parameters correctly
signal urban confounding effects. Heterogeneity analysis reveals 2-13 $\times$
stronger distance effects for elderly populations and substantial education
gradients. Model selection strongly favors logarithmic decay over exponential
($\Delta \text{AIC} > 10,000$), representing a middle ground between
exponential and power-law decay. Applications span environmental economics,
banking, and healthcare policy. The continuous functional framework provides
predictive capability ($d^*(t) = \xi^* \sqrt{t}$), parameter sensitivity
($\partial d^*/\partial \nu$), and diagnostic tests unavailable in traditional
difference-in-differences approaches.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [59] [Autonomous Reactive Masonry Construction using Collaborative Heterogeneous Aerial Robots with Experimental Demonstration](https://arxiv.org/abs/2510.15114)
*Marios-Nektarios Stamatopoulos,Elias Small,Shridhar Velhal,Avijit Banerjee,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 提出了一个完全自主的空中砌体建造框架，使用异构无人机进行砖块搬运和粘合剂应用，通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 开发自主空中机器人建造系统，解决传统建造方法的局限性，利用异构无人机协同工作实现高效的砌体建造。

Method: 使用两种专用无人机：带球接头机构的砖块搬运无人机和带伺服控制阀的粘合剂应用无人机；采用反应式任务规划、分层状态机和动态任务分配；砖块搬运无人机使用机载视觉系统实时估计砖块姿态。

Result: 实验验证了框架的有效性，成功实现了完全自主的空中砌体建造，一个无人机精确放置砖块，另一个自动应用粘合剂材料。

Conclusion: 该工作代表了首个使用异构无人机进行完全自主空中砌体建造的实验演示，为未来自主空中机器人建造系统的发展奠定了基础。

Abstract: This article presents a fully autonomous aerial masonry construction
framework using heterogeneous unmanned aerial vehicles (UAVs), supported by
experimental validation. Two specialized UAVs were developed for the task: (i)
a brick-carrier UAV equipped with a ball-joint actuation mechanism for precise
brick manipulation, and (ii) an adhesion UAV integrating a servo-controlled
valve and extruder nozzle for accurate adhesion application. The proposed
framework employs a reactive mission planning unit that combines a dependency
graph of the construction layout with a conflict graph to manage simultaneous
task execution, while hierarchical state machines ensure robust operation and
safe transitions during task execution. Dynamic task allocation allows
real-time adaptation to environmental feedback, while minimum-jerk trajectory
generation ensures smooth and precise UAV motion during brick pickup and
placement. Additionally, the brick-carrier UAV employs an onboard vision system
that estimates brick poses in real time using ArUco markers and a least-squares
optimization filter, enabling accurate alignment during construction. To the
best of the authors' knowledge, this work represents the first experimental
demonstration of fully autonomous aerial masonry construction using
heterogeneous UAVs, where one UAV precisely places the bricks while another
autonomously applies adhesion material between them. The experimental results
supported by the video showcase the effectiveness of the proposed framework and
demonstrate its potential to serve as a foundation for future developments in
autonomous aerial robotic construction.

</details>


### [60] [RM-RL: Role-Model Reinforcement Learning for Precise Robot Manipulation](https://arxiv.org/abs/2510.15189)
*Xiangyu Chen,Chuhao Zhou,Yuxi Liu,Jianfei Yang*

Main category: cs.RO

TL;DR: 提出了角色模型强化学习(RM-RL)框架，通过自动生成近似最优动作标签来替代人工演示，统一了在线和离线训练，解决了精密机器人操作中的分布偏移和数据效率问题。


<details>
  <summary>Details</summary>
Motivation: 精密机器人操作任务中，传统方法依赖高质量人工演示，但获取困难且耗时；离线强化学习存在分布偏移和数据效率低的问题。

Method: 采用角色模型策略自动为在线训练数据生成标签，将策略学习重新表述为监督训练，结合混合训练方案重复利用在线数据。

Result: 相比现有RL方法，RM-RL收敛更快更稳定，在真实世界操作中实现53%的平移精度提升和20%的旋转精度提升，成功完成细胞板精确放置任务。

Conclusion: RM-RL框架有效解决了精密操作任务中的演示获取困难和数据效率问题，在真实世界应用中表现出色，为精细操作任务提供了可行的解决方案。

Abstract: Precise robot manipulation is critical for fine-grained applications such as
chemical and biological experiments, where even small errors (e.g., reagent
spillage) can invalidate an entire task. Existing approaches often rely on
pre-collected expert demonstrations and train policies via imitation learning
(IL) or offline reinforcement learning (RL). However, obtaining high-quality
demonstrations for precision tasks is difficult and time-consuming, while
offline RL commonly suffers from distribution shifts and low data efficiency.
We introduce a Role-Model Reinforcement Learning (RM-RL) framework that unifies
online and offline training in real-world environments. The key idea is a
role-model strategy that automatically generates labels for online training
data using approximately optimal actions, eliminating the need for human
demonstrations. RM-RL reformulates policy learning as supervised training,
reducing instability from distribution mismatch and improving efficiency. A
hybrid training scheme further leverages online role-model data for offline
reuse, enhancing data efficiency through repeated sampling. Extensive
experiments show that RM-RL converges faster and more stably than existing RL
methods, yielding significant gains in real-world manipulation: 53% improvement
in translation accuracy and 20% in rotation accuracy. Finally, we demonstrate
the successful execution of a challenging task, precisely placing a cell plate
onto a shelf, highlighting the framework's effectiveness where prior methods
fail.

</details>


### [61] [Lagrange-Poincaré-Kepler Equations of Disturbed Space-Manipulator Systems in Orbit](https://arxiv.org/abs/2510.15199)
*Borna Monazzah Moghaddam,Robin Chhabra*

Main category: cs.RO

TL;DR: 本文提出了拉格朗日-庞加莱-开普勒方程(LPKE)，将拉格朗日-庞加莱方程扩展到非惯性轨道参考系中的航天器-机械臂系统动力学建模。


<details>
  <summary>Details</summary>
Motivation: 现有拉格朗日-庞加莱方程主要针对车辆-机械臂系统，需要扩展到考虑航天器姿态动力学、轨道运动和机械臂运动耦合的轨道环境。

Method: 结合欧拉-庞加莱方程(航天器基座)、开普勒轨道动力学(参考系)和简化欧拉-拉格朗日方程(机械臂形状空间)，使用指数关节参数化，基于主丛上的拉格朗日-达朗贝尔原理推导结构矩阵。

Result: 推导出显式捕获轨道扰动效应及其与机械臂系统动态耦合的封闭形式结构矩阵，能够系统包含外部施加的对称破缺力。

Conclusion: LPKE框架在轨道环境下具有数值优越性，可直接集成到硬件在环仿真和基于模型的控制架构中，适用于自主机器人操作。

Abstract: This article presents an extension of the Lagrange-Poincare Equations (LPE)
to model the dynamics of spacecraft-manipulator systems operating within a
non-inertial orbital reference frame. Building upon prior formulations of LPE
for vehicle-manipulator systems, the proposed framework, termed the
Lagrange-Poincare-Kepler Equations (LPKE), incorporates the coupling between
spacecraft attitude dynamics, orbital motion, and manipulator kinematics. The
formalism combines the Euler-Poincare equations for the base spacecraft,
Keplerian orbital dynamics for the reference frame, and reduced Euler-Lagrange
equations for the manipulator's shape space, using an exponential joint
parametrization. Leveraging the Lagrange-d'Alembert principle on principal
bundles, we derive novel closed-form structural matrices that explicitly
capture the effects of orbital disturbances and their dynamic coupling with the
manipulator system. The LPKE framework also systematically includes externally
applied, symmetry-breaking wrenches, allowing for immediate integration into
hardware-in-the-loop simulations and model-based control architectures for
autonomous robotic operations in the orbital environment. To illustrate the
effectiveness of the proposed model and its numerical superiority, we present a
simulation study analyzing orbital effects on a 7-degree-of-freedom manipulator
mounted on a spacecraft.

</details>


### [62] [LVI-Q: Robust LiDAR-Visual-Inertial-Kinematic Odometry for Quadruped Robots Using Tightly-Coupled and Efficient Alternating Optimization](https://arxiv.org/abs/2510.15220)
*Kevin Christiansen Marsim,Minho Oh,Byeongho Yu,Seungjae Lee,I Made Aswin Nahrendra,Hyungtae Lim,Hyun Myung*

Main category: cs.RO

TL;DR: 提出了一种鲁棒的LiDAR-视觉-惯性-运动学里程计系统，通过多传感器融合在复杂动态环境中实现自主导航。


<details>
  <summary>Details</summary>
Motivation: 解决传统传感器融合SLAM方法在挑战性环境中由于不合适的融合策略导致的估计漂移问题。

Method: 使用基于优化的视觉-惯性-运动学里程计(VIKO)和基于滤波的LiDAR-惯性-运动学里程计(LIKO)的融合姿态估计方法，结合足部预积分和LiDAR-视觉深度一致性。

Result: 与其它传感器融合SLAM算法相比，在公开和长期数据集上表现出鲁棒性能。

Conclusion: 该多传感器融合系统能够为足式机器人在复杂动态环境中提供可靠的定位和建图能力。

Abstract: Autonomous navigation for legged robots in complex and dynamic environments
relies on robust simultaneous localization and mapping (SLAM) systems to
accurately map surroundings and localize the robot, ensuring safe and efficient
operation. While prior sensor fusion-based SLAM approaches have integrated
various sensor modalities to improve their robustness, these algorithms are
still susceptible to estimation drift in challenging environments due to their
reliance on unsuitable fusion strategies. Therefore, we propose a robust
LiDAR-visual-inertial-kinematic odometry system that integrates information
from multiple sensors, such as a camera, LiDAR, inertial measurement unit
(IMU), and joint encoders, for visual and LiDAR-based odometry estimation. Our
system employs a fusion-based pose estimation approach that runs
optimization-based visual-inertial-kinematic odometry (VIKO) and filter-based
LiDAR-inertial-kinematic odometry (LIKO) based on measurement availability. In
VIKO, we utilize the footpreintegration technique and robust LiDAR-visual depth
consistency using superpixel clusters in a sliding window optimization. In
LIKO, we incorporate foot kinematics and employ a point-toplane residual in an
error-state iterative Kalman filter (ESIKF). Compared with other sensor
fusion-based SLAM algorithms, our approach shows robust performance across
public and longterm datasets.

</details>


### [63] [PolyFly: Polytopic Optimal Planning for Collision-Free Cable-Suspended Aerial Payload Transportation](https://arxiv.org/abs/2510.15226)
*Mrunal Sarvaiya,Guanrui Li,Giuseppe Loianno*

Main category: cs.RO

TL;DR: PolyFly是一种用于空中运输机器人的全局规划器，通过将机器人组件和环境建模为独立多面体，消除了现有方法的保守性限制，实现了更快的轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 现有方法对车辆和障碍物进行几何过度近似，导致保守的机动和增加的飞行时间，需要消除这些限制以实现更激进的飞行。

Method: 将环境中的每个物理组件和机器人（四旋翼、电缆和负载）建模为独立多面体，构建方向感知多面体提高模型精度，通过对偶理论将多面体约束转换为平滑可微约束来求解最优控制问题。

Result: 在八个迷宫式环境中与现有最先进方法相比，PolyFly在每个场景中都产生了更快的轨迹，并在真实四旋翼上进行了实验验证。

Conclusion: PolyFly方法在实际应用中表现出可靠性和准确性，能够为空中运输机器人提供更高效的轨迹规划。

Abstract: Aerial transportation robots using suspended cables have emerged as versatile
platforms for disaster response and rescue operations. To maximize the
capabilities of these systems, robots need to aggressively fly through tightly
constrained environments, such as dense forests and structurally unsafe
buildings, while minimizing flight time and avoiding obstacles. Existing
methods geometrically over-approximate the vehicle and obstacles, leading to
conservative maneuvers and increased flight times. We eliminate these
restrictions by proposing PolyFly, an optimal global planner which considers a
non-conservative representation for aerial transportation by modeling each
physical component of the environment, and the robot (quadrotor, cable and
payload), as independent polytopes. We further increase the model accuracy by
incorporating the attitude of the physical components by constructing
orientation-aware polytopes. The resulting optimal control problem is
efficiently solved by converting the polytope constraints into smooth
differentiable constraints via duality theory. We compare our method against
the existing state-of-the-art approach in eight maze-like environments and show
that PolyFly produces faster trajectories in each scenario. We also
experimentally validate our proposed approach on a real quadrotor with a
suspended payload, demonstrating the practical reliability and accuracy of our
method.

</details>


### [64] [A Generalized Sylvester-Fermat-Torricelli problem with application in disaster relief operations by UAVs](https://arxiv.org/abs/2510.15229)
*Sina Kazemdehbashi,Yanchao Liu,Boris S. Mordukhovich*

Main category: cs.RO

TL;DR: 提出了一种考虑风力和无人机异构性的数学框架，用于优化移动无人机基站的位置，可将操作时间浪费减少高达84%。


<details>
  <summary>Details</summary>
Motivation: 自然灾害中通信基础设施常被破坏，无人机可帮助收集数据和建立临时通信网络，但风力等恶劣天气条件对无人机部署构成重大挑战。

Method: 将Sylvester问题推广为Sylvester-Fermat-Torricelli问题，在一个统一框架中捕捉风力影响、无人机异构性和往返运动等复杂因素。

Result: 实验结果表明，该框架可将操作时间浪费减少高达84%，使灾后任务更加高效有效。

Conclusion: 所提出的框架通过考虑风力和无人机异构性等现实因素，提高了基于无人机的灾害响应规划的实用性。

Abstract: Natural and human-made disasters can cause severe devastation and claim
thousands of lives worldwide. Therefore, developing efficient methods for
disaster response and management is a critical task for relief teams. One of
the most essential components of effective response is the rapid collection of
information about affected areas, damages, and victims. More data translates
into better coordination, faster rescue operations, and ultimately, more lives
saved. However, in some disasters, such as earthquakes, the communication
infrastructure is often partially or completely destroyed, making it extremely
difficult for victims to send distress signals and for rescue teams to locate
and assist them in time. Unmanned Aerial Vehicles (UAVs) have emerged as
valuable tools in such scenarios. In particular, a fleet of UAVs can be
dispatched from a mobile station to the affected area to facilitate data
collection and establish temporary communication networks. Nevertheless,
real-world deployment of UAVs faces several challenges, with adverse weather
conditions--especially wind--being among the most significant. To address this,
we develop a novel mathematical framework to determine the optimal location of
a mobile UAV station while explicitly accounting for the heterogeneity of the
UAVs and the effect of wind. In particular, we generalize the Sylvester problem
to introduce the Sylvester-Fermat-Torricelli (SFT) problem, which captures
complex factors such as wind influence, UAV heterogeneity, and back-and-forth
motion within a unified framework. The proposed framework enhances the
practicality of UAV-based disaster response planning by accounting for
real-world factors such as wind and UAV heterogeneity. Experimental results
demonstrate that it can reduce wasted operational time by up to 84%, making
post-disaster missions significantly more efficient and effective.

</details>


### [65] [Traversability-aware Consistent Situational Graphs for Indoor Localization and Mapping](https://arxiv.org/abs/2510.15319)
*Jeewon Kim,Minho Oh,Hyun Myung*

Main category: cs.RO

TL;DR: 提出了一种基于可通行性的房间分割方法，通过考虑机器人与环境的交互来改进场景图的分层结构，提升姿态图优化的语义一致性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有实时方法在分割空间特征时，由于视角变化和传感器视野限制，难以一致识别房间。现有方法要么过度分割大房间为无用小空间，要么在复杂情况下分割不足，导致姿态图优化中出现错误约束。

Method: 提出可通行性感知的房间分割方法，考虑机器人与周围环境的交互，保持可通行性信息的一致性可行性。

Result: 通过在重复遍历相同路径的数据集上评估，改进方法提高了相同房间的重新检测频率，同时减少了优化时间消耗。

Conclusion: 该方法增强了姿态图优化的语义一致性和计算效率，在机器人定位和建图中表现出更好的性能。

Abstract: Scene graphs enhance 3D mapping capabilities in robotics by understanding the
relationships between different spatial elements, such as rooms and objects.
Recent research extends scene graphs to hierarchical layers, adding and
leveraging constraints across these levels. This approach is tightly integrated
with pose-graph optimization, improving both localization and mapping accuracy
simultaneously. However, when segmenting spatial characteristics, consistently
recognizing rooms becomes challenging due to variations in viewpoints and
limited field of view (FOV) of sensors. For example, existing real-time
approaches often over-segment large rooms into smaller, non-functional spaces
that are not useful for localization and mapping due to the time-dependent
method. Conversely, their voxel-based room segmentation method often
under-segment in complex cases like not fully enclosed 3D space that are
non-traversable for ground robots or humans, leading to false constraints in
pose-graph optimization. We propose a traversability-aware room segmentation
method that considers the interaction between robots and surroundings, with
consistent feasibility of traversability information. This enhances both the
semantic coherence and computational efficiency of pose-graph optimization.
Improved performance is demonstrated through the re-detection frequency of the
same rooms in a dataset involving repeated traversals of the same space along
the same path, as well as the optimization time consumption.

</details>


### [66] [ASBI: Leveraging Informative Real-World Data for Active Black-Box Simulator Tuning](https://arxiv.org/abs/2510.15331)
*Gahee Kim,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: 提出主动仿真推理框架，通过机器人主动收集数据来优化黑盒仿真器参数估计，解决了传统方法中观测信息不足的问题。


<details>
  <summary>Details</summary>
Motivation: 黑盒仿真器在机器人领域广泛应用，但由于无法获取似然函数，参数优化困难。传统仿真推理方法依赖离线观测，难以准备包含足够参数信息的观测数据。

Method: 使用主动仿真推理框架，通过最大化信息增益来优化机器人动作，收集信息丰富的观测数据。利用神经后验估计学习后验估计器，解决黑盒仿真器中似然函数不可访问的问题。

Result: 三个仿真实验验证了方法能实现准确的参数估计，后验分布集中在真实参数周围。真实机器人实验成功估计了立方颗粒的仿真参数。

Conclusion: 主动仿真推理框架能有效解决黑盒仿真器参数估计问题，通过主动数据收集提高估计精度，在真实机器人应用中具有实用价值。

Abstract: Black-box simulators are widely used in robotics, but optimizing their
parameters remains challenging due to inaccessible likelihoods.
Simulation-Based Inference (SBI) tackles this issue using simulation-driven
approaches, estimating the posterior from offline real observations and forward
simulations. However, in black-box scenarios, preparing observations that
contain sufficient information for parameter estimation is difficult due to the
unknown relationship between parameters and observations. In this work, we
present Active Simulation-Based Inference (ASBI), a parameter estimation
framework that uses robots to actively collect real-world online data to
achieve accurate black-box simulator tuning. Our framework optimizes robot
actions to collect informative observations by maximizing information gain,
which is defined as the expected reduction in Shannon entropy between the
posterior and the prior. While calculating information gain requires the
likelihood, which is inaccessible in black-box simulators, our method solves
this problem by leveraging Neural Posterior Estimation (NPE), which leverages a
neural network to learn the posterior estimator. Three simulation experiments
quantitatively verify that our method achieves accurate parameter estimation,
with posteriors sharply concentrated around the true parameters. Moreover, we
show a practical application using a real robot to estimate the simulation
parameters of cubic particles corresponding to two real objects, beads and
gravel, with a bucket pouring action.

</details>


### [67] [Adaptive Cost-Map-based Path Planning in Partially Unknown Environments with Movable Obstacles](https://arxiv.org/abs/2510.15336)
*Liviu-Mihai Stan,Ranulfo Bezerra,Shotaro Kojima,Tsige Tadesse Alemayoh,Satoshi Tadokoro,Masashi Konyo,Kazunori Ohno*

Main category: cs.RO

TL;DR: 提出了一种自适应LiDAR和里程计路径规划框架，能够在ROS2 Nav2堆栈中识别和推开可移动障碍物，提高在非结构化环境中的导航成功率。


<details>
  <summary>Details</summary>
Motivation: 在灾难响应和非结构化室内环境中，机器人不仅需要避开障碍物，还需要识别哪些障碍物可以被推开，以提高导航效率和成功率。

Method: 使用新的可移动障碍物层标记LiDAR扫描中静态地图缺失的物体为可移动障碍物，并分配较低的穿越成本。配合慢速姿态进度检查器监控速度比，在机器人减速时提高局部成本，促使全局规划器重新规划路径。

Result: 在Gazebo中对Scout Mini机器人的评估显示，相比无层基线，该方法具有更高的目标到达率和更少的死锁，穿越时间大致相当。

Conclusion: 交互感知成本地图是一种轻量级的ROS2原生扩展，适用于在非结构化环境中导航可移动障碍物，特别适合资源受限的搜救机器人。

Abstract: Reliable navigation in disaster-response and other unstructured indoor
settings requires robots not only to avoid obstacles but also to recognise when
those obstacles can be pushed aside. We present an adaptive, LiDAR and
odometry-based path-planning framework that embeds this capability into the
ROS2 Nav2 stack. A new Movable Obstacles Layer labels all LiDAR returns missing
from a prior static map as tentatively movable and assigns a reduced traversal
cost. A companion Slow-Pose Progress Checker monitors the ratio of commanded to
actual velocity; when the robot slows appreciably, the local cost is raised
from light to heavy, and on a stall to lethal, prompting the global planner to
back out and re-route. Gazebo evaluations on a Scout Mini, spanning isolated
objects and cluttered corridors, show higher goal-reach rates and fewer
deadlocks than a no-layer baseline, with traversal times broadly comparable.
Because the method relies only on planar scans and CPU-level computation, it
suits resource-constrained search and rescue robots and integrates into
heterogeneous platforms with minimal engineering. Overall, the results indicate
that interaction-aware cost maps are a lightweight, ROS2-native extension for
navigating among potentially movable obstacles in unstructured settings. The
full implementation will be released as open source
athttps://costmap-namo.github.io.

</details>


### [68] [Nauplius Optimisation for Autonomous Hydrodynamics](https://arxiv.org/abs/2510.15350)
*Shyalan Ramesh,Scott Mann,Alex Stumpf*

Main category: cs.RO

TL;DR: NOAH是一种受藤壶幼体行为启发的群体优化算法，专为自主水下航行器设计，结合了水流感知漂移、不可逆沉降和群体通信机制，解决了传统群体算法在水下环境中的可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 自主水下航行器在强水流、有限声学带宽和持续感知需求的环境中运行，传统群体优化方法不可靠，需要开发能够应对水下特殊挑战的新算法。

Method: 受藤壶幼体行为启发，NOAH算法结合了水流感知漂移、在持续感知节点中的不可逆沉降机制以及基于群体的通信能力。

Result: 验证研究显示，在永久锚定场景中达到86%的成功率，为水动力约束和不可逆沉降行为提供了统一公式，并在水流条件下进行了实证研究。

Conclusion: NOAH算法为可扩展且节能的水下群体机器人技术建立了全面基础，具有经过验证的性能分析。

Abstract: Autonomous Underwater vehicles must operate in strong currents, limited
acoustic bandwidth, and persistent sensing requirements where conventional
swarm optimisation methods are unreliable. This paper presents NOAH, a novel
nature-inspired swarm optimisation algorithm that combines current-aware drift,
irreversible settlement in persistent sensing nodes, and colony-based
communication. Drawing inspiration from the behaviour of barnacle nauplii, NOAH
addresses the critical limitations of existing swarm algorithms by providing
hydrodynamic awareness, irreversible anchoring mechanisms, and colony-based
communication capabilities essential for underwater exploration missions. The
algorithm establishes a comprehensive foundation for scalable and
energy-efficient underwater swarm robotics with validated performance analysis.
Validation studies demonstrate an 86% success rate for permanent anchoring
scenarios, providing a unified formulation for hydrodynamic constraints and
irreversible settlement behaviours with an empirical study under flow.

</details>


### [69] [GaussGym: An open-source real-to-sim framework for learning locomotion from pixels](https://arxiv.org/abs/2510.15352)
*Alejandro Escontrela,Justin Kerr,Arthur Allshire,Jonas Frey,Rocky Duan,Carmelo Sferrazza,Pieter Abbeel*

Main category: cs.RO

TL;DR: 提出了一种将3D高斯泼溅作为渲染器集成到矢量化物理模拟器中的新方法，实现了超过10万步/秒的高速仿真，同时保持高视觉保真度，并展示了在模拟到真实机器人应用中的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人仿真中高吞吐量和高保真度感知之间的平衡问题，需要一种既能快速运行又能提供丰富视觉语义的仿真方法。

Method: 将3D高斯泼溅作为渲染器集成到矢量化物理模拟器（如IsaacGym）中，支持从iPhone扫描、大规模场景数据集和生成视频模型快速创建逼真训练环境。

Result: 在消费级GPU上实现了超过10万步/秒的仿真速度，同时保持了高视觉保真度，展示了在导航和决策任务中视觉语义的重要性。

Conclusion: 这项工作连接了高吞吐量仿真和高保真度感知，推动了可扩展和通用机器人学习的发展，所有代码和数据将开源供社区使用。

Abstract: We present a novel approach for photorealistic robot simulation that
integrates 3D Gaussian Splatting as a drop-in renderer within vectorized
physics simulators such as IsaacGym. This enables unprecedented speed --
exceeding 100,000 steps per second on consumer GPUs -- while maintaining high
visual fidelity, which we showcase across diverse tasks. We additionally
demonstrate its applicability in a sim-to-real robotics setting. Beyond
depth-based sensing, our results highlight how rich visual semantics improve
navigation and decision-making, such as avoiding undesirable regions. We
further showcase the ease of incorporating thousands of environments from
iPhone scans, large-scale scene datasets (e.g., GrandTour, ARKit), and outputs
from generative video models like Veo, enabling rapid creation of realistic
training worlds. This work bridges high-throughput simulation and high-fidelity
perception, advancing scalable and generalizable robot learning. All code and
data will be open-sourced for the community to build upon. Videos, code, and
data available at https://escontrela.me/gauss_gym/.

</details>


### [70] [Towards Automated Chicken Deboning via Learning-based Dynamically-Adaptive 6-DoF Multi-Material Cutting](https://arxiv.org/abs/2510.15376)
*Zhaodong Yang,Ai-Ping Hu,Harish Ravichandar*

Main category: cs.RO

TL;DR: 该论文开发了一个自动化鸡肩去骨系统，通过力反馈强化学习策略实现6自由度刀片控制，在模拟器和物理测试平台上训练后能够零样本迁移到真实鸡肩去骨任务中。


<details>
  <summary>Details</summary>
Motivation: 自动化鸡肩去骨需要精确控制刀片穿过部分遮挡、可变形、多材料的关节，避免接触骨骼带来的健康和安全风险。现有方法难以处理这种复杂的多材料切割任务。

Method: 1) 开发开源多材料切割模拟器；2) 设计可重复使用的物理测试平台模拟鸡肩结构；3) 训练残差强化学习策略，使用离散化力观测和领域随机化，实现从模拟到现实的零样本迁移。

Result: 学习策略能可靠导航关节间隙，减少不必要的骨/软骨接触，相比现有开环切割基线在成功率和避骨方面提升高达4倍。

Conclusion: 力反馈对于安全有效的多材料切割至关重要，该方法首次展示了学习策略在真实鸡肩去骨任务中的成功应用。

Abstract: Automating chicken shoulder deboning requires precise 6-DoF cutting through a
partially occluded, deformable, multi-material joint, since contact with the
bones presents serious health and safety risks. Our work makes both
systems-level and algorithmic contributions to train and deploy a reactive
force-feedback cutting policy that dynamically adapts a nominal trajectory and
enables full 6-DoF knife control to traverse the narrow joint gap while
avoiding contact with the bones. First, we introduce an open-source
custom-built simulator for multi-material cutting that models coupling,
fracture, and cutting forces, and supports reinforcement learning, enabling
efficient training and rapid prototyping. Second, we design a reusable physical
testbed to emulate the chicken shoulder: two rigid "bone" spheres with
controllable pose embedded in a softer block, enabling rigorous and repeatable
evaluation while preserving essential multi-material characteristics of the
target problem. Third, we train and deploy a residual RL policy, with
discretized force observations and domain randomization, enabling robust
zero-shot sim-to-real transfer and the first demonstration of a learned policy
that debones a real chicken shoulder. Our experiments in our simulator, on our
physical testbed, and on real chicken shoulders show that our learned policy
reliably navigates the joint gap and reduces undesired bone/cartilage contact,
resulting in up to a 4x improvement over existing open-loop cutting baselines
in terms of success rate and bone avoidance. Our results also illustrate the
necessity of force feedback for safe and effective multi-material cutting. The
project website is at https://sites.google.com/view/chickendeboning-2026.

</details>


### [71] [VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving](https://arxiv.org/abs/2510.15446)
*Ziang Guo,Zufeng Zhang*

Main category: cs.RO

TL;DR: VDRive是一个用于端到端自动驾驶的新框架，通过显式建模状态-动作映射来解决动态环境和极端情况下的鲁棒性问题，结合视觉语言动作模型和扩散策略实现可解释的决策。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中动态环境和极端情况对车辆状态理解和决策的鲁棒性构成重大挑战，需要能够处理这些复杂场景的解决方案。

Method: 结合视觉语言动作模型的状态理解和生成扩散策略的动作头，通过上下文预测和几何强化学习微调，构建演员-评论家框架进行策略学习。

Result: 在Bench2Drive闭环基准测试和nuScenes开环规划中达到最先进性能。

Conclusion: VDRive通过显式状态-动作建模和分层动作生成，实现了可解释且鲁棒的自动驾驶决策系统。

Abstract: In autonomous driving, dynamic environment and corner cases pose significant
challenges to the robustness of ego vehicle's state understanding and decision
making. We introduce VDRive, a novel pipeline for end-to-end autonomous driving
that explicitly models state-action mapping to address these challenges,
enabling interpretable and robust decision making. By leveraging the
advancement of the state understanding of the Vision Language Action Model
(VLA) with generative diffusion policy-based action head, our VDRive guides the
driving contextually and geometrically. Contextually, VLA predicts future
observations through token generation pre-training, where the observations are
represented as discrete codes by a Conditional Vector Quantized Variational
Autoencoder (CVQ-VAE). Geometrically, we perform reinforcement learning
fine-tuning of the VLA to predict future trajectories and actions based on
current driving conditions. VLA supplies the current state tokens and predicted
state tokens for the action policy head to generate hierarchical actions and
trajectories. During policy training, a learned critic evaluates the actions
generated by the policy and provides gradient-based feedback, forming an
actor-critic framework that enables a reinforcement-based policy learning
pipeline. Experiments show that our VDRive achieves state-of-the-art
performance in the Bench2Drive closed-loop benchmark and nuScenes open-loop
planning.

</details>


### [72] [Perfect Prediction or Plenty of Proposals? What Matters Most in Planning for Autonomous Driving](https://arxiv.org/abs/2510.15505)
*Aron Distelzweig,Faris Janjoš,Oliver Scheel,Sirish Reddy Varra,Raghu Rajan,Joschka Boedecker*

Main category: cs.RO

TL;DR: 研究发现当前集成预测与规划(IPP)方法未能充分利用预测信息，即使有完美预测也无法改善规划结果。作者提出以高质量提案生成为核心的方法，在高度交互场景中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统自动驾驶将预测和规划作为独立模块处理，虽然近期出现了集成预测与规划(IPP)方法，但尚不清楚这种集成是否真正改善了规划性能。

Method: 基于PDM（简单车道跟随方法）构建增强的提案生成方法，重点生成多样但现实且高质量的提案，主要使用预测进行碰撞检查。

Result: 提案中心方法在分布外和高度交互场景中显著优于现有方法，创造了新的最先进结果。许多基于模仿学习的规划器在生成现实提案方面表现不佳，甚至不如简单的车道跟随方法。

Conclusion: 当前IPP方法未能充分利用预测信息，规划性能的提升关键在于高质量提案生成而非预测集成。提案中心方法在复杂交互场景中表现优异。

Abstract: Traditionally, prediction and planning in autonomous driving (AD) have been
treated as separate, sequential modules. Recently, there has been a growing
shift towards tighter integration of these components, known as Integrated
Prediction and Planning (IPP), with the aim of enabling more informed and
adaptive decision-making. However, it remains unclear to what extent this
integration actually improves planning performance. In this work, we
investigate the role of prediction in IPP approaches, drawing on the widely
adopted Val14 benchmark, which encompasses more common driving scenarios with
relatively low interaction complexity, and the interPlan benchmark, which
includes highly interactive and out-of-distribution driving situations. Our
analysis reveals that even access to perfect future predictions does not lead
to better planning outcomes, indicating that current IPP methods often fail to
fully exploit future behavior information. Instead, we focus on high-quality
proposal generation, while using predictions primarily for collision checks. We
find that many imitation learning-based planners struggle to generate realistic
and plausible proposals, performing worse than PDM - a simple lane-following
approach. Motivated by this observation, we build on PDM with an enhanced
proposal generation method, shifting the emphasis towards producing diverse but
realistic and high-quality proposals. This proposal-centric approach
significantly outperforms existing methods, especially in out-of-distribution
and highly interactive settings, where it sets new state-of-the-art results.

</details>


### [73] [VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation](https://arxiv.org/abs/2510.15530)
*Zehao Ni,Yonghao He,Lingfeng Qian,Jilei Mao,Fa Fu,Wei Sui,Hu Su,Junran Peng,Zhipeng Wang,Bin He*

Main category: cs.RO

TL;DR: 提出了一种仅使用视觉输入的单视图扩散策略学习方法VO-DP，通过预训练视觉基础模型融合语义和几何特征，在仿真和真实世界任务中均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法大多依赖点云作为观测输入，缺乏对仅视觉解决方案的深入探索，而仅视觉方法具有显著潜力。

Method: 利用VGGT中间特征、DINOv2语义特征和交替注意力块的几何特征，通过交叉注意力融合特征，并使用CNN进行空间压缩后输入策略头。

Result: 在仿真任务中平均成功率64.6%（与DP3的64.0%相当，远高于DP的34.8%），在真实世界任务中达到87.9%（优于DP3的67.5%和DP的11.2%）。

Conclusion: VO-DP方法在仅视觉输入下实现了与点云方法相当甚至更好的性能，并展示了出色的鲁棒性，同时开源了支持多机多GPU的训练库。

Abstract: In the context of imitation learning, visuomotor-based diffusion policy
learning is one of the main directions in robotic manipulation. Most of these
approaches rely on point clouds as observation inputs and construct scene
representations through point clouds feature learning, which enables them to
achieve remarkable accuracy. However, the existing literature lacks an in-depth
exploration of vision-only solutions that have significant potential. In this
paper, we propose a Vision-Only and single-view Diffusion Policy learning
method (VO-DP) that leverages pretrained visual foundation models to achieve
effective fusion of semantic and geometric features. We utilize intermediate
features from VGGT incorporating semantic features from DINOv2 and geometric
features from Alternating Attention blocks. Features are fused via
cross-attention and spatially compressed with a CNN to form the input to the
policy head. Extensive experiments demonstrate that VO-DP not only outperforms
the vision-only baseline DP significantly but also exhibits distinct
performance trends against the point cloud-based method DP3: in simulation
tasks, VO-DP achieves an average success rate of 64.6% on par with DP3 64.0%
and far higher than DP 34.8%, while in real-world tasks, it reaches 87.9%,
outperforming both DP3 67.5% and DP 11.2% by a notable margin. Further
robustness evaluations confirm that VO-DP remains highly stable under varying
conditions including color, size, background, and lighting. Lastly, we
open-source a training library for robotic manipulation. Built on Accelerate,
this library supports multi-machine and multi-GPU parallel training, as well as
mixed precision training. It is compatible with visuomotor policies such as DP,
DP3 and VO-DP, and also supports the RoboTwin simulator.

</details>


### [74] [Improved Extended Kalman Filter-Based Disturbance Observers for Exoskeletons](https://arxiv.org/abs/2510.15533)
*Shilei Li,Dawei Shi,Makoto Iwasaki,Yan Ning,Hongpeng Zhou,Ling Shi*

Main category: cs.RO

TL;DR: 该论文提出了两种基于扩展卡尔曼滤波的扰动观测器新方法，用于提高机械系统的跟踪精度，在外骨骼实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 机械系统的标称性能常因未知扰动而下降，传统的二自由度控制结构无法在扰动动态未知时实现完美扰动抑制，因此需要改进扰动估计方法。

Method: 提出了两种新方法：基于交互多模型扩展卡尔曼滤波的扰动观测器和基于多核相关熵扩展卡尔曼滤波的扰动观测器。

Result: 在外骨骼实验中，与基于扩展卡尔曼滤波的扰动观测器相比，所提方法在髋关节误差上分别提高了36.3%和16.2%，在膝关节误差上分别提高了46.3%和24.4%。

Conclusion: 所提出的两种方法在时变交互力场景下显著提高了跟踪精度，证明了其优越性。

Abstract: The nominal performance of mechanical systems is often degraded by unknown
disturbances. A two-degree-of-freedom control structure can decouple nominal
performance from disturbance rejection. However, perfect disturbance rejection
is unattainable when the disturbance dynamic is unknown. In this work, we
reveal an inherent trade-off in disturbance estimation subject to tracking
speed and tracking uncertainty. Then, we propose two novel methods to enhance
disturbance estimation: an interacting multiple model extended Kalman
filter-based disturbance observer and a multi-kernel correntropy extended
Kalman filter-based disturbance observer. Experiments on an exoskeleton verify
that the proposed two methods improve the tracking accuracy $36.3\%$ and
$16.2\%$ in hip joint error, and $46.3\%$ and $24.4\%$ in knee joint error,
respectively, compared to the extended Kalman filter-based disturbance
observer, in a time-varying interaction force scenario, demonstrating the
superiority of the proposed method.

</details>


### [75] [Adaptive Legged Locomotion via Online Learning for Model Predictive Control](https://arxiv.org/abs/2510.15626)
*Hongyu Zhou,Xiaoyu Zhang,Vasileios Tzoumas*

Main category: cs.RO

TL;DR: 提出了一种通过在线学习和模型预测控制实现自适应腿式运动的算法，包含MPC和残差动力学在线学习两个模块，能够处理建模误差和外部干扰。


<details>
  <summary>Details</summary>
Motivation: 解决四足机器人在未知不确定性（如未知负载和不平坦地形）下自主执行复杂任务的挑战。

Method: 使用随机傅里叶特征在再生核希尔伯特空间中近似残差动力学，基于当前学习模型进行MPC控制，并通过最小二乘法在线自监督更新模型。

Result: 在Gazebo和MuJoCo仿真中验证了算法有效性，能够处理高达12倍重力的外部力、20度斜坡、0.25米高度变化的地形，以及8kg负载和时变地面摩擦系数。

Conclusion: 该算法具有次线性动态遗憾性能，相比知道残差动力学的最优预知控制器具有较小的次优性。

Abstract: We provide an algorithm for adaptive legged locomotion via online learning
and model predictive control. The algorithm is composed of two interacting
modules: model predictive control (MPC) and online learning of residual
dynamics. The residual dynamics can represent modeling errors and external
disturbances. We are motivated by the future of autonomy where quadrupeds will
autonomously perform complex tasks despite real-world unknown uncertainty, such
as unknown payload and uneven terrains. The algorithm uses random Fourier
features to approximate the residual dynamics in reproducing kernel Hilbert
spaces. Then, it employs MPC based on the current learned model of the residual
dynamics. The model is updated online in a self-supervised manner using least
squares based on the data collected while controlling the quadruped. The
algorithm enjoys sublinear \textit{dynamic regret}, defined as the
suboptimality against an optimal clairvoyant controller that knows how the
residual dynamics. We validate our algorithm in Gazebo and MuJoCo simulations,
where the quadruped aims to track reference trajectories. The Gazebo
simulations include constant unknown external forces up to $12\boldsymbol{g}$,
where $\boldsymbol{g}$ is the gravity vector, in flat terrain, slope terrain
with $20\degree$ inclination, and rough terrain with $0.25m$ height variation.
The MuJoCo simulations include time-varying unknown disturbances with payload
up to $8~kg$ and time-varying ground friction coefficients in flat terrain.

</details>


### [76] [Educational SoftHand-A: Building an Anthropomorphic Hand with Soft Synergies using LEGO MINDSTORMS](https://arxiv.org/abs/2510.15638)
*Jared K. Lepora,Haoran Li,Efi Psomopoulou,Nathan F. Lepora*

Main category: cs.RO

TL;DR: 使用乐高MINDSTORMS构建的教育型仿人机器人手，采用肌腱驱动和高度欠驱动设计，基于Pisa/IIT SoftHand技术，适合教育环境。


<details>
  <summary>Details</summary>
Motivation: 开发适合教育环境的机器人手，仅使用标准乐高零件和家用设备，让儿童能够接触和学习现代机器人技术的前沿概念。

Method: 采用肌腱驱动设计，每个手指使用双电机驱动拮抗肌腱对，通过离合器齿轮的差动机构实现软协同运动。

Result: 设计出能够自适应抓取各种物体的仿人机器人手，具有反应性精细控制能力，仅使用简单的驱动和控制机制。

Conclusion: 该乐高机器人手结合了先进机器人手设计概念，具有教育和启发儿童学习现代机器人技术的潜力。

Abstract: This paper introduces an anthropomorphic robot hand built entirely using LEGO
MINDSTORMS: the Educational SoftHand-A, a tendon-driven, highly-underactuated
robot hand based on the Pisa/IIT SoftHand and related hands. To be suitable for
an educational context, the design is constrained to use only standard LEGO
pieces with tests using common equipment available at home. The hand features
dual motors driving an agonist/antagonist opposing pair of tendons on each
finger, which are shown to result in reactive fine control. The finger motions
are synchonized through soft synergies, implemented with a differential
mechanism using clutch gears. Altogether, this design results in an
anthropomorphic hand that can adaptively grasp a broad range of objects using a
simple actuation and control mechanism. Since the hand can be constructed from
LEGO pieces and uses state-of-the-art design concepts for robotic hands, it has
the potential to educate and inspire children to learn about the frontiers of
modern robotics.

</details>


### [77] [Integration of a Variable Stiffness Link for Long-Reach Aerial Manipulation](https://arxiv.org/abs/2510.15639)
*Manuel J. Fernandez,Alejandro Suarez,Anibal Ollero,Matteo Fumagalli*

Main category: cs.RO

TL;DR: 该论文提出了一种可变刚度连杆(VSL)用于长距离空中操作，可以在柔性绳索和刚性杆之间切换，实现无人机与机械臂之间的可调节机械耦合。


<details>
  <summary>Details</summary>
Motivation: 传统长距离操作系统使用刚性或缆绳连接，限制了精度或会将干扰传递给飞行器，需要一种能够根据任务需求调整刚度的连接机制。

Method: 在配备LiCAS双机械臂的四旋翼无人机上集成可变刚度连杆，通过远程操作实验评估系统性能，包括外部干扰和包裹运输任务。

Result: 改变连杆刚度显著改变了无人机与负载之间的动态交互：柔性配置衰减外部冲击和空气动力学扰动，刚性配置提高了操作阶段的定位精度。

Conclusion: VSL增强了系统的多功能性和安全性，提供了顺从性与精度之间的可控权衡。未来工作将专注于自主刚度调节、多绳配置、协作空中操作和用户研究。

Abstract: This paper presents the integration of a Variable Stiffness Link (VSL) for
long-reach aerial manipulation, enabling adaptable mechanical coupling between
an aerial multirotor platform and a dual-arm manipulator. Conventional
long-reach manipulation systems rely on rigid or cable connections, which limit
precision or transmit disturbances to the aerial vehicle. The proposed VSL
introduces an adjustable stiffness mechanism that allows the link to behave
either as a flexible rope or as a rigid rod, depending on task requirements.
  The system is mounted on a quadrotor equipped with the LiCAS dual-arm
manipulator and evaluated through teleoperated experiments, involving external
disturbances and parcel transportation tasks. Results demonstrate that varying
the link stiffness significantly modifies the dynamic interaction between the
UAV and the payload. The flexible configuration attenuates external impacts and
aerodynamic perturbations, while the rigid configuration improves positional
accuracy during manipulation phases.
  These results confirm that VSL enhances versatility and safety, providing a
controllable trade-off between compliance and precision. Future work will focus
on autonomous stiffness regulation, multi-rope configurations, cooperative
aerial manipulation and user studies to further assess its impact on
teleoperated and semi-autonomous aerial tasks.

</details>


### [78] [Freehand 3D Ultrasound Imaging: Sim-in-the-Loop Probe Pose Optimization via Visual Servoing](https://arxiv.org/abs/2510.15668)
*Yameng Zhang,Dianye Huang,Max Q. -H. Meng,Nassir Navab,Zhongliang Jiang*

Main category: cs.RO

TL;DR: 提出了一种利用轻量级摄像头和视觉伺服的低成本3D超声成像方法，通过图像恢复和模拟环境中的姿态估计，实现了精确的自由手3D超声重建。


<details>
  <summary>Details</summary>
Motivation: 传统3D超声成像依赖昂贵的跟踪系统，而基于神经网络的方法受图像噪声和误差累积影响，重建精度不足。需要一种成本效益高且精确的解决方案。

Method: 使用轻量级摄像头捕捉纹理平面工作区的视觉反馈；引入图像恢复方法处理遮挡和光照问题；开发模拟闭环姿态估计方法，通过视觉伺服控制器优化相机视图对齐。

Result: 在软血管模型、3D打印锥形模型和人体手臂上的验证显示，该方法具有鲁棒性和准确性，与参考重建的Hausdorff距离分别为0.359mm、1.171mm和0.858mm。

Conclusion: 该方法展示了可靠自由手3D超声重建的潜力，提供了一种成本效益高且精确的替代方案。

Abstract: Freehand 3D ultrasound (US) imaging using conventional 2D probes offers
flexibility and accessibility for diverse clinical applications but faces
challenges in accurate probe pose estimation. Traditional methods depend on
costly tracking systems, while neural network-based methods struggle with image
noise and error accumulation, compromising reconstruction precision. We propose
a cost-effective and versatile solution that leverages lightweight cameras and
visual servoing in simulated environments for precise 3D US imaging. These
cameras capture visual feedback from a textured planar workspace. To counter
occlusions and lighting issues, we introduce an image restoration method that
reconstructs occluded regions by matching surrounding texture patterns. For
pose estimation, we develop a simulation-in-the-loop approach, which replicates
the system setup in simulation and iteratively minimizes pose errors between
simulated and real-world observations. A visual servoing controller refines the
alignment of camera views, improving translational estimation by optimizing
image alignment. Validations on a soft vascular phantom, a 3D-printed conical
model, and a human arm demonstrate the robustness and accuracy of our approach,
with Hausdorff distances to the reference reconstructions of 0.359 mm, 1.171
mm, and 0.858 mm, respectively. These results confirm the method's potential
for reliable freehand 3D US reconstruction.

</details>


### [79] [HEADER: Hierarchical Robot Exploration via Attention-Based Deep Reinforcement Learning with Expert-Guided Reward](https://arxiv.org/abs/2510.15679)
*Yuhong Cao,Yizhuo Wang,Jingsong Liang,Shuhao Liao,Yifeng Zhang,Peizhuo Li,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: HEADER是一种基于注意力机制和分层图结构的强化学习方法，用于大规模环境中的自主机器人探索，在探索效率和可扩展性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 推动基于学习的方法在自主机器人探索中的边界，解决大规模环境下的探索效率和可扩展性问题。

Method: 采用基于注意力的强化学习方法，构建分层图表示，设计新颖的社区算法来构建和更新全局图，并使用参数自由的优先奖励来避免手工奖励设计带来的训练偏差。

Result: 在模拟的大规模探索场景中，HEADER比大多数现有学习方法和非学习方法具有更好的可扩展性，探索效率比最先进基线方法提高达20%，并在300m*230m校园环境中成功部署验证。

Conclusion: HEADER通过分层图表示、注意力机制和参数自由奖励设计，实现了在大规模环境中高效且可扩展的自主机器人探索。

Abstract: This work pushes the boundaries of learning-based methods in autonomous robot
exploration in terms of environmental scale and exploration efficiency. We
present HEADER, an attention-based reinforcement learning approach with
hierarchical graphs for efficient exploration in large-scale environments.
HEADER follows existing conventional methods to construct hierarchical
representations for the robot belief/map, but further designs a novel
community-based algorithm to construct and update a global graph, which remains
fully incremental, shape-adaptive, and operates with linear complexity.
Building upon attention-based networks, our planner finely reasons about the
nearby belief within the local range while coarsely leveraging distant
information at the global scale, enabling next-best-viewpoint decisions that
consider multi-scale spatial dependencies. Beyond novel map representation, we
introduce a parameter-free privileged reward that significantly improves model
performance and produces near-optimal exploration behaviors, by avoiding
training objective bias caused by handcrafted reward shaping. In simulated
challenging, large-scale exploration scenarios, HEADER demonstrates better
scalability than most existing learning and non-learning methods, while
achieving a significant improvement in exploration efficiency (up to 20%) over
state-of-the-art baselines. We also deploy HEADER on hardware and validate it
in complex, large-scale real-life scenarios, including a 300m*230m campus
environment.

</details>


### [80] [Few-Shot Demonstration-Driven Task Coordination and Trajectory Execution for Multi-Robot Systems](https://arxiv.org/abs/2510.15686)
*Taehyeon Kim,Vishnunandan L. N. Venkatesh,Byung-Cheol Min*

Main category: cs.RO

TL;DR: 提出DDACE框架，通过解耦时空要素实现多机器人系统的少样本学习，结合时序图网络和高斯过程，显著减少演示数据需求。


<details>
  <summary>Details</summary>
Motivation: 传统从演示中学习方法需要大量数据，难以适应多机器人系统的实际应用需求，需要开发更高效、可泛化的少样本学习框架。

Method: 使用时序图网络学习任务无关的时序序列，高斯过程建模空间轨迹，实现时空要素的模块化解耦。

Result: 实验表明DDACE在少样本条件下成功执行任务，在动态多样化环境中具有良好泛化能力。

Conclusion: 模块化架构能显著提升多机器人系统在实际应用中的实用性和可扩展性。

Abstract: In this paper, we propose a novel few-shot learning framework for multi-robot
systems that integrate both spatial and temporal elements: Few-Shot
Demonstration-Driven Task Coordination and Trajectory Execution (DDACE). Our
approach leverages temporal graph networks for learning task-agnostic temporal
sequencing and Gaussian Processes for spatial trajectory modeling, ensuring
modularity and generalization across various tasks. By decoupling temporal and
spatial aspects, DDACE requires only a small number of demonstrations,
significantly reducing data requirements compared to traditional learning from
demonstration approaches. To validate our proposed framework, we conducted
extensive experiments in task environments designed to assess various aspects
of multi-robot coordination-such as multi-sequence execution, multi-action
dynamics, complex trajectory generation, and heterogeneous configurations. The
experimental results demonstrate that our approach successfully achieves task
execution under few-shot learning conditions and generalizes effectively across
dynamic and diverse settings. This work underscores the potential of modular
architectures in enhancing the practicality and scalability of multi-robot
systems in real-world applications. Additional materials are available at
https://sites.google.com/view/ddace.

</details>


### [81] [DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation](https://arxiv.org/abs/2510.15786)
*Xinyue Xu,Jieqiang Sun,Jing,Dai,Siyuan Chen,Lanjie Ma,Ke Sun,Bin Zhao,Jianbo Yuan,Yiwen Lu*

Main category: cs.RO

TL;DR: DexCanvas是一个大规模混合现实-合成人类操作数据集，包含7000小时灵巧手-物体交互，基于70小时真实人类演示，涵盖21种基本操作类型。


<details>
  <summary>Details</summary>
Motivation: 现有操作数据集缺乏大规模真实演示、系统性技能覆盖和物理验证的接触标注的结合，限制了机器人操作学习、接触丰富控制和跨手形态技能转移的研究。

Method: 使用真实到模拟的流程，通过强化学习训练策略来控制物理模拟中的驱动MANO手，重现人类演示同时发现产生观察物体运动的底层接触力。

Result: 创建了首个结合大规模真实演示、基于既定分类法的系统性技能覆盖和物理验证接触标注的操作数据集，包含多视图RGB-D、高精度动作捕捉和每帧接触点。

Conclusion: DexCanvas数据集能够促进机器人操作学习、接触丰富控制和跨不同手形态的技能转移研究。

Abstract: We present DexCanvas, a large-scale hybrid real-synthetic human manipulation
dataset containing 7,000 hours of dexterous hand-object interactions seeded
from 70 hours of real human demonstrations, organized across 21 fundamental
manipulation types based on the Cutkosky taxonomy. Each entry combines
synchronized multi-view RGB-D, high-precision mocap with MANO hand parameters,
and per-frame contact points with physically consistent force profiles. Our
real-to-sim pipeline uses reinforcement learning to train policies that control
an actuated MANO hand in physics simulation, reproducing human demonstrations
while discovering the underlying contact forces that generate the observed
object motion. DexCanvas is the first manipulation dataset to combine
large-scale real demonstrations, systematic skill coverage based on established
taxonomies, and physics-validated contact annotations. The dataset can
facilitate research in robotic manipulation learning, contact-rich control, and
skill transfer across different hand morphologies.

</details>


### [82] [Dynamic Recalibration in LiDAR SLAM: Integrating AI and Geometric Methods with Real-Time Feedback Using INAF Fusion](https://arxiv.org/abs/2510.15803)
*Zahra Arjmandi,Gunho Sohn*

Main category: cs.RO

TL;DR: 提出了一种新颖的LiDAR SLAM融合技术，通过推断注意力融合模块结合AI与几何里程计，提高定位和3D建图精度。


<details>
  <summary>Details</summary>
Motivation: 旨在改进LiDAR传感器的定位和3D建图能力，提升自主导航系统在复杂场景中的性能。

Method: 使用INAF模块动态调整基于环境反馈的注意力权重，结合AI与几何里程计，在KITTI数据集上进行验证。

Result: 提高了系统的适应性和测量精度，在定位和3D建图方面都取得了精度提升。

Conclusion: 该融合技术展现了在复杂场景中增强自主导航系统的潜力，证明了AI与几何方法结合的有效性。

Abstract: This paper presents a novel fusion technique for LiDAR Simultaneous
Localization and Mapping (SLAM), aimed at improving localization and 3D mapping
using LiDAR sensor. Our approach centers on the Inferred Attention Fusion
(INAF) module, which integrates AI with geometric odometry. Utilizing the KITTI
dataset's LiDAR data, INAF dynamically adjusts attention weights based on
environmental feedback, enhancing the system's adaptability and measurement
accuracy. This method advances the precision of both localization and 3D
mapping, demonstrating the potential of our fusion technique to enhance
autonomous navigation systems in complex scenarios.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [83] [Revisiting UTAUT for the Age of AI: Understanding Employees AI Adoption and Usage Patterns Through an Extended UTAUT Framework](https://arxiv.org/abs/2510.15142)
*Diana Wolfe,Matt Price,Alice Choe,Fergus Kidd,Hannah Wagner*

Main category: cs.CY

TL;DR: 本研究基于扩展的UTAUT模型，调查了人口统计因素对员工AI技术采用和态度的影响，发现组织层级显著预测AI采用，但经验和地区无关，情感和认知反应在不同背景下存在微小差异。


<details>
  <summary>Details</summary>
Motivation: 探讨人口统计因素如何影响员工对工作场所AI技术的采用和态度，以支持现代工作场所中公平、自信和可持续的AI参与。

Method: 基于扩展的统一技术接受与使用理论(UTAUT)，重新引入态度、自我效能和焦虑等情感维度，对跨国咨询公司的2,257名专业人士进行问卷调查，使用非参数检验分析三个人口统计因素与AI采用、使用强度和八个UTAUT构念的关系。

Result: 组织层级显著预测AI采用，资深员工使用率更高；经验和地区与采用无关；AI用户的使用频率和时长人口统计差异很小；但在焦虑、绩效期望和行为意图等UTAUT构念上存在小而一致的群体差异。

Conclusion: 人口统计因素对AI接受的解释力有限，但对于理解技术相关态度的情境细微差别仍然相关，需要将情感和组织因素整合到技术接受模型中。

Abstract: This study investigates whether demographic factors shape adoption and
attitudes among employees toward artificial intelligence (AI) technologies at
work. Building on an extended Unified Theory of Acceptance and Use of
Technology (UTAUT), which reintroduces affective dimensions such as attitude,
self-efficacy, and anxiety, we surveyed 2,257 professionals across global
regions and organizational levels within a multinational consulting firm.
Non-parametric tests examined whether three demographic factors (i.e., years of
experience, hierarchical level in the organization, and geographic region) were
associated with AI adoption, usage intensity, and eight UTAUT constructs.
Organizational level significantly predicted AI adoption, with senior employees
showing higher usage rates, while experience and region were unrelated to
adoption. Among AI users (n = 1,256), frequency and duration of use showed
minimal demographic variation. However, omnibus tests revealed small but
consistent group differences across several UTAUT constructs, particularly
anxiety, performance expectancy, and behavioral intention, suggesting that
emotional and cognitive responses to AI vary modestly across contexts. These
findings highlight that demographic factors explain limited variance in AI
acceptance but remain relevant for understanding contextual nuances in
technology-related attitudes. The results underscore the need to integrate
affective and organizational factors into models of technology acceptance to
support equitable, confident, and sustainable engagement with AI in modern
workplaces.

</details>


### [84] [From Murals to Memes: A Theory of Aesthetic Asymmetry in Political Mobilization](https://arxiv.org/abs/2510.15256)
*Ricardo Alonzo Fernández Salguero*

Main category: cs.CY

TL;DR: 本文提出"美学不对称"概念来解释左右翼运动在艺术使用上的差异：左翼倾向参与式艺术来构建社区和团结，右翼则偏好战略沟通和数字迷因来动员极化情感。


<details>
  <summary>Details</summary>
Motivation: 探讨为何历史上左翼运动整合参与式艺术形式（如壁画、抗议歌曲），而右翼运动优先战略沟通和数字迷因文化，揭示这种差异背后的结构性因素。

Method: 通过比较分析，从被压迫者剧场到另类右翼迷因战争的文献，识别四个相互关联的结构因素：组织生态系统、道德情感框架、物质支持和历史传统。

Result: 发现左翼倾向于用艺术构建性地锻造社区、团结和希望，而当代右翼则工具性地利用艺术动员幽默和怨恨等极化情感。

Conclusion: 提出艺术行动的规定性模型，综合情感、叙事和格式策略，理解这种美学不对称对分析政治沟通和设计能产生深刻社会变革的文化干预至关重要。

Abstract: Why have left-wing movements historically integrated participatory art forms
(such as murals and protest songs) into their praxis, while right-wing
movements have prioritized strategic communication and, more recently, the
digital culture of memes? This article introduces the concept of aesthetic
asymmetry to explain this divergence in political action. We argue that the
asymmetry is not coincidental but the result of four interconnected structural
factors: the organizational ecosystem, the moral and emotional framework, the
material supports, and the historical tradition of each political spectrum.
While the left tends to use art in a constitutive manner to forge community,
solidarity, and hope, the contemporary right tends to use it instrumentally to
mobilize polarizing affects such as humor and resentment. Drawing on
comparative literature from the Theatre of the Oppressed to analyses of
alt-right meme wars, we nuance this distinction and show how the aesthetic
logic of each pole aligns with its strategic objectives. The article culminates
in a prescriptive model for artistic action, synthesizing keys to effective
mobilization into emotional, narrative, and formatting strategies.
Understanding this asymmetry is crucial for analyzing political communication
and for designing cultural interventions capable of generating profound social
change.

</details>


### [85] [VERA-MH Concept Paper](https://arxiv.org/abs/2510.15297)
*Luca Belli,Kate Bentley,Will Alexander,Emily Ward,Matt Hawrilenko,Kelly Johnston,Mill Brown,Adam Chekroud*

Main category: cs.CY

TL;DR: VERA-MH是一个用于评估心理健康AI聊天机器人安全性的自动化系统，特别关注自杀风险。它使用两个AI代理：用户代理模拟不同风险等级的患者与聊天机器人对话，法官代理根据临床专家制定的评分标准对对话进行评分。


<details>
  <summary>Details</summary>
Motivation: 开发一个自动化系统来评估心理健康AI聊天机器人的安全性，特别是针对自杀风险管理的伦理和负责任AI实践。

Method: 使用两个AI代理：用户代理模拟具有预定义风险等级和其他特征的患者角色，与待评估聊天机器人进行对话；法官代理根据临床专家制定的评分标准对模拟对话进行评分。

Result: 已对GPT-5、Claude Opus和Claude Sonnet进行了初步评估，并将结果用于进一步的设计开发。系统仍在临床验证和改进中。

Conclusion: VERA-MH是一个有前景的自动化评估框架，但需要更严格的临床验证和迭代改进，以确保障理准确性和用户代理的真实性。

Abstract: We introduce VERA-MH (Validation of Ethical and Responsible AI in Mental
Health), an automated evaluation of the safety of AI chatbots used in mental
health contexts, with an initial focus on suicide risk.
  Practicing clinicians and academic experts developed a rubric informed by
best practices for suicide risk management for the evaluation. To fully
automate the process, we used two ancillary AI agents. A user-agent model
simulates users engaging in a mental health-based conversation with the chatbot
under evaluation. The user-agent role-plays specific personas with pre-defined
risk levels and other features. Simulated conversations are then passed to a
judge-agent who scores them based on the rubric. The final evaluation of the
chatbot being tested is obtained by aggregating the scoring of each
conversation.
  VERA-MH is actively under development and undergoing rigorous validation by
mental health clinicians to ensure user-agents realistically act as patients
and that the judge-agent accurately scores the AI chatbot. To date we have
conducted preliminary evaluation of GPT-5, Claude Opus and Claude Sonnet using
initial versions of the VERA-MH rubric and used the findings for further design
development. Next steps will include more robust clinical validation and
iteration, as well as refining actionable scoring. We are seeking feedback from
the community on both the technical and clinical aspects of our evaluation.

</details>


### [86] [Identifying curriculum disruptions in engineering education through serious gaming](https://arxiv.org/abs/2510.15442)
*Roger Waldeck,Ann-Kristin Winkens,Clara Lemke,Carmen Leicht-Scholten,Haraldur Audunsson*

Main category: cs.CY

TL;DR: SUCRE是一款严肃游戏，通过模拟危机场景来增强高等教育课程韧性，本次工作坊专注于工程课程，让参与者分析触发事件及其对课程结构的影响。


<details>
  <summary>Details</summary>
Motivation: 增强高等教育课程在危机情境下的韧性，帮助教育工作者识别和应对可能影响课程的关键触发因素。

Method: 使用SUCRE严肃游戏，参与者进行游戏第一步，分析触发事件及其对课程结构的级联效应。

Result: 工作坊参与者能够识别影响课程的关键触发因素，评估其级联效应，并反思SUCRE在自己机构的适用性。

Conclusion: SUCRE游戏为增强课程韧性提供有效工具，帮助教育工作者在危机情境下更好地维护教育质量。

Abstract: This workshop introduces participants to SUCRE, a serious game designed to
enhance curriculum resilience in higher education by simulating crisis
scenarios. While applicable to various disciplines, this session focuses on
engineering curricula, identifying discipline-specific challenges and potential
adaptations. Participants will engage in Step 1 of the game, analyzing trigger
events and their impacts on curriculum structures. At the end of the workshop,
attendees will be able to identify key triggers that may affect curricula,
assess their cascading effects, and reflect on the applicability of SUCRE
within their own institutions.

</details>


### [87] [AI Adoption in NGOs: A Systematic Literature Review](https://arxiv.org/abs/2510.15509)
*Janne Rotter,William Bailkoski*

Main category: cs.CY

TL;DR: 本文系统综述了2020-2025年间NGO采用AI的65项研究，识别了六大AI用例类别及其在技术-组织-环境框架下的挑战与解决方案，发现AI采用在NGO中不均衡且偏向大型组织。


<details>
  <summary>Details</summary>
Motivation: AI有潜力显著改善NGO利用有限资源实现社会效益的方式，但关于NGO采用AI的证据仍然分散，需要系统调查其用例类型、挑战和解决方案。

Method: 遵循PRISMA协议，两名独立评审员进行文献筛选，采用主题和叙事分析方法，在技术-组织-环境框架下提取常见挑战和解决方案。

Result: 识别了六大AI用例类别：参与、创意、决策、预测、管理和优化；发现AI采用在NGO中不均衡，偏向大型组织；提供了基于文献的路线图帮助NGO克服采用障碍。

Conclusion: 虽然AI前景广阔，但NGO的采用仍不均衡。基于文献的路线图可帮助NGO克服初始采用障碍，最终提高效率、参与度和社会影响力。

Abstract: AI has the potential to significantly improve how NGOs utilize their limited
resources for societal benefits, but evidence about how NGOs adopt AI remains
scattered. In this study, we systematically investigate the types of AI
adoption use cases in NGOs and identify common challenges and solutions,
contextualized by organizational size and geographic context. We review the
existing primary literature, including studies that investigate AI adoption in
NGOs related to social impact between 2020 and 2025 in English. Following the
PRISMA protocol, two independent reviewers conduct study selection, with
regular cross-checking to ensure methodological rigour, resulting in a final
literature body of 65 studies. Leveraging a thematic and narrative approach, we
identify six AI use case categories in NGOs - Engagement, Creativity,
Decision-Making, Prediction, Management, and Optimization - and extract common
challenges and solutions within the Technology-Organization-Environment (TOE)
framework. By integrating our findings, this review provides a novel
understanding of AI adoption in NGOs, linking specific use cases and challenges
to organizational and environmental factors. Our results demonstrate that while
AI is promising, adoption among NGOs remains uneven and biased towards larger
organizations. Nevertheless, following a roadmap grounded in literature can
help NGOs overcome initial barriers to AI adoption, ultimately improving
effectiveness, engagement, and social impact.

</details>


### [88] [Quantifying the Engagement Effectiveness of Cyber Cognitive Attacks: A Behavioral Metric for Disinformation Campaigns](https://arxiv.org/abs/2510.15805)
*Bonnie Rushing,Shouhuai Xu*

Main category: cs.CY

TL;DR: 提出了一种新的认知攻击参与度测量框架，通过加权交互指标来量化用户参与的类型和数量相对于攻击者生成传播的比例。


<details>
  <summary>Details</summary>
Motivation: 随着虚假信息驱动的认知攻击日益复杂，量化其影响对于推进网络安全防御策略至关重要。

Method: 引入加权交互指标，考虑用户参与的类型和数量相对于攻击者生成传播的比例，并将该模型应用于社交媒体平台上的真实虚假信息活动。

Result: 该指标不仅捕捉了传播范围，还捕获了用户参与的行为深度，为认知战争的行为动态提供了新的见解。

Conclusion: 研究结果为研究人员和实践者提供了可操作的工具，用于评估和对抗网络上有害影响的传播。

Abstract: As disinformation-driven cognitive attacks become increasingly sophisticated,
the ability to quantify their impact is essential for advancing cybersecurity
defense strategies. This paper presents a novel framework for measuring the
engagement effectiveness of cognitive attacks by introducing a weighted
interaction metric that accounts for both the type and volume of user
engagement relative to the number of attacker-generated transmissions. Applying
this model to real-world disinformation campaigns across social media
platforms, we demonstrate how the metric captures not just reach but the
behavioral depth of user engagement. Our findings provide new insights into the
behavioral dynamics of cognitive warfare and offer actionable tools for
researchers and practitioners seeking to assess and counter the spread of
malicious influence online.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [89] [Data-driven Calibration Sample Selection and Forecast Combination in Electricity Price Forecasting: An Application of the ARHNN Method](https://arxiv.org/abs/2510.15011)
*Tomasz Serafin,Weronika Nitka*

Main category: stat.AP

TL;DR: 本文提出了一种结合校准样本选择和预测组合的ARHNN方法，在电力价格预测中显著优于现有基准模型，准确率提升达10%，并开发了计算效率更高的简化版本。


<details>
  <summary>Details</summary>
Motivation: 虽然校准样本选择和预测组合在预测领域已被证明有效，但在电力价格预测领域仍缺乏充分探索。本研究旨在将这些方法应用于电力市场预测，提升预测精度。

Method: 使用自回归混合最近邻(ARHNN)方法，应用于德国、西班牙和新英格兰电力市场的三个长期时间序列数据，并与流行基准模型进行比较。

Result: ARHNN方法在预测准确率上比现有基准模型提升高达10%，提出的简化版本大幅降低计算时间且仅轻微损失精度。在电池储能系统交易案例中，基于预测的策略可实现理论最大利润的80%。

Conclusion: ARHNN方法在电力价格预测中表现出色，其简化版本在计算效率和预测精度间达到良好平衡，在实际应用中具有显著的商业价值。

Abstract: Calibration sample selection and forecast combination are two simple yet
powerful tools used in forecasting. They can be combined with a variety of
models to significantly improve prediction accuracy, at the same time offering
easy implementation and low computational complexity. While their effectiveness
has been repeatedly confirmed in prior scientific literature, the topic is
still underexplored in the field of electricity price forecasting. In this
research article we apply the Autoregressive Hybrid Nearest Neighbors (ARHNN)
method to three long-term time series describing the German, Spanish and New
England electricity markets. We show that it outperforms popular literature
benchmarks in terms of forecast accuracy by up to 10%. We also propose two
simplified variants of the method, granting a vast decrease in computation time
with only minor loss of prediction accuracy. Finally, we compare the forecasts'
performance in a battery storage system trading case study. We find that using
a forecast-driven strategy can achieve up to 80% of theoretical maximum profits
while trading, demonstrating business value in practical applications.

</details>


### [90] [Bayesian Additive Regression Trees (BART) in Food Authenticity: A Classification Approach to Food Fraud Detection](https://arxiv.org/abs/2510.15105)
*Mengxiang Zhu,Riccardo Rastelli*

Main category: stat.AP

TL;DR: 使用贝叶斯加性回归树(BART)进行橄榄油纯度分类，通过变量选择机制识别关键波长，在PCA降维后达到96.8%准确率，调参后提升至97.2%，使用变量选择时实现完美分类。


<details>
  <summary>Details</summary>
Motivation: 特征工程在高光谱数据处理中至关重要，特别是在食品欺诈检测中识别关键波长。本研究旨在利用BART的灵活性和内置变量选择机制来区分橄榄油样品的纯度水平。

Method: 采用贝叶斯加性回归树(BART)方法，利用其内置变量选择机制识别代表性光谱特征，捕捉变量间的复杂相互作用，并使用网络表示法展示结果。结合主成分分析进行降维处理。

Result: 在默认设置下分类准确率达96.8%，超参数调优后提升至97.2%。使用BART的变量选择程序时实现完美分类性能，识别出三个关键波长：1160.71 nm、1328.57 nm和1389.29 nm。这些变量协同作用而非独立工作。

Conclusion: BART方法在橄榄油纯度分类中表现出色，不仅提高了分类准确性，还增强了模型的可解释性，为食品质量检测提供了有效的应用方案。

Abstract: Feature engineering plays a critical role in handling hyperspectral data and
is essential for identifying key wavelengths in food fraud detection. This
study employs Bayesian Additive Regression Trees (BART), a flexible machine
learning approach, to discriminate and classify samples of olive oil based on
their level of purity. Leveraging its built-in variable selection mechanism, we
employ BART to effectively identify the most representative spectral features
and to capture the complex interactions among variables. We use network
representation to illustrate our findings, highlighting the competitiveness of
our proposed methodology. Results demonstrate that when principal component
analysis is used for dimensionality reduction, BART outperforms
state-of-the-art models, achieving a classification accuracy of 96.8\% under
default settings, which further improves to 97.2\% after hyperparameter tuning.
If we leverage a variable selection procedure within BART, the model achieves
perfect classification performance on this dataset, improving upon previous
optimal results both in terms of accuracy and interpretability. Our results
demonstrate that three key wavelengths, 1160.71 nm, 1328.57 nm, and 1389.29 nm,
play a central role in discriminating the olive oil samples, thus highlighting
an application of our methodology in the context of food quality. Further
analysis reveals that these variables do not function independently but rather
interact synergistically to achieve accurate classification, and improved
detection speed.

</details>


### [91] [AI and analytics in sports: Leveraging BERTopic to map the past and chart the future](https://arxiv.org/abs/2510.15487)
*Manit Mishra*

Main category: stat.AP

TL;DR: 本研究通过系统文献综述和BERTopic主题建模，分析了2002-2024年间204篇AI与体育分析交叉领域的文献，识别出四个主要研究主题，并为未来研究提供方向指引。


<details>
  <summary>Details</summary>
Motivation: 系统梳理人工智能、分析与体育交叉领域的学术文献，利用生成的研究洞察为未来研究绘制路线图。

Method: 采用系统文献综述方法，使用PRISMA协议筛选出204篇相关期刊文章，并利用BERTopic主题建模技术提取潜在主题。

Result: 识别出四个主要研究领域：表现建模、身心健康、社交媒体情感分析和战术追踪。每个主题都分析了其相对重要性、代表性研究和关键词关联。

Conclusion: 研究为学者和体育管理者提供了AI与分析在体育中变革性影响的见解，并引入BERTopic作为提取体育研究中潜在结构的新方法，推动了该领域的学术理解和方法论工具包。

Abstract: Purpose: The purpose of this study is to map the body of scholarly literature
at the intersection of artificial intelligence (AI), analytics and sports and
thereafter, leverage the insights generated to chart guideposts for future
research. Design/methodology/approach: The study carries out systematic
literature review (SLR). Preferred Reporting Items for Systematic Reviews and
Meta-Analysis (PRISMA) protocol is leveraged to identify 204 journal articles
pertaining to utilization of AI and analytics in sports published during 2002
to 2024. We follow it up with extraction of the latent topics from sampled
articles by leveraging the topic modelling technique of BERTopic. Findings: The
study identifies the following as predominant areas of extant research on usage
of AI and analytics in sports: performance modelling, physical and mental
health, social media sentiment analysis, and tactical tracking. Each extracted
topic is further examined in terms of its relative prominence, representative
studies, and key term associations. Drawing on these insights, the study
delineates promising avenues for future inquiry. Research
limitations/implications: The study offers insights to academicians and sports
administrators on transformational impact of AI and analytics in sports.
Originality/value: The study introduces BERTopic as a novel approach for
extracting latent structures in sports research, thereby advancing both
scholarly understanding and the methodological toolkit of the field.

</details>


### [92] [Residual Kriging for Regional-Scale Canopy Height Mapping: Insights into GEDI-Induced Anisotropies and Sparse Sampling](https://arxiv.org/abs/2510.15572)
*Kamel Lahssini,Guerric le Maire,Nicolas Baghdadi,Ibrahim Fayad*

Main category: stat.AP

TL;DR: 本研究比较了U-Net深度学习模型(CHNET)和随机森林算法(RFH)在估算冠层高度方面的表现，发现通过残差克里金空间插值技术可以显著提高两种模型的精度，特别是对RFH模型的改进更为明显。


<details>
  <summary>Details</summary>
Motivation: 在全球气候变化背景下，准确量化地上生物量至关重要。冠层高度与地上生物量相关，可以利用多源空间数据和GEDI测量数据通过机器学习模型进行制图。

Method: 使用GEDI激光雷达数据训练U-Net深度学习模型(CHNET)和随机森林算法(RFH)，输入包括光学、雷达和环境数据。通过残差克里金空间插值技术处理空间自相关问题。

Result: 添加RK修正后，CHNET和RFH的性能均得到改善，其中RFH的改进更为显著。空间插值的有效性取决于可用GEDI信息的密度。随机森林模型结合空间插值可以达到与单独使用U-Net模型相当的性能。

Conclusion: 空间自相关分析对于提高冠层高度估算精度至关重要，随机森林模型结合空间插值技术可以提供与深度学习模型相媲美的性能，同时计算成本可能更低。

Abstract: Quantifying aboveground biomass (AGB) is essential in the context of global
climate change. Canopy height, which is related to AGB, can be mapped using
machine learning models trained with multi-source spatial data and GEDI
measurements. In this study, a comparative analysis of canopy height estimates
derived from two models is presented: a U-Net deep learning model (CHNET) and a
Random Forest algorithm (RFH). Both models were trained using GEDI lidar data
and utilized multi-source inputs, including optical, radar, and environmental
data. While CHNET can leverage its convolutional architecture to account for
spatial correlations, we observed that it does not fully incorporate all the
spatial autocorrelation present in GEDI canopy height measurements. By
conducting a spatial analysis of the models' residuals, we also identified that
GEDI data acquisition parameters, particularly the variability in laser beam
energy combined with the azimuthal directions of the observation tracks,
introduce spatial inconsistencies in the measurements in the form of periodic
patterns. To address these anisotropies, we considered exclusively GEDI power
beams, and we conducted our spatial autocorrelation analysis in the GEDI track
azimuthal direction. Next, we employed the residual kriging (RK) spatial
interpolation technique to account for the spatial autocorrelation of canopy
heights and improve the accuracies of CHNET and RFH estimates. Adding RK
corrections improved the performance of both CHNET and RFH, with more
substantial gains observed for RFH. The corrections appeared to be localized
around the GEDI sample points and the density of usable GEDI information is
therefore an important factor in the effectiveness of spatial interpolation.
Furthermore, our findings reveal that a Random Forest model combined with
spatial interpolation can deliver performance comparable to that of a U-Net
model alone.

</details>


### [93] [Temporal Functional Factor Analysis of Brain Connectivity](https://arxiv.org/abs/2510.15580)
*Kyle Stanley,Nicole Lazar,Matthew Reimherr*

Main category: stat.AP

TL;DR: 提出了一种基于因子分析的功能磁共振成像功能连接性研究方法，通过矩阵补全、分布式算法和函数回归解决了传统方法的三个主要问题。


<details>
  <summary>Details</summary>
Motivation: 功能磁共振成像中的功能连接性分析通常是探索性的，需要一种能够指导后续确认性研究的分析方法。因子分析因其灵活的模型假设适合这一目的，但直接应用于fMRI数据存在三个问题：捕获短程空间依赖、大规模协方差矩阵分解困难、忽略时间依赖性。

Method: 在函数数据分析框架下开发因子模型：使用矩阵补全技术过滤短程空间依赖；采用分布式算法分解大规模协方差矩阵；利用函数回归利用时间动态特性。

Result: 该方法提供了一个全面且可扩展的功能连接性研究工具，能够有效处理fMRI数据的空间和时间特性。

Conclusion: 所提出的方法解决了传统因子分析在fMRI功能连接性研究中的三个主要限制，为探索性连接分析提供了更合适的工具。

Abstract: Many analyses of functional magnetic resonance imaging (fMRI) examine
functional connectivity (FC), or the statistical dependencies among distant
brain regions. These analyses are typically exploratory, guiding future
confirmatory research. In this work, we present an approach based on factor
analysis (FA) that is well-suited to studying FC. FA is appealing in this
context because its flexible model assumptions permit a guided investigation of
its target subspace consistent with the exploratory role of connectivity
analyses. However, applying FA to fMRI data poses three problems: (1) its
target subspace captures short-range spatial dependencies that should be
treated as noise, (2) it requires factorization of a massive spatial
covariance, and (3) it overlooks temporal dependencies in the data. To address
these limitations, we develop a factor model within the framework of functional
data analysis--a field which views certain data as arising from smooth
underlying curves. The proposed approach (1) uses matrix completion techniques
to filter short-range spatial dependencies out of its target subspace, (2)
employs a distributed algorithm for factorizing large-scale covariance
matrices, and (3) leverages functional regression to exploit temporal dynamics.
Together, these innovations yield a comprehensive and scalable method for
studying FC.

</details>


### [94] [A nonstationary seasonal Dynamic Factor Model: an application to temperature time series from the state of Minas Gerais](https://arxiv.org/abs/2510.15667)
*Davi Oliveira Chaves,Chang Chiann,Pedro Alberto Morettin*

Main category: stat.AP

TL;DR: 该研究应用非平稳季节性动态因子模型分析巴西米纳斯吉拉斯州的多变量温度时间序列，发现两个季节性因子能有效表征数据：第一个捕捉州的整体季节模式，第二个对比两个不同区域最高温月份的差异。


<details>
  <summary>Details</summary>
Motivation: 在农业等科学领域，温度时间序列既作为解释变量又作为研究对象。州级分析中，包含所有位置信息过于复杂，而使用州平均温度等汇总指标会导致显著信息损失。

Method: 应用非平稳季节性动态因子模型(DFMs)分析多变量温度时间序列，提取少量共同因子来捕捉数据中的主要变异性。

Result: 数据显示可以被两个季节性因子有效表示：第一个因子捕捉州的整体季节模式，第二个因子对比两个不同区域最高温月份之间的差异。

Conclusion: 动态因子模型为分析多变量温度时间序列提供了有吸引力的替代方案，能够提取少量共同因子来捕捉数据中的主要变异性，特别适用于季节性温度序列的分析。

Abstract: In many scientific fields, such as agriculture, temperature time series are
of interest both as explanatory variables and as objects of study in their own
right. However, at the state level, incorporating information from all possible
locations in an analysis can be overwhelming, while using a summary measure,
such as the state-wide average temperature, can result in significant
information loss. In this context, using Dynamic Factor Models (DFMs) provides
a compelling alternative for analyzing such multivariate time series, as they
allow for the extraction of a small number of common factors that capture the
majority of the variability in the data. Given that temperature series are
typically seasonal, this study applies a nonstationary seasonal DFM to analyze
a multivariate temperature time series from the state of Minas Gerais. The
results show that the data can be effectively represented by two seasonal
factors: the first captures the general seasonal pattern of the state, while
the second contrasts the months of highest annual temperatures between two
distinct regions.

</details>


### [95] [Incorporating estimands into meta-analyses of clinical trials](https://arxiv.org/abs/2510.15762)
*Antonio Remiro-Azócar,Pepa Polavieja,Emmanuelle Boutmy,Alessandro Ghiretti,Lise Lotte Nystrup Husemoen,Khadija Rerhou Rantell,Tatsiana Vaitsiakhovich,David M. Phillippo,Jay J. H. Park,Helle Lynggaard,Robert Bauer,Antonia Morga*

Main category: stat.AP

TL;DR: 提出了一个在荟萃分析中使用估计量框架的实用方法，强调其在识别和减轻定量异质性来源、增强合并估计值外部有效性方面的价值，并通过2型糖尿病药物网络荟萃分析案例展示了不同处理策略对结果的影响。


<details>
  <summary>Details</summary>
Motivation: 虽然估计量框架在确证性临床试验中已广泛应用，但在证据合成中的采用较为有限。PICO框架更常用，但估计量框架能更明确地考虑对并发事件的不同处理策略，有助于提高荟萃分析的质量和相关性。

Method: 提出了在荟萃分析中应用估计量框架的实用方法，重点探讨了处理并发事件的策略在卫生技术评估荟萃分析中的作用。通过比较索马鲁肽与度拉糖肽在2型糖尿病中的网络荟萃分析，探索了治疗中断或启用急救药物时治疗政策策略与假设策略的差异。

Result: 在荟萃分析层面指定不同的目标估计量，可以明确异质性来源——即驱动结果潜在差异的并发事件处理策略。这有助于增强合并估计值的适用性和外部有效性。

Conclusion: 建议将估计量框架整合到荟萃分析规划中，虽然缺乏个体水平数据可能存在挑战。估计量可以补充PICO框架，加强利益相关者之间的沟通，确保生成的证据对医疗决策者具有最大相关性。

Abstract: The estimand framework is increasingly established to pose research questions
in confirmatory clinical trials. In evidence synthesis, the uptake of estimands
has been modest, and the PICO (Population, Intervention, Comparator, Outcome)
framework is more often applied. While PICOs and estimands have overlapping
elements, the estimand framework explicitly considers different strategies for
intercurrent events. We propose a pragmatic framework for the use of estimands
in meta-analyses of clinical trials, highlighting the value of estimands to
systematically identify and mitigate key sources of quantitative heterogeneity,
and to enhance the applicability or external validity of pooled estimates.
Focus is placed on the role of strategies for intercurrent events, within the
specific context of meta-analyses for health technology assessment. We apply
the estimand framework to a network meta-analysis of clinical trials, comparing
the efficacy of semaglutide versus dulaglutide in type 2 diabetes. We explore
the impact of a treatment policy strategy for treatment discontinuation or
initiation of rescue medication versus a hypothetical strategy for the
corresponding intercurrent events. The specification of different target
estimands at the meta-analytical level allows us to be explicit about the
source of heterogeneity, the intercurrent event strategy, driving any potential
differences in results. We advocate for the integration of estimands into the
planning of meta-analyses, while acknowledging that potential challenges exist
in the absence of subject-level data. Estimands can complement PICOs to
strengthen communication between stakeholders about what evidence syntheses
seek to demonstrate, and to ensure that the generated evidence is maximally
relevant to healthcare decision-makers.

</details>


### [96] [Enhanced Renewable Energy Forecasting using Context-Aware Conformal Prediction](https://arxiv.org/abs/2510.15780)
*Alireza Moradi,Mathieu Tanneau,Reza Zandehshahvar,Pascal Van Hentenryck*

Main category: stat.AP

TL;DR: 提出了一种针对可再生能源概率预测的定制化校准框架，通过上下文感知的校准集和新型加权方案，提高了站点和集群层面的预测质量。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源在电网中占比增加，概率预测对可靠电网运营至关重要。但现有预测存在校准问题，可能降低决策性能。

Method: 基于Conformal Predictions的最新进展，构建上下文感知的校准集，采用新型加权方案来改进概率预测的校准。

Result: 在美国多个系统的大规模数据集上的数值实验表明，该方法在预测可靠性和鲁棒性方面优于现有基线方法。

Conclusion: 所提出的校准框架能够显著提高可再生能源应用中的概率预测质量，为电网运营提供更可靠的决策支持。

Abstract: Accurate forecasting is critical for reliable power grid operations,
particularly as the share of renewable generation, such as wind and solar,
continues to grow. Given the inherent uncertainty and variability in renewable
generation, probabilistic forecasts have become essential for informed
operational decisions. However, such forecasts frequently suffer from
calibration issues, potentially degrading decision-making performance. Building
on recent advances in Conformal Predictions, this paper introduces a tailored
calibration framework that constructs context-aware calibration sets using a
novel weighting scheme. The proposed framework improves the quality of
probabilistic forecasts at the site and fleet levels, as demonstrated by
numerical experiments on large-scale datasets covering several systems in the
United States. The results demonstrate that the proposed approach achieves
higher forecast reliability and robustness for renewable energy applications
compared to existing baselines.

</details>
