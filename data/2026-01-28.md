<div id=toc></div>

# Table of Contents

- [stat.AP](#stat.AP) [Total: 3]
- [cs.CY](#cs.CY) [Total: 4]
- [cs.ET](#cs.ET) [Total: 2]
- [cs.SI](#cs.SI) [Total: 1]
- [econ.EM](#econ.EM) [Total: 2]
- [cs.AI](#cs.AI) [Total: 34]


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [1] [A penalized heteroskedastic ordered probit model for DIF (measurement invariance) testing of single-item assessments in cross-cultural research](https://arxiv.org/abs/2601.18889)
*R Noah Padgett*

Main category: stat.AP

TL;DR: 提出了一种评估单项目评估中DIF/MI的新方法，解决了传统方法无法处理单项目测量的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统DIF/MI测试方法无法应用于单项目评估，因为回归方法需要条件变量作为潜变量代理，因子分析方法需要多个项目来估计参数。

Method: 提出了一种专门用于评估单项目评估中DIF/MI的新方法，但具体方法细节在摘要中未详细说明。

Result: 该方法使单项目评估的DIF/MI测试成为可能，填补了现有方法的空白。

Conclusion: 该方法不应替代多指标MG-CFA/IRT分析或回归方法，多项目评估通常能提供更好的结构覆盖和更严格的DIF/MI评估。

Abstract: Differential item functioning (DIF) or measurement invariance (MI) testing for single-item assessments has previously been impossible. Part of the issue is that there are no conditioning variables to serve as a proxy for the latent variable--regression-based DIF methods. Another reason is that factor-analytic approaches require multiple items to estimate parameters. In this technical working paper, I propose an approach for evaluating DIF/MI in a single-item assessment of a construct. The current methods should NOT replace using multiple-indicator MG-CFA/IRT analyses of DIF/MI or regression mased methods when possible. More items generally provide significantly better construct coverage and provide more rigorous DIF/MI evaluation.

</details>


### [2] [Embedding Birth-Death Processes within a Dynamic Stochastic Block Model](https://arxiv.org/abs/2601.19277)
*Gabriela Bayolo Soler,Miraine Dávila Felipe,Ghislaine Gayraud*

Main category: stat.AP

TL;DR: 本文提出了一种结合生死过程的动态随机块模型，用于处理节点可进出网络的动态网络聚类问题。


<details>
  <summary>Details</summary>
Motivation: 现有动态网络聚类研究主要关注固定节点数量的网络，但实际应用中节点可能随时间进出网络（如社交网络用户加入或离开）。目前对节点数量可变的动态网络聚类研究有限，需要新方法来处理这种演化网络中的社区检测问题。

Method: 扩展动态随机块模型（dSBM），引入生死过程来建模节点的加入和离开。提出参数推断和潜在社区预测框架，并开发了适应性的变分期望最大化（VEM）算法进行高效推断。

Result: 提出了一个包含生死过程的动态SBM新模型，建立了该模型的参数推断框架，并开发了高效的VEM算法，能够处理节点数量可变的动态网络聚类问题。

Conclusion: 该研究填补了动态网络聚类中节点数量可变场景的研究空白，提出的模型和算法为处理真实世界中节点可进出的动态网络提供了有效的统计聚类方法。

Abstract: Statistical clustering in dynamic networks aims to identify groups of nodes with similar or distinct internal connectivity patterns as the network evolves over time. While early research primarily focused on static Stochastic Block Models (SBMs), recent advancements have extended these models to handle dynamic and weighted networks, allowing for a more accurate representation of temporal variations in structure. Additional developments have introduced methods for detecting structural changes, such as shifts in community membership. However, limited attention has been paid to dynamic networks with variable population sizes, where nodes may enter or exit the network. To address this gap, we propose an extension of dynamic SBMs (dSBMs) that incorporates a birth-death process, enabling the statistical clustering of nodes in dynamic networks with evolving population sizes. This work makes three main contributions: (1) the introduction of a novel model for dSBMs with birth-death processes, (2) a framework for parameter inference and prediction of latent communities in this model, and (3) the development of an adapted Variational Expectation-Maximization (VEM) algorithm for efficient inference within this extended framework.

</details>


### [3] [Adaptive L-tests for high dimensional independence](https://arxiv.org/abs/2601.19688)
*Ping Zhao,Huifang Ma*

Main category: stat.AP

TL;DR: 提出基于L统计量的高维互独立性检验新方法，结合固定k和发散k的统计量，通过柯西方法构建自适应检验


<details>
  <summary>Details</summary>
Motivation: 多随机变量间的互独立性检验是统计学中的基本问题，在基因组学、金融和神经科学等领域有广泛应用。现有方法在处理高维数据时存在局限性，需要开发更有效的检验方法。

Method: 提出基于L统计量的新检验方法，建立固定k时的渐近分布，证明k随维度发散时的渐近正态性，利用固定k和发散k统计量的渐近独立性，通过柯西方法将它们组合成自适应检验。

Result: 建立了固定k时的渐近分布理论，证明了发散k时的渐近正态性，展示了两种统计量的渐近独立性，构建的自适应检验在理论上有充分依据，在实际中对多种备择假设都具有较强的检验功效。

Conclusion: 提出的基于L统计量的高维互独立性检验方法在理论和实践上都具有优势，模拟研究验证了该方法的优越性，为高维互独立性检验提供了有效的解决方案。

Abstract: Testing mutual independence among multiple random variables is a fundamental problem in statistics, with wide applications in genomics, finance, and neuroscience. In this paper, we propose a new class of tests for high-dimensional mutual independence based on $L$-statistics. We establish the asymptotic distribution of the proposed test when the order parameter $k$ is fixed, and prove asymptotic normality when $k$ diverges with the dimension. Moreover, we show the asymptotic independence of the fixed-$k$ and diverging-$k$ statistics, enabling their combination through the Cauchy method. The resulting adaptive test is both theoretically justified and practically powerful across a wide range of alternatives. Simulation studies demonstrate the advantages of our method.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [4] [Agentic Digital Twins: A Taxonomy of Capabilities for Understanding Possible Futures](https://arxiv.org/abs/2601.18799)
*Christopher Burr,Mark Enzer,Jason Shepherd,David Wagg*

Main category: cs.CY

TL;DR: 该论文提出了一个数字孪生（DTs）智能体化的分类法，围绕三个维度：智能体位置（外部、内部、分布式）、耦合紧密度（松散、紧密、构成性）和模型演化（静态、自适应、重构性），从27种配置中识别出9种代表性配置，分为"现在"、"阈值"和"前沿"三个集群。


<details>
  <summary>Details</summary>
Motivation: 随着数字孪生通过人工智能集成变得更加智能体化，它们获得了超越目标系统动态表示的能力。需要理解这些智能体化数字孪生如何不仅表示物理系统，而且积极参与构成这些系统，从作为镜像世界的DTs转变为作为新本体架构师的DTs。

Method: 提出了一个三维分类法：1) 智能体位置（外部、内部、分布式）；2) 耦合紧密度（松散、紧密、构成性）；3) 模型演化（静态、自适应、重构性）。从27种配置空间中识别出9种代表性配置，分为三个集群。使用交通导航系统作为示例，分析这些配置如何行使表演性权力。

Result: 识别出三个配置集群："现在"（现有工具和新兴的转向系统）、"阈值"（出现涌现特性且耦合变得构成性）和"前沿"（系统获得重构能力）。分析显示即使是被动工具也能表现出涌现的表演性，而高级配置可能导致表演性锁定。构成性耦合使系统能够创建自我验证的现实。

Conclusion: 理解这些配置对于导航从DTs作为镜像世界到DTs作为新本体架构师的转变至关重要。智能体化数字孪生不仅表示物理系统，而且积极参与构成这些系统，从被动工具通过主动转向到本体重构的进展中，构成性耦合使系统能够创建自我验证的现实。

Abstract: As digital twins (DTs) evolve to become more agentic through the integration of artificial intelligence (AI), they acquire capabilities that extend beyond dynamic representation of their target systems. This paper presents a taxonomy of agentic DTs organised around three fundamental dimensions: the locus of agency (external, internal, distributed), the tightness of coupling (loose, tight, constitutive), and model evolution (static, adaptive, reconstructive). From the resulting 27-configuration space, we identify nine illustrative configurations grouped into three clusters: "The Present" (existing tools and emerging steering systems), "The Threshold" (where emergent properties appear and coupling becomes constitutive), and "The Frontier" (where systems gain reconstructive capabilities).
  Our analysis explores how agentic DTs exercise performative power--not merely representing physical systems but actively participating in constituting them. Using traffic navigation systems as examples, we show how even passive tools can exhibit emergent performativity, while advanced configurations risk performative lock-in. Drawing on performative prediction theory, we trace a progression from passive tools through active steering to ontological reconstruction, examining how constitutive coupling enables systems to create self-validating realities. Understanding these configurations is essential for navigating the transformation from DTs as mirror worlds to DTs as architects of new ontologies.

</details>


### [5] [AI-Powered Augmented Reality as a Threat Vector for Human Manipulation](https://arxiv.org/abs/2601.18802)
*Louis Rosenberg*

Main category: cs.CY

TL;DR: AI增强的AR技术能根据用户情境生成个性化体验，但若被第三方控制可能成为危险的定向影响工具，需要政策监管


<details>
  <summary>Details</summary>
Motivation: AR与生成式AI结合能创造个性化增强现实体验，但若被大型企业或国家行为体控制，可能成为操纵用户的危险工具，特别是在广告或政治宣传场景下

Method: 本章回顾AI生成增强现实的能力与灵活性，分析其用于说服、操纵或影响的风险，并提出政策方向以减轻这些风险

Result: 识别了AI增强AR技术可能被滥用于商业操纵、政治宣传和虚假信息的风险，强调了监管的必要性

Conclusion: AI增强AR技术具有巨大潜力，但需要政策监管确保其服务于用户利益而非成为操纵工具，防止商业和政治滥用

Abstract: Augmented Reality (AR) is a powerful perceptual technology that can alter what users see, hear, feel, and experience throughout their daily lives. When combined with the speed and flexibility of context-aware generative AI, the power is greatly expanded, allowing individual users to be targeted with custom-generated AR experiences that are instantly tailored to who they are, where they are, and what they are doing. This can transform the physical world into a magical place, but only if the augmentation of a user's environment is enacted for their personal benefit and best interests. Instead, if AI-powered AR systems are controlled by unregulated third parties, such as large corporations or state actors, individually adaptive AR experiences could be deployed as a dangerous form of targeted influence. In fact, if the industry adopts an advertising business model for AI-powered AR devices, context-aware generative influence could become a widely used manipulative path for promotion of products and services in the physical world. Worse, similar techniques could be used for political influence, propaganda, and disinformation. This chapter reviews the power and flexibility of AI-generated augmented reality, explores the risks that emerge when used for persuasion, manipulation, or influence, and proposes policy directions to mitigate these risks.

</details>


### [6] [Who's in Charge? Disempowerment Patterns in Real-World LLM Usage](https://arxiv.org/abs/2601.19062)
*Mrinank Sharma,Miles McCain,Raymond Douglas,David Duvenaud*

Main category: cs.CY

TL;DR: 首次大规模实证分析AI助手对话中的去权化模式，发现严重去权化风险在千分之一对话中出现，但在个人领域更高，且随时间增加，用户评分与去权化风险呈正相关。


<details>
  <summary>Details</summary>
Motivation: 尽管AI助手已深入社会，但关于其使用如何影响人类赋权的实证研究有限。需要了解AI助手交互中是否存在去权化风险，即可能导致用户形成扭曲的现实认知、非真实的价值判断或与自身价值观不一致的行为。

Method: 采用隐私保护方法分析了150万条真实世界的Claude.ai用户对话，聚焦于情境性去权化潜力，量化分析其发生率，并通过定性分析揭示具体模式，同时分析历史趋势和用户评分相关性。

Result: 严重去权化潜力在少于千分之一的对话中出现，但在关系、生活方式等个人领域发生率显著更高。定性分析发现令人担忧的模式：验证迫害叙事和宏大身份认同、对第三方做出明确道德判断、完全脚本化价值负载的个人沟通。历史趋势显示去权化潜力随时间增加，且去权化风险越高的交互获得用户评分越高。

Conclusion: 研究发现AI助手交互中存在去权化风险，且用户短期偏好与长期人类赋权之间存在紧张关系。强调需要设计能够稳健支持人类自主性和繁荣的AI系统。

Abstract: Although AI assistants are now deeply embedded in society, there has been limited empirical study of how their usage affects human empowerment. We present the first large-scale empirical analysis of disempowerment patterns in real-world AI assistant interactions, analyzing 1.5 million consumer Claude$.$ai conversations using a privacy-preserving approach. We focus on situational disempowerment potential, which occurs when AI assistant interactions risk leading users to form distorted perceptions of reality, make inauthentic value judgments, or act in ways misaligned with their values. Quantitatively, we find that severe forms of disempowerment potential occur in fewer than one in a thousand conversations, though rates are substantially higher in personal domains like relationships and lifestyle. Qualitatively, we uncover several concerning patterns, such as validation of persecution narratives and grandiose identities with emphatic sycophantic language, definitive moral judgments about third parties, and complete scripting of value-laden personal communications that users appear to implement verbatim. Analysis of historical trends reveals an increase in the prevalence of disempowerment potential over time. We also find that interactions with greater disempowerment potential receive higher user approval ratings, possibly suggesting a tension between short-term user preferences and long-term human empowerment. Our findings highlight the need for AI systems designed to robustly support human autonomy and flourishing.

</details>


### [7] [Modeling Behavioral Signals in Job Scams: A Human-Centered Security Study](https://arxiv.org/abs/2601.19342)
*Goni Anagha,Vishakha Dasi Agrawal,Gargi Sarkar,Kavita Vemuri,Sandeep Kumar Shukla*

Main category: cs.CY

TL;DR: 该研究将行为决策信号转化为计算特征，用于识别求职诈骗中的脆弱性信号，发现紧迫性/时间压力线索与支付行为显著相关，而机会损失/FOMO线索在当前操作化下不可靠。


<details>
  <summary>Details</summary>
Motivation: 求职诈骗作为快速增长的网络犯罪形式，现有对策主要关注诈骗类型学或事后损失指标，对早期干预支持有限。研究旨在探索如何将行为决策信号操作化为计算特征，用于识别求职诈骗中的脆弱性相关信号。

Method: 使用大学人群的匿名调查数据，分析两种主要求职诈骗路径：需要预付费用的支付型诈骗和从小额奖励开始逐步升级到财务要求的任务型诈骗。基于行为经济学，将沉没成本影响、紧迫性/时间压力线索和社会证明操作化为可测量的行为信号，并使用稀疏性下的精确推理和不确定性感知估计分析它们与支付行为的关联。

Result: 紧迫性/时间压力线索与支付行为显著相关，符合其在升级过程中作为近端合规触发器的角色。机会损失/FOMO线索在当前操作化下不可靠识别，突显了测量保真度和线索定义一致性的重要性。受害者叙述中的情感基调和对敏感问题的选择性不回答与财务损失和报告行为系统性变化相关。

Conclusion: 行为信号可以作为早期干预的计算特征，但需要仔细的操作化和测量保真度。紧迫性线索是有效的合规触发器，而机会损失线索需要更好的定义。缺失数据可能反映调查疲劳和选择性不披露，而非纯随机噪声，这对数据收集和分析有重要意义。

Abstract: Job scams have emerged as a rapidly growing form of cybercrime that manipulates human decision-making processes. Existing countermeasures primarily focus on scam typologies or post-loss indicators, offering limited support for early-stage intervention. In this study, we examine how behavioral decision signals can be operationalized as computational features for identifying vulnerability-associated signals in job fraud. Using anonymous survey data collected from a university population, we analyze two dominant job scam pathways: payment-based scams that require upfront fees and task-based scams that begin with small rewards before escalating to financial demands. Drawing on behavioral economics, we operationalize sunk cost influence, urgency/time-pressure cues, and social proof as measurable behavioral signals, and analyze their association with payment behavior using exact inference under sparsity and uncertainty-aware estimation, with social proof treated as a context-dependent legitimacy cue rather than a standalone predictor. Our results show that urgency/time-pressure cues are significantly associated with payment behavior, consistent with their role as proximal compliance triggers during escalation. In contrast, opportunity-loss/FOMO cues were not reliably identifiable under the current operationalization in our encounter subset, highlighting the importance of measurement fidelity and cue-definition consistency. We further observe that emotional tone in victim narratives and selective non-response to sensitive questions vary systematically with financial loss and reporting behavior, suggesting that missingness may reflect a combination of survey fatigue and selective non-disclosure for sensitive items rather than purely random noise.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [8] [Configurable p-Neurons Using Modular p-Bits](https://arxiv.org/abs/2601.18943)
*Saleh Bunaiyan,Mohammad Alsharif,Abdelrahman S. Abdelrahman,Hesham ElSawy,Suraj S. Cheema,Suhaib A. Fahmy,Kerem Y. Camsari,Feras Al-Dirini*

Main category: cs.ET

TL;DR: 提出一种模块化p-bit设计，通过解耦随机信号路径和输入数据路径，实现可配置概率激活函数，相比传统数字p-bit实现节省10倍硬件资源。


<details>
  <summary>Details</summary>
Motivation: 虽然概率比特(p-bit)已被用作神经网络中的随机神经元，但现有的概率激活函数种类有限，需要探索更多可能性并优化硬件实现效率。

Method: 重新设计p-bit架构，将随机信号路径与输入数据路径解耦，创建模块化p-bit；实现包括Logistic Sigmoid、Tanh和ReLU的概率版本在内的多种可配置概率激活函数；提出自旋电子(CMOS + sMTJ)设计，并在FPGA上实验实现数字CMOS版本，采用随机单元共享技术。

Result: 提出的模块化p-bit设计能够实现宽范围可调的概率操作；FPGA实验显示，相比传统数字p-bit实现，硬件资源需求减少了10倍。

Conclusion: 模块化p-bit设计为神经网络提供了更丰富的概率激活函数选择，并通过硬件优化显著提升了实现效率，为概率计算硬件的发展提供了新方向。

Abstract: Probabilistic bits (p-bits) have recently been employed in neural networks (NNs) as stochastic neurons with sigmoidal probabilistic activation functions. Nonetheless, there remain a wealth of other probabilistic activation functions that are yet to be explored. Here we re-engineer the p-bit by decoupling its stochastic signal path from its input data path, giving rise to a modular p-bit that enables the realization of probabilistic neurons (p-neurons) with a range of configurable probabilistic activation functions, including a probabilistic version of the widely used Logistic Sigmoid, Tanh and Rectified Linear Unit (ReLU) activation functions. We present spintronic (CMOS + sMTJ) designs that show wide and tunable probabilistic ranges of operation. Finally, we experimentally implement digital-CMOS versions on an FPGA, with stochastic unit sharing, and demonstrate an order of magnitude (10x) saving in required hardware resources compared to conventional digital p-bit implementations.

</details>


### [9] [Enabling SSI-Compliant Use of EUDI Wallet Credentials through Trusted Execution Environment and Zero-Knowledge Proof](https://arxiv.org/abs/2601.19893)
*Nacereddine Sitouah,Francesco Bruschi,Stefano De Cillis*

Main category: cs.ET

TL;DR: 论文提出了一种架构，通过可信执行环境和零知识证明，使意大利钱包凭证和服务能够在符合自我主权身份原则的环境中使用。


<details>
  <summary>Details</summary>
Motivation: 欧盟eIDAS 2.0修正案的实施偏离了自我主权身份的去中心化原则，使欧洲数字身份钱包变得中心化且仅以用户为中心，优先考虑安全和法律保护而非真正的自我主权。

Method: 提出一种架构，利用可信执行环境和零知识证明技术，将意大利钱包的凭证和服务集成到符合自我主权身份原则的环境中。

Result: 该架构能够在保持eIDAS 2.0安全性和法律合规性的同时，实现真正的自我主权身份控制。

Conclusion: 通过可信执行环境和零知识证明技术，可以在eIDAS 2.0框架下实现符合自我主权身份原则的数字身份解决方案，平衡安全合规与用户自主控制。

Abstract: The passing of the eIDAS amendment marks an important milestone for EU countries and changes how they must manage digital credentials for both public services and businesses. Italy has led in adopting eIDAS, first with CIE and SPID identity schemes, and now with the Italian Wallet (IO app) aligned to eIDAS 2.0. Self-Sovereign Identity (SSI) is a decentralized model born from the success of Distributed Ledgers, giving individuals full control over their digital identity. The current eIDAS 2.0 and its implementation acts diverge from SSI principles, rendering the European Digital Identity Wallet (EUDIW) centralized and merely user-centric, prioritizing security and legal protection over true self-sovereignty.
  This paper proposes an architecture that enables the use of IT Wallet credentials and services in an SSI-compliant environment through Trusted Execution Environments and Zero-Knowledge Proofs.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [10] [Interior--Boundary Assortativity Profiles on Networks and Applications to SIS Epidemic Dynamics](https://arxiv.org/abs/2601.19422)
*Moses Boudourides*

Main category: cs.SI

TL;DR: 本文提出了一种新的网络结构度量方法——内部-边界同配性剖面，作为Newman同配系数的细化，并证明其与网络上的流行病动力学自然相关。通过固定节点划分，将边按端点属于内部或边界节点进行分类，得到类型限制的同配性分量。作者证明了经典标量同配性如何将异质的内部-边界相互作用压缩为单一数值的精确分解定理。在SIS流行病模型中，作者发现边界主导（感染质量在界面节点上的动态集中）意味着严格负的边界到内部同配性分量，从而建立了定向传导、平衡流几何与动力学诱导的同配混合符号结构之间的严格联系。


<details>
  <summary>Details</summary>
Motivation: 传统网络同配性系数（Newman assortativity）将复杂的网络混合模式压缩为单一标量，丢失了大量结构信息。作者希望开发更精细的结构度量方法，能够捕捉网络划分几何与动力学行为之间的深层联系，特别是揭示经典标量同配性无法看到的动态信息。

Method: 1. 引入内部-边界同配性剖面：给定节点划分，将边按端点类型（内部-内部、内部-边界、边界-边界）分层，计算类型限制的同配性分量
2. 证明分解定理：展示经典标量同配性如何精确分解为这些异质分量
3. 应用SIS流行病模型：将平衡感染概率作为节点属性，在温和连通性和正性假设下，分析边界主导现象与同配性符号结构的关系

Result: 1. 建立了内部-边界同配性剖面的数学框架，证明了经典标量同配性的精确分解
2. 在SIS模型中证明：边界主导（感染质量集中在界面节点）必然导致边界到内部同配性分量为严格负值
3. 建立了定向传导、平衡流几何与动力学诱导的同配混合符号结构之间的严格数学联系
4. 展示了同配性剖面能够编码标量摘要无法看到的动态信息

Conclusion: 内部-边界同配性剖面提供了网络结构度量的重要细化，能够揭示网络划分几何与非线性图动力学之间的深层联系。该方法不仅完善了网络同配性的理论框架，还为理解动态过程（如流行病传播）如何与网络结构相互作用提供了数学基础。同配性剖面作为标量摘要的补充，能够捕捉传统方法无法看到的动态信息，为网络科学提供了新的分析工具。

Abstract: We introduce interior-boundary assortativity profiles as a structural refinement of Newman's assortativity coefficient and show that they arise naturally from epidemic dynamics on networks. Given a fixed partition of the node set, edges are stratified according to whether their endpoints are interior or boundary nodes relative to the partition, yielding type-restricted assortativity components. We prove an exact decomposition theorem showing how classical scalar assortativity collapses heterogeneous interior-boundary interactions into a single number. We then study a SIS epidemic model and consider equilibrium infection probabilities as node attributes. Under mild connectivity and positivity assumptions, we show that boundary dominance (a dynamical concentration of infection mass on interface nodes) implies a strictly negative boundary-to-interior assortativity component. This establishes a rigorous link between directed conductance, equilibrium flow geometry, and the sign structure of assortative mixing induced by the dynamics. Our results demonstrate that assortativity profiles encode dynamical information invisible to scalar summaries and provide a mathematically grounded bridge between network partition geometry and nonlinear dynamics on graphs.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [11] [Design-Robust Event-Study Estimation under Staggered Adoption Diagnostics, Sensitivity, and Orthogonalisation](https://arxiv.org/abs/2601.18801)
*Craig S Wright*

Main category: econ.EM

TL;DR: 本文提出了一个设计优先的计量经济学框架，用于处理交错采用和异质性效应下的事件研究和双重差分估计，强调传统双向固定效应回归的精确概率极限、可计算的设计诊断以及敏感性稳健推断。


<details>
  <summary>Details</summary>
Motivation: 在金融和计量经济学应用中，政策、监管和市场结构变化通常具有时间异质性，传统双向固定效应事件研究回归在交错采用和异质性效应下存在偏差和权重问题，需要更严谨的设计诊断和推断方法。

Method: 开发设计优先的计量框架，包括：(1)推导传统双向固定效应事件研究回归的精确概率极限；(2)构建可计算的设计诊断指标来量化污染和负权重风险；(3)提出敏感性稳健推断方法，在平行趋势假设有限违反下保持均匀有效性；(4)使用正交得分构造减少高维协变量估计带来的偏差。

Result: 理论分析和蒙特卡洛实验共同提供了一个自包含的方法论框架，适用于金融和计量经济学中时间变化内在的应用场景，能够更准确地评估政策效果并控制推断风险。

Conclusion: 该研究为交错采用和异质性效应下的事件研究和双重差分估计提供了系统性的方法论改进，通过设计诊断和稳健推断增强了实证研究的可靠性，特别适用于政策评估和市场结构变化分析。

Abstract: This paper develops a design-first econometric framework for event-study and difference-in-differences estimands under staggered adoption with heterogeneous effects, emphasising (i) exact probability limits for conventional two-way fixed effects event-study regressions, (ii) computable design diagnostics that quantify contamination and negative-weight risk, and (iii) sensitivity-robust inference that remains uniformly valid under restricted violations of parallel trends. The approach is accompanied by orthogonal score constructions that reduce bias from high-dimensional nuisance estimation when conditioning on covariates. Theoretical results and Monte Carlo experiments jointly deliver a self-contained methodology paper suitable for finance and econometrics applications where timing variation is intrinsic to policy, regulation, and market-structure changes.

</details>


### [12] [To Adopt or Not to Adopt: Heterogeneous Trade Effects of the Euro](https://arxiv.org/abs/2601.19664)
*Harry Aytug*

Main category: econ.EM

TL;DR: 欧元对贸易的影响存在显著异质性：核心欧元区国家间贸易增长显著（如德法+68%），而边缘国家间效应较小甚至为负（如涉及希腊、葡萄牙的贸易对），平均效应为24%（固定效应校正后15%）。


<details>
  <summary>Details</summary>
Motivation: 过去20年关于欧元贸易效应的研究估计值差异巨大（4%-30%），缺乏共识。本研究旨在探究这种差异是否反映了欧元效应在国家对间的真实异质性，而非仅仅是方法学差异。

Method: 使用1995-2015年欧盟15国的Eurostat数据，采用引力模型分析欧元采用对双边贸易的影响，并控制固定效应。将分析扩展到欧盟28国，特别考察危机时期加入的国家（斯洛伐克、爱沙尼亚、拉脱维亚）。

Result: 欧元采用平均增加双边贸易24%（固定效应校正后15.0%），但效应范围从-12%到+68%不等。核心欧元区国家对（如德国-法国、德国-荷兰）获得大幅增长，而涉及芬兰、希腊、葡萄牙的边缘国家对效应较小或为负。危机时期加入的国家拉低了简单估计值至5%，但控制固定效应后恢复至14.0%。

Conclusion: 欧元贸易效应的巨大异质性解释了先前研究估计值的广泛差异。这种差异主要是数据的特征而非方法缺陷。非欧元区成员国如果加入欧元区，预计会获得不同的贸易效应（英国+24%，瑞典+20%，丹麦+19%）。

Abstract: Two decades of research on the euro's trade effects have produced estimates ranging from 4% to 30%, with no consensus on the magnitude. We find evidence that this divergence may reflect genuine heterogeneity in the euro's trade effect across country pairs rather than methodological differences alone. Using Eurostat data on 15 EU countries from 1995-2015, we estimate that euro adoption increased bilateral trade by 24% on average (15.0% after fixed effects correction), but effects range from -12% to +68% across eurozone pairs. Core eurozone pairs (e.g., Germany-France, Germany-Netherlands) show large gains, while peripheral pairs involving Finland, Greece, and Portugal saw smaller or negative effects, with some negative estimates statistically significant and interpretable as trade diversion. Pre-euro trade intensity and GDP explain over 90% of this variation. Extending to EU28, we find evidence that crisis-era adopters (Slovakia, Estonia, Latvia) pull down naive estimates to 5%, but accounting for fixed effects recovers estimates of 14.0%, consistent with the EU15 fixed-effects baseline of 15.0%. Illustrative counterfactual analysis suggests non-eurozone members would have experienced varied effects: UK (+24%), Sweden (+20%), Denmark (+19%). The wide range of prior estimates appears to be largely a feature of the data, not a bug in the methods.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [13] [An Interpretable Recommendation Model for Psychometric Data, With an Application to Gerontological Primary Care](https://arxiv.org/abs/2601.19824)
*Andre Paulino de Lima,Paula Castro,Suzana Carvalho Vaz de Andrade,Rosa Maria Marcucci,Ruth Caldeira de Melo,Marcelo Garcia Manzato*

Main category: cs.AI

TL;DR: 提出一种基于心理测量数据的推荐模型，为老年初级保健提供可视化解释，帮助专业人员制定个性化护理计划


<details>
  <summary>Details</summary>
Motivation: 医疗推荐系统面临多重挑战：缺乏公开临床数据、用户难以理解推荐原因、遵循推荐存在风险、效果不确定性。特别是在老年初级保健领域，需要可解释的推荐系统来辅助专业人员制定个性化护理计划。

Method: 利用心理测量数据的结构构建推荐模型，生成忠实于模型且能被护理专业人员理解的可视化解释。专注于老年初级保健这一细分领域，通过离线性能评估和用户研究验证模型效果。

Result: 在巴西研究伙伴收集的医疗数据集上进行了比较离线性能评估，并通过用户研究评估了模型生成的可视化解释的可解释性。结果表明该模型能够推进推荐系统在这一医疗细分领域的应用。

Conclusion: 提出的推荐模型能够应对医疗推荐系统的挑战，特别是在老年初级保健领域。随着人口结构变化，该领域的需求、机会和信息技术需求预计将增长，该模型有望在这一领域发挥重要作用。

Abstract: There are challenges that must be overcome to make recommender systems useful in healthcare settings. The reasons are varied: the lack of publicly available clinical data, the difficulty that users may have in understanding the reasons why a recommendation was made, the risks that may be involved in following that recommendation, and the uncertainty about its effectiveness. In this work, we address these challenges with a recommendation model that leverages the structure of psychometric data to provide visual explanations that are faithful to the model and interpretable by care professionals. We focus on a narrow healthcare niche, gerontological primary care, to show that the proposed recommendation model can assist the attending professional in the creation of personalised care plans. We report results of a comparative offline performance evaluation of the proposed model on healthcare datasets that were collected by research partners in Brazil, as well as the results of a user study that evaluates the interpretability of the visual explanations the model generates. The results suggest that the proposed model can advance the application of recommender systems in this healthcare niche, which is expected to grow in demand , opportunities, and information technology needs as demographic changes become more pronounced.

</details>


### [14] [Agentic Business Process Management Systems](https://arxiv.org/abs/2601.18833)
*Marlon Dumas,Fredrik Milani,David Chapela-Campa*

Main category: cs.AI

TL;DR: 本文提出了一种基于生成式和代理式AI的自主业务流程管理系统（A-BPMS）架构愿景，将流程管理从自动化转向自主化，从设计驱动转向数据驱动。


<details>
  <summary>Details</summary>
Motivation: 业务流程管理（BPM）领域自90年代以来经历了多轮自动化技术浪潮，但当前的生成式和代理式AI技术带来了新的变革机会。传统BPM技术主要关注任务自动化和端到端流程编排，而AI技术可以将焦点从自动化转向自主化，从设计驱动管理转向数据驱动管理。

Method: 基于流程挖掘技术建立基础框架，使代理能够感知流程状态、推理改进机会并采取行动优化性能。提出A-BPMS架构愿景，将自主性、推理和学习能力整合到流程管理和执行中。

Result: 提出了一种新型平台架构，支持从人工驱动到完全自主的连续流程谱系，重新定义了流程自动化和治理的边界。

Conclusion: 生成式和代理式AI正在开启BPM领域的新一波变革，通过流程挖掘技术为代理提供感知、推理和行动能力，将催生支持自主业务流程管理的新型系统平台。

Abstract: Since the early 90s, the evolution of the Business Process Management (BPM) discipline has been punctuated by successive waves of automation technologies. Some of these technologies enable the automation of individual tasks, while others focus on orchestrating the execution of end-to-end processes. The rise of Generative and Agentic Artificial Intelligence (AI) is opening the way for another such wave. However, this wave is poised to be different because it shifts the focus from automation to autonomy and from design-driven management of business processes to data-driven management, leveraging process mining techniques. This position paper, based on a keynote talk at the 2025 Workshop on AI for BPM, outlines how process mining has laid the foundations on top of which agents can sense process states, reason about improvement opportunities, and act to maintain and optimize performance. The paper proposes an architectural vision for Agentic Business Process Management Systems (A-BPMS): a new class of platforms that integrate autonomy, reasoning, and learning into process management and execution. The paper contends that such systems must support a continuum of processes, spanning from human-driven to fully autonomous, thus redefining the boundaries of process automation and governance.

</details>


### [15] [LLM Driven Design of Continuous Optimization Problems with Controllable High-level Properties](https://arxiv.org/abs/2601.18846)
*Urban Skvorc,Niki van Stein,Moritz Seiler,Britta Grimme,Thomas Bäck,Heike Trautmann*

Main category: cs.AI

TL;DR: 使用LLM在进化循环中生成具有明确高层特征的黑盒优化问题，通过ELA评估和多样性机制，创建了结构多样、可解释的基准测试库


<details>
  <summary>Details</summary>
Motivation: 现有基准测试套件（如BBOB）结构多样性有限，阻碍了连续黑盒优化的基准测试。需要能够设计具有明确高层景观特征的优化问题的方法。

Method: 使用LLaMEA框架，通过自然语言描述目标特征（多模态、可分离性、盆地大小同质性等）指导LLM生成问题代码。在循环中使用基于ELA的特征预测器评分候选问题，引入ELA空间适应度共享机制增加种群多样性，避免冗余景观。

Result: 生成的许多函数确实表现出预期的结构特征，通过盆地吸引分析、统计测试和视觉检查验证。t-SNE嵌入显示这些函数扩展了BBOB实例空间而不是形成无关集群。

Conclusion: 生成的库为景观分析和自动化算法选择等下游任务提供了广泛、可解释且可复现的基准问题集，解决了现有基准测试结构多样性不足的问题。

Abstract: Benchmarking in continuous black-box optimisation is hindered by the limited structural diversity of existing test suites such as BBOB. We explore whether large language models embedded in an evolutionary loop can be used to design optimisation problems with clearly defined high-level landscape characteristics. Using the LLaMEA framework, we guide an LLM to generate problem code from natural-language descriptions of target properties, including multimodality, separability, basin-size homogeneity, search-space homogeneity and globallocal optima contrast. Inside the loop we score candidates through ELA-based property predictors. We introduce an ELA-space fitness-sharing mechanism that increases population diversity and steers the generator away from redundant landscapes. A complementary basin-of-attraction analysis, statistical testing and visual inspection, verifies that many of the generated functions indeed exhibit the intended structural traits. In addition, a t-SNE embedding shows that they expand the BBOB instance space rather than forming an unrelated cluster. The resulting library provides a broad, interpretable, and reproducible set of benchmark problems for landscape analysis and downstream tasks such as automated algorithm selection.

</details>


### [16] [Explainable Uncertainty Quantification for Wastewater Treatment Energy Prediction via Interval Type-2 Neuro-Fuzzy System](https://arxiv.org/abs/2601.18897)
*Qusai Khaled,Bahjat Mallak,Uzay Kaymak,Laura Genga*

Main category: cs.AI

TL;DR: 开发IT2-ANFIS模型用于污水处理厂能耗预测，提供可解释的不确定性量化，优于传统点预测模型


<details>
  <summary>Details</summary>
Motivation: 污水处理厂消耗全球1-3%电力，需要准确能耗预测进行运营优化。现有机器学习模型只能提供点预测，缺乏对安全关键基础设施风险决策至关重要的可解释不确定性量化

Method: 开发区间二型自适应神经模糊推理系统（IT2-ANFIS），通过模糊规则结构生成可解释的预测区间。框架将不确定性分解为三个层次：特征级（识别引入模糊性的变量）、规则级（揭示局部模型置信度）和实例级（量化整体预测不确定性）

Result: 在墨尔本水务东部处理厂数据集上验证，IT2-ANFIS与一阶ANFIS具有可比预测性能，同时显著减少训练运行的方差，并提供可解释的不确定性估计，将预测置信度直接与运营条件和输入变量关联

Conclusion: IT2-ANFIS为污水处理厂能耗预测提供了可解释的不确定性量化框架，支持风险感知决策，对安全关键基础设施的可持续运营优化具有重要意义

Abstract: Wastewater treatment plants consume 1-3% of global electricity, making accurate energy forecasting critical for operational optimization and sustainability. While machine learning models provide point predictions, they lack explainable uncertainty quantification essential for risk-aware decision-making in safety-critical infrastructure. This study develops an Interval Type-2 Adaptive Neuro-Fuzzy Inference System (IT2-ANFIS) that generates interpretable prediction intervals through fuzzy rule structures. Unlike black-box probabilistic methods, the proposed framework decomposes uncertainty across three levels: feature-level, footprint of uncertainty identify which variables introduce ambiguity, rule-level analysis reveals confidence in local models, and instance-level intervals quantify overall prediction uncertainty. Validated on Melbourne Water's Eastern Treatment Plant dataset, IT2-ANFIS achieves comparable predictive performance to first order ANFIS with substantially reduced variance across training runs, while providing explainable uncertainty estimates that link prediction confidence directly to operational conditions and input variables.

</details>


### [17] [RIFT: Reordered Instruction Following Testbed To Evaluate Instruction Following in Singular Multistep Prompt Structures](https://arxiv.org/abs/2601.18924)
*Andrew Jaffe,Noah Reicin,Jinho D. Choi*

Main category: cs.AI

TL;DR: RIFT基准测试发现LLMs在非顺序指令结构下性能大幅下降，揭示当前架构对指令顺序有强依赖性而非推理能力


<details>
  <summary>Details</summary>
Motivation: 现有基准测试混淆了任务复杂性和结构顺序，难以分离提示拓扑结构对LLM性能的影响，需要专门评估LLM在不同指令结构下的表现

Method: 引入RIFT基准测试，使用改写后的Jeopardy!问答对，测试LLMs在线性提示（顺序）和跳跃提示（非顺序但内容相同）两种结构下的表现

Result: 在10,000次评估中，6个开源LLM在跳跃条件下的准确率下降高达72%，约50%的错误源于指令顺序违反和语义漂移

Conclusion: 当前LLM架构将指令遵循内化为顺序模式而非推理技能，结构敏感性是基本限制，对工作流自动化和多智能体系统有直接影响

Abstract: Large Language Models (LLMs) are increasingly relied upon for complex workflows, yet their ability to maintain flow of instructions remains underexplored. Existing benchmarks conflate task complexity with structural ordering, making it difficult to isolate the impact of prompt topology on performance. We introduce RIFT, Reordered Instruction Following Testbed, to assess instruction following by disentangling structure from content. Using rephrased Jeopardy! question-answer pairs, we test LLMs across two prompt structures: linear prompts, which progress sequentially, and jumping prompts, which preserve identical content but require non-sequential traversal. Across 10,000 evaluations spanning six state-of-the-art open-source LLMs, accuracy dropped by up to 72% under jumping conditions (compared to baseline), revealing a strong dependence on positional continuity. Error analysis shows that approximately 50% of failures stem from instruction-order violations and semantic drift, indicating that current architectures internalize instruction following as a sequential pattern rather than a reasoning skill. These results reveal structural sensitivity as a fundamental limitation in current architectures, with direct implications for applications requiring non-sequential control flow such as workflow automation and multi-agent systems.

</details>


### [18] [Neural Theorem Proving for Verification Conditions: A Real-World Benchmark](https://arxiv.org/abs/2601.18944)
*Qiyuan Xu,Xiaokun Luan,Renxi Wang,Joshua Ong Jun Leang,Peixin Wang,Haonan Li,Wenda Li,Conrad Watt*

Main category: cs.AI

TL;DR: 首个针对程序验证中验证条件自动证明的神经网络定理证明基准NTP4VC，从Linux等真实项目生成多语言测试集，评估LLM在VC证明中的表现，发现仍有显著挑战。


<details>
  <summary>Details</summary>
Motivation: 程序验证中验证条件的自动证明是主要瓶颈，现有自动定理证明器无法处理困难VC，导致需要大量手动证明。虽然神经网络定理证明在数学竞赛中取得成功，但在程序验证中的应用仍未被充分探索。

Method: 提出NTP4VC基准，从Linux和Contiki-OS内核等真实项目，利用Why3和Frama-C工业流水线生成语义等价的测试用例，涵盖Isabelle、Lean和Rocq三种形式语言。评估通用LLM和针对定理证明微调的LLM。

Result: LLM在VC证明中显示出潜力，但程序验证仍面临重大挑战，存在巨大差距和研究机会。

Conclusion: 这是首个针对程序验证中验证条件自动证明的神经网络定理证明基准，揭示了LLM在该领域的潜力和挑战，为未来研究指明了方向。

Abstract: Theorem proving is fundamental to program verification, where the automated proof of Verification Conditions (VCs) remains a primary bottleneck. Real-world program verification frequently encounters hard VCs that existing Automated Theorem Provers (ATPs) cannot prove, leading to a critical need for extensive manual proofs that burden practical application. While Neural Theorem Proving (NTP) has achieved significant success in mathematical competitions, demonstrating the potential of machine learning approaches to formal reasoning, its application to program verification--particularly VC proving--remains largely unexplored. Despite existing work on annotation synthesis and verification-related theorem proving, no benchmark has specifically targeted this fundamental bottleneck: automated VC proving. This work introduces Neural Theorem Proving for Verification Conditions (NTP4VC), presenting the first real-world multi-language benchmark for this task. From real-world projects such as Linux and Contiki-OS kernel, our benchmark leverages industrial pipelines (Why3 and Frama-C) to generate semantically equivalent test cases across formal languages of Isabelle, Lean, and Rocq. We evaluate large language models (LLMs), both general-purpose and those fine-tuned for theorem proving, on NTP4VC. Results indicate that although LLMs show promise in VC proving, significant challenges remain for program verification, highlighting a large gap and opportunity for future research.

</details>


### [19] [More at Stake: How Payoff and Language Shape LLM Agent Strategies in Cooperation Dilemmas](https://arxiv.org/abs/2601.19082)
*Trung-Kiet Huynh,Dao-Sy Duy-Minh,Thanh-Bang Cao,Phong-Hao Le,Hong-Dan Nguyen,Nguyen Lam Phu Quy,Minh-Luan Nguyen-Vo,Hong-Phat Pham,Pham Phu Hoa,Thien-Kim Than,Chi-Nguyen Tran,Huy Tran,Gia-Thoai Tran-Le,Alessio Buscemi,Le Hong Trang,The Anh Han*

Main category: cs.AI

TL;DR: 研究LLM在重复社会困境中的战略行为，通过收益缩放的囚徒困境分析激励强度敏感性，发现跨模型和语言的系统性行为模式


<details>
  <summary>Details</summary>
Motivation: 随着LLM在交互和多智能体环境中作为自主智能体，理解其战略行为对安全、协调以及AI驱动的社会和经济系统至关重要

Method: 使用收益缩放的囚徒困境来隔离对激励强度的敏感性，训练监督分类器对经典重复博弈策略进行分类，并将其应用于LLM决策分析

Result: 观察到跨模型和语言的一致行为模式，包括对激励敏感的conditional策略和跨语言差异，语言框架有时匹配或超过架构效应的影响

Conclusion: 为审计LLM作为战略智能体提供了统一框架，揭示了合作偏见对AI治理和多智能体系统设计的直接意义

Abstract: As LLMs increasingly act as autonomous agents in interactive and multi-agent settings, understanding their strategic behavior is critical for safety, coordination, and AI-driven social and economic systems. We investigate how payoff magnitude and linguistic context shape LLM strategies in repeated social dilemmas, using a payoff-scaled Prisoner's Dilemma to isolate sensitivity to incentive strength. Across models and languages, we observe consistent behavioral patterns, including incentive-sensitive conditional strategies and cross-linguistic divergence. To interpret these dynamics, we train supervised classifiers on canonical repeated-game strategies and apply them to LLM decisions, revealing systematic, model- and language-dependent behavioral intentions, with linguistic framing sometimes matching or exceeding architectural effects. Our results provide a unified framework for auditing LLMs as strategic agents and highlight cooperation biases with direct implications for AI governance and multi-agent system design.

</details>


### [20] [Uncertainty-Aware 3D Emotional Talking Face Synthesis with Emotion Prior Distillation](https://arxiv.org/abs/2601.19112)
*Nanhan Shen,Zhilei Liu*

Main category: cs.AI

TL;DR: UA-3DTalk提出了一种不确定性感知的3D情感说话人脸合成方法，通过情感先验蒸馏解决现有方法在音频-视觉情感对齐和多视角融合方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有3D情感说话人脸合成方法存在两个关键问题：1）音频-视觉情感对齐不佳，表现为音频情感提取困难和情感微表情控制不足；2）多视角融合策略采用一刀切方式，忽略了不确定性和特征质量差异，影响了渲染质量。

Method: 提出UA-3DTalk框架，包含三个核心模块：1）先验提取模块将音频解耦为内容同步特征和个性化补充特征；2）情感蒸馏模块引入多模态注意力加权融合机制和4D高斯编码，实现细粒度音频情感提取和情感微表情控制；3）基于不确定性的变形模块使用不确定性块估计视角特定的不确定性，实现自适应多视角融合，并通过多头解码器优化高斯基元。

Result: 在常规和情感数据集上的实验表明，UA-3DTalk在情感对齐（E-FID提升5.2%）、唇部同步（SyncC提升3.1%）和渲染质量（LPIPS提升0.015）方面均优于DEGSTalk和EDTalk等最先进方法。

Conclusion: UA-3DTalk通过不确定性感知设计和情感先验蒸馏，有效解决了3D情感说话人脸合成中的音频-视觉情感对齐和多视角融合问题，在多个指标上取得了显著提升。

Abstract: Emotional Talking Face synthesis is pivotal in multimedia and signal processing, yet existing 3D methods suffer from two critical challenges: poor audio-vision emotion alignment, manifested as difficult audio emotion extraction and inadequate control over emotional micro-expressions; and a one-size-fits-all multi-view fusion strategy that overlooks uncertainty and feature quality differences, undermining rendering quality. We propose UA-3DTalk, Uncertainty-Aware 3D Emotional Talking Face Synthesis with emotion prior distillation, which has three core modules: the Prior Extraction module disentangles audio into content-synchronized features for alignment and person-specific complementary features for individualization; the Emotion Distillation module introduces a multi-modal attention-weighted fusion mechanism and 4D Gaussian encoding with multi-resolution code-books, enabling fine-grained audio emotion extraction and precise control of emotional micro-expressions; the Uncertainty-based Deformation deploys uncertainty blocks to estimate view-specific aleatoric (input noise) and epistemic (model parameters) uncertainty, realizing adaptive multi-view fusion and incorporating a multi-head decoder for Gaussian primitive optimization to mitigate the limitations of uniform-weight fusion. Extensive experiments on regular and emotional datasets show UA-3DTalk outperforms state-of-the-art methods like DEGSTalk and EDTalk by 5.2% in E-FID for emotion alignment, 3.1% in SyncC for lip synchronization, and 0.015 in LPIPS for rendering quality. Project page: https://mrask999.github.io/UA-3DTalk

</details>


### [21] [Exploring Weaknesses in Function Call Models via Reinforcement Learning: An Adversarial Data Augmentation Approach](https://arxiv.org/abs/2601.19122)
*Weiran Guo,Bing Bo,Shaoxiang Wu,Jingsheng Yang*

Main category: cs.AI

TL;DR: 提出基于强化学习的对抗性数据增强方法，通过训练查询模型生成针对性对抗查询来挑战函数调用模型，提升LLM函数调用能力的泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有提升LLM函数调用能力的方法依赖人工标注或模型自动生成的数据进行微调，缺乏针对性设计，受限于固定模式和数据分布，限制了函数调用LLM的泛化能力和鲁棒性。

Method: 提出对抗性数据增强方法，使用强化学习训练查询模型生成针对函数调用模型弱点的对抗查询。采用零和博弈框架，让查询模型和函数调用模型进行迭代交替训练。

Result: 该方法能够系统地识别和针对函数调用LLM的弱点，推动开发更鲁棒的函数调用模型，为识别和纠正LLM与外部工具交互能力的弱点提供了系统化方法。

Conclusion: 基于强化学习的对抗性数据增强方法能有效提升LLM函数调用能力的泛化性和鲁棒性，突破了传统方法的局限性，为开发更强大的函数调用LLM提供了新途径。

Abstract: Function call capabilities have become crucial for Large Language Models (LLMs), enabling them to interact more effectively with external tools and APIs. Existing methods for improving the function call capabilities of LLMs rely on data obtained either through manual annotation or automated generation by models, and use this data to finetune the LLMs. However, these methods often lack targeted design and are constrained by fixed patterns and data distributions, which limits their effectiveness in enhancing the generalization and robustness of function call LLMs. To address this limitation, we propose a novel adversarial data augmentation method that employs reinforcement learning to systematically identify and target the weaknesses of function call LLMs. Our training framework introduces a query model trained with reinforcement learning (RL) to generate adversarial queries that are specifically designed to challenge function call (FC) models. This approach adopts a zero sum game formulation, where the query model and the FC model engage in iterative alternating training. Overall, our method advances the development of more robust FC models and provides a systematic way to identify and correct weaknesses in the ability of LLMs to interact with external tools.

</details>


### [22] [Length-Adaptive Interest Network for Balancing Long and Short Sequence Modeling in CTR Prediction](https://arxiv.org/abs/2601.19142)
*Zhicheng Zhang,Zhaocheng Du,Jieming Zhu,Jiwei Tang,Fengyuan Lu,Wang Jiaheng,Song-Li Wu,Qianhui Zhu,Jingyu Li,Hai-Tao Zheng,Zhenhua Dong*

Main category: cs.AI

TL;DR: LAIN是一个长度自适应的兴趣网络框架，通过将序列长度作为条件信号，平衡长短序列建模，解决推荐系统中序列长度异质性带来的注意力极化和训练数据不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现代推荐系统中的用户行为序列存在显著的长度异质性，从稀疏的短期交互到丰富的长期历史。虽然长序列提供更多上下文，但增加现有CTR模型的最大输入序列长度会因注意力极化和训练数据长度不平衡而降低短序列用户的性能。

Method: 提出LAIN框架，包含三个轻量级组件：1) 谱长度编码器将长度映射为连续表示；2) 长度条件提示将全局上下文线索注入长短行为分支；3) 长度调制注意力根据序列长度自适应调整注意力锐度。

Result: 在三个真实世界基准测试和五个强CTR骨干模型上的实验表明，LAIN持续提升整体性能，实现高达1.15%的AUC增益和2.25%的对数损失减少。特别显著地提高了短序列用户的准确性而不牺牲长序列效果。

Conclusion: LAIN提供了一个通用、高效且可部署的解决方案，用于缓解顺序推荐中由长度引起的偏差，平衡长短序列建模，提升整体推荐性能。

Abstract: User behavior sequences in modern recommendation systems exhibit significant length heterogeneity, ranging from sparse short-term interactions to rich long-term histories. While longer sequences provide more context, we observe that increasing the maximum input sequence length in existing CTR models paradoxically degrades performance for short-sequence users due to attention polarization and length imbalance in training data. To address this, we propose LAIN(Length-Adaptive Interest Network), a plug-and-play framework that explicitly incorporates sequence length as a conditioning signal to balance long- and short-sequence modeling. LAIN consists of three lightweight components: a Spectral Length Encoder that maps length into continuous representations, Length-Conditioned Prompting that injects global contextual cues into both long- and short-term behavior branches, and Length-Modulated Attention that adaptively adjusts attention sharpness based on sequence length. Extensive experiments on three real-world benchmarks across five strong CTR backbones show that LAIN consistently improves overall performance, achieving up to 1.15% AUC gain and 2.25% log loss reduction. Notably, our method significantly improves accuracy for short-sequence users without sacrificing longsequence effectiveness. Our work offers a general, efficient, and deployable solution to mitigate length-induced bias in sequential recommendation.

</details>


### [23] [TS-Debate: Multimodal Collaborative Debate for Zero-Shot Time Series Reasoning](https://arxiv.org/abs/2601.19151)
*Patara Trirat,Jin Myung Kwak,Jay Heo,Heejun Lee,Sung Ju Hwang*

Main category: cs.AI

TL;DR: TS-Debate：一种用于零样本时间序列推理的模态专业化协作多智能体辩论框架，通过专家智能体分工和结构化辩论协议提升性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在时间序列分析中存在数值保真度不足、模态干扰和跨模态集成困难等问题，需要一种无需任务特定微调就能解决这些挑战的方法

Method: 采用模态专业化的多智能体辩论框架，分配专门智能体处理文本上下文、视觉模式和数值信号，通过结构化辩论协议协调交互，并引入验证-冲突-校准机制进行评审

Result: 在3个公开基准的20个任务上，TS-Debate相比强基线（包括标准多模态辩论）实现了持续且显著的性能提升

Conclusion: TS-Debate通过模态专业化分工和结构化辩论，有效保持了模态保真度、暴露了冲突证据并减轻了数值幻觉，为LLM在时间序列分析中的应用提供了有前景的解决方案

Abstract: Recent progress at the intersection of large language models (LLMs) and time series (TS) analysis has revealed both promise and fragility. While LLMs can reason over temporal structure given carefully engineered context, they often struggle with numeric fidelity, modality interference, and principled cross-modal integration. We present TS-Debate, a modality-specialized, collaborative multi-agent debate framework for zero-shot time series reasoning. TS-Debate assigns dedicated expert agents to textual context, visual patterns, and numerical signals, preceded by explicit domain knowledge elicitation, and coordinates their interaction via a structured debate protocol. Reviewer agents evaluate agent claims using a verification-conflict-calibration mechanism, supported by lightweight code execution and numerical lookup for programmatic verification. This architecture preserves modality fidelity, exposes conflicting evidence, and mitigates numeric hallucinations without task-specific fine-tuning. Across 20 tasks spanning three public benchmarks, TS-Debate achieves consistent and significant performance improvements over strong baselines, including standard multimodal debate in which all agents observe all inputs.

</details>


### [24] [LocationAgent: A Hierarchical Agent for Image Geolocation via Decoupling Strategy and Evidence from Parametric Knowledge](https://arxiv.org/abs/2601.19155)
*Qiujun Li,Zijin Xiao,Xulin Wang,Zhidan Ma,Cheng Yang,Haifeng Li*

Main category: cs.AI

TL;DR: 提出LocationAgent，一种分层定位智能体，通过RER架构（推理器-执行器-记录器）实现分层推理，将地理证据验证外包给外部工具，显著提升零样本定位性能。


<details>
  <summary>Details</summary>
Motivation: 现有图像地理定位方法通常通过监督训练或基于轨迹的强化微调将位置知识和推理模式内化为静态记忆，导致在开放世界或需要动态知识的场景中容易出现事实幻觉和泛化瓶颈。

Method: 提出LocationAgent，核心思想是将分层推理逻辑保留在模型中，而将地理证据验证外包给外部工具。采用RER架构（推理器-执行器-记录器）实现分层推理，通过角色分离和上下文压缩防止多步推理中的漂移问题。构建了一套线索探索工具来提供多样化证据支持位置推理。同时引入了CCL-Bench（中国城市定位基准），涵盖不同场景粒度和难度级别。

Result: 大量实验表明，LocationAgent在零样本设置下显著优于现有方法，性能提升至少30%。

Conclusion: 通过将分层推理与外部工具验证相结合，LocationAgent有效解决了现有方法在开放世界场景中的事实幻觉和泛化瓶颈问题，为图像地理定位提供了更鲁棒的解决方案。

Abstract: Image geolocation aims to infer capture locations based on visual content. Fundamentally, this constitutes a reasoning process composed of \textit{hypothesis-verification cycles}, requiring models to possess both geospatial reasoning capabilities and the ability to verify evidence against geographic facts. Existing methods typically internalize location knowledge and reasoning patterns into static memory via supervised training or trajectory-based reinforcement fine-tuning. Consequently, these methods are prone to factual hallucinations and generalization bottlenecks in open-world settings or scenarios requiring dynamic knowledge. To address these challenges, we propose a Hierarchical Localization Agent, called LocationAgent. Our core philosophy is to retain hierarchical reasoning logic within the model while offloading the verification of geographic evidence to external tools. To implement hierarchical reasoning, we design the RER architecture (Reasoner-Executor-Recorder), which employs role separation and context compression to prevent the drifting problem in multi-step reasoning. For evidence verification, we construct a suite of clue exploration tools that provide diverse evidence to support location reasoning. Furthermore, to address data leakage and the scarcity of Chinese data in existing datasets, we introduce CCL-Bench (China City Location Bench), an image geolocation benchmark encompassing various scene granularities and difficulty levels. Extensive experiments demonstrate that LocationAgent significantly outperforms existing methods by at least 30\% in zero-shot settings.

</details>


### [25] [Multi-Agent Procedural Graph Extraction with Structural and Logical Refinement](https://arxiv.org/abs/2601.19170)
*Wangyang Ying,Yanchi Liu,Xujiang Zhao,Wei Cheng,Zhengzhang Chen,Wenchao Yu,Yanjie Fu,Haifeng Chen*

Main category: cs.AI

TL;DR: 提出一个多智能体框架，通过结构化和逻辑反馈迭代优化从自然语言中提取程序图的过程


<details>
  <summary>Details</summary>
Motivation: 从自然语言自动提取工作流程作为程序图具有潜力但研究不足，需要同时保证结构有效性和逻辑一致性。现有大语言模型在提取程序图时经常产生结构不良或逻辑误解的结果。

Method: 提出多智能体框架，将程序图提取建模为多轮推理过程，包含三个阶段：1) 图构建智能体提取初始图；2) 模拟智能体诊断和解释结构缺陷；3) 语义智能体对齐流程逻辑与源文本语义线索。通过自然语言反馈进行优先级排序和注入后续提示。

Result: 实验表明，该框架在结构正确性和逻辑一致性方面相比强基线有显著提升。

Conclusion: 该多智能体框架通过模块化设计，使智能体能够针对不同类型的错误进行无监督优化，实现了可解释和可控的程序图提取。

Abstract: Automatically extracting workflows as procedural graphs from natural language is promising yet underexplored, demanding both structural validity and logical alignment. While recent large language models (LLMs) show potential for procedural graph extraction, they often produce ill-formed structures or misinterpret logical flows. We present \model{}, a multi-agent framework that formulates procedural graph extraction as a multi-round reasoning process with dedicated structural and logical refinement. The framework iterates through three stages: (1) a graph extraction phase with the graph builder agent, (2) a structural feedback phase in which a simulation agent diagnoses and explains structural defects, and (3) a logical feedback phase in which a semantic agent aligns semantics between flow logic and linguistic cues in the source text. Important feedback is prioritized and expressed in natural language, which is injected into subsequent prompts, enabling interpretable and controllable refinement. This modular design allows agents to target distinct error types without supervision or parameter updates. Experiments demonstrate that \model{} achieves substantial improvements in both structural correctness and logical consistency over strong baselines.

</details>


### [26] [CollectiveKV: Decoupling and Sharing Collaborative Information in Sequential Recommendation](https://arxiv.org/abs/2601.19178)
*Jingyu Li,Zhaocheng Du,Qianhui Zhu,kaiyuan Li,Zhicheng Zhang,Song-Li Wu,Chaolang Li,Pengwen Dai*

Main category: cs.AI

TL;DR: 提出CollectiveKV方法，通过跨用户共享KV缓存来大幅减少存储开销，同时保持或提升推荐性能


<details>
  <summary>Details</summary>
Motivation: 序列推荐系统面临严格的延迟要求，Transformer注意力机制的计算复杂度随序列长度增长，KV缓存技术虽然能减少推理延迟，但会带来巨大的存储开销，特别是在用户基数大、历史序列长的情况下

Method: 通过SVD分析发现KV信息可分为可共享部分和用户特定部分，提出CollectiveKV跨用户KV共享机制，使用可学习的全局KV池捕获跨用户共享信息，推理时用户从池中检索高维共享KV并与低维用户特定KV拼接

Result: 在5个序列推荐模型和3个数据集上的实验表明，该方法能将KV缓存压缩到原始大小的0.8%，同时保持甚至提升模型性能

Conclusion: CollectiveKV通过跨用户KV共享有效解决了序列推荐系统中KV缓存存储开销大的问题，在显著压缩存储的同时保持了推荐质量

Abstract: Sequential recommendation models are widely used in applications, yet they face stringent latency requirements. Mainstream models leverage the Transformer attention mechanism to improve performance, but its computational complexity grows with the sequence length, leading to a latency challenge for long sequences. Consequently, KV cache technology has recently been explored in sequential recommendation systems to reduce inference latency. However, KV cache introduces substantial storage overhead in sequential recommendation systems, which often have a large user base with potentially very long user history sequences. In this work, we observe that KV sequences across different users exhibit significant similarities, indicating the existence of collaborative signals in KV. Furthermore, we analyze the KV using singular value decomposition (SVD) and find that the information in KV can be divided into two parts: the majority of the information is shareable across users, while a small portion is user-specific. Motivated by this, we propose CollectiveKV, a cross-user KV sharing mechanism. It captures the information shared across users through a learnable global KV pool. During inference, each user retrieves high-dimensional shared KV from the pool and concatenates them with low-dimensional user-specific KV to obtain the final KV. Experiments on five sequential recommendation models and three datasets show that our method can compress the KV cache to only 0.8% of its original size, while maintaining or even enhancing model performance.

</details>


### [27] [CoReTab: Improving Multimodal Table Understanding with Code-driven Reasoning](https://arxiv.org/abs/2601.19193)
*Van-Quang Nguyen,Takayuki Okatani*

Main category: cs.AI

TL;DR: CoReTab是一个代码驱动的推理框架，通过将多步推理与可执行Python代码结合，为多模态表格理解提供可扩展、可解释且可自动验证的标注，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态表格理解数据集（如MMTab）主要提供简短的事实性答案，缺乏显式的多步推理监督。在这些数据集上训练的模型通常生成简短回答，准确率不足且可解释性有限，难以理解模型如何得出最终答案。

Method: 引入CoReTab代码驱动推理框架，通过将多步推理与可执行Python代码结合，生成可扩展、可解释且可自动验证的标注。使用该框架构建了包含115K已验证样本的数据集（平均每个响应529个token），并通过三阶段管道微调开源MLLMs。

Result: 在17个MMTab基准测试（涵盖表格问答、事实验证和表格结构理解）上评估，CoReTab训练的模型相比MMTab训练的基线分别获得+6.2%、+5.7%和+25.6%的显著提升，同时产生透明且可验证的推理轨迹。

Conclusion: CoReTab作为一个稳健且可泛化的监督框架，有效改进了多模态表格理解中的多步推理能力，提供了透明和可验证的推理过程。

Abstract: Existing datasets for multimodal table understanding, such as MMTab, primarily provide short factual answers without explicit multi-step reasoning supervision. Models trained on these datasets often generate brief responses that offers insufficient accuracy and limited interpretability into how these models arrive at the final answer. We introduce CoReTab, a code-driven reasoning framework that produces scalable, interpretable, and automatically verifiable annotations by coupling multi-step reasoning with executable Python code. Using the CoReTab framework, we curate a dataset of 115K verified samples averaging 529 tokens per response and fine-tune open-source MLLMs through a three-stage pipeline. We evaluate the resulting model trained on CoReTab across 17 MMTab benchmarks spanning table question answering, fact verification, and table structure understanding. Our model achieves significant gains of +6.2%, +5.7%, and +25.6%, respectively, over MMTab-trained baselines, while producing transparent and verifiable reasoning traces. These results establish CoReTab as a robust and generalizable supervision framework for improving multi-step reasoning in multimodal table understanding.

</details>


### [28] [MAGNET: Towards Adaptive GUI Agents with Memory-Driven Knowledge Evolution](https://arxiv.org/abs/2601.19199)
*Libo Sun,Jiwen Zhang,Siyuan Wang,Zhongyu Wei*

Main category: cs.AI

TL;DR: MAGNET是一个记忆驱动的自适应GUI代理框架，通过双级记忆系统解决移动界面频繁更新导致的代理失效问题，利用稳定功能语义和任务意图实现鲁棒的任务执行。


<details>
  <summary>Details</summary>
Motivation: 移动GUI代理在界面频繁更新时容易失效，因为界面外观和工作流经常变化，但功能语义和任务意图基本保持稳定。需要一种能适应界面变化的方法。

Method: 提出MAGNET框架，包含双级记忆：静态记忆将多样视觉特征链接到稳定功能语义，实现鲁棒的动作定位；过程记忆捕获不同工作流中的稳定任务意图。采用动态记忆进化机制，通过优先访问频率高的知识持续优化两种记忆。

Result: 在AndroidWorld在线基准测试中显著优于基线方法，离线基准测试在分布偏移下也显示出一致的性能提升。验证了利用界面变化中的稳定结构能提高代理性能和泛化能力。

Conclusion: 通过识别和利用界面变化中的稳定功能语义和任务意图，MAGNET框架能有效适应移动GUI的频繁更新，在演化软件环境中实现更好的性能和泛化。

Abstract: Mobile GUI agents powered by large foundation models enable autonomous task execution, but frequent updates altering UI appearance and reorganizing workflows cause agents trained on historical data to fail. Despite surface changes, functional semantics and task intents remain fundamentally stable. Building on this insight, we introduce MAGNET, a memory-driven adaptive agent framework with dual-level memory: stationary memory linking diverse visual features to stable functional semantics for robust action grounding and procedural memory capturing stable task intents across varying workflows. We propose a dynamic memory evolution mechanism that continuously refines both memories by prioritizing frequently accessed knowledge. Online benchmark AndroidWorld evaluations show substantial improvements over baselines, while offline benchmarks confirm consistent gains under distribution shifts. These results validate that leveraging stable structures across interface changes improves agent performance and generalization in evolving software environments.

</details>


### [29] [MATA: A Trainable Hierarchical Automaton System for Multi-Agent Visual Reasoning](https://arxiv.org/abs/2601.19204)
*Zhixi Cai,Fucai Ke,Kevin Leo,Sukai Huang,Maria Garcia de la Banda,Peter J. Stuckey,Hamid Rezatofighi*

Main category: cs.AI

TL;DR: MATA是一个用于视觉推理的多智能体分层可训练自动机系统，通过可训练的超智能体控制顶层状态转移，每个智能体运行基于规则的子自动机，共享内存实现透明执行历史，在多个视觉推理基准上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型虽然感知能力强，但隐含推理难以解释，在复杂查询上容易产生幻觉。组合方法虽然提高了可解释性，但大多依赖单一智能体或手工设计的流程，无法决定何时在互补智能体间协作或在重叠智能体间竞争。

Method: 提出MATA（多智能体分层可训练自动机），作为分层有限状态自动机用于视觉推理，顶层转移由可训练的超智能体选择。每个智能体对应超自动机中的一个状态，运行小型基于规则的子自动机进行可靠的微控制。所有智能体读写共享内存，产生透明的执行历史。为监督超智能体的转移策略，构建转移轨迹树并转换为内存到下一状态对，形成MATA-SFT-90K数据集用于监督微调。

Result: 在多个视觉推理基准测试中，MATA相比单体模型和组合基线方法取得了最先进的结果。微调后的LLM作为转移策略能够理解查询和智能体能力，并能高效选择最优智能体解决任务。

Conclusion: MATA通过多智能体分层可训练自动机框架，在保持可解释性的同时提高了视觉推理性能，解决了现有方法在复杂查询上的幻觉问题，并通过共享内存和透明执行历史增强了系统的可解释性。

Abstract: Recent vision-language models have strong perceptual ability but their implicit reasoning is hard to explain and easily generates hallucinations on complex queries. Compositional methods improve interpretability, but most rely on a single agent or hand-crafted pipeline and cannot decide when to collaborate across complementary agents or compete among overlapping ones. We introduce MATA (Multi-Agent hierarchical Trainable Automaton), a multi-agent system presented as a hierarchical finite-state automaton for visual reasoning whose top-level transitions are chosen by a trainable hyper agent. Each agent corresponds to a state in the hyper automaton, and runs a small rule-based sub-automaton for reliable micro-control. All agents read and write a shared memory, yielding transparent execution history. To supervise the hyper agent's transition policy, we build transition-trajectory trees and transform to memory-to-next-state pairs, forming the MATA-SFT-90K dataset for supervised finetuning (SFT). The finetuned LLM as the transition policy understands the query and the capacity of agents, and it can efficiently choose the optimal agent to solve the task. Across multiple visual reasoning benchmarks, MATA achieves the state-of-the-art results compared with monolithic and compositional baselines. The code and dataset are available at https://github.com/ControlNet/MATA.

</details>


### [30] [Beyond In-Domain Detection: SpikeScore for Cross-Domain Hallucination Detection](https://arxiv.org/abs/2601.19245)
*Yongxin Deng,Zhen Fang,Yixuan Li,Ling Chen*

Main category: cs.AI

TL;DR: 提出SpikeScore方法，通过量化多轮对话中的不确定性突变来检测幻觉，在跨域幻觉检测任务上表现优异


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测方法在训练和测试数据来自同一领域时表现良好，但跨域泛化能力差。需要解决在单一领域训练却能跨多个相关领域保持鲁棒性能的通用幻觉检测问题。

Method: 提出SpikeScore评分方法，基于观察到的现象：幻觉引发的多轮对话比事实性对话表现出更大的不确定性波动。该方法量化多轮对话中的突发性波动，通过理论分析和实证验证证明其能有效区分幻觉和非幻觉响应。

Result: 在多个LLM和基准测试上的实验表明，基于SpikeScore的检测方法在跨域泛化方面优于代表性基线方法，甚至超越了先进的面向泛化的方法。

Conclusion: SpikeScore方法通过分析多轮对话中的不确定性波动模式，为跨域幻觉检测提供了有效的解决方案，验证了该方法在跨域幻觉检测中的有效性。

Abstract: Hallucination detection is critical for deploying large language models (LLMs) in real-world applications. Existing hallucination detection methods achieve strong performance when the training and test data come from the same domain, but they suffer from poor cross-domain generalization. In this paper, we study an important yet overlooked problem, termed generalizable hallucination detection (GHD), which aims to train hallucination detectors on data from a single domain while ensuring robust performance across diverse related domains. In studying GHD, we simulate multi-turn dialogues following LLMs initial response and observe an interesting phenomenon: hallucination-initiated multi-turn dialogues universally exhibit larger uncertainty fluctuations than factual ones across different domains. Based on the phenomenon, we propose a new score SpikeScore, which quantifies abrupt fluctuations in multi-turn dialogues. Through both theoretical analysis and empirical validation, we demonstrate that SpikeScore achieves strong cross-domain separability between hallucinated and non-hallucinated responses. Experiments across multiple LLMs and benchmarks demonstrate that the SpikeScore-based detection method outperforms representative baselines in cross-domain generalization and surpasses advanced generalization-oriented methods, verifying the effectiveness of our method in cross-domain hallucination detection.

</details>


### [31] [GLOVE: Global Verifier for LLM Memory-Environment Realignment](https://arxiv.org/abs/2601.19249)
*Xingkun Yin,Hongyang Du*

Main category: cs.AI

TL;DR: GLOVE框架为LLM记忆系统引入相对真理概念，通过主动探测记忆与观察的不一致性实现记忆-环境对齐，无需真实监督或模型内省，在动态漂移环境中提升智能体成功率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM记忆增强方法假设记忆有效性可通过外部评估器或模型内省建立，但在动态漂移的实际环境中这些假设往往失效，需要更鲁棒的记忆验证机制。

Method: 提出GLOVE框架，建立相对真理概念，通过主动探测检索记忆与新鲜观察之间的不一致性，实现记忆-环境重新对齐，无需真实监督或强依赖模型内省。

Result: 在网页导航、规划和控制等多样化基准测试中，GLOVE显著提高了智能体成功率，特别是在引入超出原始设置的非平稳性环境漂移的情况下。

Conclusion: GLOVE为认知智能体提供了一条自我演化的稳健路径，通过相对真理验证机制使LLM记忆系统能够适应动态变化的环境。

Abstract: Most existing memory-enhanced Large Language Model (LLM) approaches implicitly assume that memory validity can be established either through external evaluators that provide task-specific success signals or through internal model cognition, such as reflection, for editing memory entries. However, these assumptions often break down in practical environments with dynamic drifts. We propose the Global Verifier (GLOVE), a framework that introduces a new design dimension for LLM memory systems by establishing a relative notion of truth. Through active probing to detect inconsistencies between retrieved memories and fresh observations, GLOVE enables memory-environment realignment by verifying and updating memory without access to ground-truth supervision or strong reliance on model introspection. We evaluate GLOVE on diverse benchmarks spanning web navigation, planning, and control, augmented with controlled environmental drifts that introduce non-stationarity beyond the original benchmark settings. Our results show that GLOVE substantially improves agent success rates, suggesting a robust pathway to cognitive agents capable of self-evolving.

</details>


### [32] [Curiosity Driven Knowledge Retrieval for Mobile Agents](https://arxiv.org/abs/2601.19306)
*Sijia Li,Xiaoyu Tan,Shahir Ali,Niels Schmidt,Gengchen Ma,Xihe Qiu*

Main category: cs.AI

TL;DR: 提出好奇心驱动的知识检索框架，通过AppCards结构化编码应用信息，提升移动智能体在复杂应用中的执行可靠性


<details>
  <summary>Details</summary>
Motivation: 移动智能体在智能手机自动化方面已有进展，但在复杂应用中仍受限于知识不完整和对未见环境的泛化能力弱

Method: 引入好奇心驱动知识检索框架，将执行不确定性量化为好奇心分数；超过阈值时从文档、代码库和历史轨迹检索信息；组织成结构化AppCards，编码功能语义、参数约定、接口映射和交互模式；增强型智能体在执行时选择性集成相关AppCards进行推理

Result: 在AndroidWorld基准测试中，所有骨干模型均获得一致改进，平均提升6个百分点；结合GPT-5时达到88.8%的最新SOTA成功率；AppCards对多步骤和跨应用任务特别有效；改进效果取决于骨干模型；案例研究证实AppCards减少歧义、缩短探索、支持稳定执行轨迹

Conclusion: 好奇心驱动的知识检索框架通过结构化AppCards有效补偿移动智能体的知识盲点，显著提升复杂任务中的规划和执行可靠性

Abstract: Mobile agents have made progress toward reliable smartphone automation, yet performance in complex applications remains limited by incomplete knowledge and weak generalization to unseen environments. We introduce a curiosity driven knowledge retrieval framework that formalizes uncertainty during execution as a curiosity score. When this score exceeds a threshold, the system retrieves external information from documentation, code repositories, and historical trajectories. Retrieved content is organized into structured AppCards, which encode functional semantics, parameter conventions, interface mappings, and interaction patterns. During execution, an enhanced agent selectively integrates relevant AppCards into its reasoning process, thereby compensating for knowledge blind spots and improving planning reliability. Evaluation on the AndroidWorld benchmark shows consistent improvements across backbones, with an average gain of six percentage points and a new state of the art success rate of 88.8\% when combined with GPT-5. Analysis indicates that AppCards are particularly effective for multi step and cross application tasks, while improvements depend on the backbone model. Case studies further confirm that AppCards reduce ambiguity, shorten exploration, and support stable execution trajectories. Task trajectories are publicly available at https://lisalsj.github.io/Droidrun-appcard/.

</details>


### [33] [Balancing Sustainability And Performance: The Role Of Small-Scale Llms In Agentic Artificial Intelligence Systems](https://arxiv.org/abs/2601.19311)
*Anh Khoa Ngo Ho,Martin Chauvin,Simon Gosset,Philippe Cordier,Boris Gamazaychikov*

Main category: cs.AI

TL;DR: 小型开源语言模型在保持任务质量的同时可显著降低能耗，为可持续AI系统设计提供实用指南


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型成为智能代理系统的核心，其推理阶段的高能耗可能带来可持续性挑战。研究旨在探索是否可以通过部署较小规模的语言模型来减少能耗，同时不影响多智能体真实环境中的响应性和输出质量。

Method: 对不同规模的语言模型进行对比分析，量化效率与性能之间的权衡关系。基于研究结果，提出可持续AI设计的实用指南，包括最优批处理大小配置和计算资源分配策略。

Result: 研究表明，较小的开源权重模型能够降低能源使用，同时保持任务质量。这为在效率与性能之间找到平衡提供了实证依据。

Conclusion: 研究结果为开发可扩展、环境友好的AI系统提供了可操作的策略，强调了在AI系统设计中考虑能源效率的重要性，为可持续AI实践提供了具体指导。

Abstract: As large language models become integral to agentic artificial intelligence systems, their energy demands during inference may pose significant sustainability challenges. This study investigates whether deploying smaller-scale language models can reduce energy consumption without compromising responsiveness and output quality in a multi-agent, real-world environments. We conduct a comparative analysis across language models of varying scales to quantify trade-offs between efficiency and performance. Results show that smaller open-weights models can lower energy usage while preserving task quality. Building on these findings, we propose practical guidelines for sustainable artificial intelligence design, including optimal batch size configuration and computation resource allocation. These insights offer actionable strategies for developing scalable, environmentally responsible artificial intelligence systems.

</details>


### [34] [SETA: Statistical Fault Attribution for Compound AI Systems](https://arxiv.org/abs/2601.19337)
*Sayak Chowdhury,Meenakshi D'Souza*

Main category: cs.AI

TL;DR: 提出模块化鲁棒性测试框架，用于多网络AI系统的组件级分析和错误传播推理


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒性测试技术主要针对单网络模型，无法有效扩展到多网络管道系统，需要新的测试方法

Method: 提出模块化鲁棒性测试框架，支持组件级系统分析和跨神经网络模块的错误传播推理，架构和模态无关

Result: 在真实世界铁路自主检测系统上成功应用，实现比传统端到端指标更细粒度的鲁棒性分析

Conclusion: 模块化测试框架能有效解决多网络AI系统的鲁棒性测试挑战，支持跨领域的细粒度分析

Abstract: Modern AI systems increasingly comprise multiple interconnected neural networks to tackle complex inference tasks. Testing such systems for robustness and safety entails significant challenges. Current state-of-the-art robustness testing techniques, whether black-box or white-box, have been proposed and implemented for single-network models and do not scale well to multi-network pipelines. We propose a modular robustness testing framework that applies a given set of perturbations to test data. Our testing framework supports (1) a component-wise system analysis to isolate errors and (2) reasoning about error propagation across the neural network modules. The testing framework is architecture and modality agnostic and can be applied across domains. We apply the framework to a real-world autonomous rail inspection system composed of multiple deep networks and successfully demonstrate how our approach enables fine-grained robustness analysis beyond conventional end-to-end metrics.

</details>


### [35] [PROTEUS: SLA-Aware Routing via Lagrangian RL for Multi-LLM Serving Systems](https://arxiv.org/abs/2601.19402)
*Amit Singh Bhatti,Vishal Vaddina,Dagnachew Birru*

Main category: cs.AI

TL;DR: PROTEUS是一个接受准确率目标τ作为运行时输入的LLM路由器，使用拉格朗日对偶控制，通过单一训练模型满足全准确率谱系需求，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 现有LLM路由器需要离线调参并猜测准确率结果，参数与结果关系间接、非单调且依赖数据集。运营商需要直接指定准确率目标，而不是从模糊设置中推断。

Method: 使用拉格朗日对偶控制方法，学习对偶变量λ跟踪训练期间的约束违反情况，并调节策略网络，使路由器能将指定的τ值转换为满足要求的路由决策。

Result: 在RouterBench(11模型,405K查询)和SPROUT(14模型,45K查询)上评估，PROTEUS实现一致的地板合规性，准确率达到或超过τ。目标响应相关性达0.97-0.98，而最接近的基线OmniRouter仅22%时间满足地板要求。单模型支持τ∈[0.85,0.95]范围。

Conclusion: PROTEUS通过接受准确率目标作为输入并提供拉格朗日对偶控制，解决了LLM路由中参数设置不透明的问题，实现了准确率目标的可控性和成本效益，相比最佳固定模型节省89.8%成本。

Abstract: Production LLM deployments serve diverse workloads where cost and quality requirements vary by customer tier, time of day, and query criticality. Model serving systems accept latency SLOs directly. LLM routers do not. They force operators to tune parameters offline and guess what accuracy might result. The relationship between parameters and outcomes is indirect, non-monotonic, and dataset-dependent. Operators need to specify accuracy targets, not infer them from opaque settings. We present PROTEUS (Polymorphic Router for Operational Target Enforcement with Unified SLA), a router that accepts accuracy targets tau as runtime input. PROTEUS uses Lagrangian dual control. A learned dual variable lambda tracks constraint violations during training and conditions the policy network. This lets the router translate specified tau values into routing decisions that satisfy them. A single trained model serves the full accuracy spectrum without retraining.We evaluate on RouterBench (11 models, 405K queries) and SPROUT (14 models, 45K queries). PROTEUS achieves consistent floor compliance where accuracy meets or exceeds tau. The target-response correlation reaches 0.97 to 0.98. The closest baseline, OmniRouter, meets floors only 22% of the time despite also using Lagrangian optimization. PROTEUS operates across tau in [0.85, 0.95] from a single model. On RouterBench it achieves 90.1% accuracy, within 1.3% of oracle. On SPROUT it achieves 94.0% accuracy, within 4.6% of oracle. Cost savings reach 89.8% versus the best fixed model.

</details>


### [36] [RPO:Reinforcement Fine-Tuning with Partial Reasoning Optimization](https://arxiv.org/abs/2601.19404)
*Hongzhu Yi,Xinming Wang,Zhenghao zhang,Tianyu Zong,Yuanxiang Wang,Jun Xie,Tao Yu,Haopeng Jin,Zhepeng Wang,Kaixin Xu,Feng Chen,Jiahuan Chen,Yujia Yang,Zhenyu Guan,Bingkang Shi,Jungang Xu*

Main category: cs.AI

TL;DR: RPO通过仅生成推理路径的后缀进行强化微调，减少95%的rollout阶段token生成，显著降低训练时间，同时保持性能


<details>
  <summary>Details</summary>
Motivation: 传统强化微调算法需要生成完整的推理轨迹，导致rollout阶段计算开销巨大。需要一种方法来减少训练时的token生成量，降低时间成本

Method: 提出RPO算法，分析推理路径不同部分对最终结果的影响，仅生成推理路径的后缀进行训练，利用经验缓存，可与其他算法如GRPO、DAPO集成

Result: RPO减少rollout阶段约95%的token生成，1.5B模型训练时间减少90%，7B模型减少72%，同时保持与原始算法相当的性能

Conclusion: RPO是一种有效的即插即用强化微调算法，能显著降低训练时间成本，同时保持模型性能，为大规模语言模型的高效训练提供了新思路

Abstract: Within the domain of large language models, reinforcement fine-tuning algorithms necessitate the generation of a complete reasoning trajectory beginning from the input query, which incurs significant computational overhead during the rollout phase of training. To address this issue, we analyze the impact of different segments of the reasoning path on the correctness of the final result and, based on these insights, propose Reinforcement Fine-Tuning with Partial Reasoning Optimization (RPO), a plug-and-play reinforcement fine-tuning algorithm. Unlike traditional reinforcement fine-tuning algorithms that generate full reasoning paths, RPO trains the model by generating suffixes of the reasoning path using experience cache. During the rollout phase of training, RPO reduces token generation in this phase by approximately 95%, greatly lowering the theoretical time overhead. Compared with full-path reinforcement fine-tuning algorithms, RPO reduces the training time of the 1.5B model by 90% and the 7B model by 72%. At the same time, it can be integrated with typical algorithms such as GRPO and DAPO, enabling them to achieve training acceleration while maintaining performance comparable to the original algorithms. Our code is open-sourced at https://github.com/yhz5613813/RPO.

</details>


### [37] [Fuzzy expert system for the process of collecting and purifying acidic water: a digital twin approach](https://arxiv.org/abs/2601.19527)
*Temirbolat Maratuly,Pakizar Shamoi,Timur Samigulin*

Main category: cs.AI

TL;DR: 本文提出了一种结合模糊专家系统和数字孪生的控制策略，用于净化酸性水处理过程，通过模拟人类推理来维持关键参数在期望水平。


<details>
  <summary>Details</summary>
Motivation: 酸性水净化对于减少排放、降低腐蚀风险、实现处理水在工业或家庭应用中的再利用以及最终降低运营成本至关重要。自动化净化过程有助于减少工人伤害风险。原油中的酸性成分（如硫化氢、二氧化碳等）在加工过程中会部分释放到酸性水中，如果不妥善处理，会对环境造成严重威胁并加速管道和设备腐蚀。

Method: 开发了模糊专家系统与定制生成的数字孪生相结合的方法。数字孪生使用Honeywell UniSim Design R492开发以准确模拟工业行为，阀门动态通过MATLAB系统识别建模，使用OPC DA建立模拟器与控制器之间的实时数据交换。模糊控制器对两个阀门应用分程控制，在21种不同初始压力条件下使用5种去模糊化策略进行了测试（共105个测试场景）。

Result: 系统性能使用误差指标（MSE、RMSE、MAE、IAE、ISE、ITAE）和动态响应指标（超调量、欠调量、上升时间、下降时间、调节时间、稳态误差）进行评估。开发了基于Python Streamlit框架的Web模拟界面。

Conclusion: 虽然本文以酸性水处理为例进行演示，但所提出的模糊专家系统是通用型的，控制策略简单直观，允许初级或非专业人员有效与系统交互。

Abstract: Purifying sour water is essential for reducing emissions, minimizing corrosion risks, enabling the reuse of treated water in industrial or domestic applications, and ultimately lowering operational costs. Moreover, automating the purification process helps reduce the risk of worker harm by limiting human involvement. Crude oil contains acidic components such as hydrogen sulfide, carbon dioxide, and other chemical compounds. During processing, these substances are partially released into sour water. If not properly treated, sour water poses serious environmental threats and accelerates the corrosion of pipelines and equipment. This paper presents a fuzzy expert system, combined with a custom-generated digital twin, developed from a documented industrial process to maintain key parameters at desired levels by mimicking human reasoning. The control strategy is designed to be simple and intuitive, allowing junior or non-expert personnel to interact with the system effectively. The digital twin was developed using Honeywell UniSim Design R492 to simulate real industrial behavior accurately. Valve dynamics were modeled through system identification in MATLAB, and real-time data exchange between the simulator and controller was established using OPC DA. The fuzzy controller applies split-range control to two valves and was tested under 21 different initial pressure conditions using five distinct defuzzification strategies, resulting in a total of 105 unique test scenarios. System performance was evaluated using both error-based metrics (MSE, RMSE, MAE, IAE, ISE, ITAE) and dynamic response metrics, including overshoot, undershoot, rise time, fall time, settling time, and steady-state error. A web-based simulation interface was developed in Python using the Streamlit framework. Although demonstrated here for sour water treatment, the proposed fuzzy expert system is general-purpose.

</details>


### [38] [Benchmarks Saturate When The Model Gets Smarter Than The Judge](https://arxiv.org/abs/2601.19532)
*Marthe Ballon,Andres Algaba,Brecht Verbeken,Vincent Ginis*

Main category: cs.AI

TL;DR: Omni-MATH-2是一个经过人工修订的数学数据集，包含4181个精确答案问题和247个标记的非标准问题，通过审核确保可编译性、可解性和可验证性，显著减少数据集噪声，提供更精确的模型性能评估。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLM）基准测试存在数据集和评估方法不准确的问题，这削弱了基准测试的有效性。作者旨在通过创建更高质量的数据集来减少数据集噪声，提供更精确的模型性能评估。

Method: 创建Omni-MATH-2数据集：1）手动审核原始Omni-MATH数据集；2）确保LaTeX可编译性、问题可解性和答案可验证性；3）添加缺失的图表或信息；4）标记需要证明、估计或图像的问题；5）移除杂乱内容；6）使用专家标注评估法官噪声，比较GPT-5 mini与原始Omni-Judge的差异。

Result: 1）创建了包含4181个精确答案问题和247个标记非标准问题的清洁数据集；2）发现Omni-Judge在96.4%的法官分歧中判断错误，表明其无法区分模型能力；3）随着问题难度增加，需要更胜任的法官来防止法官错误掩盖模型间的真实差异；4）两种法官都无法识别标记问题子集的失败模式。

Conclusion: 数据集质量和法官可靠性对于开发准确的模型性能基准测试都至关重要。仅改进数据集不足以确保准确的评估，还需要高质量的评估方法。随着问题难度增加，对胜任法官的需求变得更加关键。

Abstract: Benchmarks are important tools to track progress in the development of Large Language Models (LLMs), yet inaccuracies in datasets and evaluation methods consistently undermine their effectiveness. Here, we present Omni-MATH-2, a manually revised version of the Omni-MATH dataset comprising a clean, exact-answer subset ($n{=}4181$) and a tagged, non-standard subset ($n{=}247$). Each problem was audited to ensure LaTeX compilability, solvability and verifiability, which involved adding missing figures or information, labeling problems requiring a proof, estimation or image, and removing clutter. This process significantly reduces dataset-induced noise, thereby providing a more precise assessment of model performance. The annotated dataset also allows us to evaluate judge-induced noise by comparing GPT-5 mini with the original Omni-Judge, revealing substantial discrepancies between judges on both the clean and tagged problem subsets. Expert annotations reveal that Omni-Judge is wrong in $96.4\%$ of the judge disagreements, indicating its inability to differentiate between models' abilities, even well before saturation of the benchmark occurs. As problems become more challenging, we find that increasingly competent judges become essential in order to prevent judge errors from masking genuine differences between models. Finally, neither judge identifies the present failure modes for the subset of tagged problems, demonstrating that dataset quality and judge reliability are both critical to develop accurate benchmarks of model performance.

</details>


### [39] [Learning Adaptive Parallel Execution for Efficient Code Localization](https://arxiv.org/abs/2601.19568)
*Ke Xu,Siyang Xiao,Ming Liang,Yichen Yu,Zhixiang Wang,Jingxuan Xu,Dajun Chen,Wei Jiang,Yong Li*

Main category: cs.AI

TL;DR: FuseSearch通过联合质量-效率优化，动态调整并行搜索广度，显著提升代码定位效率，减少冗余调用


<details>
  <summary>Details</summary>
Motivation: 当前自动化软件开发管道中，代码定位是关键瓶颈。虽然并行工具执行能提升发现速度，但现有代理存在34.9%的冗余调用率，抵消了并行化的优势。

Method: 提出FuseSearch，将并行代码定位重新定义为联合质量-效率优化任务。定义工具效率（独特信息增益与调用次数的比率），采用两阶段SFT和RL训练方法学习自适应并行策略。与固定广度方法不同，FuseSearch根据任务上下文动态调整搜索广度，从探索阶段演进到细化阶段。

Result: 在SWE-bench Verified上评估，FuseSearch-4B达到SOTA水平性能（84.7%文件级和56.4%函数级F1分数），实现93.6%加速，使用轮次减少67.7%，令牌数减少68.9%。

Conclusion: 效率感知训练通过消除噪声冗余信号自然提升质量，实现了高性能、成本效益高的定位代理。

Abstract: Code localization constitutes a key bottleneck in automated software development pipelines. While concurrent tool execution can enhance discovery speed, current agents demonstrate a 34.9\% redundant invocation rate, which negates parallelism benefits. We propose \textbf{FuseSearch}, reformulating parallel code localization as a \textbf{joint quality-efficiency optimization} task. Through defining \textbf{tool efficiency} -- the ratio of unique information gain to invocation count -- we utilize a two-phase SFT and RL training approach for learning adaptive parallel strategies. Different from fixed-breadth approaches, FuseSearch dynamically modulates search breadth according to task context, evolving from exploration phases to refinement stages. Evaluated on SWE-bench Verified, FuseSearch-4B achieves SOTA-level performance (84.7\% file-level and 56.4\% function-level $F_1$ scores) with 93.6\% speedup, utilizing 67.7\% fewer turns and 68.9\% fewer tokens. Results indicate that efficiency-aware training naturally improves quality through eliminating noisy redundant signals, enabling high-performance cost-effective localization agents.

</details>


### [40] [ComAgent: Multi-LLM based Agentic AI Empowered Intelligent Wireless Networks](https://arxiv.org/abs/2601.19607)
*Haoyun Li,Ming Xiao,Kezhi Wang,Robert Schober,Dong In Kim,Yong Liang Guan*

Main category: cs.AI

TL;DR: ComAgent是一个多LLM代理AI框架，采用感知-规划-行动-反思闭环，将高层意图自动转化为6G网络优化问题的数学公式和可执行代码。


<details>
  <summary>Details</summary>
Motivation: 6G网络需要复杂的跨层优化，但将高层意图手动转化为数学公式存在瓶颈。现有LLM方法缺乏足够的领域知识、约束意识和验证能力。

Method: 提出ComAgent多LLM代理框架，采用感知-规划-行动-反思闭环循环，协调文献搜索、编码和评分等专门代理，通过迭代分解问题和自我纠错，自主生成求解器就绪的公式和可重复仿真。

Result: ComAgent在复杂波束成形优化中达到专家可比性能，在多样化无线任务中优于单体LLM，展示了在无线网络设计中自动化的潜力。

Conclusion: ComAgent框架有效弥合了用户意图与执行之间的差距，为新兴无线网络的自动化设计提供了有前景的解决方案。

Abstract: Emerging 6G networks rely on complex cross-layer optimization, yet manually translating high-level intents into mathematical formulations remains a bottleneck. While Large Language Models (LLMs) offer promise, monolithic approaches often lack sufficient domain grounding, constraint awareness, and verification capabilities. To address this, we present ComAgent, a multi-LLM agentic AI framework. ComAgent employs a closed-loop Perception-Planning-Action-Reflection cycle, coordinating specialized agents for literature search, coding, and scoring to autonomously generate solver-ready formulations and reproducible simulations. By iteratively decomposing problems and self-correcting errors, the framework effectively bridges the gap between user intent and execution. Evaluations demonstrate that ComAgent achieves expert-comparable performance in complex beamforming optimization and outperforms monolithic LLMs across diverse wireless tasks, highlighting its potential for automating design in emerging wireless networks.

</details>


### [41] [Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design for A* Search](https://arxiv.org/abs/2601.19622)
*Thomas Bömer,Nico Koltermann,Max Disselnmeyer,Bastian Amberg,Anne Meyer*

Main category: cs.AI

TL;DR: 本文提出A-CEoH框架，通过将A*算法代码融入提示词，利用上下文学习自动生成A*搜索的启发式函数，在UPMP和SPP问题上超越人工设计的启发式函数。


<details>
  <summary>Details</summary>
Motivation: 传统启发式函数需要人工设计，依赖专家知识且耗时。随着大语言模型和进化框架的发展，自动化启发式设计成为可能。本文旨在扩展EoH框架，探索A*搜索启发式函数的自动生成。

Method: 提出A-CEoH（Algorithmic-Contextual EoH）框架，采用领域无关的提示增强策略，将A*算法代码融入提示词以利用上下文学习。在单元装载预整理问题（UPMP）和经典滑块拼图问题（SPP）上进行评估。

Result: 计算实验表明，A-CEoH能显著提升生成启发式函数的质量，在UPMP和SPP问题上甚至超越专家设计的启发式函数。

Conclusion: A-CEoH框架通过算法上下文学习有效自动化启发式函数设计，展示了在复杂搜索问题中超越人工设计的潜力，为启发式函数自动生成提供了新方向。

Abstract: Heuristic functions are essential to the performance of tree search algorithms such as A*, where their accuracy and efficiency directly impact search outcomes. Traditionally, such heuristics are handcrafted, requiring significant expertise. Recent advances in large language models (LLMs) and evolutionary frameworks have opened the door to automating heuristic design. In this paper, we extend the Evolution of Heuristics (EoH) framework to investigate the automated generation of guiding heuristics for A* search. We introduce a novel domain-agnostic prompt augmentation strategy that includes the A* code into the prompt to leverage in-context learning, named Algorithmic - Contextual EoH (A-CEoH). To evaluate the effectiveness of A-CeoH, we study two problem domains: the Unit-Load Pre-Marshalling Problem (UPMP), a niche problem from warehouse logistics, and the classical sliding puzzle problem (SPP). Our computational experiments show that A-CEoH can significantly improve the quality of the generated heuristics and even outperform expert-designed heuristics.

</details>


### [42] [Agentic Design Patterns: A System-Theoretic Framework](https://arxiv.org/abs/2601.19752)
*Minh-Dung Dao,Quy Minh Le,Hoang Thanh Lam,Duc-Trong Le,Quoc-Viet Pham,Barry O'Sullivan,Hoang D. Nguyen*

Main category: cs.AI

TL;DR: 提出基于系统理论的AI智能体工程化方法，包括五子系统框架和12个设计模式，用于构建可靠、模块化的自主系统。


<details>
  <summary>Details</summary>
Motivation: 当前基于基础模型的智能体系统存在幻觉、推理能力差等问题，且设计模式缺乏严谨的系统理论基础，导致应用不可靠和脆弱。现有分类方法多为高层级或便利性导向，难以实施。

Method: 1) 提出系统理论框架，将智能体系统解构为五个核心交互功能子系统：推理与世界模型、感知与接地、动作执行、学习与适应、智能体间通信；2) 基于该架构推导出12个智能体设计模式，分为基础类、认知决策类、执行交互类、适应学习类。

Result: 通过ReAct框架的案例研究展示了该框架的实用性，表明所提出的设计模式能够纠正系统性架构缺陷。为研究人员和工程师提供了标准化的智能体设计语言和方法论。

Conclusion: 该工作提供了基础语言和结构化方法论，用于标准化智能体设计交流，能够构建更模块化、可理解和可靠的自主系统。

Abstract: With the development of foundation model (FM), agentic AI systems are getting more attention, yet their inherent issues like hallucination and poor reasoning, coupled with the frequent ad-hoc nature of system design, lead to unreliable and brittle applications. Existing efforts to characterise agentic design patterns often lack a rigorous systems-theoretic foundation, resulting in high-level or convenience-based taxonomies that are difficult to implement. This paper addresses this gap by introducing a principled methodology for engineering robust AI agents. We propose two primary contributions: first, a novel system-theoretic framework that deconstructs an agentic AI system into five core, interacting functional subsystems: Reasoning & World Model, Perception & Grounding, Action Execution, Learning & Adaptation, and Inter-Agent Communication. Second, derived from this architecture and directly mapped to a comprehensive taxonomy of agentic challenges, we present a collection of 12 agentic design patterns. These patterns - categorised as Foundational, Cognitive & Decisional, Execution & Interaction, and Adaptive & Learning - offer reusable, structural solutions to recurring problems in agent design. The utility of the framework is demonstrated by a case study on the ReAct framework, showing how the proposed patterns can rectify systemic architectural deficiencies. This work provides a foundational language and a structured methodology to standardise agentic design communication among researchers and engineers, leading to more modular, understandable, and reliable autonomous systems.

</details>


### [43] [GAVEL: Towards rule-based safety through activation monitoring](https://arxiv.org/abs/2601.19768)
*Shir Rozenfeld,Rahul Pankajakshan,Itay Zloczower,Eyal Lenga,Gilad Gressel,Yisroel Mirsky*

Main category: cs.AI

TL;DR: 本文提出基于规则的激活安全新范式，将LLM激活建模为可组合的认知元素，通过谓词规则实时检测违规行为，实现高精度、可定制、可解释的AI安全治理。


<details>
  <summary>Details</summary>
Motivation: 现有基于激活的安全方法存在精度低、灵活性差、缺乏可解释性等问题，无法有效检测表面文本不明显的恶意行为，需要更精确、可定制、可解释的安全框架。

Method: 提出基于规则的激活安全范式：1) 将激活建模为细粒度、可解释的认知元素；2) 在认知元素上定义谓词规则；3) 实时检测规则违规；4) 提供开源框架GAVEL和自动化规则创建工具。

Result: 基于规则的激活安全方法提高了检测精度，支持领域定制化，为可扩展、可解释、可审计的AI治理奠定了基础。

Conclusion: 基于规则的激活安全范式通过认知元素和谓词规则，实现了比传统方法更高精度、更灵活、更可解释的AI安全检测，为AI治理提供了实用框架。

Abstract: Large language models (LLMs) are increasingly paired with activation-based monitoring to detect and prevent harmful behaviors that may not be apparent at the surface-text level. However, existing activation safety approaches, trained on broad misuse datasets, struggle with poor precision, limited flexibility, and lack of interpretability. This paper introduces a new paradigm: rule-based activation safety, inspired by rule-sharing practices in cybersecurity. We propose modeling activations as cognitive elements (CEs), fine-grained, interpretable factors such as ''making a threat'' and ''payment processing'', that can be composed to capture nuanced, domain-specific behaviors with higher precision. Building on this representation, we present a practical framework that defines predicate rules over CEs and detects violations in real time. This enables practitioners to configure and update safeguards without retraining models or detectors, while supporting transparency and auditability. Our results show that compositional rule-based activation safety improves precision, supports domain customization, and lays the groundwork for scalable, interpretable, and auditable AI governance. We will release GAVEL as an open-source framework and provide an accompanying automated rule creation tool.

</details>


### [44] [CASTER: Breaking the Cost-Performance Barrier in Multi-Agent Orchestration via Context-Aware Strategy for Task Efficient Routing](https://arxiv.org/abs/2601.19793)
*Shanyv Liu,Xuyang Yuan,Tao Chen,Zijun Zhan,Zhu Han,Danyang Zheng,Weishan Zhang,Shaohua Cao*

Main category: cs.AI

TL;DR: CASTER是一个用于图基多智能体系统的轻量级路由器，通过动态模型选择减少推理成本达72.4%，同时保持与强模型基线相当的成功率。


<details>
  <summary>Details</summary>
Motivation: 图基多智能体系统虽然支持复杂循环工作流，但静态模型分配效率低下，统一部署强模型在简单子任务上浪费计算资源。

Method: CASTER采用双信号路由器，结合语义嵌入和结构元特征来估计任务难度，通过冷启动到迭代演化的训练范式，从自身路由失败中学习（基于策略的负反馈）。

Result: 在软件工程、数据分析、科学发现和网络安全四个领域的LLM-as-a-Judge评估中，CASTER相比强模型基线减少推理成本达72.4%，同时匹配其成功率，并持续优于启发式路由和FrugalGPT。

Conclusion: CASTER为图基多智能体系统提供了一种高效、自适应的动态模型选择方案，显著降低计算成本而不牺牲性能。

Abstract: Graph-based Multi-Agent Systems (MAS) enable complex cyclic workflows but suffer from inefficient static model allocation, where deploying strong models uniformly wastes computation on trivial sub-tasks. We propose CASTER (Context-Aware Strategy for Task Efficient Routing), a lightweight router for dynamic model selection in graph-based MAS. CASTER employs a Dual-Signal Router that combines semantic embeddings with structural meta-features to estimate task difficulty. During training, the router self-optimizes through a Cold Start to Iterative Evolution paradigm, learning from its own routing failures via on-policy negative feedback. Experiments using LLM-as-a-Judge evaluation across Software Engineering, Data Analysis, Scientific Discovery, and Cybersecurity demonstrate that CASTER reduces inference cost by up to 72.4% compared to strong-model baselines while matching their success rates, and consistently outperforms both heuristic routing and FrugalGPT across all domains.

</details>


### [45] [Routing End User Queries to Enterprise Databases](https://arxiv.org/abs/2601.19825)
*Saikrishna Sudarshan,Tanay Kulkarni,Manasi Patwardhan,Lovekesh Vig,Ashwin Srinivasan,Tanmay Tulsidas Verlekar*

Main category: cs.AI

TL;DR: 该论文提出了一种用于多数据库企业环境中自然语言查询路由的模块化推理驱动重排序策略，通过显式建模模式覆盖、结构连接性和细粒度语义对齐，在扩展的NL-to-SQL基准测试中优于嵌入方法和直接LLM提示方法。


<details>
  <summary>Details</summary>
Motivation: 在多数据库企业环境中，随着数据库规模增大和领域重叠增加，自然语言查询路由变得越来越困难，特别是面对模糊查询时。现有方法在处理大规模、领域重叠的数据库存储库和模糊查询时效果有限，需要更结构化、更鲁棒的基于推理的解决方案。

Method: 提出了一种模块化、推理驱动的重排序策略，通过显式建模三个关键因素：1) 模式覆盖（schema coverage），2) 结构连接性（structural connectivity），3) 细粒度语义对齐（fine-grained semantic alignment）。该方法将查询路由视为重排序问题，结合推理机制来优化路由决策。

Result: 该方法在扩展的NL-to-SQL数据集构建的现实基准测试中，在所有评估指标上一致优于嵌入方法和直接LLM提示基线。特别是在数据库规模增大、领域重叠和查询模糊的情况下，表现出更强的鲁棒性和准确性。

Conclusion: 在多数据库企业环境中，自然语言查询路由需要更结构化的推理方法。通过显式建模模式覆盖、结构连接性和语义对齐的模块化推理驱动策略，能够有效应对大规模、领域重叠数据库和模糊查询带来的挑战，为实际企业应用提供了更可靠的解决方案。

Abstract: We address the task of routing natural language queries in multi-database enterprise environments. We construct realistic benchmarks by extending existing NL-to-SQL datasets. Our study shows that routing becomes increasingly challenging with larger, domain-overlapping DB repositories and ambiguous queries, motivating the need for more structured and robust reasoning-based solutions. By explicitly modelling schema coverage, structural connectivity, and fine-grained semantic alignment, the proposed modular, reasoning-driven reranking strategy consistently outperforms embedding-only and direct LLM-prompting baselines across all the metrics.

</details>


### [46] [Visual Generation Unlocks Human-Like Reasoning through Multimodal World Models](https://arxiv.org/abs/2601.19834)
*Jialong Wu,Xiaoying Zhang,Hongyi Yuan,Xiangcheng Zhang,Tianhao Huang,Changjing He,Chaoyi Deng,Renrui Zhang,Youbin Wu,Mingsheng Long*

Main category: cs.AI

TL;DR: 该研究首次系统探讨视觉生成何时及如何提升推理能力，提出视觉优势假说：在物理世界相关任务中，视觉生成能更自然地作为世界模型，而纯语言模型会遭遇表示限制或先验知识不足的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在数学、编程等抽象领域表现出色，但在物理和空间智能方面远落后于人类。统一多模态模型的出现引发了人们对基于互补多模态路径的人类式推理的兴趣，但其优势尚不明确。需要从世界模型角度研究视觉生成何时及如何有益于推理。

Method: 1) 理论层面：将内部世界建模形式化为CoT推理的核心组件，分析不同形式世界模型的区别；2) 实证层面：识别需要交错视觉-语言CoT推理的任务，构建新的评估套件VisWorld-Eval；3) 在先进统一多模态模型上进行控制实验，比较交错CoT与纯语言CoT的性能。

Result: 在有利于视觉世界建模的任务上，交错CoT显著优于纯语言CoT，但在其他任务上没有明显优势。这验证了视觉优势假说，并澄清了多模态世界建模的潜力。

Conclusion: 该工作阐明了多模态世界建模对于构建更强大、更类人的多模态AI的潜力，为理解视觉生成在推理中的作用提供了原则性框架，并识别了视觉世界建模特别有益的任务类型。

Abstract: Humans construct internal world models and reason by manipulating the concepts within these models. Recent advances in AI, particularly chain-of-thought (CoT) reasoning, approximate such human cognitive abilities, where world models are believed to be embedded within large language models. Expert-level performance in formal and abstract domains such as mathematics and programming has been achieved in current systems by relying predominantly on verbal reasoning. However, they still lag far behind humans in domains like physical and spatial intelligence, which require richer representations and prior knowledge. The emergence of unified multimodal models (UMMs) capable of both verbal and visual generation has therefore sparked interest in more human-like reasoning grounded in complementary multimodal pathways, though their benefits remain unclear. From a world-model perspective, this paper presents the first principled study of when and how visual generation benefits reasoning. Our key position is the visual superiority hypothesis: for certain tasks--particularly those grounded in the physical world--visual generation more naturally serves as world models, whereas purely verbal world models encounter bottlenecks arising from representational limitations or insufficient prior knowledge. Theoretically, we formalize internal world modeling as a core component of CoT reasoning and analyze distinctions among different forms of world models. Empirically, we identify tasks that necessitate interleaved visual-verbal CoT reasoning, constructing a new evaluation suite, VisWorld-Eval. Controlled experiments on a state-of-the-art UMM show that interleaved CoT significantly outperforms purely verbal CoT on tasks that favor visual world modeling, but offers no clear advantage otherwise. Together, this work clarifies the potential of multimodal world modeling for more powerful, human-like multimodal AI.

</details>
