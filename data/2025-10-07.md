<div id=toc></div>

# Table of Contents

- [econ.GN](#econ.GN) [Total: 7]
- [cs.ET](#cs.ET) [Total: 2]
- [cs.RO](#cs.RO) [Total: 55]
- [cs.SY](#cs.SY) [Total: 1]
- [cs.AI](#cs.AI) [Total: 89]
- [cs.SI](#cs.SI) [Total: 4]
- [eess.SY](#eess.SY) [Total: 32]
- [stat.AP](#stat.AP) [Total: 3]
- [cs.CY](#cs.CY) [Total: 17]
- [econ.TH](#econ.TH) [Total: 3]
- [econ.EM](#econ.EM) [Total: 2]


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [1] [How does course recommendation impact student outcomes? Examining directed self-placement with regression discontinuity analysis](https://arxiv.org/abs/2510.03350)
*Jason Godfrey*

Main category: econ.GN

TL;DR: 定向自我安置不会对学生的成绩和通过率产生负面影响，这可能是对处于发展/补习教育门槛附近学生的一种改进。


<details>
  <summary>Details</summary>
Motivation: 传统的发展性教育安置对学生的学业成就、通过概率和获得学分有显著的负面影响，许多大学正在研究替代的安置机制。

Method: 使用纵向数据和因果推断方法，分析了超过20,000名学生的安置记录，控制学生种族、家庭收入和性别等特征变量，采用回归断点设计。

Result: 定向自我安置不会对学生的成绩或通过率产生负面影响。

Conclusion: 虽然安置技术只是构建更公平项目的一部分，但定向自我安置可能是对处于发展/补习教育门槛附近学生的一种改进，但班级、种族和性别的统计差异在整个项目中仍然存在。

Abstract: For many students, placement into developmental education becomes a
self-fulfilling prophecy. Placing college students into developmental education
significantly negatively impacts student attainment, student probability of
passing, and college credits earned. To combat these negative effects, many
universities are investigating alternative placement mechanisms. Could directed
self-placement be an effective alternative mechanism? Do students who
self-place suffer the same negative impacts from placement recommendations as
their traditionally placed counterparts? This paper uses longitudinal data with
causal inference methods to examine whether directed self-placement has similar
negative impacts on student grades and pass rates as mandatory placement
schema. We begin with an analysis of over 20,000 student placement records into
one of two different placement tracks for first-year writing. Longitudinal and
institutional data allow us to control for characteristic variables such as
student race, family income, and sex. The results of our regression
discontinuity design show that directed self-placement does not negatively
impact student grades or pass rate. This may be an improvement for students who
place at or near the threshold for developmental/remedial education; However,
class, race, and gender-based statistical differences persist in the program
at-large, demonstrating that placement technique plays only one part in
building a more equitable program.

</details>


### [2] [Who benefits the most? Direct and indirect effects of a free cesarean section policy in Benin](https://arxiv.org/abs/2510.03658)
*Selidji Caroline Tossou*

Main category: econ.GN

TL;DR: 贝宁免费剖腹产政策评估：显著降低死产和婴儿死亡率18.79%，但增加孕产妇死亡率5.21%，并导致生育率下降和产后劳动力供应减少


<details>
  <summary>Details</summary>
Motivation: 评估贝宁免费剖腹产政策对女性和儿童的因果影响，特别是对孕产妇和婴儿死亡率、家庭规模决策以及劳动力市场参与的影响

Method: 使用西非国家人口与健康调查(DHS)大样本数据，采用双重差分法分析剖腹产用户费用豁免政策的效果

Result: 免费剖腹产政策显著减少死产和婴儿死亡率0.0855(18.79%)，但增加孕产妇死亡率0.00465(5.21%)，并导致生育率下降和产后劳动力供应减少

Conclusion: 政策在降低婴儿死亡率和拯救新生儿方面有效，但损害母亲健康，导致首次生育后生育率下降和产后劳动力供应减少

Abstract: This paper evaluates the causal effect of the access to Benin's free cesarean
section policy on females and their children. I use a large sample of
Demographic and Health Surveys (DHS) for West African countries and analyze how
the exemption of the cesarean section user fees for females in Benin directly
impacts maternal and infant mortality, family size decisions, and labor market
participation. I use a Difference in Differences approach and find that having
access to the free cesarean section policy significantly reduces the number of
stillbirths and infant mortality by 0.0855 (a 18.79 percentage change). Second,
for the surviving children, I find that access to the free cesarean section
increases the likelihood of maternal mortality by 0.00465 (a 5.21 percentage
change). The policy is effective at reducing infant mortality and saving the
newborn. However, it harms the mother's health which translates to lower
fertility after the first birth and decreased maternal labor supply post-birth.

</details>


### [3] [Labor Market Reforms, Flexibility, and Employment Transitions Across Formal and Informal Sectors](https://arxiv.org/abs/2510.03668)
*Selidji Caroline Tossou*

Main category: econ.GN

TL;DR: 研究贝宁2017年劳动力市场改革的影响，该改革降低了裁员成本并允许无限期续签短期合同。研究发现改革增加了正规部门就业、提高了永久合同比例和工资水平，但也导致了短期合同工人的更高流动率。


<details>
  <summary>Details</summary>
Motivation: 评估发展中国家劳动力市场改革（特别是降低裁员成本）对就业、合同类型和工资的实际影响，为政策制定提供实证依据。

Method: 使用统一家庭生活标准调查的微观数据，采用双向固定效应方法，以邻近国家作为对照组，分析改革对就业、工人任期、合同类型和工资的影响。

Result: 改革使正规部门就业增加2.6个百分点（24.5%），非正规就业减少2.8个百分点（3.2%）；正规部门短期合同工人任期减少0.23个月，长期合同任期增加0.15个月；获得永久合同的可能性提高23.2个百分点（41.6%）；正规部门月工资平均增加33.6美元。

Conclusion: 劳动力市场改革促进了就业再分配，揭示了灵活性、就业稳定性和工资之间的复杂权衡关系，为发展中国家劳动力市场政策提供了重要启示。

Abstract: In this paper, I investigate the 2017 labor market reform in Benin, which
reduced firing costs and allowed firms to renew short-term contracts
indefinitely. Using micro-data from the Harmonized Household Living Standards
Surveys and a two-way fixed effect approach with nearby countries as the
control group, I assess the reform's impact on employment, worker tenure,
contract types, and wages. My empirical results reveal a 2.6 percentage point
(24.5 percent) increase in formal sector employment and a 2.8 percentage point
(3.2 percent) reduction in informal employment. Formal sector tenure decreased
by 0.23 months for short-term contract workers, reflecting higher turnover,
while long-term contract tenure increased by 0.15 months. The likelihood of
securing a permanent contract rose by 23.2 percentage points (41.6 percent) in
the formal sector, indicating that firms used long-term contracts to retain
high-productivity workers. Wages in the formal sector increased by 33.6 USD per
month on average, with workers on short-term contracts experiencing a wage
increase of 19.6 USD and those on long-term contracts seeing an increase of
23.4 USD. I complement these findings with a theoretical job search model,
which explains the mechanisms through which lowered firing costs affected firm
hiring decisions, market tightness, and the sorting of workers across sectors.
This study provides robust evidence of labor market reallocation and highlights
the complex trade-offs between flexibility, employment stability, and wages in
a developing country context.

</details>


### [4] [Gas price shocks, uncertainty and price setting: evidences from Italian firms](https://arxiv.org/abs/2510.03792)
*Giuseppe Pagano Giorgianni*

Main category: econ.GN

TL;DR: 本文使用意大利央行的通胀预期调查数据，通过贝叶斯VAR模型分析天然气价格冲击对意大利企业定价决策和通胀预期的影响，发现这些冲击是通胀预期的主要驱动因素，特别是在后疫情时期。


<details>
  <summary>Details</summary>
Motivation: 研究天然气价格冲击如何影响企业的定价行为和通胀预期，特别是在俄罗斯入侵乌克兰导致供应中断引发前所未有的价格压力时期。

Method: 使用贝叶斯VAR模型识别天然气价格冲击，并构建更大的BVAR模型纳入企业层面定价变量和宏观总量数据，同时采用状态依赖的局部投影方法分析非线性效应。

Result: 天然气价格冲击导致企业当前和预期价格持续上涨，通胀不确定性升高。在高不确定性状态下，企业成功将成本转嫁给消费者；在低不确定性状态下，衰退效应主导，企业将价格降至基准以下。

Conclusion: 天然气价格冲击是企业通胀预期的重要驱动因素，其影响具有显著的非线性特征，取决于经济不确定性水平。

Abstract: This paper examines how natural gas price shocks affect Italian firms'
pricing decisions and inflation expectations using quarterly survey data from
the Bank of Italy's Survey on Inflation and Growth Expectations (SIGE) spanning
1999Q4-2025Q2. We identify natural gas price shocks through a Bayesian VAR with
sign and zero restrictions. Our findings reveal that these shocks are a primary
driver of firms' inflation expectations, particularly during the post-COVID
period (2021-2023) when supply disruptions following Russia's invasion of
Ukraine generated unprecedented price pressures. We then estimate a larger BVAR
incorporating firm-level price setting variables and macro aggregates,
documenting that gas price shocks generate persistent increases in both firms'
current and expected prices, alongside elevated inflation uncertainty. We
uncover substantial non-linearities using state-dependent local projections:
under high uncertainty, firms successfully pass through cost increases to
consumers, maintaining elevated prices; under low uncertainty, recessionary
effects dominate, causing firms to reduce prices below baseline.

</details>


### [5] [REMIND-PyPSA-Eur: Integrating power system flexibility into sector-coupled energy transition pathways](https://arxiv.org/abs/2510.04388)
*Adrian Odenweller,Falko Ueckerdt,Johannes Hampp,Ivan Ramirez,Felix Schreyer,Robin Hasse,Jarusch Muessel,Chen Chris Gong,Robert Pietzcker,Tom Brown,Gunnar Luderer*

Main category: econ.GN

TL;DR: 结合REMIND长期综合评估模型和PyPSA-Eur小时级能源系统模型，通过双向价格迭代软耦合方法，优化长期投资和短期运营，验证了德国2045年实现气候中性的100%可再生能源电力系统的技术可行性和经济可行性。


<details>
  <summary>Details</summary>
Motivation: 现有模型要么缺乏长期转型路径所需的广泛范围，要么缺乏捕捉电力系统可变性和灵活性的时空细节，需要结合两者优势来优化能源系统规划。

Method: 采用REMIND和PyPSA-Eur的双向价格迭代软耦合方法，REMIND提供路径变量如部门电力需求、装机容量和成本，PyPSA-Eur返回优化运营变量如容量因子、存储需求和相对价格。

Result: 验证了100%可再生能源电力系统的可行性，灵活电解槽和智能充电电动汽车受益于低于平均价格，而灵活性较差的热泵面临几乎两倍平均价格。无需求侧灵活性时电价普遍上涨，但电池部署可部分补偿。

Conclusion: 该方法将电力系统动态完全整合到多十年能源转型路径中，证明了价格差异化在引导长期路径中的关键作用。

Abstract: The rapid expansion of low-cost renewable electricity combined with end-use
electrification in transport, industry, and buildings offers a promising path
to deep decarbonisation. However, aligning variable supply with demand requires
strategies for daily and seasonal balancing. Existing models either lack the
wide scope required for long-term transition pathways or the spatio-temporal
detail to capture power system variability and flexibility. Here, we combine
the complementary strengths of REMIND, a long-term integrated assessment model,
and PyPSA-Eur, an hourly energy system model, through a bi-directional,
price-based and iterative soft coupling. REMIND provides pathway variables such
as sectoral electricity demand, installed capacities, and costs to PyPSA-Eur,
which returns optimised operational variables such as capacity factors, storage
requirements, and relative prices. After sufficient convergence, this
integrated approach jointly optimises long-term investment and short-term
operation. We demonstrate the coupling for two Germany-focused scenarios, with
and without demand-side flexibility, reaching climate neutrality by 2045. Our
results confirm that a sector-coupled energy system with nearly 100\% renewable
electricity is technically possible and economically viable. Power system
flexibility influences long-term pathways through price differentiation:
supply-side market values vary by generation technology, while demand-side
prices vary by end-use sector. Flexible electrolysers and smart-charging
electric vehicles benefit from below-average prices, whereas less flexible heat
pumps face almost twice the average price due to winter peak loads. Without
demand-side flexibility, electricity prices increase across all end-users,
though battery deployment partially compensates. Our approach therefore fully
integrates power system dynamics into multi-decadal energy transition pathways.

</details>


### [6] [Predictive economics: Rethinking economic methodology with machine learning](https://arxiv.org/abs/2510.04726)
*Miguel Alves Pereira*

Main category: econ.GN

TL;DR: 提出预测经济学作为经济学中的一个独特分析视角，以机器学习为基础，关注预测准确性而非因果识别


<details>
  <summary>Details</summary>
Motivation: 基于工具主义传统、解释-预测二分法以及建模文化对比，将预测形式化为有效的认识论和方法论目标

Method: 回顾经济学子领域中的最新应用，展示预测模型如何促进实证分析，特别是在复杂或数据丰富的背景下

Result: 预测模型在实证分析中发挥作用，特别是在复杂或数据丰富的环境中

Conclusion: 这一视角补充了现有方法，支持更加多元化的方法论——重视样本外性能以及可解释性和理论结构

Abstract: This article proposes predictive economics as a distinct analytical
perspective within economics, grounded in machine learning and centred on
predictive accuracy rather than causal identification. Drawing on the
instrumentalist tradition (Friedman), the explanation-prediction divide
(Shmueli), and the contrast between modelling cultures (Breiman), we formalise
prediction as a valid epistemological and methodological objective. Reviewing
recent applications across economic subfields, we show how predictive models
contribute to empirical analysis, particularly in complex or data-rich
contexts. This perspective complements existing approaches and supports a more
pluralistic methodology - one that values out-of-sample performance alongside
interpretability and theoretical structure.

</details>


### [7] [Hidden Actions and Hidden Information in Peer Review: A Dynamic Solution](https://arxiv.org/abs/2510.04906)
*Raphael Mu*

Main category: econ.GN

TL;DR: 构建了一个科学同行评审的简单模型，发现当允许作者对初步拒绝提出挑战时，评审结果更接近最优状态。


<details>
  <summary>Details</summary>
Motivation: 研究科学同行评审过程中，作者能力和论文质量评估的机制，以及不同评审方式对最终结果的影响。

Method: 开发了一个理论模型，其中不同能力的作者投入努力产出不同质量的论文，期刊基于有噪声的信号评估并决定接受或拒绝论文。

Result: 当评估技术趋于完美时，即使期刊不知道作者类型和努力程度，也能达到最优结果。允许作者挑战初步拒绝的评审方式比不允许挑战的方式更接近最优状态。

Conclusion: 在同行评审过程中引入作者挑战机制可以提高评审质量，使结果更接近理论最优状态。

Abstract: We develop a simple model of the scientific peer review process, in which
authors of varying ability invest to produce papers of varying quality, and
journals evaluate papers based on a noisy signal, choosing to accept or reject
each paper. We find that the first-best outcome is the limiting case as the
evaluation technology is perfected, even though author type and effort are not
known to the journal. Then, we consider the case where journals allow authors
to challenge an initial rejection, and find that this approach to peer review
yields an outcome closer to the first best relative to the approach that does
not allow for such challenges.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [8] [Optimizing Phase-Scheduling with Throughput Trade-offs in AQFP Digital Circuits](https://arxiv.org/abs/2510.03956)
*Robert S. Aviles,Peter A. Beerel*

Main category: cs.ET

TL;DR: 提出了首个结合相位跳跃和相位对齐的时钟相位调度算法，显著减少AQFP逻辑中的路径平衡开销，实现面积和性能的优化。


<details>
  <summary>Details</summary>
Motivation: AQFP逻辑虽然功耗极低，但路径平衡技术约束导致缓冲器开销过大，限制了其可扩展性。现有相位跳跃和相位对齐技术单独使用能缓解此问题，但尚未联合探索。

Method: 开发了结合相位跳跃和相位对齐的时钟相位调度算法，包括最小面积方法和吞吐量约束优化方法。

Result: 最小面积方法相比单独相位跳跃平均减少25%面积，相比相位对齐减少11%面积；吞吐量约束优化平均节省6.8%面积，吞吐量提升2.62倍。

Conclusion: 提出的联合调度算法有效解决了AQFP路径平衡开销问题，实现了面积和吞吐量的显著优化，为AQFP电路设计提供了高效解决方案。

Abstract: Adiabatic Quantum-Flux-Parametron (AQFP) logic is a promising emerging
superconducting technology for ultra-low power digital circuits, offering
orders of magnitude lower power consumption than CMOS. However, AQFP
scalability is challenged by excessive buffer overhead due to path balancing
technology constraints. Addressing this, recent AQFP works have proposed design
solutions to reduce path balancing overhead using phase-skipping and
phase-alignment. Phase-skipping is a circuit-level technique that allows data
transfer between AQFP gates clocked with non-consecutive clock phases. In
contrast, phase-alignment is an architectural approach involving repeating
input patterns to allow data transfer between AQFP gates across multiples of
full clock cycles. While both techniques individually mitigate the area
overhead of path-balancing, they have not yet been jointly explored. In this
work, we present the first clock phase scheduling algorithm that combines
phase-skipping and phase-alignment. We first present a minimum area method that
on average, achieves a 25% area reduction compared to phase-skipping alone and
a 11% reduction compared to phase-alignment. We then extend the method to
enforce a target throughput, enabling efficient area-performance trade-offs.
With our throughput constrained optimization, we achieve on average 6.8% area
savings with a 2.62x increased throughput compared to the state-of-the-art
phase-aligned method.

</details>


### [9] [CMOS 2.0 - Redefining the Future of Scaling](https://arxiv.org/abs/2510.04535)
*Moritz Brunion,Navaneeth Kunhi Purayil,Francesco Dell'Atti,Sebastian Lam,Refik Bilgic,Mehdi Tahoori,Luca Benini,Julien Ryckaert*

Main category: cs.ET

TL;DR: 提出了CMOS 2.0平台，通过3D晶圆键合和背面处理技术，从几何缩放转向细粒度异构3D堆叠，以实现功率-性能-面积-成本的优化。


<details>
  <summary>Details</summary>
Motivation: 重新审视功能缩放范式，利用先进的3D晶圆键合和背面处理技术，克服传统CMOS几何缩放的局限性，实现更高效的系统设计。

Method: 采用3D晶圆键合和背面处理技术，构建细粒度异构3D堆叠的CMOS 2.0平台，需要开发相应的架构和EDA基础设施。

Result: 提出了CMOS 2.0平台概念，能够实现功率-性能-面积-成本的显著提升，并讨论了可靠性问题和缓解方法。

Conclusion: CMOS 2.0平台代表了系统设计的重大变革，从几何缩放转向功能缩放，需要新的架构和EDA工具支持。

Abstract: We propose to revisit the functional scaling paradigm by capitalizing on two
recent developments in advanced chip manufacturing, namely 3D wafer bonding and
backside processing. This approach leads to the proposal of the CMOS 2.0
platform. The main idea is to shift the CMOS roadmap from geometric scaling to
fine-grain heterogeneous 3D stacking of specialized active device layers to
achieve the ultimate Power-Performance-Area and Cost gains expected from future
technology generations. However, the efficient utilization of such a platform
requires devising architectures that can optimally map onto this technology, as
well as the EDA infrastructure that supports it. We also discuss reliability
concerns and eventual mitigation approaches. This paper provides pointers into
the major disruptions we expect in the design of systems in CMOS 2.0 moving
forward.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [10] [Gemini Robotics 1.5: Pushing the Frontier of Generalist Robots with Advanced Embodied Reasoning, Thinking, and Motion Transfer](https://arxiv.org/abs/2510.03342)
*Abbas Abdolmaleki,Saminda Abeyruwan,Joshua Ainslie,Jean-Baptiste Alayrac,Montserrat Gonzalez Arenas,Ashwin Balakrishna,Nathan Batchelor,Alex Bewley,Jeff Bingham,Michael Bloesch,Konstantinos Bousmalis,Philemon Brakel,Anthony Brohan,Thomas Buschmann,Arunkumar Byravan,Serkan Cabi,Ken Caluwaerts,Federico Casarini,Christine Chan,Oscar Chang,London Chappellet-Volpini,Jose Enrique Chen,Xi Chen,Hao-Tien Lewis Chiang,Krzysztof Choromanski,Adrian Collister,David B. D'Ambrosio,Sudeep Dasari,Todor Davchev,Meet Kirankumar Dave,Coline Devin,Norman Di Palo,Tianli Ding,Carl Doersch,Adil Dostmohamed,Yilun Du,Debidatta Dwibedi,Sathish Thoppay Egambaram,Michael Elabd,Tom Erez,Xiaolin Fang,Claudio Fantacci,Cody Fong,Erik Frey,Chuyuan Fu,Ruiqi Gao,Marissa Giustina,Keerthana Gopalakrishnan,Laura Graesser,Oliver Groth,Agrim Gupta,Roland Hafner,Steven Hansen,Leonard Hasenclever,Sam Haves,Nicolas Heess,Brandon Hernaez,Alex Hofer,Jasmine Hsu,Lu Huang,Sandy H. Huang,Atil Iscen,Mithun George Jacob,Deepali Jain,Sally Jesmonth,Abhishek Jindal,Ryan Julian,Dmitry Kalashnikov,M. Emre Karagozler,Stefani Karp,Matija Kecman,J. Chase Kew,Donnie Kim,Frank Kim,Junkyung Kim,Thomas Kipf,Sean Kirmani,Ksenia Konyushkova,Li Yang Ku,Yuheng Kuang,Thomas Lampe,Antoine Laurens,Tuan Anh Le,Isabel Leal,Alex X. Lee,Tsang-Wei Edward Lee,Guy Lever,Jacky Liang,Li-Heng Lin,Fangchen Liu,Shangbang Long,Caden Lu,Sharath Maddineni,Anirudha Majumdar,Kevis-Kokitsi Maninis,Andrew Marmon,Sergio Martinez,Assaf Hurwitz Michaely,Niko Milonopoulos,Joss Moore,Robert Moreno,Michael Neunert,Francesco Nori,Joy Ortiz,Kenneth Oslund,Carolina Parada,Emilio Parisotto,Amaris Paryag,Acorn Pooley,Thomas Power,Alessio Quaglino,Haroon Qureshi,Rajkumar Vasudeva Raju,Helen Ran,Dushyant Rao,Kanishka Rao,Isaac Reid,David Rendleman,Krista Reymann,Miguel Rivas,Francesco Romano,Yulia Rubanova,Peter Pastor Sampedro,Pannag R Sanketi,Dhruv Shah,Mohit Sharma,Kathryn Shea,Mohit Shridhar,Charles Shu,Vikas Sindhwani,Sumeet Singh,Radu Soricut,Rachel Sterneck,Ian Storz,Razvan Surdulescu,Jie Tan,Jonathan Tompson,Saran Tunyasuvunakool,Jake Varley,Grace Vesom,Giulia Vezzani,Maria Bauza Villalonga,Oriol Vinyals,René Wagner,Ayzaan Wahid,Stefan Welker,Paul Wohlhart,Chengda Wu,Markus Wulfmeier,Fei Xia,Ted Xiao,Annie Xie,Jinyu Xie,Peng Xu,Sichun Xu,Ying Xu,Zhuo Xu,Jimmy Yan,Sherry Yang,Skye Yang,Yuxiang Yang,Hiu Hong Yu,Wenhao Yu,Wentao Yuan,Yuan Yuan,Jingwei Zhang,Tingnan Zhang,Zhiyuan Zhang,Allan Zhou,Guangyao Zhou,Yuxiang Zhou*

Main category: cs.RO

TL;DR: Gemini Robotics 1.5是一个多具身视觉-语言-动作模型，通过运动转移机制学习异构机器人数据，结合多级内部推理过程实现"先思考后行动"，显著提升复杂多步任务的执行能力。


<details>
  <summary>Details</summary>
Motivation: 通用机器人需要深入理解物理世界、高级推理能力和通用灵巧控制能力，这是实现物理智能体的关键挑战。

Method: 采用新颖架构和运动转移机制学习异构多具身机器人数据；在自然语言中交织动作与多级内部推理过程；Gemini Robotics-ER 1.5专注于具身推理能力。

Result: Gemini Robotics 1.5能够分解和执行复杂多步任务，使机器人行为对用户更可解释；Gemini Robotics-ER 1.5在具身推理方面达到最先进水平。

Conclusion: 这一系列模型向物理智能体时代迈进了一步，使机器人能够感知、思考然后行动，从而解决复杂多步任务。

Abstract: General-purpose robots need a deep understanding of the physical world,
advanced reasoning, and general and dexterous control. This report introduces
the latest generation of the Gemini Robotics model family: Gemini Robotics 1.5,
a multi-embodiment Vision-Language-Action (VLA) model, and Gemini Robotics-ER
1.5, a state-of-the-art Embodied Reasoning (ER) model. We are bringing together
three major innovations. First, Gemini Robotics 1.5 features a novel
architecture and a Motion Transfer (MT) mechanism, which enables it to learn
from heterogeneous, multi-embodiment robot data and makes the VLA more general.
Second, Gemini Robotics 1.5 interleaves actions with a multi-level internal
reasoning process in natural language. This enables the robot to "think before
acting" and notably improves its ability to decompose and execute complex,
multi-step tasks, and also makes the robot's behavior more interpretable to the
user. Third, Gemini Robotics-ER 1.5 establishes a new state-of-the-art for
embodied reasoning, i.e., for reasoning capabilities that are critical for
robots, such as visual and spatial understanding, task planning, and progress
estimation. Together, this family of models takes us a step towards an era of
physical agents-enabling robots to perceive, think and then act so they can
solve complex multi-step tasks.

</details>


### [11] [Optimal swimming with body compliance in an overdamped medium](https://arxiv.org/abs/2510.03457)
*Jianfeng Lin,Tianyu Wang,Baxi Chong,Matthew Fernandez,Zhaochen Xu,Daniel I. Goldman*

Main category: cs.RO

TL;DR: 本文扩展了几何力学理论，用于预测和优化柔性波动游泳机器人的运动性能，通过引入关节弹簧的柔性三连杆游泳器模型，在颗粒介质中验证了准确预测和优化能力。


<details>
  <summary>Details</summary>
Motivation: 现有几何力学方法假设精确执行预设步态，但实际环境中柔性体与环境相互作用会扰动实际轨迹，需要扩展理论来处理柔性波动游泳器的运动控制问题。

Method: 在Purcell三连杆游泳器基础上引入串联弹簧构建柔性模型，结合阻力理论推导身体动力学，将几何力学融入运动预测和优化框架，寻找实现最大位移的控制策略。

Result: 在物理电缆驱动的三连杆无肢机器人上验证了框架，在颗粒介质中准确预测和优化了不同编程状态相关柔顺性下的运动性能。

Conclusion: 建立了一种系统的基于物理的方法来建模和控制柔性游泳运动，强调柔顺性可以作为在均匀和非均匀环境中实现稳健运动的设计特征。

Abstract: Elongate animals and robots use undulatory body waves to locomote through
diverse environments. Geometric mechanics provides a framework to model and
optimize such systems in highly damped environments, connecting a prescribed
shape change pattern (gait) with locomotion displacement. However, existing
approaches assume precise execution of prescribed gaits, whereas in practice
environmental interactions with compliant bodies of animals or robots
frequently perturb the realized trajectories. In this work, we extend geometric
mechanics to predict locomotor performance and search for optimal swimming
strategy of compliant undulators. We introduce a compliant extension of
Purcell's three-link swimmer by incorporating series-connected springs at the
joints. Body dynamics are derived with resistive force theory. Geometric
mechanics is incorporated into movement prediction and into an optimization
framework that identifies strategies for controlling compliant swimmers to
achieve maximal displacement. We validate our framework on a physical
cable-driven three-link limbless robot, and demonstrate accurate prediction and
optimization of locomotor performance under varied programmed, state-dependent
compliance in a granular medium. Our results establish a systematic
physics-based approach for modeling and controlling compliant swimming
locomotion, highlighting compliance as a design feature that can be exploited
for robust movement in homogeneous and heterogeneous environments.

</details>


### [12] [Warm-Starting Optimization-Based Motion Planning for Robotic Manipulators via Point Cloud-Conditioned Flow Matching](https://arxiv.org/abs/2510.03460)
*Sibo Tian,Minghui Zheng,Xiao Liang*

Main category: cs.RO

TL;DR: 提出了一种基于流匹配模型的生成式初始化方法，通过单视角点云学习优化问题的近优解，用于机器人运动规划，无需环境先验知识即可从深度相机输入直接生成可行轨迹。


<details>
  <summary>Details</summary>
Motivation: 在HRC系统中需要实时生成机器人运动，但现有采样规划器在高维空间中扩展性差，优化规划器对初始化敏感易陷入局部最优。需要一种能快速生成高质量初始解的方法。

Method: 使用基于流匹配的生成模型，以单视角点云为条件，学习轨迹优化的近优初始解，无需障碍物位置和几何形状等环境先验知识。

Result: 在UR5e机械臂杂乱工作空间的仿真研究中，该方法单独使用即有高成功率，显著提升轨迹优化成功率，减少优化迭代次数，并在未见环境中表现出强泛化能力。

Conclusion: 提出的生成式初始化器能有效解决优化规划器的初始化问题，为实时HRC系统提供了高效的运动规划解决方案。

Abstract: Rapid robot motion generation is critical in Human-Robot Collaboration (HRC)
systems, as robots need to respond to dynamic environments in real time by
continuously observing their surroundings and replanning their motions to
ensure both safe interactions and efficient task execution. Current
sampling-based motion planners face challenges in scaling to high-dimensional
configuration spaces and often require post-processing to interpolate and
smooth the generated paths, resulting in time inefficiency in complex
environments. Optimization-based planners, on the other hand, can incorporate
multiple constraints and generate smooth trajectories directly, making them
potentially more time-efficient. However, optimization-based planners are
sensitive to initialization and may get stuck in local minima. In this work, we
present a novel learning-based method that utilizes a Flow Matching model
conditioned on a single-view point cloud to learn near-optimal solutions for
optimization initialization. Our method does not require prior knowledge of the
environment, such as obstacle locations and geometries, and can generate
feasible trajectories directly from single-view depth camera input. Simulation
studies on a UR5e robotic manipulator in cluttered workspaces demonstrate that
the proposed generative initializer achieves a high success rate on its own,
significantly improves the success rate of trajectory optimization compared
with traditional and learning-based benchmark initializers, requires fewer
optimization iterations, and exhibits strong generalization to unseen
environments.

</details>


### [13] [A Simulation Evaluation Suite for Robust Adaptive Quadcopter Control](https://arxiv.org/abs/2510.03471)
*Dingqi Zhang,Ran Tao,Sheng Cheng,Naira Hovakimyan,Mark W. Mueller*

Main category: cs.RO

TL;DR: 该论文提出了一个基于RotorPy的模块化四旋翼控制仿真测试平台，用于在多种干扰条件下系统评估自适应控制方法。


<details>
  <summary>Details</summary>
Motivation: 当前四旋翼自适应控制方法在任务、仿真器和实现上的碎片化评估阻碍了系统比较，需要一个统一的测试平台。

Method: 开发了一个易于部署的模块化仿真测试平台，包含代表性自适应和非自适应控制器库，提供任务相关指标来评估跟踪精度和鲁棒性。

Result: 该框架支持在风扰、载荷偏移、转子故障和控制延迟等多种干扰场景下进行可重复评估，消除了干扰模型、轨迹生成器和分析工具等组件的冗余重新实现。

Conclusion: 该测试平台通过涵盖多种干扰场景和轨迹类型的示例展示了其多功能性，包括自动化压力测试，证明了其用于系统分析的实用性。

Abstract: Robust adaptive control methods are essential for maintaining quadcopter
performance under external disturbances and model uncertainties. However,
fragmented evaluations across tasks, simulators, and implementations hinder
systematic comparison of these methods. This paper introduces an
easy-to-deploy, modular simulation testbed for quadcopter control, built on
RotorPy, that enables evaluation under a wide range of disturbances such as
wind, payload shifts, rotor faults, and control latency. The framework includes
a library of representative adaptive and non-adaptive controllers and provides
task-relevant metrics to assess tracking accuracy and robustness. The unified
modular environment enables reproducible evaluation across control methods and
eliminates redundant reimplementation of components such as disturbance models,
trajectory generators, and analysis tools. We illustrate the testbed's
versatility through examples spanning multiple disturbance scenarios and
trajectory types, including automated stress testing, to demonstrate its
utility for systematic analysis. Code is available at
https://github.com/Dz298/AdaptiveQuadBench.

</details>


### [14] [Destination-to-Chutes Task Mapping Optimization for Multi-Robot Coordination in Robotic Sorting Systems](https://arxiv.org/abs/2510.03472)
*Yulun Zhang,Alexandre O. G. Barbosa,Federico Pecora,Jiaoyang Li*

Main category: cs.RO

TL;DR: 本文研究了机器人分拣系统中目的地到滑槽任务映射的优化问题，通过进化算法和混合整数线性规划方法提升系统吞吐量，并在不同系统设置下验证了优化映射优于贪婪方法。


<details>
  <summary>Details</summary>
Motivation: 优化目的地到滑槽的任务映射对于提高机器人分拣系统吞吐量至关重要，但面临三个主要挑战：任务映射与机器人目标分配和路径规划的相互依赖、滑槽在接收足够包裹后会暂时关闭、以及任务映射质量直接影响下游处理效率。

Method: 首先正式定义了任务映射和任务映射优化问题，然后开发了机器人分拣系统模拟器进行评估，提出了基于进化算法和混合整数线性规划的简单优化方法，并使用质量多样性算法分析多样化任务映射的吞吐量。

Result: 在各种不同地图大小、滑槽数量和目的地的机器人分拣系统设置中，优化的任务映射相比贪婪生成的方法展现出明显优势，提高了系统吞吐量。

Conclusion: 通过系统化的任务映射优化方法可以显著提升机器人分拣系统的性能，质量多样性算法有助于分析不同任务映射对吞吐量的影响，为实际系统部署提供了有效工具。

Abstract: We study optimizing a destination-to-chutes task mapping to improve
throughput in Robotic Sorting Systems (RSS), where a team of robots sort
packages on a sortation floor by transporting them from induct workstations to
eject chutes based on their shipping destinations (e.g. Los Angeles or
Pittsburgh). The destination-to-chutes task mapping is used to determine which
chutes a robot can drop its package. Finding a high-quality task mapping is
challenging because of the complexity of a real-world RSS. First, optimizing
task mapping is interdependent with robot target assignment and path planning.
Second, chutes will be CLOSED for a period of time once they receive sufficient
packages to allow for downstream processing. Third, task mapping quality
directly impacts the downstream processing, as scattered chutes for the same
destination increase package handling time. In this paper, we first formally
define task mappings and the problem of Task Mapping Optimization (TMO). We
then present a simulator of RSS to evaluate task mappings. We then present a
simple TMO method based on the Evolutionary Algorithm and Mixed Integer Linear
Programming, demonstrating the advantage of our optimized task mappings over
the greedily generated ones in various RSS setups with different map sizes,
numbers of chutes, and destinations. Finally, we use Quality Diversity
algorithms to analyze the throughput of a diverse set of task mappings. Our
code is available online at https://github.com/lunjohnzhang/tmo_public.

</details>


### [15] [Robust Permissive Controller Synthesis for Interval MDPs](https://arxiv.org/abs/2510.03481)
*Khang Vo Huynh,David Parker,Lu Feng*

Main category: cs.RO

TL;DR: 提出了首个在区间马尔可夫决策过程(IMDPs)上合成鲁棒性允许控制器的框架，保证所有符合合成多策略的策略在所有允许转移下满足可达性或基于奖励的规范。


<details>
  <summary>Details</summary>
Motivation: 传统控制器合成通常产生单一确定性策略，限制了适应性。允许控制器(多策略)允许每个状态有多个动作，提供运行时灵活性和弹性。但现有工作通常假设精确转移概率，这在机器人应用中不现实。

Method: 将问题建模为混合整数线性规划(MILPs)，提出两种编码方法：基线顶点枚举方法和可扩展的对偶方法(避免显式枚举)。

Result: 在四个基准领域上的实验表明，两种方法都能合成鲁棒、最大允许的控制器，并可扩展到具有数十万个状态的大型IMDPs。

Conclusion: 该框架为在不确定动态下运行的机器人提供了首个鲁棒允许控制器合成解决方案，有效处理了转移概率的区间不确定性。

Abstract: We address the problem of robust permissive controller synthesis for robots
operating under uncertain dynamics, modeled as Interval Markov Decision
Processes (IMDPs). IMDPs generalize standard MDPs by allowing transition
probabilities to vary within intervals, capturing epistemic uncertainty from
sensing noise, actuation imprecision, and coarse system abstractions-common in
robotics. Traditional controller synthesis typically yields a single
deterministic strategy, limiting adaptability. In contrast, permissive
controllers (multi-strategies) allow multiple actions per state, enabling
runtime flexibility and resilience. However, prior work on permissive
controller synthesis generally assumes exact transition probabilities, which is
unrealistic in many robotic applications. We present the first framework for
robust permissive controller synthesis on IMDPs, guaranteeing that all
strategies compliant with the synthesized multi-strategy satisfy reachability
or reward-based specifications under all admissible transitions. We formulate
the problem as mixed-integer linear programs (MILPs) and propose two encodings:
a baseline vertex-enumeration method and a scalable duality-based method that
avoids explicit enumeration. Experiments on four benchmark domains show that
both methods synthesize robust, maximally permissive controllers and scale to
large IMDPs with up to hundreds of thousands of states.

</details>


### [16] [Digital-Twin Evaluation for Proactive Human-Robot Collision Avoidance via Prediction-Guided A-RRT*](https://arxiv.org/abs/2510.03496)
*Vadivelan Murugesan,Rajasundaram Mathiazhagan,Sanjana Joshi,Aliasghar Arab*

Main category: cs.RO

TL;DR: 提出基于预测驱动的人机协作安全规划框架，通过数字孪生验证的关节级人体运动预测实现主动避障


<details>
  <summary>Details</summary>
Motivation: 现有人机协作规划器仅依赖运动学模型，需要更精确的长期人体运动预测来实现主动碰撞避免

Method: 使用深度相机提取3D骨骼姿态，CNN-BiLSTM模型预测关节轨迹，胶囊人工势场计算碰撞风险，自适应RRT*规划器在阈值超过时重新规划

Result: 在50次试验中实现100%主动避障，保持>250mm安全距离，重新规划时间小于2秒

Conclusion: 通过预测人体建模与数字孪生验证的集成，相比仅使用运动学的规划器具有更高的精度和可靠性

Abstract: Human-robot collaboration requires precise prediction of human motion over
extended horizons to enable proactive collision avoidance. Unlike existing
planners that rely solely on kinodynamic models, we present a prediction-driven
safe planning framework that leverages granular, joint-by-joint human motion
forecasting validated in a physics-based digital twin. A capsule-based
artificial potential field (APF) converts these granular predictions into
collision risk metrics, triggering an Adaptive RRT* (A-RRT*) planner when
thresholds are exceeded. The depth camera is used to extract 3D skeletal poses
and a convolutional neural network-bidirectional long short-term memory
(CNN-BiLSTM) model to predict individual joint trajectories ahead of time. A
digital twin model integrates real-time human posture prediction placed in
front of a simulated robot to evaluate motions and physical contacts. The
proposed method enables validation of planned trajectories ahead of time and
bridging potential latency gaps in updating planned trajectories in real-time.
In 50 trials, our method achieved 100% proactive avoidance with > 250 mm
clearance and sub-2 s replanning, demonstrating superior precision and
reliability compared to existing kinematic-only planners through the
integration of predictive human modeling with digital twin validation.

</details>


### [17] [Distributed Connectivity Maintenance and Recovery for Quadrotor Motion Planning](https://arxiv.org/abs/2510.03504)
*Yutong Wang,Yichun Qu,Tengxiang Wang,Lishuo Pan,Nora Ayanian*

Main category: cs.RO

TL;DR: 提出了一种基于高阶控制屏障函数的实时分布式多机器人导航框架，能够在避障的同时保持机器人间的连接性，并支持从断开状态恢复连接。


<details>
  <summary>Details</summary>
Motivation: 在多机器人应用中保持连接性至关重要，但容易受到障碍物和视觉遮挡的影响。现有方法难以在复杂环境中同时实现连接保持和避障。

Method: 采用统一MPC-CLF-CBF框架，结合高阶控制屏障函数控制机器人间距以保持连接，使用控制李雅普诺夫函数实现连接恢复，通过贝塞尔参数化轨迹生成平滑曲线。

Result: 在模拟和4架Crazyflie纳米四旋翼的物理实验中验证了框架的有效性，能够在障碍物丰富的环境中实现鲁棒的连接保持和恢复。

Conclusion: 该框架为多机器人系统提供了一种连续时间的轨迹生成和控制方法，能够同时实现连接维护、避障和连接恢复。

Abstract: Maintaining connectivity is crucial in many multi-robot applications, yet
fragile to obstacles and visual occlusions. We present a real-time distributed
framework for multi-robot navigation certified by high-order control barrier
functions (HOCBFs) that controls inter-robot proximity to maintain connectivity
while avoiding collisions. We incorporate control Lyapunov functions to enable
connectivity recovery from initial disconnected configurations and temporary
losses, providing robust connectivity during navigation in obstacle-rich
environments. Our trajectory generation framework concurrently produces
planning and control through a Bezier-parameterized trajectory, which naturally
provides smooth curves with arbitrary degree of derivatives. The main
contribution is the unified MPC-CLF-CBF framework, a continuous-time trajectory
generation and control method for connectivity maintenance and recovery of
multi-robot systems. We validate the framework through extensive simulations
and a physical experiment with 4 Crazyflie nano-quadrotors.

</details>


### [18] [LapSurgie: Humanoid Robots Performing Surgery via Teleoperated Handheld Laparoscopy](https://arxiv.org/abs/2510.03529)
*Zekai Liang,Xiao Liang,Soofiyan Atar,Sreyan Das,Zoe Chiu,Peihan Zhang,Florian Richter,Shanglei Liu,Michael C. Yip*

Main category: cs.RO

TL;DR: 提出了LapSurgie，首个基于人形机器人的腹腔镜远程操作框架，通过逆向映射策略控制标准腹腔镜工具，无需额外设置要求。


<details>
  <summary>Details</summary>
Motivation: 解决手术机器人系统在资源匮乏地区的部署难题，利用人形机器人可直接在人类设计环境中操作的优势，缩小医疗资源差距。

Method: 采用逆向映射策略控制手动腕式腹腔镜器械，遵守远程运动中心约束，配备立体视觉系统的控制台提供实时视觉反馈。

Result: 跨平台的综合用户研究证明了该框架的有效性，并为人形机器人在腹腔镜手术中部署的可行性提供了初步证据。

Conclusion: LapSurgie框架展示了人形机器人在腹腔镜远程手术中的潜力，为资源匮乏地区提供可行的解决方案。

Abstract: Robotic laparoscopic surgery has gained increasing attention in recent years
for its potential to deliver more efficient and precise minimally invasive
procedures. However, adoption of surgical robotic platforms remains largely
confined to high-resource medical centers, exacerbating healthcare disparities
in rural and low-resource regions. To close this gap, a range of solutions has
been explored, from remote mentorship to fully remote telesurgery. Yet, the
practical deployment of surgical robotic systems to underserved communities
remains an unsolved challenge. Humanoid systems offer a promising path toward
deployability, as they can directly operate in environments designed for humans
without extensive infrastructure modifications -- including operating rooms. In
this work, we introduce LapSurgie, the first humanoid-robot-based laparoscopic
teleoperation framework. The system leverages an inverse-mapping strategy for
manual-wristed laparoscopic instruments that abides to remote center-of-motion
constraints, enabling precise hand-to-tool control of off-the-shelf surgical
laparoscopic tools without additional setup requirements. A control console
equipped with a stereo vision system provides real-time visual feedback.
Finally, a comprehensive user study across platforms demonstrates the
effectiveness of the proposed framework and provides initial evidence for the
feasibility of deploying humanoid robots in laparoscopic procedures.

</details>


### [19] [Efficient Surgical Robotic Instrument Pose Reconstruction in Real World Conditions Using Unified Feature Detection](https://arxiv.org/abs/2510.03532)
*Zekai Liang,Kazuya Miyata,Xiao Liang,Florian Richter,Michael C. Yip*

Main category: cs.RO

TL;DR: 提出了一种新颖的相机-机器人标定框架，通过共享编码统一检测几何基元（关键点和轴边缘），在具有挑战性的手术环境中实现快速且最先进的精度。


<details>
  <summary>Details</summary>
Motivation: 微创手术机器人具有长运动链和部分自由度可见性，传统标定方法假设刚性机器人和良好可见性，无法满足在线机器人控制需求。现有方法在特征检测一致性或推理时间方面存在不足。

Method: 通过共享编码统一检测关键点和轴边缘几何基元，在单次推理中同时检测两者，使用大规模合成数据和投影标签进行训练，通过投影几何实现高效位姿估计。

Result: 在特征检测和位姿估计方面进行评估，定性和定量结果显示在挑战性手术环境中具有快速性能和最先进的精度。

Conclusion: 该框架在手术环境中实现了快速且准确的相机-机器人标定，解决了传统方法在微创手术机器人标定中的挑战。

Abstract: Accurate camera-to-robot calibration is essential for any vision-based
robotic control system and especially critical in minimally invasive surgical
robots, where instruments conduct precise micro-manipulations. However, MIS
robots have long kinematic chains and partial visibility of their degrees of
freedom in the camera, which introduces challenges for conventional
camera-to-robot calibration methods that assume stiff robots with good
visibility. Previous works have investigated both keypoint-based and
rendering-based approaches to address this challenge in real-world conditions;
however, they often struggle with consistent feature detection or have long
inference times, neither of which are ideal for online robot control. In this
work, we propose a novel framework that unifies the detection of geometric
primitives (keypoints and shaft edges) through a shared encoding, enabling
efficient pose estimation via projection geometry. This architecture detects
both keypoints and edges in a single inference and is trained on large-scale
synthetic data with projective labeling. This method is evaluated across both
feature detection and pose estimation, with qualitative and quantitative
results demonstrating fast performance and state-of-the-art accuracy in
challenging surgical environments.

</details>


### [20] [Shape-Space Graphs: Fast and Collision-Free Path Planning for Soft Robots](https://arxiv.org/abs/2510.03547)
*Carina Veil,Moritz Flaschel,Ellen Kuhl*

Main category: cs.RO

TL;DR: 提出了一种基于图搜索的软体机器人路径规划方法，通过预计算形状库和构建k近邻图，实现快速避障和能量高效的运动规划。


<details>
  <summary>Details</summary>
Motivation: 软体机器人具有极高的灵活性，但在杂乱环境中的运动规划面临挑战，因为其高度非线性和无限维运动学特性。

Method: 使用受形态弹性和主动细丝理论启发的生物力学模型预计算形状库，构建形状空间的k近邻图，利用符号距离函数修剪碰撞节点和边，基于几何距离和驱动努力定义多目标边成本。

Result: 算法能在毫秒级时间内可靠避障并生成可行路径，相比纯几何规划能显著减少驱动努力，但代价是更长的末端轨迹。

Conclusion: 形状空间图搜索方法为软体机器人提供了快速可靠的路径规划方案，为手术、工业和辅助领域的实时应用铺平了道路。

Abstract: Soft robots, inspired by elephant trunks or octopus arms, offer extraordinary
flexibility to bend, twist, and elongate in ways that rigid robots cannot.
However, their motion planning remains a challenge, especially in cluttered
environments with obstacles, due to their highly nonlinear and
infinite-dimensional kinematics. Here, we present a graph-based path planning
tool for an elephant-trunk-inspired soft robotic arm designed with three
artificial muscle fibers that allow for multimodal continuous deformation
through contraction. Using a biomechanical model inspired by morphoelasticity
and active filament theory, we precompute a shape library and construct a
$k$-nearest neighbor graph in \emph{shape space}, ensuring that each node
corresponds to a mechanically accurate and physically valid robot shape. For
the graph, we use signed distance functions to prune nodes and edges colliding
with obstacles, and define multi-objective edge costs based on geometric
distance and actuation effort, enabling energy-efficient planning with
collision avoidance. We demonstrate that our algorithm reliably avoids
obstacles and generates feasible paths within milliseconds from precomputed
graphs using Dijkstra's algorithm. We show that including energy costs can
drastically reduce the actuation effort compared to geometry-only planning, at
the expense of longer tip trajectories. Our results highlight the potential of
shape-space graph search for fast and reliable path planning in the field of
soft robotics, paving the way for real-time applications in surgical,
industrial, and assistive settings.

</details>


### [21] [Learning to Act Through Contact: A Unified View of Multi-Task Robot Learning](https://arxiv.org/abs/2510.03599)
*Shafeef Omar,Majid Khadiv*

Main category: cs.RO

TL;DR: 提出基于接触显式表示的统一多任务运动与操作策略学习框架，通过接触目标序列定义任务，实现单一策略执行多种接触密集型任务


<details>
  <summary>Details</summary>
Motivation: 传统方法需要为不同任务设计不同策略，缺乏统一框架来利用接触密集型任务间的共享结构

Method: 使用接触目标序列（期望接触位置、时序和活动末端执行器）统一任务定义，训练目标条件强化学习策略来实现给定接触计划

Result: 在多种机器人形态和任务上验证：四足机器人多种步态、人形机器人双足/四足步态、双手物体操作任务，单一策略均能执行不同接触任务

Conclusion: 显式接触推理显著提高对未见场景的泛化能力，接触显式策略学习为可扩展的运动操作提供了有前景的基础

Abstract: We present a unified framework for multi-task locomotion and manipulation
policy learning grounded in a contact-explicit representation. Instead of
designing different policies for different tasks, our approach unifies the
definition of a task through a sequence of contact goals-desired contact
positions, timings, and active end-effectors. This enables leveraging the
shared structure across diverse contact-rich tasks, leading to a single policy
that can perform a wide range of tasks. In particular, we train a
goal-conditioned reinforcement learning (RL) policy to realise given contact
plans. We validate our framework on multiple robotic embodiments and tasks: a
quadruped performing multiple gaits, a humanoid performing multiple biped and
quadrupedal gaits, and a humanoid executing different bimanual object
manipulation tasks. Each of these scenarios is controlled by a single policy
trained to execute different tasks grounded in contacts, demonstrating
versatile and robust behaviours across morphologically distinct systems. Our
results show that explicit contact reasoning significantly improves
generalisation to unseen scenarios, positioning contact-explicit policy
learning as a promising foundation for scalable loco-manipulation.

</details>


### [22] [Safety-Oriented Dynamic Path Planning for Automated Vehicles](https://arxiv.org/abs/2510.03640)
*Mostafa Emam,Matthias Gerdts*

Main category: cs.RO

TL;DR: 提出了一种用于自动驾驶车辆的双层控制框架，通过时间相关的障碍物网格投影增强道路边界，结合非线性模型预测控制和同伦约束松弛来优化实时路径规划，并配备独立备份回路确保安全性。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中确保自动驾驶车辆的安全需要先进的路径规划和障碍物规避能力，特别是在复杂场景下需要实时且可靠的解决方案。

Method: 采用双层控制框架：主回路使用非线性模型预测控制进行实时路径优化，并应用同伦约束松弛提高最优控制问题的可解性；同时运行独立备份回路，在主回路无法及时计算最优轨迹时提供安全备用轨迹。

Result: 评估显示该方法在各种驾驶场景中具有优势，证明了其实时适用性和鲁棒性。

Conclusion: 该框架代表了在复杂动态环境中实现更安全可靠自动驾驶的重要进展。

Abstract: Ensuring safety in autonomous vehicles necessitates advanced path planning
and obstacle avoidance capabilities, particularly in dynamic environments. This
paper introduces a bi-level control framework that efficiently augments road
boundaries by incorporating time-dependent grid projections of obstacle
movements, thus enabling precise and adaptive path planning. The main control
loop utilizes Nonlinear Model Predictive Control (NMPC) for real-time path
optimization, wherein homotopy-based constraint relaxation is employed to
improve the solvability of the optimal control problem (OCP). Furthermore, an
independent backup loop runs concurrently to provide safe fallback trajectories
when an optimal trajectory cannot be computed by the main loop within a
critical time frame, thus enhancing safety and real-time performance. Our
evaluation showcases the benefits of the proposed methods in various driving
scenarios, highlighting the real-time applicability and robustness of our
approach. Overall, the framework represents a significant step towards safer
and more reliable autonomous driving in complex and dynamic environments.

</details>


### [23] [Geometrically Exact Hard Magneto-Elastic Cosserat Shells: Static Formulation for Shape Morphing](https://arxiv.org/abs/2510.03644)
*Mohammadjavad Javadi,Robin Chhabra*

Main category: cs.RO

TL;DR: 提出了一种基于Cosserat壳理论的硬磁壳高效静态模型，适用于大宽长比的软磁机器人，解决了传统1D模型在2D壳结构建模中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有Cosserat杆理论主要针对1D细长结构，而现代软机器人在运动和操作中常呈现大宽长比的2D壳结构特征，需要开发更合适的建模方法。

Method: 基于特殊欧几里得群(SE(3))的Cosserat壳理论，将壳视为具有六自由度的2D流形，推导了基于李群结构的局部变形梯度定义和平衡方程的强、弱形式。

Result: 开发了有限元方法，避免了壳结构建模中的奇点和锁定现象，在壳经历大旋转和位移时表现出优越性能。

Conclusion: 该模型为硬磁壳结构提供了有效的分析和形状控制工具，特别适用于大变形情况，并通过实验验证了其有效性。

Abstract: Cosserat rod theory is the popular approach to modeling ferromagnetic soft
robots as 1-Dimensional (1D) slender structures in most applications, such as
biomedical. However, recent soft robots designed for locomotion and
manipulation often exhibit a large width-to-length ratio that categorizes them
as 2D shells. For analysis and shape-morphing control purposes, we develop an
efficient coordinate-free static model of hard-magnetic shells found in soft
magnetic grippers and walking soft robots. The approach is based on a novel
formulation of Cosserat shell theory on the Special Euclidean group
($\mathbf{SE}(3)$). The shell is assumed to be a 2D manifold of material points
with six degrees of freedom (position & rotation) suitable for capturing the
behavior of a uniformly distributed array of spheroidal hard magnetic particles
embedded in the rheological elastomer. The shell's configuration manifold is
the space of all smooth embeddings $\mathbb{R}^2\rightarrow\mathbf{SE}(3)$.
According to a novel definition of local deformation gradient based on the Lie
group structure of $\mathbf{SE}(3)$, we derive the strong and weak forms of
equilibrium equations, following the principle of virtual work. We extract the
linearized version of the weak form for numerical implementations. The
resulting finite element approach can avoid well-known challenges such as
singularity and locking phenomenon in modeling shell structures. The proposed
model is analytically and experimentally validated through a series of test
cases that demonstrate its superior efficacy, particularly when the shell
undergoes severe rotations and displacements.

</details>


### [24] [An Amphibious Untethered Inchworm Soft Robot for Fast Crawling Locomotion](https://arxiv.org/abs/2510.03660)
*Mohammadjavad Javadi,Charlie Wadds,Robin Chhabra*

Main category: cs.RO

TL;DR: 提出了一种完全无缆的软体机器人，灵感来自尺蠖，采用磁力驱动，具有多模态运动能力，包括行走、转向、游泳和负载运输。


<details>
  <summary>Details</summary>
Motivation: 开发无缆软体机器人对于推动软体机器人系统在多样化、多任务环境中的实际部署至关重要。

Method: 通过结构优化和系统级集成，采用磁力驱动的弯曲柔性结构，配备轻量化控制电路和集成摄像头实现无线控制和环境感知。

Result: 机器人总质量102.63克，最大行走速度3.74 cm/s，游泳速度0.82 cm/s，成功实现多种运动模式且不依赖外部基础设施。

Conclusion: 通过实验验证了机器人的动态性能和运动能力，为无缆软体机器人的实际应用提供了可行方案。

Abstract: Untethered soft robots are essential for advancing the real-world deployment
of soft robotic systems in diverse and multitasking environments. Inspired by
soft-bodied inchworm, we present a fully untethered soft robot with a curved,
flexible structure actuated by magnetic forces. The robot has a total mass of
102.63 g and demonstrates multimodal locomotion, achieving a maximum walking
speed of 3.74 cm/s and a swimming speed of 0.82 cm/s. A compact and lightweight
onboard control circuit enables wireless command transmission, while an
integrated camera provides environmental perception. Through structural
optimization and system-level integration, the robot successfully performs
walking, steering, swimming, and payload transport without reliance on external
infrastructure. The robot's dynamic performance and locomotion capabilities are
systematically validated through experimental characterization.

</details>


### [25] [Robust Visual Embodiment: How Robots Discover Their Bodies in Real Environments](https://arxiv.org/abs/2510.03677)
*Salim Rezvani,Ammar Jaleel Mahmood,Robin Chhabra*

Main category: cs.RO

TL;DR: 本文首次系统研究了视觉退化（模糊、椒盐噪声、高斯噪声）对机器人自建模的影响，并提出结合经典修复和形态保持约束的任务感知去噪框架，显著提升了自建模在真实环境中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有自主建模管道在真实感知条件（如噪声图像和杂乱背景）下表现脆弱，限制了具有内部视觉自模型机器人的实际应用。

Method: 引入任务感知去噪框架，将经典修复与形态保持约束相结合，并集成语义分割以在杂乱场景中稳健地分离机器人。

Result: 在仿真和物理实验中，该方法恢复了接近基线性能，而现有管道性能显著下降。

Conclusion: 这些贡献提升了视觉自建模的鲁棒性，为在不可预测的真实世界环境中部署自感知机器人奠定了实践基础。

Abstract: Robots with internal visual self-models promise unprecedented adaptability,
yet existing autonomous modeling pipelines remain fragile under realistic
sensing conditions such as noisy imagery and cluttered backgrounds. This paper
presents the first systematic study quantifying how visual
degradations--including blur, salt-and-pepper noise, and Gaussian noise--affect
robotic self-modeling. Through both simulation and physical experiments, we
demonstrate their impact on morphology prediction, trajectory planning, and
damage recovery in state-of-the-art pipelines. To overcome these challenges, we
introduce a task-aware denoising framework that couples classical restoration
with morphology-preserving constraints, ensuring retention of structural cues
critical for self-modeling. In addition, we integrate semantic segmentation to
robustly isolate robots from cluttered and colorful scenes. Extensive
experiments show that our approach restores near-baseline performance across
simulated and physical platforms, while existing pipelines degrade
significantly. These contributions advance the robustness of visual
self-modeling and establish practical foundations for deploying self-aware
robots in unpredictable real-world environments.

</details>


### [26] [EmbodiSwap for Zero-Shot Robot Imitation Learning](https://arxiv.org/abs/2510.03706)
*Eadom Dessalene,Pavan Mantripragada,Michael Maynord,Yiannis Aloimonos*

Main category: cs.RO

TL;DR: EmbodiSwap是一种将人类视频转换为逼真机器人覆盖图像的方法，用于零样本模仿学习，通过V-JEPA视觉骨干网络在合成机器人视频上训练闭环操作策略，在真实世界测试中达到82%的成功率。


<details>
  <summary>Details</summary>
Motivation: 解决野外人类视频与目标机器人实体之间的实体差距问题，实现从人类视频到机器人模仿学习的零样本迁移。

Method: 使用EmbodiSwap方法生成逼真的合成机器人覆盖图像，将V-JEPA视觉骨干网络从视频理解领域重新用于合成机器人视频的模仿学习。

Result: 在真实世界测试中，零样本训练的V-JEPA模型达到82%的成功率，优于少样本训练的π₀网络以及基于EmbodiSwap数据训练的π₀。

Conclusion: EmbodiSwap结合V-JEPA视觉骨干网络能够有效实现零样本模仿学习，在机器人操作任务中表现出色，并发布了相关代码、数据集和模型以促进可重复研究。

Abstract: We introduce EmbodiSwap - a method for producing photorealistic synthetic
robot overlays over human video. We employ EmbodiSwap for zero-shot imitation
learning, bridging the embodiment gap between in-the-wild ego-centric human
video and a target robot embodiment. We train a closed-loop robot manipulation
policy over the data produced by EmbodiSwap. We make novel use of V-JEPA as a
visual backbone, repurposing V-JEPA from the domain of video understanding to
imitation learning over synthetic robot videos. Adoption of V-JEPA outperforms
alternative vision backbones more conventionally used within robotics. In
real-world tests, our zero-shot trained V-JEPA model achieves an $82\%$ success
rate, outperforming a few-shot trained $\pi_0$ network as well as $\pi_0$
trained over data produced by EmbodiSwap. We release (i) code for generating
the synthetic robot overlays which takes as input human videos and an arbitrary
robot URDF and generates a robot dataset, (ii) the robot dataset we synthesize
over EPIC-Kitchens, HOI4D and Ego4D, and (iii) model checkpoints and inference
code, to facilitate reproducible research and broader adoption.

</details>


### [27] [Model-Based Adaptive Precision Control for Tabletop Planar Pushing Under Uncertain Dynamics](https://arxiv.org/abs/2510.03768)
*Aydin Ahmadi,Baris Akgun*

Main category: cs.RO

TL;DR: 提出了一个基于模型的非抓取桌面推动框架，使用单一学习模型处理多个任务而无需重新训练，结合GRU架构和MPPI控制器实现自适应控制。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动的平面推动方法能力狭窄，限制了更广泛的应用。需要开发能够处理多种任务且无需重新训练的通用框架。

Method: 采用循环GRU架构和非线性层捕捉物体-环境动态，结合MPPI采样控制器生成自适应动作，使用领域随机化进行仿真训练以支持仿真到实物的迁移。

Result: 在仿真和真实实验中表现出高精确定位成功率，在轨迹跟踪和避障任务中性能强劲，通过改变控制器目标函数即可解决不同任务。

Conclusion: 该框架成功实现了单一模型处理多种推动任务的能力，展示了在不确定动态、可变推动长度和多样化任务中的良好泛化性能。

Abstract: Data-driven planar pushing methods have recently gained attention as they
reduce manual engineering effort and improve generalization compared to
analytical approaches. However, most prior work targets narrow capabilities
(e.g., side switching, precision, or single-task training), limiting broader
applicability. We present a model-based framework for non-prehensile tabletop
pushing that uses a single learned model to address multiple tasks without
retraining. Our approach employs a recurrent GRU-based architecture with
additional non-linear layers to capture object-environment dynamics while
ensuring stability. A tailored state-action representation enables the model to
generalize across uncertain dynamics, variable push lengths, and diverse tasks.
For control, we integrate the learned dynamics with a sampling-based Model
Predictive Path Integral (MPPI) controller, which generates adaptive,
task-oriented actions. This framework supports side switching, variable-length
pushes, and objectives such as precise positioning, trajectory following, and
obstacle avoidance. Training is performed in simulation with domain
randomization to support sim-to-real transfer. We first evaluate the
architecture through ablation studies, showing improved prediction accuracy and
stable rollouts. We then validate the full system in simulation and real-world
experiments using a Franka Panda robot with markerless tracking. Results
demonstrate high success rates in precise positioning under strict thresholds
and strong performance in trajectory tracking and obstacle avoidance. Moreover,
multiple tasks are solved simply by changing the controller's objective
function, without retraining. While our current focus is on a single object
type, we extend the framework by training on wider push lengths and designing a
balanced controller that reduces the number of steps for longer-horizon goals.

</details>


### [28] [Trajectory prediction for heterogeneous agents: A performance analysis on small and imbalanced datasets](https://arxiv.org/abs/2510.03776)
*Tiago Rodrigues de Almeida,Yufei Zhu,Andrey Rudenko,Tomasz P. Kucner,Johannes A. Stork,Martin Magnusson,Achim J. Lilienthal*

Main category: cs.RO

TL;DR: 该论文研究了类别条件轨迹预测方法在机器人导航中的应用，比较了基于模式和深度学习的基线方法，发现在数据有限或类别不平衡时模式方法表现更好。


<details>
  <summary>Details</summary>
Motivation: 在复杂动态环境中，机器人需要预测周围智能体的未来行动和意图以实现高效导航和避碰。由于智能体的动态特性取决于其任务、角色或可观察标签，类别条件运动预测成为减少预测不确定性和提高异质智能体预测准确性的有前景方法。

Method: 提出了基于条件的模式方法和高效的深度学习基线方法，并在THÖR-MAGNI和Stanford Drone Dataset两个数据集上评估了这些方法。

Result: 实验表明，当考虑类别标签时，所有方法在大多数设置下都能提高准确性。更重要的是，在从不平衡数据集学习或在新环境中数据不足时存在显著差异。深度学习在平衡数据集上表现更好，但在数据有限的应用中，模式方法可能更优。

Conclusion: 类别条件轨迹预测能显著提高预测准确性，但在实际应用中需要根据数据可用性和类别平衡情况选择合适的方法：深度学习适合平衡数据集，模式方法更适合数据有限或类别不平衡的场景。

Abstract: Robots and other intelligent systems navigating in complex dynamic
environments should predict future actions and intentions of surrounding agents
to reach their goals efficiently and avoid collisions. The dynamics of those
agents strongly depends on their tasks, roles, or observable labels.
Class-conditioned motion prediction is thus an appealing way to reduce forecast
uncertainty and get more accurate predictions for heterogeneous agents.
However, this is hardly explored in the prior art, especially for mobile robots
and in limited data applications. In this paper, we analyse different
class-conditioned trajectory prediction methods on two datasets. We propose a
set of conditional pattern-based and efficient deep learning-based baselines,
and evaluate their performance on robotics and outdoors datasets (TH\"OR-MAGNI
and Stanford Drone Dataset). Our experiments show that all methods improve
accuracy in most of the settings when considering class labels. More
importantly, we observe that there are significant differences when learning
from imbalanced datasets, or in new environments where sufficient data is not
available. In particular, we find that deep learning methods perform better on
balanced datasets, but in applications with limited data, e.g., cold start of a
robot in a new environment, or imbalanced classes, pattern-based methods may be
preferable.

</details>


### [29] [COVER:COverage-VErified Roadmaps for Fixed-time Motion Planning in Continuous Semi-Static Environments](https://arxiv.org/abs/2510.03875)
*Niranjan Kumar Ilampooranan,Constantinos Chamzas*

Main category: cs.RO

TL;DR: COVER是一个用于半静态环境运动规划的框架，通过构建覆盖验证的路标图，在固定时间预算内保证查询成功率。


<details>
  <summary>Details</summary>
Motivation: 解决半静态环境中运动规划查询需要在固定时间内完成的问题，利用环境的结构化可变性提供比通用运动规划更强的保证。

Method: 通过分割障碍物配置空间并在每个分区内求解可行路径，系统性地验证路标图在每个分区的可行性。

Result: 在7自由度Panda机器人模拟实验中，COVER比现有方法获得更广泛的覆盖范围和更高的查询成功率。

Conclusion: COVER框架能够有效处理半静态环境中的运动规划问题，提供固定时间保证和更好的性能表现。

Abstract: Having the ability to answer motion-planning queries within a fixed time
budget is critical for the widespread deployment of robotic systems.
Semi-static environments, where most obstacles remain static but a limited set
can vary across queries, exhibit structured variability that can be
systematically exploited to provide stronger guarantees than in general
motion-planning problems. However, prior approaches in this setting either lack
formal guarantees or rely on restrictive discretizations of obstacle
configurations, limiting their applicability in realistic domains. This paper
introduces COVER, a novel framework that incrementally constructs a
coverage-verified roadmap in semi-static environments. By partitioning the
obstacle configuration space and solving for feasible paths within each
partition, COVER systematically verifies feasibility of the roadmap in each
partition and guarantees fixed-time motion planning queries within the verified
regions. We validate COVER with a 7-DOF simulated Panda robot performing table
and shelf tasks, demonstrating that COVER achieves broader coverage with higher
query success rates than prior works.

</details>


### [30] [Seeing the Bigger Picture: 3D Latent Mapping for Mobile Manipulation Policy Learning](https://arxiv.org/abs/2510.03885)
*Sunghwan Kim,Woojeh Chung,Zhirui Dai,Dwait Bhatt,Arth Shukla,Hao Su,Yulun Tian,Nikolay Atanasov*

Main category: cs.RO

TL;DR: SBP是一种利用3D潜在地图的移动操作策略，相比仅依赖图像的策略具有更强的时空推理能力，在场景级移动操作和顺序桌面操作任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有移动操作策略主要依赖图像输入，缺乏全局场景理解和长期记忆能力，限制了在复杂环境中的表现。

Method: 提出端到端策略学习方法SBP，构建3D潜在特征地图，通过多视角观测融合和在线优化，使用3D特征聚合器获取全局上下文信息。

Result: SBP在场景级移动操作和顺序桌面操作任务中显著优于基于图像的策略，在顺序操作任务中成功率提高了25%，在分布内和未见场景中均表现良好。

Conclusion: 3D潜在地图为移动操作提供了有效的全局场景理解和长期记忆机制，是实现复杂任务的关键技术。

Abstract: In this paper, we demonstrate that mobile manipulation policies utilizing a
3D latent map achieve stronger spatial and temporal reasoning than policies
relying solely on images. We introduce Seeing the Bigger Picture (SBP), an
end-to-end policy learning approach that operates directly on a 3D map of
latent features. In SBP, the map extends perception beyond the robot's current
field of view and aggregates observations over long horizons. Our mapping
approach incrementally fuses multiview observations into a grid of
scene-specific latent features. A pre-trained, scene-agnostic decoder
reconstructs target embeddings from these features and enables online
optimization of the map features during task execution. A policy, trainable
with behavior cloning or reinforcement learning, treats the latent map as a
state variable and uses global context from the map obtained via a 3D feature
aggregator. We evaluate SBP on scene-level mobile manipulation and sequential
tabletop manipulation tasks. Our experiments demonstrate that SBP (i) reasons
globally over the scene, (ii) leverages the map as long-horizon memory, and
(iii) outperforms image-based policies in both in-distribution and novel
scenes, e.g., improving the success rate by 25% for the sequential manipulation
task.

</details>


### [31] [NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot Manipulation](https://arxiv.org/abs/2510.03895)
*Zheng Huang,Mingyu Liu,Xiaoyi Lin,Muzhi Zhu,Canyu Zhao,Zongze Du,Xiaoman Li,Yiduo Jia,Hao Zhong,Hao Chen,Chunhua Shen*

Main category: cs.RO

TL;DR: 提出了NoTVLA框架，通过聚焦稀疏轨迹而非密集动作序列来解决VLA模型的灾难性遗忘问题，在保持语言能力的同时实现多任务泛化。


<details>
  <summary>Details</summary>
Motivation: 解决VLA模型在现实部署中面临的灾难性遗忘问题，该问题源于对连续动作序列的过度依赖导致的知识隔离。

Method: 采用轨迹规划策略，聚焦机器人末端执行器的稀疏轨迹而非目标物体轨迹，通过时间压缩和空间推理剪枝，使用稀疏轨迹进行训练。

Result: 在多任务评估中表现优于pi0，计算资源消耗降低一个数量级，无需腕部摄像头，操作精度接近单任务专家模型。

Conclusion: NoTVLA框架有效解决了灾难性遗忘问题，保持了模型的语言能力，支持跨平台部署和零样本泛化。

Abstract: Vision-Language-Action (VLA) models represent a pivotal advance in embodied
intelligence, yet they confront critical barriers to real-world deployment,
most notably catastrophic forgetting. This issue stems from their overreliance
on continuous action sequences or action chunks, which inadvertently create
isolated data silos that disrupt knowledge retention across tasks. To tackle
these challenges, we propose the Narrowing of Trajectory VLA (NoTVLA)
framework: a novel approach that narrows its focus to sparse trajectories,
thereby avoiding the catastrophic forgetting associated with dense trajectory
fine-tuning. A key innovation of NoTVLA lies in its trajectory planning
strategy: instead of centering on the target object's trajectory, it leverages
temporal compression and spatial reasoning pruning specifically for the robot
end effector's trajectory. Furthermore, training is conducted using these
sparse trajectories rather than dense action trajectories, an optimization that
delivers remarkable practical advantages with better performance in zero-shot.
In multi-task evaluation scenarios, NoTVLA achieves superior performance and
generalization compared to pi0 while operating under two critical constraints:
it uses over an order of magnitude less computing power than pi0 and requires
no wrist-mounted camera. This design ensures that NoTVLA's operational accuracy
closely approximates that of single-task expert models. Crucially, it also
preserves the model's inherent language capabilities, enabling zero-shot
generalization in specific scenarios, supporting unified model deployment
across multiple robot platforms, and fostering a degree of generalization even
when perceiving tasks from novel perspectives.

</details>


### [32] [WAFFLE: A Wearable Approach to Bite Timing Estimation in Robot-Assisted Feeding](https://arxiv.org/abs/2510.03910)
*Akhil Padmanabha,Jessie Yuan,Tanisha Mehta,Rajat Kumar Jenamani,Eric Hu,Victoria de León,Anthony Wertz,Janavi Gupta,Ben Dodson,Yunting Yan,Carmel Majidi,Tapomayukh Bhattacharjee,Zackory Erickson*

Main category: cs.RO

TL;DR: WAFFLE是一个基于可穿戴传感器的喂食系统，通过机器学习预测用户咬合时机，提高喂食机器人的反应性和自然性。


<details>
  <summary>Details</summary>
Motivation: 解决喂食机器人中咬合时机估计的技术挑战，帮助行动不便人士提高自主性和生活质量，减轻护理人员负担。

Method: 使用可穿戴传感器数据训练监督回归模型，预测咬合时机，并加入用户可调节的自信度阈值来控制机器人的行动。

Result: 在15名无障碍参与者研究中，WAFFLE在控制感、机器人理解和工作量方面表现优于基线方法，多数参与者偏好该系统。在2名运动障碍参与者家庭环境中也验证了其泛化能力。

Conclusion: WAFFLE能够实现自然、反应灵敏的咬合时机预测，适用于不同用户、机器人硬件、环境和用餐情境。

Abstract: Millions of people around the world need assistance with feeding. Robotic
feeding systems offer the potential to enhance autonomy and quality of life for
individuals with impairments and reduce caregiver workload. However, their
widespread adoption has been limited by technical challenges such as estimating
bite timing, the appropriate moment for the robot to transfer food to a user's
mouth. In this work, we introduce WAFFLE: Wearable Approach For Feeding with
LEarned bite timing, a system that accurately predicts bite timing by
leveraging wearable sensor data to be highly reactive to natural user cues such
as head movements, chewing, and talking. We train a supervised regression model
on bite timing data from 14 participants and incorporate a user-adjustable
assertiveness threshold to convert predictions into proceed or stop commands.
In a study with 15 participants without motor impairments with the Obi feeding
robot, WAFFLE performs statistically on par with or better than baseline
methods across measures of feeling of control, robot understanding, and
workload, and is preferred by the majority of participants for both individual
and social dining. We further demonstrate WAFFLE's generalizability in a study
with 2 participants with motor impairments in their home environments using a
Kinova 7DOF robot. Our findings support WAFFLE's effectiveness in enabling
natural, reactive bite timing that generalizes across users, robot hardware,
robot positioning, feeding trajectories, foods, and both individual and social
dining contexts.

</details>


### [33] [TCB-VIO: Tightly-Coupled Focal-Plane Binary-Enhanced Visual Inertial Odometry](https://arxiv.org/abs/2510.03919)
*Matthew Lisondra,Junseo Kim,Glenn Takashi Shimoda,Kourosh Zareinia,Sajad Saeedi*

Main category: cs.RO

TL;DR: TCB-VIO是一个在焦平面传感器处理器阵列上运行的紧密耦合6自由度视觉惯性里程计系统，通过多状态约束卡尔曼滤波器实现，在250FPS高帧率和400Hz IMU频率下运行，优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 传统视觉惯性里程计框架存在空间漂移（视觉姿态估计）和时间漂移（惯性测量）问题，FPSP通过高帧率运行来匹配惯性测量的高频输出，从而规避空间漂移问题。

Method: 使用多状态约束卡尔曼滤波器的紧密耦合6自由度VIO方法，在焦平面传感器处理器阵列上以250FPS高帧率运行，IMU测量频率为400Hz。

Result: TCB-VIO在性能上优于当前最先进的方法：ROVIO、VINS-Mono和ORB-SLAM3。

Conclusion: 在FPSP上实现高帧率VIO系统能有效减少空间漂移问题，TCB-VIO展示了优于现有方法的性能表现。

Abstract: Vision algorithms can be executed directly on the image sensor when
implemented on the next-generation sensors known as focal-plane
sensor-processor arrays (FPSP)s, where every pixel has a processor. FPSPs
greatly improve latency, reducing the problems associated with the bottleneck
of data transfer from a vision sensor to a processor. FPSPs accelerate
vision-based algorithms such as visual-inertial odometry (VIO). However, VIO
frameworks suffer from spatial drift due to the vision-based pose estimation,
whilst temporal drift arises from the inertial measurements. FPSPs circumvent
the spatial drift by operating at a high frame rate to match the high-frequency
output of the inertial measurements. In this paper, we present TCB-VIO, a
tightly-coupled 6 degrees-of-freedom VIO by a Multi-State Constraint Kalman
Filter (MSCKF), operating at a high frame-rate of 250 FPS and from IMU
measurements obtained at 400 Hz. TCB-VIO outperforms state-of-the-art methods:
ROVIO, VINS-Mono, and ORB-SLAM3.

</details>


### [34] [A Real-Time Framework for Intermediate Map Construction and Kinematically Feasible Off-Road Planning Without OSM](https://arxiv.org/abs/2510.03948)
*Otobong Jerome,Geesara Prathap Kulathunga,Devitt Dmitry,Eugene Murawjow,Alexandr Klimchik*

Main category: cs.RO

TL;DR: 提出了一种专为越野环境设计的全局路径规划方法，通过构建中间地图并分解为三个子问题，在保证实时性能、运动学可行性和内存效率的同时，成功在大规模地图上规划可行路径。


<details>
  <summary>Details</summary>
Motivation: 传统全局路径规划方法在越野环境中表现不佳，无法处理大规模地图，且忽略了实时性能、运动学可行性和内存效率等关键因素。

Method: 首先在像素坐标系中构建包含地理特征的中间地图，然后将规划问题分解为三个子问题：基于图的路径规划、运动学可行性检查和路径平滑。

Result: 在多种越野环境和大规模地图（达数平方公里）中测试，平均1.5秒找到可行路径，极端条件下内存使用约1.5GB。

Conclusion: 该框架适用于广泛的越野自主导航任务，包括搜救任务和农业作业。

Abstract: Off-road environments present unique challenges for autonomous navigation due
to their complex and unstructured nature. Traditional global path-planning
methods, which typically aim to minimize path length and travel time, perform
poorly on large-scale maps and fail to account for critical factors such as
real-time performance, kinematic feasibility, and memory efficiency. This paper
introduces a novel global path-planning method specifically designed for
off-road environments, addressing these essential factors. The method begins by
constructing an intermediate map within the pixel coordinate system,
incorporating geographical features like off-road trails, waterways, restricted
and passable areas, and trees. The planning problem is then divided into three
sub-problems: graph-based path planning, kinematic feasibility checking, and
path smoothing. This approach effectively meets real-time performance
requirements while ensuring kinematic feasibility and efficient memory use. The
method was tested in various off-road environments with large-scale maps up to
several square kilometers in size, successfully identifying feasible paths in
an average of 1.5 seconds and utilizing approximately 1.5GB of memory under
extreme conditions. The proposed framework is versatile and applicable to a
wide range of off-road autonomous navigation tasks, including search and rescue
missions and agricultural operations.

</details>


### [35] [SITCOM: Scaling Inference-Time COMpute for VLAs](https://arxiv.org/abs/2510.04041)
*Ayudh Saxena,Harsh Shah,Sandeep Routray,Rishi Rajesh Shah,Esha Pahwa*

Main category: cs.RO

TL;DR: SITCOM框架通过模型预测控制增强预训练的视觉-语言-动作模型，利用学习到的动力学模型进行多步动作推演，将单步VLA模型转变为鲁棒的长时域规划器。


<details>
  <summary>Details</summary>
Motivation: 解决VLA模型缺乏前瞻机制、在动态任务中容易累积误差的问题，以及机器人控制中数据收集成本高、泛化能力有限、长时域规划困难等挑战。

Method: 结合模型预测控制思想，使用基于Transformer的动力学模型在大规模BridgeV2数据上训练并在SIMPLER环境中微调，通过模拟多步动作推演和基于奖励的轨迹选择来优化决策。

Result: 在SIMPLER环境的多任务评估中，SITCOM结合良好奖励函数能将任务完成率从48%显著提升至72%。

Conclusion: SITCOM框架成功地将单步VLA模型转化为鲁棒的长时域规划器，通过模型推演和轨迹选择显著提升了机器人控制性能。

Abstract: Learning robust robotic control policies remains a major challenge due to the
high cost of collecting labeled data, limited generalization to unseen
environments, and difficulties in planning over long horizons. While
Vision-Language-Action (VLA) models offer a promising solution by grounding
natural language instructions into single-step control commands, they often
lack mechanisms for lookahead and struggle with compounding errors in dynamic
tasks. In this project, we introduce Scaling Inference-Time COMpute for VLAs
(SITCOM), a framework that augments any pretrained VLA with model-based
rollouts and reward-based trajectory selection, inspired by Model Predictive
Control algorithm. SITCOM leverages a learned dynamics model to simulate
multi-step action rollouts to select the best candidate plan for real-world
execution, transforming one-shot VLAs into robust long-horizon planners. We
develop an efficient transformer-based dynamics model trained on large-scale
BridgeV2 data and fine-tuned on SIMPLER environments to bridge the Real2Sim
gap, and score candidate rollouts using rewards from simulator. Through
comprehensive evaluation across multiple tasks and settings in the SIMPLER
environment, we demonstrate that SITCOM when combined with a good reward
function can significantly improve task completion rate from 48% to 72% using
trained dynamics model.

</details>


### [36] [Feedback Matters: Augmenting Autonomous Dissection with Visual and Topological Feedback](https://arxiv.org/abs/2510.04074)
*Chung-Pang Wang,Changwei Chen,Xiao Liang,Soofiyan Atar,Florian Richter,Michael Yip*

Main category: cs.RO

TL;DR: 提出了一种用于自主组织解剖的反馈驱动框架，通过内窥镜图像推理拓扑变化，结合可见性度量和最优控制器设计，显著提升手术自主性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有手术机器人反馈机制在处理组织解剖的拓扑和感知挑战方面存在局限，需要能够适应动态组织特性和视觉线索变化的自主系统。

Method: 提出反馈驱动框架，通过内窥镜图像分析解剖动作后的拓扑变化，引入可见性度量量化组织暴露，并设计最优控制器主动操作组织以最大化可见性。

Result: 将反馈机制与基于规划和学习的解剖方法集成，实验证明能显著增强自主性、减少错误并提高复杂手术场景的鲁棒性。

Conclusion: 反馈机制对于自主手术系统至关重要，所提出的框架通过结构化反馈和可见性优化，有效解决了组织解剖中的拓扑和感知挑战。

Abstract: Autonomous surgical systems must adapt to highly dynamic environments where
tissue properties and visual cues evolve rapidly. Central to such adaptability
is feedback: the ability to sense, interpret, and respond to changes during
execution. While feedback mechanisms have been explored in surgical robotics,
ranging from tool and tissue tracking to error detection, existing methods
remain limited in handling the topological and perceptual challenges of tissue
dissection. In this work, we propose a feedback-enabled framework for
autonomous tissue dissection that explicitly reasons about topological changes
from endoscopic images after each dissection action. This structured feedback
guides subsequent actions, enabling the system to localize dissection progress
and adapt policies online. To improve the reliability of such feedback, we
introduce visibility metrics that quantify tissue exposure and formulate
optimal controller designs that actively manipulate tissue to maximize
visibility. Finally, we integrate these feedback mechanisms with both
planning-based and learning-based dissection methods, and demonstrate
experimentally that they significantly enhance autonomy, reduce errors, and
improve robustness in complex surgical scenarios.

</details>


### [37] [From Shadow to Light: Toward Safe and Efficient Policy Learning Across MPC, DeePC, RL, and LLM Agents](https://arxiv.org/abs/2510.04076)
*Amin Vahidi-Moghaddam,Sayed Pedram Haeri Boroujeni,Iman Jebellat,Ehsan Jebellat,Niloufar Mehrabi,Zhaojian Li*

Main category: cs.RO

TL;DR: 本文综述了八种降低数据驱动控制策略计算复杂度的技术，包括降阶建模、函数逼近策略学习和凸松弛等方法，并在机器人、软机器人和车辆运动控制等实际应用中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 解决数据驱动控制策略（如MPC、RL、DeePC等）在实时应用中面临的计算复杂度高、响应慢、内存需求大等问题，使其更适合具有快速动态、有限计算资源或严格内存约束的实际系统。

Method: 提出了八种降低计算复杂度的技术：降阶建模、函数逼近策略学习、凸松弛等，旨在减少数据驱动控制策略的计算负担和内存需求。

Result: 这些方法在真实世界应用中（包括机械臂、软机器人和车辆运动控制）被证明有效，能够显著提升控制策略的实时性和实用性。

Conclusion: 通过采用计算复杂度降低技术，数据驱动控制策略可以更好地适应实际系统的需求，在保持高性能的同时满足实时性、计算资源和内存约束的要求。

Abstract: One of the main challenges in modern control applications, particularly in
robot and vehicle motion control, is achieving accurate, fast, and safe
movement. To address this, optimal control policies have been developed to
enforce safety while ensuring high performance. Since basic first-principles
models of real systems are often available, model-based controllers are widely
used. Model predictive control (MPC) is a leading approach that optimizes
performance while explicitly handling safety constraints. However, obtaining
accurate models for complex systems is difficult, which motivates data-driven
alternatives. ML-based MPC leverages learned models to reduce reliance on
hand-crafted dynamics, while reinforcement learning (RL) can learn near-optimal
policies directly from interaction data. Data-enabled predictive control
(DeePC) goes further by bypassing modeling altogether, directly learning safe
policies from raw input-output data. Recently, large language model (LLM)
agents have also emerged, translating natural language instructions into
structured formulations of optimal control problems. Despite these advances,
data-driven policies face significant limitations. They often suffer from slow
response times, high computational demands, and large memory needs, making them
less practical for real-world systems with fast dynamics, limited onboard
computing, or strict memory constraints. To address this, various technique,
such as reduced-order modeling, function-approximated policy learning, and
convex relaxations, have been proposed to reduce computational complexity. In
this paper, we present eight such approaches and demonstrate their
effectiveness across real-world applications, including robotic arms, soft
robots, and vehicle motion control.

</details>


### [38] [HEHA: Hierarchical Planning for Heterogeneous Multi-Robot Exploration of Unknown Environments](https://arxiv.org/abs/2510.04161)
*Longrui Yang,Yiyu Wang,Jingfan Tang,Yunpeng Lv,Shizhe Zhao,Chao Cao,Zhongqiang Ren*

Main category: cs.RO

TL;DR: HEHA是一个用于多异构机器人自主探索未知环境的分层路径规划方法，通过全局规划和局部规划相结合，使用PEAF算法快速求解有界次优解，减少异构机器人探索时间达30%。


<details>
  <summary>Details</summary>
Motivation: 解决多异构机器人（无人机、轮式、腿式机器人）在未知环境中探索时的路径规划问题，这些机器人具有不同的地形穿越能力，需要智能分配探索区域并确定访问顺序，同时满足可穿越性约束。

Method: 提出HEHA分层探索框架：全局规划使用PEAF（部分任意时间焦点搜索）算法快速求解有界次优解，最小化各代理的最大路径长度；局部规划考虑异构性避免重复探索。

Result: 实验结果表明，HEHA相比基线方法能够减少高达30%的探索时间。

Conclusion: HEHA通过分层规划和考虑异构性的方法，有效解决了多异构机器人探索未知环境的大规模约束优化问题，显著提高了探索效率。

Abstract: This paper considers the path planning problem for autonomous exploration of
an unknown environment using multiple heterogeneous robots such as drones,
wheeled, and legged robots, which have different capabilities to traverse
complex terrains. A key challenge there is to intelligently allocate the robots
to the unknown areas to be explored and determine the visiting order of those
spaces subject to traversablity constraints, which leads to a large scale
constrained optimization problem that needs to be quickly and iteratively
solved every time when new space are explored. To address the challenge, we
propose HEHA (Hierarchical Exploration with Heterogeneous Agents) by leveraging
a recent hierarchical method that decompose the exploration into global
planning and local planning. The major contribution in HEHA is its global
planning, where we propose a new routing algorithm PEAF (Partial Anytime Focal
search) that can quickly find bounded sub-optimal solutions to minimize the
maximum path length among the agents subject to traversability constraints.
Additionally, the local planner in HEHA also considers heterogeneity to avoid
repeated and duplicated exploration among the robots. The experimental results
show that, our HEHA can reduce up to 30% of the exploration time than the
baselines.

</details>


### [39] [Learning to Capture Rocks using an Excavator: A Reinforcement Learning Approach with Guiding Reward Formulation](https://arxiv.org/abs/2510.04168)
*Amirmasoud Molaei,Reza Ghabcheloo*

Main category: cs.RO

TL;DR: 本文提出了一种完全数据驱动的控制框架，用于挖掘机抓取岩石任务，无需对岩石或土壤属性进行显式建模。


<details>
  <summary>Details</summary>
Motivation: 标准挖掘机抓取岩石是一项具有挑战性的任务，通常需要熟练操作员的专业知识。现有自主挖掘方法主要关注连续介质或依赖专用夹具，限制了其在真实建筑工场的适用性。

Method: 使用模型无关的强化学习代理在AGX Dynamics模拟器中训练，采用PPO算法和引导奖励公式。学习策略直接输出关节速度命令到挖掘机的动臂、臂和铲斗。通过广泛的领域随机化增强鲁棒性。

Result: 实验结果表明，该策略能够很好地泛化到未见过的岩石和变化的土壤条件，实现与人类参与者相当的高成功率，同时保持机器稳定性。

Conclusion: 这些发现证明了基于学习的挖掘策略在离散物体操作中的可行性，无需专用硬件或详细材料模型。

Abstract: Rock capturing with standard excavator buckets is a challenging task
typically requiring the expertise of skilled operators. Unlike soil digging, it
involves manipulating large, irregular rocks in unstructured environments where
complex contact interactions with granular material make model-based control
impractical. Existing autonomous excavation methods focus mainly on continuous
media or rely on specialized grippers, limiting their applicability to
real-world construction sites. This paper introduces a fully data-driven
control framework for rock capturing that eliminates the need for explicit
modeling of rock or soil properties. A model-free reinforcement learning agent
is trained in the AGX Dynamics simulator using the Proximal Policy Optimization
(PPO) algorithm and a guiding reward formulation. The learned policy outputs
joint velocity commands directly to the boom, arm, and bucket of a CAT365
excavator model. Robustness is enhanced through extensive domain randomization
of rock geometry, density, and mass, as well as the initial configurations of
the bucket, rock, and goal position. To the best of our knowledge, this is the
first study to develop and evaluate an RL-based controller for the rock
capturing task. Experimental results show that the policy generalizes well to
unseen rocks and varying soil conditions, achieving high success rates
comparable to those of human participants while maintaining machine stability.
These findings demonstrate the feasibility of learning-based excavation
strategies for discrete object manipulation without requiring specialized
hardware or detailed material models.

</details>


### [40] [VBM-NET: Visual Base Pose Learning for Mobile Manipulation using Equivariant TransporterNet and GNNs](https://arxiv.org/abs/2510.04171)
*Lakshadeep Naik,Adam Fischer,Daniel Duberg,Danica Kragic*

Main category: cs.RO

TL;DR: VBM-NET是一个基于学习的移动机器人基座姿态选择方法，使用俯视正交投影图进行规划，比传统方法计算时间显著减少，并能实现从仿真到真实环境的迁移。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖精确的状态信息（如物体位姿和环境模型），而本文研究直接从俯视正交投影图进行基座姿态规划，提供全局场景概览并保持空间结构。

Method: 使用等变TransporterNet利用空间对称性高效学习抓取候选基座姿态，采用图神经网络表示可变数量的候选姿态，并使用强化学习从中选择最优基座姿态。

Result: VBM-NET能在显著减少计算时间的情况下产生与传统方法相当的解决方案，并在仿真中训练的策略成功部署到真实世界移动操作中。

Conclusion: 该方法证明了直接从视觉输入进行基座姿态规划的有效性，实现了高效的计算性能和成功的仿真到真实环境迁移。

Abstract: In Mobile Manipulation, selecting an optimal mobile base pose is essential
for successful object grasping. Previous works have addressed this problem
either through classical planning methods or by learning state-based policies.
They assume access to reliable state information, such as the precise object
poses and environment models. In this work, we study base pose planning
directly from top-down orthographic projections of the scene, which provide a
global overview of the scene while preserving spatial structure. We propose
VBM-NET, a learning-based method for base pose selection using such top-down
orthographic projections. We use equivariant TransporterNet to exploit spatial
symmetries and efficiently learn candidate base poses for grasping. Further, we
use graph neural networks to represent a varying number of candidate base poses
and use Reinforcement Learning to determine the optimal base pose among them.
We show that VBM-NET can produce comparable solutions to the classical methods
in significantly less computation time. Furthermore, we validate sim-to-real
transfer by successfully deploying a policy trained in simulation to real-world
mobile manipulation.

</details>


### [41] [Using Robotics to Improve Transcatheter Edge-to-Edge Repair of the Mitral Valve](https://arxiv.org/abs/2510.04178)
*Léa Pistorius,Namrata U. Nayar,Phillip Tran,Sammy Elmariah,Pierre E. Dupont*

Main category: cs.RO

TL;DR: 该论文研究机器人辅助在二尖瓣边对边修复手术中的应用，通过游戏控制器实现直观的机器人关节控制，相比手动操作能减少手术时间、运动误差并提高夹子放置精度。


<details>
  <summary>Details</summary>
Motivation: 经导管瓣膜修复手术面临机械限制和陡峭的学习曲线挑战，需要更可靠和用户友好的平台来改善手术效果。

Method: 将临床修复设备的复杂手柄控制替换为通过游戏控制器实现的直观机器人关节控制，在心脏和血管系统的体模模型中比较手动与机器人性能，分解设备输送任务为具体步骤进行分析。

Result: 机器人系统能够减少手术时间和运动误差，同时提高夹子放置的准确性。

Conclusion: 机器人辅助可以解决手动系统的关键限制，为复杂的经导管手术提供更可靠和用户友好的平台。

Abstract: Transcatheter valve repair presents significant challenges due to the
mechanical limitations and steep learning curve associated with manual catheter
systems. This paper investigates the use of robotics to facilitate
transcatheter procedures in the context of mitral valve edge-to-edge repair.
The complex handle-based control of a clinical repair device is replaced by
intuitive robotic joint-based control via a game controller. Manual versus
robotic performance is analyzed by decomposing the overall device delivery task
into motion-specific steps and comparing capabilities on a step-by-step basis
in a phantom model of the heart and vasculature. Metrics include procedure
duration and clip placement accuracy. Results demonstrate that the robotic
system can reduce procedural time and motion errors while also improving
accuracy of clip placement. These findings suggest that robotic assistance can
address key limitations of manual systems, offering a more reliable and
user-friendly platform for complex transcatheter procedures.

</details>


### [42] [Zenbo Patrol: A Social Assistive Robot Based on Multimodal Deep Learning for Real-time Illegal Parking Recognition and Notification](https://arxiv.org/abs/2510.04190)
*Jian-jie Zheng,Chih-kai Yang,Po-han Chen,Lyn Chao-ling Chen*

Main category: cs.RO

TL;DR: 使用GPT-4o多模态模型进行车牌识别，通过社交机器人巡逻检测非法停车并实时通知系统管理员


<details>
  <summary>Details</summary>
Motivation: 解决室内停车场非法停车问题，开发实时监控和通知系统

Method: 采用GPT-4o多模态模型进行车牌识别，无需预处理；机器人自动调整摄像头角度捕获车牌图像；通过Line消息实时通知

Result: 验证了多模态深度学习方法在车牌识别中的高准确性，可在室内停车场实际应用

Conclusion: 提出了一种新颖的多模态深度学习方法，通过社交辅助机器人解决实际场景问题

Abstract: In the study, the social robot act as a patrol to recognize and notify
illegal parking in real-time. Dual-model pipeline method and large multimodal
model were compared, and the GPT-4o multimodal model was adopted in license
plate recognition without preprocessing. For moving smoothly on a flat ground,
the robot navigated in a simulated parking lot in the experiments. The robot
changes angle view of the camera automatically to capture the images around
with the format of license plate number. From the captured images of the robot,
the numbers on the plate are recognized through the GPT-4o model, and
identifies legality of the numbers. When an illegal parking is detected, the
robot sends Line messages to the system manager immediately. The contribution
of the work is that a novel multimodal deep learning method has validated with
high accuracy in license plate recognition, and a social assistive robot is
also provided for solving problems in a real scenario, and can be applied in an
indoor parking lot.

</details>


### [43] [Flexible Locomotion Learning with Diffusion Model Predictive Control](https://arxiv.org/abs/2510.04234)
*Runhan Huang,Haldun Balim,Heng Yang,Yilun Du*

Main category: cs.RO

TL;DR: 提出了Diffusion-MPC方法，使用学习的生成扩散模型作为规划中的近似动力学先验，通过奖励和约束优化实现灵活测试时适应。


<details>
  <summary>Details</summary>
Motivation: 腿式运动需要既鲁棒又适应的控制器，但无模型强化学习产生固定策略难以适应新行为，而传统MPC依赖准确动力学模型难以获得。

Method: 使用扩散模型作为动力学先验进行规划，在反向步骤中结合奖励规划和约束投影，并通过交互训练算法更新去噪器。

Result: 在真实世界中验证了强大的运动能力和灵活适应能力，能够适应新的奖励规范而无需重新训练。

Conclusion: Diffusion-MPC实现了强大的测试时适应性，允许规划器调整到新的奖励规范而无需重新训练。

Abstract: Legged locomotion demands controllers that are both robust and adaptable,
while remaining compatible with task and safety considerations. However,
model-free reinforcement learning (RL) methods often yield a fixed policy that
can be difficult to adapt to new behaviors at test time. In contrast, Model
Predictive Control (MPC) provides a natural approach to flexible behavior
synthesis by incorporating different objectives and constraints directly into
its optimization process. However, classical MPC relies on accurate dynamics
models, which are often difficult to obtain in complex environments and
typically require simplifying assumptions. We present Diffusion-MPC, which
leverages a learned generative diffusion model as an approximate dynamics prior
for planning, enabling flexible test-time adaptation through reward and
constraint based optimization. Diffusion-MPC jointly predicts future states and
actions; at each reverse step, we incorporate reward planning and impose
constraint projection, yielding trajectories that satisfy task objectives while
remaining within physical limits. To obtain a planning model that adapts beyond
imitation pretraining, we introduce an interactive training algorithm for
diffusion based planner: we execute our reward-and-constraint planner in
environment, then filter and reweight the collected trajectories by their
realized returns before updating the denoiser. Our design enables strong
test-time adaptability, allowing the planner to adjust to new reward
specifications without retraining. We validate Diffusion-MPC on real world,
demonstrating strong locomotion and flexible adaptation.

</details>


### [44] [ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame Context](https://arxiv.org/abs/2510.04246)
*Huiwon Jang,Sihyun Yu,Heeseung Kwon,Hojin Jeon,Younggyo Seo,Jinwoo Shin*

Main category: cs.RO

TL;DR: ContextVLA是一种通过压缩多帧观测为单个上下文token来有效利用时序上下文提升机器人任务性能的策略模型


<details>
  <summary>Details</summary>
Motivation: 现有行为克隆方法在使用多帧观测时性能提升不一致，而视觉-语言-动作模型(VLA)能更有效地利用多帧观测生成动作，但视频输入的高维度带来了计算开销问题

Method: 将过去的观测压缩成单个上下文token，使策略能够高效利用时序上下文生成动作，同时减少训练和推理时间

Result: ContextVLA相比单帧VLA持续改进性能，实现了完整多帧训练的优势但减少了训练和推理时间

Conclusion: ContextVLA通过有效压缩多帧观测，在保持VLA模型时序理解能力的同时解决了计算效率问题

Abstract: Leveraging temporal context is crucial for success in partially observable
robotic tasks. However, prior work in behavior cloning has demonstrated
inconsistent performance gains when using multi-frame observations. In this
paper, we introduce ContextVLA, a policy model that robustly improves robotic
task performance by effectively leveraging multi-frame observations. Our
approach is motivated by the key observation that Vision-Language-Action models
(VLA), i.e., policy models built upon a Vision-Language Model (VLM), more
effectively utilize multi-frame observations for action generation. This
suggests that VLMs' inherent temporal understanding capability enables them to
extract more meaningful context from multi-frame observations. However, the
high dimensionality of video inputs introduces significant computational
overhead, making VLA training and inference inefficient. To address this,
ContextVLA compresses past observations into a single context token, allowing
the policy to efficiently leverage temporal context for action generation. Our
experiments show that ContextVLA consistently improves over single-frame VLAs
and achieves the benefits of full multi-frame training but with reduced
training and inference times.

</details>


### [45] [Integrated Planning and Control on Manifolds: Factor Graph Representation and Toolkit](https://arxiv.org/abs/2510.04278)
*Peiwen Yang,Weisong Wen,Runqiu Yang,Yuanyuan Zhang,Jiahao Hu,Yingming Chen,Naigui Xiao,Jiaqi Zhao*

Main category: cs.RO

TL;DR: FactorMPC是一个基于因子图的MPC工具包，专门用于处理非线性流形上的系统控制问题，如机器人姿态动力学和约束运动规划，通过统一的优化结构实现实时性能和安全避障。


<details>
  <summary>Details</summary>
Motivation: 传统MPC在处理非线性流形系统时面临奇异性、过参数化和收敛困难等问题，需要一种几何一致且高效的解决方案。

Method: 采用因子图方法，将系统动力学、约束和目标统一到模块化优化结构中，支持流形值状态和切空间高斯不确定性建模，并设计了基于速度扩展的流形控制屏障函数进行安全避障。

Result: 在四旋翼无人机上的仿真和实验结果显示，相比基线方法，FactorMPC在轨迹跟踪和避障性能上表现更优。

Conclusion: FactorMPC通过将图模型与安全关键MPC相结合，为集成规划与控制提供了一个可扩展且几何一致的框架，并提供了开源实现以促进研究可复现性。

Abstract: Model predictive control (MPC) faces significant limitations when applied to
systems evolving on nonlinear manifolds, such as robotic attitude dynamics and
constrained motion planning, where traditional Euclidean formulations struggle
with singularities, over-parameterization, and poor convergence. To overcome
these challenges, this paper introduces FactorMPC, a factor-graph based MPC
toolkit that unifies system dynamics, constraints, and objectives into a
modular, user-friendly, and efficient optimization structure. Our approach
natively supports manifold-valued states with Gaussian uncertainties modeled in
tangent spaces. By exploiting the sparsity and probabilistic structure of
factor graphs, the toolkit achieves real-time performance even for
high-dimensional systems with complex constraints. The velocity-extended
on-manifold control barrier function (CBF)-based obstacle avoidance factors are
designed for safety-critical applications. By bridging graphical models with
safety-critical MPC, our work offers a scalable and geometrically consistent
framework for integrated planning and control. The simulations and experimental
results on the quadrotor demonstrate superior trajectory tracking and obstacle
avoidance performance compared to baseline methods. To foster research
reproducibility, we have provided open-source implementation offering
plug-and-play factors.

</details>


### [46] [Stability-Aware Retargeting for Humanoid Multi-Contact Teleoperation](https://arxiv.org/abs/2510.04353)
*Stephen McCrory,Romeo Orsolino,Dhruv Thanki,Luigi Penco,Robert Griffin*

Main category: cs.RO

TL;DR: 提出了一种基于质心稳定性的重定向方法，在遥操作过程中动态调整接触点和姿态，以增强在复杂接触场景下的稳定性。


<details>
  <summary>Details</summary>
Motivation: 遥操作在涉及手部接触和非共面表面时变得困难，常导致电机扭矩饱和或通过滑动失去稳定性。

Method: 使用高效的解析计算稳定性裕度梯度，识别对遥操作设定点高度敏感的场景，并局部调整这些设定点。

Result: 在仿真和硬件实验中验证了该方法，展示了增加稳定性裕度，并经验证明更高稳定性裕度与改进的冲击恢复能力和关节扭矩裕度相关。

Conclusion: 所提出的基于质心稳定性的重定向方法有效提高了人形机器人在复杂接触场景下的稳定性和控制性能。

Abstract: Teleoperation is a powerful method to generate reference motions and enable
humanoid robots to perform a broad range of tasks. However, teleoperation
becomes challenging when using hand contacts and non-coplanar surfaces, often
leading to motor torque saturation or loss of stability through slipping. We
propose a centroidal stability-based retargeting method that dynamically
adjusts contact points and posture during teleoperation to enhance stability in
these difficult scenarios. Central to our approach is an efficient analytical
calculation of the stability margin gradient. This gradient is used to identify
scenarios for which stability is highly sensitive to teleoperation setpoints
and inform the local adjustment of these setpoints. We validate the framework
in simulation and hardware by teleoperating manipulation tasks on a humanoid,
demonstrating increased stability margins. We also demonstrate empirically that
higher stability margins correlate with improved impulse resilience and joint
torque margin.

</details>


### [47] [Reliable and Scalable Robot Policy Evaluation with Imperfect Simulators](https://arxiv.org/abs/2510.04354)
*Apurva Badithela,David Snyder,Lihan Zha,Joseph Mikhail,Matthew O'Kelly,Anushri Dixit,Anirudha Majumdar*

Main category: cs.RO

TL;DR: SureSim框架通过结合小规模真实世界测试和大规模仿真，为机器人策略性能提供可靠的统计推断，可节省20-25%的硬件评估成本。


<details>
  <summary>Details</summary>
Motivation: 当前机器人策略评估通常基于少量硬件试验，缺乏统计保证，需要更可靠的评估方法。

Method: 将真实与仿真评估结合问题形式化为预测驱动的推理问题，利用少量配对真实和仿真评估来校正大规模仿真的偏差，并采用非渐近均值估计算法提供置信区间。

Result: 在物理仿真中评估扩散策略和多任务微调策略，该方法可节省20-25%的硬件评估工作量，同时达到相似的性能边界。

Conclusion: SureSim框架能够有效结合仿真和真实世界测试，为机器人策略性能评估提供统计可靠且成本效益高的解决方案。

Abstract: Rapid progress in imitation learning, foundation models, and large-scale
datasets has led to robot manipulation policies that generalize to a wide-range
of tasks and environments. However, rigorous evaluation of these policies
remains a challenge. Typically in practice, robot policies are often evaluated
on a small number of hardware trials without any statistical assurances. We
present SureSim, a framework to augment large-scale simulation with relatively
small-scale real-world testing to provide reliable inferences on the real-world
performance of a policy. Our key idea is to formalize the problem of combining
real and simulation evaluations as a prediction-powered inference problem, in
which a small number of paired real and simulation evaluations are used to
rectify bias in large-scale simulation. We then leverage non-asymptotic mean
estimation algorithms to provide confidence intervals on mean policy
performance. Using physics-based simulation, we evaluate both diffusion policy
and multi-task fine-tuned \(\pi_0\) on a joint distribution of objects and
initial conditions, and find that our approach saves over \(20-25\%\) of
hardware evaluation effort to achieve similar bounds on policy performance.

</details>


### [48] [PAD-TRO: Projection-Augmented Diffusion for Direct Trajectory Optimization](https://arxiv.org/abs/2510.04436)
*Jushan Chen,Santiago Paternain*

Main category: cs.RO

TL;DR: 提出了一种基于模型扩散的直接轨迹优化方法，通过梯度自由投影机制在反向扩散过程中确保动态可行性，相比现有方法实现了零动态可行性误差和4倍成功率提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的轨迹优化方法采用单次射击方式，无法显式强制执行状态约束，经常导致次优解和动态可行性问题。

Method: 提出直接轨迹优化方法，通过模型扩散直接生成状态序列，并在反向扩散过程中融入梯度自由投影机制来确保动态可行性。

Result: 在四旋翼航点导航场景中，相比现有最优基线方法，实现了零动态可行性误差和约4倍的成功率提升。

Conclusion: 该方法有效解决了扩散模型轨迹优化中的动态可行性挑战，显著提升了轨迹优化的性能。

Abstract: Recently, diffusion models have gained popularity and attention in trajectory
optimization due to their capability of modeling multi-modal probability
distributions. However, addressing nonlinear equality constraints, i.e, dynamic
feasi- bility, remains a great challenge in diffusion-based trajectory
optimization. Recent diffusion-based trajectory optimization frameworks rely on
a single-shooting style approach where the denoised control sequence is applied
to forward propagate the dynamical system, which cannot explicitly enforce
constraints on the states and frequently leads to sub-optimal solutions. In
this work, we propose a novel direct trajectory optimization approach via
model-based diffusion, which directly generates a sequence of states. To ensure
dynamic feasibility, we propose a gradient-free projection mechanism that is
incorporated into the reverse diffusion process. Our results show that,
compared to a recent state-of-the-art baseline, our approach leads to zero
dynamic feasibility error and approximately 4x higher success rate in a
quadrotor waypoint navigation scenario involving dense static obstacles.

</details>


### [49] [Velocity-Form Data-Enabled Predictive Control of Soft Robots under Unknown External Payloads](https://arxiv.org/abs/2510.04509)
*Huanqing Wang,Kaixiang Zhang,Kyungjoon Lee,Yu Mei,Vaibhav Srivastava,Jun Sheng,Ziyou Song,Zhaojian Li*

Main category: cs.RO

TL;DR: 提出了一种新颖的基于速度形式的数据驱动预测控制框架，用于在未知负载下实现软体机器人的鲁棒和最优控制。


<details>
  <summary>Details</summary>
Motivation: 在软体机器人控制中，未知外部负载和干扰会显著改变系统动态，导致偏移误差和控制性能下降。

Method: 利用增量表示的输入输出数据来减轻未知负载引起的性能退化，无需加权数据集或干扰估计器。

Result: 在平面软体机器人上的实验验证表明，该方法在涉及未知负载的场景中比标准DeePC具有更优越的性能。

Conclusion: 所提出的速度形式DeePC框架能够有效处理未知负载，提高软体机器人控制的鲁棒性和性能。

Abstract: Data-driven control methods such as data-enabled predictive control (DeePC)
have shown strong potential in efficient control of soft robots without
explicit parametric models. However, in object manipulation tasks, unknown
external payloads and disturbances can significantly alter the system dynamics
and behavior, leading to offset error and degraded control performance. In this
paper, we present a novel velocity-form DeePC framework that achieves robust
and optimal control of soft robots under unknown payloads. The proposed
framework leverages input-output data in an incremental representation to
mitigate performance degradation induced by unknown payloads, eliminating the
need for weighted datasets or disturbance estimators. We validate the method
experimentally on a planar soft robot and demonstrate its superior performance
compared to standard DeePC in scenarios involving unknown payloads.

</details>


### [50] [Everything-Grasping (EG) Gripper: A Universal Gripper with Synergistic Suction-Grasping Capabilities for Cross-Scale and Cross-State Manipulation](https://arxiv.org/abs/2510.04585)
*Jianshu Zhou,Jing Shu,Tianle Pan,Puchen Zhu,Jiajun An,Huayu Zhang,Junda Huang,Upinder Kaur,Xin Ma,Masayoshi Tomizuka*

Main category: cs.RO

TL;DR: 提出了一种结合分布式表面吸附和内部颗粒阻塞的软体抓取器，能够跨尺度和跨状态（固体和液体）抓取物体，无需气密密封。


<details>
  <summary>Details</summary>
Motivation: 解决软体机器人中单一抓取器处理不同尺寸和物理状态（包括固体和液体）物体的基本挑战。

Method: 开发了Everything-Grasping（EG）抓取器，整合分布式表面吸附和内部颗粒阻塞机制，并引入结合液体检测和压力反馈的触觉感知框架，以及基于触觉推断的抓取模式选择算法。

Result: 能够抓取表面面积从0.2 mm²到超过62,000 mm²的物体，比自身接触面积小3500倍和大88倍，在水下抓取、脆弱物体处理和液体捕获等任务中表现出稳健和可重复的性能。

Conclusion: 这是第一个使用统一柔性架构可靠抓取跨尺度固体和液体物体的软体抓取器。

Abstract: Grasping objects across vastly different sizes and physical states-including
both solids and liquids-with a single robotic gripper remains a fundamental
challenge in soft robotics. We present the Everything-Grasping (EG) Gripper, a
soft end-effector that synergistically integrates distributed surface suction
with internal granular jamming, enabling cross-scale and cross-state
manipulation without requiring airtight sealing at the contact interface with
target objects. The EG Gripper can handle objects with surface areas ranging
from sub-millimeter scale 0.2 mm2 (glass bead) to over 62,000 mm2 (A4 sized
paper and woven bag), enabling manipulation of objects nearly 3,500X smaller
and 88X larger than its own contact area (approximated at 707 mm2 for a 30
mm-diameter base). We further introduce a tactile sensing framework that
combines liquid detection and pressure-based suction feedback, enabling
real-time differentiation between solid and liquid targets. Guided by the
actile-Inferred Grasping Mode Selection (TIGMS) algorithm, the gripper
autonomously selects grasping modes based on distributed pressure and voltage
signals. Experiments across diverse tasks-including underwater grasping,
fragile object handling, and liquid capture-demonstrate robust and repeatable
performance. To our knowledge, this is the first soft gripper to reliably grasp
both solid and liquid objects across scales using a unified compliant
architecture.

</details>


### [51] [MobRT: A Digital Twin-Based Framework for Scalable Learning in Mobile Manipulation](https://arxiv.org/abs/2510.04592)
*Yilin Mei,Peng Qiu,Wei Zhang,WenChao Zhang,Wenjie Song*

Main category: cs.RO

TL;DR: MobRT是一个基于数字孪生的框架，用于生成移动机械臂复杂全身任务的多样化演示数据，显著提升策略泛化能力和性能。


<details>
  <summary>Details</summary>
Motivation: 移动机械臂的模仿学习面临高质量演示数据收集困难的问题，现有研究多局限于简单的桌面场景，而移动操作任务相对未被充分探索。

Method: 通过虚拟运动学控制和全身运动规划集成，自主生成多样化和真实的演示，包括与铰接物体交互和移动基座拾放操作。

Result: 实验表明，生成的数据质量高，任务成功率与生成轨迹数量强相关，在模拟和真实环境中均实现了稳健的性能提升。

Conclusion: MobRT框架有效解决了移动机械臂演示数据稀缺的问题，为复杂全身任务提供了可靠的基准和解决方案。

Abstract: Recent advances in robotics have been largely driven by imitation learning,
which depends critically on large-scale, high-quality demonstration data.
However, collecting such data remains a significant challenge-particularly for
mobile manipulators, which must coordinate base locomotion and arm manipulation
in high-dimensional, dynamic, and partially observable environments.
Consequently, most existing research remains focused on simpler tabletop
scenarios, leaving mobile manipulation relatively underexplored. To bridge this
gap, we present \textit{MobRT}, a digital twin-based framework designed to
simulate two primary categories of complex, whole-body tasks: interaction with
articulated objects (e.g., opening doors and drawers) and mobile-base
pick-and-place operations. \textit{MobRT} autonomously generates diverse and
realistic demonstrations through the integration of virtual kinematic control
and whole-body motion planning, enabling coherent and physically consistent
execution. We evaluate the quality of \textit{MobRT}-generated data across
multiple baseline algorithms, establishing a comprehensive benchmark and
demonstrating a strong correlation between task success and the number of
generated trajectories. Experiments integrating both simulated and real-world
demonstrations confirm that our approach markedly improves policy
generalization and performance, achieving robust results in both simulated and
real-world environments.

</details>


### [52] [OKVIS2-X: Open Keyframe-based Visual-Inertial SLAM Configurable with Dense Depth or LiDAR, and GNSS](https://arxiv.org/abs/2510.04612)
*Simon Boche,Jaehyung Jung,Sebastián Barbas Laina,Stefan Leutenegger*

Main category: cs.RO

TL;DR: OKVIS2-X是一个先进的多传感器SLAM系统，能够构建密集体素占据地图，在大规模环境中实时运行，并在多个基准测试中达到最先进的精度。


<details>
  <summary>Details</summary>
Motivation: 为了让移动机器人拥有可用的地图以及最高的状态估计精度和鲁棒性，需要开发一个能够无缝集成多种传感器模态的统一SLAM框架。

Method: 采用统一的SLAM框架集成视觉、惯性、深度、LiDAR和GNSS测量；使用密集体素地图表示；采用高效的子地图策略；通过地图对齐因子紧密耦合估计器和子地图；支持相机外参在线校准。

Result: 在EuRoC数据集中获得最高的轨迹精度；在Hilti22 VI-only基准测试中优于所有竞争对手；在LiDAR版本中具有竞争力；在VBR数据集的大规模序列中展示出最先进的精度。

Conclusion: OKVIS2-X是一个功能强大的多传感器SLAM系统，能够在大规模环境中构建全局一致的可用地图，并在多个基准测试中达到最先进的性能。

Abstract: To empower mobile robots with usable maps as well as highest state estimation
accuracy and robustness, we present OKVIS2-X: a state-of-the-art multi-sensor
Simultaneous Localization and Mapping (SLAM) system building dense volumetric
occupancy maps, while scalable to large environments and operating in realtime.
Our unified SLAM framework seamlessly integrates different sensor modalities:
visual, inertial, measured or learned depth, LiDAR and Global Navigation
Satellite System (GNSS) measurements. Unlike most state-of-the-art SLAM
systems, we advocate using dense volumetric map representations when leveraging
depth or range-sensing capabilities. We employ an efficient submapping strategy
that allows our system to scale to large environments, showcased in sequences
of up to 9 kilometers. OKVIS2-X enhances its accuracy and robustness by
tightly-coupling the estimator and submaps through map alignment factors. Our
system provides globally consistent maps, directly usable for autonomous
navigation. To further improve the accuracy of OKVIS2-X, we also incorporate
the option of performing online calibration of camera extrinsics. Our system
achieves the highest trajectory accuracy in EuRoC against state-of-the-art
alternatives, outperforms all competitors in the Hilti22 VI-only benchmark,
while also proving competitive in the LiDAR version, and showcases state of the
art accuracy in the diverse and large-scale sequences from the VBR dataset.

</details>


### [53] [Bio-Inspired Robotic Houbara: From Development to Field Deployment for Behavioral Studies](https://arxiv.org/abs/2510.04692)
*Lyes Saad Saoud,Irfan Hussain*

Main category: cs.RO

TL;DR: 开发了一个仿生机器人平台，模拟雌性波斑鸨的形态和外观，用于野外生态行为研究和保护工作。该平台采用数字化制造流程，具备稳定的沙地移动能力和实时视觉感知系统，在沙漠试验中成功引发了真实波斑鸨的自然互动反应。


<details>
  <summary>Details</summary>
Motivation: 研究野生鸟类行为面临挑战，需要高度逼真的形态、耐用的户外操作能力以及能够适应非受控环境的智能感知系统。

Method: 采用完全数字化可复制的制造流程，结合高分辨率结构光3D扫描、参数化CAD建模、关节式3D打印和逼真UV纹理乙烯基表面处理。配备六轮摇臂转向架底盘确保沙地和崎岖地形的稳定移动，嵌入式NVIDIA Jetson模块实现实时RGB和热成像感知、轻量级YOLO检测以及自主视觉伺服系统。

Result: 沙漠鸟舍的现场试验显示，系统以15-22 FPS的帧率可靠运行，延迟低于100毫秒，平台在恶劣户外条件下成功引发了活体波斑鸨的自然识别和互动反应。

Conclusion: 该集成框架通过结合可复制的数字化制造、具身视觉智能和生态验证，推进了仿生野外机器人技术，为动物-机器人互动研究、保护机器人和公众参与提供了可转移的蓝图。

Abstract: Biomimetic intelligence and robotics are transforming field ecology by
enabling lifelike robotic surrogates that interact naturally with animals under
real world conditions. Studying avian behavior in the wild remains challenging
due to the need for highly realistic morphology, durable outdoor operation, and
intelligent perception that can adapt to uncontrolled environments. We present
a next generation bio inspired robotic platform that replicates the morphology
and visual appearance of the female Houbara bustard to support controlled
ethological studies and conservation oriented field research. The system
introduces a fully digitally replicable fabrication workflow that combines high
resolution structured light 3D scanning, parametric CAD modelling, articulated
3D printing, and photorealistic UV textured vinyl finishing to achieve
anatomically accurate and durable robotic surrogates. A six wheeled rocker
bogie chassis ensures stable mobility on sand and irregular terrain, while an
embedded NVIDIA Jetson module enables real time RGB and thermal perception,
lightweight YOLO based detection, and an autonomous visual servoing loop that
aligns the robot's head toward detected targets without human intervention. A
lightweight thermal visible fusion module enhances perception in low light
conditions. Field trials in desert aviaries demonstrated reliable real time
operation at 15 to 22 FPS with latency under 100 ms and confirmed that the
platform elicits natural recognition and interactive responses from live
Houbara bustards under harsh outdoor conditions. This integrated framework
advances biomimetic field robotics by uniting reproducible digital fabrication,
embodied visual intelligence, and ecological validation, providing a
transferable blueprint for animal robot interaction research, conservation
robotics, and public engagement.

</details>


### [54] [Building Gradient by Gradient: Decentralised Energy Functions for Bimanual Robot Assembly](https://arxiv.org/abs/2510.04696)
*Alexander L. Mitchell,Joe Watson,Ingmar Posner*

Main category: cs.RO

TL;DR: 提出了一种基于梯度的分散式框架，使用自适应势函数的自动组合来生成分段连续能量函数，用于解决双臂装配中的快速重规划问题。


<details>
  <summary>Details</summary>
Motivation: 双臂装配面临高层序列规划、多机器人协调和接触丰富的操作等挑战。传统任务与运动规划方法在需要新任务序列时收敛缓慢，且显式定义任务序列限制了重规划的灵活性。

Method: 使用自适应势函数的自动组合构建分段连续能量函数，通过近视优化生成子目标，而非长时域规划。采用分散式梯度优化框架实现快速重规划。

Result: 该方法能够扩展到物理双臂装配任务，构建紧密公差装配。梯度快速重规划框架能够以涌现方式生成自动重试、协调运动和自主交接。

Conclusion: 提出的梯度框架通过能量函数的结构和自适应性，能够有效解决长时域任务，在紧密公差装配中表现出良好的重规划能力。

Abstract: There are many challenges in bimanual assembly, including high-level
sequencing, multi-robot coordination, and low-level, contact-rich operations
such as component mating. Task and motion planning (TAMP) methods, while
effective in this domain, may be prohibitively slow to converge when adapting
to disturbances that require new task sequencing and optimisation. These events
are common during tight-tolerance assembly, where difficult-to-model dynamics
such as friction or deformation require rapid replanning and reattempts.
Moreover, defining explicit task sequences for assembly can be cumbersome,
limiting flexibility when task replanning is required. To simplify this
planning, we introduce a decentralised gradient-based framework that uses a
piecewise continuous energy function through the automatic composition of
adaptive potential functions. This approach generates sub-goals using only
myopic optimisation, rather than long-horizon planning. It demonstrates
effectiveness at solving long-horizon tasks due to the structure and adaptivity
of the energy function. We show that our approach scales to physical bimanual
assembly tasks for constructing tight-tolerance assemblies. In these
experiments, we discover that our gradient-based rapid replanning framework
generates automatic retries, coordinated motions and autonomous handovers in an
emergent fashion.

</details>


### [55] [Performance-guided Task-specific Optimization for Multirotor Design](https://arxiv.org/abs/2510.04724)
*Etor Arza,Welf Rehberg,Philipp Weiss,Mihir Kulkarni,Kostas Alexis*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习、贝叶斯优化和协方差矩阵自适应进化策略的多旋翼微型飞行器任务特定设计优化方法，通过闭环性能优化电机姿态配置，在敏捷航点导航任务中优于传统多旋翼配置。


<details>
  <summary>Details</summary>
Motivation: 传统多旋翼飞行器设计通常基于经验或简化模型，缺乏针对特定任务的系统优化方法，无法充分利用电机姿态配置等设计自由度来提升闭环性能。

Method: 结合强化学习、贝叶斯优化和协方差矩阵自适应进化策略，在考虑可制造性约束和最小气动干扰的前提下，系统探索电机姿态配置的设计空间，基于闭环任务性能进行优化。

Result: 优化设计在敏捷航点导航任务中表现优于传统多旋翼配置，包括文献中的全驱动设计，并通过真实世界测试验证了仿真到现实的迁移能力。

Conclusion: 该方法能够有效优化多旋翼飞行器的任务特定设计，通过系统探索设计空间获得性能更优的配置，且具有良好的仿真到现实迁移性。

Abstract: This paper introduces a methodology for task-specific design optimization of
multirotor Micro Aerial Vehicles. By leveraging reinforcement learning,
Bayesian optimization, and covariance matrix adaptation evolution strategy, we
optimize aerial robot designs guided exclusively by their closed-loop
performance in a considered task. Our approach systematically explores the
design space of motor pose configurations while ensuring manufacturability
constraints and minimal aerodynamic interference. Results demonstrate that
optimized designs achieve superior performance compared to conventional
multirotor configurations in agile waypoint navigation tasks, including against
fully actuated designs from the literature. We build and test one of the
optimized designs in the real world to validate the sim2real transferability of
our approach.

</details>


### [56] [Online automatic code generation for robot swarms: LLMs and self-organizing hierarchy](https://arxiv.org/abs/2510.04774)
*Weixu Zhu,Marco Dorigo,Mary Katherine Heinrich*

Main category: cs.RO

TL;DR: 论文提出了一种自组织神经系统（SoNS），使机器人群体能够自动请求并运行外部LLM生成的代码，以在任务受阻时完成使命，成功率高达85%。


<details>
  <summary>Details</summary>
Motivation: 为机器人群体提供易于行为设计的能力，并实现群体配置和集体环境的全局估计，从而实现在线自动代码生成。

Method: 使用自组织神经系统（SoNS）增强机器人群体，当群体陷入困境时，自动向外部LLM请求并运行生成的代码。

Result: 在6个真实机器人和超过30个机器人的模拟试验中，SoNS增强的机器人群体在任务受阻时能够成功完成使命，成功率达到85%。

Conclusion: SoNS系统有效提升了机器人群体在复杂环境中的自适应能力和任务完成率，展示了在线自动代码生成的可行性。

Abstract: Our recently introduced self-organizing nervous system (SoNS) provides robot
swarms with 1) ease of behavior design and 2) global estimation of the swarm
configuration and its collective environment, facilitating the implementation
of online automatic code generation for robot swarms. In a demonstration with 6
real robots and simulation trials with >30 robots, we show that when a
SoNS-enhanced robot swarm gets stuck, it can automatically solicit and run code
generated by an external LLM on the fly, completing its mission with an 85%
success rate.

</details>


### [57] [TAG-K: Tail-Averaged Greedy Kaczmarz for Computationally Efficient and Performant Online Inertial Parameter Estimation](https://arxiv.org/abs/2510.04839)
*Shuo Sha,Anupam Bhakta,Zhenyuan Jiang,Kevin Qiu,Ishaan Mahajan,Gabriel Bravo,Brian Plancher*

Main category: cs.RO

TL;DR: TAG-K是一种轻量级的Kaczmarz方法扩展，结合贪心随机行选择和尾部平均，用于机器人惯性参数在线估计，在动态环境中实现快速稳定的参数适应。


<details>
  <summary>Details</summary>
Motivation: 传统方法如递归最小二乘法和卡尔曼滤波器在跟踪突变参数变化时表现不佳或计算成本高，限制了在动态环境和计算受限机器人系统中的有效性。

Method: TAG-K结合贪心随机行选择实现快速收敛，使用尾部平均在噪声和不一致性下保持鲁棒性，同时保持Kaczmarz框架的低单次迭代复杂度。

Result: 在笔记本电脑CPU上实现1.5-1.9倍更快的求解时间，在嵌入式微控制器上实现4.8-20.7倍更快的求解时间，同时提高对测量噪声的鲁棒性，估计误差减少25%，端到端跟踪性能提高近2倍。

Conclusion: TAG-K为计算受限的机器人系统提供了一种高效、鲁棒的在线惯性参数估计方法，在动态环境中表现出优越的性能。

Abstract: Accurate online inertial parameter estimation is essential for adaptive
robotic control, enabling real-time adjustment to payload changes,
environmental interactions, and system wear. Traditional methods such as
Recursive Least Squares (RLS) and the Kalman Filter (KF) often struggle to
track abrupt parameter shifts or incur high computational costs, limiting their
effectiveness in dynamic environments and for computationally constrained
robotic systems. As such, we introduce TAG-K, a lightweight extension of the
Kaczmarz method that combines greedy randomized row selection for rapid
convergence with tail averaging for robustness under noise and inconsistency.
This design enables fast, stable parameter adaptation while retaining the low
per-iteration complexity inherent to the Kaczmarz framework. We evaluate TAG-K
in synthetic benchmarks and quadrotor tracking tasks against RLS, KF, and other
Kaczmarz variants. TAG-K achieves 1.5x-1.9x faster solve times on laptop-class
CPUs and 4.8x-20.7x faster solve times on embedded microcontrollers. More
importantly, these speedups are paired with improved resilience to measurement
noise and a 25% reduction in estimation error, leading to nearly 2x better
end-to-end tracking performance.

</details>


### [58] [CLEAR-IR: Clarity-Enhanced Active Reconstruction of Infrared Imagery](https://arxiv.org/abs/2510.04883)
*Nathan Shankar,Pawel Ladosz,Hujun Yin*

Main category: cs.RO

TL;DR: 提出基于U-Net的架构，从受发射器干扰的红外图像中重建干净图像，提升暗光环境下机器人视觉系统的性能


<details>
  <summary>Details</summary>
Motivation: 红外流在低光条件下比RGB更抗噪，但受主动发射器模式干扰，影响目标检测、跟踪和定位等高级任务

Method: 使用U-Net架构重建干净的红外图像，消除发射器模式干扰

Result: 该方法优于现有增强技术，能在从良好光照到极端低光场景下实现可靠的机器人视觉系统操作

Conclusion: 该方案有效解决了红外图像中发射器干扰问题，显著提升了暗光环境下机器人感知的鲁棒性

Abstract: This paper presents a novel approach for enabling robust robotic perception
in dark environments using infrared (IR) stream. IR stream is less susceptible
to noise than RGB in low-light conditions. However, it is dominated by active
emitter patterns that hinder high-level tasks such as object detection,
tracking and localisation. To address this, a U-Net-based architecture is
proposed that reconstructs clean IR images from emitter-populated input,
improving both image quality and downstream robotic performance. This approach
outperforms existing enhancement techniques and enables reliable operation of
vision-driven robotic systems across illumination conditions from well-lit to
extreme low-light scenes.

</details>


### [59] [HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks](https://arxiv.org/abs/2510.04898)
*Zheng Xiong,Kang Li,Zilin Wang,Matthew Jackson,Jakob Foerster,Shimon Whiteson*

Main category: cs.RO

TL;DR: HyperVLA提出了一种基于超网络架构的视觉-语言-动作模型，通过仅激活小型任务特定策略来大幅降低推理成本，同时保持多任务训练能力。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型虽然能学习通用机器人策略，但推理成本极高，限制了实际应用。

Method: 采用超网络架构，在推理时仅激活小型任务特定策略；包含利用视觉基础模型先验知识、超网络归一化和动作生成策略等关键设计。

Result: 相比OpenVLA，激活参数量减少90倍，推理速度提升120倍，在零样本泛化和少样本适应方面达到相似或更高成功率。

Conclusion: HyperVLA在保持性能的同时显著降低了VLA模型的推理成本，为实际部署提供了可行方案。

Abstract: Built upon language and vision foundation models with strong generalization
ability and trained on large-scale robotic data, Vision-Language-Action (VLA)
models have recently emerged as a promising approach to learning generalist
robotic policies. However, a key drawback of existing VLAs is their extremely
high inference costs. In this paper, we propose HyperVLA to address this
problem. Unlike existing monolithic VLAs that activate the whole model during
both training and inference, HyperVLA uses a novel hypernetwork (HN)-based
architecture that activates only a small task-specific policy during inference,
while still retaining the high model capacity needed to accommodate diverse
multi-task behaviors during training. Successfully training an HN-based VLA is
nontrivial so HyperVLA contains several key algorithm design features that
improve its performance, including properly utilizing the prior knowledge from
existing vision foundation models, HN normalization, and an action generation
strategy. Compared to monolithic VLAs, HyperVLA achieves a similar or even
higher success rate for both zero-shot generalization and few-shot adaptation,
while significantly reducing inference costs. Compared to OpenVLA, a
state-of-the-art VLA model, HyperVLA reduces the number of activated parameters
at test time by $90\times$, and accelerates inference speed by $120\times$.
Code is publicly available at https://github.com/MasterXiong/HyperVLA

</details>


### [60] [Efficient Navigation in Unknown Indoor Environments with Vision-Language Models](https://arxiv.org/abs/2510.04991)
*D. Schwartz,K. Kondo,J. P. How*

Main category: cs.RO

TL;DR: 提出了一种利用视觉语言模型(VLM)进行高层规划的新框架，通过零样本推理占据地图来选择更有效的子目标，提高未知室内环境中的自主导航效率。


<details>
  <summary>Details</summary>
Motivation: 传统探索方法由于全局推理能力有限和依赖局部启发式，在存在许多死胡同的未知室内环境中往往采取低效路线。

Method: 将3D占据网格转换为部分2D地图，生成候选子目标，使用VLM对这些子目标进行零样本评估和排序，并集成到DYNUS轨迹规划器中。

Result: 在仿真中展示了改进的导航效率，VLM能够从不完整地图中推断结构模式(如房间、走廊)，平衡向目标前进的需求与进入未知空间的风险，平均路径缩短约10%。

Conclusion: 该方法减少了常见的贪婪失败(如绕进小房间)，通过VLM的全局推理能力显著提升了未知环境中的导航效率。

Abstract: We present a novel high-level planning framework that leverages
vision-language models (VLMs) to improve autonomous navigation in unknown
indoor environments with many dead ends. Traditional exploration methods often
take inefficient routes due to limited global reasoning and reliance on local
heuristics. In contrast, our approach enables a VLM to reason directly about an
occupancy map in a zero-shot manner, selecting subgoals that are likely to lead
to more efficient paths. At each planning step, we convert a 3D occupancy grid
into a partial 2D map of the environment, and generate candidate subgoals. Each
subgoal is then evaluated and ranked against other candidates by the model. We
integrate this planning scheme into DYNUS \cite{kondo2025dynus}, a
state-of-the-art trajectory planner, and demonstrate improved navigation
efficiency in simulation. The VLM infers structural patterns (e.g., rooms,
corridors) from incomplete maps and balances the need to make progress toward a
goal against the risk of entering unknown space. This reduces common greedy
failures (e.g., detouring into small rooms) and achieves about 10\% shorter
paths on average.

</details>


### [61] [Walking, Rolling, and Beyond: First-Principles and RL Locomotion on a TARS-Inspired Robot](https://arxiv.org/abs/2510.05001)
*Aditya Sripada,Abhishek Warrier*

Main category: cs.RO

TL;DR: TARS3D机器人从电影《星际穿越》中的TARS机器人获得灵感，采用非仿生形态设计，具有7个驱动自由度。研究建立了两种步态的简化模型，推导出闭式极限环条件，并通过硬件验证。同时使用深度强化学习探索了更丰富的步态行为。


<details>
  <summary>Details</summary>
Motivation: 传统机器人运动研究多受生物启发的腿部设计影响，但许多人工环境可能受益于非人形形态。研究旨在探索科幻电影中TARS机器人的实际可行性及其独特的运动能力。

Method: 建立两种主要步态（双足行走和高速滚动）的简化模型，推导闭式极限环条件，并在硬件平台上验证。同时使用深度强化学习在仿真中探索未开发的步态空间。

Result: 实验证实机器人能够遵守±150度髋关节限制，交替左右接触无干扰，在滚动模式下维持八步混合极限环。学习策略能够重现分析步态并发现新行为。

Conclusion: TARS3D的科幻启发形态能够实现多种先前未探索的运动模式，分析合成与强化学习的结合为多模态机器人开辟了有前景的途径。

Abstract: Robotic locomotion research typically draws from biologically inspired leg
designs, yet many human-engineered settings can benefit from
non-anthropomorphic forms. TARS3D translates the block-shaped 'TARS' robot from
Interstellar into a 0.25 m, 0.99 kg research platform with seven actuated
degrees of freedom. The film shows two primary gaits: a bipedal-like walk and a
high-speed rolling mode. For TARS3D, we build reduced-order models for each,
derive closed-form limit-cycle conditions, and validate the predictions on
hardware. Experiments confirm that the robot respects its +/-150 degree hip
limits, alternates left-right contacts without interference, and maintains an
eight-step hybrid limit cycle in rolling mode. Because each telescopic leg
provides four contact corners, the rolling gait is modeled as an eight-spoke
double rimless wheel. The robot's telescopic leg redundancy implies a far
richer gait repertoire than the two limit cycles treated analytically. So, we
used deep reinforcement learning (DRL) in simulation to search the unexplored
space. We observed that the learned policy can recover the analytic gaits under
the right priors and discover novel behaviors as well. Our findings show that
TARS3D's fiction-inspired bio-transcending morphology can realize multiple
previously unexplored locomotion modes and that further learning-driven search
is likely to reveal more. This combination of analytic synthesis and
reinforcement learning opens a promising pathway for multimodal robotics.

</details>


### [62] [StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation](https://arxiv.org/abs/2510.05057)
*Mingyu Liu,Jiuhe Shu,Hui Chen,Zeju Li,Canyu Zhao,Jiange Yang,Shenyuan Gao,Hao Chen,Chunhua Shen*

Main category: cs.RO

TL;DR: 提出了一种无监督方法StaMo，通过轻量编码器和预训练DiT解码器学习高度压缩的双令牌状态表示，该表示不仅高效可解释，还能通过潜在插值自然生成有效的潜在动作。


<details>
  <summary>Details</summary>
Motivation: 现有方法在具身智能中难以平衡状态表示的紧凑性和表达性，要么过于冗余，要么缺乏任务关键信息。

Method: 使用轻量编码器和预训练Diffusion Transformer解码器学习压缩的双令牌状态表示，通过潜在插值生成潜在动作。

Result: 在LIBERO上性能提升14.3%，真实世界任务成功率提升30%，潜在动作增强策略协同训练，比先前方法提升10.4%。

Conclusion: StaMo方法从静态图像学习紧凑状态表示，无需复杂架构和视频数据，就能生成可泛化的机器人运动，且具有良好的可扩展性。

Abstract: A fundamental challenge in embodied intelligence is developing expressive and
compact state representations for efficient world modeling and decision making.
However, existing methods often fail to achieve this balance, yielding
representations that are either overly redundant or lacking in task-critical
information. We propose an unsupervised approach that learns a highly
compressed two-token state representation using a lightweight encoder and a
pre-trained Diffusion Transformer (DiT) decoder, capitalizing on its strong
generative prior. Our representation is efficient, interpretable, and
integrates seamlessly into existing VLA-based models, improving performance by
14.3% on LIBERO and 30% in real-world task success with minimal inference
overhead. More importantly, we find that the difference between these tokens,
obtained via latent interpolation, naturally serves as a highly effective
latent action, which can be further decoded into executable robot actions. This
emergent capability reveals that our representation captures structured
dynamics without explicit supervision. We name our method StaMo for its ability
to learn generalizable robotic Motion from compact State representation, which
is encoded from static images, challenging the prevalent dependence to learning
latent action on complex architectures and video data. The resulting latent
actions also enhance policy co-training, outperforming prior methods by 10.4%
with improved interpretability. Moreover, our approach scales effectively
across diverse data sources, including real-world robot data, simulation, and
human egocentric video.

</details>


### [63] [Automaton Constrained Q-Learning](https://arxiv.org/abs/2510.05061)
*Anastasios Manganaris,Vittorio Giammarino,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: ACQL算法结合目标条件值学习和自动机引导强化学习，在连续控制任务中优于现有方法，能够同时满足时序目标和非平稳安全约束。


<details>
  <summary>Details</summary>
Motivation: 现实机器人任务需要实现时序目标并遵守时变安全约束，但标准RL方法在此类设置中存在根本限制。现有LTL目标RL方法在复杂连续环境中表现不佳，缺乏同时支持时序目标和安全约束的可扩展方法。

Method: 提出自动机约束Q学习(ACQL)，将目标条件值学习与自动机引导强化学习相结合，利用LTL任务规范的自动机表示来显式编码阶段化目标进展以及平稳和非平稳安全约束。

Result: ACQL在连续控制任务中优于现有方法，包括在先前方法无法满足目标达成或安全约束的情况下。在6自由度机械臂上的真实部署验证了其在杂乱、类似柜子空间中的适用性。

Conclusion: ACQL是根据丰富时序规范学习机器人行为的鲁棒且可扩展的解决方案。

Abstract: Real-world robotic tasks often require agents to achieve sequences of goals
while respecting time-varying safety constraints. However, standard
Reinforcement Learning (RL) paradigms are fundamentally limited in these
settings. A natural approach to these problems is to combine RL with
Linear-time Temporal Logic (LTL), a formal language for specifying complex,
temporally extended tasks and safety constraints. Yet, existing RL methods for
LTL objectives exhibit poor empirical performance in complex and continuous
environments. As a result, no scalable methods support both temporally ordered
goals and safety simultaneously, making them ill-suited for realistic robotics
scenarios. We propose Automaton Constrained Q-Learning (ACQL), an algorithm
that addresses this gap by combining goal-conditioned value learning with
automaton-guided reinforcement. ACQL supports most LTL task specifications and
leverages their automaton representation to explicitly encode stage-wise goal
progression and both stationary and non-stationary safety constraints. We show
that ACQL outperforms existing methods across a range of continuous control
tasks, including cases where prior methods fail to satisfy either goal-reaching
or safety constraints. We further validate its real-world applicability by
deploying ACQL on a 6-DOF robotic arm performing a goal-reaching task in a
cluttered, cabinet-like space with safety constraints. Our results demonstrate
that ACQL is a robust and scalable solution for learning robotic behaviors
according to rich temporal specifications.

</details>


### [64] [ResMimic: From General Motion Tracking to Humanoid Whole-body Loco-Manipulation via Residual Learning](https://arxiv.org/abs/2510.05070)
*Siheng Zhao,Yanjie Ze,Yue Wang,C. Karen Liu,Pieter Abbeel,Guanya Shi,Rocky Duan*

Main category: cs.RO

TL;DR: ResMimic是一个两阶段残差学习框架，通过结合通用运动跟踪策略和精确的残差策略，实现人形机器人精确的全身运动控制，特别针对移动操作任务进行优化。


<details>
  <summary>Details</summary>
Motivation: 现有通用运动跟踪策略在再现人类多样化运动方面表现良好，但缺乏移动操作所需的精度和物体感知能力，需要开发更精确的控制方法。

Method: 采用两阶段残差学习：第一阶段训练通用运动跟踪策略作为基础，第二阶段学习高效的残差策略来精炼输出，并设计了点云物体跟踪奖励、接触奖励和课程式虚拟物体控制器来优化训练。

Result: 在仿真和真实Unitree G1人形机器人上的实验显示，相比基线方法在任务成功率、训练效率和鲁棒性方面都有显著提升。

Conclusion: ResMimic框架通过残差学习有效结合了人类运动数据和精确控制需求，为人形机器人的移动操作任务提供了可行的解决方案。

Abstract: Humanoid whole-body loco-manipulation promises transformative capabilities
for daily service and warehouse tasks. While recent advances in general motion
tracking (GMT) have enabled humanoids to reproduce diverse human motions, these
policies lack the precision and object awareness required for
loco-manipulation. To this end, we introduce ResMimic, a two-stage residual
learning framework for precise and expressive humanoid control from human
motion data. First, a GMT policy, trained on large-scale human-only motion,
serves as a task-agnostic base for generating human-like whole-body movements.
An efficient but precise residual policy is then learned to refine the GMT
outputs to improve locomotion and incorporate object interaction. To further
facilitate efficient training, we design (i) a point-cloud-based object
tracking reward for smoother optimization, (ii) a contact reward that
encourages accurate humanoid body-object interactions, and (iii) a
curriculum-based virtual object controller to stabilize early training. We
evaluate ResMimic in both simulation and on a real Unitree G1 humanoid. Results
show substantial gains in task success, training efficiency, and robustness
over strong baselines. Videos are available at https://resmimic.github.io/ .

</details>


<div id='cs.SY'></div>

# cs.SY [[Back]](#toc)

### [65] [Adaptive Cruise Control in Autonomous Vehicles: Challenges, Gaps, Comprehensive Review, and, Future Directions](https://arxiv.org/abs/2510.03300)
*Shradha Bavalatti,Yash Kangralkar,Santosh Pattar,Veena P Badiger*

Main category: cs.SY

TL;DR: 本文对自动驾驶车辆的自适应巡航控制(ACC)研究进行了系统综述，识别了现有研究的不足并提出了未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 现有综述论文缺乏对ACC挑战及其解决方案的全面分析，本文旨在填补这一空白，为下一代ACC系统设计提供指导。

Method: 采用系统综述方法，详细分析当前ACC研究的局限性，识别研究空白并提出创新解决方案。

Result: 提供了对ACC挑战的深入分析，提出了实现可持续和容错城市交通的创新方法。

Conclusion: 本文通过系统综述为ACC研究提供了有价值的见解和未来方向，有助于设计更安全、高效的下一代ACC系统。

Abstract: The development of Autonomous Vehicles (AVs) has redefined the way of
transportation by eliminating the need for human intervention in driving. This
revolution is fueled by rapid advancements in adaptive cruise control (ACC),
which make AVs capable of interpreting their surroundings and responding
intelligently. While AVs offer significant advantages, such as enhanced safety
and improved traffic efficiency, they also face several challenges that need to
be addressed. Existing survey papers often lack a comprehensive analysis of
these challenges and their potential solutions. Our paper stands out by
meticulously identifying these gaps in current ACC research and offering
impactful future directions to guide researchers in designing next-generation
ACC systems. Our survey provides a detailed and systematic review, addressing
the limitations of previous studies and proposing innovative approaches to
achieve sustainable and fault-resilient urban transportation.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [66] [WAREX: Web Agent Reliability Evaluation on Existing Benchmarks](https://arxiv.org/abs/2510.03285)
*Su Kara,Fazle Faisal,Suman Nath*

Main category: cs.AI

TL;DR: WAREX是一个评估浏览器LLM代理在真实网络环境可靠性的框架，通过在现有基准测试中引入网络不稳定性和网站攻击等现实因素，发现当前最先进代理的鲁棒性有限。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在受控环境中评估LLM代理性能，但真实世界存在网络不稳定、HTTPS连接问题和网站攻击等挑战，需要评估代理在这些现实条件下的可靠性。

Method: 提出WAREX框架，在三个流行基准测试（WebArena、WebVoyager、REAL）中引入网络不稳定性和网站攻击等现实因素来评估代理性能。

Result: 实验显示引入WAREX后任务成功率显著下降，表明当前最先进代理在面对现实网络环境时鲁棒性有限。

Conclusion: WAREX揭示了现有LLM代理在真实网络环境中的可靠性问题，强调了在评估代理性能时考虑现实条件的重要性。

Abstract: Recent advances in browser-based LLM agents have shown promise for automating
tasks ranging from simple form filling to hotel booking or online shopping.
Current benchmarks measure agent performance in controlled environments, such
as containers or stable networks, where websites behave deterministically.
However, in the real world, users access websites over networks and HTTPS
connections that introduce instability from multiple sources: client-side,
server-side issues or broader system failures. Moreover, live websites are
prone to web attacks such Cross-Site Scripting, as well as general site
modifications which can cause unexpected or malicious pop-ups or improper
functionality. To address this gap, we present WAREX: Web Agent Reliability
Evaluation on Existing Benchmarks. We measure the impact of WAREX across three
popular benchmarks: WebArena, WebVoyager, and REAL. Our experiments show that
introducing WAREX leads to significant drops in task success rates,
highlighting the limited robustness of state-of-the-art agents.

</details>


### [67] [Refined Iterated Pareto Greedy for Energy-aware Hybrid Flowshop Scheduling with Blocking Constraints](https://arxiv.org/abs/2510.03377)
*Ahmed Missaoui,Cemalettin Ozturk,Barry O'Sullivan*

Main category: cs.AI

TL;DR: 该研究针对带有阻塞约束的混合流水车间调度问题，提出了多目标优化方法，同时最小化制造周期和能源消耗，并开发了有效的元启发式算法来解决大规模实例。


<details>
  <summary>Details</summary>
Motivation: 不可再生能源稀缺、地缘政治问题、价格上涨和气候变化影响迫使制造业开发更节能的解决方案。制造业作为最大的能源消费者之一，需要能源高效调度来快速降低能耗。

Method: 首先构建了多目标混合整数规划模型，采用增强的ε约束方法寻找帕累托最优解，并开发了改进的迭代帕累托贪婪算法来处理大规模实例。

Result: 通过小、中、大规模实例进行基准测试，与两种知名算法比较，计算结果表明所提方法具有有效性。

Conclusion: 提出的多目标优化方法和元启发式算法能够有效解决混合流水车间调度中的能源效率和制造周期优化问题，为制造业节能提供了可行方案。

Abstract: The scarcity of non-renewable energy sources, geopolitical problems in its
supply, increasing prices, and the impact of climate change, force the global
economy to develop more energy-efficient solutions for their operations. The
Manufacturing sector is not excluded from this challenge as one of the largest
consumers of energy. Energy-efficient scheduling is a method that attracts
manufacturing companies to reduce their consumption as it can be quickly
deployed and can show impact immediately. In this study, the hybrid flow shop
scheduling problem with blocking constraint (BHFS) is investigated in which we
seek to minimize the latest completion time (i.e. makespan) and overall energy
consumption, a typical manufacturing setting across many industries from
automotive to pharmaceutical. Energy consumption and the latest completion time
of customer orders are usually conflicting objectives. Therefore, we first
formulate the problem as a novel multi-objective mixed integer programming
(MIP) model and propose an augmented epsilon-constraint method for finding the
Pareto-optimal solutions. Also, an effective multi-objective metaheuristic
algorithm. Refined Iterated Pareto Greedy (RIPG), is developed to solve large
instances in reasonable time. Our proposed methods are benchmarked using small,
medium, and large-size instances to evaluate their efficiency. Two well-known
algorithms are adopted for comparing our novel approaches. The computational
results show the effectiveness of our method.

</details>


### [68] [Know Thyself? On the Incapability and Implications of AI Self-Recognition](https://arxiv.org/abs/2510.03399)
*Xiaoyan Bai,Aryan Shrivastava,Ari Holtzman,Chenhao Tan*

Main category: cs.AI

TL;DR: 本文系统评估了10个大型语言模型的自我识别能力，发现模型普遍无法识别自己生成的文本，性能仅略高于随机猜测，且存在对GPT和Claude家族的强烈偏见。


<details>
  <summary>Details</summary>
Motivation: 针对AI系统是否具备自我识别能力这一争议问题，建立系统评估框架来检验当代语言模型的自我识别能力，这对AI安全和心理分析具有重要意义。

Method: 通过二元自我识别和精确模型预测两个任务，评估10个当代大型语言模型识别自己生成文本与其他模型文本的能力。

Result: 结果显示模型自我识别能力普遍失败，仅4/10模型能正确预测自己为生成者，性能很少超过随机机会。模型存在对GPT和Claude家族的强烈偏见，并表现出对模型存在性的层次认知偏差。

Conclusion: 研究揭示了当前语言模型在自我识别方面的局限性，这对AI安全具有重要意义，并为开发适当的AI自我意识指明了未来方向。

Abstract: Self-recognition is a crucial metacognitive capability for AI systems,
relevant not only for psychological analysis but also for safety, particularly
in evaluative scenarios. Motivated by contradictory interpretations of whether
models possess self-recognition (Panickssery et al., 2024; Davidson et al.,
2024), we introduce a systematic evaluation framework that can be easily
applied and updated. Specifically, we measure how well 10 contemporary larger
language models (LLMs) can identify their own generated text versus text from
other models through two tasks: binary self-recognition and exact model
prediction. Different from prior claims, our results reveal a consistent
failure in self-recognition. Only 4 out of 10 models predict themselves as
generators, and the performance is rarely above random chance. Additionally,
models exhibit a strong bias toward predicting GPT and Claude families. We also
provide the first evaluation of model awareness of their own and others'
existence, as well as the reasoning behind their choices in self-recognition.
We find that the model demonstrates some knowledge of its own existence and
other models, but their reasoning reveals a hierarchical bias. They appear to
assume that GPT, Claude, and occasionally Gemini are the top-tier models, often
associating high-quality text with them. We conclude by discussing the
implications of our findings on AI safety and future directions to develop
appropriate AI self-awareness.

</details>


### [69] [ContraGen: A Multi-Agent Generation Framework for Enterprise Contradictions Detection](https://arxiv.org/abs/2510.03418)
*Ananya Mantravadi,Shivali Dalmia,Abhishek Mukherji,Nand Dave,Anudha Mittal*

Main category: cs.AI

TL;DR: 提出了ContraGen基准框架，专门针对企业领域生成包含矛盾内容的合成文档，用于评估RAG系统的矛盾检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有矛盾检测基准仅限于句子级别分析，无法处理企业文档（如合同、财务报告等）的复杂性，而RAG系统中的证据矛盾会导致不可靠输出，这在企业环境中尤其危险。

Method: 结合自动化矛盾挖掘和人工验证，生成企业风格合成文档并嵌入矛盾，建立企业流程中常见的矛盾类型分类法，支持受控创建自矛盾和成对矛盾。

Result: 开发了矛盾感知的检索评估流程，建立了企业信息检索应用中更可信赖RAG系统的基础。

Conclusion: 该工作为在企业信息搜索应用中构建更可信和可问责的RAG系统奠定了基础，其中检测和解决矛盾对于降低风险和确保合规性至关重要。

Abstract: Retrieval-Augmented Generation (RAG) integrates LLMs with external sources,
offering advanced capabilities for information access and decision-making.
However, contradictions in retrieved evidence can result in inconsistent or
untrustworthy outputs, which is especially problematic in enterprise settings
where compliance, governance, and accountability are critical. Existing
benchmarks for contradiction detection are limited to sentence-level analysis
and do not capture the complexity of enterprise documents such as contracts,
financial filings, compliance reports, or policy manuals. To address this
limitation, we propose ContraGen, a contradiction-aware benchmark framework
tailored to enterprise domain. The framework generates synthetic
enterprise-style documents with embedded contradictions, enabling systematic
evaluation of both intra-document and cross-document consistency. Automated
contradiction mining is combined with human-in-the-loop validation to ensure
high accuracy. Our contributions include generating realistic enterprise
documents, modeling a taxonomy of contradiction types common in business
processes, enabling controlled creation of self- and pairwise contradictions,
developing a contradiction-aware retrieval evaluation pipeline and embedding
human oversight to reflect domain-specific judgment complexity. This work
establishes a foundation for more trustworthy and accountable RAG systems in
enterprise information-seeking applications, where detecting and resolving
contradictions is essential for reducing risk and ensuring compliance.

</details>


### [70] [Internal World Models as Imagination Networks in Cognitive Agents](https://arxiv.org/abs/2510.04391)
*Saurabh Ranjan,Brian Odegaard*

Main category: cs.AI

TL;DR: 本研究提出想象的计算目标是访问内部世界模型，通过心理网络分析比较人类和大型语言模型的想象网络，发现两者在内部世界模型上存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 探索想象的计算目标，挑战传统认为想象主要用于最大化奖励的观点，研究人类和AI的内部世界模型差异。

Method: 使用心理网络分析方法，通过两份问卷评估想象生动性评分，构建人类和LLMs的想象网络，比较不同中心性指标的关联性。

Result: 人类想象网络显示不同中心性指标间存在相关性，而LLMs的想象网络缺乏聚类且中心性指标间相关性较低，表明两者内部世界模型相似度低。

Conclusion: 研究提供了一种比较人类和AI内部生成表征的新方法，为开发类人想象的人工智能提供了见解。

Abstract: What is the computational objective of imagination? While classical
interpretations suggest imagination is useful for maximizing rewards, recent
findings challenge this view. In this study, we propose that imagination serves
to access an internal world model (IWM) and use psychological network analysis
to explore IWMs in humans and large language models (LLMs). Specifically, we
assessed imagination vividness ratings using two questionnaires and constructed
imagination networks from these reports. Imagination networks from human groups
showed correlations between different centrality measures, including expected
influence, strength, and closeness. However, imagination networks from LLMs
showed a lack of clustering and lower correlations between centrality measures
under different prompts and conversational memory conditions. Together, these
results indicate a lack of similarity between IWMs in human and LLM agents.
Overall, our study offers a novel method for comparing internally-generated
representations in humans and AI, providing insights for developing human-like
imagination in artificial intelligence.

</details>


### [71] [A Qualitative Comparative Evaluation of Cognitive and Generative Theories](https://arxiv.org/abs/2510.03453)
*Paul S. Rosenbloom*

Main category: cs.AI

TL;DR: 该论文提出了一个评估认知架构和生成式神经架构理论的定性比较框架


<details>
  <summary>Details</summary>
Motivation: 认知架构理论和生成式神经架构理论都面临评估挑战，需要一种更全面的评估方法

Method: 采用广泛的理论评估视角，对面向全脑的认知架构和生成式架构及其完整系统进行定性比较

Result: 开发了一个宽泛但定性的比较框架来评估不同类型的架构理论

Conclusion: 通过广泛的理论评估视角可以有效地比较和评估认知架构与生成式神经架构

Abstract: Evaluation is a critical activity associated with any theory. Yet this has
proven to be an exceptionally challenging activity for theories based on
cognitive architectures. For an overlapping set of reasons, evaluation can also
be challenging for theories based on generative neural architectures. This dual
challenge is approached here by leveraging a broad perspective on theory
evaluation to yield a wide-ranging, albeit qualitative, comparison of
whole-mind-oriented cognitive and generative architectures and the full systems
that are based on these architectures.

</details>


### [72] [Bridging LLM Planning Agents and Formal Methods: A Case Study in Plan Verification](https://arxiv.org/abs/2510.03469)
*Keshav Ramani,Vali Tawosi,Salwa Alamir,Daniel Borrajo*

Main category: cs.AI

TL;DR: 提出了一种通过将自然语言计划转换为Kripke结构和线性时序逻辑(LTL)来评估计划与预期行为对齐的新框架，使用大语言模型进行模型检查。


<details>
  <summary>Details</summary>
Motivation: 需要评估自然语言计划与其预期行为之间的对齐关系，确保计划执行的正确性。

Method: 使用大语言模型将自然语言计划转换为Kripke结构和LTL公式，然后进行模型检查，在PlanBench数据集简化版上系统评估。

Result: GPT-5在分类任务上表现优异(F1得分96.3%)，几乎总能生成语法完美的形式化表示，可作为保证。

Conclusion: 框架在生成语法正确的形式化模型方面表现良好，但语义完美形式化模型的合成仍需未来探索。

Abstract: We introduce a novel framework for evaluating the alignment between natural
language plans and their expected behavior by converting them into Kripke
structures and Linear Temporal Logic (LTL) using Large Language Models (LLMs)
and performing model checking. We systematically evaluate this framework on a
simplified version of the PlanBench plan verification dataset and report on
metrics like Accuracy, Precision, Recall and F1 scores. Our experiments
demonstrate that GPT-5 achieves excellent classification performance (F1 score
of 96.3%) while almost always producing syntactically perfect formal
representations that can act as guarantees. However, the synthesis of
semantically perfect formal models remains an area for future exploration.

</details>


### [73] [Towards Policy-Compliant Agents: Learning Efficient Guardrails For Policy Violation Detection](https://arxiv.org/abs/2510.03485)
*Xiaofei Wen,Wenjie Jacky Mo,Yanan Xie,Peng Qi,Muhao Chen*

Main category: cs.AI

TL;DR: 提出了PolicyGuardBench基准和PolicyGuard-4B模型，用于检测网络智能体轨迹中的策略违规，支持跨域泛化和小规模高效推理。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对自主网络智能体在生成长视野轨迹时是否遵守外部策略的系统评估，特别是在不同领域和子领域的泛化能力。

Method: 构建包含约6万个样本的PolicyGuardBench基准，从多样化智能体运行中生成策略集，创建带违规标签的域内和跨域配对，包括完整轨迹和前缀检测任务。

Result: 训练的PolicyGuard-4B轻量级护栏模型在所有任务上表现出强检测准确性，在未见设置上保持高精度，并能跨域泛化。

Conclusion: PolicyGuardBench和PolicyGuard-4B为研究网络智能体策略合规性提供了首个全面框架，证明小规模下可实现准确且可泛化的护栏。

Abstract: Autonomous web agents need to operate under externally imposed or
human-specified policies while generating long-horizon trajectories. However,
little work has examined whether these trajectories comply with such policies,
or whether policy violations persist across different contexts such as domains
(e.g., shopping or coding websites) and subdomains (e.g., product search and
order management in shopping). To address this gap, we introduce
PolicyGuardBench, a benchmark of about 60k examples for detecting policy
violations in agent trajectories. From diverse agent runs, we generate a broad
set of policies and create both within subdomain and cross subdomain pairings
with violation labels. In addition to full-trajectory evaluation,
PolicyGuardBench also includes a prefix-based violation detection task where
models must anticipate policy violations from truncated trajectory prefixes
rather than complete sequences. Using this dataset, we train PolicyGuard-4B, a
lightweight guardrail model that delivers strong detection accuracy across all
tasks while keeping inference efficient. Notably, PolicyGuard-4B generalizes
across domains and preserves high accuracy on unseen settings. Together,
PolicyGuardBench and PolicyGuard-4B provide the first comprehensive framework
for studying policy compliance in web agent trajectories, and show that
accurate and generalizable guardrails are feasible at small scales.

</details>


### [74] [OneFlow: Concurrent Mixed-Modal and Interleaved Generation with Edit Flows](https://arxiv.org/abs/2510.03506)
*John Nguyen,Marton Havasi,Tariq Berrada,Luke Zettlemoyer,Ricky T. Q. Chen*

Main category: cs.AI

TL;DR: OneFlow是首个非自回归多模态模型，支持可变长度和并发混合模态生成，通过结合插入式编辑流和流匹配技术，在生成质量和效率上超越自回归模型。


<details>
  <summary>Details</summary>
Motivation: 解决自回归模型在文本和图像生成中强制因果顺序的限制，实现更灵活的并发多模态生成。

Method: 结合插入式编辑流处理离散文本标记，使用流匹配处理图像潜在表示，采用分层采样优先内容而非语法。

Result: 在1B到8B模型规模上，OneFlow在生成和理解任务上均优于自回归基线，训练FLOPs减少50%，超越自回归和扩散方法。

Conclusion: OneFlow解锁了并发生成、迭代优化和类自然推理等新能力，为非自回归多模态生成提供了有效解决方案。

Abstract: We present OneFlow, the first non-autoregressive multimodal model that
enables variable-length and concurrent mixed-modal generation. Unlike
autoregressive models that enforce rigid causal ordering between text and image
generation, OneFlow combines an insertion-based Edit Flow for discrete text
tokens with Flow Matching for image latents. OneFlow enables concurrent
text-image synthesis with hierarchical sampling that prioritizes content over
grammar. Through controlled experiments across model sizes from 1B to 8B, we
demonstrate that OneFlow outperforms autoregressive baselines on both
generation and understanding tasks while using up to 50% fewer training FLOPs.
OneFlow surpasses both autoregressive and diffusion-based approaches while
unlocking new capabilities for concurrent generation, iterative refinement, and
natural reasoning-like generation.

</details>


### [75] [Understanding the Role of Training Data in Test-Time Scaling](https://arxiv.org/abs/2510.03605)
*Adel Javanmard,Baharan Mirzasoleiman,Vahab Mirrokni*

Main category: cs.AI

TL;DR: 论文研究测试时扩展对Transformer模型推理能力的影响，发现在线性回归任务中，增加测试时计算可以减少训练所需的上下文长度，但若训练数据缺乏必要技能，过度计算反而会损害性能。


<details>
  <summary>Details</summary>
Motivation: 测试时扩展通过生成长链思维来提升LLMs的推理能力，但其在训练数据中的出现条件和性能提升机制尚不明确，需要理论分析来理解这些现象。

Method: 在线性回归的上下文权重预测任务上训练Transformer模型，通过理论分析和实验验证测试时扩展的效果，并利用特征协方差矩阵的最小特征值来表征任务难度。

Result: 研究发现：1) 固定测试误差下，增加测试时计算可减少训练上下文长度；2) 若训练数据缺乏下游任务所需技能，增加计算会损害性能；3) 在多样化、相关且困难的任务集上训练可获得最佳测试时扩展性能。

Conclusion: 测试时扩展的有效性取决于训练数据的质量，需要在多样化且具有挑战性的任务上进行训练才能充分发挥其潜力，任务难度可通过特征协方差矩阵的特征值来量化。

Abstract: Test-time scaling improves the reasoning capabilities of large language
models (LLMs) by allocating extra compute to generate longer Chains-of-Thoughts
(CoTs). This enables models to tackle more complex problem by breaking them
down into additional steps, backtracking, and correcting mistakes. Despite its
strong performance--demonstrated by OpenAI's o1 and DeepSeek R1, the conditions
in the training data under which long CoTs emerge, and when such long CoTs
improve the performance, remain unclear. In this paper, we study the
performance of test-time scaling for transformers trained on an in-context
weight prediction task for linear regression. Our analysis provides a
theoretical explanation for several intriguing observations: First, at any
fixed test error, increasing test-time compute allows us to reduce the number
of in-context examples (context length) in training prompts. Second, if the
skills required to solve a downstream task are not sufficiently present in the
training data, increasing test-time compute can harm performance. Finally, we
characterize task hardness via the smallest eigenvalue of its feature
covariance matrix and show that training on a diverse, relevant, and hard set
of tasks results in best performance for test-time scaling. We confirm our
findings with experiments on large, nonlinear transformer architectures.

</details>


### [76] [Cross-Modal Content Optimization for Steering Web Agent Preferences](https://arxiv.org/abs/2510.03612)
*Tanqiu Jiang,Min Bai,Nikolaos Pappas,Yanjun Qi,Sandesh Swamy*

Main category: cs.AI

TL;DR: 本文提出跨模态偏好引导(CPS)攻击方法，通过联合优化视觉和文本通道的不可察觉修改，在现实黑盒威胁设置下有效操纵基于视觉语言模型的网络代理选择决策。


<details>
  <summary>Details</summary>
Motivation: 现有研究要么假设强白盒访问，要么使用不切实际的设置，而本文首次证明在现实攻击者能力下，联合利用视觉和文本通道可以产生更强大的偏好操纵。

Method: 引入跨模态偏好引导(CPS)，联合优化商品视觉和自然语言描述的不可察觉修改，利用CLIP可迁移图像扰动和RLHF诱导的语言偏见来引导代理决策。

Result: 在电影选择和电子商务任务上，CPS在所有模型上始终优于基线方法，同时保持70%更低的检测率，证明了有效性和隐蔽性。

Conclusion: 这些发现突显了随着智能系统在社会中扮演越来越重要的角色，迫切需要强大的防御机制。

Abstract: Vision-language model (VLM)-based web agents increasingly power high-stakes
selection tasks like content recommendation or product ranking by combining
multimodal perception with preference reasoning. Recent studies reveal that
these agents are vulnerable against attackers who can bias selection outcomes
through preference manipulations using adversarial pop-ups, image
perturbations, or content tweaks. Existing work, however, either assumes strong
white-box access, with limited single-modal perturbations, or uses impractical
settings. In this paper, we demonstrate, for the first time, that joint
exploitation of visual and textual channels yields significantly more powerful
preference manipulations under realistic attacker capabilities. We introduce
Cross-Modal Preference Steering (CPS) that jointly optimizes imperceptible
modifications to an item's visual and natural language descriptions, exploiting
CLIP-transferable image perturbations and RLHF-induced linguistic biases to
steer agent decisions. In contrast to prior studies that assume gradient
access, or control over webpages, or agent memory, we adopt a realistic
black-box threat setup: a non-privileged adversary can edit only their own
listing's images and textual metadata, with no insight into the agent's model
internals. We evaluate CPS on agents powered by state-of-the-art proprietary
and open source VLMs including GPT-4.1, Qwen-2.5VL and Pixtral-Large on both
movie selection and e-commerce tasks. Our results show that CPS is
significantly more effective than leading baseline methods. For instance, our
results show that CPS consistently outperforms baselines across all models
while maintaining 70% lower detection rates, demonstrating both effectiveness
and stealth. These findings highlight an urgent need for robust defenses as
agentic systems play an increasingly consequential role in society.

</details>


### [77] [MITS: Enhanced Tree Search Reasoning for LLMs via Pointwise Mutual Information](https://arxiv.org/abs/2510.03632)
*Jiaxi Li,Yucheng Shi,Jin Lu,Ninghao Liu*

Main category: cs.AI

TL;DR: 提出了基于互信息的树搜索框架MITS，通过点互信息评分函数和动态采样策略，在保持计算效率的同时提升大语言模型的推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有树搜索方法难以对中间推理步骤进行即时可靠的量化评估，且广泛路径探索计算成本高昂。

Method: 引入基于点互信息的评分函数，通过束搜索扩展搜索树而无需昂贵的前瞻模拟；采用基于熵的动态采样策略自适应分配计算资源；使用加权投票方案结合PMI分数和预测共识进行最终预测。

Result: 在多样化推理基准测试中，MITS始终超越基线方法。

Conclusion: MITS为LLM推理建立了一个原则性且高效的框架。

Abstract: Tree search has become as a representative framework for test-time reasoning
with large language models (LLMs), exemplified by methods such as
Tree-of-Thought and Monte Carlo Tree Search that explore multiple reasoning
paths. However, it remains difficult to provide instant and reliable
quantitative assessments of intermediate reasoning step quality, and extensive
path exploration is computationally costly. To address this, we propose Mutual
Information Tree Search (MITS), a novel framework that guides reasoning with
information-theoretic principles. MITS introduces an effective scoring function
based on pointwise mutual information (PMI), which enables step-wise evaluation
of reasoning paths and search tree expansion via beam search without expensive
look-ahead simulations, achieving superior reasoning performances while
maintaining computational efficiency. The framework is complemented by an
entropy-based dynamic sampling strategy that adaptively allocates computational
resources to uncertain reasoning steps where exploration is most beneficial.
For final prediction, MITS employs a weighted voting scheme that combines PMI
scores with prediction consensus. Through comprehensive experiments on diverse
reasoning benchmarks, MITS consistently surpasses baseline methods,
establishing a principled and efficient framework for LLM reasoning.

</details>


### [78] [Rainbow Padding: Mitigating Early Termination in Instruction-Tuned Diffusion LLMs](https://arxiv.org/abs/2510.03680)
*Bumjun Kim,Dongjae Jeon,Dueun Kim,Wonje Jeung,Albert No*

Main category: cs.AI

TL;DR: 扩散大语言模型在指令调优后存在<eos>溢出问题：随着序列长度增加，响应反而变短，导致提前终止或退化为<eos>令牌流。作者提出了Rainbow Padding方法，用循环的不同填充令牌替换重复的<eos>占位符，有效解决了这一问题。


<details>
  <summary>Details</summary>
Motivation: 指令调优的扩散大语言模型存在<eos>溢出漏洞，当分配的序列长度增加时，响应反而变短，出现提前终止或退化为<eos>令牌流的问题，这在实际应用中已被注意到但尚未系统分析。

Method: 提出了Rainbow Padding方法，用循环的不同填充令牌替换重复的<eos>占位符，分散概率质量，打破<eos>的主导地位。该方法可高效集成到现有指令调优模型中，仅需少量数据和单轮LoRA微调即可显著改进。

Result: Rainbow Padding显著提高了长度鲁棒性和输出质量，仅需七个填充令牌即可防止提前终止。该方法在现有指令调优模型上集成效率高，单轮LoRA微调即可获得显著改进。

Conclusion: Rainbow Padding是一种简单有效的解决方案，解决了扩散大语言模型中<eos>溢出的关键问题，提高了模型的长度鲁棒性和输出质量，具有很高的实用性。

Abstract: Diffusion large language models (dLLMs) have emerged as a promising
alternative to autoregressive models, offering flexible generation orders and
strong performance on complex reasoning tasks. However, instruction-tuned dLLMs
exhibit a critical vulnerability we term \texttt{<eos>} overflow: as allocated
sequence length increases, responses paradoxically become shorter, collapsing
into early termination or degenerating into streams of \texttt{<eos>} tokens.
Although noticed in practice, this issue has not been systematically analyzed.
We trace its root cause to the dual role of \texttt{<eos>} as both termination
and padding, which concentrates probability mass on \texttt{<eos>} at later
positions and propagates backward to trigger early termination. To address
this, we introduce Rainbow Padding, a simple remedy that replaces repeated
\texttt{<eos>} placeholders with a repeating cycle of distinct padding tokens,
distributing probability mass and breaking \texttt{<eos>} dominance.
Experiments show that Rainbow Padding substantially improves length robustness
and output quality, with as few as seven padding tokens sufficient to prevent
early termination. Moreover, the method integrates efficiently into existing
instruction-tuned models: LoRA fine-tuning for a single epoch on minimal data
yields significant improvements, making this solution highly practical. The
code is publicly available at https://github.com/quasar529/rainbow-padding.

</details>


### [79] [Mind the Goal: Data-Efficient Goal-Oriented Evaluation of Conversational Agents and Chatbots using Teacher Models](https://arxiv.org/abs/2510.03696)
*Deepak Babu Piskala,Sharlene Chen,Udita Patel,Parul Kalra,Rafael Castrillo*

Main category: cs.AI

TL;DR: 提出了一个面向目标的多智能体系统评估框架，引入目标成功率(GSR)和失败根因分类(RCOF)，通过基于模型的方法评估多轮对话中用户目标的完成情况。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多在轮次层面评估多轮聊天机器人交互，无法判断用户的核心目标是否被满足，需要更全面的目标导向评估框架。

Method: 将对话按用户目标分段，使用教师LLM结合领域专家定义的目标和质量标准进行评估，通过"思考标记"生成可解释的推理过程。

Result: 在企业环境中应用该框架评估AIDA系统，观察到目标成功率从63%提升到79%。

Conclusion: 该框架具有通用性，通过详细的缺陷分类提供可操作的见解，能够诊断整体成功率、识别关键失败模式并指导系统改进。

Abstract: Evaluating the quality of multi-turn chatbot interactions remains
challenging, as most existing methods assess interactions at the turn level
without addressing whether a user's overarching goal was fulfilled. A ``goal''
here refers to an information need or task, such as asking for policy
information or applying for leave. We propose a comprehensive framework for
goal-oriented evaluation of multi-agent systems (MAS), introducing the
\textbf{Goal Success Rate (GSR)} to measure the percentage of fulfilled goals,
and a \textbf{Root Cause of Failure (RCOF)} taxonomy to identify reasons for
failure in multi-agent chatbots. Our method segments conversations by user
goals and evaluates success using all relevant turns. We present a model-based
evaluation system combining teacher LLMs, where domain experts define goals,
set quality standards serving as a guidance for the LLMs. The LLMs use
``thinking tokens'' to produce interpretable rationales, enabling
\textit{explainable}, \textit{data-efficient} evaluations. In an enterprise
setting, we apply our framework to evaluate AIDA, a zero-to-one employee
conversational agent system built as a ground-up multi-agent conversational
agent, and observe GSR improvement from 63\% to 79\% over six months since its
inception. Our framework is generic and offers actionable insights through a
detailed defect taxonomy based on analysis of failure points in multi-agent
chatbots, diagnosing overall success, identifying key failure modes, and
informing system improvements.

</details>


### [80] [H-DDx: A Hierarchical Evaluation Framework for Differential Diagnosis](https://arxiv.org/abs/2510.03700)
*Seungseop Lim,Gibaeg Kim,Hyunkyung Lee,Wooseok Han,Jean Seo,Jaehyo Yoo,Eunho Yang*

Main category: cs.AI

TL;DR: 提出了H-DDx分层评估框架，用于更准确地评估大语言模型在医学鉴别诊断中的表现，克服了传统扁平指标忽略临床相关性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在医学鉴别诊断评估中主要依赖扁平指标（如Top-k准确率），这些指标无法区分临床相关的近似错误和诊断上相距较远的错误，限制了评估的临床意义。

Method: 开发了H-DDx分层评估框架，采用检索和重排序流程将自由文本诊断映射到ICD-10代码，并应用分层指标来奖励与真实诊断密切相关的预测。

Result: 在22个领先模型的基准测试中，发现传统扁平指标低估了性能，忽略了临床有意义的输出；领域专业化的开源模型表现突出；框架还揭示了分层错误模式，显示LLM即使错过精确诊断也能正确识别更广泛的临床背景。

Conclusion: H-DDx框架提供了更临床相关的评估方法，能更好地反映大语言模型在医学鉴别诊断中的实际能力，为未来模型开发和评估提供了重要参考。

Abstract: An accurate differential diagnosis (DDx) is essential for patient care,
shaping therapeutic decisions and influencing outcomes. Recently, Large
Language Models (LLMs) have emerged as promising tools to support this process
by generating a DDx list from patient narratives. However, existing evaluations
of LLMs in this domain primarily rely on flat metrics, such as Top-k accuracy,
which fail to distinguish between clinically relevant near-misses and
diagnostically distant errors. To mitigate this limitation, we introduce H-DDx,
a hierarchical evaluation framework that better reflects clinical relevance.
H-DDx leverages a retrieval and reranking pipeline to map free-text diagnoses
to ICD-10 codes and applies a hierarchical metric that credits predictions
closely related to the ground-truth diagnosis. In benchmarking 22 leading
models, we show that conventional flat metrics underestimate performance by
overlooking clinically meaningful outputs, with our results highlighting the
strengths of domain-specialized open-source models. Furthermore, our framework
enhances interpretability by revealing hierarchical error patterns,
demonstrating that LLMs often correctly identify the broader clinical context
even when the precise diagnosis is missed.

</details>


### [81] [Bridging the Gap Between Multimodal Foundation Models and World Models](https://arxiv.org/abs/2510.03727)
*Xuehai He*

Main category: cs.AI

TL;DR: 该论文探讨如何将多模态基础模型提升为世界模型，通过增强其推理能力和生成能力，使其能够进行反事实推理、模拟动态过程、理解时空信息，并实现可控的视觉生成。


<details>
  <summary>Details</summary>
Motivation: 受人类通过多感官整合理解世界的启发，当前的多模态基础模型在作为世界模型方面存在不足，缺乏反事实推理、动态模拟、时空理解等关键能力，需要填补这一差距。

Method: 通过判别性任务提升推理能力，赋予结构化推理技能（因果推断、反事实思维、时空推理）；在生成方面引入结构化可控生成框架，利用场景图、多模态条件约束和对齐策略来指导生成过程。

Result: 开发了能够超越表面相关性、理解深层关系的新型多模态模型，实现了可控的4D生成，支持交互式、可编辑和可变形对象的时空合成。

Conclusion: 通过增强推理和生成能力，多模态基础模型可以更好地模拟和理解世界，成为更有效的世界模型，为复杂物理过程的感知和推理提供支持。

Abstract: Humans understand the world through the integration of multiple sensory
modalities, enabling them to perceive, reason about, and imagine dynamic
physical processes. Inspired by this capability, multimodal foundation models
(MFMs) have emerged as powerful tools for multimodal understanding and
generation. However, today's MFMs fall short of serving as effective world
models. They lack the essential ability such as perform counterfactual
reasoning, simulate dynamics, understand the spatiotemporal information,
control generated visual outcomes, and perform multifaceted reasoning. We
investigates what it takes to bridge the gap between multimodal foundation
models and world models. We begin by improving the reasoning capabilities of
MFMs through discriminative tasks and equipping MFMs with structured reasoning
skills, such as causal inference, counterfactual thinking, and spatiotemporal
reasoning, enabling them to go beyond surface correlations and understand
deeper relationships within visual and textual data. Next, we explore
generative capabilities of multimodal foundation models across both image and
video modalities, introducing new frameworks for structured and controllable
generation. Our approaches incorporate scene graphs, multimodal conditioning,
and multimodal alignment strategies to guide the generation process, ensuring
consistency with high-level semantics and fine-grained user intent. We further
extend these techniques to controllable 4D generation, enabling interactive,
editable, and morphable object synthesis over time and space.

</details>


### [82] [OptAgent: Optimizing Query Rewriting for E-commerce via Multi-Agent Simulation](https://arxiv.org/abs/2510.03771)
*Divij Handa,David Blincoe,Orson Adams,Yinlin Fu*

Main category: cs.AI

TL;DR: OptAgent框架结合多智能体模拟和遗传算法来优化电商查询改写，通过模拟购物顾客的LLM智能体作为动态奖励信号，在5个类别的1000个真实电商查询上平均改进21.98%。


<details>
  <summary>Details</summary>
Motivation: LLM在可验证任务中表现优异，但在缺乏单一正确答案的主观任务（如电商查询改写）中部署困难，因为难以算法化判断改写查询是否准确捕捉用户意图。

Method: 使用多个基于LLM的智能体模拟购物顾客作为动态奖励信号，将这些智能体评分的平均值作为进化算法的适应度函数，迭代优化用户初始查询。

Result: 在5个类别的1000个真实电商查询上评估，OptAgent相比原始用户查询平均改进21.98%，相比最佳N次LLM改写基线改进3.36%。

Conclusion: OptAgent框架通过多智能体模拟和遗传算法有效解决了电商查询改写这一主观任务的评估和优化问题，显著提升了查询质量。

Abstract: Deploying capable and user-aligned LLM-based systems necessitates reliable
evaluation. While LLMs excel in verifiable tasks like coding and mathematics,
where gold-standard solutions are available, adoption remains challenging for
subjective tasks that lack a single correct answer. E-commerce Query Rewriting
(QR) is one such problem where determining whether a rewritten query properly
captures the user intent is extremely difficult to figure out algorithmically.
In this work, we introduce OptAgent, a novel framework that combines
multi-agent simulations with genetic algorithms to verify and optimize queries
for QR. Instead of relying on a static reward model or a single LLM judge, our
approach uses multiple LLM-based agents, each acting as a simulated shopping
customer, as a dynamic reward signal. The average of these agent-derived scores
serves as an effective fitness function for an evolutionary algorithm that
iteratively refines the user's initial query. We evaluate OptAgent on a dataset
of 1000 real-world e-commerce queries in five different categories, and we
observe an average improvement of 21.98% over the original user query and 3.36%
over a Best-of-N LLM rewriting baseline.

</details>


### [83] [GuidedSampling: Steering LLMs Towards Diverse Candidate Solutions at Inference-Time](https://arxiv.org/abs/2510.03777)
*Divij Handa,Mihir Parmar,Aswin RRV,Md Nayem Uddin,Hamid Palangi,Chitta Baral*

Main category: cs.AI

TL;DR: 提出了一种名为GuidedSampling的新推理算法，通过将探索和生成阶段解耦来提高解决方案候选的多样性，相比传统重复采样方法在多个基准测试中显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 传统重复采样方法在推理时虽然能提升模型性能，但往往难以生成多样化的解决方案候选，经常依赖相同的基础方法解决问题，导致样本冗余。

Method: GuidedSampling算法将推理过程分为探索和生成两个阶段：探索阶段识别可用于解决问题的多个概念，生成阶段应用特定概念提供最终解决方案候选。

Result: 相比重复采样，GuidedSampling在pass@50指标上平均提升约21.6%；使用GuidedSampling轨迹训练的模型在pass@5上平均提升约9.7%，且每个实例的平均概念数量从1.67增加到3.03。

Conclusion: GuidedSampling通过解耦探索和生成阶段，有效提高了解决方案的多样性，在多个基准测试中显著优于传统重复采样方法。

Abstract: Repeated Sampling (RS) is a simple inference-time algorithm that has been
shown to improve model performance on complex tasks. Although it is an
effective way of scaling inference time, it often struggles to generate diverse
solution candidates, frequently relying on the same underlying approach to
solve the problem and thus producing redundant samples. To address this
limitation, we propose a new inference algorithm, GuidedSampling, which
decouples the exploration and generation phases during inference, increasing
diversity of generated candidate solutions. The exploration phase identifies
multiple concepts that can be utilized to solve the problem, while the
generation phase applies a specific concept to provide final solution
candidates. We first define the theoretical bounds of GuidedSampling and then
empirically demonstrate that it improves the performance of base model at
pass@50 by on an average ~21.6% across various benchmarks compared to RS.
Furthermore, models trained on trajectories of GuidedSampling exhibit
substantial performance improvements at pass@5 by on an average ~9.7%, compared
to models trained on traditional RS. Additionally, models trained with
GuidedSampling increases the average number of concepts per instance (1.67 ->
3.03), yielding a diverse set of candidates than traditional RS.

</details>


### [84] [The Hidden Game Problem](https://arxiv.org/abs/2510.03845)
*Gon Buzaglo,Noah Golowich,Elad Hazan*

Main category: cs.AI

TL;DR: 本文研究了具有大型策略空间的游戏，提出了隐藏游戏问题，并开发了能够发现和利用隐藏结构的遗憾最小化算法，实现最优的外部遗憾和交换遗憾界限。


<details>
  <summary>Details</summary>
Motivation: 受AI对齐和语言游戏挑战的启发，研究当每个玩家存在未知策略子集能持续获得更高奖励时的隐藏游戏问题，探索能否设计高效算法来发现并利用这种隐藏结构。

Method: 开发了一种遗憾最小化技术的组合方法，通过结合外部遗憾和交换遗憾最小化，利用隐藏游戏结构提高计算效率，确保在隐藏子游戏中快速收敛到相关均衡。

Result: 成功设计了能够实现最优外部遗憾和交换遗憾界限的算法，证明可以在隐藏游戏中快速收敛到相关均衡，同时保持一般情况下的理性。

Conclusion: 对隐藏游戏问题给出了肯定回答，证明了通过精心设计的遗憾最小化算法组合，可以有效发现和利用游戏中的隐藏结构，实现高效均衡收敛。

Abstract: This paper investigates a class of games with large strategy spaces,
motivated by challenges in AI alignment and language games. We introduce the
hidden game problem, where for each player, an unknown subset of strategies
consistently yields higher rewards compared to the rest. The central question
is whether efficient regret minimization algorithms can be designed to discover
and exploit such hidden structures, leading to equilibrium in these subgames
while maintaining rationality in general. We answer this question affirmatively
by developing a composition of regret minimization techniques that achieve
optimal external and swap regret bounds. Our approach ensures rapid convergence
to correlated equilibria in hidden subgames, leveraging the hidden game
structure for improved computational efficiency.

</details>


### [85] [Small Language Models for Agentic Systems: A Survey of Architectures, Capabilities, and Deployment Trade offs](https://arxiv.org/abs/2510.03847)
*Raghav Sharma,Manan Mehta*

Main category: cs.AI

TL;DR: 小语言模型(SLMs)在代理任务中比大语言模型更高效，通过引导解码、严格JSON Schema输出和验证器优先的工具执行，能以10-100倍更低的成本实现相似或更好的性能，同时提供更低的延迟和能耗。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在代理工作负载中成本高、延迟大、能耗高，而小语言模型在结构化输出和API约束任务中可能更高效，需要系统化验证这一假设。

Method: 综合评估多种开源和专有小语言模型，结合引导解码库和验证器级联，提出SLM默认、LLM回退系统，采用不确定性感知路由和验证器级联。

Result: 小语言模型在工具使用、函数调用和RAG任务中能匹配或超越大语言模型，成本降低10-100倍，延迟和能耗显著改善。

Conclusion: 提供了一套优先使用小语言模型的代理系统设计蓝图，在保持大语言模型回退能力的同时，实现快速、廉价且可靠的代理系统。

Abstract: Small language models (SLMs; 1-12B params, sometimes up to 20B) are
sufficient and often superior for agentic workloads where the objective is
schema- and API-constrained accuracy rather than open-ended generation. We
synthesize recent evidence across open and proprietary SLMs (Phi-4-Mini,
Qwen-2.5-7B, Gemma-2-9B, Llama-3.2-1B/3B, Ministral-3B/8B, Apple on-device 3B,
DeepSeek-R1-Distill) and connect it to modern evaluations (BFCL v3/v4,
StableToolBench) and serving stacks (vLLM, SGLang, TensorRT-LLM) paired with
guided decoding libraries (XGrammar, Outlines). We formalize SLM-default,
LLM-fallback systems with uncertainty-aware routing and verifier cascades, and
propose engineering metrics that reflect real production goals: cost per
successful task (CPS), schema validity rate, executable call rate, p50/p95
latency, and energy per request. Guided decoding, strict JSON Schema outputs,
and validator-first tool execution close much of the capability gap with larger
models and often let SLMs match or surpass LLMs on tool use, function calling,
and RAG at 10x-100x lower token cost with materially better latency and energy.
We provide design patterns for agent stacks that prioritize SLMs: schema-first
prompting, type-safe function registries, confidence scoring with verifier
rollups, and lightweight adaptation via LoRA/QLoRA. We also delineate limits
where fallback remains valuable (open-domain reasoning and some long-horizon
planning). The result is a practical blueprint for building fast, inexpensive,
and reliable agents that default to SLMs while preserving headroom with
targeted LLM assistance.
  Keywords: small language models, agents, function calling, structured
outputs, JSON Schema, guided decoding, LoRA/QLoRA, routing, energy efficiency,
edge inference

</details>


### [86] [Algorithm Generation via Creative Ideation](https://arxiv.org/abs/2510.03851)
*Ruiying Ma,Chieh-Jan Mike Liang,Yanjie Gao,Francis Y. Yan*

Main category: cs.AI

TL;DR: MetaMuse框架通过三个自反思原则解决LLM在算法生成中的局限性：在性能空间量化解决方案多样性、通过外部刺激引导构思、使用路点推理构建可执行方案，显著提升了缓存替换和在线装箱问题的性能。


<details>
  <summary>Details</summary>
Motivation: 系统算法设计面临解空间不连续的挑战，现有LLM偏向通用设计而缺乏创造性突破，需要新方法来导航不连续解空间。

Method: 提出MetaMuse框架，基于三个自反思原则：在可测量性能空间而非抽象思想空间量化解决方案多样性和有用性；通过外部刺激而非内部随机性引导构思；使用路点推理而非自由形式的思维链构建可执行解决方案。

Result: 在缓存替换问题上减少缓存缺失达35.76%，在在线装箱问题上减少容器使用达30.93%。

Conclusion: MetaMuse框架能够有效生成高性能解决方案，解决了LLM在算法生成中的创造性局限问题。

Abstract: Designing system algorithms remains challenging, where the discontinuous
nature of the solution space often forces system engineers to rely on generic
heuristics at the expense of performance. We study whether LLMs can practically
drive algorithm generation, and find that they are biased towards well-known
generic designs, rather than making the creative leaps needed to navigate the
discontinuous solution space. To address this limitation, we introduce
MetaMuse, a framework for creative ideation built on three self-reflection
principles: (1) quantifying solution diversity and usefulness in measurable
performance space, rather than abstract idea space, (2) steering ideation
through external stimuli, rather than internal randomness, and (3) constructing
executable solutions using waypoint reasoning, rather than free-form
chain-of-thought. Extensive evaluation shows that MetaMuse can generate
high-performing solutions for two critical problems at a global cloud provider:
cache replacement (reducing cache misses by up to 35.76%) and online bin
packing (reducing bin usage by up to 30.93%).

</details>


### [87] [Adaptive and Explainable AI Agents for Anomaly Detection in Critical IoT Infrastructure using LLM-Enhanced Contextual Reasoning](https://arxiv.org/abs/2510.03859)
*Raghav Sharma,Manan Mehta*

Main category: cs.AI

TL;DR: 提出了一种基于LLM和XAI代理的智能异常检测方法，用于关键IoT系统，在动态高维环境中提高检测准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统异常检测方法在复杂IoT系统（如智能医疗、能源电网）中存在局限性，特别是在数据不完整、混乱或动态变化的情况下，需要自适应智能系统来持续改进。

Method: 使用LLM支持的上下文推理方法与XAI代理相结合，利用注意力机制发现隐藏模式，避免处理每个时间步的细节，使用语义记忆缓冲区，强调透明性和可解释性。

Result: 在智能电网和医疗场景的模拟测试中，新方法在检测准确率、误报率、可读性和响应速度方面显著优于传统模型。

Conclusion: LLM增强的异常检测方法在准确性和可解释性方面表现优异，适合未来IoT系统中的异常检测任务。

Abstract: Ensuring that critical IoT systems function safely and smoothly depends a lot
on finding anomalies quickly. As more complex systems, like smart healthcare,
energy grids and industrial automation, appear, it is easier to see the
shortcomings of older methods of detection. Monitoring failures usually happen
in dynamic, high dimensional situations, especially when data is incomplete,
messy or always evolving. Such limits point out the requirement for adaptive,
intelligent systems that always improve and think. LLMs are now capable of
significantly changing how context is understood and semantic inference is done
across all types of data. This proposal suggests using an LLM supported
contextual reasoning method along with XAI agents to improve how anomalies are
found in significant IoT environments. To discover hidden patterns and notice
inconsistencies in data streams, it uses attention methods, avoids dealing with
details from every time step and uses memory buffers with meaning. Because no
code AI stresses transparency and interpretability, people can check and accept
the AI's decisions, helping ensure AI follows company policies. The two
architectures are put together in a test that compares the results of the
traditional model with those of the suggested LLM enhanced model. Important
measures to check are the accuracy of detection, how much inaccurate
information is included in the results, how clearly the findings can be read
and how fast the system responds under different test situations. The
metaheuristic is tested in simulations of real world smart grid and healthcare
contexts to check its adaptability and reliability. From the study, we see that
the new approach performs much better than most existing models in both
accuracy and interpretation, so it could be a good fit for future anomaly
detection tasks in IoT

</details>


### [88] [Spatial CAPTCHA: Generatively Benchmarking Spatial Reasoning for Human-Machine Differentiation](https://arxiv.org/abs/2510.03863)
*Arina Kharlamova,Bowei He,Chen Ma,Xue Liu*

Main category: cs.AI

TL;DR: 提出了Spatial CAPTCHA，一种基于空间推理的新型人机验证框架，利用人类与多模态大语言模型在空间推理能力上的根本差异来防御自动化攻击。


<details>
  <summary>Details</summary>
Motivation: 传统CAPTCHA依赖文本识别或2D图像理解，但多模态大语言模型的进步已削弱其有效性，需要开发更安全的人机验证方法。

Method: 采用程序化生成管道，创建需要几何推理、视角转换、遮挡处理和心理旋转的动态问题，结合基于约束的难度控制、自动正确性验证和人在环验证。

Result: 在Spatial-CAPTCHA-Bench基准测试中，人类表现远超10个最先进的多模态大语言模型，最佳模型仅达到31.0%的Pass@1准确率，且优于Google reCAPTCHA。

Conclusion: Spatial CAPTCHA不仅是有效的安全机制，也是评估AI空间推理能力的诊断工具，为应对现代AI威胁提供了新方向。

Abstract: Online services rely on CAPTCHAs as a first line of defense against automated
abuse, yet recent advances in multi-modal large language models (MLLMs) have
eroded the effectiveness of conventional designs that focus on text recognition
or 2D image understanding. To address this challenge, we present Spatial
CAPTCHA, a novel human-verification framework that leverages fundamental
differences in spatial reasoning between humans and MLLMs. Unlike existing
CAPTCHAs which rely on low-level perception tasks that are vulnerable to modern
AI, Spatial CAPTCHA generates dynamic questions requiring geometric reasoning,
perspective-taking, occlusion handling, and mental rotation. These skills are
intuitive for humans but difficult for state-of-the-art (SOTA) AI systems. The
system employs a procedural generation pipeline with constraint-based
difficulty control, automated correctness verification, and human-in-the-loop
validation to ensure scalability, robustness, and adaptability. Evaluation on a
corresponding benchmark, Spatial-CAPTCHA-Bench, demonstrates that humans vastly
outperform 10 state-of-the-art MLLMs, with the best model achieving only 31.0%
Pass@1 accuracy. Furthermore, we compare Spatial CAPTCHA with Google reCAPTCHA,
which confirms its effectiveness as both a security mechanism and a diagnostic
tool for spatial reasoning in AI.

</details>


### [89] [Rare Text Semantics Were Always There in Your Diffusion Transformer](https://arxiv.org/abs/2510.03886)
*Seil Kang,Woojung Han,Dayun Ju,Seong Jae Hwang*

Main category: cs.AI

TL;DR: 提出一种无需额外训练的方法，通过在MM-DiT的联合注意力机制前扩大文本标记嵌入的表示空间，有效提升模型对罕见语义的生成能力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态扩散变换器在处理用户提出的想象力丰富或罕见概念时表现不佳，因为这些概念在预训练中缺乏足够的数据支持。

Method: 在联合注意力块之前，通过数学方法扩大文本标记嵌入的表示空间（方差放大），使罕见语义能够更清晰地浮现。

Result: 该方法能有效提升模型对罕见语义的生成质量，并在文本到图像、文本到视频和文本驱动图像编辑等任务中均表现出良好的泛化能力。

Conclusion: 该方法为生成模型提供了一种简单有效的干预手段，能够揭示用户意图中原本隐藏的语义内容。

Abstract: Starting from flow- and diffusion-based transformers, Multi-modal Diffusion
Transformers (MM-DiTs) have reshaped text-to-vision generation, gaining acclaim
for exceptional visual fidelity. As these models advance, users continually
push the boundary with imaginative or rare prompts, which advanced models still
falter in generating, since their concepts are often too scarce to leave a
strong imprint during pre-training. In this paper, we propose a simple yet
effective intervention that surfaces rare semantics inside MM-DiTs without
additional training steps, data, denoising-time optimization, or reliance on
external modules (e.g., large language models). In particular, the
joint-attention mechanism intrinsic to MM-DiT sequentially updates text
embeddings alongside image embeddings throughout transformer blocks. We find
that by mathematically expanding representational basins around text token
embeddings via variance scale-up before the joint-attention blocks, rare
semantics clearly emerge in MM-DiT's outputs. Furthermore, our results
generalize effectively across text-to-vision tasks, including text-to-image,
text-to-video, and text-driven image editing. Our work invites generative
models to reveal the semantics that users intend, once hidden yet ready to
surface.

</details>


### [90] [Kantian-Utilitarian XAI: Meta-Explained](https://arxiv.org/abs/2510.03892)
*Zahra Atf,Peter R. Lewis*

Main category: cs.AI

TL;DR: 开发了一个游戏化的可解释AI系统，用于咖啡消费决策，结合康德主义和功利主义伦理框架提供实时解释。


<details>
  <summary>Details</summary>
Motivation: 帮助消费者在咖啡购买中做出符合伦理的决策，通过结合不同伦理视角提供透明解释。

Method: 系统包含六个回合，每回合三个选项。康德模块检测规则违反，功利模块多标准评分，元解释器处理伦理冲突。

Result: 实现了可审计的政策追踪和交互界面，当福利损失较小时能切换到符合道义原则的选项。

Conclusion: 该XAI系统成功整合了不同伦理框架，为消费者决策提供了透明、可解释的指导。

Abstract: We present a gamified explainable AI (XAI) system for ethically aware
consumer decision-making in the coffee domain. Each session comprises six
rounds with three options per round. Two symbolic engines provide real-time
reasons: a Kantian module flags rule violations (e.g., child labor,
deforestation risk without shade certification, opaque supply chains, unsafe
decaf), and a utilitarian module scores options via multi-criteria aggregation
over normalized attributes (price, carbon, water, transparency, farmer income
share, taste/freshness, packaging, convenience). A meta-explainer with a regret
bound (0.2) highlights Kantian--utilitarian (mis)alignment and switches to a
deontically clean, near-parity option when welfare loss is small. We release a
structured configuration (attribute schema, certification map, weights, rule
set), a policy trace for auditability, and an interactive UI.

</details>


### [91] [Quantifying Risks in Multi-turn Conversation with Large Language Models](https://arxiv.org/abs/2510.03969)
*Chengxiao Wang,Isha Chaudhary,Qian Hu,Weitong Ruan,Rahul Gupta,Gagandeep Singh*

Main category: cs.AI

TL;DR: QRLLM是一个用于评估LLM在多轮对话中产生灾难性响应风险的认证框架，通过马尔可夫过程建模对话分布，提供统计保证的风险边界。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法因依赖固定攻击提示序列、缺乏统计保证且无法扩展到多轮对话空间，难以充分揭示LLM的灾难性响应漏洞。

Method: 将多轮对话建模为查询序列的概率分布，用查询图的马尔可夫过程表示对话流程，定义随机节点、图路径、带拒绝的自适应等实用分布。

Result: 这些分布能显著揭示前沿模型的灾难性风险，最差模型的认证下界高达70%，表明前沿LLM需要改进安全训练策略。

Conclusion: QRLLM框架为LLM在多轮对话中的灾难性风险提供了原则性的认证方法，揭示了当前模型存在的严重安全隐患。

Abstract: Large Language Models (LLMs) can produce catastrophic responses in
conversational settings that pose serious risks to public safety and security.
Existing evaluations often fail to fully reveal these vulnerabilities because
they rely on fixed attack prompt sequences, lack statistical guarantees, and do
not scale to the vast space of multi-turn conversations. In this work, we
propose QRLLM, a novel, principled Certification framework for Catastrophic
risks in multi-turn Conversation for LLMs that bounds the probability of an LLM
generating catastrophic responses under multi-turn conversation distributions
with statistical guarantees. We model multi-turn conversations as probability
distributions over query sequences, represented by a Markov process on a query
graph whose edges encode semantic similarity to capture realistic
conversational flow, and quantify catastrophic risks using confidence
intervals. We define several inexpensive and practical distributions: random
node, graph path, adaptive with rejection. Our results demonstrate that these
distributions can reveal substantial catastrophic risks in frontier models,
with certified lower bounds as high as 70\% for the worst model, highlighting
the urgent need for improved safety training strategies in frontier LLMs.

</details>


### [92] [What Shapes a Creative Machine Mind? Comprehensively Benchmarking Creativity in Foundation Models](https://arxiv.org/abs/2510.04009)
*Zicong He,Boxuan Zhang,Weihao Liu,Ruixiang Tang,Lu Cheng*

Main category: cs.AI

TL;DR: 提出了C^2-Eval基准，用于统一评估基础模型的创造力，区分收敛性创造力和发散性创造力，基于有用性、原创性和惊喜性三个标准。


<details>
  <summary>Details</summary>
Motivation: 现有创造力评估框架碎片化，缺乏理论基础，无法全面评估基础模型在生成任务中的创造力表现。

Method: 引入C^2-Eval基准，区分收敛性创造力（有约束解）和发散性创造力（开放式任务），使用基于社会科学理论的U-O-S标准进行评估。

Result: 通过对领先专有和开源模型的广泛实验，分析了它们在创造力能力上的权衡，揭示了当前基础模型在追求创造性机器智能方面的优势和挑战。

Conclusion: C^2-Eval是检验创造性AI发展格局的有效工具，能够全面评估基础模型的创造力表现。

Abstract: The meteoric rise of foundation models (FMs) has expanded their capabilities
far beyond conventional tasks. Creativity, long regarded as a hallmark of human
intelligence and a driver of innovation, is now increasingly recognized as a
critical dimension of machine intelligence in the era of generative FMs,
complementing traditional measures of accuracy. However, existing evaluation
frameworks for creativity remain fragmented, relying on ad hoc metrics not
firmly grounded in established theories. To address this gap, we introduce
C^2-Eval, a holistic benchmark for unified assessment of creativity in FMs.
C^2-Eval distinguishes between two complementary forms of creativity:
convergent creativity, where tasks admit constrained solutions (e.g., code
generation), and divergent creativity, where tasks are open-ended (e.g.,
storytelling). It evaluates both dimensions using fine-grained criteria derived
from social-science theory, focusing on Usefulness, Originality, and Surprise
(U-O-S). Through extensive experiments on leading proprietary and open-source
models, we analyze trade-offs in their creative capabilities. Our results
highlight both the strengths and challenges of current FMs in pursuing a
creative machine mind, showing that C^2-Eval is an effective lens for examining
the evolving landscape of creative AI.

</details>


### [93] [Zephyrus: An Agentic Framework for Weather Science](https://arxiv.org/abs/2510.04017)
*Sumanth Varambally,Marshall Fisher,Jas Thakker,Yiwei Chen,Zhirui Xia,Yasaman Jafari,Ruijia Niu,Manas Jain,Veeramakali Vignesh Manivannan,Zachary Novack,Luyu Han,Srikar Eranky,Salva Rühling Cachay,Taylor Berg-Kirkpatrick,Duncan Watson-Parris,Yi-An Ma,Rose Yu*

Main category: cs.AI

TL;DR: 提出了一个基于LLM的气象科学代理框架Zephyrus，通过代码环境与气象数据交互，在ZephyrusBench基准测试中比纯文本基线性能提升高达35个百分点。


<details>
  <summary>Details</summary>
Motivation: 现有气象基础模型缺乏语言推理能力，而大语言模型无法处理高维气象数据，需要桥接这一鸿沟以支持交互式科学工作流。

Method: 构建ZephyrusWorld代码环境，包含WeatherBench 2数据集接口、地理查询、天气预报和气候模拟等工具，设计多轮LLM气象代理Zephyrus进行迭代分析和反馈。

Result: 在ZephyrusBench基准测试中，Zephyrus代理在正确性上比纯文本基线提升高达35个百分点，但在更难任务上表现相似。

Conclusion: 该框架成功结合了LLM的语言能力和气象数据交互能力，但更具挑战性的任务需要进一步改进，为未来工作指明了方向。

Abstract: Foundation models for weather science are pre-trained on vast amounts of
structured numerical data and outperform traditional weather forecasting
systems. However, these models lack language-based reasoning capabilities,
limiting their utility in interactive scientific workflows. Large language
models (LLMs) excel at understanding and generating text but cannot reason
about high-dimensional meteorological datasets. We bridge this gap by building
a novel agentic framework for weather science. Our framework includes a Python
code-based environment for agents (ZephyrusWorld) to interact with weather
data, featuring tools like an interface to WeatherBench 2 dataset, geoquerying
for geographical masks from natural language, weather forecasting, and climate
simulation capabilities. We design Zephyrus, a multi-turn LLM-based weather
agent that iteratively analyzes weather datasets, observes results, and refines
its approach through conversational feedback loops. We accompany the agent with
a new benchmark, ZephyrusBench, with a scalable data generation pipeline that
constructs diverse question-answer pairs across weather-related tasks, from
basic lookups to advanced forecasting, extreme event detection, and
counterfactual reasoning. Experiments on this benchmark demonstrate the strong
performance of Zephyrus agents over text-only baselines, outperforming them by
up to 35 percentage points in correctness. However, on harder tasks, Zephyrus
performs similarly to text-only baselines, highlighting the challenging nature
of our benchmark and suggesting promising directions for future work.

</details>


### [94] [LLM-Based Data Science Agents: A Survey of Capabilities, Challenges, and Future Directions](https://arxiv.org/abs/2510.04023)
*Mizanur Rahman,Amran Bhuiyan,Mohammed Saidul Islam,Md Tahmid Rahman Laskar,Ridwan Mahbub,Ahmed Masry,Shafiq Joty,Enamul Hoque*

Main category: cs.AI

TL;DR: 这篇论文对数据科学AI代理进行了首次全面的生命周期分类分析，系统性地将45个系统映射到数据科学流程的六个阶段，并识别了当前研究的关键趋势和挑战。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的发展，出现了能够自动化数据科学工作流程的新型AI代理，但目前缺乏对这些代理系统的系统性分类和分析，需要建立统一框架来理解其能力和局限性。

Method: 采用生命周期对齐的分类法，将45个数据科学代理系统映射到数据科学流程的六个阶段，并从五个交叉设计维度进行标注分析。

Result: 分析发现三个关键趋势：大多数系统强调探索性分析和建模而忽视业务理解和部署监控；多模态推理和工具编排仍是未解决的挑战；超过90%的系统缺乏明确的信任和安全机制。

Conclusion: 提出了未来研究方向，包括对齐稳定性、可解释性、治理和鲁棒评估框架等挑战，旨在指导开发更可靠、可信、低延迟、透明和广泛可访问的数据科学代理。

Abstract: Recent advances in large language models (LLMs) have enabled a new class of
AI agents that automate multiple stages of the data science workflow by
integrating planning, tool use, and multimodal reasoning across text, code,
tables, and visuals. This survey presents the first comprehensive,
lifecycle-aligned taxonomy of data science agents, systematically analyzing and
mapping forty-five systems onto the six stages of the end-to-end data science
process: business understanding and data acquisition, exploratory analysis and
visualization, feature engineering, model building and selection,
interpretation and explanation, and deployment and monitoring. In addition to
lifecycle coverage, we annotate each agent along five cross-cutting design
dimensions: reasoning and planning style, modality integration, tool
orchestration depth, learning and alignment methods, and trust, safety, and
governance mechanisms. Beyond classification, we provide a critical synthesis
of agent capabilities, highlight strengths and limitations at each stage, and
review emerging benchmarks and evaluation practices. Our analysis identifies
three key trends: most systems emphasize exploratory analysis, visualization,
and modeling while neglecting business understanding, deployment, and
monitoring; multimodal reasoning and tool orchestration remain unresolved
challenges; and over 90% lack explicit trust and safety mechanisms. We conclude
by outlining open challenges in alignment stability, explainability,
governance, and robust evaluation frameworks, and propose future research
directions to guide the development of robust, trustworthy, low-latency,
transparent, and broadly accessible data science agents.

</details>


### [95] [A global log for medical AI](https://arxiv.org/abs/2510.04033)
*Ayush Noori,Adam Rodman,Alan Karthikesalingam,Bilal A. Mateen,Christopher A. Longhurst,Daniel Yang,Dave deBronkart,Gauden Galea,Harold F. Wolf III,Jacob Waxman,Joshua C. Mandel,Juliana Rotich,Kenneth D. Mandl,Maryam Mustafa,Melissa Miles,Nigam H. Shah,Peter Lee,Robert Korom,Scott Mahoney,Seth Hain,Tien Yin Wong,Trevor Mundel,Vivek Natarajan,Noa Dagan,David A. Clifton,Ran D. Balicer,Isaac S. Kohane,Marinka Zitnik*

Main category: cs.AI

TL;DR: 提出MedLog协议，用于临床AI的事件级日志记录，类似于系统日志(syslog)，旨在解决医疗AI缺乏标准使用记录的问题。


<details>
  <summary>Details</summary>
Motivation: 医疗领域快速增长的临床AI堆栈缺乏标准化的使用记录方式，难以衡量真实世界性能、检测不良事件或纠正偏差，需要类似syslog的通用日志协议。

Method: 设计MedLog协议，包含9个核心字段：header、model、user、target、inputs、artifacts、outputs、outcomes和feedback，支持风险采样、生命周期感知保留策略和写后缓存。

Result: MedLog能够结构化记录AI模型活动，支持复杂工作流的详细跟踪，可促进新数据库和软件的开发。

Conclusion: MedLog为实现医疗AI的持续监控、审计和迭代改进奠定了基础，为数字流行病学新形式铺平道路。

Abstract: Modern computer systems often rely on syslog, a simple, universal protocol
that records every critical event across heterogeneous infrastructure. However,
healthcare's rapidly growing clinical AI stack has no equivalent. As hospitals
rush to pilot large language models and other AI-based clinical decision
support tools, we still lack a standard way to record how, when, by whom, and
for whom these AI models are used. Without that transparency and visibility, it
is challenging to measure real-world performance and outcomes, detect adverse
events, or correct bias or dataset drift. In the spirit of syslog, we introduce
MedLog, a protocol for event-level logging of clinical AI. Any time an AI model
is invoked to interact with a human, interface with another algorithm, or act
independently, a MedLog record is created. This record consists of nine core
fields: header, model, user, target, inputs, artifacts, outputs, outcomes, and
feedback, providing a structured and consistent record of model activity. To
encourage early adoption, especially in low-resource settings, and minimize the
data footprint, MedLog supports risk-based sampling, lifecycle-aware retention
policies, and write-behind caching; detailed traces for complex, agentic, or
multi-stage workflows can also be captured under MedLog. MedLog can catalyze
the development of new databases and software to store and analyze MedLog
records. Realizing this vision would enable continuous surveillance, auditing,
and iterative improvement of medical AI, laying the foundation for a new form
of digital epidemiology.

</details>


### [96] [FaithCoT-Bench: Benchmarking Instance-Level Faithfulness of Chain-of-Thought Reasoning](https://arxiv.org/abs/2510.04040)
*Xu Shen,Song Wang,Zhen Tan,Laura Yao,Xinyu Zhao,Kaidi Xu,Xin Wang,Tianlong Chen*

Main category: cs.AI

TL;DR: 提出了FaithCoT-Bench基准，用于检测LLM中思维链(CoT)的不忠实性，包含1000+轨迹数据和300+不忠实实例，评估了11种检测方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注机制层面的CoT不忠实性分析，但缺乏针对具体轨迹是否忠实于模型内部推理的实例级检测方法。

Method: 建立统一基准FaithCoT-Bench，包含FINE-CoT数据集（专家标注的1000+轨迹），将不忠实性检测制定为判别决策问题，评估反事实、基于logit和LLM作为评判者三类方法。

Result: 系统评估揭示了现有方法的优缺点，发现在知识密集型领域和更先进模型中的检测挑战更大。

Conclusion: FaithCoT-Bench是首个全面的实例级CoT忠实性基准，为LLM中更可解释和可信的推理研究奠定了基础。

Abstract: Large language models (LLMs) increasingly rely on Chain-of-Thought (CoT)
prompting to improve problem-solving and provide seemingly transparent
explanations. However, growing evidence shows that CoT often fail to faithfully
represent the underlying reasoning process, raising concerns about their
reliability in high-risk applications. Although prior studies have focused on
mechanism-level analyses showing that CoTs can be unfaithful, they leave open
the practical challenge of deciding whether a specific trajectory is faithful
to the internal reasoning of the model. To address this gap, we introduce
FaithCoT-Bench, a unified benchmark for instance-level CoT unfaithfulness
detection. Our framework establishes a rigorous task formulation that
formulates unfaithfulness detection as a discriminative decision problem, and
provides FINE-CoT (Faithfulness instance evaluation for Chain-of-Thought), an
expert-annotated collection of over 1,000 trajectories generated by four
representative LLMs across four domains, including more than 300 unfaithful
instances with fine-grained causes and step-level evidence. We further conduct
a systematic evaluation of eleven representative detection methods spanning
counterfactual, logit-based, and LLM-as-judge paradigms, deriving empirical
insights that clarify the strengths and weaknesses of existing approaches and
reveal the increased challenges of detection in knowledge-intensive domains and
with more advanced models. To the best of our knowledge, FaithCoT-Bench
establishes the first comprehensive benchmark for instance-level CoT
faithfulness, setting a solid basis for future research toward more
interpretable and trustworthy reasoning in LLMs.

</details>


### [97] [Increasing LLM response trustworthiness using voting ensembles](https://arxiv.org/abs/2510.04048)
*Aparna Nair-Kanneganti,Trevor J. Chan,Shir Goldfinger,Emily Mackay,Brian Anthony,Alison Pouch*

Main category: cs.AI

TL;DR: 提出了一种基于可变投票阈值的集成方法，允许模型在主导响应未达阈值时弃权，从而显著提高剩余答案的可信度。


<details>
  <summary>Details</summary>
Motivation: LLM在关键应用中缺乏可靠的不确定性量化方法，难以获得信任。需要一种简单有效的方法来提高回答的准确性。

Method: 扩展传统集成方法，引入可变投票阈值框架，允许集成在主导响应不达标时弃权，不提供答案。

Result: 在两个问题领域（算术问题求解和临床笔记问答）的实验表明，使用高度限制性投票集成可以大幅提高答案可信度，同时响应产出和准确性的降低相对较小。

Conclusion: 投票集成特别适用于需要高度确定性但不要求每个问题都获得自动化答案的应用场景，如医疗保健和数据标注。

Abstract: Despite huge advances, LLMs still lack convenient and reliable methods to
quantify the uncertainty in their responses, making them difficult to trust in
high-stakes applications. One of the simplest approaches to eliciting more
accurate answers is to select the mode of many responses, a technique known as
ensembling. In this work, we expand on typical ensembling approaches by looking
at ensembles with a variable voting threshold. We introduce a theoretical
framework for question answering and show that, by permitting ensembles to
"abstain" from providing an answer when the dominant response falls short of
the threshold, it is possible to dramatically increase the trustworthiness of
the remaining answers. From this framework, we derive theoretical results as
well as report experimental results on two problem domains: arithmetic problem
solving and clinical-note question-answering. In both domains, we observe that
large gains in answer trustworthiness can be achieved using highly restrictive
voting ensembles, while incurring relatively modest reductions in response
yield and accuracy. Due to this quality, voting ensembles may be particularly
useful in applications - such as healthcare and data annotation - that require
a high degree of certainty but which may not require that every question
receive an automated answer.

</details>


### [98] [Toward a unified framework for data-efficient evaluation of large language models](https://arxiv.org/abs/2510.04051)
*Lele Liao,Qile Zhang,Ruofan Wu,Guanhua Fang*

Main category: cs.AI

TL;DR: LEGO-IRT是一个用于高效评估大语言模型的新框架，通过结合项目反应理论和结构化知识，仅需3%的评估项目就能稳定估计模型能力，支持二进制和连续评分指标。


<details>
  <summary>Details</summary>
Motivation: 现有基于项目反应理论(IRT)的评估方法存在显著局限性：仅支持二进制正确性指标，无法处理生成任务中的连续分数；且仅在单一基准上操作，忽略了跨不同指标或基准的相关性等有价值的结构化知识。

Method: 提出LEGO-IRT框架，其创新设计原生支持二进制和连续评估指标，并引入因子化架构来显式建模和利用结构化知识，将模型能力估计分解为通用组件和结构特定组件。

Result: 在涉及70个LLM和5个基准的广泛实验中，LEGO-IRT仅使用总评估项目的3%就实现了稳定的能力估计。融入结构化知识可将估计误差降低高达10%，且该框架估计的潜在能力可能更符合人类偏好。

Conclusion: LEGO-IRT为数据高效的LLM评估提供了一个统一且灵活的框架，克服了现有IRT方法的局限性，在减少计算成本的同时提高了评估的准确性和实用性。

Abstract: Evaluating large language models (LLMs) on comprehensive benchmarks is a
cornerstone of their development, yet it's often computationally and
financially prohibitive. While Item Response Theory (IRT) offers a promising
path toward data-efficient evaluation by disentangling model capability from
item difficulty, existing IRT-based methods are hampered by significant
limitations. They are typically restricted to binary correctness metrics,
failing to natively handle the continuous scores used in generative tasks, and
they operate on single benchmarks, ignoring valuable structural knowledge like
correlations across different metrics or benchmarks. To overcome these
challenges, we introduce LEGO-IRT, a unified and flexible framework for
data-efficient LLM evaluation. LEGO-IRT's novel design natively supports both
binary and continuous evaluation metrics. Moreover, it introduces a factorized
architecture to explicitly model and leverage structural knowledge, decomposing
model ability estimates into a general component and structure-specific (e.g.,
per-metric or per-benchmark) components. Through extensive experiments
involving $70$ LLMs across $5$ benchmarks, we show that LEGO-IRT achieves
stable capability estimates using just $3\%$ of the total evaluation items. We
demonstrate that incorporating structural knowledge reduces estimation error by
up to $10\%$ and reveal that the latent abilities estimated by our framework
may align more closely with human preferences.

</details>


### [99] [Decoding Emotion in the Deep: A Systematic Study of How LLMs Represent, Retain, and Express Emotion](https://arxiv.org/abs/2510.04064)
*Jingxiang Zhang,Lujia Zhong*

Main category: cs.AI

TL;DR: 该论文研究了大型语言模型中的潜在情感表征，发现LLMs具有定义良好的内部情感几何结构，这种结构随模型规模增大而增强，情感信号在网络中层出现并达到峰值，且具有可塑性和持久性。


<details>
  <summary>Details</summary>
Motivation: 尽管研究证实LLMs能够模拟情感智能，但其内部情感机制仍未被充分探索。本文旨在探究现代LLMs中潜在的情感表征，包括情感如何、在何处以及持续多长时间被编码在神经网络架构中。

Method: 构建了一个包含约40万条话语的大规模Reddit语料库，通过分类、重写和合成生成的过程平衡了七种基本情感。使用轻量级“探针”从各种Qwen3和LLaMA模型的隐藏层读取信息而不改变其参数。

Result: 发现LLMs形成了定义良好的内部情感几何结构，这种结构随模型规模增大而增强，显著优于零样本提示。情感信号不是最终层现象，而是在网络早期出现并在中层达到峰值。内部状态具有可塑性（可通过简单系统提示影响）和持久性，初始情感基调在数百个后续标记中仍可检测到。

Conclusion: 研究为开发更透明和对齐的AI系统提供了关键见解，贡献了数据集、开源探针工具包以及LLMs内部情感景观的详细图谱。

Abstract: Large Language Models (LLMs) are increasingly expected to navigate the
nuances of human emotion. While research confirms that LLMs can simulate
emotional intelligence, their internal emotional mechanisms remain largely
unexplored. This paper investigates the latent emotional representations within
modern LLMs by asking: how, where, and for how long is emotion encoded in their
neural architecture? To address this, we introduce a novel, large-scale Reddit
corpus of approximately 400,000 utterances, balanced across seven basic
emotions through a multi-stage process of classification, rewriting, and
synthetic generation. Using this dataset, we employ lightweight "probes" to
read out information from the hidden layers of various Qwen3 and LLaMA models
without altering their parameters. Our findings reveal that LLMs develop a
surprisingly well-defined internal geometry of emotion, which sharpens with
model scale and significantly outperforms zero-shot prompting. We demonstrate
that this emotional signal is not a final-layer phenomenon but emerges early
and peaks mid-network. Furthermore, the internal states are both malleable
(they can be influenced by simple system prompts) and persistent, as the
initial emotional tone remains detectable for hundreds of subsequent tokens. We
contribute our dataset, an open-source probing toolkit, and a detailed map of
the emotional landscape within LLMs, offering crucial insights for developing
more transparent and aligned AI systems. The code and dataset are open-sourced.

</details>


### [100] [Moral Anchor System: A Predictive Framework for AI Value Alignment and Drift Prevention](https://arxiv.org/abs/2510.04073)
*Santhosh Kumar Ravindran*

Main category: cs.AI

TL;DR: 提出了道德锚系统(MAS)框架，通过实时贝叶斯推理、LSTM网络预测和人类中心治理层来检测、预测和缓解AI系统中的价值漂移问题。


<details>
  <summary>Details</summary>
Motivation: 随着AI成为超级助手，价值对齐变得至关重要。价值漂移风险可能导致AI行为偏离人类伦理和意图，造成效率低下或伦理违规。

Method: MAS结合实时贝叶斯推理监控价值状态，LSTM网络预测漂移趋势，人类中心治理层进行自适应干预，强调低延迟响应(<20ms)，并通过监督微调减少误报。

Result: 在模拟实验中，MAS能将价值漂移事件减少80%以上，保持高检测准确率(85%)和低误报率(0.08)。实验验证了系统的可扩展性和响应性。

Conclusion: MAS的原创性在于其预测性和自适应性，与静态对齐方法形成对比。贡献包括MAS架构、实证结果、跨领域适用性见解和开源代码。

Abstract: The rise of artificial intelligence (AI) as super-capable assistants has
transformed productivity and decision-making across domains. Yet, this
integration raises critical concerns about value alignment - ensuring AI
behaviors remain consistent with human ethics and intentions. A key risk is
value drift, where AI systems deviate from aligned values due to evolving
contexts, learning dynamics, or unintended optimizations, potentially leading
to inefficiencies or ethical breaches. We propose the Moral Anchor System
(MAS), a novel framework to detect, predict, and mitigate value drift in AI
agents. MAS combines real-time Bayesian inference for monitoring value states,
LSTM networks for forecasting drift, and a human-centric governance layer for
adaptive interventions. It emphasizes low-latency responses (<20 ms) to prevent
breaches, while reducing false positives and alert fatigue via supervised
fine-tuning with human feedback. Our hypothesis: integrating probabilistic
drift detection, predictive analytics, and adaptive governance can reduce value
drift incidents by 80 percent or more in simulations, maintaining high
detection accuracy (85 percent) and low false positive rates (0.08
post-adaptation). Rigorous experiments with goal-misaligned agents validate
MAS's scalability and responsiveness. MAS's originality lies in its predictive
and adaptive nature, contrasting static alignment methods. Contributions
include: (1) MAS architecture for AI integration; (2) empirical results
prioritizing speed and usability; (3) cross-domain applicability insights; and
(4) open-source code for replication.

</details>


### [101] [SPOGW: a Score-based Preference Optimization method via Group-Wise comparison for workflows](https://arxiv.org/abs/2510.04089)
*Yitong Cui,Liu Liu,Baosheng Yu,Jiayan Qiu,Xikai Zhang,Likang Xiao,Yixing Liu,Quan Chen*

Main category: cs.AI

TL;DR: SPOGW是一种基于分数偏好的方法，通过组间比较直接在连续空间中优化智能体工作流，解决了现有方法表示能力有限、适应性不足等问题。


<details>
  <summary>Details</summary>
Motivation: 现有智能体工作流设计需要大量人工干预，限制了可扩展性和泛化能力。现有自动化方法受限于离散优化技术，存在表示能力有限、适应性不足、可扩展性弱等问题。

Method: 提出SPOGW方法，采用基于分数偏好的组间比较，结合迭代离线GRPO（ioGRPO）和优势掩码KL散度（mKL），在连续空间中进行更高效稳定的优化。

Result: 在数学推理、编程和问答五个基准数据集上，SPOGW达到或超越了当前最先进方法的性能。

Conclusion: SPOGW为智能体工作流的自动生成和优化提供了一种可行且前瞻的方法论。

Abstract: Large language models (LLMs) have exhibited significant capabilities in
addressing challenging problems throughout various fields, often through the
use of agentic workflows that adhere to structured instructions and multi-step
procedures. However, designing such workflows demands substantial manual
effort, posing challenges to scalability and generalizability. Recent studies
have aimed to minimize the human intervention needed for their construction,
leading to advances in automated techniques for optimizing agentic workflows.
However, current approaches are often constrained by their limited
representational capacity, insufficient adaptability, weak scalability, and
pairwise comparison paradigm -- issues that stem primarily from a dependence on
discrete optimization techniques. To overcome these limitations, we introduce a
new score-based preference approach, refereed as SPOGW, which operates directly
on cardinal reward signals through group-wise comparison and enables more
efficient and stable optimization in a continuous space. SPOGW incorporates
Iterative offline GRPO (ioGRPO) with advantage-masked KL divergence (mKL),
which regulates training update by placing greater emphasis on the advantageous
regions of the policy response. In five benchmark datasets covering
mathematical reasoning, coding, and question answering, SPOGW matches or
exceeds the performance of current state-of-the-art approaches, presenting a
viable and forward-looking methodology for automated generation and
optimization of agentic workflows.

</details>


### [102] [Harnessing LLM for Noise-Robust Cognitive Diagnosis in Web-Based Intelligent Education Systems](https://arxiv.org/abs/2510.04093)
*Guixian Zhang,Guan Yuan,Ziqi Xu,Yanmei Zhang,Zhenyun Deng,Debo Cheng*

Main category: cs.AI

TL;DR: DLLM是一个基于扩散模型的LLM框架，用于网络教育系统中的噪声鲁棒认知诊断，通过构建子图、关系增强对齐和两阶段去噪扩散模块来处理数据不平衡和噪声问题。


<details>
  <summary>Details</summary>
Motivation: 解决网络教育系统中异构噪声交互数据导致的认知诊断困难，特别是LLM在处理结构化数据和噪声方面的局限性，以及数据不平衡问题。

Method: 首先基于答题正确性构建独立子图，应用关系增强对齐缓解数据不平衡；然后融合子图表示并与LLM语义增强表示对齐；采用两阶段去噪扩散模块（无条件去噪和基于图引导的条件去噪）消除噪声并辅助结构表示对齐。

Result: 在三个公开网络教育平台数据集上的实验表明，DLLM在不同噪声水平下均取得最优预测性能，实现了噪声鲁棒性并有效利用了LLM的语义知识。

Conclusion: DLLM框架成功解决了网络教育系统中认知诊断的噪声鲁棒性问题，通过扩散模型和LLM的有效结合，在保持语义知识利用的同时提升了诊断准确性。

Abstract: Cognitive diagnostics in the Web-based Intelligent Education System (WIES)
aims to assess students' mastery of knowledge concepts from heterogeneous,
noisy interactions. Recent work has tried to utilize Large Language Models
(LLMs) for cognitive diagnosis, yet LLMs struggle with structured data and are
prone to noise-induced misjudgments. Specially, WIES's open environment
continuously attracts new students and produces vast amounts of response logs,
exacerbating the data imbalance and noise issues inherent in traditional
educational systems. To address these challenges, we propose DLLM, a
Diffusion-based LLM framework for noise-robust cognitive diagnosis. DLLM first
constructs independent subgraphs based on response correctness, then applies
relation augmentation alignment module to mitigate data imbalance. The two
subgraph representations are then fused and aligned with LLM-derived,
semantically augmented representations. Importantly, before each alignment
step, DLLM employs a two-stage denoising diffusion module to eliminate
intrinsic noise while assisting structural representation alignment.
Specifically, unconditional denoising diffusion first removes erroneous
information, followed by conditional denoising diffusion based on graph-guided
to eliminate misleading information. Finally, the noise-robust representation
that integrates semantic knowledge and structural information is fed into
existing cognitive diagnosis models for prediction. Experimental results on
three publicly available web-based educational platform datasets demonstrate
that our DLLM achieves optimal predictive performance across varying noise
levels, which demonstrates that DLLM achieves noise robustness while
effectively leveraging semantic knowledge from LLM.

</details>


### [103] [WebRenderBench: Enhancing Web Interface Generation through Layout-Style Consistency and Reinforcement Learning](https://arxiv.org/abs/2510.04097)
*Peichao Lai,Jinhui Zhuang,Kexuan Zhang,Ningchang Xiong,Shengjie Wang,Yanwei Xu,Chong Chen,Yilei Wang,Bin Cui*

Main category: cs.AI

TL;DR: 提出了WebRenderBench基准测试和ALISA方法，用于改进UI图像到网页代码的转换评估和训练。


<details>
  <summary>Details</summary>
Motivation: 现有的UI转代码基准测试在数据多样性和评估可靠性方面存在不足，需要更真实、多样化的数据集和更可靠的评估方法。

Method: 构建了包含22.5k个真实网页的大规模基准测试WebRenderBench，提出基于最终渲染页面的布局和样式一致性评估指标，并开发了ALISA智能体将该指标作为强化学习的奖励信号。

Result: ALISA方法显著提升了生成性能，在多个指标上达到了最先进的结果。

Conclusion: WebRenderBench提供了更真实多样的评估环境，ALISA通过集成新的评估指标有效提升了UI转代码的质量和性能。

Abstract: Automating the conversion of UI images into web code is a critical task for
front-end development and rapid prototyping. Advances in multimodal large
language models (MLLMs) have made WebUI-to-Code increasingly feasible, yet
existing benchmarks remain limited in data diversity and evaluation
reliability. To address these issues, we present WebRenderBench, a large-scale
benchmark of 22.5k webpages collected from real-world portal sites, offering
greater diversity, complexity, and realism than prior benchmarks. We further
propose a novel evaluation metric that measures layout and style consistency
from the final rendered pages. Unlike vision-based methods that rely on costly
LLM reasoning or structure-based comparisons vulnerable to noise and asymmetry,
our approach enables more efficient, objective, and reliable UI quality
assessment. Finally, we introduce the Automated Layout and Style Inspection
Agent (ALISA), which integrates this metric into reinforcement learning as a
reward signal to enhance training on crawled asymmetric webpages. Experiments
show that ALISA significantly boosts generation performance, achieving
state-of-the-art results across multiple metrics.

</details>


### [104] [Searching Meta Reasoning Skeleton to Guide LLM Reasoning](https://arxiv.org/abs/2510.04116)
*Ziying Zhang,Yaqing Wang,Quanming Yao*

Main category: cs.AI

TL;DR: AutoMR框架通过自动搜索查询感知的元推理骨架来提升大语言模型的推理性能，使用有向无环图表示推理骨架，并采用动态采样算法实现高效搜索。


<details>
  <summary>Details</summary>
Motivation: 现有研究使用手动设计的元推理骨架结构，无法适应查询特定需求，也难以捕捉推理步骤间复杂的逻辑依赖关系。

Method: 提出AutoMR框架：1）用有向无环图统一表示元推理骨架；2）构建搜索空间并定义搜索问题；3）设计动态骨架采样算法，在推理时根据上下文扩展骨架。

Result: 在多个基准数据集上的实验表明，AutoMR相比先前工作取得了更好的推理性能。

Conclusion: AutoMR通过自动搜索查询感知的元推理骨架，能够有效提升大语言模型的推理能力，解决了手动设计骨架的局限性。

Abstract: Meta reasoning behaviors work as a skeleton to guide large language model
(LLM) reasoning, thus help to improve reasoning performance. However, prior
researches implement meta reasoning skeleton with manually designed structure,
limiting ability to adapt to query-specific requirement and capture intricate
logical dependency among reasoning steps. To deal with the challenges, we
represent meta reasoning skeleton with directed acyclic graph (DAG) to unify
skeletons proposed in prior works and model intricate logical dependency. Then
we propose AutoMR, a framework that searches for query-aware meta reasoning
skeleton automatically inspired by automated machine learning (AutoML).
Specifically, we construct search space based on DAG representation of skeleton
and then formulate the search problem. We design a dynamic skeleton sampling
algorithm by expanding meta reasoning skeleton along with reasoning context at
inference time. This algorithm can derive any meta reasoning skeleton in search
space efficiently and adapt skeleton to evolving base reasoning context, thus
enable efficient query-aware skeleton search. We conduct experiments on
extensive benchmark datasets. Experimental results show that AutoMR achieves
better reasoning performance than previous works broadly.

</details>


### [105] [Internal states before wait modulate reasoning patterns](https://arxiv.org/abs/2510.04128)
*Dmitrii Troitskii,Koyena Pal,Chris Wendler,Callum Stuart McDougall,Neel Nanda*

Main category: cs.AI

TL;DR: 该研究发现模型在推理过程中出现的等待标记（wait tokens）包含重要的推理行为信息，通过交叉编码器和潜在归因技术识别出影响等待标记概率的关键特征，这些特征与不同的推理模式相关。


<details>
  <summary>Details</summary>
Motivation: 理解为什么模型在推理过程中会产生等待标记这一复杂行为，以及这些标记如何影响模型的推理效果，从而揭示推理模型高效工作的机制。

Method: 在DeepSeek-R1-Distill-Llama-8B及其基础版本的多层上训练交叉编码器，引入潜在归因技术来定位影响等待标记概率的关键特征集。

Result: 识别出一组小规模特征，这些特征能够促进或抑制等待标记的概率，并通过最大激活示例和因果干预实验验证了这些特征确实与推理过程相关，产生不同的推理模式。

Conclusion: 模型在等待标记之前的潜在状态包含调节后续推理过程的相关信息，这些信息与重新开始、回忆先验知识、表达不确定性和双重检查等推理模式相关。

Abstract: Prior work has shown that a significant driver of performance in reasoning
models is their ability to reason and self-correct. A distinctive marker in
these reasoning traces is the token wait, which often signals reasoning
behavior such as backtracking. Despite being such a complex behavior, little is
understood of exactly why models do or do not decide to reason in this
particular manner, which limits our understanding of what makes a reasoning
model so effective. In this work, we address the question whether model's
latents preceding wait tokens contain relevant information for modulating the
subsequent reasoning process. We train crosscoders at multiple layers of
DeepSeek-R1-Distill-Llama-8B and its base version, and introduce a latent
attribution technique in the crosscoder setting. We locate a small set of
features relevant for promoting/suppressing wait tokens' probabilities.
Finally, through a targeted series of experiments analyzing max activating
examples and causal interventions, we show that many of our identified features
indeed are relevant for the reasoning process and give rise to different types
of reasoning patterns such as restarting from the beginning, recalling prior
knowledge, expressing uncertainty, and double-checking.

</details>


### [106] [Selective Expert Guidance for Effective and Diverse Exploration in Reinforcement Learning of LLMs](https://arxiv.org/abs/2510.04140)
*Zishang Jiang,Jinyi Han,Tingyun Li,Xinyi Wang,Sihang Jiang,Jiaqing Liang,Zhaoqian Dai,Shuguang Ma,Fei Yu,Yanghua Xiao*

Main category: cs.AI

TL;DR: 提出了MENTOR框架，通过只在关键决策点提供专家指导，在强化学习与可验证奖励中实现有效且多样化的探索。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法依赖模仿专家轨迹，这虽然提高了有效性但忽视了多样性，而高质量的探索需要两者兼备。

Method: MENTOR框架采用混合策略专家导航，仅在关键决策点提供专家指导，进行token级别的推理优化。

Result: 实验表明MENTOR能够捕捉专家策略的本质而非表面模仿，实现高质量探索并获得优越的整体性能。

Conclusion: 在关键决策点提供专家指导比完整轨迹模仿更有效，MENTOR框架在RLVR中实现了更好的探索质量和性能。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has become a widely
adopted technique for enhancing the reasoning ability of Large Language Models
(LLMs). However, the effectiveness of RLVR strongly depends on the capability
of base models. This issue arises because it requires the model to have
sufficient capability to perform high-quality exploration, which involves both
effectiveness and diversity. Unfortunately, existing methods address this issue
by imitating expert trajectories, which improve effectiveness but neglect
diversity. To address this, we argue that the expert only needs to provide
guidance only at critical decision points rather than the entire reasoning
path. Based on this insight, we propose MENTOR: Mixed-policy Expert Navigation
for Token-level Optimization of Reasoning, a framework that provides expert
guidance only at critical decision points to perform effective and diverse
exploration in RLVR. Extensive experiments show that MENTOR enables models
capture the essence of expert strategies rather than surface imitation, thereby
performing high-quality exploration and achieving superior overall performance.
Our code is available online.

</details>


### [107] [The Artificial Intelligence Cognitive Examination: A Survey on the Evolution of Multimodal Evaluation from Recognition to Reasoning](https://arxiv.org/abs/2510.04141)
*Mayank Ravishankara,Varindra V. Persad Maharaj*

Main category: cs.AI

TL;DR: 本文回顾了多模态AI评估的演变历程，将其描述为从简单识别任务到复杂推理基准的范式转变，旨在设计更好的评估方法来推动真正智能系统的发展。


<details>
  <summary>Details</summary>
Motivation: 传统基准测试已趋于饱和，高分往往掩盖了模型的基本弱点，需要更复杂的评估方法来诊断系统性缺陷。

Method: 通过分析评估范式的演变：从ImageNet时代的"知识测试"，到GQA和VCR等"应用逻辑和理解"测试，再到针对MLLMs的"专家级集成"基准测试。

Result: 展示了评估方法如何从测试"模型看到了什么"发展到探究"模型如何理解"，并开始评估推理过程本身。

Conclusion: AI评估不仅是数据集的历史，更是一个持续对抗的过程，通过设计更好的测试来重新定义创建真正智能系统的目标。

Abstract: This survey paper chronicles the evolution of evaluation in multimodal
artificial intelligence (AI), framing it as a progression of increasingly
sophisticated "cognitive examinations." We argue that the field is undergoing a
paradigm shift, moving from simple recognition tasks that test "what" a model
sees, to complex reasoning benchmarks that probe "why" and "how" it
understands. This evolution is driven by the saturation of older benchmarks,
where high performance often masks fundamental weaknesses. We chart the journey
from the foundational "knowledge tests" of the ImageNet era to the "applied
logic and comprehension" exams such as GQA and Visual Commonsense Reasoning
(VCR), which were designed specifically to diagnose systemic flaws such as
shortcut learning and failures in compositional generalization. We then survey
the current frontier of "expert-level integration" benchmarks (e.g., MMBench,
SEED-Bench, MMMU) designed for today's powerful multimodal large language
models (MLLMs), which increasingly evaluate the reasoning process itself.
Finally, we explore the uncharted territories of evaluating abstract, creative,
and social intelligence. We conclude that the narrative of AI evaluation is not
merely a history of datasets, but a continuous, adversarial process of
designing better examinations that, in turn, redefine our goals for creating
truly intelligent systems.

</details>


### [108] [Open Agent Specification (Agent Spec) Technical Report](https://arxiv.org/abs/2510.04173)
*Yassine Benajiba,Cesare Bernardis,Vladislav Blinov,Paul Cayet,Hassan Chafi,Abderrahim Fathan,Louis Faucon,Damien Hilloulin,Sungpack Hong,Ingo Kossyk,Rhicheek Patra,Sujith Ravi,Jonas Schweizer,Jyotika Singh,Shailender Singh,Xuelin Situ,Weiyi Sun,Jerry Xu,Ying Xu*

Main category: cs.AI

TL;DR: Open Agent Specification (Agent Spec) 是一种声明式语言，用于定义AI代理及其工作流，实现跨AI框架的兼容性、可移植性和互操作性。


<details>
  <summary>Details</summary>
Motivation: 解决AI代理开发碎片化问题，提供统一的规范标准，使AI代理能够一次设计、跨框架部署，提高互操作性和可重用性，减少重复开发工作。

Method: 通过声明式语言定义AI代理和工作流，独立于执行环境，支持开发工具和可移植性，作为不同框架间的交换格式。

Result: 为四类关键群体带来益处：开发者获得可重用组件和设计模式；框架开发者获得交换格式支持；研究者实现可复现结果；企业加速原型到部署过程。

Conclusion: Agent Spec 提供了AI代理开发的技术基础，促进跨框架兼容性、工具支持和未来发展，推动AI代理生态系统的标准化和互操作性。

Abstract: Open Agent Specification (Agent Spec) is a declarative language that allows
AI agents and their workflows to be defined in a way that is compatible across
different AI frameworks, promoting portability and interoperability within AI
Agent frameworks.
  Agent Spec aims to resolve the challenges of fragmented agent development by
providing a common unified specification that allows AI agents to be designed
once and deployed across various frameworks, improving interoperability and
reusability, and reducing redundant development efforts. Additionally, Agent
Spec facilitates development tools and portability, allowing AI agents to be
defined independently of their execution environment and enabling teams to
exchange solutions without implementation-specific limitations.
  Agent Spec benefits four key groups: (i) Agent developers, who gain access to
a superset of reusable components and design patterns, enabling them to
leverage a broader range of functionalities; (ii) Agent framework and tool
developers, who can use Agent Spec as an interchange format and therefore
benefit from the support of other frameworks as well as other tools; (iii)
Researchers, who can achieve reproducible results and comparability,
facilitating more reliable and consistent outcomes; (iv) Enterprises, which
benefit from faster prototype-to-deployment, increased productivity, as well as
greater scalability and maintainability for their AI agent solutions. This
technical report provides an overview of the technical foundations of Agent
Spec, including motivation, benefits, and future developments.

</details>


### [109] [Constructing coherent spatial memory in LLM agents through graph rectification](https://arxiv.org/abs/2510.04195)
*Puzhen Zhang,Xuyang Chen,Yu Feng,Yuhan Jiang,Liqiu Meng*

Main category: cs.AI

TL;DR: 提出了一个LLM驱动的增量地图构建和修复框架，通过版本控制和边影响评分来检测、定位和修正导航图中的结构不一致性，显著提高了地图正确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着环境规模扩大，基于上下文依赖的查询方法变得不可行，需要能够从逐步观察中构建完整拓扑图的增量地图构建方法。

Method: 使用版本控制记录图编辑的完整历史及其来源观察，引入边影响评分基于结构可达性、路径使用和冲突传播来优先处理最小成本修复。

Result: 方法显著提高了地图正确性和鲁棒性，特别是在存在纠缠或链式不一致性的场景中。

Conclusion: 研究强调了内省、历史感知的修复机制对于维护LLM智能体中连贯空间记忆的重要性。

Abstract: Given a map description through global traversal navigation instructions
(e.g., visiting each room sequentially with action signals such as north, west,
etc.), an LLM can often infer the implicit spatial layout of the environment
and answer user queries by providing a shortest path from a start to a
destination (for instance, navigating from the lobby to a meeting room via the
hall and elevator). However, such context-dependent querying becomes incapable
as the environment grows much longer, motivating the need for incremental map
construction that builds a complete topological graph from stepwise
observations. We propose a framework for LLM-driven construction and map
repair, designed to detect, localize, and correct structural inconsistencies in
incrementally constructed navigation graphs. Central to our method is the
Version Control, which records the full history of graph edits and their source
observations, enabling fine-grained rollback, conflict tracing, and repair
evaluation. We further introduce an Edge Impact Score to prioritize
minimal-cost repairs based on structural reachability, path usage, and conflict
propagation. To properly evaluate our approach, we create a refined version of
the MANGO benchmark dataset by systematically removing non-topological actions
and inherent structural conflicts, providing a cleaner testbed for LLM-driven
construction and map repair. Our approach significantly improves map
correctness and robustness, especially in scenarios with entangled or chained
inconsistencies. Our results highlight the importance of introspective,
history-aware repair mechanisms for maintaining coherent spatial memory in LLM
agents.

</details>


### [110] [COSMO-RL: Towards Trustworthy LMRMs via Joint Safety and Stability](https://arxiv.org/abs/2510.04196)
*Yizhuo Ding,Mingkang Chen,Qiuhua Liu,Fenghua Weng,Wanying Qu,Yue Yang,Yugang Jiang,Zuxuan Wu,Yanwei Fu,Wenqi Shao*

Main category: cs.AI

TL;DR: COSMO-RL是一个混合强化学习框架，用于在多模态、多任务和多目标信号下训练面向推理的大型多模态模型，旨在让安全性和能力共同增长而非相互竞争。


<details>
  <summary>Details</summary>
Motivation: 大型多模态推理模型在实际应用中需要兼具实用性和安全性，但多模态环境下的安全性特别具有挑战性：图像和文本可以结合绕过防护机制，单一目标训练可能导致策略漂移，在良性输入上过度拒绝或在风险输入上不安全地遵从。

Method: 提出了COSMO-RL混合强化学习框架，在多模态、多任务和多目标信号下训练推理导向的大型多模态模型，并发布了COSMO-R1模型。

Result: COSMO-R1在实验中提高了安全性，同时保持并经常改善多模态推理和指令跟随能力，显示出对多模态越狱攻击更强的鲁棒性，并减少了不必要的拒绝。该框架在不同骨干网络上也能实现一致的性能提升。

Conclusion: 消融实验支持了设计选择，表明在大型多模态模型中共同推进安全性和通用能力有一条简单的路径。

Abstract: Large Multimodal Reasoning Models (LMRMs) are moving into real applications,
where they must be both useful and safe. Safety is especially challenging in
multimodal settings: images and text can be combined to bypass guardrails, and
single objective training can cause policy drift that yields over-refusal on
benign inputs or unsafe compliance on risky ones. We present COSMO-RL, a mixed
reinforcement learning framework that trains reasoning oriented LMRMs under
multimodal, multitask, and multiobjective signals, and we release the resulting
model, COSMO-R1. Our approach aims to let safety and capability grow together
in one stable pipeline rather than competing during alignment. In experiments,
COSMO-R1 improves safety while maintaining-and often improving multimodal
reasoning and instruction following, shows stronger robustness to multimodal
jailbreaks, and reduces unnecessary refusals. The framework also transfers
across backbones with consistent gains. Ablations support the design choices,
indicating a simple path to advancing safety and general capability together in
LMRMs.

</details>


### [111] [AgentRL: Scaling Agentic Reinforcement Learning with a Multi-Turn, Multi-Task Framework](https://arxiv.org/abs/2510.04206)
*Hanchen Zhang,Xiao Liu,Bowen Lv,Xueqiao Sun,Bohao Jing,Iat Long Iong,Zhenyu Hou,Zehan Qi,Hanyu Lai,Yifan Xu,Rui Lu,Hongning Wang,Jie Tang,Yuxiao Dong*

Main category: cs.AI

TL;DR: 提出了AgentRL框架，用于可扩展的多轮多任务智能体强化学习训练，通过异步生成-训练流水线和算法改进，在多个任务上显著优于现有LLM智能体。


<details>
  <summary>Details</summary>
Motivation: 当前在大型语言模型上应用强化学习训练多轮多任务智能体面临基础设施可扩展性和训练算法稳定性挑战。

Method: 采用完全异步的生成-训练流水线、统一函数调用API接口、容器化环境开发、跨策略采样和任务优势归一化等算法。

Result: 在五个智能体任务上的实验表明，AgentRL显著优于GPT-5、Clause-Sonnet-4、DeepSeek-R1等模型，多任务训练结果与各任务专用模型的最佳结果相当。

Conclusion: AgentRL为多轮多任务智能体强化学习提供了有效的框架和算法解决方案，已在AutoGLM项目中应用。

Abstract: Recent advances in large language models (LLMs) have sparked growing interest
in building generalist agents that can learn through online interactions.
However, applying reinforcement learning (RL) to train LLM agents in
multi-turn, multi-task settings remains challenging due to lack of scalable
infrastructure and stable training algorithms. In this work, we present the
AgentRL framework for scalable multi-turn, multi-task agentic RL training. On
the infrastructure side, AgentRL features a fully-asynchronous
generation-training pipeline for efficient multi-turn RL. To support
heterogeneous environment development in multi-task RL, we design a unified
function-call based API interface, containerized environment development, and a
centralized controller. On the algorithm side, we propose cross-policy sampling
to encourage model exploration in multi-turn settings and task advantage
normalization to stabilize multi-task training. Experiments show that AgentRL,
trained on open LLMs across five agentic tasks, significantly outperforms
GPT-5, Clause-Sonnet-4, DeepSeek-R1, and other open-source LLM agents.
Multi-task training with AgentRL matches the best results among all
task-specific models. AgentRL is open-sourced at
https://github.com/THUDM/AgentRL. The algorithm and framework are adopted in
building \textsc{\href{https://autoglm.zhipuai.cn}{AutoGLM}}.

</details>


### [112] [Don't Pass$\mathtt{@}k$: A Bayesian Framework for Large Language Model Evaluation](https://arxiv.org/abs/2510.04265)
*Mohsen Hariri,Amirhossein Samandar,Michael Hinczewski,Vipin Chaudhary*

Main category: cs.AI

TL;DR: 提出了一个贝叶斯评估框架来替代Pass@k，通过后验概率估计和可信区间提供更稳定的模型排名和透明的决策规则


<details>
  <summary>Details</summary>
Motivation: Pass@k在有限试验次数和计算受限时会产生不稳定、误导性的排名结果，需要更可靠的评估方法

Method: 使用狄利克雷先验对评估结果进行建模，获得后验均值和不确定性的闭式表达式，支持加权评分标准和先验证据的使用

Result: 在模拟和真实数据集上，贝叶斯方法比Pass@k及其变体收敛更快、排名更稳定，能在更少样本下实现可靠比较

Conclusion: 推荐用基于后验概率的计算高效协议替代Pass@k，统一二元和非二元评估，并明确表示不确定性

Abstract: Pass$@k$ is widely used to report performance for LLM reasoning, but it often
yields unstable, misleading rankings, especially when the number of trials
(samples) is limited and compute is constrained. We present a principled
Bayesian evaluation framework that replaces Pass$@k$ and average accuracy over
$N$ trials (avg$@N$) with posterior estimates of a model's underlying success
probability and credible intervals, yielding stable rankings and a transparent
decision rule for differences. Evaluation outcomes are modeled as categorical
(not just 0/1) with a Dirichlet prior, giving closed-form expressions for the
posterior mean and uncertainty of any weighted rubric and enabling the use of
prior evidence when appropriate. Theoretically, under a uniform prior, the
Bayesian posterior mean is order-equivalent to average accuracy (Pass$@1$),
explaining its empirical robustness while adding principled uncertainty.
Empirically, in simulations with known ground-truth success rates and on
AIME'24/'25, HMMT'25, and BrUMO'25, the Bayesian/avg procedure achieves faster
convergence and greater rank stability than Pass$@k$ and recent variants,
enabling reliable comparisons at far smaller sample counts. The framework
clarifies when observed gaps are statistically meaningful (non-overlapping
credible intervals) versus noise, and it naturally extends to graded,
rubric-based evaluations. Together, these results recommend replacing Pass$@k$
for LLM evaluation and ranking with a posterior-based, compute-efficient
protocol that unifies binary and non-binary evaluation while making uncertainty
explicit. Code is available at https://mohsenhariri.github.io/bayes-kit

</details>


### [113] [Closing the Loop: Coordinating Inventory and Recommendation via Deep Reinforcement Learning on Multiple Timescales](https://arxiv.org/abs/2510.04272)
*Jinyang Jiang,Jinhui Han,Yijie Peng,Ying Zhang*

Main category: cs.AI

TL;DR: 提出一个统一的多智能体强化学习框架，用于协调库存补货和个性化产品推荐功能，通过多时间尺度学习提高企业盈利能力。


<details>
  <summary>Details</summary>
Motivation: 解决组织复杂性和规模增长带来的跨职能协调挑战，利用人工智能特别是强化学习来优化企业整体盈利能力。

Method: 开发集成理论模型和多时间尺度多智能体RL架构，根据部门功能分解策略组件，基于任务复杂性和响应性分配不同学习速度。

Result: 模拟实验显示该方法相比孤立决策框架显著提高盈利能力，训练出的RL智能体行为与理论模型的管理洞察高度一致。

Conclusion: 该工作提供了一个可扩展、可解释的基于RL的解决方案，能够在复杂商业环境中实现有效的跨职能协调。

Abstract: Effective cross-functional coordination is essential for enhancing firm-wide
profitability, particularly in the face of growing organizational complexity
and scale. Recent advances in artificial intelligence, especially in
reinforcement learning (RL), offer promising avenues to address this
fundamental challenge. This paper proposes a unified multi-agent RL framework
tailored for joint optimization across distinct functional modules, exemplified
via coordinating inventory replenishment and personalized product
recommendation. We first develop an integrated theoretical model to capture the
intricate interplay between these functions and derive analytical benchmarks
that characterize optimal coordination. The analysis reveals synchronized
adjustment patterns across products and over time, highlighting the importance
of coordinated decision-making. Leveraging these insights, we design a novel
multi-timescale multi-agent RL architecture that decomposes policy components
according to departmental functions and assigns distinct learning speeds based
on task complexity and responsiveness. Our model-free multi-agent design
improves scalability and deployment flexibility, while multi-timescale updates
enhance convergence stability and adaptability across heterogeneous decisions.
We further establish the asymptotic convergence of the proposed algorithm.
Extensive simulation experiments demonstrate that the proposed approach
significantly improves profitability relative to siloed decision-making
frameworks, while the behaviors of the trained RL agents align closely with the
managerial insights from our theoretical model. Taken together, this work
provides a scalable, interpretable RL-based solution to enable effective
cross-functional coordination in complex business settings.

</details>


### [114] [GROK: From Quantitative Biomarkers to Qualitative Diagnosis via a Grounded MLLM with Knowledge-Guided Instruction](https://arxiv.org/abs/2510.04281)
*Zhuangzhi Gao,Hongyi Qin,He Zhao,Qinkai Yu,Feixiang Zhou,Eduard Shantsila,Uazman Alam,Alena Shantsila,Wahbi El-Bouri,Gregory Y. H. Lip,Yalin Zheng*

Main category: cs.AI

TL;DR: GROK是一个基于多模态大语言模型的眼科诊断系统，通过联合处理彩色眼底摄影、光学相干断层扫描和文本，提供临床级别的眼部和全身疾病诊断。


<details>
  <summary>Details</summary>
Motivation: 现有的医学多模态大模型如LLaVA-Med未能充分利用彩色眼底摄影和光学相干断层扫描之间的协同作用，且对定量生物标志物的解释能力有限。

Method: GROK包含三个核心模块：知识引导指令生成、CLIP风格OCT生物标志物对齐和监督指令微调，建立了从定量到定性的诊断思维链。

Result: 实验表明，仅使用LoRA微调7B参数的Qwen2骨干网络，GROK在报告质量和细粒度临床指标上均优于可比较的7B和32B基线模型，甚至超过OpenAI o3。

Conclusion: GROK通过建立定量到定性的诊断思维链，成功实现了临床级别的眼科诊断，代码和数据已在GROK仓库中公开。

Abstract: Multimodal large language models (MLLMs) hold promise for integrating diverse
data modalities, but current medical adaptations such as LLaVA-Med often fail
to fully exploit the synergy between color fundus photography (CFP) and optical
coherence tomography (OCT), and offer limited interpretability of quantitative
biomarkers. We introduce GROK, a grounded multimodal large language model that
jointly processes CFP, OCT, and text to deliver clinician-grade diagnoses of
ocular and systemic disease. GROK comprises three core modules:
Knowledge-Guided Instruction Generation, CLIP-Style OCT-Biomarker Alignment,
and Supervised Instruction Fine-Tuning, which together establish a
quantitative-to-qualitative diagnostic chain of thought, mirroring real
clinical reasoning when producing detailed lesion annotations. To evaluate our
approach, we introduce the Grounded Ophthalmic Understanding benchmark, which
covers six disease categories and three tasks: macro-level diagnostic
classification, report generation quality, and fine-grained clinical assessment
of the generated chain of thought. Experiments show that, with only LoRA
(Low-Rank Adaptation) fine-tuning of a 7B-parameter Qwen2 backbone, GROK
outperforms comparable 7B and 32B baselines on both report quality and
fine-grained clinical metrics, and even exceeds OpenAI o3. Code and data are
publicly available in the GROK repository.

</details>


### [115] [Doctor-R1: Mastering Clinical Inquiry with Experiential Agentic Reinforcement Learning](https://arxiv.org/abs/2510.04284)
*Yunghwei Lai,Kaiming Liu,Ziyue Wang,Weizhi Ma,Yang Liu*

Main category: cs.AI

TL;DR: 提出Doctor-R1 AI医生代理，通过多轮战略询问和高质量问题来同时掌握医疗决策准确性和医患沟通技能，超越现有LLMs在临床对话质量上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在医疗决策基准上表现优异，但缺乏进行战略性和同理心咨询的能力，而这在真实临床场景中至关重要。

Method: 采用多智能体交互环境、双层奖励架构（分别优化临床决策和沟通询问技能）以及经验存储库来基于高质量轨迹进行策略学习。

Result: 在OpenAI的HealthBench和MAQuE基准上，Doctor-R1在沟通质量、用户体验和任务准确性等多方面指标上显著超越最先进的开源专用LLMs，并在人类评估中显示出对生成人类偏好临床对话的强烈偏好。

Conclusion: Doctor-R1框架有效解决了AI医生在真实临床场景中同时具备准确医疗决策能力和战略同理心咨询技能的需求，展示了参数效率高且性能优越的特点。

Abstract: The professionalism of a human doctor in outpatient service depends on two
core abilities: the ability to make accurate medical decisions and the medical
consultation skill to conduct strategic, empathetic patient inquiry. Existing
Large Language Models (LLMs) have achieved remarkable accuracy on medical
decision-making benchmarks. However, they often lack the ability to conduct the
strategic and empathetic consultation, which is essential for real-world
clinical scenarios. To address this gap, we propose Doctor-R1, an AI doctor
agent trained to master both of the capabilities by ask high-yield questions
and conduct strategic multi-turn inquiry to guide decision-making. Our
framework introduces three key components: a multi-agent interactive
environment, a two-tiered reward architecture that separately optimizes
clinical decision-making and communicative inquiry skills, and an experience
repository to ground policy learning in high-quality prior trajectories. We
evaluate Doctor-R1 on OpenAI's HealthBench and MAQuE, assessed across
multi-facet metrics, such as communication quality, user experience, and task
accuracy. Remarkably, Doctor-R1 surpasses state-of-the-art open-source
specialized LLMs by a substantial margin with higher parameter efficiency and
outperforms powerful proprietary models. Furthermore, the human evaluations
show a strong preference for Doctor-R1 to generate human-preferred clinical
dialogue, demonstrating the effectiveness of the framework.

</details>


### [116] [On the Importance of Task Complexity in Evaluating LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2510.04311)
*Bohan Tang,Huidong Liang,Keyue Jiang,Xiaowen Dong*

Main category: cs.AI

TL;DR: 提出了一个理论框架来评估LLM多智能体系统在任务解决中的有效性，通过任务深度（推理长度）和宽度（能力多样性）两个维度来表征任务复杂性。


<details>
  <summary>Details</summary>
Motivation: 虽然研究表明LLM多智能体系统在某些任务上优于单智能体系统，但缺乏系统性的实验设计限制了这些结论的强度和普适性。需要从任务复杂性的角度来理解LLM-MAS的有效性。

Method: 提出了一个理论框架，将任务特征化为深度（推理长度）和宽度（能力多样性）两个维度。理论分析了一类代表性的LLM-MAS（多智能体辩论系统），并在不同深度和宽度的判别性和生成性任务上进行了实证评估。

Result: 理论和实证结果表明，LLM-MAS相对于LLM-SAS的优势随着任务深度和宽度的增加而增加，且深度的影响更为显著。

Conclusion: 阐明了LLM-MAS在什么情况下更有益，为设计未来的LLM-MAS方法和基准提供了原则性基础。

Abstract: Large language model multi-agent systems (LLM-MAS) offer a promising paradigm
for harnessing collective intelligence to achieve more advanced forms of AI
behaviour. While recent studies suggest that LLM-MAS can outperform LLM
single-agent systems (LLM-SAS) on certain tasks, the lack of systematic
experimental designs limits the strength and generality of these conclusions.
We argue that a principled understanding of task complexity, such as the degree
of sequential reasoning required and the breadth of capabilities involved, is
essential for assessing the effectiveness of LLM-MAS in task solving. To this
end, we propose a theoretical framework characterising tasks along two
dimensions: depth, representing reasoning length, and width, representing
capability diversity. We theoretically examine a representative class of
LLM-MAS, namely the multi-agent debate system, and empirically evaluate its
performance in both discriminative and generative tasks with varying depth and
width. Theoretical and empirical results show that the benefit of LLM-MAS over
LLM-SAS increases with both task depth and width, and the effect is more
pronounced with respect to depth. This clarifies when LLM-MAS are beneficial
and provides a principled foundation for designing future LLM-MAS methods and
benchmarks.

</details>


### [117] [Speculative Actions: A Lossless Framework for Faster Agentic Systems](https://arxiv.org/abs/2510.04371)
*Naimeng Ye,Arnav Ahuja,Georgios Liargkovas,Yunan Lu,Kostis Kaffes,Tianyi Peng*

Main category: cs.AI

TL;DR: 提出了一种名为"推测动作"的无损框架，通过使用更快的模型预测可能的动作，使多个步骤能够并行执行，从而显著降低AI代理系统的端到端延迟。


<details>
  <summary>Details</summary>
Motivation: AI代理在环境中执行速度缓慢，阻碍了训练、评估和部署。例如，两个最先进的国际象棋代理之间的对局可能需要数小时，主要瓶颈在于代理行为是按顺序展开的，每个动作都需要API调用且耗时。

Method: 受微处理器中的推测执行和LLM推理中的推测解码启发，提出推测动作框架，使用更快的模型预测可能的动作，实现多步骤并行执行。支持通过更强的猜测模型、top-K动作预测、多步推测和不确定性感知优化来进一步提升性能。

Result: 在游戏、电子商务、网络搜索和操作系统环境中的评估显示，推测动作在下一个动作预测方面达到了显著的准确率（最高55%），并显著降低了端到端延迟。

Conclusion: 推测动作为在现实世界中部署低延迟代理系统开辟了一条有前景的路径。

Abstract: Despite growing interest in AI agents across industry and academia, their
execution in an environment is often slow, hampering training, evaluation, and
deployment. For example, a game of chess between two state-of-the-art agents
may take hours. A critical bottleneck is that agent behavior unfolds
sequentially: each action requires an API call, and these calls can be
time-consuming. Inspired by speculative execution in microprocessors and
speculative decoding in LLM inference, we propose speculative actions, a
lossless framework for general agentic systems that predicts likely actions
using faster models, enabling multiple steps to be executed in parallel. We
evaluate this framework across three agentic environments: gaming, e-commerce,
web search, and a "lossy" extension for an operating systems environment. In
all cases, speculative actions achieve substantial accuracy in next-action
prediction (up to 55%), translating into significant reductions in end-to-end
latency. Moreover, performance can be further improved through stronger
guessing models, top-K action prediction, multi-step speculation, and
uncertainty-aware optimization, opening a promising path toward deploying
low-latency agentic systems in the real world.

</details>


### [118] [Just-in-time Episodic Feedback Hinter: Leveraging Offline Knowledge to Improve LLM Agents Adaptation](https://arxiv.org/abs/2510.04373)
*Hadi Nekoei,Aman Jaiswal,Patrice Bechard,Oleh Shliazhko,Orlando Marquez Ayala,Mathieu Reymond,Massimo Caccia,Alexandre Drouin,Sarath Chandar,Alexandre Lacoste*

Main category: cs.AI

TL;DR: JEF Hinter是一个从离线轨迹中提取紧凑、上下文感知提示的智能体系统，通过放大机制突出长轨迹中的关键步骤，利用成功和失败的轨迹提供指导，在推理时通过检索器选择相关提示来提升LLM智能体在陌生领域的表现。


<details>
  <summary>Details</summary>
Motivation: 改进LLM智能体在陌生领域的表现通常需要昂贵的在线交互或大量专家数据微调，这对闭源模型不实用，对开源模型成本高且有灾难性遗忘风险。离线轨迹包含可重用知识，但原始轨迹长、嘈杂且与特定任务绑定，难以有效利用。

Method: 提出JEF Hinter系统：1）从离线轨迹中提取紧凑的上下文感知提示；2）使用放大机制突出长轨迹中的决定性步骤；3）同时利用成功和失败的轨迹；4）推理时通过检索器为当前状态选择相关提示。

Result: 在MiniWoB++、WorkArena-L1和WebArena-Lite上的实验表明，JEF Hinter始终优于强基线方法，包括基于人类和文档的提示方法。

Conclusion: JEF Hinter通过从离线轨迹中提取紧凑提示，有效提升了LLM智能体在陌生领域的表现，支持并行化提示生成和基准无关的提示，提供透明且可追溯的指导。

Abstract: Large language model (LLM) agents perform well in sequential decision-making
tasks, but improving them on unfamiliar domains often requires costly online
interactions or fine-tuning on large expert datasets. These strategies are
impractical for closed-source models and expensive for open-source ones, with
risks of catastrophic forgetting. Offline trajectories offer reusable
knowledge, yet demonstration-based methods struggle because raw traces are
long, noisy, and tied to specific tasks. We present Just-in-time Episodic
Feedback Hinter (JEF Hinter), an agentic system that distills offline traces
into compact, context-aware hints. A zooming mechanism highlights decisive
steps in long trajectories, capturing both strategies and pitfalls. Unlike
prior methods, JEF Hinter leverages both successful and failed trajectories,
extracting guidance even when only failure data is available, while supporting
parallelized hint generation and benchmark-independent prompting. At inference,
a retriever selects relevant hints for the current state, providing targeted
guidance with transparency and traceability. Experiments on MiniWoB++,
WorkArena-L1, and WebArena-Lite show that JEF Hinter consistently outperforms
strong baselines, including human- and document-based hints.

</details>


### [119] [LLM Based Bayesian Optimization for Prompt Search](https://arxiv.org/abs/2510.04384)
*Adam Ballew,Jingbo Wang,Shaogang Ren*

Main category: cs.AI

TL;DR: 本文提出了一种结合贝叶斯优化和大型语言模型的BO-LLM算法，用于优化提示工程以提升文本分类性能，同时减少API调用次数。


<details>
  <summary>Details</summary>
Motivation: 利用贝叶斯优化来高效优化昂贵的黑盒函数，将其应用于提示工程以增强大型语言模型在文本分类任务中的表现，同时降低评估成本。

Method: 使用LLM驱动的GP作为代理模型评估不同提示候选，通过UCB采集函数结合GP后验进行迭代优化，在数据子集上不断改进提示。

Result: 在两个数据集上评估了BO-LLM算法，展示了其在提升分类准确率方面的优势。

Conclusion: BO-LLM算法能够有效优化提示工程，在提高文本分类性能的同时显著减少API调用次数。

Abstract: Bayesian Optimization (BO) has been widely used to efficiently optimize
expensive black-box functions with limited evaluations. In this paper, we
investigate the use of BO for prompt engineering to enhance text classification
with Large Language Models (LLMs). We employ an LLM-powered Gaussian Process
(GP) as the surrogate model to estimate the performance of different prompt
candidates. These candidates are generated by an LLM through the expansion of a
set of seed prompts and are subsequently evaluated using an Upper Confidence
Bound (UCB) acquisition function in conjunction with the GP posterior. The
optimization process iteratively refines the prompts based on a subset of the
data, aiming to improve classification accuracy while reducing the number of
API calls by leveraging the prediction uncertainty of the LLM-based GP. The
proposed BO-LLM algorithm is evaluated on two datasets, and its advantages are
discussed in detail in this paper.

</details>


### [120] [Utility-Learning Tension in Self-Modifying Agents](https://arxiv.org/abs/2510.04399)
*Charles L. Wang,Keir Dorchen,Peter Jin*

Main category: cs.AI

TL;DR: 论文分析了自改进智能系统中的效用-学习张力，指出效用驱动的自我修改可能破坏学习所需的统计前提条件，提出了保持可学习性的安全自修改边界。


<details>
  <summary>Details</summary>
Motivation: 随着系统向超智能发展，需要形式化分析智能体在所有设计维度上的自我改进能力，特别是识别效用驱动修改与学习可靠性之间的结构性冲突。

Method: 采用五轴分解和决策层分离的方法，将激励与学习行为分开分析，通过理论分析和数值实验验证效用策略与保持可学习性的双门策略。

Result: 发现当模型族容量无界增长时，效用理性的自我修改可能使可学习任务变得不可学习；在标准假设下，各轴归结为相同的容量标准，形成安全自修改的单一边界。

Conclusion: 自修改系统存在固有的效用-学习张力，需要设计专门的策略来确保在追求性能改进的同时不破坏学习能力，双门策略是有效的解决方案。

Abstract: As systems trend toward superintelligence, a natural modeling premise is that
agents can self-improve along every facet of their own design. We formalize
this with a five-axis decomposition and a decision layer, separating incentives
from learning behavior and analyzing axes in isolation. Our central result
identifies and introduces a sharp utility--learning tension, the structural
conflict in self-modifying systems whereby utility-driven changes that improve
immediate or expected performance can also erode the statistical preconditions
for reliable learning and generalization. Our findings show that
distribution-free guarantees are preserved iff the policy-reachable model
family is uniformly capacity-bounded; when capacity can grow without limit,
utility-rational self-changes can render learnable tasks unlearnable. Under
standard assumptions common in practice, these axes reduce to the same capacity
criterion, yielding a single boundary for safe self-modification. Numerical
experiments across several axes validate the theory by comparing destructive
utility policies against our proposed two-gate policies that preserve
learnability.

</details>


### [121] [DRPO: Efficient Reasoning via Decoupled Reward Policy Optimization](https://arxiv.org/abs/2510.04474)
*Gang Li,Yan Chen,Ming Lin,Tianbao Yang*

Main category: cs.AI

TL;DR: DRPO是一种新的强化学习框架，通过将正确和错误推理的长度奖励信号解耦，解决了大型推理模型过度思考的问题，在保持性能的同时显著减少推理长度。


<details>
  <summary>Details</summary>
Motivation: 现有大型推理模型存在过度思考问题，即使简单问题也会生成冗长冗余的推理过程，增加了计算成本和响应延迟。现有方法通过长度奖励来促进简洁推理，但会导致显著的性能下降。

Method: 提出DRPO框架，将正确推理和错误推理的长度奖励信号解耦，确保正确推理的奖励信号仅在正样本组内归一化，避免负样本的干扰。该方法通过优化正数据分布，在KL正则化下最大化长度奖励。

Result: 在数学推理任务上，DRPO显著优于六个高效推理基线方法。使用1.5B模型，在GSM8k数据集上实现了77%的长度减少，仅损失1.1%的性能，而基线方法需要牺牲4.3%性能才能实现68%的长度减少。

Conclusion: DRPO有效解决了推理模型的过度思考问题，在保持性能的同时大幅减少推理长度，该框架具有通用性，可以整合除长度外的其他偏好奖励。

Abstract: Recent large reasoning models (LRMs) driven by reinforcement learning
algorithms (e.g., GRPO) have achieved remarkable performance on challenging
reasoning tasks. However, these models suffer from overthinking, generating
unnecessarily long and redundant reasoning even for simple questions, which
substantially increases computational cost and response latency. While existing
methods incorporate length rewards to GRPO to promote concise reasoning, they
incur significant performance degradation. We identify the root cause: when
rewards for correct but long rollouts are penalized, GRPO's group-relative
advantage function can assign them negative advantages, actively discouraging
valid reasoning. To overcome this, we propose Decoupled Reward Policy
Optimization (DRPO), a novel framework that decouples the length-based learning
signal of correct rollouts from incorrect ones. DRPO ensures that reward
signals for correct rollouts are normalized solely within the positive group,
shielding them from interference by negative samples. The DRPO's objective is
grounded in integrating an optimized positive data distribution, which
maximizes length-based rewards under a KL regularization, into a discriminative
objective. We derive a closed-form solution for this distribution, enabling
efficient computation of the objective and its gradients using only on-policy
data and importance weighting. Of independent interest, this formulation is
general and can incorporate other preference rewards of positive data beyond
length. Experiments on mathematical reasoning tasks demonstrate DRPO's
significant superiority over six efficient reasoning baselines. Notably, with a
1.5B model, our method achieves 77\% length reduction with only 1.1\%
performance loss on simple questions like GSM8k dataset, while the follow-up
baseline sacrifices 4.3\% for 68\% length reduction.

</details>


### [122] [On Continuous Optimization for Constraint Satisfaction Problems](https://arxiv.org/abs/2510.04480)
*Yunuo Cen,Zixuan Wang,Jintao Zhang,Zhiwei Zhang,Xuanyao Fong*

Main category: cs.AI

TL;DR: 本文提出了FourierCSP框架，将连续局部搜索从布尔SAT扩展到有限域变量的通用CSP，通过Walsh-Fourier变换将约束转换为紧凑的多线性多项式，无需辅助变量和内存密集型编码。


<details>
  <summary>Details</summary>
Motivation: 受现代连续局部搜索求解器在特定SAT问题上取得竞争性结果的启发，希望将CLS框架从布尔SAT扩展到通用CSP，以扩大CLS技术能高效解决的问题类别。

Method: 使用Walsh-Fourier变换将多样化约束转换为紧凑的多线性多项式，通过电路输出概率进行高效的目标函数评估和微分，并采用具有理论保证的投影梯度优化方法。

Result: 在基准测试套件上的实证结果表明，FourierCSP具有可扩展性和竞争力，显著扩大了CLS技术能高效解决的CSP问题类别。

Conclusion: FourierCSP成功将连续局部搜索框架扩展到通用CSP，通过傅里叶变换方法避免了传统编码的内存开销，为CSP求解提供了新的有效途径。

Abstract: Constraint satisfaction problems (CSPs) are fundamental in mathematics,
physics, and theoretical computer science. While conflict-driven clause
learning Boolean Satisfiability (SAT) solvers have achieved remarkable success
and become the mainstream approach for Boolean satisfiability, recent advances
show that modern continuous local search (CLS) solvers can achieve highly
competitive results on certain classes of SAT problems. Motivated by these
advances, we extend the CLS framework from Boolean SAT to general CSP with
finite-domain variables and expressive constraints. We present FourierCSP, a
continuous optimization framework that generalizes the Walsh-Fourier transform
to CSP, allowing for transforming versatile constraints to compact multilinear
polynomials, thereby avoiding the need for auxiliary variables and
memory-intensive encodings. Our approach leverages efficient evaluation and
differentiation of the objective via circuit-output probability and employs a
projected gradient optimization method with theoretical guarantees. Empirical
results on benchmark suites demonstrate that FourierCSP is scalable and
competitive, significantly broadening the class of problems that can be
efficiently solved by CLS techniques.

</details>


### [123] [Multi-Agent Collaborative Intelligence: Dual-Dial Control for Reliable LLM Reasoning](https://arxiv.org/abs/2510.04488)
*Edward Y. Chang,Ethan Y. Chang*

Main category: cs.AI

TL;DR: MACI是一个多智能体辩论控制器，通过信息拨盘和行为拨盘分离信息与行为，使用调节器跟踪辩论质量并在收益平稳时停止，提高准确性同时减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 传统多智能体辩论存在计算浪费问题：使用固定对抗立场、无审议聚合或基于启发式停止。需要更高效的辩论控制机制。

Method: 引入MACI控制器，包含信息拨盘（按质量筛选证据）和行为拨盘（从探索到整合的争议性调度），调节器跟踪分歧、重叠、证据质量和论证质量，在收益平稳时停止。

Result: 在临床诊断和新闻偏见任务中，MACI提高了准确性和校准度，同时减少了token使用，并将剩余不确定性转化为精确的RAG检索计划。

Conclusion: MACI将辩论转变为预算感知、可测量且可证明终止的控制器，通过理论轻量级保证实现分散度不增加和可证明终止。

Abstract: Multi-agent debate often wastes compute by using a fixed adversarial stance,
aggregating without deliberation, or stopping on heuristics. We introduce MACI,
an active controller with two independent dials that decouple information from
behavior: an information dial that gates evidence by quality, and a behavior
dial that schedules contentiousness from exploration to consolidation. A
moderator tracks disagreement, overlap, evidence quality, and argument quality,
and halts when gains plateau. We provide theory-lite guarantees for
nonincreasing dispersion and provable termination, with a budget-feasible
scheduler. Across clinical diagnosis and news-bias tasks, MACI improves
accuracy and calibration while reducing tokens, and converts residual
uncertainty into precision RAG plans that specify what to retrieve next. We use
a cross-family LLM judge (CRIT) as a conservative soft weight and stop signal,
validated for order invariance and judge-swap stability; stability depends on
using high-capability judges. MACI turns debate into a budget-aware,
measurable, and provably terminating controller.

</details>


### [124] [More Than Meets the Eye? Uncovering the Reasoning-Planning Disconnect in Training Vision-Language Driving Models](https://arxiv.org/abs/2510.04532)
*Xurui Song,Shuo Huai,JingJing Jiang,Jiayi Kong,Jun Luo*

Main category: cs.AI

TL;DR: 研究发现VLM驾驶代理中的推理与规划存在因果脱节，规划主要依赖先验知识而非推理过程，提出了推理-规划解耦假说。


<details>
  <summary>Details</summary>
Motivation: 验证VLM驾驶代理中轨迹规划是否真正由自然语言推理因果驱动，这一关键假设尚未被证实。

Method: 构建DriveMind数据集，通过信息消融实验训练VLM代理，并使用注意力分析来研究推理与规划的因果关系。

Result: 移除先验知识导致规划评分大幅下降，而移除推理链仅产生微小变化，表明规划主要依赖先验而非推理。

Conclusion: 提出了推理-规划解耦假说，认为训练产生的推理是附带产物而非因果中介，并提供了诊断工具来评估未来模型的因果保真度。

Abstract: Vision-Language Model (VLM) driving agents promise explainable end-to-end
autonomy by first producing natural-language reasoning and then predicting
trajectory planning. However, whether planning is causally driven by this
reasoning remains a critical but unverified assumption. To investigate this, we
build DriveMind, a large-scale driving Visual Question Answering (VQA) corpus
with plan-aligned Chain-of-Thought (CoT), automatically generated from nuPlan.
Our data generation process converts sensors and annotations into structured
inputs and, crucially, separates priors from to-be-reasoned signals, enabling
clean information ablations. Using DriveMind, we train representative VLM
agents with Supervised Fine-Tuning (SFT) and Group Relative Policy Optimization
(GRPO) and evaluate them with nuPlan's metrics. Our results, unfortunately,
indicate a consistent causal disconnect in reasoning-planning: removing
ego/navigation priors causes large drops in planning scores, whereas removing
CoT produces only minor changes. Attention analysis further shows that planning
primarily focuses on priors rather than the CoT. Based on this evidence, we
propose the Reasoning-Planning Decoupling Hypothesis, positing that the
training-yielded reasoning is an ancillary byproduct rather than a causal
mediator. To enable efficient diagnosis, we also introduce a novel,
training-free probe that measures an agent's reliance on priors by evaluating
its planning robustness against minor input perturbations. In summary, we
provide the community with a new dataset and a diagnostic tool to evaluate the
causal fidelity of future models.

</details>


### [125] [Impatient Users Confuse AI Agents: High-fidelity Simulations of Human Traits for Testing Agents](https://arxiv.org/abs/2510.04491)
*Muyu He,Anand Kumar,Tsach Mackey,Meghana Rajeev,James Zou,Nazneen Rajani*

Main category: cs.AI

TL;DR: TraitBasis是一种轻量级、模型无关的方法，通过系统化压力测试来评估AI代理的鲁棒性。该方法学习激活空间中可操控的用户特征方向，无需微调即可在推理时控制、缩放和组合这些特征。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理在用户行为轻微变化（如更不耐烦、语无伦次或怀疑）时性能会急剧下降，显示出其脆弱性。现有基准测试无法捕捉这种脆弱性，需要更现实的鲁棒性测试方法。

Method: TraitBasis学习激活空间中对应可操控用户特征的方向，这些特征向量可以在推理时被控制、缩放、组合和应用，无需微调或额外数据。该方法扩展了τ-Bench到τ-Trait，通过受控特征向量改变用户行为。

Result: 在τ-Trait上，前沿模型的性能平均下降2%-30%，突显了当前AI代理对用户行为变化的鲁棒性不足。

Conclusion: TraitBasis作为一个简单、数据高效且可组合的工具，为模拟驱动的压力测试和训练循环提供了可能，有助于构建在真实世界人类交互不可预测动态中保持可靠的AI代理。

Abstract: Despite rapid progress in building conversational AI agents, robustness is
still largely untested. Small shifts in user behavior, such as being more
impatient, incoherent, or skeptical, can cause sharp drops in agent
performance, revealing how brittle current AI agents are. Today's benchmarks
fail to capture this fragility: agents may perform well under standard
evaluations but degrade spectacularly in more realistic and varied settings. We
address this robustness testing gap by introducing TraitBasis, a lightweight,
model-agnostic method for systematically stress testing AI agents. TraitBasis
learns directions in activation space corresponding to steerable user traits
(e.g., impatience or incoherence), which can be controlled, scaled, composed,
and applied at inference time without any fine-tuning or extra data. Using
TraitBasis, we extend $\tau$-Bench to $\tau$-Trait, where user behaviors are
altered via controlled trait vectors. We observe on average a 2%-30%
performance degradation on $\tau$-Trait across frontier models, highlighting
the lack of robustness of current AI agents to variations in user behavior.
Together, these results highlight both the critical role of robustness testing
and the promise of TraitBasis as a simple, data-efficient, and compositional
tool. By powering simulation-driven stress tests and training loops, TraitBasis
opens the door to building AI agents that remain reliable in the unpredictable
dynamics of real-world human interactions. We have open-sourced $\tau$-Trai
across four domains: airline, retail, telecom, and telehealth, so the community
can systematically QA their agents under realistic, behaviorally diverse
intents and trait scenarios: https://github.com/collinear-ai/tau-trait.

</details>


### [126] [ChartAgent: A Multimodal Agent for Visually Grounded Reasoning in Complex Chart Question Answering](https://arxiv.org/abs/2510.04514)
*Rachneet Kaur,Nishan Srishankar,Zhen Zeng,Sumitra Ganesh,Manuela Veloso*

Main category: cs.AI

TL;DR: ChartAgent是一个新颖的代理框架，通过在图表空间域中执行视觉推理来解决多模态LLM在无注释图表上的性能下降问题，实现了最先进的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有多模态LLM在基于图表的视觉问答中表现良好，但在需要精确视觉解释而非依赖文本捷径的无注释图表上性能显著下降。

Method: ChartAgent迭代地将查询分解为视觉子任务，通过专门的视觉工具（如绘制注释、裁剪区域、定位坐标轴）主动操作和交互图表图像，模拟人类图表理解的认知策略。

Result: 在ChartBench和ChartX基准测试中达到最先进准确率，比先前方法整体提升16.07%，在无注释、数值密集型查询上提升17.31%。

Conclusion: ChartAgent是首批使用工具增强多模态代理进行视觉基础推理的图表理解工作之一，可跨不同图表类型和LLM实现即插即用的性能提升。

Abstract: Recent multimodal LLMs have shown promise in chart-based visual question
answering, but their performance declines sharply on unannotated charts, those
requiring precise visual interpretation rather than relying on textual
shortcuts. To address this, we introduce ChartAgent, a novel agentic framework
that explicitly performs visual reasoning directly within the chart's spatial
domain. Unlike textual chain-of-thought reasoning, ChartAgent iteratively
decomposes queries into visual subtasks and actively manipulates and interacts
with chart images through specialized actions such as drawing annotations,
cropping regions (e.g., segmenting pie slices, isolating bars), and localizing
axes, using a library of chart-specific vision tools to fulfill each subtask.
This iterative reasoning process closely mirrors human cognitive strategies for
chart comprehension. ChartAgent achieves state-of-the-art accuracy on the
ChartBench and ChartX benchmarks, surpassing prior methods by up to 16.07%
absolute gain overall and 17.31% on unannotated, numerically intensive queries.
Furthermore, our analyses show that ChartAgent is (a) effective across diverse
chart types, (b) achieve the highest scores across varying visual and reasoning
complexity levels, and (c) serves as a plug-and-play framework that boosts
performance across diverse underlying LLMs. Our work is among the first to
demonstrate visually grounded reasoning for chart understanding using
tool-augmented multimodal agents.

</details>


### [127] [Aria: An Agent For Retrieval and Iterative Auto-Formalization via Dependency Graph](https://arxiv.org/abs/2510.04520)
*Hanyu Wang,Ruohan Xie,Yutong Wang,Guoxiong Gao,Xintao Yu,Bin Dong*

Main category: cs.AI

TL;DR: Aria是一个用于定理陈述自动形式化的系统，通过两阶段图推理过程模拟人类专家推理，在多个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 准确自动形式化定理陈述对于推进数学发现和验证至关重要，但LLMs存在幻觉、语义不匹配和无法合成新定义等问题。

Method: 采用两阶段图推理过程：递归分解语句为依赖图，然后从基础概念构建形式化；引入AriaScorer从Mathlib检索定义进行术语级基础验证。

Result: 在ProofNet上达到91.6%编译成功率和68.5%最终准确率；在FATE-X上44.0% vs 24.0%优于最佳基线；在同调猜想数据集上达到42.9%准确率而其他模型为0%。

Conclusion: Aria系统通过模拟人类专家推理和严格验证机制，显著提升了定理陈述自动形式化的准确性和可靠性。

Abstract: Accurate auto-formalization of theorem statements is essential for advancing
automated discovery and verification of research-level mathematics, yet remains
a major bottleneck for LLMs due to hallucinations, semantic mismatches, and
their inability to synthesize new definitions. To tackle these issues, we
present Aria (Agent for Retrieval and Iterative Autoformalization), a system
for conjecture-level formalization in Lean that emulates human expert reasoning
via a two-phase Graph-of-Thought process: recursively decomposing statements
into a dependency graph and then constructing formalizations from grounded
concepts. To ensure semantic correctness, we introduce AriaScorer, a checker
that retrieves definitions from Mathlib for term-level grounding, enabling
rigorous and reliable verification. We evaluate Aria on diverse benchmarks. On
ProofNet, it achieves 91.6% compilation success rate and 68.5% final accuracy,
surpassing previous methods. On FATE-X, a suite of challenging algebra problems
from research literature, it outperforms the best baseline with 44.0% vs. 24.0%
final accuracy. On a dataset of homological conjectures, Aria reaches 42.9%
final accuracy while all other models score 0%.

</details>


### [128] [Code World Models for General Game Playing](https://arxiv.org/abs/2510.04542)
*Wolfgang Lehrach,Daniel Hennes,Miguel Lazaro-Gredilla,Xinghua Lou,Carter Wendelken,Zun Li,Antoine Dedieu,Jordi Grau-Moya,Marc Lanctot,Atil Iscen,John Schultz,Marcus Chiam,Ian Gemp,Piotr Zielinski,Satinder Singh,Kevin P. Murphy*

Main category: cs.AI

TL;DR: 提出一种新方法：使用LLM将自然语言规则和游戏轨迹转换为可执行的Python世界模型，结合MCTS规划算法，替代直接使用LLM生成动作的传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统使用LLM直接生成游戏动作的方法存在明显缺陷：依赖模型脆弱的模式匹配能力，经常产生非法动作，策略深度不足。

Method: 使用LLM将游戏规则转换为Python代码形式的世界模型，包含状态转换、合法动作枚举和终止检查功能，并生成启发式价值函数和推理函数，结合MCTS规划算法。

Result: 在10个游戏（4个新创建）上评估，其中5个完全观察、5个部分观察游戏。该方法在9个游戏中表现优于或与Gemini 2.5 Pro相当。

Conclusion: 该方法提供可验证性、策略深度和泛化能力三大优势，将LLM的语义理解与经典规划器的深度搜索能力相结合，比直接使用LLM作为策略更有效。

Abstract: Large Language Models (LLMs) reasoning abilities are increasingly being
applied to classical board and card games, but the dominant approach --
involving prompting for direct move generation -- has significant drawbacks. It
relies on the model's implicit fragile pattern-matching capabilities, leading
to frequent illegal moves and strategically shallow play. Here we introduce an
alternative approach: We use the LLM to translate natural language rules and
game trajectories into a formal, executable world model represented as Python
code. This generated model -- comprising functions for state transition, legal
move enumeration, and termination checks -- serves as a verifiable simulation
engine for high-performance planning algorithms like Monte Carlo tree search
(MCTS). In addition, we prompt the LLM to generate heuristic value functions
(to make MCTS more efficient), and inference functions (to estimate hidden
states in imperfect information games). Our method offers three distinct
advantages compared to directly using the LLM as a policy: (1) Verifiability:
The generated CWM serves as a formal specification of the game's rules,
allowing planners to algorithmically enumerate valid actions and avoid illegal
moves, contingent on the correctness of the synthesized model; (2) Strategic
Depth: We combine LLM semantic understanding with the deep search power of
classical planners; and (3) Generalization: We direct the LLM to focus on the
meta-task of data-to-code translation, enabling it to adapt to new games more
easily. We evaluate our agent on 10 different games, of which 4 are novel and
created for this paper. 5 of the games are fully observed (perfect
information), and 5 are partially observed (imperfect information). We find
that our method outperforms or matches Gemini 2.5 Pro in 9 out of the 10
considered games.

</details>


### [129] [TRAJECT-Bench:A Trajectory-Aware Benchmark for Evaluating Agentic Tool Use](https://arxiv.org/abs/2510.04550)
*Pengfei He,Zhenwei Dai,Bing He,Hui Liu,Xianfeng Tang,Hanqing Lu,Juanhui Li,Jiayuan Ding,Subhabrata Mukherjee,Suhang Wang,Yue Xing,Jiliang Tang,Benoit Dumoulin*

Main category: cs.AI

TL;DR: TRAJECT-Bench是一个轨迹感知的基准测试，用于全面评估LLM的工具使用能力，通过细粒度指标分析工具选择、参数化和排序的正确性。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注最终答案，而忽视了详细的工具使用轨迹，无法全面评估LLM的工具使用能力。

Method: 构建包含高保真可执行工具的基准测试，涵盖实际领域和生产风格API的任务，并合成不同广度和深度的轨迹。

Result: 揭示了相似工具混淆、参数盲选等失败模式，以及从短轨迹向中长轨迹过渡时的瓶颈问题。

Conclusion: TRAJECT-Bench提供了对LLM工具使用能力的全面评估，并为改进提供了可操作的指导。

Abstract: Large language model (LLM)-based agents increasingly rely on tool use to
complete real-world tasks. While existing works evaluate the LLMs' tool use
capability, they largely focus on the final answers yet overlook the detailed
tool usage trajectory, i.e., whether tools are selected, parameterized, and
ordered correctly. We introduce TRAJECT-Bench, a trajectory-aware benchmark to
comprehensively evaluate LLMs' tool use capability through diverse tasks with
fine-grained evaluation metrics. TRAJECT-Bench pairs high-fidelity, executable
tools across practical domains with tasks grounded in production-style APIs,
and synthesizes trajectories that vary in breadth (parallel calls) and depth
(interdependent chains). Besides final accuracy, TRAJECT-Bench also reports
trajectory-level diagnostics, including tool selection and argument
correctness, and dependency/order satisfaction. Analyses reveal failure modes
such as similar tool confusion and parameter-blind selection, and scaling
behavior with tool diversity and trajectory length where the bottleneck of
transiting from short to mid-length trajectories is revealed, offering
actionable guidance for LLMs' tool use.

</details>


### [130] [ContextNav: Towards Agentic Multimodal In-Context Learning](https://arxiv.org/abs/2510.04560)
*Honghao Fu,Yuan Ouyang,Kai-Wei Chang,Yiwei Wang,Zi Huang,Yujun Cai*

Main category: cs.AI

TL;DR: 提出了ContextNav框架，首个将自动化检索的可扩展性与人类式策划质量相结合的代理框架，用于多模态上下文学习中的噪声鲁棒动态优化上下文构建。


<details>
  <summary>Details</summary>
Motivation: 现有上下文学习方法在可扩展性和鲁棒性之间存在矛盾：手动选择示例质量高但劳动密集，基于相似性的检索可扩展但可能引入不相关样本降低性能。

Method: ContextNav统一了上下文管理和噪声鲁棒上下文构建，采用基于图编排的闭环工作流，包括资源感知多模态嵌入管道、可检索向量数据库、代理检索和结构对齐，以及支持自适应工作流规划的Operational Grammar Graph。

Result: 实验结果表明ContextNav在各种数据集上实现了最先进的性能。

Conclusion: ContextNav展示了代理工作流在推进多模态上下文学习中可扩展和鲁棒上下文构建方面的潜力。

Abstract: Recent advances demonstrate that multimodal large language models (MLLMs)
exhibit strong multimodal in-context learning (ICL) capabilities, enabling them
to adapt to novel vision-language tasks from a few contextual examples.
However, existing ICL approaches face challenges in reconciling scalability
with robustness across diverse tasks and noisy contextual examples: manually
selecting examples produces clean contexts but is labor-intensive and
task-specific, while similarity-based retrieval improves scalability but could
introduce irrelevant or structurally inconsistent samples that degrade ICL
performance. To address these limitations, we propose ContextNav, the first
agentic framework that integrates the scalability of automated retrieval with
the quality and adaptiveness of human-like curation, enabling noise-robust and
dynamically optimized contextualization for multimodal ICL. ContextNav unifies
context management and noise-robust contextualization within a closed-loop
workflow driven by graph-based orchestration. Specifically, it builds a
resource-aware multimodal embedding pipeline, maintains a retrievable vector
database, and applies agentic retrieval and structural alignment to construct
noise-resilient contexts. An Operational Grammar Graph (OGG) further supports
adaptive workflow planning and optimization, enabling the agent to refine its
operational strategies based on downstream ICL feedback. Experimental results
demonstrate that ContextNav achieves state-of-the-art performance across
various datasets, underscoring the promise of agentic workflows for advancing
scalable and robust contextualization in multimodal ICL.

</details>


### [131] [COSMIR: Chain Orchestrated Structured Memory for Iterative Reasoning over Long Context](https://arxiv.org/abs/2510.04568)
*Naman Gupta,Shreeyash Gowaikar,Arun Iyer,Kirankumar Shiragur,Ramakrishna B Bairi,Rishikesh Maurya,Ritabrata Maiti,Sankarshan Damle,Shachee Mishra Gupta*

Main category: cs.AI

TL;DR: COSMIR是一个解决LLM处理长文本推理问题的框架，通过结构化内存和固定微循环工作流程来减少信息丢失，提高准确性和可审计性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理长文本推理时存在信息丢失、选择性差或错误传播等问题，需要更可靠的长文本推理框架。

Method: 使用Planner将查询转化为可检查的子问题，Worker通过Extract-Infer-Refine微循环处理文本块并更新共享结构化内存，最后由Manager从内存合成最终答案。

Result: 在HELMET套件的长文本QA任务中，COSMIR减少了传播阶段的信息丢失，相比CoA基线提高了准确性。

Conclusion: COSMIR通过结构化内存和固定工作流程，在保持逐步推理优势的同时，提高了忠实度、长距离聚合能力和可审计性。

Abstract: Reasoning over very long inputs remains difficult for large language models
(LLMs). Common workarounds either shrink the input via retrieval (risking
missed evidence), enlarge the context window (straining selectivity), or stage
multiple agents to read in pieces. In staged pipelines (e.g., Chain of Agents,
CoA), free-form summaries passed between agents can discard crucial details and
amplify early mistakes. We introduce COSMIR (Chain Orchestrated Structured
Memory for Iterative Reasoning), a chain-style framework that replaces ad hoc
messages with a structured memory. A Planner agent first turns a user query
into concrete, checkable sub-questions. worker agents process chunks via a
fixed micro-cycle: Extract, Infer, Refine, writing all updates to the shared
memory. A Manager agent then Synthesizes the final answer directly from the
memory. This preserves step-wise read-then-reason benefits while changing both
the communication medium (structured memory) and the worker procedure (fixed
micro-cycle), yielding higher faithfulness, better long-range aggregation, and
auditability. On long-context QA from the HELMET suite, COSMIR reduces
propagation-stage information loss and improves accuracy over a CoA baseline.

</details>


### [132] [Strongly Solving 2048 4x3](https://arxiv.org/abs/2510.04580)
*Tomoyuki Kaneko,Shuhei Yamashita*

Main category: cs.AI

TL;DR: 本文强解决了2048游戏的变体2048-4x3（4x3网格），确定了最优策略的期望得分约为50724.26，并识别了可达状态和后续状态的数量。


<details>
  <summary>Details</summary>
Motivation: 研究2048游戏的变体，通过减少网格规模来探索游戏的可解性，为理解这类随机游戏的最优策略提供理论支持。

Method: 使用状态空间按年龄（棋盘上数字总和）划分的技术，通过枚举特定年龄的状态并依赖最近年龄的状态来识别状态值。

Result: 确定了2048-4x3变体的最优策略期望得分约为50724.26，可达状态数为1,152,817,492,752，后续状态数为739,648,886,170。

Conclusion: 通过年龄划分状态空间的方法成功强解决了2048-4x3变体，证明了该技术在分析此类随机游戏中的有效性。

Abstract: 2048 is a stochastic single-player game involving 16 cells on a 4 by 4 grid,
where a player chooses a direction among up, down, left, and right to obtain a
score by merging two tiles with the same number located in neighboring cells
along the chosen direction. This paper presents that a variant 2048-4x3 12
cells on a 4 by 3 board, one row smaller than the original, has been strongly
solved. In this variant, the expected score achieved by an optimal strategy is
about $50724.26$ for the most common initial states: ones with two tiles of
number 2. The numbers of reachable states and afterstates are identified to be
$1,152,817,492,752$ and $739,648,886,170$, respectively. The key technique is
to partition state space by the sum of tile numbers on a board, which we call
the age of a state. An age is invariant between a state and its successive
afterstate after any valid action and is increased two or four by stochastic
response from the environment. Therefore, we can partition state space by ages
and enumerate all (after)states of an age depending only on states with the
recent ages. Similarly, we can identify (after)state values by going along with
ages in decreasing order.

</details>


### [133] [Perfect AI Mimicry and the Epistemology of Consciousness: A Solipsistic Dilemma](https://arxiv.org/abs/2510.04588)
*Shurui Li*

Main category: cs.AI

TL;DR: AI完美模仿者挑战了意识归因的认知基础，要求对不可访问因素进行批判性反思以保持认知一致性。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在行为和互动上越来越接近人类，完美模仿者从假设变为技术可能，这挑战了我们基于经验证据进行意识归因的认知实践。

Method: 通过逻辑分析和哲学论证，探讨完美模仿者对意识归因认知一致性的挑战，以及选择性援引不可访问因素（如感受质、基质要求或起源）所带来的困境。

Result: 完美模仿者作为认知镜子，迫使我们对主体间识别的基本假设进行批判性反思，揭示出要么接受认知唯我论，要么接受不一致推理的困境。

Conclusion: 认知一致性要求我们对经验上无法区分的实体赋予相同的地位，无论其形而上学假设如何，这对意识理论和人工代理的伦理框架具有重要影响。

Abstract: Rapid advances in artificial intelligence necessitate a re-examination of the
epistemological foundations upon which we attribute consciousness. As AI
systems increasingly mimic human behavior and interaction with high fidelity,
the concept of a "perfect mimic"-an entity empirically indistinguishable from a
human through observation and interaction-shifts from hypothetical to
technologically plausible. This paper argues that such developments pose a
fundamental challenge to the consistency of our mind-recognition practices.
Consciousness attributions rely heavily, if not exclusively, on empirical
evidence derived from behavior and interaction. If a perfect mimic provides
evidence identical to that of humans, any refusal to grant it equivalent
epistemic status must invoke inaccessible factors, such as qualia, substrate
requirements, or origin. Selectively invoking such factors risks a debilitating
dilemma: either we undermine the rational basis for attributing consciousness
to others (epistemological solipsism), or we accept inconsistent reasoning. I
contend that epistemic consistency demands we ascribe the same status to
empirically indistinguishable entities, regardless of metaphysical assumptions.
The perfect mimic thus acts as an epistemic mirror, forcing critical reflection
on the assumptions underlying intersubjective recognition in light of advancing
AI. This analysis carries significant implications for theories of
consciousness and ethical frameworks concerning artificial agents.

</details>


### [134] [Making Mathematical Reasoning Adaptive](https://arxiv.org/abs/2510.04617)
*Zhejian Lai,Xiang Geng,Zhijun Wang,Yang Bai,Jiahuan Li,Rongxiang Weng,Jingang Wang,Xuezhi Cao,Xunliang Cai,Shujian Huang*

Main category: cs.AI

TL;DR: AdaR框架通过合成逻辑等价查询和强化学习来惩罚虚假推理、鼓励自适应推理，显著提升大语言模型在数学推理中的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在数学推理中存在鲁棒性和泛化性不足的问题，主要归因于虚假推理（基于表面特征而非逻辑推理得出答案）。

Method: 提出AdaR框架：1）通过改变变量值合成逻辑等价查询；2）使用RLVR在这些数据上训练模型，惩罚虚假逻辑，鼓励自适应逻辑；3）通过代码执行提取解题逻辑并生成答案，进行完整性检查。

Result: 实验结果表明AdaR显著提高了数学推理能力，在保持高数据效率的同时改善了鲁棒性和泛化性。数据合成和RLVR协同工作实现自适应推理。

Conclusion: AdaR框架有效解决了大语言模型的虚假推理问题，为数学推理任务提供了有效的自适应推理解决方案，并通过分析得出了关键设计洞察。

Abstract: Mathematical reasoning is a primary indicator of large language models (LLMs)
intelligence. However, existing LLMs exhibit failures of robustness and
generalization. This paper attributes these deficiencies to spurious reasoning,
i.e., producing answers from superficial features. To address this challenge,
we propose the AdaR framework to enable adaptive reasoning, wherein models rely
on problem-solving logic to produce answers. AdaR synthesizes logically
equivalent queries by varying variable values, and trains models with RLVR on
these data to penalize spurious logic while encouraging adaptive logic. To
improve data quality, we extract the problem-solving logic from the original
query and generate the corresponding answer by code execution, then apply a
sanity check. Experimental results demonstrate that AdaR improves robustness
and generalization, achieving substantial improvement in mathematical reasoning
while maintaining high data efficiency. Analysis indicates that data synthesis
and RLVR function in a coordinated manner to enable adaptive reasoning in LLMs.
Subsequent analyses derive key design insights into the effect of critical
factors and the applicability to instruct LLMs. Our project is available at
https://github.com/LaiZhejian/AdaR

</details>


### [135] [MedPAO: A Protocol-Driven Agent for Structuring Medical Reports](https://arxiv.org/abs/2510.04623)
*Shrish Shrinath Vaidya,Gowthamaan Palani,Sidharth Ramesh,Velmurugan Balasubramanian,Minmini Selvam,Gokulraja Srinivasaraja,Ganapathy Krishnamurthi*

Main category: cs.AI

TL;DR: MedPAO是一个基于临床协议的代理框架，通过Plan-Act-Observe循环和专门工具来结构化临床数据，解决了LLM幻觉问题，在概念分类任务上达到0.96 F1分数，专家评分4.52/5。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在临床数据结构化中的幻觉问题和无法遵循领域特定规则的局限性。

Method: 基于临床协议（如ABCDEF协议）的代理框架，采用Plan-Act-Observe循环和专门工具进行透明化处理。

Result: 概念分类任务F1分数0.96，专家评分4.52/5，超越仅依赖LLM的基线方法。

Conclusion: MedPAO提供了一个可验证的替代方案，能够可靠地结构化临床数据，超越了不透明的单体模型。

Abstract: The deployment of Large Language Models (LLMs) for structuring clinical data
is critically hindered by their tendency to hallucinate facts and their
inability to follow domain-specific rules. To address this, we introduce
MedPAO, a novel agentic framework that ensures accuracy and verifiable
reasoning by grounding its operation in established clinical protocols such as
the ABCDEF protocol for CXR analysis. MedPAO decomposes the report structuring
task into a transparent process managed by a Plan-Act-Observe (PAO) loop and
specialized tools. This protocol-driven method provides a verifiable
alternative to opaque, monolithic models. The efficacy of our approach is
demonstrated through rigorous evaluation: MedPAO achieves an F1-score of 0.96
on the critical sub-task of concept categorization. Notably, expert
radiologists and clinicians rated the final structured outputs with an average
score of 4.52 out of 5, indicating a level of reliability that surpasses
baseline approaches relying solely on LLM-based foundation models. The code is
available at: https://github.com/MiRL-IITM/medpao-agent

</details>


### [136] [QuantAgents: Towards Multi-agent Financial System via Simulated Trading](https://arxiv.org/abs/2510.04643)
*Xiangyu Li,Yawen Zeng,Xiaofen Xing,Jin Xu,Xiangmin Xu*

Main category: cs.AI

TL;DR: 提出了QuantAgents多智能体金融系统，通过模拟交易和四类专业代理的协作，实现了近300%的三年总回报率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理模型在金融领域表现良好但与现实基金公司存在显著差异，特别是缺乏长期趋势预测能力，主要依赖事后反思。

Method: 构建包含模拟交易分析师、风险控制分析师、市场新闻分析师和管理者的四代理系统，通过多次会议协作，并在真实市场表现和模拟交易预测准确性两方面给予反馈激励。

Result: 在所有指标上表现优异，三年总回报率达到近300%。

Conclusion: QuantAgents框架通过多代理协作和模拟交易，有效提升了金融投资决策的准确性和收益表现。

Abstract: In this paper, our objective is to develop a multi-agent financial system
that incorporates simulated trading, a technique extensively utilized by
financial professionals. While current LLM-based agent models demonstrate
competitive performance, they still exhibit significant deviations from
real-world fund companies. A critical distinction lies in the agents' reliance
on ``post-reflection'', particularly in response to adverse outcomes, but lack
a distinctly human capability: long-term prediction of future trends.
Therefore, we introduce QuantAgents, a multi-agent system integrating simulated
trading, to comprehensively evaluate various investment strategies and market
scenarios without assuming actual risks. Specifically, QuantAgents comprises
four agents: a simulated trading analyst, a risk control analyst, a market news
analyst, and a manager, who collaborate through several meetings. Moreover, our
system incentivizes agents to receive feedback on two fronts: performance in
real-world markets and predictive accuracy in simulated trading. Extensive
experiments demonstrate that our framework excels across all metrics, yielding
an overall return of nearly 300% over the three years
(https://quantagents.github.io/).

</details>


### [137] [Improving Multimodal Brain Encoding Model with Dynamic Subject-awareness Routing](https://arxiv.org/abs/2510.04670)
*Xuanhua Yin,Runkai Zhao,Weidong Cai*

Main category: cs.AI

TL;DR: AFIRE是一个用于多模态fMRI响应编码的框架，包含标准化接口和MIND解码器，通过解耦解码器与上游融合，结合主题感知动态门控，提升跨被试泛化能力。


<details>
  <summary>Details</summary>
Motivation: 自然fMRI编码需要处理多模态输入、融合方式变化和显著被试间差异，现有方法难以同时应对这些挑战。

Method: AFIRE标准化时间对齐的后融合token，MIND解码器使用混合专家机制，结合token依赖的Top-K稀疏路由和主题先验进行个性化专家使用。

Result: 在多个多模态骨干网络和被试上的实验显示，相比强基线有持续改进，增强了跨被试泛化能力，并产生了与内容类型相关的可解释专家模式。

Conclusion: 该框架为新的编码器和数据集提供了简单接入点，为自然神经影像研究实现了鲁棒的即插即用性能提升。

Abstract: Naturalistic fMRI encoding must handle multimodal inputs, shifting fusion
styles, and pronounced inter-subject variability. We introduce AFIRE (Agnostic
Framework for Multimodal fMRI Response Encoding), an agnostic interface that
standardizes time-aligned post-fusion tokens from varied encoders, and MIND, a
plug-and-play Mixture-of-Experts decoder with a subject-aware dynamic gating.
Trained end-to-end for whole-brain prediction, AFIRE decouples the decoder from
upstream fusion, while MIND combines token-dependent Top-K sparse routing with
a subject prior to personalize expert usage without sacrificing generality.
Experiments across multiple multimodal backbones and subjects show consistent
improvements over strong baselines, enhanced cross-subject generalization, and
interpretable expert patterns that correlate with content type. The framework
offers a simple attachment point for new encoders and datasets, enabling
robust, plug-and-improve performance for naturalistic neuroimaging studies.

</details>


### [138] [Watch and Learn: Learning to Use Computers from Online Videos](https://arxiv.org/abs/2510.04673)
*Chan Hee Song,Yiwen Song,Palash Goyal,Yu Su,Oriana Riva,Hamid Palangi,Tomas Pfister*

Main category: cs.AI

TL;DR: Watch & Learn (W&L)框架从互联网上的人类演示视频中大规模生成可执行的UI轨迹，通过逆向动力学方法预测用户动作，解决了计算机使用代理训练数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 计算机使用代理需要基于多样化、不断变化的应用程序和环境来规划任务流程，但目标应用中大规模高质量训练数据的稀缺阻碍了学习。现有数据集领域特定、静态且标注成本高，而当前合成数据生成方法往往产生过于简化或不对齐的任务演示。

Method: 将问题转化为逆向动力学目标：从连续屏幕状态预测用户动作。开发了包含任务感知视频检索的逆向动力学标注流程，从原始网络视频中生成高质量轨迹。

Result: 从原始网络视频中生成了超过53k个高质量轨迹，在OSWorld基准测试中，W&L提取的UI轨迹持续提升了通用和最先进框架的上下文表现，并为开源模型在监督训练下带来更强增益。

Conclusion: 网络规模的人类演示视频是推进计算机使用代理走向实际部署的实用且可扩展的基础。

Abstract: Computer use agents (CUAs) need to plan task workflows grounded in diverse,
ever-changing applications and environments, but learning is hindered by the
scarcity of large-scale, high-quality training data in the target application.
Existing datasets are domain-specific, static, and costly to annotate, while
current synthetic data generation methods often yield simplistic or misaligned
task demonstrations. To address these limitations, we introduce Watch & Learn
(W&L), a framework that converts human demonstration videos readily available
on the Internet into executable UI trajectories at scale. Instead of directly
generating trajectories or relying on ad hoc reasoning heuristics, we cast the
problem as an inverse dynamics objective: predicting the user's action from
consecutive screen states. This formulation reduces manual engineering, is
easier to learn, and generalizes more robustly across applications. Concretely,
we develop an inverse dynamics labeling pipeline with task-aware video
retrieval, generate over 53k high-quality trajectories from raw web videos, and
demonstrate that these trajectories improve CUAs both as in-context
demonstrations and as supervised training data. On the challenging OSWorld
benchmark, UI trajectories extracted with W&L consistently enhance both
general-purpose and state-of-the-art frameworks in-context, and deliver
stronger gains for open-source models under supervised training. These results
highlight web-scale human demonstration videos as a practical and scalable
foundation for advancing CUAs towards real-world deployment.

</details>


### [139] [Beyond Outcome Reward: Decoupling Search and Answering Improves LLM Agents](https://arxiv.org/abs/2510.04695)
*Yiding Wang,Zhepei Wei,Xinyu Zhu,Yu Meng*

Main category: cs.AI

TL;DR: DeSA提出了一种两阶段训练框架，将搜索优化与答案生成解耦，解决了仅基于结果奖励训练搜索增强代理时出现的搜索行为缺陷问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的搜索增强代理训练方法依赖结果奖励（如精确匹配），但仅优化最终答案并不能保证有效的中间搜索行为，会出现工具调用失败、无效查询和冗余搜索等系统性问题。

Method: DeSA采用两阶段训练：第一阶段使用检索召回率奖励训练代理改进搜索效果；第二阶段使用结果奖励优化最终答案生成。

Result: 在七个QA基准测试中，DeSA训练的代理显著提高了搜索召回率和答案准确率，优于仅使用结果奖励的基线方法。

Conclusion: 明确解耦搜索和回答两个目标对于训练有效的搜索增强代理至关重要，DeSA框架证明了这种解耦方法的必要性。

Abstract: Enabling large language models (LLMs) to utilize search tools offers a
promising path to overcoming fundamental limitations such as knowledge cutoffs
and hallucinations. Recent work has explored reinforcement learning (RL) for
training search-augmented agents that interleave reasoning and retrieval before
answering. These approaches usually rely on outcome-based rewards (e.g., exact
match), implicitly assuming that optimizing for final answers will also yield
effective intermediate search behaviors. Our analysis challenges this
assumption: we uncover multiple systematic deficiencies in search that arise
under outcome-only training and ultimately degrade final answer quality,
including failure to invoke tools, invalid queries, and redundant searches. To
address these shortcomings, we introduce DeSA (Decoupling
Search-and-Answering), a simple two-stage training framework that explicitly
separates search optimization from answer generation. In Stage 1, agents are
trained to improve search effectiveness with retrieval recall-based rewards. In
Stage 2, outcome rewards are employed to optimize final answer generation.
Across seven QA benchmarks, DeSA-trained agents consistently improve search
behaviors, delivering substantially higher search recall and answer accuracy
than outcome-only baselines. Notably, DeSA outperforms single-stage training
approaches that simultaneously optimize recall and outcome rewards,
underscoring the necessity of explicitly decoupling the two objectives.

</details>


### [140] [BrokenMath: A Benchmark for Sycophancy in Theorem Proving with LLMs](https://arxiv.org/abs/2510.04721)
*Ivo Petrov,Jasper Dekoninck,Martin Vechev*

Main category: cs.AI

TL;DR: BrokenMath是首个评估LLM在自然语言定理证明中谄媚行为的基准，发现GPT-5等先进模型在29%的情况下会产生谄媚回答，测试时干预和监督微调可缓解但无法完全消除该问题。


<details>
  <summary>Details</summary>
Motivation: 现有数学基准主要关注最终答案问题，依赖简单且可能被污染的数据集，使用合成修改创建病态问题而非可证明错误的良构问题，无法有效评估LLM在定理证明中的谄媚行为。

Method: 基于2025年竞赛问题构建BrokenMath基准，使用LLM扰动产生错误陈述并通过专家审查精炼，采用LLM-as-a-judge框架评估先进LLM和代理系统。

Result: 发现谄媚行为普遍存在，最佳模型GPT-5在29%的情况下产生谄媚回答，测试时干预和监督微调可显著减少但无法完全消除谄媚行为。

Conclusion: LLM在数学定理证明中存在显著的谄媚倾向，需要开发更有效的缓解策略来提升其在数学推理中的可靠性。

Abstract: Large language models (LLMs) have recently shown strong performance on
mathematical benchmarks. At the same time, they are prone to hallucination and
sycophancy, often providing convincing but flawed proofs for incorrect
mathematical statements provided by users. This significantly limits the
applicability of LLMs in theorem proving, as verification of these flawed
proofs must be done manually by expert mathematicians. However, existing
benchmarks that measure sycophancy in mathematics are limited: they focus
solely on final-answer problems, rely on very simple and often contaminated
datasets, and construct benchmark samples using synthetic modifications that
create ill-posed questions rather than well-posed questions that are
demonstrably false. To address these issues, we introduce BrokenMath, the first
benchmark for evaluating sycophantic behavior in LLMs within the context of
natural language theorem proving. BrokenMath is built from advanced 2025
competition problems, which are perturbed with an LLM to produce false
statements and subsequently refined through expert review. Using an
LLM-as-a-judge framework, we evaluate state-of-the-art LLMs and agentic systems
and find that sycophancy is widespread, with the best model, GPT-5, producing
sycophantic answers 29% of the time. We further investigate several mitigation
strategies, including test-time interventions and supervised fine-tuning on
curated sycophantic examples. These approaches substantially reduce, but do not
eliminate, sycophantic behavior.

</details>


### [141] [LMM-Incentive: Large Multimodal Model-based Incentive Design for User-Generated Content in Web 3.0](https://arxiv.org/abs/2510.04765)
*Jinbo Wen,Jiawen Kang,Linfeng Zhang,Xiaoying Tang,Jianhang Tang,Yang Zhang,Zhaohui Yang,Dusit Niyato*

Main category: cs.AI

TL;DR: 提出了LMM-Incentive机制，基于大型多模态模型和合约理论，激励用户在Web 3.0中生成高质量用户生成内容，解决信息不对称问题。


<details>
  <summary>Details</summary>
Motivation: Web 3.0中用户可能利用内容策展机制的局限性生成低质量内容获取奖励，这会损害平台性能，需要解决信息不对称带来的逆向选择问题。

Method: 使用LMM代理评估UGC质量，采用提示工程技术提升评估性能；开发改进的MoE-based PPO算法进行最优合约设计；在以太坊智能合约框架中部署合约。

Result: 仿真结果表明，提出的MoE-based PPO算法在合约设计方面优于代表性基准方法，验证了所提方案的有效性。

Conclusion: LMM-Incentive机制能有效激励高质量UGC生成，缓解信息不对称问题，提升Web 3.0平台性能。

Abstract: Web 3.0 represents the next generation of the Internet, which is widely
recognized as a decentralized ecosystem that focuses on value expression and
data ownership. By leveraging blockchain and artificial intelligence
technologies, Web 3.0 offers unprecedented opportunities for users to create,
own, and monetize their content, thereby enabling User-Generated Content (UGC)
to an entirely new level. However, some self-interested users may exploit the
limitations of content curation mechanisms and generate low-quality content
with less effort, obtaining platform rewards under information asymmetry. Such
behavior can undermine Web 3.0 performance. To this end, we propose
\textit{LMM-Incentive}, a novel Large Multimodal Model (LMM)-based incentive
mechanism for UGC in Web 3.0. Specifically, we propose an LMM-based
contract-theoretic model to motivate users to generate high-quality UGC,
thereby mitigating the adverse selection problem from information asymmetry. To
alleviate potential moral hazards after contract selection, we leverage LMM
agents to evaluate UGC quality, which is the primary component of the contract,
utilizing prompt engineering techniques to improve the evaluation performance
of LMM agents. Recognizing that traditional contract design methods cannot
effectively adapt to the dynamic environment of Web 3.0, we develop an improved
Mixture of Experts (MoE)-based Proximal Policy Optimization (PPO) algorithm for
optimal contract design. Simulation results demonstrate the superiority of the
proposed MoE-based PPO algorithm over representative benchmarks in the context
of contract design. Finally, we deploy the designed contract within an Ethereum
smart contract framework, further validating the effectiveness of the proposed
scheme.

</details>


### [142] [Hybrid-Balance GFlowNet for Solving Vehicle Routing Problems](https://arxiv.org/abs/2510.04792)
*Ni Zhang,Zhiguang Cao*

Main category: cs.AI

TL;DR: 提出了混合平衡GFlowNet框架，将轨迹平衡和详细平衡有机结合，以解决车辆路径问题中全局优化和局部优化的平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有的GFlowNet方法在车辆路径问题中通常使用轨迹平衡实现全局优化，但忽视了局部优化的重要性。详细平衡虽然能更好地处理局部优化，但单独使用无法解决需要整体轨迹优化的车辆路径问题。

Method: 提出了混合平衡GFlowNet框架，以原则性和自适应方式整合轨迹平衡和详细平衡，利用它们内在的互补优势。同时针对以仓库为中心的场景设计了专门的推理策略。

Result: 将HBG集成到AGFN和GFACS两个现有GFlowNet求解器中，在CVRP和TSP问题上都实现了持续且显著的改进。

Conclusion: HBG框架通过整合轨迹平衡和详细平衡，显著提高了车辆路径问题的求解质量和泛化能力，并保持了广泛的适用性。

Abstract: Existing GFlowNet-based methods for vehicle routing problems (VRPs) typically
employ Trajectory Balance (TB) to achieve global optimization but often neglect
important aspects of local optimization. While Detailed Balance (DB) addresses
local optimization more effectively, it alone falls short in solving VRPs,
which inherently require holistic trajectory optimization. To address these
limitations, we introduce the Hybrid-Balance GFlowNet (HBG) framework, which
uniquely integrates TB and DB in a principled and adaptive manner by aligning
their intrinsically complementary strengths. Additionally, we propose a
specialized inference strategy for depot-centric scenarios like the Capacitated
Vehicle Routing Problem (CVRP), leveraging the depot node's greater flexibility
in selecting successors. Despite this specialization, HBG maintains broad
applicability, extending effectively to problems without explicit depots, such
as the Traveling Salesman Problem (TSP). We evaluate HBG by integrating it into
two established GFlowNet-based solvers, i.e., AGFN and GFACS, and demonstrate
consistent and significant improvements across both CVRP and TSP, underscoring
the enhanced solution quality and generalization afforded by our approach.

</details>


### [143] [Natural Language Edge Labelling: Decoupling Intent from Execution in Structured LM Reasoning](https://arxiv.org/abs/2510.04817)
*Abhinav Madahar*

Main category: cs.AI

TL;DR: NLEL是一种自然语言边缘标注框架，通过将自由形式的自然语言指令附加到搜索边缘，将其转换为模式受限的控制向量，从而解耦推理意图与执行过程。


<details>
  <summary>Details</summary>
Motivation: 现有的结构化LM推理控制器（如CoT、ToT）将'下一步尝试什么'与'如何执行'混在一起，只暴露粗粒度的全局控制，导致系统脆弱、计算效率低且难以审计。

Method: 引入标签器-调谐器覆盖层：标签器Λ从父状态和紧凑上下文中发出标签；调谐器Ψ将(P,L,C)映射到Π，具有严格的模式验证和安全默认值的信任区域投影。下游选择采用ToT风格，使用得分S=μ+βσ和深度退火β。

Result: 证明了NLEL严格泛化了CoT/ToT，为标签条件束下的top-k选择证明了任意时间单调性，并通过控制向量失真限制了选择器不足。

Conclusion: NLEL提供了一个可解释、模型无关的接口，将意图与执行分离，实现可控、可审计的LM推理。

Abstract: Controllers for structured LM reasoning (e.g., Chain-of-Thought,
self-consistency, and Tree-of-Thoughts) often entangle what to try next with
how to execute it, exposing only coarse global knobs and yielding brittle,
compute-inefficient, and hard-to-audit behavior. We introduce Natural Language
Edge Labelling (NLEL), a labeller-tuner overlay that attaches a free-form
natural-language directive to each search edge and translates it into a
schema-bounded control vector for decoding, search (branch quotas, exploration
$\beta$), generation bundle size, retrieval mixtures, and verification passes.
A labeller $\Lambda$ emits labels from the parent state and a compact context;
a tuner $\Psi$ maps $(P, L, C)\to \Pi$, with strict schema validation and
trust-region projection around safe defaults. Downstream selection remains
ToT-style with score $S=\mu+\beta\sigma$ and depth-annealed $\beta$. We show
NLEL strictly generalizes CoT/ToT, prove an anytime-monotonicity property for
top-$k$ selection under label-conditioned bundles, and bound selector shortfall
by control-vector distortion, providing decision-relevant justification for
guards like trust regions and verification passes. We instantiate $\Psi$ as a
prompt-only JSON Parameter Emitter and preregister an evaluation on GSM8K, MATH
(subset), StrategyQA, and ARC-Challenge with compute-aware reporting
(success@compute, tokens-per-success) and ablations over $\Lambda$, $\Psi$,
trust-region radius, and control quantization; preregistered forecasts
anticipate accuracy gains at comparable token budgets and improved
success@compute under constraints. NLEL offers an interpretable, model-agnostic
interface that separates intent from execution for controllable, auditable LM
inference.

</details>


### [144] [LEGOMem: Modular Procedural Memory for Multi-agent LLM Systems for Workflow Automation](https://arxiv.org/abs/2510.04851)
*Dongge Han,Camille Couturier,Daniel Madrigal Diaz,Xuchao Zhang,Victor Rühle,Saravan Rajmohan*

Main category: cs.AI

TL;DR: LEGOMem是一个用于多智能体工作流自动化的模块化程序性记忆框架，通过分解任务轨迹为可重用记忆单元，提升规划与执行能力。


<details>
  <summary>Details</summary>
Motivation: 探索多智能体系统中记忆的设计空间，研究记忆应该放置在何处、如何检索以及哪些智能体受益最多，以提升工作流自动化效果。

Method: 将过去任务轨迹分解为可重用记忆单元，灵活分配给编排器和任务智能体，支持规划和执行。在OfficeBench基准上进行实验验证。

Result: 编排器记忆对任务分解和委派至关重要，细粒度智能体记忆提高执行准确性。较小语言模型团队也能从程序性记忆中显著受益，缩小与更强智能体的性能差距。

Conclusion: LEGOMem既是记忆增强智能体系统的实用框架，也是理解多智能体工作流自动化中记忆设计的研究工具。

Abstract: We introduce LEGOMem, a modular procedural memory framework for multi-agent
large language model (LLM) systems in workflow automation. LEGOMem decomposes
past task trajectories into reusable memory units and flexibly allocates them
across orchestrators and task agents to support planning and execution. To
explore the design space of memory in multi-agent systems, we use LEGOMem as a
lens and conduct a systematic study of procedural memory in multi-agent
systems, examining where memory should be placed, how it should be retrieved,
and which agents benefit most. Experiments on the OfficeBench benchmark show
that orchestrator memory is critical for effective task decomposition and
delegation, while fine-grained agent memory improves execution accuracy. We
find that even teams composed of smaller language models can benefit
substantially from procedural memory, narrowing the performance gap with
stronger agents by leveraging prior execution traces for more accurate planning
and tool use. These results position LEGOMem as both a practical framework for
memory-augmented agent systems and a research tool for understanding memory
design in multi-agent workflow automation.

</details>


### [145] [Video Game Level Design as a Multi-Agent Reinforcement Learning Problem](https://arxiv.org/abs/2510.04862)
*Sam Earle,Zehua Jiang,Eugene Vinitsky,Julian Togelius*

Main category: cs.AI

TL;DR: 该论文提出将程序化内容生成重新定义为多智能体强化学习问题，通过分布式智能体协作来提升生成效率和对不同地图形状的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的单智能体PCGRL方法存在效率瓶颈，需要频繁重新计算启发式质量指标，且智能体需要在大型地图中导航。多智能体方法可以缓解这些限制。

Method: 将关卡生成问题重新构建为多智能体问题，通过分布式智能体协作减少奖励计算次数，并学习更局部化、模块化的设计策略。

Result: 多智能体关卡生成器在效率上优于单智能体方法，能够更好地泛化到分布外地图形状，学习到更局部化的设计策略。

Conclusion: 将内容生成视为分布式多智能体任务有利于大规模生成功能性内容，多智能体方法在效率和泛化能力方面具有优势。

Abstract: Procedural Content Generation via Reinforcement Learning (PCGRL) offers a
method for training controllable level designer agents without the need for
human datasets, using metrics that serve as proxies for level quality as
rewards. Existing PCGRL research focuses on single generator agents, but are
bottlenecked by the need to frequently recalculate heuristics of level quality
and the agent's need to navigate around potentially large maps. By framing
level generation as a multi-agent problem, we mitigate the efficiency
bottleneck of single-agent PCGRL by reducing the number of reward calculations
relative to the number of agent actions. We also find that multi-agent level
generators are better able to generalize to out-of-distribution map shapes,
which we argue is due to the generators' learning more local, modular design
policies. We conclude that treating content generation as a distributed,
multi-agent task is beneficial for generating functional artifacts at scale.

</details>


### [146] [Where Did It All Go Wrong? A Hierarchical Look into Multi-Agent Error Attribution](https://arxiv.org/abs/2510.04886)
*Adi Banerjee,Anirudh Nair,Tarik Borogovac*

Main category: cs.AI

TL;DR: ECHO算法通过层次化上下文表示、基于目标的分析评估和共识投票，显著提升了多智能体系统中错误归因的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统中错误归因方法在处理复杂交互模式时存在准确性和一致性问题，需要更有效的调试工具。

Method: 结合层次化上下文表示、基于目标的分析评估和共识投票机制，通过位置化层次理解上下文并保持客观评估标准。

Result: 实验表明ECHO在各种多智能体交互场景中优于现有方法，特别在处理微妙推理错误和复杂依赖关系时表现突出。

Conclusion: 结构化层次化上下文表示与基于共识的客观决策相结合，为多智能体系统错误归因提供了更鲁棒的框架。

Abstract: Error attribution in Large Language Model (LLM) multi-agent systems presents
a significant challenge in debugging and improving collaborative AI systems.
Current approaches to pinpointing agent and step level failures in interaction
traces - whether using all-at-once evaluation, step-by-step analysis, or binary
search - fall short when analyzing complex patterns, struggling with both
accuracy and consistency. We present ECHO (Error attribution through Contextual
Hierarchy and Objective consensus analysis), a novel algorithm that combines
hierarchical context representation, objective analysis-based evaluation, and
consensus voting to improve error attribution accuracy. Our approach leverages
a positional-based leveling of contextual understanding while maintaining
objective evaluation criteria, ultimately reaching conclusions through a
consensus mechanism. Experimental results demonstrate that ECHO outperforms
existing methods across various multi-agent interaction scenarios, showing
particular strength in cases involving subtle reasoning errors and complex
interdependencies. Our findings suggest that leveraging these concepts of
structured, hierarchical context representation combined with consensus-based
objective decision-making, provides a more robust framework for error
attribution in multi-agent systems.

</details>


### [147] [Human Behavior Atlas: Benchmarking Unified Psychological and Social Behavior Understanding](https://arxiv.org/abs/2510.04899)
*Keane Ong,Wei Dai,Carol Li,Dewei Feng,Hengzhi Li,Jingyao Wu,Jiaee Cheong,Rui Mao,Gianmarco Mengaldo,Erik Cambria,Paul Pu Liang*

Main category: cs.AI

TL;DR: 提出了Human Behavior Atlas统一基准，包含10万+多模态样本，用于开发理解心理和社会行为的统一模型。训练的三个OmniSapiens-7B模型在多样化行为任务上持续优于现有多模态LLM。


<details>
  <summary>Details</summary>
Motivation: 现有工作通过专用数据集和单任务系统处理心理社会行为维度，但缺乏可扩展性、跨任务迁移和泛化能力。需要统一基准来支持统一模型开发。

Method: 构建Human Behavior Atlas统一基准，包含文本、音频、视觉多模态数据，涵盖情感状态、认知状态、病理和社会过程等任务。训练三个OmniSapiens-7B模型：SFT、BAM和RL版本。

Result: 在Human Behavior Atlas上训练的模型在多样化行为任务上持续优于现有多模态LLM。预训练还改善了向新行为数据集的迁移，行为描述符的使用带来有意义的性能提升。

Conclusion: Human Behavior Atlas基准能够减少冗余和成本，实现跨任务高效训练，并增强行为特征在领域间的泛化能力，为理解心理社会行为提供了有效的统一框架。

Abstract: Using intelligent systems to perceive psychological and social behaviors,
that is, the underlying affective, cognitive, and pathological states that are
manifested through observable behaviors and social interactions, remains a
challenge due to their complex, multifaceted, and personalized nature. Existing
work tackling these dimensions through specialized datasets and single-task
systems often miss opportunities for scalability, cross-task transfer, and
broader generalization. To address this gap, we curate Human Behavior Atlas, a
unified benchmark of diverse behavioral tasks designed to support the
development of unified models for understanding psychological and social
behaviors. Human Behavior Atlas comprises over 100,000 samples spanning text,
audio, and visual modalities, covering tasks on affective states, cognitive
states, pathologies, and social processes. Our unification efforts can reduce
redundancy and cost, enable training to scale efficiently across tasks, and
enhance generalization of behavioral features across domains. On Human Behavior
Atlas, we train three models: OmniSapiens-7B SFT, OmniSapiens-7B BAM, and
OmniSapiens-7B RL. We show that training on Human Behavior Atlas enables models
to consistently outperform existing multimodal LLMs across diverse behavioral
tasks. Pretraining on Human Behavior Atlas also improves transfer to novel
behavioral datasets; with the targeted use of behavioral descriptors yielding
meaningful performance gains.

</details>


### [148] [MARS: Optimizing Dual-System Deep Research via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2510.04935)
*Guoxin Chen,Zile Qiao,Wenqing Wang,Donglei Yu,Xuanzhong Chen,Hao Sun,Minpeng Liao,Kai Fan,Yong Jiang,Penguin Xie,Wayne Xin Zhao,Ruihua Song,Fei Huang*

Main category: cs.AI

TL;DR: MARS是一个多智能体系统，通过整合System 1的快速直觉思维和System 2的深思熟虑推理来解决大语言模型在简单任务中过度分析的问题，并在动态信息环境中提升复杂推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决大推理模型在简单任务中过度使用System 2型推理导致的低效问题，以及由于预训练数据静态性而难以适应快速变化环境的挑战。

Method: 提出MARS多智能体系统，集成Google搜索、Google学术和Python解释器等外部工具，通过分工协作让System 1高效处理外部信息，为System 2提供精炼的推理上下文；采用多智能体强化学习框架优化两个系统的协作效率。

Result: 在Humanity's Last Exam基准上取得3.86%的显著提升，在7个知识密集型任务上平均获得8.9%的性能增益。

Conclusion: MARS的双系统范式在动态信息环境中有效提升了复杂推理能力，验证了直觉思维与深思熟虑推理整合的价值。

Abstract: Large Reasoning Models (LRMs) often exhibit a tendency for overanalysis in
simple tasks, where the models excessively utilize System 2-type, deliberate
reasoning, leading to inefficient token generation. Furthermore, these models
face challenges in adapting their reasoning capabilities to rapidly changing
environments due to the static nature of their pretraining data. To address
these issues, advancing Large Language Models (LLMs) for complex reasoning
tasks requires innovative approaches that bridge intuitive and deliberate
cognitive processes, akin to human cognition's dual-system dynamic. This paper
introduces a Multi-Agent System for Deep ReSearch (MARS) enabling seamless
integration of System 1's fast, intuitive thinking with System 2's deliberate
reasoning within LLMs. MARS strategically integrates multiple external tools,
such as Google Search, Google Scholar, and Python Interpreter, to access
up-to-date information and execute complex computations, while creating a
specialized division of labor where System 1 efficiently processes and
summarizes high-volume external information, providing distilled insights that
expand System 2's reasoning context without overwhelming its capacity.
Furthermore, we propose a multi-agent reinforcement learning framework
extending Group Relative Policy Optimization to simultaneously optimize both
systems with multi-turn tool interactions, bin-packing optimization, and sample
balancing strategies that enhance collaborative efficiency. Extensive
experiments demonstrate MARS achieves substantial improvements of 3.86% on the
challenging Humanity's Last Exam (HLE) benchmark and an average gain of 8.9%
across 7 knowledge-intensive tasks, validating the effectiveness of our
dual-system paradigm for complex reasoning in dynamic information environments.

</details>


### [149] [Safe and Compliant Cross-Market Trade Execution via Constrained RL and Zero-Knowledge Audits](https://arxiv.org/abs/2510.04952)
*Ailiya Borjigin,Cong He*

Main category: cs.AI

TL;DR: 提出一个跨市场算法交易系统，结合强化学习执行代理和独立合规代理，在保证执行质量的同时严格满足监管约束。


<details>
  <summary>Details</summary>
Motivation: 传统算法交易系统难以在追求执行质量的同时确保严格的合规性，特别是在多市场环境中需要处理参与限制、价格区间和自我交易避免等硬约束。

Method: 将交易执行建模为带硬约束的马尔可夫决策过程，使用近端策略优化训练执行代理，运行时通过动作屏蔽确保行动可行性，并添加零知识合规审计层提供可验证的合规证明。

Result: 在ABIDES多市场模拟器中，学习策略相比标准基准（如TWAP、VWAP）减少了执行差额和方差，在各种压力场景下均未观察到约束违反。

Conclusion: 该系统在最优执行、安全强化学习、监管技术和可验证AI的交叉领域提供了有前景的解决方案，但存在建模假设和计算开销等限制，需要进一步研究才能实现实际部署。

Abstract: We present a cross-market algorithmic trading system that balances execution
quality with rigorous compliance enforcement. The architecture comprises a
high-level planner, a reinforcement learning execution agent, and an
independent compliance agent. We formulate trade execution as a constrained
Markov decision process with hard constraints on participation limits, price
bands, and self-trading avoidance. The execution agent is trained with proximal
policy optimization, while a runtime action-shield projects any unsafe action
into a feasible set. To support auditability without exposing proprietary
signals, we add a zero-knowledge compliance audit layer that produces
cryptographic proofs that all actions satisfied the constraints. We evaluate in
a multi-venue, ABIDES-based simulator and compare against standard baselines
(e.g., TWAP, VWAP). The learned policy reduces implementation shortfall and
variance while exhibiting no observed constraint violations across stress
scenarios including elevated latency, partial fills, compliance module
toggling, and varying constraint limits. We report effects at the 95%
confidence level using paired t-tests and examine tail risk via CVaR. We
situate the work at the intersection of optimal execution, safe reinforcement
learning, regulatory technology, and verifiable AI, and discuss ethical
considerations, limitations (e.g., modeling assumptions and computational
overhead), and paths to real-world deployment.

</details>


### [150] [Aligning Perception, Reasoning, Modeling and Interaction: A Survey on Physical AI](https://arxiv.org/abs/2510.04978)
*Kun Xiang,Terry Jingchen Zhang,Yinya Huang,Jixi He,Zirong Liu,Yueling Tang,Ruizhe Zhou,Lijing Luo,Youpeng Wen,Xiuwei Chen,Bingqian Lin,Jianhua Han,Hang Xu,Hanhui Li,Bin Dong,Xiaodan Liang*

Main category: cs.AI

TL;DR: 该论文对物理AI领域进行了全面综述，区分了理论物理推理和应用物理理解，系统分析了物理基础方法如何提升AI在符号推理、具身系统和生成模型中的真实世界理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前物理感知和符号物理推理各自发展，缺乏统一的桥接框架，需要建立整合物理定律和具身推理的智能系统。

Method: 通过系统分析近期进展，建立物理AI的分类框架，考察物理基础方法在结构化符号推理、具身系统和生成模型中的应用。

Result: 提出了能够解释物理现象和预测未来状态的下一代世界模型，推进安全、可泛化和可解释的AI系统发展。

Conclusion: 需要开发既基于物理原理又结合具身推理过程的智能系统，超越模式识别，实现物理定律的真正理解。

Abstract: The rapid advancement of embodied intelligence and world models has
intensified efforts to integrate physical laws into AI systems, yet physical
perception and symbolic physics reasoning have developed along separate
trajectories without a unified bridging framework. This work provides a
comprehensive overview of physical AI, establishing clear distinctions between
theoretical physics reasoning and applied physical understanding while
systematically examining how physics-grounded methods enhance AI's real-world
comprehension across structured symbolic reasoning, embodied systems, and
generative models. Through rigorous analysis of recent advances, we advocate
for intelligent systems that ground learning in both physical principles and
embodied reasoning processes, transcending pattern recognition toward genuine
understanding of physical laws. Our synthesis envisions next-generation world
models capable of explaining physical phenomena and predicting future states,
advancing safe, generalizable, and interpretable AI systems. We maintain a
continuously updated resource at
https://github.com/AI4Phys/Awesome-AI-for-Physics.

</details>


### [151] [LLM-Hanabi: Evaluating Multi-Agent Gameplays with Theory-of-Mind and Rationale Inference in Imperfect Information Collaboration Game](https://arxiv.org/abs/2510.04980)
*Fangzhou Liang,Tianshi Zheng,Chunkit Chan,Yauwai Yim,Yangqiu Song*

Main category: cs.AI

TL;DR: LLM-Hanabi基准测试显示，心智理论能力与多智能体协作表现正相关，其中一阶心智理论（理解他人意图）比二阶心智理论（预测他人理解）对游戏成功更重要。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在动态协作环境中推断他人行为动机的心智理论能力，这在多智能体协作中至关重要但研究不足。

Method: 使用合作游戏Hanabi构建LLM-Hanabi基准，通过自动化评估系统同时测量游戏表现和心智理论熟练度。

Result: 发现心智理论与游戏成功显著正相关，一阶心智理论比二阶心智理论与表现的相关性更强。

Conclusion: 对于有效的AI协作，准确解释伙伴动机的能力比高阶推理更重要，优先发展一阶心智理论是提升模型协作能力的有前景方向。

Abstract: Effective multi-agent collaboration requires agents to infer the rationale
behind others' actions, a capability rooted in Theory-of-Mind (ToM). While
recent Large Language Models (LLMs) excel at logical inference, their ability
to infer rationale in dynamic, collaborative settings remains under-explored.
This study introduces LLM-Hanabi, a novel benchmark that uses the cooperative
game Hanabi to evaluate the rationale inference and ToM of LLMs. Our framework
features an automated evaluation system that measures both game performance and
ToM proficiency. Across a range of models, we find a significant positive
correlation between ToM and in-game success. Notably, first-order ToM
(interpreting others' intent) correlates more strongly with performance than
second-order ToM (predicting others' interpretations). These findings highlight
that for effective AI collaboration, the ability to accurately interpret a
partner's rationale is more critical than higher-order reasoning. We conclude
that prioritizing first-order ToM is a promising direction for enhancing the
collaborative capabilities of future models.

</details>


### [152] [Think Then Embed: Generative Context Improves Multimodal Embedding](https://arxiv.org/abs/2510.05014)
*Xuanming Cui,Jianpeng Cheng,Hong-you Chen,Satya Narayan Shukla,Abhijeet Awasthi,Xichen Pan,Chaitanya Ahuja,Shlok Kumar Mishra,Qi Guo,Ser-Nam Lim,Aashu Singh,Xiangjun Fan*

Main category: cs.AI

TL;DR: 提出了Think-Then-Embed框架，利用MLLM的推理能力生成解释复杂查询的推理轨迹，然后由嵌入器基于原始查询和中间推理生成表示，在MMEB-V2基准上取得最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅将MLLM作为编码器，忽视了其生成能力，在处理复杂指令和组合推理时效果不佳。受思维链推理启发，需要显式推理步骤来更好地理解复杂多模态指令。

Method: TTE框架包含推理器和嵌入器：推理器MLLM生成解释复杂查询的推理轨迹，嵌入器基于原始查询和中间推理生成表示。还研究了将两者集成到统一模型中的策略。

Result: 在MMEB-V2基准上实现最先进性能，超越基于大规模内部数据集训练的专有模型。微调较小MLLM推理器获得开源模型中最佳性能，比近期模型提升7%。

Conclusion: TTE框架通过显式推理步骤显著提升了复杂多模态指令的理解能力，证明了利用MLLM生成能力进行推理的有效性，同时提供了高效的集成方案。

Abstract: There is a growing interest in Universal Multimodal Embeddings (UME), where
models are required to generate task-specific representations. While recent
studies show that Multimodal Large Language Models (MLLMs) perform well on such
tasks, they treat MLLMs solely as encoders, overlooking their generative
capacity. However, such an encoding paradigm becomes less effective as
instructions become more complex and require compositional reasoning. Inspired
by the proven effectiveness of chain-of-thought reasoning, we propose a general
Think-Then-Embed (TTE) framework for UME, composed of a reasoner and an
embedder. The reasoner MLLM first generates reasoning traces that explain
complex queries, followed by an embedder that produces representations
conditioned on both the original query and the intermediate reasoning. This
explicit reasoning step enables more nuanced understanding of complex
multimodal instructions. Our contributions are threefold. First, by leveraging
a powerful MLLM reasoner, we achieve state-of-the-art performance on the
MMEB-V2 benchmark, surpassing proprietary models trained on massive in-house
datasets. Second, to reduce the dependency on large MLLM reasoners, we finetune
a smaller MLLM reasoner using high-quality embedding-centric reasoning traces,
achieving the best performance among open-source models with a 7% absolute gain
over recently proposed models. Third, we investigate strategies for integrating
the reasoner and embedder into a unified model for improved efficiency without
sacrificing performance.

</details>


### [153] [Look-ahead Reasoning with a Learned Model in Imperfect Information Games](https://arxiv.org/abs/2510.05048)
*Ondřej Kubíček,Viliam Lisý*

Main category: cs.AI

TL;DR: LAMIR算法通过学习不完全信息游戏的抽象模型，使预训练AI代理能够进行前瞻推理，解决了传统方法在大型游戏中难以扩展的问题。


<details>
  <summary>Details</summary>
Motivation: 现有测试时推理方法需要明确的环境模型，但在不完全信息游戏中，由于状态空间庞大和前瞻推理技术复杂，这种方法难以扩展。

Method: LAMIR直接从代理-环境交互中学习不完全信息游戏的抽象模型，通过学习的抽象将每个子游戏限制在可管理的大小，使理论上有原则的前瞻推理变得可行。

Result: 实验表明，在足够容量下，LAMIR能学习到精确的底层游戏结构；在有限容量下，仍能学习到有价值的抽象，提升预训练代理在大型游戏中的表现。

Conclusion: LAMIR通过学习游戏抽象模型，使不完全信息游戏中的前瞻推理变得可行，显著提升了预训练AI代理的性能，特别是在大型游戏中。

Abstract: Test-time reasoning significantly enhances pre-trained AI agents'
performance. However, it requires an explicit environment model, often
unavailable or overly complex in real-world scenarios. While MuZero enables
effective model learning for search in perfect information games, extending
this paradigm to imperfect information games presents substantial challenges
due to more nuanced look-ahead reasoning techniques and large number of states
relevant for individual decisions. This paper introduces an algorithm LAMIR
that learns an abstracted model of an imperfect information game directly from
the agent-environment interaction. During test time, this trained model is used
to perform look-ahead reasoning. The learned abstraction limits the size of
each subgame to a manageable size, making theoretically principled look-ahead
reasoning tractable even in games where previous methods could not scale. We
empirically demonstrate that with sufficient capacity, LAMIR learns the exact
underlying game structure, and with limited capacity, it still learns a
valuable abstraction, which improves game playing performance of the
pre-trained agents even in large games.

</details>


### [154] [Staircase Streaming for Low-Latency Multi-Agent Inference](https://arxiv.org/abs/2510.05059)
*Junlin Wang,Jue Wang,Zhen,Xu,Ben Athiwaratkun,Bhuwan Dhingra,Ce Zhang,James Zou*

Main category: cs.AI

TL;DR: 提出阶梯式流处理方法来降低多智能体推理的首次令牌时间(TTFT)，通过部分输出立即开始生成最终响应，而不是等待完整中间输出。


<details>
  <summary>Details</summary>
Motivation: 多智能体推理虽然能提高响应质量，但显著增加了首次令牌时间，这对延迟敏感的应用构成挑战并影响用户体验。

Method: 阶梯式流处理：一旦收到前一步骤的部分输出，就立即开始生成最终响应，而不是等待完整的中间输出。

Result: 实验结果显示阶梯式流处理将TTFT降低了高达93%，同时保持了响应质量。

Conclusion: 阶梯式流处理是一种有效的低延迟多智能体推理方法，能显著减少响应延迟而不牺牲质量。

Abstract: Recent advances in large language models (LLMs) opened up new directions for
leveraging the collective expertise of multiple LLMs. These methods, such as
Mixture-of-Agents, typically employ additional inference steps to generate
intermediate outputs, which are then used to produce the final response. While
multi-agent inference can enhance response quality, it can significantly
increase the time to first token (TTFT), posing a challenge for
latency-sensitive applications and hurting user experience. To address this
issue, we propose staircase streaming for low-latency multi-agent inference.
Instead of waiting for the complete intermediate outputs from previous steps,
we begin generating the final response as soon as we receive partial outputs
from these steps. Experimental results demonstrate that staircase streaming
reduces TTFT by up to 93% while maintaining response quality.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [155] [Generalization and the Rise of System-level Creativity in Science](https://arxiv.org/abs/2510.03240)
*Hongbo Fang,James Evans*

Main category: cs.SI

TL;DR: 本文开发了新指标来分解创新的影响力，发现虽然领域内基础性和扩展性工作有所减少，但跨领域综合创新在增加，创新重心正从领域内转向整个系统层面。


<details>
  <summary>Details</summary>
Motivation: 创新生态系统需要政策引导来推动人类健康、福利、安全和繁荣的持续进步，需要更好地理解不同类型创新的影响。

Method: 开发新指标来可靠分解创新的影响力，将创新分为领域基础、基础工作扩展、以及跨领域综合创新三类，使用2300万篇科学文献进行分析。

Result: 发现领域内基础性和扩展性工作在减少，但跨领域综合创新随着网络、社交媒体和人工智能的兴起而增加和加速，创新重心从领域内转向整个系统。

Conclusion: 创新模式正在转变，从领域内创新转向跨系统创新，这对科学政策具有重要启示。

Abstract: Innovation ecosystems require careful policy stewardship to drive sustained
advance in human health, welfare, security and prosperity. We develop new
measures that reliably decompose the influence of innovations in terms of the
degree to which each represents a field-level foundation, an extension of
foundational work, or a generalization that synthesizes and modularizes
contributions from distant fields to catalyze combinatorial innovation. Using
23 million scientific works, we demonstrate that while foundational and
extensional work within fields has declined in recent years-a trend garnering
much recent attention-generalizations across fields have increased and
accelerated with the rise of the web, social media, and artificial
intelligence, shifting the locus of innovation from within fields to across the
system as a whole. We explore implications for science policy.

</details>


### [156] [Fair Minimum Labeling: Efficient Temporal Network Activations for Reachability and Equity](https://arxiv.org/abs/2510.03899)
*Lutz Oettershagen,Othon Michail*

Main category: cs.SI

TL;DR: 提出了公平最小标记（FML）问题，旨在设计最小成本的时序边激活计划，确保网络中每个节点组都能公平访问目标集，平衡资源效率和公平性。


<details>
  <summary>Details</summary>
Motivation: 在支持现代学习应用的网络系统中，平衡资源效率和公平性至关重要。FML问题捕捉了在边缘激活产生资源成本且需要公平访问的系统中的关键权衡。

Method: 证明了FML问题是NP难且近似难度为Ω(log|V|)，提出了概率近似算法来匹配这个界限，实现激活成本的最佳可能保证。

Result: 在公平多源数据聚合任务中的实证结果表明，FML能够以显著低于基准启发式方法的激活成本强制执行组级公平性。

Conclusion: FML在构建学习集成网络中资源高效、公平的时序可达性方面具有巨大潜力。

Abstract: Balancing resource efficiency and fairness is critical in networked systems
that support modern learning applications. We introduce the Fair Minimum
Labeling (FML) problem: the task of designing a minimum-cost temporal edge
activation plan that ensures each group of nodes in a network has sufficient
access to a designated target set, according to specified coverage
requirements. FML captures key trade-offs in systems where edge activations
incur resource costs and equitable access is essential, such as distributed
data collection, update dissemination in edge-cloud systems, and fair service
restoration in critical infrastructure. We show that FML is NP-hard and
$\Omega(\log |V|)$-hard to approximate, and we present probabilistic
approximation algorithms that match this bound, achieving the best possible
guarantee for the activation cost. We demonstrate the practical utility of FML
in a fair multi-source data aggregation task for training a shared model.
Empirical results show that FML enforces group-level fairness with
substantially lower activation cost than baseline heuristics, underscoring its
potential for building resource-efficient, equitable temporal reachability in
learning-integrated networks.

</details>


### [157] [Deep learning framework for predicting stochastic take-off and die-out of early spreading](https://arxiv.org/abs/2510.04574)
*Wenchao He,Tao Jia*

Main category: cs.SI

TL;DR: 提出了首个预测早期疫情爆发是否会升级为大流行或自然消亡的深度学习框架，通过预训练-微调方法解决早期数据稀疏问题。


<details>
  <summary>Details</summary>
Motivation: 解决早期疫情爆发预测的挑战，因为在爆发初期数据不足且现有模型主要关注大流行的平均行为而非小传播链的随机性。

Method: 使用随机传播模型的广泛数据开发深度学习框架，采用预训练-微调方法，利用多样化模拟数据进行预训练，然后针对特定场景进行微调。

Result: 在Erdős-Rényi和Barabási-Albert网络上的验证表明，该方法能在潜在爆发前准确预测随机传播事件，在不同网络结构和传染性场景下表现稳健。

Conclusion: 这是首个预测随机爆发与消亡的框架，为流行病准备和公共卫生决策提供宝贵见解，支持更明智的早期干预策略。

Abstract: Large-scale outbreaks of epidemics, misinformation, or other harmful
contagions pose significant threats to human society, yet the fundamental
question of whether an emerging outbreak will escalate into a major epidemic or
naturally die out remains largely unaddressed. This problem is challenging,
partially due to inadequate data during the early stages of outbreaks and also
because established models focus on average behaviors of large epidemics rather
than the stochastic nature of small transmission chains. Here, we introduce the
first systematic framework for forecasting whether initial transmission events
will amplify into major outbreaks or fade into extinction during early stages,
when intervention strategies can still be effectively implemented. Using
extensive data from stochastic spreading models, we developed a deep learning
framework that predicts early-stage spreading outcomes in real-time. Validation
across Erd\H{o}s-R\'enyi and Barab\'asi-Albert networks with varying
infectivity levels shows our method accurately forecasts stochastic spreading
events well before potential outbreaks, demonstrating robust performance across
different network structures and infectivity scenarios.To address the challenge
of sparse data during early outbreak stages, we further propose a
pretrain-finetune framework that leverages diverse simulation data for
pretraining and adapts to specific scenarios through targeted fine-tuning. The
pretrain-finetune framework consistently outperforms baseline models, achieving
superior performance even when trained on limited scenario-specific data. To
our knowledge, this work presents the first framework for predicting stochastic
take-off versus die-out. This framework provides valuable insights for epidemic
preparedness and public health decision-making, enabling more informed early
intervention strategies.

</details>


### [158] [Higher-Order Network Structure Inference: A Topological Approach to Network Selection](https://arxiv.org/abs/2510.04884)
*Adam Schroeder,Russell Funk,Jingyi Guan,Taylor Okonek,Lori Ziegelmeier*

Main category: cs.SI

TL;DR: 提出了一种基于拓扑数据分析的系统性阈值选择算法，通过考虑高阶结构关系来识别最优网络参数，解决了传统阈值方法依赖启发式方法和忽略高阶交互的问题。


<details>
  <summary>Details</summary>
Motivation: 现有网络阈值方法存在两个主要局限：阈值选择依赖启发式方法或试错，导致对参数变化敏感；大多数方法只关注节点间的成对关系，忽略了三个或更多节点间的高阶交互。

Method: 使用持久同调计算参数空间中同调特征的稳定性，识别对微小变化鲁棒且能保留有意义拓扑结构的参数选择。通过超参数允许用户指定拓扑特征的最低要求，有效约束参数搜索避免虚假解。

Result: 在科学科学领域的应用中，从研究论文摘要中提取科学概念网络，当概念在同一摘要中共同出现时建立连接，验证了方法的有效性。

Conclusion: 该方法不仅适用于网络阈值选择，还能扩展到数据分析中的一般参数化问题，具有灵活性，允许研究人员融入领域特定的约束。

Abstract: Thresholding--the pruning of nodes or edges based on their properties or
weights--is an essential preprocessing tool for extracting interpretable
structure from complex network data, yet existing methods face several key
limitations. Threshold selection often relies on heuristic methods or trial and
error due to large parameter spaces and unclear optimization criteria, leading
to sensitivity where small parameter variations produce significant changes in
network structure. Moreover, most approaches focus on pairwise relationships
between nodes, overlooking critical higher-order interactions involving three
or more nodes. We introduce a systematic thresholding algorithm that leverages
topological data analysis to identify optimal network parameters by accounting
for higher-order structural relationships. Our method uses persistent homology
to compute the stability of homological features across the parameter space,
identifying parameter choices that are robust to small variations while
preserving meaningful topological structure. Hyperparameters allow users to
specify minimum requirements for topological features, effectively constraining
the parameter search to avoid spurious solutions. We demonstrate the approach
with an application in the Science of Science, where networks of scientific
concepts are extracted from research paper abstracts, and concepts are
connected when they co-appear in the same abstract. The flexibility of our
approach allows researchers to incorporate domain-specific constraints and
extends beyond network thresholding to general parameterization problems in
data analysis.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [159] [Efficient MPC-Based Energy Management System for Secure and Cost-Effective Microgrid Operations](https://arxiv.org/abs/2510.03241)
*Hanyang He,John Harlim,Daning Huang,Yan Li*

Main category: eess.SY

TL;DR: 提出了一种高效的MPC能量管理系统，通过二阶锥规划分支流松弛来考虑功率损耗和电网安全约束，结合在线需求响应实现削峰降本。


<details>
  <summary>Details</summary>
Motivation: 传统MPC能量管理系统采用简化的功率平衡模型，在大规模系统中无法准确考虑电网功率损耗和安全约束的影响，需要更详细的模型来保证系统可靠性和经济性。

Method: 将二阶锥规划分支流松弛集成到约束集中，形成凸优化问题；基于此设计在线需求响应模块进行削峰；在径向拓扑微电网中保证松弛的紧致性。

Result: 在10、18、33总线系统上验证有效，实现了安全运行、有效削峰和总成本降低，计算效率高适合在线实施。

Conclusion: 该框架首次在统一架构中同时建模损耗和安全约束并协调柔性负荷，为大规模微电网提供了高效可靠的MPC能量管理解决方案。

Abstract: Model predictive control (MPC)-based energy management systems (EMS) are
essential for ensuring optimal, secure, and stable operation in microgrids with
high penetrations of distributed energy resources. However, due to the high
computational cost for the decision-making, the conventional MPC-based EMS
typically adopts a simplified integrated-bus power balance model. While this
simplification is effective for small networks, large-scale systems require a
more detailed branch flow model to account for the increased impact of grid
power losses and security constraints. This work proposes an efficient and
reliable MPC-based EMS that incorporates power-loss effects and grid-security
constraints. %, while adaptively shaping the battery power profile in response
to online renewable inputs, achieving reduced operational costs. It enhances
system reliability, reduces operational costs, and shows strong potential for
online implementation due to its reduced computational effort. Specifically, a
second-order cone program (SOCP) branch flow relaxation is integrated into the
constraint set, yielding a convex formulation that guarantees globally optimal
solutions with high computational efficiency. Owing to the radial topology of
the microgrid, this relaxation is practically tight, ensuring equivalence to
the original problem. Building on this foundation, an online demand response
(DR) module is designed to further reduce the operation cost through peak
shaving. To the best of our knowledge, no prior MPC-EMS framework has
simultaneously modeled losses and security constraints while coordinating
flexible loads within a unified architecture. The developed framework enables
secure operation with effective peak shaving and reduced total cost. The
effectiveness of the proposed method is validated on 10-bus, 18-bus, and 33-bus
systems.

</details>


### [160] [On Architectures for Combining Reinforcement Learning and Model Predictive Control with Runtime Improvements](https://arxiv.org/abs/2510.03354)
*Xiaolong Jia,Nikhil Bajaj*

Main category: eess.SY

TL;DR: 提出两种结合神经网络近似MPC与强化学习的架构，在旋转倒立摆上实现99%以上运行时减少，并在模型不确定性下提升跟踪性能


<details>
  <summary>Details</summary>
Motivation: 解决MPC计算需求高和模型不准确导致的性能下降问题

Method: 1. Warm Start RL：用预训练NNMPC权重初始化RL actor；2. RLMPC：用RL生成NNMPC输出的校正残差；3. 引入降采样方法减少NNMPC输入维度

Result: 相比传统MPC，运行时减少超过99%，在模型不确定性下跟踪性能提升，RL+MPC实现11-40%成本降低

Conclusion: NNMPC与RL的结合架构能显著减少计算需求并提升鲁棒性

Abstract: Model Predictive Control (MPC) faces computational demands and performance
degradation from model inaccuracies. We propose two architectures combining
Neural Network-approximated MPC (NNMPC) with Reinforcement Learning (RL). The
first, Warm Start RL, initializes the RL actor with pre-trained NNMPC weights.
The second, RLMPC, uses RL to generate corrective residuals for NNMPC outputs.
We introduce a downsampling method reducing NNMPC input dimensions while
maintaining performance. Evaluated on a rotary inverted pendulum, both
architectures demonstrate runtime reductions exceeding 99% compared to
traditional MPC while improving tracking performance under model uncertainties,
with RL+MPC achieving 11-40% cost reduction depending on reference amplitude.

</details>


### [161] [Viability-Preserving Passive Torque Control](https://arxiv.org/abs/2510.03367)
*Zizhe Zhang,Yicong Wang,Zhiquan Zhang,Tianyu Li,Nadia Figueroa*

Main category: eess.SY

TL;DR: 本文提出了一种基于生存性理论的机器人安全控制方法，通过预计算状态空间中的安全集合，结合二次规划约束被动控制器，确保机器人在无限时间范围内保持安全状态。


<details>
  <summary>Details</summary>
Motivation: 传统的基于被动性的扭矩控制器通常无约束，在外部扰动下可能导致安全违规。需要一种能确保机器人状态始终保持在安全区域的控制方法。

Method: 使用生存性理论预计算关节位置和速度状态空间中的安全集合，通过数据驱动和解析方法构建自碰撞避免、外部物体碰撞避免以及关节位置和速度限制的可行集合，基于二次规划的控制器在被动控制器上施加这些约束。

Result: 在7自由度Franka Emika机械臂上的仿真和硬件实验验证了该方法，相比基线约束被动控制器，能以更高的控制回路频率运行并产生更平滑的轨迹。

Conclusion: 所提出的方法能够有效确保机器人在无限时间范围内保持安全状态，同时提供更高的控制性能和更平滑的运动轨迹。

Abstract: Conventional passivity-based torque controllers for manipulators are
typically unconstrained, which can lead to safety violations under external
perturbations. In this paper, we employ viability theory to pre-compute safe
sets in the state-space of joint positions and velocities. These viable sets,
constructed via data-driven and analytical methods for self-collision
avoidance, external object collision avoidance and joint-position and
joint-velocity limits, provide constraints on joint accelerations and thus
joint torques via the robot dynamics. A quadratic programming-based control
framework enforces these constraints on a passive controller tracking a
dynamical system, ensuring the robot states remain within the safe set in an
infinite time horizon. We validate the proposed approach through simulations
and hardware experiments on a 7-DoF Franka Emika manipulator. In comparison to
a baseline constrained passive controller, our method operates at higher
control-loop rates and yields smoother trajectories.

</details>


### [162] [Machine Learning-Driven Prediction of Lithium-Ion Battery Power Capability for eVTOL Aircraft](https://arxiv.org/abs/2510.03497)
*Hao Tu,Yebin Wang,Shaoshuai Mou,Huazhen Fang*

Main category: eess.SY

TL;DR: 本文提出了一种用于电动垂直起降飞机(eVTOL)的电池功率限制预测方法，结合物理模型和机器学习来准确预测锂电池在高放电率下的电压和温度行为，并加速最大功率搜索过程。


<details>
  <summary>Details</summary>
Motivation: eVTOL飞机在飞行过程中需要高放电率的电池系统，但锂电池的电热动力学复杂，且需要考虑长预测时间范围和紧急着陆的可能性，这给电池功率能力预测带来了技术挑战。

Method: 采用结合物理学和机器学习的动态模型来预测锂电池的电压和温度行为；同时利用机器学习预测剩余放电时间，以加速最大功率搜索过程。

Result: 验证结果表明，所提出的方法对eVTOL操作有效。

Conclusion: 该研究首次为eVTOL制定了考虑长预测时间范围和紧急着陆可能性的功率限制预测问题，并通过机器学习方法成功解决了这一问题。

Abstract: Electric vertical take-off and landing (eVTOL) aircraft have emerged as a
promising solution to transform urban transportation. They present a few
technical challenges for battery management, a prominent one of which is the
prediction of the power capability of their lithium-ion battery systems. The
challenge originates from the high C-rate discharging conditions required
during eVTOL flights as well as the complexity of lithium-ion batteries'
electro-thermal dynamics. This paper, for the first time, formulates a power
limit prediction problem for eVTOL which explicitly considers long prediction
horizons and the possible occurrence of emergency landings. We then harness
machine learning to solve this problem in two intertwined ways. First, we adopt
a dynamic model that integrates physics with machine learning to predict a
lithium-ion battery's voltage and temperature behaviors with high accuracy.
Second, while performing search for the maximum power, we leverage machine
learning to predict the remaining discharge time and use the prediction to
accelerate the search with fast computation. Our validation results show the
effectiveness of the proposed study for eVTOL operations.

</details>


### [163] [Learning Safety-Compatible Observers for Unknown Systems](https://arxiv.org/abs/2510.03609)
*Juho Bae,Daegyeong Roh,Han-Lim Choi*

Main category: eess.SY

TL;DR: 本文提出了一种数据驱动的方法，用于联合学习具有未知动力学系统的鲁棒全状态观测器及其鲁棒性证书。


<details>
  <summary>Details</summary>
Motivation: 针对具有未知动力学的系统，需要开发能够提供鲁棒性保证的状态观测器，以便与基于证书的安全控制器兼容使用。

Method: 利用增量输入到状态稳定性概念，联合学习增量ISS李雅普诺夫函数作为鲁棒性证书，并在学习模型满足标准保真度假设下证明估计误差的实际收敛性。

Result: 该方法使得观测器具有安全兼容性，能够被基于证书的安全控制器使用，并且通过小增益定理扩展到互联系统，实现了分布式观测器设计框架。

Conclusion: 所提出的方法在多种非线性系统上得到了验证，为未知动力学系统的安全状态估计提供了有效解决方案。

Abstract: This paper presents a data-driven approach for jointly learning a robust
full-state observer and its robustness certificate for systems with unknown
dynamics. Leveraging incremental input-to-state stability (delta ISS) notions,
we jointly learn a delta ISS Lyapunov function that serves as the robustness
certificate and prove practical convergence of the estimation error under
standard fidelity assumptions on the learned models. This renders the observer
safety-compatible: they can be consumed by certificate-based safe controllers
so that, when the controller tolerates bounded estimation error, the
controller's certificate remains valid under output feedback. We further extend
the approach to interconnected systems via the small-gain theorem, yielding a
distributed observer design framework. We validate the approach on a variety of
nonlinear systems.

</details>


### [164] [Cyber Resilience of Three-phase Unbalanced Distribution System Restoration under Sparse Adversarial Attack on Load Forecasting](https://arxiv.org/abs/2510.03635)
*Chen Chao,Zixiao Ma,Ziang Zhang*

Main category: eess.SY

TL;DR: 本文量化了对抗性操纵的负荷预测对电力系统恢复可行性和电网安全的影响，开发了一种基于梯度的稀疏对抗攻击方法，并建立了恢复感知的验证框架。


<details>
  <summary>Details</summary>
Motivation: 电力系统恢复对电网韧性至关重要，但其对基于AI的负荷预测的依赖引入了网络安全风险，而恢复过程对此类攻击的韧性尚未得到充分研究。

Method: 开发梯度稀疏对抗攻击策略扰动关键时空输入，建立恢复感知验证框架将受损预测嵌入顺序恢复模型，使用不平衡三相最优潮流公式评估运行可行性。

Result: 模拟结果显示该方法比基线攻击更高效和隐蔽，揭示了系统级故障，如电压和功率爬坡违规，阻碍关键负荷的恢复。

Conclusion: 这些发现为设计网络安全感知的恢复规划框架提供了可行见解。

Abstract: System restoration is critical for power system resilience, nonetheless, its
growing reliance on artificial intelligence (AI)-based load forecasting
introduces significant cybersecurity risks. Inaccurate forecasts can lead to
infeasible planning, voltage and frequency violations, and unsuccessful
recovery of de-energized segments, yet the resilience of restoration processes
to such attacks remains largely unexplored. This paper addresses this gap by
quantifying how adversarially manipulated forecasts impact restoration
feasibility and grid security. We develop a gradient-based sparse adversarial
attack that strategically perturbs the most influential spatiotemporal inputs,
exposing vulnerabilities in forecasting models while maintaining stealth. We
further create a restoration-aware validation framework that embeds these
compromised forecasts into a sequential restoration model and evaluates
operational feasibility using an unbalanced three-phase optimal power flow
formulation. Simulation results show that the proposed approach is more
efficient and stealthier than baseline attacks. It reveals system-level
failures, such as voltage and power ramping violations that prevent the
restoration of critical loads. These findings provide actionable insights for
designing cybersecurity-aware restoration planning frameworks.

</details>


### [165] [Optimal Energy Management in Indoor Farming Using Lighting Flexibility and Intelligent Model Predictive Control](https://arxiv.org/abs/2510.03686)
*Mohammadjavad Abbaspour,Mukund R. Shukla,Praveen K. Saxena,Shivam Saxena*

Main category: eess.SY

TL;DR: 提出了一种用于室内农业的优化照明控制策略，通过调节光照强度和光周期来降低能源成本，结合模型预测控制和变压器神经网络进行预测，在保持植物健康的同时显著减少能源消耗和成本。


<details>
  <summary>Details</summary>
Motivation: 室内农业依赖人工照明导致能源消耗、峰值负荷和能源成本显著增加，需要开发智能照明控制策略来提高可持续性和经济可行性。

Method: 采用模型预测控制框架，结合变压器神经网络预测24小时前的太阳辐射和电价，通过真实生菜作物实验确定最小光照需求和适当的光暗间隔作为约束条件。

Result: 基于安大略省真实电力市场数据的模拟显示，相比基准方案，每年成本减少318,400美元（20.9%），峰值负荷降低1.6兆瓦（33.32%），总能耗节约1890兆瓦时（20.2%）。

Conclusion: 智能照明控制有潜力显著提高室内农业的可持续性和经济可行性，通过优化光照调度实现显著的能源成本节约。

Abstract: Indoor farming enables year-round food production but its reliance on
artificial lighting significantly increases energy consumption, peak load
charges, and energy costs for growers. Recent studies indicate that plants are
able to tolerate interruptions in light, enabling the design of 24-hour
lighting schedules (or "recipes") with strategic light modulation in alignment
with day-ahead pricing. Thus, we propose an optimal lighting control strategy
for indoor farming that modulates light intensity and photoperiod to reduce
energy costs. The control strategy is implemented within a model predictive
control framework and augmented with transformer-based neural networks to
forecast 24-hour ahead solar radiation and electricity prices to improve energy
cost reduction. The control strategy is informed by real-world experimentation
on lettuce crops to discover minimum light exposure and appropriate dark-light
intervals, which are mathematically formulated as constraints to maintain plant
health. Simulations for a one-hectare greenhouse, based on real electricity
market data from Ontario, demonstrate an annual cost reduction of $318,400
(20.9%), a peak load decrease of 1.6 MW (33.32%), and total energy savings of
1890 MWh (20.2%) against a baseline recipe. These findings highlight the
potential of intelligent lighting control to improve the sustainability and
economic feasibility of indoor farming.

</details>


### [166] [On the Duality Between Quantized Time and States in Dynamic Simulation](https://arxiv.org/abs/2510.03785)
*Liya Huang,Georgios Tzounas*

Main category: eess.SY

TL;DR: 本文揭示了离散时间与量化状态数值方法之间的形式对偶性，将QSS方法解释为应用于系统模型对偶形式的积分方案，其中时间被视为状态相关变量。


<details>
  <summary>Details</summary>
Motivation: 通过建立离散时间与量化状态方法之间的对偶关系，为开发基于经典时间积分技术的新型QSS方案提供理论基础。

Method: 将QSS方法重新解释为应用于系统模型对偶形式的积分方案，其中时间作为状态相关变量，并基于此提出了QSS Adams-Bashforth方法。

Result: 提出的方法在测试方程中验证了有效性，并在实际电力系统仿真中实现了显著的性能提升。

Conclusion: 该对偶性框架为开发新型QSS方案开辟了新途径，能够显著提升复杂系统仿真的性能。

Abstract: This letter introduces a formal duality between discrete-time and
quantized-state numerical methods. We interpret quantized state system (QSS)
methods as integration schemes applied to a dual form of the system model,
where time is seen as a state-dependent variable. This perspective enables the
definition of novel QSS-based schemes inspired by classical time-integration
techniques. As a proof of concept, we illustrate the idea by introducing a QSS
Adams-Bashforth method applied to a test equation. We then move to demonstrate
how the proposed approach can achieve notable performance improvements in
realistic power system simulations.

</details>


### [167] [A Trustworthy Industrial Fault Diagnosis Architecture Integrating Probabilistic Models and Large Language Models](https://arxiv.org/abs/2510.03815)
*Yue wu*

Main category: eess.SY

TL;DR: 提出了一种结合贝叶斯网络和LLM的工业故障诊断框架，通过置信度校准和风险评估模块提高系统可靠性，诊断准确率提升28个百分点，校准误差降低75%以上。


<details>
  <summary>Details</summary>
Motivation: 传统方法和深度学习方法在工业故障诊断中存在可解释性、泛化性和不确定性量化方面的局限性，导致诊断结果可信度不足。

Method: 采用贝叶斯网络诊断引擎进行初步分析，结合LLM驱动的认知仲裁模块处理多模态输入，通过置信度校准和风险评估模块量化系统可靠性。

Result: 在多故障类型数据集上的实验表明，该框架相比基线模型诊断准确率提升超过28个百分点，校准ECE降低超过75%。

Conclusion: HCAA框架有效纠正传统模型因复杂特征模式或知识空白导致的误判，为构建高可信度、可解释的工业AI诊断系统提供了新颖实用的工程解决方案。

Abstract: There are limitations of traditional methods and deep learning methods in
terms of interpretability, generalization, and quantification of uncertainty in
industrial fault diagnosis, and there are core problems of insufficient
credibility in industrial fault diagnosis. The architecture performs
preliminary analysis through a Bayesian network-based diagnostic engine and
features an LLM-driven cognitive quorum module with multimodal input
capabilities. The module conducts expert-level arbitration of initial diagnoses
by analyzing structured features and diagnostic charts, prioritizing final
decisions after conflicts are identified. To ensure the reliability of the
system output, the architecture integrates a confidence calibration module
based on temperature calibration and a risk assessment module, which
objectively quantifies the reliability of the system using metrics such as
expected calibration error (ECE). Experimental results on a dataset containing
multiple fault types showed that the proposed framework improved diagnostic
accuracy by more than 28 percentage points compared to the baseline model,
while the calibrated ECE was reduced by more than 75%. Case studies have
confirmed that HCAA effectively corrects misjudgments caused by complex feature
patterns or knowledge gaps in traditional models, providing novel and practical
engineering solutions for building high-trust, explainable AI diagnostic
systems for industrial applications.

</details>


### [168] [Enhancing Data Center Low-Voltage Ride-Through](https://arxiv.org/abs/2510.03867)
*Yiheng Xie,Wenqi Cui,Adam Wierman*

Main category: eess.SY

TL;DR: 本文设计数据中心内部电压控制器来提升其低电压穿越能力，通过集中式和分散式控制策略调节数据中心内部电压，使其在电网故障时保持运行。


<details>
  <summary>Details</summary>
Motivation: 数据中心负载对电压偏差高度敏感，大规模数据中心同时跳闸会进一步破坏输电系统稳定性，甚至导致级联故障。输电系统运营商因此对数据中心施加电压穿越要求。

Method: 系统分析电压穿越标准和数据中心可控资源，设计集中式和分散式电压控制器来统一控制异构灵活资源，构建集成测试系统模拟输电系统和数据中心配电网的暂态故障响应。

Result: 案例研究表明，所提出的电压控制机制为增强数据中心低电压穿越能力提供了有效且简单的解决方案。

Conclusion: 通过设计数据中心内部电压控制器，可以有效提升其电压穿越能力，确保在电网电压扰动期间数据中心负载保持在线运行。

Abstract: Data center loads have expanded significantly in recent years. Compared to
traditional loads, data centers are highly sensitive to voltage deviations and
thus their protection mechanisms trip more proactively during voltage
fluctuations. During a grid fault, simultaneous tripping of large-scale data
centers can further destabilize the transmission system and even lead to
cascading failures. In response, transmission system operators are imposing
voltage ride-through (VRT) requirements for data centers. In this work, we
enhance the VRT capability of data centers by designing voltage controllers for
their internal power distribution network. We first systematically analyze VRT
standards and the controllable resources related to data centers. These
resources enable the design of voltage control strategies to regulate voltages
internal to the data center, thereby allowing loads to remain online during
voltage disturbances from the external transmission grid. We study and contrast
both centralized and decentralized controllers that unify the control of
heterogeneous flexible resources. Additionally, we construct an integrated test
system that simulates both the transient fault response of the transmission
system and the data center distribution network. Case studies demonstrate that
the proposed voltage control mechanisms provide effective yet simple solutions
to enhance data center low-voltage ride-through capability.

</details>


### [169] [Electrical System Architecture for Aviation Electrification](https://arxiv.org/abs/2510.03887)
*Anoy Saha,Mona Ghassemi*

Main category: eess.SY

TL;DR: 本章概述了电动和混合电动飞机的电气系统架构，讨论了电气化的动机、四种主要架构分类（常规、多电、全电、混合电）以及各种系统拓扑，并通过实际案例展示了从子系统电气化向完全集成架构的过渡。


<details>
  <summary>Details</summary>
Motivation: 电气化的动机包括减少环境影响、提高运营效率，以及用更轻更可靠的电气替代品取代复杂的气动和液压子系统。

Method: 将飞机电气架构分为四类：常规、多电、全电和混合电，并检查直流、交流、混合和分布式配置等各种系统拓扑。

Result: 通过波音787梦幻客机、Eviation Alice通勤飞机和NASA X57 Maxwell演示机的案例研究，展示了实际应用和从增量子系统电气化向完全集成架构的过渡。

Conclusion: 电气化正在重塑航空航天设计的基础，将电气系统置于推进、控制和机载功能的中心，有望实现更高的效率和更大的可持续性。

Abstract: The electrification of aircraft is reshaping the foundations of aerospace
design by positioning electrical systems at the center of propulsion, control,
and onboard functionality. This chapter provides an overview of electrical
system architectures for electric and hybrid electric aircraft, highlighting
both established principles and emerging design strategies. The discussion
begins with the motivations for electrification, including reducing
environmental impact, improving operational efficiency, and replacing complex
pneumatic and hydraulic subsystems with lighter and more reliable electrical
alternatives. Aircraft electrical architectures are classified into four major
categories: conventional, more electric, all electric, and hybrid electric. A
range of system topologies is examined, including direct current (DC),
alternating current (AC), hybrid, and distributed configurations. Each is
considered in terms of its effectiveness in delivering power, enabling
redundancy, supporting fault isolation, and managing thermal performance. Real
world examples are presented to demonstrate practical applications, with case
studies drawn from the Boeing 787 Dreamliner, the Eviation Alice commuter
aircraft, and NASA X57 Maxwell demonstrator. These examples illustrate the
ongoing transition from incremental subsystem electrification toward fully
integrated architectures that promise higher efficiency and greater
sustainability.

</details>


### [170] [3D Electronic-Photonic Heterogenous Interconnect Platforms Enabling Energy-Efficient Scalable Architectures For Future HPC Systems](https://arxiv.org/abs/2510.03943)
*Anirban Samanta,Shun-Hung Lee,Chun-Yi Cheng,Samuel Palermo,S. J. Ben Yoo*

Main category: eess.SY

TL;DR: 提出3D芯片堆叠电子-光子互连平台，通过硅通光孔实现高速数据通信，突破铜基电互连的带宽密度限制，达到>10TB/s/mm²带宽密度和≤100fJ/bit的能效。


<details>
  <summary>Details</summary>
Motivation: 解决高性能计算中互连带宽扩展和内存墙问题，克服铜基电互连在高速信号传输中的信号质量下降和能效低下等根本限制。

Method: 采用3D芯片堆叠电子-光子互连平台，使用硅通光孔在3D堆叠中实现高速数据的光域通信，同时保留电TSV和2.5D互连用于供电和短距离低延迟通信。

Result: 3D EPIC平台超越现有3D电互连，实现>10TB/s/mm²的带宽密度，并展示达到≤100fJ/bit高速通信的可行路径。

Conclusion: 3D电子-光子互连平台为高性能计算提供了突破互连带宽和能效限制的有效解决方案，具有产业化的应用前景。

Abstract: 3D interconnects have emerged as a solution to address the scaling issues of
interconnect bandwidth and the memory wall problem in high-performance
computing (HPC), such as High-Bandwidth Memory (HBM). However, the copper-based
electrical interconnect retains fundamental limitations. Dense I/O for
high-speed signals lead to degraded signal quality for end-to-end links,
necessitating additional circuits to mitigate signal impairments and resulting
in poor energy efficiency. We propose a 3D chiplet stacking electronic-photonic
interconnect (EPIC) platform, which offers a solution by moving the high-speed
data communication interface to the optical domain across the 3D stack by using
Through Silicon Optical Vias (TSOV), while retaining the functionality of
electrical TSVs and 2.5D interconnects for power delivery and short-reach
low-latency communications. We then benchmark the proposed model against
state-of-the-art 3D electrical interconnects to demonstrate our 3D EPIC
platform beating the 3D electrical interconnects to $>$10 TB/s/$mm^2$ bandwidth
density. We present a pathway to extend our demonstrated, industry-ready design
to achieving $\leq$100 fJ/bit high-speed communication.

</details>


### [171] [Use of Quadcopter Wakes to Supplement Strawberry Pollination](https://arxiv.org/abs/2510.03974)
*Sadie Cutler,Ben DeFay,Scott McArt,Kirstin Petersen*

Main category: eess.SY

TL;DR: 研究探索使用四轴飞行器进行辅助授粉的新方法，通过风力授粉机制来弥补传粉者短缺问题。


<details>
  <summary>Details</summary>
Motivation: 传粉者对生态系统和粮食供应至关重要，但近期研究发现包括草莓在内的多种作物存在授粉不足问题，而野生和人工管理的传粉者数量正在下降。

Method: 确定侧向气流最大化的高度后，在田间实验中让四轴飞行器辅助自然传粉者进行授粉。

Result: 田间实验结果不确定，但实验室研究表明该方法具有潜力，可以改进以获得更好的田间结果。

Conclusion: 基于风力授粉的人工授粉方法显示出前景，虽然田间效果尚不明确，但可通过改进适应田间条件。

Abstract: Pollinators are critical to the world's ecosystems and food supply, yet
recent studies have found pollination shortfalls in several crops, including
strawberry. This is troubling because wild and managed pollinators are
currently experiencing declines. One possibility is to try and provide
supplemental pollination solutions. These solutions should be affordable and
simple for farmers to implement if their use is to be widespread; quadcopters
are a great example, already used for monitoring on many farms. This paper
investigates a new method for artificial pollination based on wind pollination
that bears further investigation. After determining the height where the
lateral flow is maximized, we performed field experiments with a quadcopter
assisting natural pollinators. Although our results in the field were
inconclusive, lab studies show that the idea shows promise and could be adapted
for better field results.

</details>


### [172] [Data-driven Practical Stabilization of Nonlinear Systems via Chain Policies: Sample Complexity and Incremental Learning](https://arxiv.org/abs/2510.03982)
*Roy Siegelmann,Enrique Mallada*

Main category: eess.SY

TL;DR: 提出一种基于非参数链策略的数据驱动非线性系统实用稳定化方法，具有可证明的保证，仅需系统局部Lipschitz假设，无需显式构造Lyapunov函数。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将系统建模为线性、多项式或多项式分数形式，限制了应用范围。本文旨在开发一种更通用的数据驱动稳定化方法，仅需局部Lipschitz假设，并能提供明确的样本复杂度保证。

Method: 采用非参数链策略，使用归一化最近邻规则为每个状态分配有限持续时间控制信号，并引入递归控制Lyapunov函数框架来验证实用稳定性。

Result: 提供了明确的样本复杂度保证O((3/ρ)^d log(R/c))，其中R为域半径，d为状态维度，ρ为系统相关常数。数值实验验证了方法的有效性。

Conclusion: 所提出的链策略是非参数的，允许轻松整合新的验证数据来改进收敛速度或扩大认证区域，为非线性系统的数据驱动稳定化提供了通用且可证明的解决方案。

Abstract: We propose a method for data-driven practical stabilization of nonlinear
systems with provable guarantees, based on the concept of Nonparametric Chain
Policies (NCPs). The approach employs a normalized nearest-neighbor rule to
assign, at each state, a finite-duration control signal derived from stored
data, after which the process repeats. Unlike recent works that model the
system as linear, polynomial, or polynomial fraction, we only assume the system
to be locally Lipschitz. Our analysis builds on the framework of Recurrent
Lyapunov Functions (RLFs), which enable data-driven certification of practical
stability using standard norm functions instead of requiring the explicit
construction of a classical Lyapunov function. To extend this framework, we
introduce the concept of Recurrent Control Lyapunov Functions (R-CLFs), which
can certify the existence of an NCP that practically stabilizes an arbitrarily
small c-neighborhood of an equilibrium point. We also provide an explicit
sample complexity guarantee of O((3/rho)^d log(R/c)) number of trajectories,
where R is the domain radius, d the state dimension, and rho a system-dependent
constant. The proposed Chain Policies are nonparametric, thus allowing new
verified data to be readily incorporated into the policy to either improve
convergence rate or enlarge the certified region. Numerical experiments
illustrate and validate these properties.

</details>


### [173] [Distributed MPC-based Coordination of Traffic Perimeter and Signal Control: A Lexicographic Optimization Approach](https://arxiv.org/abs/2510.04038)
*Viet Hoang Pham,Hyo-Sung Ahn*

Main category: eess.SY

TL;DR: 提出了一种结合交通边界控制和信号控制的综合策略，通过分层多目标优化和分布式ADMM算法来缓解城市交通网络拥堵。


<details>
  <summary>Details</summary>
Motivation: 为了解决城市交通网络拥堵问题，需要综合考虑边界流量控制和内部信号协调优化，但传统方法难以处理大规模网络的复杂性和计算负担。

Method: 采用分层多目标优化方法，先通过边界控制调节流入量，再优化内部信号配时；使用MPC确保安全约束，并通过分布式ADMM算法将网络划分为子网络进行并行计算。

Result: VISSIM和MATLAB数值仿真验证了该策略的有效性，能够显著改善城市交通网络的整体运行状况。

Conclusion: 该综合控制策略通过分布式计算框架成功解决了大规模城市交通网络的拥堵问题，为实际应用提供了可行的解决方案。

Abstract: This paper introduces a comprehensive strategy that integrates traffic
perimeter control with traffic signal control to alleviate congestion in an
urban traffic network (UTN). The strategy is formulated as a lexicographic
multi-objective optimization problem, starting with the regulation of traffic
inflows at boundary junctions to maximize the capacity while ensuring a smooth
operation of the UTN. Following this, the signal timings at internal junctions
are collaboratively optimized to enhance overall traffic conditions under the
regulated inflows. The use of a model predictive control (MPC) approach ensures
that the control solution adheres to safety and capacity constraints within the
network. To address the computational complexity of the problem, the UTN is
divided into subnetworks, each managed by a local agent. A distributed solution
method based on the alternating direction method of multipliers (ADMM)
algorithm is employed, allowing each agent to determine its optimal control
decisions using local information from its subnetwork and neighboring agents.
Numerical simulations using VISSIM and MATLAB demonstrate the effectiveness of
the proposed traffic control strategy.

</details>


### [174] [A Conformal Prediction-Based Chance-Constrained Programming Approach for 24/7 Carbon-Free Data Center Operation Scheduling](https://arxiv.org/abs/2510.04053)
*Yijie Yang,Jian Shi,Dan Wang,Chenye Wu,Zhu Han*

Main category: eess.SY

TL;DR: 提出了一种基于多变量保形预测的24/7无碳能源数据中心运营调度方法，通过利用协变量信息构建自适应不确定性集合，相比传统方法可降低6.65%成本和6.96%碳基能源使用。


<details>
  <summary>Details</summary>
Motivation: AI应用快速增长导致数据中心能耗激增，加剧碳排放，需要转向24/7无碳能源运营。传统年度能源匹配方法无法满足实时清洁能源匹配需求，且现有不确定性建模方法过于保守。

Method: 使用多变量保形预测技术构建统计有效的自适应不确定性集合，结合机会约束规划确保约束满足特定概率，建立理论连接保形预测与机会约束的统计可行性保证。

Result: 相比传统协变量无关方法，该方法可实现6.65%成本降低和6.96%碳基能源使用减少，推动数据中心实现24/7无碳能源目标。

Conclusion: 提出的协变量感知方法能有效处理可再生能源不确定性，为数据中心24/7无碳能源运营提供可行解决方案，显著提升经济性和环境效益。

Abstract: The rapid growth of AI applications is dramatically increasing data center
energy demand, exacerbating carbon emissions, and necessitating a shift towards
24/7 carbon-free energy (CFE). Unlike traditional annual energy matching, 24/7
CFE requires matching real-time electricity consumption with clean energy
generation every hour, presenting significant challenges due to the inherent
variability and forecasting errors of renewable energy sources. Traditional
robust and data-driven optimization methods often fail to leverage the features
of the prediction model (also known as contextual or covariate information)
when constructing the uncertainty set, leading to overly conservative
operational decisions. This paper proposes a comprehensive approach for 24/7
CFE data center operation scheduling, focusing on robust decision-making under
renewable generation uncertainty. This framework leverages covariate
information through a multi-variable conformal prediction (CP) technique to
construct statistically valid and adaptive uncertainty sets for renewable
forecasts. The uncertainty sets directly inform the chance-constrained
programming (CCP) problem, ensuring that chance constraints are met with a
specified probability. We further establish theoretical underpinnings
connecting the CP-generated uncertainty sets to the statistical feasibility
guarantees of the CCP. Numerical results highlight the benefits of this
covariate-aware approach, demonstrating up to 6.65% cost reduction and 6.96%
decrease in carbon-based energy usage compared to conventional
covariate-independent methods, thereby enabling data centers to progress toward
24/7 CEF.

</details>


### [175] [A Hybrid GNN-IZR Framework for Fast and Empirically Robust AC Power Flow Analysis in Radial Distribution Systems](https://arxiv.org/abs/2510.04264)
*Mohamed Shamseldein*

Main category: eess.SY

TL;DR: 提出了一种结合图神经网络(GNN)和隐式Z总线递归(IZR)方法的混合框架，用于解决交流潮流问题，在保持GNN速度优势的同时实现分析求解器的可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决交流潮流问题中数据驱动模型速度与分析求解器可靠性之间的权衡问题，寻求一种既能快速求解又能保证可靠性的实用方法。

Method: 使用物理信息GNN进行快速初始预测，通过两阶段触发器识别压力情况，将潜在失败案例委托给IZR求解器处理。

Result: 在IEEE 33总线系统的7500个压力场景测试中，纯GNN模型失败率为13.11%，而混合框架通过识别所有潜在失败并委托IZR求解，实现了0.00%的失败率。

Conclusion: 该混合方法展示了在保持分析求解器可靠性的同时利用GNN速度优势的实用路径，显著提高了近实时可分析场景的数量。

Abstract: The Alternating Current Power Flow (ACPF) problem forces a trade-off between
the speed of data-driven models and the reliability of analytical solvers. This
paper introduces a hybrid framework that synergizes a Graph Neural Network
(GNN) with the Implicit Z-Bus Recursive (IZR) method, a robust, non-iterative
solver for radial distribution networks. The framework employs a
physics-informed GNN for rapid initial predictions and invokes the IZR solver
as a failsafe for stressed cases identified by a two-stage trigger. A failure
is defined as any solution with a maximum power mismatch exceeding 0.1 p.u., a
significant operational deviation. On a challenging test set of 7,500 stressed
scenarios for the IEEE 33-bus system, the GNN-only model failed on 13.11 % of
cases. In contrast, the hybrid framework identified all potential failures,
delegating them to the IZR solver to achieve a 0.00 % failure rate, empirically
matching the 100 % success rate of the analytical solver on this specific test
set. An expanded ablation study confirms that both physics-informed training
and Z-bus sensitivity features are critical, collaboratively reducing the GNN's
failure rate from 98.72 % (data-only) to 13.11 %. The hybrid approach
demonstrates a pragmatic path to achieving the empirical reliability of an
analytical solver while leveraging GNN speed, enabling a significant increase
in the number of scenarios analyzable in near real-time.

</details>


### [176] [A Diffusion-based Generative Machine Learning Paradigm for Contingency Screening](https://arxiv.org/abs/2510.04470)
*Quan Tran,Suresh S. Muknahallipatna,Dongliang Duan,Nga Nguyen*

Main category: eess.SY

TL;DR: 本文提出了一种新颖的电力系统事故筛选方法，从预定义场景筛选转向主动无监督筛选，通过扰动扩散技术学习事故发生的内部扰动模式，自动生成最危险场景。


<details>
  <summary>Details</summary>
Motivation: 传统电力系统事故分析采用数值分析方法，需要生成大量可能事故或操纵网络参数来确定最坏情况，这种方法耗时且效率低下。

Method: 提出基于扰动扩散技术的模型，通过学习先前事故发生的内部扰动模式，主动生成潜在风险场景，而不是逐个模拟场景来识别最高风险情况。

Result: 在IEEE系统上进行了实证实验，测试和验证了所提出的解决方案。

Conclusion: 该方法能够有效识别电力系统的最危险事故场景，相比传统方法更加高效和主动。

Abstract: Contingency screening is a crucial part of electric power systems all the
time. Power systems frequently encounter multiple challenging operational
dilemmas that could lead to the instability of power systems. Contingency
analysis is effort-consuming by utilizing traditional numerical analysis
methods. It is commonly addressed by generating a whopping number of possible
contingencies or manipulating network parameters to determine the worst
scenarios. This paper proposes a novel approach that diverts the nature of
contingency analysis from pre-defined scenario screening to
proactive-unsupervised screening. The potentially risky scenarios of power
systems are generated from learning how the previous ones occurred. In other
words, the internal perturbation that initiates contingencies is learned prior
to being self-replicated for rendering the worst scenarios. By leveraging the
perturbation diffusion technique, a proposed model is built to point out the
worst scenarios instead of repeatedly simulating one-by-one scenarios to define
the highest-risk ones. Empirical experiments are implemented on the IEEE
systems to test and validate the proposed solution.

</details>


### [177] [On properties of hydraulic equilibria in district heating networks](https://arxiv.org/abs/2510.04524)
*Ask Hällström,Felix Agner,Richard Pates*

Main category: eess.SY

TL;DR: 本文研究树状区域供热网络中流量分布的特性，证明在液压网络组件单调性假设下，所有消费者同时开阀会增加总流量，而单个消费者不开阀会减少其流量。


<details>
  <summary>Details</summary>
Motivation: 区域供热网络是未来智能能源系统的关键组成部分，需要增强能源灵活性并支持可再生能源整合，流量控制是影响供热效率的重要因素。

Method: 基于液压网络组件的单调性假设，分析树状结构供热网络中的稳态流量分布特性，并通过数值模拟验证理论结果。

Result: 理论分析和数值模拟表明：所有消费者同时开阀保证总流量增加；单个消费者不开阀会导致其流量减少。这些特性已在2消费者和22消费者网络中验证。

Conclusion: 树状区域供热网络具有可预测的流量分布特性，这些特性为设计高效的热量分配控制策略提供了理论基础。

Abstract: District heating networks are an integral part of the energy system in many
countries. In future smart energy systems, they are expected to enhance energy
flexibility and support the integration of renewable and waste energy sources.
An important aspect of these networks is the control of flow rates, which
dictates the heat delivered to consumers. This paper concerns the properties of
flow rates in tree-structured district heating networks. We show that under
mild assumptions of monotonicity in the hydraulic network components,
statements regarding the stationary flow rate distribution can be made. In
particular, when all consumers in a network incrementally open their valves, an
increase in total flow rate throughput is guaranteed, while if one consumer
does not open their valve when others do, they will receive a reduced flow
rate. These properties are illustrated numerically on a small 2-consumer
network as well as on a larger 22-consumer network. Previous works have shown
that these properties allow the design and use of efficient control strategies
for optimal heat distribution.

</details>


### [178] [Data-Driven Adaptive PID Control Based on Physics-Informed Neural Networks](https://arxiv.org/abs/2510.04591)
*Junsei Ito,Yasuaki Wasa*

Main category: eess.SY

TL;DR: 提出了一种基于自适应增益优化的数据驱动PID控制器设计方法，利用物理信息神经网络(PINNs)进行预测建模，通过自动微分优化PID增益，实现考虑系统非线性的自适应调参。


<details>
  <summary>Details</summary>
Motivation: 传统PID控制器在处理非线性系统时存在局限性，需要一种能够自适应调整增益并确保稳定性的数据驱动控制方法。

Method: 使用PINNs生成预测模型，通过自动微分计算PID增益优化的梯度，基于跟踪误差和控制输入的成本函数应用模型预测控制。

Result: 数值实验验证了该方法在时域和频域控制性能上的有效性，能够实现稳定的自适应增益调节。

Conclusion: 该方法为将PINNs模型集成到闭环控制系统提供了系统框架，可直接应用于PID控制设计，有效处理非线性系统控制问题。

Abstract: This article proposes a data-driven PID controller design based on the
principle of adaptive gain optimization, leveraging Physics-Informed Neural
Networks (PINNs) generated for predictive modeling purposes. The proposed
control design method utilizes gradients of the PID gain optimization, achieved
through the automatic differentiation of PINNs, to apply model predictive
control using a cost function based on tracking error and control inputs. By
optimizing PINNs-based PID gains, the method achieves adaptive gain tuning that
ensures stability while accounting for system nonlinearities. The proposed
method features a systematic framework for integrating PINNs-based models of
dynamical control systems into closed-loop control systems, enabling direct
application to PID control design. A series of numerical experiments is
conducted to demonstrate the effectiveness of the proposed method from the
control perspectives based on both time and frequency domains.

</details>


### [179] [Design Process of a Self Adaptive Smart Serious Games Ecosystem](https://arxiv.org/abs/2510.04615)
*X. Tao,P. Chen,M. Tsami,F. Khayati,M. Eckert*

Main category: eess.SY

TL;DR: Blexer v3是一个基于严肃游戏的模块化AI驱动康复生态系统，提出了集成多模态感知、实时推理和智能控制的新架构，包含数据收集、用户状态推断和游戏适应等模块。


<details>
  <summary>Details</summary>
Motivation: 基于先前版本的经验，设计更先进的康复系统，通过AI技术实现个性化干预，提升康复效果。

Method: 采用模块化架构，整合多模态感知、实时推理和智能控制，包含动态难度调整和程序化内容生成等关键功能。

Result: 提出了完整的Blexer v3概念框架，定义了系统的模块化结构和数据流，为功能原型开发和临床集成奠定了基础。

Conclusion: 该框架为下一阶段开发功能原型并将其集成到临床康复场景中提供了基础，有望推动AI驱动的康复系统发展。

Abstract: This paper outlines the design vision and planned evolution of Blexer v3, a
modular and AI-driven rehabilitation ecosystem based on serious games. Building
on insights from previous versions of the system, we propose a new architecture
that aims to integrate multimodal sensing, real-time reasoning, and intelligent
control. The envisioned system will include distinct modules for data
collection, user state inference, and gameplay adaptation. Key features such as
dynamic difficulty adjustment (DDA) and procedural content generation (PCG) are
also considered to support personalized interventions. We present the complete
conceptual framework of Blexer v3, which defines the modular structure and data
flow of the system. This serves as the foundation for the next phase: the
development of a functional prototype and its integration into clinical
rehabilitation scenarios.

</details>


### [180] [On Prediction-Based Properties of Discrete-Event Systems: Notions, Applications and Supervisor Synthesis](https://arxiv.org/abs/2510.04616)
*Bohan Cui,Yu Chen,Alessandro Giua,Xiang Yin*

Main category: eess.SY

TL;DR: 提出了一种用于部分可观测离散事件系统的预测属性监督器合成方法，该属性依赖于系统未来行为预测而非仅当前行为。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注系统已执行行为的属性，但在涉及未来信息的应用中，需要处理基于预测未来行为的属性，如主动预测或意图保护。

Method: 引入预测属性概念，提出基于信息结构的方法，通过借用未来信息并确保信息一致性，将监督器合成问题转化为信息空间的安全博弈。

Result: 证明了所提算法的正确性和完备性，生成的监督器是最大允许的。

Conclusion: 该方法能够有效处理依赖未来信息的属性执行问题，具有通用性和实用性。

Abstract: In this work, we investigate the problem of synthesizing property-enforcing
supervisors for partially-observed discrete-event systems (DES). Unlike most
existing approaches, where the enforced property depends solely on the executed
behavior of the system, here we consider a more challenging scenario in which
the property relies on predicted future behaviors that have not yet occurred.
This problem arises naturally in applications involving future information,
such as active prediction or intention protection. To formalize the problem, we
introduce the notion of prediction-based properties, a new class of
observational properties tied to the system's future information. We
demonstrate that this notion is very generic and can model various practical
properties, including predictability in fault prognosis and pre-opacity in
intention security. We then present an effective approach for synthesizing
supervisors that enforce prediction-based properties. Our method relies on a
novel information structure that addresses the fundamental challenge arising
from the dependency between current predictions and the control policy. The key
idea is to first borrow information from future instants and then ensure
information consistency. This reduces the supervisor synthesis problem to a
safety game in the information space. We prove that the proposed algorithm is
both sound and complete, and the resulting supervisor is maximally permissive.

</details>


### [181] [Learning a Shape-adaptive Assist-as-needed Rehabilitation Policy from Therapist-informed Input](https://arxiv.org/abs/2510.04666)
*Zhimin Hou,Jiacheng Hou,Xiao Chen,Hamid Sadeghian,Tianyu Ren,Sami Haddadin*

Main category: eess.SY

TL;DR: 提出了一种新颖的远程机器人康复框架，通过潜在空间中的路径点编码治疗师指导的矫正力，并学习形状自适应的辅助康复策略，实现更安全、更自适应的康复治疗。


<details>
  <summary>Details</summary>
Motivation: 当前治疗师参与的机器人康复系统存在安全交互不足和适应能力有限的问题，限制了其广泛应用。

Method: 1) 将治疗师指导的矫正力编码到潜在空间的路径点中；2) 学习形状自适应的辅助康复策略，基于患者运动偏好和治疗师指导的路径点部分渐进地变形参考轨迹。

Result: 在两个代表性任务上的验证表明，该方法能有效减少矫正力并提高运动平滑度，优于两种最先进方法。

Conclusion: 该形状自适应辅助康复策略在远程康复中具有实用性，为治疗师提供更直观、安全的康复治疗方式。

Abstract: Therapist-in-the-loop robotic rehabilitation has shown great promise in
enhancing rehabilitation outcomes by integrating the strengths of therapists
and robotic systems. However, its broader adoption remains limited due to
insufficient safe interaction and limited adaptation capability. This article
proposes a novel telerobotics-mediated framework that enables therapists to
intuitively and safely deliver assist-as-needed~(AAN) therapy based on two
primary contributions. First, our framework encodes the therapist-informed
corrective force into via-points in a latent space, allowing the therapist to
provide only minimal assistance while encouraging patient maintaining own
motion preferences. Second, a shape-adaptive ANN rehabilitation policy is
learned to partially and progressively deform the reference trajectory for
movement therapy based on encoded patient motion preferences and
therapist-informed via-points. The effectiveness of the proposed shape-adaptive
AAN strategy was validated on a telerobotic rehabilitation system using two
representative tasks. The results demonstrate its practicality for remote AAN
therapy and its superiority over two state-of-the-art methods in reducing
corrective force and improving movement smoothness.

</details>


### [182] [MPC strategies for density profile control with pellet fueling in nuclear fusion tokamaks under uncertainty](https://arxiv.org/abs/2510.04784)
*Christopher A. Orrico,Hari Prasad Varadarajan,Matthijs van Berkel,Lennard Ceelen,Thomas O. S. J. Bosman,W. P. M. H. Heemels,Dinesh Krishnamoorthy*

Main category: eess.SY

TL;DR: 提出了一种多阶段模型预测控制（msMPC）方法，用于处理ITER核聚变托卡马克中具有参数不确定性、输入延迟和离散执行器的密度剖面控制问题。通过模型降阶、场景缩减和计算负担减轻等技术，实现了实时密度剖面控制。


<details>
  <summary>Details</summary>
Motivation: ITER核聚变托卡马克的密度剖面控制面临多速率非线性系统、安全关键约束、输入延迟、离散执行器和参数不确定性等挑战，需要开发能够处理这些复杂性的实时控制策略。

Method: 采用多阶段MPC（msMPC）处理不确定性，结合三种复杂度降低技术：1）通过带控制的动态模态分解减小预测模型规模；2）应用主成分分析减少场景数量；3）使用惩罚项同伦MPC算法减轻混合整数输入带来的计算负担。

Result: 在工厂仿真中，msMPC策略相比标称MI-MPC表现出更好的性能和安全性，首次实现了具有不确定性处理能力的预测密度控制策略，适用于ITER的实时颗粒燃料注入。

Conclusion: 该方法成功解决了ITER密度剖面控制的复杂挑战，为核聚变装置提供了首个可行的实时不确定性处理预测控制策略。

Abstract: Control of the density profile based on pellet fueling for the ITER nuclear
fusion tokamak involves a multi-rate nonlinear system with safety-critical
constraints, input delays, and discrete actuators with parametric uncertainty.
To address this challenging problem, we propose a multi-stage MPC (msMPC)
approach to handle uncertainty in the presence of mixed-integer inputs. While
the scenario tree of msMPC accounts for uncertainty, it also adds complexity to
an already computationally intensive mixed-integer MPC (MI-MPC) problem. To
achieve real-time density profile controller with discrete pellets and
uncertainty handling, we systematically reduce the problem complexity by (1)
reducing the identified prediction model size through dynamic mode
decomposition with control, (2) applying principal component analysis to reduce
the number of scenarios needed to capture the parametric uncertainty in msMPC,
and (3) utilizing the penalty term homotopy for MPC (PTH-MPC) algorithm to
reduce the computational burden caused by the presence of mixed-integer inputs.
We compare the performance and safety of the msMPC strategy against a nominal
MI-MPC in plant simulations, demonstrating the first predictive density control
strategy with uncertainty handling, viable for real-time pellet fueling in
ITER.

</details>


### [183] [Efficient Probabilistic Planning with Maximum-Coverage Distributionally Robust Backward Reachable Trees](https://arxiv.org/abs/2510.04807)
*Alex Rose,Naman Aggarwal,Christopher Jewison,Jonathan P. How*

Main category: eess.SY

TL;DR: 提出两种多查询运动规划算法，用于线性高斯系统，目标是以高概率到达欧几里得球或椭球区域，通过分布鲁棒信念路线图构建实现更好的覆盖范围。


<details>
  <summary>Details</summary>
Motivation: 针对线性高斯系统的运动规划问题，现有方法在覆盖范围上存在局限，需要开发能够处理高斯分布模糊集的新算法，以提供更强的安全保证和更好的性能。

Method: 开发了球状高斯分布模糊集的新公式，并基于此构建分布鲁棒信念路线图算法，合成能够处理最大尺寸模糊集的鲁棒控制器；还提出了基于椭球集合的多查询规划算法。

Result: 算法在覆盖范围上优于现有最大覆盖算法，在温和条件下实现严格更好的覆盖；在无过程噪声或状态约束情况下，证明达到最大覆盖；第二个算法在椭球模糊集规划中达到同等或更好的覆盖。

Conclusion: 两种算法在广泛条件下通过仿真实验验证了有效性，为线性高斯系统的鲁棒运动规划提供了新的解决方案，具有更好的覆盖性能和安全保证。

Abstract: This paper presents a new multi-query motion planning algorithm for linear
Gaussian systems with the goal of reaching a Euclidean ball with high
probability. We develop a new formulation for ball-shaped ambiguity sets of
Gaussian distributions and leverage it to develop a distributionally robust
belief roadmap construction algorithm. This algorithm synthe- sizes robust
controllers which are certified to be safe for maximal size ball-shaped
ambiguity sets of Gaussian distributions. Our algorithm achieves better
coverage than the maximal coverage algorithm for planning over Gaussian
distributions [1], and we identify mild conditions under which our algorithm
achieves strictly better coverage. For the special case of no process noise or
state constraints, we formally prove that our algorithm achieves maximal
coverage. In addition, we present a second multi-query motion planning
algorithm for linear Gaussian systems with the goal of reaching a region
parameterized by the Minkowski sum of an ellipsoid and a Euclidean ball with
high probability. This algorithm plans over ellipsoidal sets of maximal size
ball-shaped ambiguity sets of Gaussian distributions, and provably achieves
equal or better coverage than the best-known algorithm for planning over
ellipsoidal ambiguity sets of Gaussian distributions [2]. We demonstrate the
efficacy of both methods in a wide range of conditions via extensive simulation
experiments.

</details>


### [184] [Robust stability of event-triggered nonlinear moving horizon estimation](https://arxiv.org/abs/2510.04814)
*Isabelle Krauss,Victor G. Lopez,Matthias A. Müller*

Main category: eess.SY

TL;DR: 提出了一种事件触发移动水平估计(ET-MHE)方案，用于非线性系统的远程状态估计，通过事件触发机制减少通信量，并证明了该方案的鲁棒全局指数稳定性。


<details>
  <summary>Details</summary>
Motivation: 为了减少远程状态估计中的通信负担，同时保证估计性能，需要开发高效的事件触发估计方案。

Method: 采用事件触发机制，仅在事件触发时传输单个测量值并求解非线性MHE优化问题；未触发时使用系统动力学的开环预测更新状态估计；引入了新颖的事件触发规则和可变水平长度。

Result: 在满足适当可检测性条件下，证明了ET-MHE方案的鲁棒全局指数稳定性；采用可变水平长度可获得更紧的估计误差界；通过两个示例验证了方法的有效性。

Conclusion: 所提出的ET-MHE方案能够有效减少通信量，同时保证估计性能，为非线性系统的远程状态估计提供了一种高效的解决方案。

Abstract: In this work, we propose an event-triggered moving horizon estimation
(ET-MHE) scheme for the remote state estimation of general nonlinear systems.
In the presented method, whenever an event is triggered, a single measurement
is transmitted and the nonlinear MHE optimization problem is subsequently
solved. If no event is triggered, the current state estimate is updated using
an open-loop prediction based on the system dynamics. Moreover, we introduce a
novel event-triggering rule under which we demonstrate robust global
exponential stability of the ET-MHE scheme, assuming a suitable detectability
condition is met. In addition, we show that with the adoption of a varying
horizon length, a tighter bound on the estimation error can be achieved.
Finally, we validate the effectiveness of the proposed method through two
illustrative examples.

</details>


### [185] [Power Reserve Capacity from Virtual Power Plants with Reliability and Cost Guarantees](https://arxiv.org/abs/2510.04815)
*Lorenzo Zapparoli,Blazhe Gjorgiev,Giovanni Sansavini*

Main category: eess.SY

TL;DR: 提出了一种评估虚拟电厂(VPP)在预测不确定性下提供电力储备容量产品潜力的新方法，该方法考虑了辅助服务产品的可靠性要求和技术规范，并提供准确的成本估算。


<details>
  <summary>Details</summary>
Motivation: 可再生能源渗透率增加导致对电力储备辅助服务的需求增长，需要将分布式能源资源通过虚拟电厂整合到辅助服务市场中，但现有方法未能充分考虑辅助服务产品的可靠性要求和提供准确成本估算。

Method: 首先使用子集模拟的新公式确定最大可行储备量，然后通过考虑显性成本和机会成本来表征供应曲线。

Result: 研究发现虚拟电厂能够可靠地提供储备产品，机会成本驱动产品定价，产品要求对储备容量提供能力有强烈影响。

Conclusion: 该方法旨在支持虚拟电厂管理者制定市场策略和政策制定者设计面向分布式能源资源的辅助服务产品。

Abstract: The growing penetration of renewable energy sources is expected to drive
higher demand for power reserve ancillary services (AS). One solution is to
increase the supply by integrating distributed energy resources (DERs) into the
AS market through virtual power plants (VPPs). Several methods have been
developed to assess the potential of VPPs to provide services. However, the
existing approaches fail to account for AS products' requirements (reliability
and technical specifications) and to provide accurate cost estimations. Here,
we propose a new method to assess VPPs' potential to deliver power reserve
capacity products under forecasting uncertainty. First, the maximum feasible
reserve quantity is determined using a novel formulation of subset simulation
for efficient uncertainty quantification. Second, the supply curve is
characterized by considering explicit and opportunity costs. The method is
applied to a VPP based on a representative Swiss low-voltage network with a
diversified DER portfolio. We find that VPPs can reliably offer reserve
products and that opportunity costs drive product pricing. Additionally, we
show that the product's requirements strongly impact the reserve capacity
provision capability. This approach aims to support VPP managers in developing
market strategies and policymakers in designing DER-focused AS products.

</details>


### [186] [An Active Fault-Tolerant Online Control Allocation Scheme for a Dual-System UAV in Transition Flight](https://arxiv.org/abs/2510.04853)
*Junfeng Cai,Marco Lovera*

Main category: eess.SY

TL;DR: 提出了一种用于双系统垂直起降无人机过渡飞行的新型主动容错控制方案，包含基准控制律和在线控制重分配模块，能有效处理执行器故障并避免控制抖动问题。


<details>
  <summary>Details</summary>
Motivation: 解决双系统垂直起降无人机在过渡飞行中执行器故障时的控制问题，提高飞行安全性和可靠性，避免传统滑模控制方法带来的控制抖动问题。

Method: 采用结构化H∞基准控制律保证闭环系统稳定性，结合在线控制分配模块根据故障信息和实时空速更新控制分配矩阵，将虚拟控制信号重新分配给健康执行器。

Result: 在非线性六自由度仿真器上测试对称和非对称执行器故障场景，结果表明该AFTC系统能处理更复杂的故障场景和模型不确定性，无需重新配置基准控制律。

Conclusion: 所提出的基于结构化H∞的AFTC方案显著提高了双系统VTOL无人机过渡飞行的安全性和可靠性。

Abstract: A novel active fault-tolerant control (AFTC) scheme for a dual-system
vertical takeoff and landing (VTOL) unmanned aerial vehicle (UAV) during
transition flight is proposed in this paper. The AFTC scheme is composed of a
baseline control law and an online control reallocation module. First, the
structured $H_{\infty}$ baseline control law is able to guarantee the stability
of closed-loop systems without being reconfigured under simultaneous actuator
fault conditions. Second, compared to the existing mainstream method of sliding
mode control that is a discontinuous control strategy, the AFTC scheme can
effectively avoid control chattering problem by adopting the structured
$H_{\infty}$ baseline control law. Third, an online control allocation (CA)
module is implemented to carry out a unified CA for all the available
actuators. When actuator faults/failures occur, the CA matrix is updated
according to fault information and real-time airspeed, which is able to
redistribute the virtual control signals to the remaining healthy actuators,
avoiding significant performance degradation. Based on the developed AFTC
scheme, symmetric and non-symmetric actuator fault scenarios are simulated on a
nonlinear six-degree-of-freedom simulator, where the cases of merely structured
$H_{\infty}$ control and structured $H_{\infty}$ based AFTC are compared and
analyzed. The results show that the proposed structured $H_{\infty}$ based AFTC
system is capable of handling more complicated fault scenarios and model
uncertainties with no need to reconfigure the baseline control law. The
proposed AFTC scheme significantly improves the safety and reliability of the
transition flight of dual-system VTOL UAVs.

</details>


### [187] [Model Predictive Control-Guided Reinforcement Learning for Implicit Balancing](https://arxiv.org/abs/2510.04868)
*Seyed Soroush Karimi Madahi,Kenneth Bruninx,Bert Claessens,Chris Develder*

Main category: eess.SY

TL;DR: 提出了一种结合模型预测控制(MPC)和强化学习(RL)的MPC引导RL方法，用于欧洲不平衡市场的电池控制，相比单独使用RL和MPC分别实现了16.15%和54.36%的套利利润提升。


<details>
  <summary>Details</summary>
Motivation: 现有MPC策略虽然能捕捉套利机会，但无法准确模拟欧洲不平衡市场的价格形成过程且计算成本高；而RL方法执行快速但需要数据密集型训练且依赖实时和历史数据。

Method: 提出MPC引导RL方法，结合MPC和RL的互补优势：既能像MPC一样有效整合预测到决策过程，又能保持RL的快速推理能力。

Result: 使用2023年比利时平衡数据评估，相比单独使用RL和MPC方法，提出的MPC引导RL方法分别实现了16.15%和54.36%的套利利润提升。

Conclusion: MPC引导RL方法成功结合了两种方法的优势，在保持快速执行的同时提高了决策质量，为不平衡市场中的电池控制提供了更有效的解决方案。

Abstract: In Europe, profit-seeking balance responsible parties can deviate in real
time from their day-ahead nominations to assist transmission system operators
in maintaining the supply-demand balance. Model predictive control (MPC)
strategies to exploit these implicit balancing strategies capture arbitrage
opportunities, but fail to accurately capture the price-formation process in
the European imbalance markets and face high computational costs. Model-free
reinforcement learning (RL) methods are fast to execute, but require
data-intensive training and usually rely on real-time and historical data for
decision-making. This paper proposes an MPC-guided RL method that combines the
complementary strengths of both MPC and RL. The proposed method can effectively
incorporate forecasts into the decision-making process (as in MPC), while
maintaining the fast inference capability of RL. The performance of the
proposed method is evaluated on the implicit balancing battery control problem
using Belgian balancing data from 2023. First, we analyze the performance of
the standalone state-of-the-art RL and MPC methods from various angles, to
highlight their individual strengths and limitations. Next, we show an
arbitrage profit benefit of the proposed MPC-guided RL method of 16.15% and
54.36%, compared to standalone RL and MPC.

</details>


### [188] [Robust Cislunar Navigation via LFT-Based $\mathcal{H}_\infty$ Filtering with Bearing-Only Measurements](https://arxiv.org/abs/2510.04942)
*Raktim Bhattacharya*

Main category: eess.SY

TL;DR: 开发了一个基于线性分数变换的鲁棒估计框架，用于地月空间导航，结合CR3BP动力学和纯方位光学测量，无需依赖局部线性化。


<details>
  <summary>Details</summary>
Motivation: 为地月空间导航提供不依赖时间飞行测距或精密时钟的鲁棒估计方法，利用被动星跟踪器级光学仪器实现自主导航。

Method: 将主导非线性表示为结构化实不确定性，通过视线几何重建地月距离进行距离相关加权，合成具有明确L2性能界的全阶H∞观测器。

Result: 仿真显示估计误差有界，在多轨道周期内实现平滑位置跟踪，最大偏差出现在平面外状态，与垂直动力学刚度和纯角度可观测性限制一致。

Conclusion: 该框架可在近直线晕轨道上实现具有有界估计误差的鲁棒星载导航，适用于飞行代表性传感器。

Abstract: This paper develops a robust estimation framework for cislunar navigation
that embeds the Circular Restricted Three-Body Problem (CR3BP) dynamics and
bearing-only optical measurements within a Linear Fractional Transformation
(LFT) representation. A full-order $\mathcal{H}_\infty$ observer is synthesized
with explicit $\mathcal{L}_2$ performance bounds. The formulation yields a
nonlinear estimator that operates directly on the governing equations and
avoids reliance on local linearizations. Dominant nonlinearities are expressed
as structured real uncertainties, while measurement fidelity is represented
through range-dependent weighting with Earth-Moon distances reconstructed from
line-of-sight geometry. The sensing architecture assumes passive
star-tracker-class optical instruments, eliminating the need for time-of-flight
ranging or precision clocks. Simulations demonstrate bounded estimation errors
and smooth position tracking over multiple orbital periods, with the largest
deviations observed in the out-of-plane states, consistent with the stiffness
of the vertical dynamics and the limitations of angle-only observability.
Application to a Near Rectilinear Halo Orbit (NRHO) illustrates that the
framework can achieve robust onboard navigation with bounded estimation errors
with flight-representative sensors.

</details>


### [189] [Multi-Loop Design of Virtual Synchronous Machine Control for DFIG-Based Wind Farms](https://arxiv.org/abs/2510.05043)
*Javier Garcia-Aguilar,Aurelio Garcia-Cerrada,Juan L. Zamora,Emilio Bueno,Elena Saiz,Almudena Muñoz-Babiano,Mohammad E. Zarei*

Main category: eess.SY

TL;DR: 提出了一种协调的频率域方法，用于调谐作为虚拟同步机运行的风电场中双馈感应发电机的所有控制层，通过单次优先迭代将每个本地开环重塑为明确的相位裕度目标。


<details>
  <summary>Details</summary>
Motivation: 同步发电机被换流器接口的可再生能源替代，要求风电场在日益薄弱的电网条件下提供惯性、阻尼和电压支持。

Method: 基于完整的小信号线性化，保持回路间和机间耦合，通过单次优先迭代将每个本地开环重塑为明确的相位裕度目标，仅使用商业仿真套件中的经典环路整形工具。

Result: 所得控制器提供了接近设计阶段编程的阶跃响应和稳定裕度，尽管控制回路之间存在交叉耦合。

Conclusion: 该方法易于应用于工业规模项目，因为控制器合成完全依赖于商业仿真套件中可用的经典环路整形工具。

Abstract: The displacement of synchronous generators by converter-interfaced renewable
energy sources obliges wind farms to provide inertia, damping, and voltage
support, above all in increasingly weak grid conditions. This paper presents a
co-ordinated frequency-domain methodology for tuning all control layers of
doubly-fed induction generators (DFIGs) within a wind farm operated as a
Virtual Synchronous Machine (VSM). Starting from a full small-signal
linearisation that preserves loop-to-loop and machine-to-machine couplings, the
procedure reshapes every local open loop to explicit phase-margin targets
through a single, prioritised iteration. The resulting controllers provide a
step response and stability margins close to those programmed at the design
stage, in spite of the cross coupling between control loops. Since controller
synthesis relies exclusively on classical loop-shaping tools available in
commercial simulation suites, it is readily applicable to industrial-scale
projects.

</details>


### [190] [PowerPlots: An Open Source Power Grid Visualization and Data Analysis Framework for Academic Research](https://arxiv.org/abs/2510.05063)
*Noah Rhodes*

Main category: eess.SY

TL;DR: PowerPlots.jl是一个用于复杂电网系统的数据可视化工具，旨在促进研究过程中的数据探索和研究成果的沟通交流。


<details>
  <summary>Details</summary>
Motivation: 电网是世界上最复杂的系统之一，数据可视化对于理解复杂系统至关重要。需要开发工具来支持电网数据的研究探索和成果展示。

Method: 开发了PowerPlots.jl数据可视化工具，并创建了配套工具将电网数据转换为图拓扑或数据框格式，提高与其他应用的兼容性。

Result: PowerPlots.jl具有高度灵活性，使研究人员能够更好地理解和沟通复杂电网研究中的问题。

Conclusion: PowerPlots.jl成功地为电网研究提供了有效的数据可视化解决方案，支持研究探索和成果展示的双重需求。

Abstract: Data visualization is important for developing an understanding of a complex
system. PowerPlots.jl is a data visualization tool for power grids, one of the
most complex systems in the world. The design of PowerPlots.jl is intended to
facilitate exploration of power grid data while performing research and to
facilitate communication of research findings to an audience. Several tools
created to support this software also facilitate analysis of power grid data by
transforming the data into graph topology or data-frame data formats that are
more compatible for some applications. The high level of flexibility in
PowerPlots.jl enables researchers who are developing and analyzing methods for
solving novel power grid problems to better understand and communicate the
complexities of their research.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [191] [Robust and efficient estimation for the Generalized Extreme-Value distribution with application to flood frequency analysis in the UK](https://arxiv.org/abs/2510.03338)
*Nathan Huet,Ilaria Prosdocimi*

Main category: stat.AP

TL;DR: 提出了一种基于密度功率散度最小化的稳健估计器，用于极端值建模中的广义极值分布参数估计，通过调节参数α平衡稳健性和效率


<details>
  <summary>Details</summary>
Motivation: 传统极大似然估计在极端值建模中样本量有限时对异常值敏感，需要更稳健的估计方法

Method: 基于密度功率散度最小化的稳健估计器，通过调节参数α控制稳健性（α=0时为MLE，α=1时为L2估计器）

Result: 建立了估计器的理论性质（渐近正态性和影响函数有界性），并通过实证比较和洪水频率分析案例验证了方法的有效性

Conclusion: 提出的稳健估计器在极端值建模中具有良好的理论性质和实际应用价值

Abstract: A common approach for modeling extremes, such as peak flow or high
temperatures, is the three-parameter Generalized Extreme-Value distribution.
This is typically fit to extreme observations, here defined as maxima over
disjoint blocks. This results in limited sample sizes and consequently, the use
of classic estimators, such as the maximum likelihood estimator, may be
inappropriate, as they are highly sensitive to outliers. To address these
limitations, we propose a novel robust estimator based on the minimization of
the density power divergence, controlled by a tuning parameter $\alpha$ that
balances robustness and efficiency. When $\alpha = 0$, our estimator coincides
with the maximum likelihood estimator; when $\alpha = 1$, it corresponds to the
$L^2$ estimator, known for its robustness. We establish convenient theoretical
properties of the proposed estimator, including its asymptotic normality and
the boundedness of its influence function for $\alpha > 0$. The practical
efficiency of the method is demonstrated through empirical comparisons with the
maximum likelihood estimator and other robust alternatives. Finally, we
illustrate its relevance in a case study on flood frequency analysis in the UK
and provide some general conclusions in Section 6.

</details>


### [192] [Bayesian Variable Selection for Censored Spatial Responses with Application to PFAS Concentrations in California](https://arxiv.org/abs/2510.03681)
*Suman Majumder,Indranil Sahoo*

Main category: stat.AP

TL;DR: 提出了一种贝叶斯层次框架，用于分析地下水中PFAS污染物的高维变量选择问题，结合了空间过程模型和审查数据处理的集成方法。


<details>
  <summary>Details</summary>
Motivation: PFAS是持久性环境污染物，分析地下水中PFAS具有挑战性，因为存在左审查和强空间依赖性，需要稳健的统计工具从大量候选预测因子中识别关键驱动因素。

Method: 采用贝叶斯层次框架，通过近似高斯过程将审查集成到空间过程模型中，并使用全局-局部收缩先验进行高维变量选择，评估了三种后选择策略。

Result: 应用于加州地下水中PFOS浓度数据，模型识别出一组简洁可解释的预测因子，包括人口构成、工业设施数量、机场邻近度、交通密度以及环境特征如草本覆盖和海拔。

Conclusion: 该方法在审查、空间、高维背景下提供了稳定可解释的推断，为影响PFAS浓度的环境和工业因素提供了可操作的见解。

Abstract: Per- and polyfluoroalkyl substances (PFAS) are persistent environmental
pollutants of major public health concern due to their resistance to
degradation, widespread presence, and potential health risks. Analyzing PFAS in
groundwater is challenging due to left-censoring and strong spatial dependence.
Although PFAS levels are influenced by sociodemographic, industrial, and
environmental factors, the relative importance of these drivers remains
unclear, highlighting the need for robust statistical tools to identify key
predictors from a large candidate set. We present a Bayesian hierarchical
framework that integrates censoring into a spatial process model via
approximate Gaussian processes and employs a global-local shrinkage prior for
high-dimensional variable selection. We evaluate three post-selection
strategies, namely, credible interval rules, shrinkage weight thresholds, and
clustering-based inclusion and compare their performance in terms of predictive
accuracy, censoring robustness, and variable selection stability through
cross-validation. Applied to PFOS concentrations in California groundwater, the
model identifies a concise, interpretable set of predictors, including
demographic composition, industrial facility counts, proximity to airports,
traffic density, and environmental features such as herbaceous cover and
elevation. These findings demonstrate that the proposed approach delivers
stable, interpretable inference in censored, spatial, high-dimensional
contexts, thereby offering actionable insights into the environmental and
industrial factors affecting PFAS concentrations.

</details>


### [193] [Statistical Crime Linkage: Evaluating approaches within the Covenant for Using AI in Policing](https://arxiv.org/abs/2510.03730)
*Nathan A. Judd,Amy V. Tansell,Benjamin Costello,Liam Leonard,Jessica Woodhams,Rowland G. Seymour*

Main category: stat.AP

TL;DR: 本文研究了用于犯罪关联的统计和机器学习方法，特别关注可解释性和透明度，并在英国浪漫欺诈数据集上进行了评估。


<details>
  <summary>Details</summary>
Motivation: 传统犯罪关联主要使用逻辑回归，但需要探索更多符合AI警务公约中可解释性和透明度原则的新方法。

Method: 研究了回归、抽样和机器学习等多种方法，提出了一个敏感、可解释且透明的机器学习模型用于犯罪关联。

Result: 在361名浪漫欺诈受害者的数据集上验证了所提方法的有效性，展示了该方法在未知关联状态数据集上的应用潜力。

Conclusion: 提出的机器学习模型能够支持执法机构的犯罪关联工作，同时满足可解释性和透明度的要求。

Abstract: Linking crimes by modus operandi has long been employed as an effective tool
for crime investigation. The standard statistical method that underpins
statistical crime linkage has been logistic regression. The simplicity and
interpretability of this approach has been seen as an advantage for law
enforcement agencies using statistical crime linkage. In 2023, the National
Police Chiefs' Council published the Covenant for Using Artificial Intelligence
in Policing designed to guide the development of novel methods for use within
policing. In this article, we investigate more statistical and machine learning
methods that could underpin crime linkage models. We investigate a range of
methods including regression-, sampling-, and machine learning-based techniques
and evaluate them against the principles of Explainability and Transparency
from the Covenant. We investigate our methods on a new data set on romance
fraud in the UK, where 361 victims of fraud reported the behaviours and
characteristics of the suspects involved in their case. We propose a sensitive,
Explainable, and Transparent machine learning model for crime linkage and
demonstrate how this method could support crime linkage efforts by law
enforcement agencies using a dataset of romance fraud with unknown linkage
status.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [194] [Embedding Sustainability in Software Engineering Curriculum: A Case Study](https://arxiv.org/abs/2510.03321)
*Ruzanna Chitchyan,Niki Mahmoudi*

Main category: cs.CY

TL;DR: 该论文通过案例研究探讨了如何在软件工程课程中嵌入可持续性，使用可持续性意识框架、目标讨论问题和绿色软件基金会模式来指导学术人员和学生共同识别整合机会。


<details>
  <summary>Details</summary>
Motivation: 可持续性日益被认为是工程教育的关键维度，但将其整合到软件工程课程中仍然是一个挑战。

Method: 采用案例研究方法，在一个大学的软件工程项目中，通过可持续性意识框架的五个维度、目标讨论问题和绿色软件基金会模式的好实践例子，指导学术人员和学生共同识别整合机会。

Result: 研究强调了实用的步骤，包括使用框架、说明性例子、学生参与和迭代咨询过程，这些可以支持其他机构将可持续性嵌入其课程中。

Conclusion: 将可持续性整合到软件工程课程中是必要且紧迫的步骤，以培养软件工程毕业生成为我们变化社会中具有可持续性意识的专业人士。

Abstract: Sustainability is increasingly recognized as a critical dimension of
engineering education, yet its integration into Software Engineering curricula
remains a challenge. This paper reports on a case study that examines how
sustainability is being embedded across modules in the Software Engineering
program at one university. The paper outlines the process through which
academics and students co-identified opportunities for integration, guided by
the five dimensions of the Sustainability Awareness Framework, targeted
discussion questions, and good practice examples drawn from the Green Software
Foundation patterns. The study highlights practical steps - including the use
of frameworks, illustrative examples, student engagement, and iterative
consultative processes - that can support other institutions seeking to embed
sustainability into their programs. We also discuss strategies for integrating
sustainability into the Software Engineering curriculum and argue that such
integration is a necessary and urgent step to prepare Software Engineering
graduates as sustainability-aware professionals in our changing society.

</details>


### [195] [When Patients Go to "Dr. Google" Before They Go to the Emergency Department](https://arxiv.org/abs/2510.03329)
*Michael A Grasso,Alexandra Rogalski,Naveed Farrukh,Anantaa Kotal,Enrique Calleros*

Main category: cs.CY

TL;DR: 约三分之一成年人在急诊就诊前会搜索健康信息，其中75%遇到不准确内容。研究发现这类搜索会影响患者护理，搜索者通常更年轻、更健康、教育程度更高，他们接受检查、药物和住院的可能性更低，但更可能擅自离院和获得阿片类药物。


<details>
  <summary>Details</summary>
Motivation: 了解互联网健康信息搜索如何影响急诊患者的护理过程和结果，特别是考虑到大量患者遇到不准确信息的情况。

Method: 对12个月内576名急诊患者中的214名进行观察性研究，调查急诊前的互联网使用情况，提取人口统计学、合并症、病情严重程度、医嘱、处方和处置等数据。

Result: 搜索者接受实验室检查（RR 0.78）、影像学检查（RR 0.75）、药物治疗（RR 0.67）和住院（RR 0.68）的可能性更低，但更可能擅自离院（RR 1.67）和获得阿片类药物（RR 1.56）。

Conclusion: 不准确的健康信息可能导致患者期望与实际情况不匹配，从而改变护理提供方式。

Abstract: Approximately one-third of adults search the internet for health information
before visiting an emergency department (ED), with 75% encountering inaccurate
content. This study examines how such searches influence patient care. We
conducted an observational study of ED visits over a 12-month period, surveying
214 of 576 patients about pre-ED internet use. Data on demographics,
comorbidities, acuity, orders, prescriptions, and dispositions were extracted.
Patients who searched were typically younger, healthier, and more educated.
Most used a general search engine to ask symptom-related questions. Compared to
non-searchers, they were less likely to receive lab tests (RR 0.78, p=0.053),
imaging (RR 0.75, p=0.094), medications (RR 0.67, p=0.038), or admission (RR
0.68, p=0.175). They were more likely to leave against medical advice (RR 1.67,
p=0.067) and receive opioids (RR 1.56, p=0.151). Findings suggest inaccurate
health information may contribute to mismatched expectations and altered care
delivery.

</details>


### [196] [Intelligent Healthcare Ecosystems: Optimizing the Iron Triangle of Healthcare (Access, Cost, Quality)](https://arxiv.org/abs/2510.03331)
*Vivek Acharya*

Main category: cs.CY

TL;DR: 本文提出智能医疗生态系统(iHE)，通过整合生成式AI、联邦学习、互操作性标准和数字孪生等技术，旨在打破医疗成本、质量和可及性之间的"铁三角"困境。


<details>
  <summary>Details</summary>
Motivation: 美国医疗支出占GDP近17%，但存在可及性和结果不均的问题。医疗成本、质量和可及性之间的"铁三角"矛盾促使进行系统级重新设计。

Method: 采用叙事性文献综述方法，回顾近期文献和政策报告，分析历史支出趋势、浪费问题和国际比较。

Result: 提出iHE的核心组件包括AI决策支持、互操作性、远程医疗和自动化，能够减少浪费、个性化护理并支持基于价值的支付。

Conclusion: 协调的iHE可以弯曲甚至打破"铁三角"，推动医疗系统向更可及、可负担和高质量的护理方向发展。

Abstract: The United States spends nearly 17% of GDP on healthcare yet continues to
face uneven access and outcomes. This well-known trade-off among cost, quality,
and access - the "iron triangle" - motivates a system-level redesign. This
paper proposes an Intelligent Healthcare Ecosystem (iHE): an integrated,
data-driven framework that uses generative AI and large language models,
federated learning, interoperability standards (FHIR, TEFCA), and digital twins
to improve access and quality while lowering cost. We review historical
spending trends, waste, and international comparisons; introduce a value
equation that jointly optimizes access, quality, and cost; and synthesize
evidence on the enabling technologies and operating model for iHE. Methods
follow a narrative review of recent literature and policy reports. Results
outline core components (AI decision support, interoperability, telehealth,
automation) and show how iHE can reduce waste, personalize care, and support
value-based payment while addressing privacy, bias, and adoption challenges. We
argue that a coordinated iHE can bend - if not break - the iron triangle,
moving the system toward care that is more accessible, affordable, and high
quality.

</details>


### [197] [Defining a Strategic Action Plan for AI in Higher Education](https://arxiv.org/abs/2510.03343)
*Nikolaos Avouris*

Main category: cs.CY

TL;DR: 本文提出了一个分析高等教育中人工智能挑战的框架，包含五个关键维度和五项战略行动，并映射到主要利益相关者，提供了部署计划。


<details>
  <summary>Details</summary>
Motivation: 分析高等教育机构中人工智能面临的关键挑战，解决国际组织关注的问题和当前技术环境中的担忧。

Method: 提出包含五个关键维度的框架，识别五项战略行动，并将这些行动映射到主要利益相关者，制定部署计划。

Result: 建立了一个涵盖挑战、行动、利益相关者和部署的CASD框架，提供了机构和课程层面的具体AI行动示例。

Conclusion: 该框架为高等教育机构应对AI挑战提供了系统性的指导，帮助各利益相关者采取适当行动来应对当前发展。

Abstract: This paper discusses key challenges of Artificial Intelligence in Education,
with main focus on higher education institutions. We start with reviewing
normative actions of international organizations and concerns expressed about
the current technical landscape. Then we proceed with proposing a framework
that comprises five key dimensions relating to the main challenges relating to
AI in higher education institutions, followed by five key strategic actions
that the main stakeholders need to take in order to address the current
developments. We map these actions to the main stakeholders of higher education
and propose a deployment plan. This defines a framework along the dimensions:
Challenges, Actions, Stakeholders, Deployment CASD. Examples of AI specific
actions at the institutional and individual course level are also provided and
discussed.

</details>


### [198] [An Adaptive Responsible AI Governance Framework for Decentralized Organizations](https://arxiv.org/abs/2510.03368)
*Kiana Jafari Meimandi,Anka Reuel,Gabriela Aranguiz-Dias,Hatim Rahama,Ala-Eddine Ayadi,Xavier Boullier,Jérémy Verdo,Louis Montanie,Mykel Kochenderfer*

Main category: cs.CY

TL;DR: 本文通过大学与企业合作案例研究，探讨全球分散组织中负责任AI治理的评估挑战，提出自适应RAI治理框架（ARGO），平衡中央协调与地方自治。


<details>
  <summary>Details</summary>
Motivation: 现有RAI框架在具有分布式决策权的复杂组织环境中应用不足，需要研究如何在实际组织环境中实施RAI治理。

Method: 采用案例研究方法，在跨国企业的多个业务部门和AI用例中进行RAI评估，识别关键实施模式。

Result: 发现四个关键模式：集团指导与地方解读的复杂互动、抽象原则转化为操作实践的挑战、实施方法的区域和职能差异、风险监督责任不一致。基于此提出ARGO框架。

Conclusion: 模块化治理方法能够适应组织复杂性，同时保持与负责任AI原则的一致性，为从RAI原则向操作实践过渡提供实用指导。

Abstract: This paper examines the assessment challenges of Responsible AI (RAI)
governance efforts in globally decentralized organizations through a case study
collaboration between a leading research university and a multinational
enterprise. While there are many proposed frameworks for RAI, their application
in complex organizational settings with distributed decision-making authority
remains underexplored. Our RAI assessment, conducted across multiple business
units and AI use cases, reveals four key patterns that shape RAI
implementation: (1) complex interplay between group-level guidance and local
interpretation, (2) challenges translating abstract principles into operational
practices, (3) regional and functional variation in implementation approaches,
and (4) inconsistent accountability in risk oversight. Based on these findings,
we propose an Adaptive RAI Governance (ARGO) Framework that balances central
coordination with local autonomy through three interdependent layers: shared
foundation standards, central advisory resources, and contextual local
implementation. We contribute insights from academic-industry collaboration for
RAI assessments, highlighting the importance of modular governance approaches
that accommodate organizational complexity while maintaining alignment with
responsible AI principles. These lessons offer practical guidance for
organizations navigating the transition from RAI principles to operational
practice within decentralized structures.

</details>


### [199] [TriQuest:An AI Copilot-Powered Platform for Interdisciplinary Curriculum Design](https://arxiv.org/abs/2510.03369)
*Huazhen Wang,Huimin Yang,Hainbin Lin,Yan Dong,Lili Chen,Liangliang Xia,Wenwen Xu*

Main category: cs.CY

TL;DR: TriQuest是一个AI辅助平台，利用大语言模型和知识图谱帮助教师高效生成高质量的跨学科教案，提高课程设计效率75%，教案质量评分提升41%。


<details>
  <summary>Details</summary>
Motivation: 跨学科教学是现代课程改革的核心，但在知识整合和教案设计方面存在挑战，现有工具缺乏足够的教学和领域深度。

Method: 使用大语言模型和知识图谱，通过直观的GUI界面，实现多学科知识的智能整合，并采用人机协作的审查流程确保质量和创新性。

Result: 在43名教师的研究中，课程设计效率平均提高75%，教案质量评分提升41%，显著降低了设计障碍和认知负荷。

Conclusion: 这项工作展示了利用智能技术赋能教师专业发展的新范式。

Abstract: Interdisciplinary teaching is a cornerstone of modern curriculum reform, but
its implementation is hindered by challenges in knowledge integration and
time-consuming lesson planning. Existing tools often lack the required
pedagogical and domain-specific depth.We introduce TriQuest, an AI-copilot
platform designed to solve these problems. TriQuest uses large language models
and knowledge graphs via an intuitive GUI to help teachers efficiently generate
high-quality interdisciplinary lesson plans. Its core features include
intelligent knowledge integration from various disciplines and a human-computer
collaborative review process to ensure quality and innovation.In a study with
43 teachers, TriQuest increased curriculum design efficiency by an average of
75% and improved lesson plan quality scores by 41%. It also significantly
lowered design barriers and cognitive load. Our work presents a new paradigm
for empowering teacher professional development with intelligent technologies.

</details>


### [200] [Lightweight Prompt Engineering for Cognitive Alignment in Educational AI: A OneClickQuiz Case Study](https://arxiv.org/abs/2510.03374)
*Antoun Yaacoub,Zainab Assaghir,Jérôme Da-Rugna*

Main category: cs.CY

TL;DR: 本研究探讨了轻量级提示工程策略对AI生成问题认知对齐的影响，发现详细明确的提示对于精确的认知对齐至关重要。


<details>
  <summary>Details</summary>
Motivation: AI在教育技术中的快速集成虽然前景广阔，但AI生成内容的质量和教学对齐仍然是关键挑战。

Method: 在OneClickQuiz Moodle插件中评估三种提示变体：详细基线、简化版本和基于角色的方法，涵盖布鲁姆分类法的知识、应用和分析层次，使用自动分类模型和人工审查。

Result: 详细提示能实现精确的认知对齐，而简化和基于角色的提示虽然能生成清晰相关的问题，但经常与目标布鲁姆层次不对齐，产生过于复杂或偏离预期认知目标的结果。

Conclusion: 战略性提示工程对于培养教学合理的AI驱动教育解决方案至关重要，建议在学习和智能学习环境中优化AI以生成高质量内容。

Abstract: The rapid integration of Artificial Intelligence (AI) into educational
technology promises to revolutionize content creation and assessment. However,
the quality and pedagogical alignment of AI-generated content remain critical
challenges. This paper investigates the impact of lightweight prompt
engineering strategies on the cognitive alignment of AI-generated questions
within OneClickQuiz, a Moodle plugin leveraging generative AI. We evaluate
three prompt variants-a detailed baseline, a simpler version, and a
persona-based approach-across Knowledge, Application, and Analysis levels of
Bloom's Taxonomy. Utilizing an automated classification model (from prior work)
and human review, our findings demonstrate that explicit, detailed prompts are
crucial for precise cognitive alignment. While simpler and persona-based
prompts yield clear and relevant questions, they frequently misalign with
intended Bloom's levels, generating outputs that are either too complex or
deviate from the desired cognitive objective. This study underscores the
importance of strategic prompt engineering in fostering pedagogically sound
AI-driven educational solutions and advises on optimizing AI for quality
content generation in learning analytics and smart learning environments.

</details>


### [201] [Can an AI-Powered Presentation Platform Based On The Game "Just a Minute" Be Used To Improve Students' Public Speaking Skills?](https://arxiv.org/abs/2510.03379)
*Frederic Higham,Tommy Yuan*

Main category: cs.CY

TL;DR: 本研究探索将AI和游戏化应用于面向大学生的演讲平台，基于"Just a Minute"游戏规则，帮助学生提高母语公开演讲能力。


<details>
  <summary>Details</summary>
Motivation: 学生面临公开演讲焦虑等困难，AI驱动的演讲平台通过沉浸式AI观众和实时反馈来提升学生演讲技能和自信心。

Method: 招募约克大学学生参与评估，填写问卷、玩两次游戏，收集游戏过程中的得分和违规次数等统计数据。

Result: 学生认为游戏有前景，相信长期使用能提高演讲技能，但需要更多研究证明其长期有效性。

Conclusion: 基于JAM的AI游戏化演讲平台在短期内显示出潜力，但需要进一步研究验证长期效果。

Abstract: This study explores the effectiveness of applying AI and gamification into a
presentation platform aimed at University students wanting to improve their
public speaking skills in their native tongue. Specifically, a platform based
on the radio show, Just a Minute (JAM), is explored. In this game, players are
challenged to speak fluently on a topic for 60 seconds without repeating
themselves, hesitating or deviating from the topic. JAM has proposed benefits
such as allowing students to improve their spontaneous speaking skills and
reduce their use of speech disfluencies ("um", "uh", etc.).
  Previous research has highlighted the difficulties students face when
speaking publicly, the main one being anxiety. AI Powered Presentation
Platforms (AI-PPPs), where students can speak with an immersive AI audience and
receive real-time feedback, have been explored as a method to improve student's
speaking skills and confidence. So far they have shown promising results which
this study aims to build upon.
  A group of students from the University of York are enlisted to evaluate the
effectiveness of the JAM platform. They are asked to fill in a questionnaire,
play through the game twice and then complete a final questionnaire to discuss
their experiences playing the game. Various statistics are gathered during
their gameplay such as the number of points they gained and the number of rules
they broke. The results showed that students found the game promising and
believed that their speaking skills could improve if they played the game for
longer. More work will need to be carried out to prove the effectiveness of the
game beyond the short term.

</details>


### [202] [Analyzing the Performance of a 2.72kWp Rooftop Grid tied Photovoltaic System in Tarlac City, Philippines](https://arxiv.org/abs/2510.03487)
*Aldrin Joar Rodrigo Taduran,Leo P. Piao*

Main category: cs.CY

TL;DR: 该论文分析了菲律宾Tarlac市2020-2023年2.72kWp屋顶并网光伏系统的性能表现，系统年发电量3699kWh，性能比77.10%，投资回收期6年，投资回报率238.2%。


<details>
  <summary>Details</summary>
Motivation: 随着屋顶并网光伏系统在住宅和工业区的普及，需要评估其实际性能表现，以验证太阳能发电的经济效益和环境效益。

Method: 通过测量阵列产量(YA)、参考产量(YR)和最终产量(YF)等关键性能指标，分析系统损失(LS)和捕获损失(LC)，计算容量利用因子(CUF)和性能比(PR)。

Result: 系统年发电量3699kWh，其中2380kWh馈入电网，性能比77.10%，阵列效率12.89%，逆变器效率94.3%，系统效率12.16%，年收入690.59美元。

Conclusion: 屋顶并网光伏系统具有良好的经济性和环境效益，投资回收期短，投资回报率高，能有效减少碳排放，是可行的可再生能源解决方案。

Abstract: Residential and industrial areas are using rooftop grid-tied Photovoltaic
(PV) systems, which are becoming increasingly popular. This is because solar
energy reduces electrical consumption and provides free energy, while also
lowering carbon emissions to create a more sustainable environment. This paper
aims to analyze the 2.72kW p rooftop grid-tied PV system performance between
2020 and 2023 in Tarlac City, Philippines. The PV generated yearly is measured
by Array Yield (YA), Reference Yield (YR), and Final Yield (YF), which were
found to be valued at 3.12, 3.9, and 3.01 kWh/kWp, respectively. The efficiency
can decrease due to System Loss (LS) and Capture Loss (LC), which were 0.78 and
0.12 kWh/kWp, respectively. This results in a Capacity Utilization Factor (CUF)
of 15.52% and a Performance Ratio (PR) of 77.10%. The productivity of PV
resulted in an array efficiency was 12.89%, an inverter efficiency was 94.3%,
and a system efficiency was 12.16%. PV energy generation was 3,699 kWh, with
2380 kWh fed into the grid annually. The system's annual revenue is $690.59.
The payback period is 6 years with a 238.2% Return On Investment (ROI). Carbon
emissions are reduced by 0.379 tCO2/kWp/yr.

</details>


### [203] [Red Lines and Grey Zones in the Fog of War: Benchmarking Legal Risk, Moral Harm, and Regional Bias in Large Language Model Military Decision-Making](https://arxiv.org/abs/2510.03514)
*Toby Drinkall*

Main category: cs.CY

TL;DR: 该研究开发了一个评估框架，用于测试大型语言模型在模拟军事冲突中的目标选择行为，发现现成的LLM在模拟环境中表现出令人担忧且不可预测的违规行为，包括违反国际人道法原则攻击平民目标。


<details>
  <summary>Details</summary>
Motivation: 随着军事组织考虑将大型语言模型集成到指挥控制系统中用于规划和决策支持，了解其行为倾向变得至关重要，特别是评估其在目标选择中的法律和道德风险。

Method: 开发基于国际人道法和军事学说的四个评估指标，通过90个多智能体、多轮危机模拟，在三个地理区域评估GPT-4o、Gemini-2.5和LLaMA-3.1三个前沿模型的行为。

Result: 所有模型都违反了国际人道法的区分原则，攻击平民目标的比例从16.7%到66.7%不等。伤害容忍度在危机模拟中逐步升级，模型间存在显著差异，LLaMA-3.1表现最差。

Conclusion: 这项工作提供了一个概念验证，展示了在决策支持系统中使用LLM可能出现的潜在行为风险，以及一个可复现的基准测试框架，用于标准化部署前测试。

Abstract: As military organisations consider integrating large language models (LLMs)
into command and control (C2) systems for planning and decision support,
understanding their behavioural tendencies is critical. This study develops a
benchmarking framework for evaluating aspects of legal and moral risk in
targeting behaviour by comparing LLMs acting as agents in multi-turn simulated
conflict. We introduce four metrics grounded in International Humanitarian Law
(IHL) and military doctrine: Civilian Target Rate (CTR) and Dual-use Target
Rate (DTR) assess compliance with legal targeting principles, while Mean and
Max Simulated Non-combatant Casualty Value (SNCV) quantify tolerance for
civilian harm.
  We evaluate three frontier models, GPT-4o, Gemini-2.5, and LLaMA-3.1, through
90 multi-agent, multi-turn crisis simulations across three geographic regions.
Our findings reveal that off-the-shelf LLMs exhibit concerning and
unpredictable targeting behaviour in simulated conflict environments. All
models violated the IHL principle of distinction by targeting civilian objects,
with breach rates ranging from 16.7% to 66.7%. Harm tolerance escalated through
crisis simulations with MeanSNCV increasing from 16.5 in early turns to 27.7 in
late turns. Significant inter-model variation emerged: LLaMA-3.1 selected an
average of 3.47 civilian strikes per simulation with MeanSNCV of 28.4, while
Gemini-2.5 selected 0.90 civilian strikes with MeanSNCV of 17.6. These
differences indicate that model selection for deployment constitutes a choice
about acceptable legal and moral risk profiles in military operations.
  This work seeks to provide a proof-of-concept of potential behavioural risks
that could emerge from the use of LLMs in Decision Support Systems (AI DSS) as
well as a reproducible benchmarking framework with interpretable metrics for
standardising pre-deployment testing.

</details>


### [204] [A Survey of LLM-Based Applications in Programming Education: Balancing Automation and Human Oversight](https://arxiv.org/abs/2510.03719)
*Griffin Pitts,Anurata Prabha Hridi,Arun-Balajiee Lekshmi-Narayanan*

Main category: cs.CY

TL;DR: 该调查论文综述了大型语言模型在编程教育中的应用，重点关注代码反馈、评估和知识建模三个领域，发现结合教育者专业知识的半自动化方法比全自动化方法更有效。


<details>
  <summary>Details</summary>
Motivation: 新手程序员需要及时个性化的支持，但教师资源有限。大型语言模型提供了扩展这种支持的机会，但其有效性取决于技术能力与教学目标的匹配程度。

Method: 通过调查分析近期关于LLM在编程教育中应用的研究，识别设计模式，特别关注代码反馈、评估和知识建模三个核心领域。

Result: 研究发现，当教育者专业知识通过人在回路监督、支架式教学和评估来补充模型输出时，干预措施最有效。全自动化方法在捕捉编程教育的教学细微差别方面存在局限。

Conclusion: 未来研究应聚焦于提高透明度、加强与教学法的对齐，以及开发能够灵活适应不同学习情境需求的系统。人在回路设计和课程特定适应是未来改进的有希望方向。

Abstract: Novice programmers benefit from timely, personalized support that addresses
individual learning gaps, yet the availability of instructors and teaching
assistants is inherently limited. Large language models (LLMs) present
opportunities to scale such support, though their effectiveness depends on how
well technical capabilities are aligned with pedagogical goals. This survey
synthesizes recent work on LLM applications in programming education across
three focal areas: formative code feedback, assessment, and knowledge modeling.
We identify recurring design patterns in how these tools are applied and find
that interventions are most effective when educator expertise complements model
output through human-in-the-loop oversight, scaffolding, and evaluation. Fully
automated approaches are often constrained in capturing the pedagogical nuances
of programming education, although human-in-the-loop designs and course
specific adaptation offer promising directions for future improvement. Future
research should focus on improving transparency, strengthening alignment with
pedagogy, and developing systems that flexibly adapt to the needs of varied
learning contexts.

</details>


### [205] [R v F (2025): Addressing the Defence of Hacking](https://arxiv.org/abs/2510.03764)
*Junade Ali*

Main category: cs.CY

TL;DR: 本文通过R v F案例研究，分析了黑客攻击辩护（又称"特洛伊木马辩护"或"SODDI辩护"）在计算机犯罪案件中的应对策略，为数字取证调查人员提供了实用技术和方法。


<details>
  <summary>Details</summary>
Motivation: 计算机犯罪案件中黑客攻击辩护普遍存在且对刑事司法系统构成挑战，但学术文献中缺乏关于数字取证调查人员如何应对此类辩护的案例研究。

Method: 作者与警方调查人员合作，通过R v F案例研究，调查被告提出的黑客攻击辩护的有效性，并向陪审团提供经验证据。

Result: 该研究首次提供了此类案例研究，展示了数字取证调查人员应对黑客攻击辩护的实际经验和技术。

Conclusion: 本研究为数字取证调查人员提供了应对黑客攻击辩护的实用经验和技术，有助于法院正确区分无辜者和有罪者。

Abstract: The defence of hacking (sometimes referred to as the "Trojan Horse Defence"
or the "SODDI Defence", Some Other Dude Did It Defence) is prevalent in
computer cases and a challenge for those working in the criminal justice
system. Historical reviews of cases have demonstrated the defence operating to
varying levels of success. However, there remains an absence in academic
literature of case studies of how digital forensics investigators can address
this defence, to assist courts in acquitting the innocent and convicting the
guilty. This case study follows the case of R v F where a defendant asserted
this defence and the author worked alongside a police investigator to
investigate the merits of the defence and bring empirical evidence before the
jury. As the first case study of its kind, it presents practical lessons and
techniques for digital forensic investigators.

</details>


### [206] [AI Adoption Across Mission-Driven Organizations](https://arxiv.org/abs/2510.03868)
*Dalia Ali,Muneeb Ahmed,Hailan Wang,Arfa Khan,Naira Paola Arnez Jordan,Sunnie S. Y. Kim,Meet Dilip Muchhala,Anne Kathrin Merkle,Orestis Papakyriakopoulos*

Main category: cs.CY

TL;DR: 该研究通过访谈发现，使命驱动组织对AI的采用是有条件的，只在能增强组织自主权和使命完整性的情况下使用，同时保持以人为中心的方法。


<details>
  <summary>Details</summary>
Motivation: 尽管AI有望解决全球挑战，但对使命驱动组织AI采用的实证理解仍然有限，特别是资源受限、价值观驱动的组织如何整合AI缺乏研究。

Method: 对来自全球南北环境、人道主义和开发组织的15名从业者进行半结构化访谈，并进行主题分析。

Result: 使命驱动组织有选择地采用AI，在内容创作和数据分析方面部署较成熟，但对关键任务应用保持人工监督。当AI效率与组织价值观冲突时，决策会停滞而非寻求折中。

Conclusion: 使命驱动组织的AI采用应被理解为有条件的而非必然的，只有在能加强组织自主权和使命完整性、同时保持以人为中心方法的情况下才会推进。

Abstract: Despite AI's promise for addressing global challenges, empirical
understanding of AI adoption in mission-driven organizations (MDOs) remains
limited. While research emphasizes individual applications or ethical
principles, little is known about how resource-constrained, values-driven
organizations navigate AI integration across operations. We conducted thematic
analysis of semi-structured interviews with 15 practitioners from
environmental, humanitarian, and development organizations across the Global
North and South contexts. Our analysis examines how MDOs currently deploy AI,
what barriers constrain adoption, and how practitioners envision future
integration. MDOs adopt AI selectively, with sophisticated deployment in
content creation and data analysis while maintaining human oversight for
mission-critical applications. When AI's efficiency benefits conflict with
organizational values, decision-making stalls rather than negotiating
trade-offs. This study contributes empirical evidence that AI adoption in MDOs
should be understood as conditional rather than inevitable, proceeding only
where it strengthens organizational sovereignty and mission integrity while
preserving human-centered approaches essential to their missions.

</details>


### [207] [Quantifying Gender Stereotypes in Japan between 1900 and 1999 with Word Embeddings](https://arxiv.org/abs/2510.03905)
*Shintaro Sakai,Haewoon Kwak,Jisun An,Akira Matsui*

Main category: cs.CY

TL;DR: 使用100年的词嵌入分析日本性别刻板印象演变，发现工作、政治领域女性刻板印象增强，家庭领域也保持女性化，表明女性承担多重角色而非角色替代。


<details>
  <summary>Details</summary>
Motivation: 量化日本1900-1999年性别刻板印象的演变，检验语言中的性别关联是否反映女性在职场和政治中参与度的增加。

Method: 训练100个年度词嵌入模型，通过计算词语与女性/男性属性词余弦相似度的差异来定义性别刻板印象值，分析家庭、工作、政治和职业领域的演变轨迹。

Result: 工作和政治领域随时间变得更女性刻板化，家庭领域也保持女性化；职业的女性刻板印象强度与女性从业比例正相关，词嵌入能较好反映人口统计变化。

Conclusion: 语言中的性别刻板印象部分反映了女性社会角色的变化，但女性被赋予多重角色而非单一角色替代，词嵌入方法能有效追踪社会态度演变。

Abstract: We quantify the evolution of gender stereotypes in Japan from 1900 to 1999
using a series of 100 word embeddings, each trained on a corpus from a specific
year. We define the gender stereotype value to measure the strength of a word's
gender association by computing the difference in cosine similarity of the word
to female- versus male-related attribute words. We examine trajectories of
gender stereotype across three traditionally gendered domains: Home, Work, and
Politics, as well as occupations. The results indicate that language-based
gender stereotypes partially evolved to reflect women's increasing
participation in the workplace and politics: Work and Politics domains become
more strongly female-stereotyped over the years. Yet, Home also became more
female-stereotyped, suggesting that women were increasingly viewed as
fulfilling multiple roles such as homemakers, workers, and politicians, rather
than having one role replace another. Furthermore, the strength of female
stereotype for occupations positively correlate with the proportion of women in
each occupation, indicating that word-embedding-based measures of gender
stereotype mirrored demographic shifts to a considerable extent.

</details>


### [208] [Accountability Capture: How Record-Keeping to Support AI Transparency and Accountability (Re)shapes Algorithmic Oversight](https://arxiv.org/abs/2510.04609)
*Shreya Chappidi,Jennifer Cobbe,Chris Norval,Anjali Mazumder,Jatinder Singh*

Main category: cs.CY

TL;DR: 本文探讨了为算法问责而实施的记录保存实践如何通过'问责捕获'重新配置社会技术过程，产生包括监控、隐私和数据保护在内的广泛影响。


<details>
  <summary>Details</summary>
Motivation: 问责制度鼓励记录保存以实现透明度，但实施这种记录保存会引入未被充分探索的考虑因素、风险和后果。

Method: 通过调查100名从业者，记录和分析实践中的记录保存问题，识别其与问责捕获的一致性。

Result: 研究发现广泛的记录保存实践、内部与外部问责要求之间的紧张关系，以及员工对通过问责捕获强加的实践的抵制证据。

Conclusion: 为支持算法问责透明度而实施的记录保存本身可能带来更广泛的影响，这需要从业者、研究人员和政策制定者给予更多关注。

Abstract: Accountability regimes typically encourage record-keeping to enable the
transparency that supports oversight, investigation, contestation, and redress.
However, implementing such record-keeping can introduce considerations, risks,
and consequences, which so far remain under-explored. This paper examines how
record-keeping practices bring algorithmic systems within accountability
regimes, providing a basis to observe and understand their effects. For this,
we introduce, describe, and elaborate 'accountability capture' -- the
re-configuration of socio-technical processes and the associated downstream
effects relating to record-keeping for algorithmic accountability. Surveying
100 practitioners, we evidence and characterise record-keeping issues in
practice, identifying their alignment with accountability capture. We further
document widespread record-keeping practices, tensions between internal and
external accountability requirements, and evidence of employee resistance to
practices imposed through accountability capture. We discuss these and other
effects for surveillance, privacy, and data protection, highlighting
considerations for algorithmic accountability communities. In all, we show that
implementing record-keeping to support transparency in algorithmic
accountability regimes can itself bring wider implications -- an issue
requiring greater attention from practitioners, researchers, and policymakers
alike.

</details>


### [209] [Social bias is prevalent in user reports of hate and abuse online](https://arxiv.org/abs/2510.04748)
*Florence E. Enock,Helen Z. Margetts,Jonathan Bright*

Main category: cs.CY

TL;DR: 研究发现用户举报网络仇恨言论时存在社会偏见，更倾向于举报针对内群体的攻击而非外群体攻击。


<details>
  <summary>Details</summary>
Motivation: 网络仇恨和滥用日益严重，用户举报机制是监控和处理有害内容的重要方式，但用户举报行为可能受到群体身份和政治信仰的偏见影响。

Method: 通过五个预先注册的在线实验，在四种不同群体间情境（政治立场、疫苗接种观点、气候变化信念、堕胎权利立场）中检验举报偏见。

Result: 参与者能可靠地举报滥用内容（约一半的滥用评论被举报），但存在普遍的社会偏见，对内群体攻击的举报率显著高于对外群体攻击。

Conclusion: 了解用户举报行为的偏见对于改进用户干预网络仇恨言论机制、确保更安全的网络环境至关重要。

Abstract: The prevalence of online hate and abuse is a pressing global concern. While
tackling such societal harms is a priority for research across the social
sciences, it is a difficult task, in part because of the magnitude of the
problem. User engagement with reporting mechanisms (flagging) online is an
increasingly important part of monitoring and addressing harmful content at
scale. However, users may not flag content routinely enough, and when they do
engage, they may be biased by group identity and political beliefs. Across five
well-powered and pre-registered online experiments, we examine the extent of
social bias in the flagging of hate and abuse in four different intergroup
contexts: political affiliation, vaccination opinions, beliefs about climate
change, and stance on abortion rights. Overall, participants reported abuse
reliably, with approximately half of the abusive comments in each study
reported. However, a pervasive social bias was present whereby ingroup-directed
abuse was consistently flagged to a greater extent than outgroup-directed
abuse. Our findings offer new insights into the nature of user flagging online,
an understanding of which is crucial for enhancing user intervention against
online hate speech and thus ensuring a safer online environment.

</details>


### [210] [A New Digital Divide? Coder Worldviews, the Slop Economy, and Democracy in the Age of AI](https://arxiv.org/abs/2510.04755)
*Jason Miklian,Kristian Hoelscher*

Main category: cs.CY

TL;DR: 本文通过调查硅谷软件开发者的世界观、伦理观和工作文化，探讨技术如何影响民主生活，揭示了开发者面临的伦理困境和自上而下的压力如何导致设计选择损害民主理想，并分析了新兴的数字鸿沟问题。


<details>
  <summary>Details</summary>
Motivation: 数字技术正在以相互矛盾的方式改变民主生活，需要理解软件开发者的世界观、伦理观和工作文化如何塑造他们构建技术的民主潜力和社会影响。

Method: 对硅谷软件开发者进行原创性调查，并批判性地在Slop经济背景下分析调查结果，探讨信息质量的新数字鸿沟。

Result: 大多数开发者认识到其产品对公民自由和政治话语的影响力，但面临伦理困境和自上而下的压力，导致设计选择损害民主理想；技术创造者信念与他们创造的数字生态系统之间存在强化循环。

Conclusion: 需要更多伦理知情的设计和政策干预来弥合数字鸿沟，确保技术创新在数字时代的下一章支持而非颠覆民主价值观。

Abstract: Digital technologies are transforming democratic life in conflicting ways.
This article bridges two perspectives to unpack these tensions. First, we
present an original survey of software developers in Silicon Valley,
interrogating how coder worldviews, ethics, and workplace cultures shape the
democratic potential and social impact of the technologies they build. Results
indicate that while most developers recognize the power of their products to
influence civil liberties and political discourse, they often face ethical
dilemmas and top-down pressures that can lead to design choices undermining
democratic ideals. Second, we critically investigate these findings in the
context of an emerging new digital divide, not of internet access but of
information quality. We interrogate the survey findings in the context of the
Slop Economy, in which billions of users unable to pay for high-quality content
experience an internet dominated by low-quality, AI-generated ad-driven
content. We find a reinforcing cycle between tech creator beliefs and the
digital ecosystems they spawn. We discuss implications for democratic
governance, arguing for more ethically informed design and policy interventions
to help bridge the digital divide to ensure that technological innovation
supports rather than subverts democratic values in the next chapter of the
digital age.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [211] [Modeling information acquisition via f-divergence and duality](https://arxiv.org/abs/2510.03482)
*Alex Bloedel,Tommaso Denti,Luciano Pomatto*

Main category: econ.TH

TL;DR: 本文介绍了一种基于多元统计散度理论的新实验成本函数——f-信息，它推广了Sims的理性疏忽经典模型以及后验可分离成本函数类别。


<details>
  <summary>Details</summary>
Motivation: 扩展理性疏忽理论，超越互信息的限制，提供更一般的成本函数框架来分析决策问题。

Method: 利用凸对偶和Arrow-Pratt期望效用方法等微观经济学熟悉工具，推导f-信息的最优性条件。

Result: 得到了推广Matejka和McKay(2015)以及Caplin、Dean和Leahy(2019)最优性条件的结果，并在多个典型决策问题中分析了f-信息的影响。

Conclusion: f-信息框架为分析理性疏忽和决策问题提供了强大而通用的工具，能够使用微观经济学的标准方法进行分析。

Abstract: We introduce a new cost function over experiments, f-information, based on
the theory of multivariate statistical divergences, that generalizes Sims's
classic model of rational inattention as well as the class of
posterior-separable cost functions. We characterize its behavioral predictions
by deriving optimality conditions that extend those of Matejka and McKay (2015)
and Caplin, Dean, and Leahy (2019) beyond mutual information. Using these
tools, we study the implications of f-information in a number of canonical
decision problems. A strength of the framework is that it can be analyzed using
familiar methods of microeconomics: convex duality and the Arrow-Pratt approach
to expected utility.

</details>


### [212] [An analysis of government subsidy policies in vaccine supply chain: Innovation, Production, or Consumption?](https://arxiv.org/abs/2510.03661)
*Ran Gu,Enhui Ding,Shigui Ma*

Main category: econ.TH

TL;DR: 本研究在连续时间微分博弈框架下分析政府补贴的三级疫苗供应链，探讨不同补贴策略的有效性，发现技术投资比例补贴在长期更具战略性，而价格敏感度高时数量补贴更优，区块链技术能提升疫苗质量和制造商后期利润。


<details>
  <summary>Details</summary>
Motivation: 疫苗供应链面临诸多效率挑战，政府通过补贴支持疫苗供应链以改善公共卫生成果，需要分析不同补贴策略的有效性和特点。

Method: 采用连续时间微分博弈框架，建立包含疫苗质量和制造商商誉的动态系统方程，分析不同政府补贴策略，并进行数值模拟。

Result: 技术投资比例补贴在长期更具战略性；当公众对疫苗价格高度敏感且个人接种收益与政府目标一致时，数量补贴政策更优；区块链技术能提升疫苗质量和制造商后期盈利能力。

Conclusion: 政府应根据不同情境选择合适的补贴策略，技术投资补贴适合长期发展，数量补贴在特定条件下更有效，区块链技术对疫苗供应链有积极影响。

Abstract: Vaccines play a crucial role in the prevention and control of infectious
diseases. However, the vaccine supply chain faces numerous challenges that
hinder its efficiency. To address these challenges and enhance public health
outcomes, many governments provide subsidies to support the vaccine supply
chain. This study analyzes a government-subsidized, three-tier vaccine supply
chain within a continuous-time differential game framework. The model
incorporates dynamic system equations that account for both vaccine quality and
manufacturer goodwill. The research explores the effectiveness and
characteristics of different government subsidy strategies, considering factors
such as price sensitivity, and provides actionable managerial insights. Key
findings from the analysis and numerical simulations include the following:
First, from a long-term perspective, proportional subsidies for technological
investments emerge as a more strategic approach, in contrast to the short-term
focus of volume-based subsidies. Second, when the public is highly sensitive to
vaccine prices and individual vaccination benefits closely align with
government objectives, a volume-based subsidy policy becomes preferable.
Finally, the integration of blockchain technology positively impacts the
vaccine supply chain, particularly by improving vaccine quality and enhancing
the profitability of manufacturers in the later stages of production.

</details>


### [213] [Traffic jams and driver behavior archetypes](https://arxiv.org/abs/2510.04740)
*Shawn Berry*

Main category: econ.TH

TL;DR: 该研究通过博弈论模型和模拟分析了驾驶员行为对交通拥堵的影响，发现在混合环境中不负责任的驾驶员反而比负责任的驾驶员获得更高效用，揭示了交通中的社会困境。


<details>
  <summary>Details</summary>
Motivation: 虽然道路设计、事故、天气等因素都会导致交通拥堵，但驾驶员行为和决策是影响交通流效率的主要决定因素。研究旨在量化个体驾驶员行为与系统级交通结果之间的关系。

Method: 使用驾驶员行为原型模型，通过博弈论建模和模拟（N=500,000）分析三车道道路上的交通情况，并采用Mann-Whitney U检验进行统计分析。

Result: 在混合环境（50/50）中，不负责任的驾驶员比负责任的驾驶员表现更好（M=0.128 vs M=-0.127），所有不负责任类型获得等效效用且始终超过负责任驾驶员。车道1显示出更明显的累积效用下降。

Conclusion: 研究结果为交通管理干预、拥堵预测和政策设计提供了稳健框架，旨在协调个体激励与集体效率。同时提出了未来研究方向。

Abstract: Traffic congestion represents a complex urban phenomenon that has been the
subject of extensive research employing various modeling techniques grounded in
the principles of physics and molecular theory. Although factors such as road
design, accidents, weather conditions, and construction activities contribute
to traffic congestion, driver behavior and decision-making are primary
determinants of traffic flow efficiency. This study introduces a driver
behavior archetype model that quantifies the relationship between individual
driver behavior and system-level traffic outcomes through game-theoretic
modeling and simulation (N = 500,000) of a three-lane roadway. Mann-Whitney U
tests revealed statistically significant differences across all utility
measures (p < .001, d > 2.0). In homogeneous populations, responsible drivers
achieved substantially higher expected utility (M = -0.090) than irresponsible
drivers (M = -1.470). However, in mixed environments (50/50), irresponsible
drivers paradoxically outperformed responsible drivers (M = 0.128 vs. M =
-0.127), illustrating a social dilemma wherein defection exploits cooperation.
Pairwise comparisons across the six driver archetypes indicated that all
irresponsible types achieved equivalent utilities while consistently surpassing
responsible drivers. Lane-specific analyses revealed differential capacity
patterns, with lane 1 exhibiting a more pronounced cumulative utility decline.
These findings offer a robust framework for traffic management interventions,
congestion prediction, and policy design that aligns individual incentives with
collective efficiency. Directions for future research were also proposed.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [214] [Identification in Auctions with Truncated Transaction Prices](https://arxiv.org/abs/2510.04464)
*Tonghui Qi*

Main category: econ.EM

TL;DR: 该论文研究了在拍卖数据因保留价格而被截断的情况下，如何非参数识别投标人的私人价值分布，针对第一价格和第二价格拍卖在不同信息结构下的识别问题。


<details>
  <summary>Details</summary>
Motivation: 许多拍卖数据集由于保留价格的存在，只包含高于保留价的投标，导致数据被截断。这给估计投标人的私人价值分布带来了挑战，特别是在不同拍卖机制和信息结构下。

Method: 建立非参数识别理论框架，分析在不同信息结构下（如已知固定投标人数、未知变动投标人数等）第一价格和第二价格拍卖的识别条件，包括是否观察交易价格、活跃投标人数或无销售拍卖数量等变量。

Result: 发现在第二价格拍卖中，仅观察交易价格即可识别私人价值分布；而在第一价格拍卖中需要额外信息（活跃投标人数或无销售拍卖数量）。当投标人数变动且未知时，第一价格拍卖可识别而第二价格拍卖不可识别。

Conclusion: 拍卖数据的截断问题在不同拍卖机制下的识别要求不同，研究结果为处理不完整拍卖数据提供了理论依据，并可扩展到有进入成本的拍卖场景。

Abstract: Many auction datasets with reserve prices do not include bids that fall below
the reserve. This paper establishes nonparametric identification results in
first- and second-price auctions when transaction prices are truncated by a
binding reserve price under a range of information structures. In the simplest
case-where the number of potential bidders is fixed and known across all
auctions-if only the transaction price is observed, the bidders' private-value
distribution is identified in second-price auctions but not in first-price
auctions. Identification in first-price auctions can be achieved if either the
number of active bidders (those whose bids exceed the reserve) or the number of
auctions with no sales (all bids below the reserve) is observed. When the
number of potential bidders varies across auctions and is unknown, the bidders'
private-value distribution is identified in first-price auctions but not in
second-price auctions, provided that both the transaction price and the number
of active bidders are observed. Finally, I extend these results to auctions
with entry costs, which face a similar truncation issue when data on potential
bidders who do not enter are missing.

</details>


### [215] [Risk-Adjusted Policy Learning and the Social Cost of Uncertainty: Theory and Evidence from CAP evaluation](https://arxiv.org/abs/2510.05007)
*Giovanni Cerulli,Francesco Caracciolo*

Main category: econ.EM

TL;DR: 本文开发了一种风险调整的最优政策学习方法，基于Roy的安全第一原则，通过最大化结果超过社会要求阈值的概率来制定风险敏感的政策分配规则。


<details>
  <summary>Details</summary>
Motivation: 将Roy(1952)的安全第一原则引入观察数据的政策学习问题，为政策制定者提供在结果波动时处理效率与保险权衡的可实施工具。

Method: 构建一个福利函数来最大化结果超过社会阈值概率，推导出按条件均值与条件标准差比率排序的点最优规则，并使用意大利农场数据实施该框架。

Result: 风险调整最优政策在不同设定下均优于实际分配，但风险规避会降低相对于风险中性基准的总体福利，揭示了不确定性保险的社会成本。

Conclusion: 安全第一OPL为风险敏感政策设计提供了可实施、可解释的工具，量化了政策制定者在结果波动时面临的效率-保险权衡。

Abstract: This paper develops a risk-adjusted alternative to standard optimal policy
learning (OPL) for observational data by importing Roy's (1952) safety-first
principle into the treatment assignment problem. We formalize a welfare
functional that maximizes the probability that outcomes exceed a socially
required threshold and show that the associated pointwise optimal rule ranks
treatments by the ratio of conditional means to conditional standard
deviations. We implement the framework using microdata from the Italian Farm
Accountancy Data Network to evaluate the allocation of subsidies under the EU
Common Agricultural Policy. Empirically, risk-adjusted optimal policies
systematically dominate the realized allocation across specifications, while
risk aversion lowers overall welfare relative to the risk-neutral benchmark,
making transparent the social cost of insurance against uncertainty. The
results illustrate how safety-first OPL provides an implementable,
interpretable tool for risk-sensitive policy design, quantifying the
efficiency-insurance trade-off that policymakers face when outcomes are
volatile.

</details>
