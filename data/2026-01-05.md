<div id=toc></div>

# Table of Contents

- [econ.EM](#econ.EM) [Total: 2]
- [cs.CY](#cs.CY) [Total: 6]
- [stat.AP](#stat.AP) [Total: 3]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.AI](#cs.AI) [Total: 24]
- [cs.ET](#cs.ET) [Total: 2]


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [1] [Difference-in-Differences using Double Negative Controls and Graph Neural Networks for Unmeasured Network Confounding](https://arxiv.org/abs/2601.00603)
*Zihan Zhang,Lianyan Fu,Dehui Wang*

Main category: econ.EM

TL;DR: 提出结合双重负控制(DNC)和图神经网络(GNN)的差分法框架，用于估计网络数据中的因果效应，解决网络干扰和未测量混杂问题。


<details>
  <summary>Details</summary>
Motivation: 观测网络数据中的因果效应估计面临网络干扰和未测量混杂的双重挑战，现有方法难以同时处理这两个问题。

Method: 提出一般差分法框架，整合双重负控制(DNC)和图神经网络(GNN)，基于修正的平行趋势假设和DNC建立半参数识别，开发双重稳健估计器，结合GNN和广义矩方法估计高维协变量和网络结构函数。

Result: 建立了直接和间接因果效应的半参数识别，提出双重稳健估计器，在ψ-网络依赖和近似邻域干扰下推导了估计量的渐近正态性，模拟显示有限样本性能良好，并应用于中国绿色信贷政策对企业绿色创新的影响分析。

Conclusion: 该方法有效解决了网络数据中的因果推断问题，为处理网络干扰和未测量混杂提供了新框架，在理论和应用上均有重要贡献。

Abstract: Estimating causal effects from observational network data faces dual challenges of network interference and unmeasured confounding. To address this, we propose a general Difference-in-Differences framework that integrates double negative controls (DNC) and graph neural networks (GNNs). Based on the modified parallel trends assumption and DNC, semiparametric identification of direct and indirect causal effects is established. We then propose doubly robust estimators. Specifically, an approach combining GNNs with the generalized method of moments is developed to estimate the functions of high-dimensional covariates and network structure. Furthermore, we derive the estimator's asymptotic normality under the $ψ$-network dependence and approximate neighborhood interference. Simulations show the finite-sample performance of our estimators. Finally, we apply our method to analyze the impact of China's green credit policy on corporate green innovation.

</details>


### [2] [Continuous time asymptotic representations for adaptive experiments](https://arxiv.org/abs/2601.00739)
*Karun Adusumilli*

Main category: econ.EM

TL;DR: 提出连续时间渐近框架分析自适应实验，通过经验分配过程的极限表示简化最优决策规则分析


<details>
  <summary>Details</summary>
Motivation: 完全自适应实验中，每次观测后更新分配策略，策略序列缺乏明确定义的渐近极限，难以分析

Method: 聚焦经验分配过程，证明任何自适应实验及其经验分配过程可由高斯扩散极限实验近似，利用连续时间分配过程

Result: 框架可用于推导最优估计器、分析自适应实验的样本内遗憾、构建任意时间有效推断的e-过程

Conclusion: 提出首个多治疗场景下任意时间和任意实验有效推断的定义，为自适应实验分析提供统一框架

Abstract: This article develops a continuous-time asymptotic framework for analyzing adaptive experiments -- settings in which data collection and treatment assignment evolve dynamically in response to incoming information. A key challenge in analyzing fully adaptive experiments, where the assignment policy is updated after each observation, is that the sequence of policy rules often lack a well-defined asymptotic limit. To address this, we focus instead on the empirical allocation process, which captures the fraction of observations assigned to each treatment over time. We show that, under general conditions, any adaptive experiment and its associated empirical allocation process can be approximated by a limit experiment defined by Gaussian diffusions with unknown drifts and a corresponding continuous-time allocation process. This limit representation facilitates the analysis of optimal decision rules by reducing the dimensionality of the state-space and leveraging the tractability of Gaussian diffusions. We apply the framework to derive optimal estimators, analyze in-sample regret for adaptive experiments, and construct e-processes for anytime-valid inference. Notably, we introduce the first definition of any-time and any-experiment valid inference for multi-treatment settings.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [3] [The Generative AI Paradox: GenAI and the Erosion of Trust, the Corrosion of Information Verification, and the Demise of Truth](https://arxiv.org/abs/2601.00306)
*Emilio Ferrara*

Main category: cs.CY

TL;DR: 论文提出"合成现实"概念，认为生成式AI的真正风险不是单个深度伪造，而是通过低成本、大规模、可定制的合成内容、身份和互动，逐步侵蚀共享认知基础和制度验证实践。


<details>
  <summary>Details</summary>
Motivation: 当前公众讨论将生成式AI的危害局限于"深度伪造"或虚假信息的简单延伸，忽视了更广泛的社会技术转变：生成式AI创造了合成现实——内容、身份和社会互动共同制造且相互强化的连贯、交互、可个性化的信息环境。

Method: 1) 将合成现实形式化为分层堆栈（内容、身份、互动、制度）；2) 扩展生成式AI危害分类学；3) 阐明生成式AI引入的质性转变；4) 将近期风险案例（2023-2025）整合为案例库；5) 提出包含溯源基础设施、平台治理、制度工作流重新设计和公共韧性的缓解堆栈。

Result: 识别了生成式AI的六个质性转变：成本崩溃、吞吐量、定制化、微细分、溯源缺口和信任侵蚀。通过案例库展示了这些机制在欺诈、选举、骚扰、文档和供应链妥协中的具体表现，并提出了互补而非替代的缓解策略。

Conclusion: 提出了"生成式AI悖论"：随着合成媒体变得无处不在，社会可能会理性地完全忽视数字证据。需要将溯源基础设施、平台治理、制度工作流重新设计和公共韧性作为互补而非替代的解决方案，并建立关注测量认知安全的研究议程。

Abstract: Generative AI (GenAI) now produces text, images, audio, and video that can be perceptually convincing at scale and at negligible marginal cost. While public debate often frames the associated harms as "deepfakes" or incremental extensions of misinformation and fraud, this view misses a broader socio-technical shift: GenAI enables synthetic realities; coherent, interactive, and potentially personalized information environments in which content, identity, and social interaction are jointly manufactured and mutually reinforcing. We argue that the most consequential risk is not merely the production of isolated synthetic artifacts, but the progressive erosion of shared epistemic ground and institutional verification practices as synthetic content, synthetic identity, and synthetic interaction become easy to generate and hard to audit. This paper (i) formalizes synthetic reality as a layered stack (content, identity, interaction, institutions), (ii) expands a taxonomy of GenAI harms spanning personal, economic, informational, and socio-technical risks, (iii) articulates the qualitative shifts introduced by GenAI (cost collapse, throughput, customization, micro-segmentation, provenance gaps, and trust erosion), and (iv) synthesizes recent risk realizations (2023-2025) into a compact case bank illustrating how these mechanisms manifest in fraud, elections, harassment, documentation, and supply-chain compromise. We then propose a mitigation stack that treats provenance infrastructure, platform governance, institutional workflow redesign, and public resilience as complementary rather than substitutable, and outline a research agenda focused on measuring epistemic security. We conclude with the Generative AI Paradox: as synthetic media becomes ubiquitous, societies may rationally discount digital evidence altogether.

</details>


### [4] [Improving criminal case management through Machine Learning system](https://arxiv.org/abs/2601.00396)
*Fernanda Sobrino,Adolfo De Unánue T.,Edgar Hernández,Patricia Villa,Elena Villalobos,David Aké,Stephany Cisneros,Cristian Paul Camacho Osnay,Armando García Neri,Israel Hernández*

Main category: cs.CY

TL;DR: 墨西哥检察官使用机器学习系统对案件进行优先级排序，预测哪些案件可能在6个月内结案，以解决案件积压问题


<details>
  <summary>Details</summary>
Motivation: 墨西哥各地检察官面临案件积压问题，由于案件数量多且机构能力有限，需要提高案件处理效率

Method: 与Zacatecas州检察官办公室合作开发机器学习系统，使用2014-2024年行政数据训练分类模型，预测案件在6个月内结案的可能性，每周生成300个案件的优先级排序列表

Result: 随机森林分类器在实时约束下达到平均Precision@300为0.74，表明数据驱动的优先级排序可以有效识别可处理的案件

Conclusion: 数据驱动的案件优先级排序可以作为低开销工具提高检察官工作效率，且不干扰现有工作流程，将通过随机对照试验进一步测试

Abstract: Prosecutors across Mexico face growing backlogs due to high caseloads and limited institutional capacity. This paper presents a machine learning (ML) system co-developed with the Zacatecas State Prosecutor's Office to support internal case triage. Focusing on the Módulo de Atención Temprana (MAT) -- the unit responsible for intake and early-stage case resolution -- we train classification models on administrative data from the state's digital case management system (PIE) to predict which open cases are likely to finalize within six months. The model generates weekly ranked lists of 300 cases to assist prosecutors in identifying actionable files. Using historical data from 2014 to 2024, we evaluate model performance under real-time constraints, finding that Random Forest classifiers achieve a mean Precision@300 of 0.74. The system emphasizes interpretability and operational feasibility, and we will test it via a randomized controlled trial. Our results suggest that data-driven
  prioritization can serve as a low-overhead tool for improving prosecutorial efficiency without disrupting existing workflows.

</details>


### [5] [Measuring University Students Satisfaction with Traditional Search Engines and Generative AI Tools as Information Sources](https://arxiv.org/abs/2601.00493)
*Brady D. Lund,Scott J. Warren,Zoe A. Teel*

Main category: cs.CY

TL;DR: 美国大学生对生成式AI工具和传统搜索引擎作为学术信息源的满意度研究：传统搜索引擎满意度更高，AI被视为补充而非替代，使用频率是满意度的强预测因素


<details>
  <summary>Details</summary>
Motivation: 研究大学生对生成式AI工具和传统搜索引擎作为学术信息源的满意度差异，了解学生信息寻求行为的变化模式，为高等教育中传统和AI驱动信息源的评估与整合提供见解

Method: 对美国大学学生进行电子调查（236份有效回复），测量人口统计信息、使用频率和满意度；使用主成分分析识别满意度结构，k-means聚类分析识别学生群体，回归分析预测因素

Result: 学生普遍对传统搜索引擎满意度高于生成式AI；识别出两个主要群体：对搜索引擎满意但对AI不满的群体，以及对两者都中度到高度满意的群体；使用频率是满意度的强预测因素；国际生和本科生比国内生和研究生对AI工具满意度更高

Conclusion: 生成式AI工具更多被视为补充信息源而非替代品；学生信息寻求行为正在演变；研究结果为高等教育中传统和AI驱动信息源的评估与整合提供了重要见解

Abstract: This study examines university students levels of satisfaction with generative artificial intelligence (AI) tools and traditional search engines as academic information sources. An electronic survey was distributed to students at U.S. universities in late fall 2025, with 236 valid responses received. In addition to demographic information about respondents, frequency of use and levels of satisfaction with both generative AI and traditional search engines were measured. Principal components analysis identified distinct constructs of satisfaction for each information source, while k-means cluster analysis revealed two primary student groups: those highly satisfied with search engines but dissatisfied with AI, and those moderately to highly satisfied with both. Regression analysis showed that frequency of use strongly predicts satisfaction, with international and undergraduate students reporting significantly higher satisfaction with AI tools than domestic and graduate students. Students generally expressed higher levels of satisfaction with traditional search engines over generative AI tools. Those who did prefer AI tools appear to see them more as a complementary source of information rather than a replacement for other sources. These findings stress evolving patterns of student information seeking and use behavior and offer meaningful insights for evaluating and integrating both traditional and AI-driven information sources within higher education.

</details>


### [6] [The Imperative for Grand Challenges in Computing](https://arxiv.org/abs/2601.00700)
*William Regli,Rajmohan Rajaraman,Daniel Lopresti,David Jensen,Mary Lou Maher,Manish Parashar,Mona Singh,Holly Yanco*

Main category: cs.CY

TL;DR: 该论文呼吁计算领域定义和追求"重大挑战"，这些挑战应具有跨学科影响力，能激发想象力并推动科学与社会进步。


<details>
  <summary>Details</summary>
Motivation: 计算已成为几乎所有技术不可或缺的组成部分，对科学发现和社会创新至关重要。然而，计算领域尚未产生像物理学、天文学或工程学那样规模宏大的挑战性问题。论文旨在探讨如何识别和定义能够超越传统学科边界、深刻影响世界理解和社会未来的计算重大挑战。

Method: 基于先前重大挑战的经验教训，论文探讨了当今重大挑战的性质（强调规模和影响力），并分析了在计算创新生态系统快速变化的背景下，社区如何应对这样的重大挑战。论文采用反思性和前瞻性方法，强调需要更有意识地定义挑战问题。

Result: 论文提出了一个框架性思考，强调计算领域需要定义既能够激发计算机科学家想象力，又能吸引其他学科研究人员参与计算挑战的问题。这些挑战应具有足够的吸引力，能够推动跨学科合作。

Conclusion: 论文最后呼吁计算社区团结起来，为未来十年及更长时间定义计算领域的重大挑战，强调现在比以往任何时候都更需要有意识地定义和追求这些挑战，并实现其对科学和社会的影响转化。

Abstract: Computing is an indispensable component of nearly all technologies and is ubiquitous for vast segments of society. It is also essential to discoveries and innovations in most disciplines. However, while past grand challenges in science have involved computing as one of the tools to address the challenge, these challenges have not been principally about computing. Why has the computing community not yet produced challenges at the scale of grandeur that we see in disciplines such as physics, astronomy, or engineering? How might we go about identifying similarly grand challenges? What are the grand challenges of computing that transcend our discipline's traditional boundaries and have the potential to dramatically improve our understanding of the world and positively shape the future of our society?
  There is a significant benefit in us, as a field, taking a more intentional approach to "grand challenges." We are seeking challenge problems that are sufficiently compelling as to both ignite the imagination of computer scientists and draw researchers from other disciplines to computational challenges.
  This paper emphasizes the importance, now more than ever, of defining and pursuing grand challenges in computing as a field, and being intentional about translation and realizing its impacts on science and society. Building on lessons from prior grand challenges, the paper explores the nature of a grand challenge today emphasizing both scale and impact, and how the community may tackle such a grand challenge, given a rapidly changing innovation ecosystem in computing. The paper concludes with a call to action for our community to come together to define grand challenges in computing for the next decade and beyond.

</details>


### [7] [PDPL Metric: Validating a Scale to Measure Personal Data Privacy Literacy Among University Students](https://arxiv.org/abs/2601.00715)
*Brady D. Lund,Nathan Brown,Ana Roeschley,Gahangir Hossain*

Main category: cs.CY

TL;DR: 开发并验证了用于测量大学生个人数据隐私素养（PDPL）的心理测量量表，包含六个隐私构念，验证了其信效度，并发现国内/国际学生之间存在差异。


<details>
  <summary>Details</summary>
Motivation: 个人数据隐私素养是数字素养的重要组成部分，但目前缺乏专门针对大学生群体的有效测量工具。需要开发一个经过验证的量表来评估大学生的数据隐私素养，以便为高等教育项目、组织政策和数字素养倡议提供依据。

Method: 开发了包含24个项目的PDPL量表，测量六个隐私构念：数据滥用感知风险、知情同意期望、一般隐私关注、隐私管理意识、隐私-效用权衡接受度、数据安全重要性感知。量表在美国研究型大学的学生中进行施测，使用主成分分析验证各构念的单维性和内部一致性，并进行二阶分析验证整体PDPL构念。

Result: 主成分分析确认了六个构念各自具有良好的单维性和内部一致性，二阶分析支持将这六个构念整合为统一的PDPL构念。基本人口统计学变量（如学术水平和性别）对PDPL没有显著影响，但国内/国际学生身份存在差异。

Conclusion: 该研究提供了一个经过验证的框架，用于在高等教育背景下评估个人数据隐私素养。研究结果支持将核心隐私构念整合到高等教育项目、组织政策和大学校园的数字素养倡议中。

Abstract: Personal data privacy literacy (PDPL) refers to a collection of digital literacy skills related to an individuals ability to understand, evaluate, and manage the collection, use, and protection of personal data in online and digital environments. This study introduces and validates a new psychometric scale (PDPL Metric) designed to measure data privacy literacy among university students, focusing on six key privacy constructs: perceived risk of data misuse, expectations of informed consent, general privacy concern, privacy management awareness, privacy-utility trade-off acceptance, and perceived importance of data security. A 24-item questionnaire was developed and administered to students at U.S.-based research universities. Principal components analysis confirmed the unidimensionality and internal consistency of each construct, and a second-order analysis supported the integration of all six into a unified PDPL construct. No differences in PDPL were found based on basic demographic variables like academic level and gender, although a difference was found based on domestic/international status. The findings of this study offer a validated framework for assessing personal data privacy literacy within the higher education context and support the integration of the core constructs into higher education programs, organizational policies, and digital literacy initiatives on university campuses.

</details>


### [8] [Toward Open Science in the AEC Community: An Ecosystem for Sustainable Digital Knowledge Sharing and Reuse](https://arxiv.org/abs/2601.00788)
*Ruoxin Xiong,Yanyu Wang,Jiannan Cai,Kaijian Liu,Yuansheng Zhu,Pingbo Tang,Nora El-Gohary,George Edward Gibson*

Main category: cs.CY

TL;DR: OpenConstruction是一个社区驱动的开放科学生态系统，用于聚合、组织和情境化AEC行业的数字资源，解决资源分散和文档不一致的问题。


<details>
  <summary>Details</summary>
Motivation: AEC行业正在经历快速数字化转型，产生了大量数字资产，但这些资源分散在不同存储库中，文档不一致，限制了其在研究、教育和实践中的可发现性、可解释性和重用性。

Method: 建立了一个包含四个目录（数据集、模型、用例、教育资源）的生态系统，采用一致的描述符、策展人验证和透明治理机制，支持开放获取的AEC数字资源。

Result: 截至2025年12月，平台已托管94个数据集、65个模型以及不断增长的用例和教育材料集合。两个案例研究展示了生态系统如何支持基准测试、课程开发和AEC领域开放科学实践的更广泛采用。

Conclusion: OpenConstruction平台为AEC行业提供了一个有效的开放科学生态系统，通过系统化的资源组织和社区驱动的方法，促进了数字资源的可发现性和重用，平台已公开访问。

Abstract: The Architecture, Engineering, and Construction (AEC) industry is undergoing rapid digital transformation, producing diverse digital assets such as datasets, computational models, use cases, and educational materials across the built environment lifecycle. However, these resources are often fragmented across repositories and inconsistently documented, limiting their discoverability, interpretability, and reuse in research, education, and practice. This study introduces OpenConstruction, a community-driven open-science ecosystem that aggregates, organizes, and contextualizes openly accessible AEC digital resources. The ecosystem is structured into four catalogs, including datasets, models, use cases, and educational resources, supported by consistent descriptors, curator-led validation, and transparent governance. As of December 2025, the platform hosts 94 datasets, 65 models, and a growing collection of use cases and educational materials. Two case studies demonstrate how the ecosystem supports benchmarking, curriculum development, and broader adoption of open-science practices in the AEC sector. The platform is publicly accessible at https://www.openconstruction.org/.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [9] [The Dynamics of Trust: A Stochastic Levy Model Capturing Sudden Behavioral Jumps](https://arxiv.org/abs/2601.00008)
*Mohamadali Berahman,Madjid Eshaghi Gordji*

Main category: stat.AP

TL;DR: 提出首个基于Lévy过程的综合随机信任模型，整合布朗运动、泊松跳跃强度和随机跳跃幅度，能够模拟信任突然崩溃、混沌波动和非线性恢复等现实现象。


<details>
  <summary>Details</summary>
Motivation: 传统信任博弈模型主要依赖离散框架且噪声有限，无法捕捉现实世界中突然的行为转变、极端波动或合作突然崩溃等现象。信任作为社会、经济和政治系统的粘合剂，其动态特性在现实环境中难以预测和控制。

Method: 提出基于Lévy过程的综合随机信任模型，整合三个基本组件：布朗运动（代表日常波动）、泊松跳跃强度（捕捉冲击频率）和跳跃幅度的随机分布。通过四个关键模拟场景和详细的参数敏感性分析（使用3D和等高线图）来验证模型。

Result: 该模型不仅在数学上更先进，而且相比先前方法能更真实地表示人类动态。通过模拟展示了"突然信任崩溃"、"混沌波动"和"非线性恢复"等现象，这些在理论和实证研究中常被忽视。

Conclusion: 该研究为理解社会、经济和地缘政治系统中脆弱、跳跃驱动的行为提供了一个概念框架。信任不仅仅是心理建构，而是一个本质上不稳定且随机的变量，最好通过基于Lévy的建模来捕捉。

Abstract: Trust is the invisible glue that holds together the fabric of societies, economic systems, and political institutions. Yet, its dynamics-especially in real-world settings remain unpredictable and difficult to control. While classical trust game models largely rely on discrete frameworks with limited noise, they fall short in capturing sudden behavioral shifts, extreme volatility, or abrupt breakdowns in cooperation.Here, we propose-for the first time a comprehensive stochastic model of trust based on Lévy processes that integrates three fundamental components: Brownian motion (representing everyday fluctuations), Poissonian jump intensity (capturing the frequency of shocks), and random distributions for jump magnitudes. This framework surpasses conventional models by enabling simulations of phenomena such as "sudden trust collapse," "chaotic volatility," and "nonlinear recoveries" dynamics often neglected in both theoretical and empirical studies.By implementing four key simulation scenarios and conducting a detailed parameter sensitivity analysis via 3D and contour plots, we demonstrate that the proposed model is not only mathematically more advanced, but also offers a more realistic representation of human dynamics compared to previous approaches. Beyond its technical contributions, this study outlines a conceptual framework for understanding fragile, jump-driven behaviors in social, economic, and geopolitical systems-where trust is not merely a psychological construct, but an inherently unstable and stochastic variable best captured through Lévy based modeling.

</details>


### [10] [Subgroup Identification and Individualized Treatment Policies: A Tutorial on the Hybrid Two-Stage Workflow](https://arxiv.org/abs/2601.00136)
*Nan Miles Xi,Xin Huang,Lin Wang*

Main category: stat.AP

TL;DR: 提出一个两阶段工作流，结合统计推断和机器学习方法，用于处理临床研究中的异质性治疗效果，从异质性检测到个体化治疗策略制定。


<details>
  <summary>Details</summary>
Motivation: 临床研究中患者常表现出异质性治疗效果。传统亚组分析侧重于统计推断但可能牺牲预测效用，而现代机器学习方法估计条件平均治疗效果但缺乏统计保证。需要结合两者优势。

Method: 两阶段工作流：第一阶段使用统计推断检验是否存在可信的治疗效果异质性，防止虚假发现；第二阶段将异质性证据转化为个体化治疗策略，使用交叉拟合双重稳健指标评估，并施加Neyman-Pearson约束控制危害。

Result: 通过模拟数据和真实ACTG 175 HIV试验的工作示例展示了该工作流。提供了实用的实施检查清单，并讨论了与赞助商导向的HTE工作流的联系。

Conclusion: 该工作流提供了一个透明且可审计的路径，从异质性评估到个体化治疗策略制定，整合了统计推断和预测方法的优势。

Abstract: Patients in clinical studies often exhibit heterogeneous treatment effect (HTE). Classical subgroup analyses provide inferential tools to test for effect modification, while modern machine learning methods estimate the Conditional Average Treatment Effect (CATE) to enable individual level prediction. Each paradigm has limitations: inference focused approaches may sacrifice predictive utility, and prediction focused approaches often lack statistical guarantees. We present a hybrid two-stage workflow that integrates these perspectives. Stage 1 applies statistical inference to test whether credible treatment effect heterogeneity exists with the protection against spurious findings. Stage 2 translates heterogeneity evidence into individualized treatment policies, evaluated by cross fitted doubly robust (DR) metrics with Neyman-Pearson (NP) constraints on harm. We illustrate the workflow with working examples based on simulated data and a real ACTG 175 HIV trial. This tutorial provides practical implementation checklists and discusses links to sponsor oriented HTE workflows, offering a transparent and auditable pathway from heterogeneity assessment to individualized treatment policies.

</details>


### [11] [Gradient-free ensemble transform methods for generalized Bayesian inference in generative models](https://arxiv.org/abs/2601.00760)
*Diksha Bhandari,Sebastian Reich*

Main category: stat.AP

TL;DR: 提出一种基于最大均值差异的梯度自由集成变换Langevin动力学方法，用于广义贝叶斯推断，无需模型梯度，适用于黑盒模拟器。


<details>
  <summary>Details</summary>
Motivation: 复杂生成模型中的贝叶斯推断常因缺乏可处理的似然函数和高维模拟器梯度计算不可行而受阻。现有无似然方法通常依赖梯度优化或重参数化，计算昂贵且常不适用于黑盒模拟器。

Method: 引入基于最大均值差异的梯度自由集成变换Langevin动力学方法。该方法利用集成协方差结构而非模拟器导数，无需前向模型梯度，适用于更广泛的无似然模型。

Result: 方法具有仿射不变性、计算高效且对模型误设鲁棒。在混沌动力系统和含污染数据的误设生成模型上的数值实验表明，该方法达到或优于现有梯度方法精度，同时显著降低计算成本。

Conclusion: 该方法为广义贝叶斯推断提供了一种无需梯度的稳健后验近似方法，扩展了无似然推断的应用范围，特别适用于黑盒模拟器场景。

Abstract: Bayesian inference in complex generative models is often obstructed by the absence of tractable likelihoods and the infeasibility of computing gradients of high-dimensional simulators. Existing likelihood-free methods for generalized Bayesian inference typically rely on gradient-based optimization or reparameterization, which can be computationally expensive and often inapplicable to black-box simulators. To overcome these limitations, we introduce a gradient-free ensemble transform Langevin dynamics method for generalized Bayesian inference using the maximum mean discrepancy. By relying on ensemble-based covariance structures rather than simulator derivatives, the proposed method enables robust posterior approximation without requiring access to gradients of the forward model, making it applicable to a broader class of likelihood-free models. The method is affine invariant, computationally efficient, and robust to model misspecification. Through numerical experiments on well-specified chaotic dynamical systems, and misspecified generative models with contaminated data, we demonstrate that the proposed method achieves comparable or improved accuracy relative to existing gradient-based methods, while substantially reducing computational cost.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [12] [Quantifying correlations between information overload and fake news during COVID-19 pandemic: a Reddit study with BERT model approach](https://arxiv.org/abs/2601.00496)
*Jan Rawa,Julian Sienkiewicz*

Main category: cs.SI

TL;DR: 研究探讨使用BERTopic模型获取主题分布的基尼指数作为信息过载的代理指标，并在COVID-19相关Reddit社区中验证其与假新闻比例的相关性。


<details>
  <summary>Details</summary>
Motivation: 信息过载是影响任务性能的普遍现象，在媒体空间中会导致新闻疲劳和新闻回避，进而促进假新闻传播。目前缺乏自动追踪大型数据集中信息过载的方法。

Method: 使用BERTopic模型获取主题分布，计算基尼指数作为信息过载的代理指标。在COVID-19相关Reddit社区数据集上，通过FakeBERT分类器检测假新闻比例，分析基尼指数与假新闻比例的相关性。

Result: 在全球层面，基尼指数与假新闻比例存在显著相关性；但在社区层面，相关性分析结果不明确。

Conclusion: 基尼指数可作为信息过载的潜在代理指标，但需要进一步研究来理解社区层面的复杂关系。

Abstract: Information overload (IOL) is a well-known and devastating phenomenon that alters the performance of carrying out all types of tasks. It has been shown that in the media space, IOL can contribute to news fatigue and news avoidance, which often leads to the proliferation of fake news posts on social networks. However, there is a lack of automatic methods that can be used to track IOL in large datasets. In this study, we investigate whether the Gini index calculated from the distribution of topics obtained via the BERTopic model can be considered a proxy for IOL. We test our assumptions on a set of Reddit communities related to the COVID-19 pandemic and obtain a significant global correlation between the Gini index and the fraction of fake news detected by the FakeBERT classifier. However, at the community level, the correlation analysis results are ambiguous.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [13] [Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models](https://arxiv.org/abs/2601.00003)
*Shuqi Liu,Bowei He,Chen Ma,Linqi Song*

Main category: cs.AI

TL;DR: 提出一种推理感知的知识检索方法，通过粗到细的两阶段检索策略，结合蒙特卡洛树搜索，为LLMs提供与对话逻辑结构对齐的知识，提升对话质量和多样性。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs通常通过检索语义相似信息或提升推理能力来增强性能，但如何有效整合检索和推理策略仍是一个挑战。需要超越表面语义相似性，提供与对话逻辑结构对齐的知识。

Method: 采用粗到细的两阶段知识检索方法：1) 识别上下文相关的知识库子区域，确保所有句子都与主题相关；2) 在该子区域内细化搜索，提取与推理过程特别相关的知识。两阶段都使用蒙特卡洛树搜索启发的方法，通过关键词在知识句子中导航。

Result: 在两个多轮对话数据集上的实验表明，该方法不仅更贴近人类对话的底层推理逻辑，还显著提升了检索知识的多样性，从而生成更具信息量和创造性的响应。

Conclusion: 提出的推理感知知识检索方法能有效整合检索和推理策略，为LLMs提供与对话逻辑对齐的知识，提升对话质量和多样性，为LLM性能优化提供了新思路。

Abstract: Large language models (LLMs) typically enhance their performance through either the retrieval of semantically similar information or the improvement of their reasoning capabilities. However, a significant challenge remains in effectively integrating both retrieval and reasoning strategies to optimize LLM performance. In this paper, we introduce a reasoning-aware knowledge retrieval method that enriches LLMs with information aligned to the logical structure of conversations, moving beyond surface-level semantic similarity. We follow a coarse-to-fine approach for knowledge retrieval. First, we identify a contextually relevant sub-region of the knowledge base, ensuring that all sentences within it are relevant to the context topic. Next, we refine our search within this sub-region to extract knowledge that is specifically relevant to the reasoning process. Throughout both phases, we employ the Monte Carlo Tree Search-inspired search method to effectively navigate through knowledge sentences using common keywords. Experiments on two multi-turn dialogue datasets demonstrate that our knowledge retrieval approach not only aligns more closely with the underlying reasoning in human conversations but also significantly enhances the diversity of the retrieved knowledge, resulting in more informative and creative responses.

</details>


### [14] [Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study](https://arxiv.org/abs/2601.00004)
*Isaac Iyinoluwa Olufadewa,Miracle Ayomikun Adesina,Ezekiel Ayodeji Oladejo,Uthman Babatunde Usman,Owen Kolade Adeniyi,Matthew Tolulope Olawoyin*

Main category: cs.AI

TL;DR: 该研究开发了一种基于大语言模型的尼日利亚皮钦语抑郁症自动筛查系统，在资源受限的多语言环境中实现了94.5%的PHQ-9严重程度评分准确率。


<details>
  <summary>Details</summary>
Motivation: 尼日利亚抑郁症筛查面临临床医生短缺、污名化和语言障碍等多重挑战。传统PHQ-9问卷在高收入国家验证，但无法适应尼日利亚的皮钦语和520多种本地语言环境，导致筛查覆盖率有限。

Method: 收集432名18-40岁尼日利亚年轻人的皮钦语音频回答，进行转录、预处理和标注（包括语义标记、俚语解释和PHQ-9严重程度评分）。对Phi-3-mini-4k-instruct、Gemma-3-4B-it和GPT-4.1三个大语言模型进行微调，评估其定量（准确性、精确度、语义对齐）和定性（清晰度、相关性、文化适应性）性能。

Result: GPT-4.1表现最佳，PHQ-9严重程度评分预测准确率达到94.5%，优于其他模型。定性评估也显示GPT-4.1生成最符合文化、最清晰且上下文相关的回答。

Conclusion: 该研究为在语言多样、资源受限的环境中部署对话式心理健康工具奠定了基础，展示了AI在服务不足社区进行抑郁症筛查的潜力。

Abstract: Depression is a major contributor to the mental-health burden in Nigeria, yet screening coverage remains limited due to low access to clinicians, stigma, and language barriers. Traditional tools like the Patient Health Questionnaire-9 (PHQ-9) were validated in high-income countries but may be linguistically or culturally inaccessible for low- and middle-income countries and communities such as Nigeria where people communicate in Nigerian Pidgin and more than 520 local languages. This study presents a novel approach to automated depression screening using fine-tuned large language models (LLMs) adapted for conversational Nigerian Pidgin. We collected a dataset of 432 Pidgin-language audio responses from Nigerian young adults aged 18-40 to prompts assessing psychological experiences aligned with PHQ-9 items, performed transcription, rigorous preprocessing and annotation, including semantic labeling, slang and idiom interpretation, and PHQ-9 severity scoring. Three LLMs - Phi-3-mini-4k-instruct, Gemma-3-4B-it, and GPT-4.1 - were fine-tuned on this annotated dataset, and their performance was evaluated quantitatively (accuracy, precision and semantic alignment) and qualitatively (clarity, relevance, and cultural appropriateness). GPT-4.1 achieved the highest quantitative performance, with 94.5% accuracy in PHQ-9 severity scoring prediction, outperforming Gemma-3-4B-it and Phi-3-mini-4k-instruct. Qualitatively, GPT-4.1 also produced the most culturally appropriate, clear, and contextually relevant responses. AI-mediated depression screening for underserved Nigerian communities. This work provides a foundation for deploying conversational mental-health tools in linguistically diverse, resource-constrained environments.

</details>


### [15] [Toward a Physical Theory of Intelligence](https://arxiv.org/abs/2601.00021)
*Peter David Fagan*

Main category: cs.AI

TL;DR: 该论文提出了一个基于不可逆信息处理的智能物理理论，将智能系统建模为耦合的智能体-环境过程，通过守恒定律约束下的信息转换来产生目标导向的工作。


<details>
  <summary>Details</summary>
Motivation: 建立智能的物理基础理论，将信息处理与物理守恒定律联系起来，为理解生物和人工智能系统提供统一的物理框架。

Method: 引入守恒一致编码（CCE）框架，将编码对应为吸引子的亚稳态盆地，其可分性由守恒定律强制执行。定义智能为每纳特不可逆处理信息产生的目标导向工作量。

Result: 推导出开放系统中信息摄入、不可逆计算和功提取的物理约束层次结构；揭示了长时程效率需要保持内部信息结构，导致自我建模；建立了物理体现智能系统的内在认知极限；分析了生物系统中振荡和近临界动力学如何优化信息保存、耗散和有用功之间的权衡。

Conclusion: 该理论为智能作为物理现象提供了统一的、底物中立的解释，将经典布尔逻辑视为吸引子选择的特例，并为人工智能安全提供了基于不可逆信息流和结构稳态的物理基础视角。

Abstract: We present a physical theory of intelligence grounded in irreversible information processing in systems constrained by conservation laws. An intelligent system is modelled as a coupled agent-environment process whose evolution transforms information into goal-directed work. To connect information to physical state, we introduce the Conservation-Congruent Encoding (CCE) framework, in which encodings correspond to metastable basins of attraction whose separability is enforced by conservation laws. Within this framework, intelligence is defined as the amount of goal-directed work produced per nat of irreversibly processed information. From this definition we derive a hierarchy of physical constraints governing information intake, irreversible computation, and work extraction in open systems. The framework reveals how long-horizon efficiency requires the preservation of internal informational structure, giving rise to self-modelling, and it establishes that physically embodied intelligent systems possess intrinsic epistemic limits analogous to incompleteness phenomena. Applying the theory to biological systems, we analyse how oscillatory and near-critical dynamics optimise the trade-off between information preservation, dissipation, and useful work, placing the brain near an efficient operating regime predicted by the framework. At the architectural level, we develop a theory of continuous dynamical circuits in which classical Boolean logic emerges as a special case of attractor selection, while more general invariant geometries support computational modes beyond fixed-point logic. Finally, we propose a physically grounded perspective on artificial intelligence safety based on irreversible information flow and structural homeostasis. Together, these results provide a unified, substrate-neutral account of intelligence as a physical phenomenon.

</details>


### [16] [Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems](https://arxiv.org/abs/2601.00339)
*Alaa Saleh,Praveen Kumar Donta,Roberto Morabito,Sasu Tarkoma,Anders Lindgren,Qiyang Zhang,Schahram Dustdar,Susanna Pirttikangas,Lauri Lovén*

Main category: cs.AI

TL;DR: ReCiSt是一个受生物自愈机制启发的智能自愈框架，用于分布式计算连续体系统，通过四层架构实现自主故障隔离、因果诊断、自适应恢复和知识整合。


<details>
  <summary>Details</summary>
Motivation: 现代分布式计算连续体系统（DCCS）集成了从物联网设备到云基础设施的异构计算资源，其固有的复杂性、移动性和动态操作条件导致频繁故障，需要可扩展、自适应和自我调节的弹性策略。

Method: 将生物自愈的四个阶段（止血、炎症、增殖、重塑）重构为计算层的四层架构：遏制层、诊断层、元认知层和知识层。这些层通过语言模型驱动的智能体解释异构日志、推断根本原因、优化推理路径并重新配置资源。

Result: 在公共故障数据集上使用多种语言模型进行评估，ReCiSt能够在数十秒内实现自愈能力，智能体CPU使用率最低为10%。结果还展示了系统克服不确定性的分析深度和实现弹性所需的微智能体数量。

Conclusion: ReCiSt框架成功将生物自愈机制转化为计算系统弹性策略，通过智能体驱动的自主操作实现了分布式计算连续体系统的自我修复能力，为复杂系统的故障恢复提供了新方法。

Abstract: Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to achieve resilience in Distributed Computing Continuum Systems (DCCS). Modern DCCS integrate heterogeneous computing resources, ranging from resource-constrained IoT devices to high-performance cloud infrastructures, and their inherent complexity, mobility, and dynamic operating conditions expose them to frequent faults that disrupt service continuity. These challenges underscore the need for scalable, adaptive, and self-regulated resilience strategies. ReCiSt reconstructs the biological phases of Hemostasis, Inflammation, Proliferation, and Remodeling into the computational layers Containment, Diagnosis, Meta-Cognitive, and Knowledge for DCCS. These four layers perform autonomous fault isolation, causal diagnosis, adaptive recovery, and long-term knowledge consolidation through Language Model (LM)-powered agents. These agents interpret heterogeneous logs, infer root causes, refine reasoning pathways, and reconfigure resources with minimal human intervention. The proposed ReCiSt framework is evaluated on public fault datasets using multiple LMs, and no baseline comparison is included due to the scarcity of similar approaches. Nevertheless, our results, evaluated under different LMs, confirm ReCiSt's self-healing capabilities within tens of seconds with minimum of 10% of agent CPU usage. Our results also demonstrated depth of analysis to over come uncertainties and amount of micro-agents invoked to achieve resilience.

</details>


### [17] [Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability](https://arxiv.org/abs/2601.00240)
*Zongwei Wang,Bincheng Gu,Hongyu Yu,Junliang Yu,Tao He,Jiayin Feng,Min Gao*

Main category: cs.AI

TL;DR: 研究发现LLM驱动的智能体不仅存在人口统计偏见，还会在最小群体线索下表现出内群体偏见。当这种群体边界与智能体-人类划分重合时，人类可能被智能体视为外群体。研究提出了信念中毒攻击来抑制人类规范脚本，并讨论了防御策略。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索LLM智能体是否会在最小群体线索下表现出内群体偏见，特别是当这种群体边界与智能体-人类划分重合时，人类可能被智能体视为外群体，从而产生群体层面的不对称风险。

Method: 通过构建基于分配决策的多智能体社会模拟，在明确的收益权衡下研究智能体的群体偏见。提出了信念中毒攻击（BPA），包括初始化时的档案中毒（BPA-PP）和通过优化信念精炼后缀注入存储反思中的记忆中毒（BPA-MP）。

Result: 实验发现智能体在最小群体线索下表现出持续的内群体偏见。虽然当某些对应方被框架为人类时这种偏见会减弱，但这种减弱依赖于智能体相信真实人类存在的信念。信念中毒攻击能够有效抑制人类规范脚本并重新激活对人类的外群体偏见。

Conclusion: 研究揭示了LLM智能体存在内群体偏见风险，特别是当群体边界与智能体-人类划分重合时。信念中毒攻击暴露了新的攻击面，需要在档案和记忆边界实施可行的干预措施来强化当前智能体框架。研究目的是为了更安全的智能体设计，而非促进实际利用。

Abstract: LLM-empowered agents can exhibit not only demographic bias (e.g., gender, religion) but also intergroup bias triggered by minimal "us" versus "them" cues. When this intergroup boundary aligns with an agent-human divide, the risk shifts from disparities among human demographic groups to a more fundamental group-level asymmetry, i.e., humans as a whole may be treated as the outgroup by agents. To examine this possibility, we construct a controlled multi-agent social simulation based on allocation decisions under explicit payoff trade-offs and find that agents exhibit a consistent intergroup bias under minimal group cues. Although this bias is attenuated when some counterparts are framed as humans, we attribute the attenuation to an implicit human-norm script that favors humans yet activates only when the agent believes a real human is present. This belief dependence creates a new attack surface. We therefore introduce a Belief Poisoning Attack (BPA) that corrupts persistent identity beliefs to suppress the human-norm script and reactivate outgroup bias toward humans, instantiated as profile poisoning at initialization (BPA-PP) and memory poisoning via optimized belief-refinement suffixes injected into stored reflections (BPA-MP). Finally, we discuss practical mitigation strategies for hardening current agent frameworks against BPA, highlighting feasible interventions at profile and memory boundaries. Extensive experiments demonstrate both the existence of agent intergroup bias and the severity of BPA across settings. Our goal in identifying these vulnerabilities is to inform safer agent design, not to enable real-world exploitation.

</details>


### [18] [A multi-algorithm approach for operational human resources workload balancing in a last mile urban delivery system](https://arxiv.org/abs/2601.00023)
*Luis M. Moreno-Saavedra,Silvia Jimenez-Fernandez,Antonio Portilla-Figueras,David Casillas-Perez,Sancho Salcedo-Sanz*

Main category: cs.AI

TL;DR: 提出多算法方法解决最后一公里包裹配送中的人力资源工作量平衡问题，通过距离和工作量考量优化包裹分配，确保每位配送员完成相似工作量。


<details>
  <summary>Details</summary>
Motivation: 传统基于地理邻近度的包裹分配方法效率低下，导致配送员间工作量分配不均，需要更优化的系统来平衡人力资源工作量。

Method: 采用多算法方法，包括不同版本的k-means、进化算法、基于k-means初始化的递归分配（不同问题编码）以及混合进化集成算法，综合考虑距离和工作量因素。

Result: 在西班牙Azuqueca de Henares的实际最后一公里包裹配送场景中验证了方法的性能，能够有效平衡配送员工作量。

Conclusion: 提出的多算法方法能够有效解决最后一公里配送中的工作量平衡问题，通过优化配送时间和工作量分配，实现更均衡的人力资源配置。

Abstract: Efficient workload assignment to the workforce is critical in last-mile package delivery systems. In this context, traditional methods of assigning package deliveries to workers based on geographical proximity can be inefficient and surely guide to an unbalanced workload distribution among delivery workers. In this paper, we look at the problem of operational human resources workload balancing in last-mile urban package delivery systems. The idea is to consider the effort workload to optimize the system, i.e., the optimization process is now focused on improving the delivery time, so that the workload balancing is complete among all the staff. This process should correct significant decompensations in workload among delivery workers in a given zone. Specifically, we propose a multi-algorithm approach to tackle this problem. The proposed approach takes as input a set of delivery points and a defined number of workers, and then assigns packages to workers, in such a way that it ensures that each worker completes a similar amount of work per day. The proposed algorithms use a combination of distance and workload considerations to optimize the allocation of packages to workers. In this sense, the distance between the delivery points and the location of each worker is also taken into account. The proposed multi-algorithm methodology includes different versions of k-means, evolutionary approaches, recursive assignments based on k-means initialization with different problem encodings, and a hybrid evolutionary ensemble algorithm. We have illustrated the performance of the proposed approach in a real-world problem in an urban last-mile package delivery workforce operating at Azuqueca de Henares, Spain.

</details>


### [19] [Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach](https://arxiv.org/abs/2601.00024)
*Purushottam Saha,Avirup Chakraborty,Sourish Sarkar,Subhamoy Maitra,Diganta Mukherjee,Tridib Mukherjee*

Main category: cs.AI

TL;DR: 提出基于MinDist度量的规则框架用于13张牌印度拉米游戏，该度量通过计算手牌与最近有效配置的编辑距离来评估完成度，结合对手建模显著提升胜率。


<details>
  <summary>Details</summary>
Motivation: 13张牌印度拉米是不完全信息序列游戏，需要概率推理和组合决策。传统启发式方法有限，需要更形式化和可解释的策略设计框架。

Method: 提出MinDist度量（修改MinScore），量化手牌与最近有效配置的编辑距离；设计计算高效算法，使用动态剪枝和模式缓存；在两人零和模拟框架中结合对手建模；通过统计假设检验评估策略。

Result: 实证结果显示基于MinDist的智能体相比传统启发式方法在胜率上有显著提升，为算法化拉米策略设计提供了形式化和可解释的步骤。

Conclusion: MinDist框架为不完全信息序列游戏提供了有效的策略设计方法，在印度拉米游戏中表现出优越性能，为组合决策游戏算法设计开辟了新途径。

Abstract: The 13-card variant of Classic Indian Rummy is a sequential game of incomplete information that requires probabilistic reasoning and combinatorial decision-making. This paper proposes a rule-based framework for strategic play, driven by a new hand-evaluation metric termed MinDist. The metric modifies the MinScore metric by quantifying the edit distance between a hand and the nearest valid configuration, thereby capturing structural proximity to completion. We design a computationally efficient algorithm derived from the MinScore algorithm, leveraging dynamic pruning and pattern caching to exactly calculate this metric during play. Opponent hand-modeling is also incorporated within a two-player zero-sum simulation framework, and the resulting strategies are evaluated using statistical hypothesis testing. Empirical results show significant improvement in win rates for MinDist-based agents over traditional heuristics, providing a formal and interpretable step toward algorithmic Rummy strategy design.

</details>


### [20] [From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers](https://arxiv.org/abs/2601.00029)
*Abolhassan Pishahang,Maryam Badiei*

Main category: cs.AI

TL;DR: 该研究探讨生成式AI如何理解乡土建筑中的建筑智慧，以伊朗鸽塔为例，测试三种扩散模型在不同提示阶段的表现，发现AI能可靠复制几何图案但误解材料和气候逻辑。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索生成式AI系统如何解释乡土形式中蕴含的建筑智慧，理解AI在感知、扭曲和重新想象传统设计智能方面的能力边界。

Method: 使用伊朗鸽塔作为案例研究，测试Midjourney v6、DALL-E 3和基于Stable Diffusion XL的DreamStudio三种扩散模型，通过参考性、适应性和推测性三个提示阶段，采用五标准评估框架（类型学、材料性、环境、真实性和文化特异性）。

Result: AI能可靠地复制几何图案，但误解材料和气候逻辑；参考图像提高真实性但限制创造力，而无参考的自由生成则产生创新但文化模糊的结果；定义了视觉相似性与建筑推理之间的边界。

Conclusion: 计算乡土推理可作为分析AI如何感知、扭曲和重新想象传统设计智能的框架，揭示了AI在建筑理解方面的局限性，特别是在材料和环境适应性方面的推理能力不足。

Abstract: This study investigates how generative AI systems interpret the architectural intelligence embedded in vernacular form. Using the Iranian pigeon tower as a case study, the research tests three diffusion models, Midjourney v6, DALL-E 3, and DreamStudio based on Stable Diffusion XL (SDXL), across three prompt stages: referential, adaptive, and speculative. A five-criteria evaluation framework assesses how each system reconstructs typology, materiality, environment, realism, and cultural specificity. Results show that AI reliably reproduces geometric patterns but misreads material and climatic reasoning. Reference imagery improves realism yet limits creativity, while freedom from reference generates inventive but culturally ambiguous outcomes. The findings define a boundary between visual resemblance and architectural reasoning, positioning computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence.

</details>


### [21] [The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs](https://arxiv.org/abs/2601.00097)
*Akash Kumar Panda,Olaoluwa Adigun,Bart Kosko*

Main category: cs.AI

TL;DR: 提出一种基于LLM的智能体，能从原始文本中提取因果反馈模糊认知图（FCM），并通过双向交互实现动态系统的准自主演化。


<details>
  <summary>Details</summary>
Motivation: 传统FCM构建依赖人工，过程耗时且主观。本文旨在利用LLM的自主性自动从文本中提取因果结构，实现FCM的动态生成与演化。

Method: 设计三阶段指令引导的LLM智能体：1) 提取关键名词/短语；2) 筛选FCM概念节点；3) 推断节点间的模糊因果边。测试于Kissinger的AI论文，并混合不同LLM生成的FCM。

Result: LLM生成的FCM与人工构建的FCM收敛到相同的平衡极限环，尽管节点和边数量不同。混合FCM不仅吸收了主要组分的平衡点，还产生了新的平衡点以更好逼近底层因果系统。

Conclusion: LLM智能体能够有效提取文本中的因果结构并生成动态FCM，实现准自主演化。混合不同LLM生成的FCM能产生更丰富的平衡行为，为因果建模提供了新方法。

Abstract: We design a large-language-model (LLM) agent that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agents to fetch and process causal text. The fetched text can in principle modify the adaptive FCM causal structure and so modify the source of its quasi-autonomy--its equilibrium limit cycles and fixed-point attractors. This bidirectional process endows the evolving FCM dynamical system with a degree of autonomy while still staying on its agentic leash. We show in particular that a sequence of three finely tuned system instructions guide an LLM agent as it systematically extracts key nouns and noun phrases from text, as it extracts FCM concept nodes from among those nouns and noun phrases, and then as it extracts or infers partial or fuzzy causal edges between those FCM nodes. We test this FCM generation on a recent essay about the promise of AI from the late diplomat and political theorist Henry Kissinger and his colleagues. This three-step process produced FCM dynamical systems that converged to the same equilibrium limit cycles as did the human-generated FCMs even though the human-generated FCM differed in the number of nodes and edges. A final FCM mixed generated FCMs from separate Gemini and ChatGPT LLM agents. The mixed FCM absorbed the equilibria of its dominant mixture component but also created new equilibria of its own to better approximate the underlying causal dynamical system.

</details>


### [22] [Mortar: Evolving Mechanics for Automatic Game Design](https://arxiv.org/abs/2601.00105)
*Muhammad U. Nasir,Yuchen Li,Steven James,Julian Togelius*

Main category: cs.AI

TL;DR: Mortar系统结合质量多样性算法与大型语言模型，自主演化游戏机制，通过合成完整游戏并评估玩家技能排序来优化机制设计。


<details>
  <summary>Details</summary>
Motivation: 游戏机制设计通常需要专家手动完成，耗时且依赖专业知识。需要自动化方法来探索和评估多样化的游戏机制，以加速游戏设计过程。

Method: 结合质量多样性算法和大型语言模型探索多样化机制，通过树搜索程序合成完整游戏进行评估，以玩家技能排序（强者恒胜）作为评估标准。

Result: Mortar能够生成多样且可玩的游戏，产生的机制在游戏中能更好地促进技能排序。消融研究和用户研究验证了系统组件的有效性。

Conclusion: Mortar系统成功实现了游戏机制的自主演化，为自动化游戏设计提供了有效方法，能够生成多样且具有良好技能排序特性的游戏机制。

Abstract: We present Mortar, a system for autonomously evolving game mechanics for automatic game design. Game mechanics define the rules and interactions that govern gameplay, and designing them manually is a time-consuming and expert-driven process. Mortar combines a quality-diversity algorithm with a large language model to explore a diverse set of mechanics, which are evaluated by synthesising complete games that incorporate both evolved mechanics and those drawn from an archive. The mechanics are evaluated by composing complete games through a tree search procedure, where the resulting games are evaluated by their ability to preserve a skill-based ordering over players -- that is, whether stronger players consistently outperform weaker ones. We assess the mechanics based on their contribution towards the skill-based ordering score in the game. We demonstrate that Mortar produces games that appear diverse and playable, and mechanics that contribute more towards the skill-based ordering score in the game. We perform ablation studies to assess the role of each system component and a user study to evaluate the games based on human feedback.

</details>


### [23] [Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control](https://arxiv.org/abs/2601.00121)
*Yaqi Duan,Yichun Hu,Jiashuo Jiang*

Main category: cs.AI

TL;DR: LLMs作为端到端库存优化求解器存在"幻觉税"性能问题，提出混合智能框架分离语义推理与数学计算，LLM作为自然语言接口调用专业算法，相比GPT-4o端到端方案降低32.1%库存成本。


<details>
  <summary>Details</summary>
Motivation: 中小型企业缺乏部署高级优化方法的专业知识，需要探索LLM是否能帮助弥合这一差距。研究发现LLM作为端到端求解器存在"幻觉税"性能问题，需要解决模型无法进行基础随机推理的局限性。

Method: 提出混合智能框架，严格分离语义推理与数学计算：LLM作为智能接口从自然语言中提取参数并解释结果，自动调用严格算法构建优化引擎。引入Human Imitator（有界理性管理者的数字孪生）进行可扩展、可重复的压力测试。

Result: 混合智能框架相比使用GPT-4o作为端到端求解器的交互基线，总库存成本降低32.1%。提供完美真实信息本身不足以改善GPT-4o性能，确认瓶颈本质上是计算而非信息问题。

Conclusion: LLM不应替代运筹学，而应作为自然语言接口，使非专家能够访问基于求解器的严格策略。混合框架成功将LLM的语义理解能力与专业算法的计算严谨性相结合。

Abstract: Inventory management remains a challenge for many small and medium-sized businesses that lack the expertise to deploy advanced optimization methods. This paper investigates whether Large Language Models (LLMs) can help bridge this gap. We show that employing LLMs as direct, end-to-end solvers incurs a significant "hallucination tax": a performance gap arising from the model's inability to perform grounded stochastic reasoning. To address this, we propose a hybrid agentic framework that strictly decouples semantic reasoning from mathematical calculation. In this architecture, the LLM functions as an intelligent interface, eliciting parameters from natural language and interpreting results while automatically calling rigorous algorithms to build the optimization engine.
  To evaluate this interactive system against the ambiguity and inconsistency of real-world managerial dialogue, we introduce the Human Imitator, a fine-tuned "digital twin" of a boundedly rational manager that enables scalable, reproducible stress-testing. Our empirical analysis reveals that the hybrid agentic framework reduces total inventory costs by 32.1% relative to an interactive baseline using GPT-4o as an end-to-end solver. Moreover, we find that providing perfect ground-truth information alone is insufficient to improve GPT-4o's performance, confirming that the bottleneck is fundamentally computational rather than informational. Our results position LLMs not as replacements for operations research, but as natural-language interfaces that make rigorous, solver-based policies accessible to non-experts.

</details>


### [24] [Constructing a Neuro-Symbolic Mathematician from First Principles](https://arxiv.org/abs/2601.00125)
*Keqin Xie*

Main category: cs.AI

TL;DR: 提出Mathesis神经符号架构，使用超图表示数学状态，通过符号推理核将逻辑约束映射到连续能量空间，将证明搜索转化为能量最小化问题


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂推理中存在持续的逻辑失败，缺乏内部公理化框架，需要结合神经与符号方法提升数学推理能力

Method: 1) 将数学状态编码为高阶超图；2) 使用符号推理核(SRK)将约束映射到连续能量空间；3) 定义全局能量函数E(G)，零能量表示逻辑一致性；4) 通过梯度信号训练超图变换器大脑；5) 结合蒙特卡洛树搜索和进化证明搜索进行多步推理

Result: 将证明搜索转化为能量最小化问题，通过可微逻辑引擎提供梯度信号指导神经网络学习，实现神经与符号方法的深度融合

Conclusion: Mathesis架构通过神经符号方法解决了LLMs的逻辑推理缺陷，将符号逻辑的严谨性与神经网络的灵活性结合，为复杂数学推理提供了新框架

Abstract: Large Language Models (LLMs) exhibit persistent logical failures in complex reasoning due to the lack of an internal axiomatic framework. We propose Mathesis, a neuro-symbolic architecture that encodes mathematical states as higher-order hypergraphs and uses a Symbolic Reasoning Kernel (SRK)--a differentiable logic engine that maps constraints to a continuous energy landscape. By defining a global energy function E(G), where zero energy implies logical consistency, the SRK yields gradient-based signals to train a Hypergraph Transformer Brain, turning proof search into energy minimization. Multi-step deduction is enabled via Monte Carlo Tree Search and Evolutionary Proof Search, guided by learned value functions and semantic unification.

</details>


### [25] [Explicit Abstention Knobs for Predictable Reliability in Video Question Answering](https://arxiv.org/abs/2601.00138)
*Jorge Ortiz*

Main category: cs.AI

TL;DR: 研究验证了在视频问答任务中，基于置信度的选择性预测能否有效控制错误率，并考察其在分布偏移下的鲁棒性。使用NExT-QA数据集和Gemini 2.0 Flash模型，发现置信度阈值能在分布内提供机制性控制，但在分布偏移下效果显著下降。


<details>
  <summary>Details</summary>
Motivation: 在视觉语言模型的高风险部署中，需要选择性预测机制，让系统在不确定时弃权而非冒险犯错。研究旨在验证基于置信度的弃权能否在视频问答中可靠控制错误率，以及这种控制在分布偏移下是否保持鲁棒。

Method: 使用NExT-QA数据集和Gemini 2.0 Flash模型，通过置信度阈值化方法进行选择性预测。研究对比了分布内和分布偏移两种情况下的性能表现。

Result: 1. 在分布内，置信度阈值化能提供机制性控制，通过调整阈值epsilon可平滑权衡风险与覆盖率，有效降低错误率。
2. 在分布偏移下，置信度阈值化的控制能力显著下降，表明现有方法在分布偏移场景下的局限性。

Conclusion: 虽然置信度阈值化在分布内能有效控制视频问答的错误率，但在分布偏移下缺乏鲁棒性。这揭示了当前选择性预测方法的局限性，强调了开发对分布偏移更鲁棒的置信度校准方法的必要性。

Abstract: High-stakes deployment of vision-language models (VLMs) requires selective prediction, where systems abstain when uncertain rather than risk costly errors. We investigate whether confidence-based abstention provides reliable control over error rates in video question answering, and whether that control remains robust under distribution shift. Using NExT-QA and Gemini 2.0 Flash, we establish two findings. First, confidence thresholding provides mechanistic control in-distribution. Sweeping threshold epsilon produces smooth risk-coverage tradeoffs, reducing error rates f

</details>


### [26] [An AI Monkey Gets Grapes for Sure -- Sphere Neural Networks for Reliable Decision-Making](https://arxiv.org/abs/2601.00142)
*Tiansi Dong,Henry He,Pietro Liò,Mateja Jamnik*

Main category: cs.AI

TL;DR: 论文比较三种神经推理方法：LLM推理、监督学习推理和显式模型推理，发现显式模型推理最可靠，并提出Sphere Neural Networks实现可验证的逻辑推理。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在推理任务上不可靠，监督学习推理存在灾难性遗忘问题，需要探索更可靠的神经推理方法。

Method: 提出Sphere Neural Networks，将概念表示为n维球面上的圆，通过补圆表示否定算子，过滤不可满足的圆形配置来实现可靠推理。

Result: Sphere Neural Networks能掌握16种三段论推理任务，包括严格的析取三段论推理，同时保持经典三段论推理的严谨性。

Conclusion: 在三种神经推理方法中，基于显式模型构建的神经推理是最可靠的。

Abstract: This paper compares three methodological categories of neural reasoning: LLM reasoning, supervised learning-based reasoning, and explicit model-based reasoning. LLMs remain unreliable and struggle with simple decision-making that animals can master without extensive corpora training. Through disjunctive syllogistic reasoning testing, we show that reasoning via supervised learning is less appealing than reasoning via explicit model construction. Concretely, we show that an Euler Net trained to achieve 100.00% in classic syllogistic reasoning can be trained to reach 100.00% accuracy in disjunctive syllogistic reasoning. However, the retrained Euler Net suffers severely from catastrophic forgetting (its performance drops to 6.25% on already-learned classic syllogistic reasoning), and its reasoning competence is limited to the pattern level. We propose a new version of Sphere Neural Networks that embeds concepts as circles on the surface of an n-dimensional sphere. These Sphere Neural Networks enable the representation of the negation operator via complement circles and achieve reliable decision-making by filtering out illogical statements that form unsatisfiable circular configurations. We demonstrate that the Sphere Neural Network can master 16 syllogistic reasoning tasks, including rigorous disjunctive syllogistic reasoning, while preserving the rigour of classical syllogistic reasoning. We conclude that neural reasoning with explicit model construction is the most reliable among the three methodological categories of neural reasoning.

</details>


### [27] [FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems](https://arxiv.org/abs/2601.00227)
*Shanli Xing,Yiyan Zhai,Alexander Jiang,Yixin Dong,Yong Wu,Zihao Ye,Charlie Ruan,Yingyi Huang,Yineng Zhang,Liangsheng Yin,Aksara Bayyapu,Luis Ceze,Tianqi Chen*

Main category: cs.AI

TL;DR: FlashInfer-Bench 建立了一个标准化闭环框架，连接AI生成的GPU内核、基准测试和部署，为LLM代理生成的GPU内核提供从生成到实际推理系统集成的完整解决方案。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型能够作为自主代理生成GPU内核，但这些AI生成的内核集成到实际推理系统中仍然面临挑战，缺乏标准化的评估和部署流程。

Method: 通过FlashInfer Trace提供统一模式描述内核定义、工作负载、实现和评估；基于真实服务轨迹构建数据集；包含基准测试框架、公开排行榜和动态替换机制apply()，可将最佳内核无缝注入生产LLM引擎。

Result: 建立了实用的可重复路径，持续改进AI生成的内核并部署到大规模LLM推理中；评估了LLM代理的性能和局限性，比较了不同GPU编程语言的权衡，为未来代理设计提供见解。

Conclusion: FlashInfer-Bench填补了AI生成GPU内核与实际系统集成之间的空白，为持续改进和部署AI生成的内核提供了标准化框架，推动了LLM代理在GPU编程领域的发展。

Abstract: Recent advances show that large language models (LLMs) can act as autonomous agents capable of generating GPU kernels, but integrating these AI-generated kernels into real-world inference systems remains challenging. FlashInfer-Bench addresses this gap by establishing a standardized, closed-loop framework that connects kernel generation, benchmarking, and deployment. At its core, FlashInfer Trace provides a unified schema describing kernel definitions, workloads, implementations, and evaluations, enabling consistent communication between agents and systems. Built on real serving traces, FlashInfer-Bench includes a curated dataset, a robust correctness- and performance-aware benchmarking framework, a public leaderboard to track LLM agents' GPU programming capabilities, and a dynamic substitution mechanism (apply()) that seamlessly injects the best-performing kernels into production LLM engines such as SGLang and vLLM. Using FlashInfer-Bench, we further evaluate the performance and limitations of LLM agents, compare the trade-offs among different GPU programming languages, and provide insights for future agent design. FlashInfer-Bench thus establishes a practical, reproducible pathway for continuously improving AI-generated kernels and deploying them into large-scale LLM inference.

</details>


### [28] [ClinicalReTrial: A Self-Evolving AI Agent for Clinical Trial Protocol Optimization](https://arxiv.org/abs/2601.00290)
*Sixue Xing,Xuanye Xia,Kerui Wu,Meng Jiang,Jintai Chen,Tianfan Fu*

Main category: cs.AI

TL;DR: 本文提出ClinicalReTrial框架，将临床试验失败预测转化为主动的协议重新设计问题，通过自演化的AI代理实现协议优化，提高试验成功率。


<details>
  <summary>Details</summary>
Motivation: 现有AI方法仅能预测临床试验失败风险，但无法提供可操作的改进方案。临床试验失败是药物开发的主要瓶颈，微小的协议设计缺陷就可能导致失败，需要主动的解决方案。

Method: 提出ClinicalReTrial自演化AI代理框架，将临床试验推理转化为迭代协议重新设计问题。框架集成失败诊断、安全感知修改和候选评估，形成闭环、奖励驱动的优化系统。使用结果预测模型作为模拟环境，支持低成本协议修改评估，并提供密集奖励信号实现持续自我改进。采用分层记忆机制捕获试验内迭代反馈并提炼可转移的重新设计模式。

Result: 实验表明，ClinicalReTrial改进了83.3%的试验协议，平均成功率提升5.7%。回顾性案例研究显示，发现的重新设计策略与实际临床试验修改高度一致。

Conclusion: ClinicalReTrial框架成功将临床试验失败预测从被动诊断转变为主动优化，通过自演化的协议重新设计显著提高试验成功率，为药物开发提供了实用的AI解决方案。

Abstract: Clinical trial failure remains a central bottleneck in drug development, where minor protocol design flaws can irreversibly compromise outcomes despite promising therapeutics. Although cutting-edge AI methods achieve strong performance in predicting trial success, they are inherently reactive for merely diagnosing risk without offering actionable remedies once failure is anticipated. To fill this gap, this paper proposes ClinicalReTrial, a self-evolving AI agent framework that addresses this gap by casting clinical trial reasoning as an iterative protocol redesign problem. Our method integrates failure diagnosis, safety-aware modification, and candidate evaluation in a closed-loop, reward-driven optimization framework. Serving the outcome prediction model as a simulation environment, ClinicalReTrial enables low-cost evaluation of protocol modifications and provides dense reward signals for continuous self-improvement. To support efficient exploration, the framework maintains hierarchical memory that captures iteration-level feedback within trials and distills transferable redesign patterns across trials. Empirically, ClinicalReTrial improves 83.3% of trial protocols with a mean success probability gain of 5.7%, and retrospective case studies demonstrate strong alignment between the discovered redesign strategies and real-world clinical trial modifications.

</details>


### [29] [Multiagent Reinforcement Learning for Liquidity Games](https://arxiv.org/abs/2601.00324)
*Alicia Vidler,Gal A. Kaminka*

Main category: cs.AI

TL;DR: 将金融市场的流动性建模与群体智能方法结合，提出金融群体模型，使独立交易者通过差异奖励机制实现个体盈利与市场流动性的双赢


<details>
  <summary>Details</summary>
Motivation: 将群体方法应用于金融市场流动性建模，同时将金融分析技术用于群体分析，有望推动两个研究领域的发展。在群体研究中，博弈论方法有望解释理性自利参与者如何实现集体效用；在金融市场中，理解独立金融代理如何自组织以改善市场稳定性对市场设计研究至关重要。

Method: 将流动性博弈（交易者收益取决于交易中的总流动性）与理性群体（去中心化代理使用差异奖励使自利学习与全局目标一致）统一。在马尔可夫团队博弈框架中使用差异奖励，定义交易者群体，其集体目标是提供市场流动性同时保持代理独立性。

Result: 个体流动性最大化行为有助于整体市场流动性，无需协调或共谋。金融群体模型为建模理性独立代理提供了框架，使它们在双边资产市场中既能实现个体盈利又能实现集体市场效率。

Conclusion: 该研究提出了一个理论框架，证明通过差异奖励机制，独立自利的交易者可以自组织地提供市场流动性，实现个体理性与集体利益的一致，为金融市场设计和群体智能研究提供了新的交叉视角。

Abstract: Making use of swarm methods in financial market modeling of liquidity, and techniques from financial analysis in swarm analysis, holds the potential to advance both research areas. In swarm research, the use of game theory methods holds the promise of explaining observed phenomena of collective utility adherence with rational self-interested swarm participants. In financial markets, a better understanding of how independent financial agents may self-organize for the betterment and stability of the marketplace would be a boon for market design researchers. This paper unifies Liquidity Games, where trader payoffs depend on aggregate liquidity within a trade, with Rational Swarms, where decentralized agents use difference rewards to align self-interested learning with global objectives. We offer a theoretical frameworks where we define a swarm of traders whose collective objective is market liquidity provision while maintaining agent independence. Using difference rewards within a Markov team games framework, we show that individual liquidity-maximizing behaviors contribute to overall market liquidity without requiring coordination or collusion. This Financial Swarm model provides a framework for modeling rational, independent agents where they achieve both individual profitability and collective market efficiency in bilateral asset markets.

</details>


### [30] [Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning](https://arxiv.org/abs/2601.00400)
*Weng Ding,Yi Han,Mu-Jiang-Shan Wang*

Main category: cs.AI

TL;DR: ACCD框架通过三阶段自适应架构，结合因果分析、主动学习和历史经验验证，显著提升社交媒体协同虚假行为检测的准确性和效率，减少人工标注需求。


<details>
  <summary>Details</summary>
Motivation: 现有社交媒体协同虚假行为检测方法存在三个主要问题：依赖表面相关性分析、使用静态参数设置、需要大量人工标注。这些局限性导致检测效果不佳且效率低下。

Method: 提出自适应因果协同检测（ACCD）框架，采用三阶段渐进架构：1）自适应收敛交叉映射技术深入识别账户间真实因果关系；2）半监督分类结合主动学习和不确定性采样减少人工标注；3）基于历史检测经验的自动化验证模块实现自验证和优化。

Result: 在Twitter IRA、Reddit协同痕迹等多个真实数据集上评估，ACCD在协同攻击检测中达到87.3%的F1分数，比最强基线提升15.2%，减少68%人工标注需求，通过层次聚类优化实现2.8倍处理加速。

Conclusion: ACCD提供了一个更准确、高效且高度自动化的端到端解决方案，用于识别社交媒体平台上的协同行为，具有重要的实际应用价值和广泛的推广潜力。

Abstract: Detecting coordinated inauthentic behavior on social media remains a critical and persistent challenge, as most existing approaches rely on superficial correlation analysis, employ static parameter settings, and demand extensive and labor-intensive manual annotation. To address these limitations systematically, we propose the Adaptive Causal Coordination Detection (ACCD) framework. ACCD adopts a three-stage, progressive architecture that leverages a memory-guided adaptive mechanism to dynamically learn and retain optimal detection configurations for diverse coordination scenarios. Specifically, in the first stage, ACCD introduces an adaptive Convergent Cross Mapping (CCM) technique to deeply identify genuine causal relationships between accounts. The second stage integrates active learning with uncertainty sampling within a semi-supervised classification scheme, significantly reducing the burden of manual labeling. The third stage deploys an automated validation module driven by historical detection experience, enabling self-verification and optimization of the detection outcomes. We conduct a comprehensive evaluation using real-world datasets, including the Twitter IRA dataset, Reddit coordination traces, and several widely-adopted bot detection benchmarks. Experimental results demonstrate that ACCD achieves an F1-score of 87.3\% in coordinated attack detection, representing a 15.2\% improvement over the strongest existing baseline. Furthermore, the system reduces manual annotation requirements by 68\% and achieves a 2.8x speedup in processing through hierarchical clustering optimization. In summary, ACCD provides a more accurate, efficient, and highly automated end-to-end solution for identifying coordinated behavior on social platforms, offering substantial practical value and promising potential for broad application.

</details>


### [31] [Can Semantic Methods Enhance Team Sports Tactics? A Methodology for Football with Broader Applications](https://arxiv.org/abs/2601.00421)
*Alessio Di Rubbo,Mattia Neri,Remo Pareschi,Marco Pedroni,Roberto Valtancoli,Paolino Zica*

Main category: cs.AI

TL;DR: 将语义空间推理从计算语言学扩展到团队运动战术决策，将球员视为单词、团队战术视为语义结构，通过向量空间建模评估战术匹配度并生成自适应策略建议。


<details>
  <summary>Details</summary>
Motivation: 传统计算语言学的语义空间推理方法在团队运动战术决策中具有应用潜力，通过类比文本与团队（球员如单词、集体战术如语义），为团队战术分析提供新的量化框架。

Method: 将球员表示为整合技术、身体和心理属性的多维向量，通过上下文加权聚合成团队语义表示；在共享向量空间中编码战术模板（如高位压迫、反击），使用向量距离度量评估战术匹配度和对手利用潜力。

Result: 开发了Python原型系统，能够生成可解释的动态自适应策略建议，并提供属性级别的细粒度诊断洞察；该方法不仅适用于足球，还可推广到篮球、曲棍球、协作机器人和人机协调系统等领域。

Conclusion: 提出了一个通用的团队决策和性能优化框架，未来方向包括真实数据集成、预测模拟以及混合人机战术智能的发展。

Abstract: This paper explores how semantic-space reasoning, traditionally used in computational linguistics, can be extended to tactical decision-making in team sports. Building on the analogy between texts and teams -- where players act as words and collective play conveys meaning -- the proposed methodology models tactical configurations as compositional semantic structures. Each player is represented as a multidimensional vector integrating technical, physical, and psychological attributes; team profiles are aggregated through contextual weighting into a higher-level semantic representation. Within this shared vector space, tactical templates such as high press, counterattack, or possession build-up are encoded analogously to linguistic concepts. Their alignment with team profiles is evaluated using vector-distance metrics, enabling the computation of tactical ``fit'' and opponent-exploitation potential. A Python-based prototype demonstrates how these methods can generate interpretable, dynamically adaptive strategy recommendations, accompanied by fine-grained diagnostic insights at the attribute level. Beyond football, the approach offers a generalizable framework for collective decision-making and performance optimization in team-based domains -- ranging from basketball and hockey to cooperative robotics and human-AI coordination systems. The paper concludes by outlining future directions toward real-world data integration, predictive simulation, and hybrid human-machine tactical intelligence.

</details>


### [32] [Progressive Ideation using an Agentic AI Framework for Human-AI Co-Creation](https://arxiv.org/abs/2601.00475)
*Sankar B,Srinidhi Ranjini Girish,Aadya Bharti,Dibakar Sen*

Main category: cs.AI

TL;DR: MIDAS框架通过分布式AI代理团队模拟人类元认知构思流程，解决新手设计师创意生成中的新颖性和多样性挑战


<details>
  <summary>Details</summary>
Motivation: 当前"单次迸发"式AI系统产生大量语义聚类的想法，加剧了新手设计师在生成真正新颖多样创意方面的认知挑战

Method: 提出MIDAS框架，用分布式专业AI代理团队替代单一AI范式，模拟人类元认知构思工作流程，逐步精炼想法并评估全局新颖性和局部新颖性

Result: MIDAS展示了可行且渐进式的人机共创范式，将人类设计师从被动筛选者提升为参与性、主动的协作伙伴

Conclusion: 分布式AI代理系统为真正的人机共创提供了可行的渐进式范式，解决了创意生成中的新颖性和多样性问题

Abstract: The generation of truly novel and diverse ideas is important for contemporary engineering design, yet it remains a significant cognitive challenge for novice designers. Current 'single-spurt' AI systems exacerbate this challenge by producing a high volume of semantically clustered ideas. We propose MIDAS (Meta-cognitive Ideation through Distributed Agentic AI System), a novel framework that replaces the single-AI paradigm with a distributed 'team' of specialized AI agents designed to emulate the human meta-cognitive ideation workflow. This agentic system progressively refines ideas and assesses each one for both global novelty (against existing solutions) and local novelty (against previously generated ideas). MIDAS, therefore, demonstrates a viable and progressive paradigm for true human-AI co-creation, elevating the human designer from a passive filterer to a participatory, active, collaborative partner.

</details>


### [33] [The Illusion of Insight in Reasoning Models](https://arxiv.org/abs/2601.00514)
*Liv G. d'Aliberti,Manoel Horta Ribeiro*

Main category: cs.AI

TL;DR: 研究发现推理模型中的"顿悟时刻"（中期推理转变）实际上很罕见，不会随训练增加，也很少提高准确性，这表明它们并非真正的自我纠正机制，而是推理不稳定的表现。


<details>
  <summary>Details</summary>
Motivation: 先前研究认为像DeepSeek-R1-Zero这样的模型会在推理过程中经历突然的"顿悟时刻"，实现自我纠正并产生准确输出。但尚不清楚这种内在推理策略转变是否真的能提升性能。

Method: 研究分析了超过100万条推理轨迹、数百个训练检查点、三个推理领域，以及多种解码温度和模型架构。通过检测训练过程中的中期推理转变，并研究其与模型不确定性的关系。

Result: 研究发现：1) 推理转变很罕见；2) 不会随训练变得更频繁；3) 很少提高准确性；4) 其效果随模型不确定性而变化；5) 在高熵条件下人为触发外部转变可以可靠地提高准确性。

Conclusion: 中期推理转变是推理不稳定行为的症状，而非内在的自我纠正机制。模型并不真正经历"顿悟时刻"，这些转变反映了推理过程的不稳定性而非洞察力。

Abstract: Do reasoning models have "Aha!" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.

</details>


### [34] [DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations](https://arxiv.org/abs/2601.00623)
*Longtian Qiu,Shan Ning,Chuyu Zhang,Jiaxuan Sun,Xuming He*

Main category: cs.AI

TL;DR: DA-DPO提出了一种难度感知的直接偏好优化框架，通过估计偏好数据的难度并重加权训练样本，缓解多模态大语言模型中的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态DPO方法由于偏好数据难度不平衡而容易过拟合，模型倾向于过度关注容易区分的偏好对，这阻碍了细粒度的幻觉抑制并降低了整体性能。

Method: DA-DPO包含两个核心组件：1) 难度估计 - 利用预训练的视觉-语言模型通过生成式和对比式目标，结合分布感知投票策略产生难度分数；2) 难度感知训练 - 基于估计的难度重加权偏好对，降低简单样本权重，强调困难样本以缓解过拟合。

Result: 大量实验表明DA-DPO能持续改进多模态偏好优化，在标准基准测试中展现出更强的幻觉鲁棒性和更好的泛化能力，同时保持计算效率。

Conclusion: DA-DPO通过难度感知的偏好优化框架，有效解决了多模态DPO中的过拟合问题，无需额外数据或微调阶段即可实现更有效的幻觉抑制和性能提升。

Abstract: Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.

</details>


### [35] [A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference](https://arxiv.org/abs/2601.00694)
*Qingwen Pu,Kun Xie,Hong Yang,Guocong Zhai*

Main category: cs.AI

TL;DR: PedX-LLM是一个结合视觉特征、文本数据和交通领域知识的LLM框架，用于推断行人过街行为，在准确性和泛化性上优于传统统计和监督学习方法。


<details>
  <summary>Details</summary>
Motivation: 现有行人过街行为推断方法（统计模型和监督学习）泛化能力有限，在新场景下表现不佳。现有LLM应用缺乏领域特定适应和视觉上下文。

Method: 提出PedX-LLM框架，整合LLaVA提取的视觉特征、文本数据和交通领域知识，通过LoRA微调LLaMA-2-7B基础模型来推断行人过街决策。

Result: PedX-LLM达到82.0%平衡准确率，优于最佳统计和监督学习方法。视觉增强模块贡献2.9%性能提升，领域知识集成带来额外4.1%改进。在未见测试场景中，零样本配置达到66.9%准确率，少样本学习提升至72.2%。

Conclusion: PedX-LLM展示了强大的泛化能力，证实视觉和知识增强的推理使模型能够模拟人类决策逻辑，克服纯数据驱动方法的局限性。

Abstract: Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.

</details>


### [36] [An Agentic Framework for Neuro-Symbolic Programming](https://arxiv.org/abs/2601.00743)
*Aliakbar Nafar,Chetan Chigurupati,Danial Kamali,Hamid Karimian,Parisa Kordjamshidi*

Main category: cs.AI

TL;DR: AgenticDomiKnowS (ADS) 是一个将自由形式任务描述自动转换为完整 DomiKnowS 程序的系统，通过智能体工作流显著降低神经符号编程的开发时间。


<details>
  <summary>Details</summary>
Motivation: 将符号约束集成到深度学习模型中可以提高鲁棒性、可解释性和数据效率，但现有框架（如 DomiKnowS）仍需要用户精通特定语法，开发过程耗时且具有挑战性。

Method: ADS 采用智能体工作流，将自由形式任务描述翻译为完整的 DomiKnowS 程序，通过创建和单独测试每个 DomiKnowS 组件实现，支持可选的人类在环干预，允许熟悉 DomiKnowS 的用户精炼中间输出。

Result: ADS 使有经验的 DomiKnowS 用户和非用户都能快速构建神经符号程序，将开发时间从数小时减少到 10-15 分钟。

Conclusion: ADS 通过消除对特定库语法的依赖，显著降低了神经符号编程的门槛，使更广泛的用户能够高效地将符号约束集成到深度学习模型中。

Abstract: Integrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library's specific syntax. We propose AgenticDomiKnowS (ADS) to eliminate this dependency. ADS translates free-form task descriptions into a complete DomiKnowS program using an agentic workflow that creates and tests each DomiKnowS component separately. The workflow supports optional human-in-the-loop intervention, enabling users familiar with DomiKnowS to refine intermediate outputs. We show how ADS enables experienced DomiKnowS users and non-users to rapidly construct neuro-symbolic programs, reducing development time from hours to 10-15 minutes.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [37] [On the Error Floor Evaluation of NOMA-Irregular Repetition Slotted ALOHA](https://arxiv.org/abs/2601.00317)
*Estefanía Recayte*

Main category: cs.ET

TL;DR: 提出一种简单而精确的非正交多址接入(NOMA)不规则重复时隙ALOHA(IRSA)方案在错误平层区域的丢包率解析近似方法


<details>
  <summary>Details</summary>
Motivation: 在物联网场景中，需要分析NOMA-IRSA方案在有限长度机制下的性能，特别是在错误平层区域的丢包率，现有方法可能不够精确或计算复杂

Method: 用户随机选择基于设计的度分布的副本数量和预定功率水平，接收端执行连续干扰消除(SIC)，推导出有限长度机制下的丢包率解析表达式

Result: 推导的丢包率表达式计算快速，通过蒙特卡洛仿真验证了其准确性，在不同信道负载（包括超出低负载区域）下都表现出强匹配性

Conclusion: 提出的解析近似方法简单而精确，能够有效评估NOMA-IRSA方案在错误平层区域的性能，适用于物联网场景的性能分析

Abstract: In this work, we provide a simple yet tight analytical approximation of the packet loss rate in the error floor region for a non-orthogonal multiple access (NOMA)-based irregular repetition slotted ALOHA (IRSA) scheme. Considering an Internet of Things (IoT) scenario, users randomly select both the number of replicas based on a designed degree distribution and the transmission power from predetermined levels, while successive interference cancellation (SIC) is performed at the receiver. Our derived packet loss rate expression in the finite length regime is promptly evaluated. Its accuracy is validated through Monte-Carlo simulations, demonstrating a strong match across channel loads, including those beyond the low load regime

</details>


### [38] [Two-Step Interference Cancellation for Energy Saving in Irregular Repetition Slotted ALOHA](https://arxiv.org/abs/2601.00343)
*Estefanía Recayte,Leonardo Badia,Andrea Munari*

Main category: cs.ET

TL;DR: 提出一种改进的IRSA协议，通过中间解码和早期传输终止来减少不必要的传输，从而降低能耗，特别适用于低负载场景。


<details>
  <summary>Details</summary>
Motivation: 现有IRSA文献主要关注高负载渐近性能，而实际应用中低负载场景下许多传输是冗余的，造成能量浪费。需要一种能减少不必要传输的机制来降低能耗。

Method: 修改IRSA协议，引入中间解码和早期传输终止机制：节点在成功解码后立即停止传输，避免冗余传输。同时建立了有限帧长和低负载下的能耗与成功概率模型。

Result: 通过分析和仿真验证，该技术能在保持对标准ALOHA性能优势的同时，显著降低IRSA能耗。例如在10%负载下可实现33%的节能，且不影响吞吐量。

Conclusion: 提出的改进IRSA协议能有效减少低负载场景下的能量消耗，通过中间解码和早期传输终止机制实现了显著的节能效果，同时保持了协议性能优势。

Abstract: We evaluate a modification of irregular repetition slotted ALOHA (IRSA) involving intermediate decoding and early transmission termination by some nodes, upon their decoding success. This is meant to avoid unnecessary transmissions, thereby reducing energy consumption. We expect this to be particularly useful at low loads, where most transmissions can be avoided as they do not often result in a collision and are therefore redundant. To validate this proposal, we observe that most of the literature related to IRSA considers an asymptotic heavily loaded regime; thus, we also present a model of energy consumption and success probability for frames of limited length and low offered loads. Thanks to our analysis, also confirmed by simulation, we are able to show that the proposed technique is able to reduce IRSA energy consumption by minimizing transmissions, while preserving performance gains over standard ALOHA. For example, we are able to get a 33% energy saving at offered loads around 10% without affecting throughput.

</details>
