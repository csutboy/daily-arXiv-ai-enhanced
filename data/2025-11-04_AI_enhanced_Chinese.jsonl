{"id": "2511.00324", "categories": ["econ.EM", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2511.00324", "abs": "https://arxiv.org/abs/2511.00324", "authors": ["Isaac Meza"], "title": "Residual Balancing for Non-Linear Outcome Models in High Dimensions", "comment": null, "summary": "We extend the approximate residual balancing (ARB) framework to nonlinear\nmodels, answering an open problem posed by Athey et al. (2018). Our approach\naddresses the challenge of estimating average treatment effects in\nhigh-dimensional settings where the outcome follows a generalized linear model.\nWe derive a new bias decomposition for nonlinear models that reveals the need\nfor a second-order correction to account for the curvature of the link\nfunction. Based on this insight, we construct balancing weights through an\noptimization problem that controls for both first and second-order sources of\nbias. We provide theoretical guarantees for our estimator, establishing its\n$\\sqrt{n}$-consistency and asymptotic normality under standard high-dimensional\nassumptions.", "AI": {"tldr": "\u5c06\u8fd1\u4f3c\u6b8b\u5dee\u5e73\u8861\u6846\u67b6\u6269\u5c55\u5230\u975e\u7ebf\u6027\u6a21\u578b\uff0c\u901a\u8fc7\u4e8c\u9636\u6821\u6b63\u5904\u7406\u94fe\u63a5\u51fd\u6570\u66f2\u7387\uff0c\u5728\u9ad8\u7ef4\u8bbe\u7f6e\u4e2d\u4f30\u8ba1\u5e7f\u4e49\u7ebf\u6027\u6a21\u578b\u7684\u5e73\u5747\u5904\u7406\u6548\u5e94", "motivation": "\u89e3\u51b3Athey\u7b49\u4eba(2018)\u63d0\u51fa\u7684\u5f00\u653e\u95ee\u9898\uff0c\u5904\u7406\u9ad8\u7ef4\u8bbe\u7f6e\u4e2d\u5e7f\u4e49\u7ebf\u6027\u6a21\u578b\u5e73\u5747\u5904\u7406\u6548\u5e94\u7684\u4f30\u8ba1\u6311\u6218", "method": "\u63a8\u5bfc\u975e\u7ebf\u6027\u6a21\u578b\u7684\u504f\u501a\u5206\u89e3\uff0c\u6784\u5efa\u63a7\u5236\u4e00\u9636\u548c\u4e8c\u9636\u504f\u501a\u6e90\u7684\u5e73\u8861\u6743\u91cd\u4f18\u5316\u95ee\u9898", "result": "\u5728\u6807\u51c6\u9ad8\u7ef4\u5047\u8bbe\u4e0b\u5efa\u7acb\u4e86\u4f30\u8ba1\u91cf\u7684\u221an\u4e00\u81f4\u6027\u548c\u6e10\u8fd1\u6b63\u6001\u6027\u7406\u8bba\u4fdd\u8bc1", "conclusion": "\u6210\u529f\u5c06ARB\u6846\u67b6\u6269\u5c55\u5230\u975e\u7ebf\u6027\u6a21\u578b\uff0c\u4e3a\u9ad8\u7ef4\u5e7f\u4e49\u7ebf\u6027\u6a21\u578b\u7684\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5"}}
{"id": "2511.00597", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2511.00597", "abs": "https://arxiv.org/abs/2511.00597", "authors": ["Chiara Amorino", "Christian Brownlees", "Ankita Ghosh"], "title": "Concentration Inequalities for Suprema of Empirical Processes with Dependent Data via Generic Chaining with Applications to Statistical Learning", "comment": "42 pages", "summary": "This paper develops a general concentration inequality for the suprema of\nempirical processes with dependent data. The concentration inequality is\nobtained by combining generic chaining with a coupling-based strategy. Our\nframework accommodates high-dimensional and heavy-tailed (sub-Weibull) data. We\ndemonstrate the usefulness of our result by deriving non-asymptotic predictive\nperformance guarantees for empirical risk minimization in regression problems\nwith dependent data. In particular, we establish an oracle inequality for a\nbroad class of nonlinear regression models and, as a special case, a\nsingle-layer neural network model. Our results show that empirical risk\nminimzaton with dependent data attains a prediction accuracy comparable to that\nin the i.i.d. setting for a wide range of nonlinear regression models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u4f9d\u8d56\u6570\u636e\u7684\u7ecf\u9a8c\u8fc7\u7a0b\u4e0a\u786e\u754c\u7684\u901a\u7528\u96c6\u4e2d\u4e0d\u7b49\u5f0f\uff0c\u7ed3\u5408\u4e86\u901a\u7528\u94fe\u548c\u8026\u5408\u7b56\u7565\uff0c\u9002\u7528\u4e8e\u9ad8\u7ef4\u548c\u91cd\u5c3e\u6570\u636e\uff0c\u5e76\u5e94\u7528\u4e8e\u975e\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u7684\u975e\u6e10\u8fd1\u9884\u6d4b\u6027\u80fd\u4fdd\u8bc1\u3002", "motivation": "\u73b0\u6709\u96c6\u4e2d\u4e0d\u7b49\u5f0f\u4e3b\u8981\u9488\u5bf9\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\uff0c\u7f3a\u4e4f\u5bf9\u4f9d\u8d56\u6570\u636e\u7684\u901a\u7528\u7406\u8bba\u6846\u67b6\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ef4\u548c\u91cd\u5c3e\u6570\u636e\u573a\u666f\u4e0b\u3002", "method": "\u7ed3\u5408\u901a\u7528\u94fe\u65b9\u6cd5\u548c\u8026\u5408\u7b56\u7565\uff0c\u6784\u5efa\u7ecf\u9a8c\u8fc7\u7a0b\u4e0a\u786e\u754c\u7684\u96c6\u4e2d\u4e0d\u7b49\u5f0f\uff0c\u9002\u7528\u4e8e\u4f9d\u8d56\u6570\u636e\u548c\u9ad8\u7ef4\u91cd\u5c3e\u5206\u5e03\u3002", "result": "\u5efa\u7acb\u4e86\u4f9d\u8d56\u6570\u636e\u4e0b\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u7684\u9884\u6d4b\u6027\u80fd\u4fdd\u8bc1\uff0c\u5305\u62ec\u975e\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u548c\u5355\u5c42\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7684oracle\u4e0d\u7b49\u5f0f\uff0c\u8868\u660e\u5176\u9884\u6d4b\u7cbe\u5ea6\u4e0e\u72ec\u7acb\u540c\u5206\u5e03\u8bbe\u7f6e\u76f8\u5f53\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u96c6\u4e2d\u4e0d\u7b49\u5f0f\u4e3a\u4f9d\u8d56\u6570\u636e\u4e0b\u7684\u7ecf\u9a8c\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u901a\u7528\u7406\u8bba\u5de5\u5177\uff0c\u5728\u975e\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u4e2d\u5b9e\u73b0\u4e86\u4e0e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u76f8\u5f53\u7684\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2511.00612", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2511.00612", "abs": "https://arxiv.org/abs/2511.00612", "authors": ["Vincent Starck"], "title": "Improving control over unobservables with network data", "comment": null, "summary": "This paper develops a method to conduct causal inference in the presence of\nunobserved confounders by leveraging networks with homophily, a frequently\nobserved tendency to form edges with similar nodes. I introduce a concept of\nasymptotic homophily, according to which individuals' selectivity scales with\nthe size of the potential connection pool. It contributes to the network\nformation literature with a model that can accommodate common empirical\nfeatures such as homophily, degree heterogeneity, sparsity, and clustering, and\nprovides a framework to obtain consistent estimators of treatment effects that\nare robust to selection on unobservables. I also consider an alternative\nsetting that accommodates dense networks and show how selecting linked\nindividuals whose observed characteristics made such a connection less likely\ndelivers an estimator with similar properties. In an application, I recover an\nestimate of the effect of parental involvement on students' test scores that is\ngreater than that of OLS, arguably due to the estimator's ability to account\nfor unobserved ability.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5f00\u53d1\u4e86\u4e00\u79cd\u5229\u7528\u540c\u8d28\u6027\u7f51\u7edc\u8fdb\u884c\u56e0\u679c\u63a8\u65ad\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6e10\u8fd1\u540c\u8d28\u6027\u6982\u5ff5\u548c\u7f51\u7edc\u5f62\u6210\u6a21\u578b\uff0c\u5728\u5b58\u5728\u672a\u89c2\u6d4b\u6df7\u6742\u56e0\u7d20\u7684\u60c5\u51b5\u4e0b\u83b7\u5f97\u4e00\u81f4\u7684\u6cbb\u7597\u6548\u679c\u4f30\u8ba1\u91cf\u3002", "motivation": "\u89e3\u51b3\u5728\u5b58\u5728\u672a\u89c2\u6d4b\u6df7\u6742\u56e0\u7d20\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u56e0\u679c\u63a8\u65ad\u7684\u6311\u6218\uff0c\u5229\u7528\u7f51\u7edc\u4e2d\u5e38\u89c1\u7684\u540c\u8d28\u6027\u7279\u5f81\u6765\u514b\u670d\u9009\u62e9\u504f\u8bef\u95ee\u9898\u3002", "method": "\u5f15\u5165\u6e10\u8fd1\u540c\u8d28\u6027\u6982\u5ff5\uff0c\u5efa\u7acb\u80fd\u591f\u5bb9\u7eb3\u540c\u8d28\u6027\u3001\u5ea6\u5f02\u8d28\u6027\u3001\u7a00\u758f\u6027\u548c\u805a\u7c7b\u7b49\u7ecf\u9a8c\u7279\u5f81\u7684\u7f51\u7edc\u5f62\u6210\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u9009\u62e9\u8fde\u63a5\u6982\u7387\u8f83\u4f4e\u7684\u4e2a\u4f53\u6765\u6784\u5efa\u4f30\u8ba1\u91cf\u3002", "result": "\u5f00\u53d1\u51fa\u5bf9\u672a\u89c2\u6d4b\u6df7\u6742\u56e0\u7d20\u5177\u6709\u9c81\u68d2\u6027\u7684\u6cbb\u7597\u6548\u679c\u4e00\u81f4\u4f30\u8ba1\u91cf\uff0c\u5728\u5e94\u7528\u4e2d\u53d1\u73b0\u7236\u6bcd\u53c2\u4e0e\u5bf9\u5b66\u751f\u8003\u8bd5\u6210\u7ee9\u7684\u5f71\u54cd\u4f30\u8ba1\u5927\u4e8eOLS\u65b9\u6cd5\u7684\u7ed3\u679c\u3002", "conclusion": "\u5229\u7528\u7f51\u7edc\u540c\u8d28\u6027\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u56e0\u679c\u63a8\u65ad\u4e2d\u7684\u672a\u89c2\u6d4b\u6df7\u6742\u95ee\u9898\uff0c\u4e3a\u5b58\u5728\u7f51\u7edc\u6570\u636e\u7684\u5b9e\u8bc1\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u8bc6\u522b\u7b56\u7565\u3002"}}
{"id": "2511.00727", "categories": ["econ.EM", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00727", "abs": "https://arxiv.org/abs/2511.00727", "authors": ["Xuelin Yang", "Licong Lin", "Susan Athey", "Michael I. Jordan", "Guido W. Imbens"], "title": "Cross-Validated Causal Inference: a Modern Method to Combine Experimental and Observational Data", "comment": "83 pages, 11 figures", "summary": "We develop new methods to integrate experimental and observational data in\ncausal inference. While randomized controlled trials offer strong internal\nvalidity, they are often costly and therefore limited in sample size.\nObservational data, though cheaper and often with larger sample sizes, are\nprone to biases due to unmeasured confounders. To harness their complementary\nstrengths, we propose a systematic framework that formulates causal estimation\nas an empirical risk minimization (ERM) problem. A full model containing the\ncausal parameter is obtained by minimizing a weighted combination of\nexperimental and observational losses--capturing the causal parameter's\nvalidity and the full model's fit, respectively. The weight is chosen through\ncross-validation on the causal parameter across experimental folds. Our\nexperiments on real and synthetic data show the efficacy and reliability of our\nmethod. We also provide theoretical non-asymptotic error bounds.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6574\u5408\u5b9e\u9a8c\u6570\u636e\u548c\u89c2\u5bdf\u6570\u636e\u8fdb\u884c\u56e0\u679c\u63a8\u65ad\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u6846\u67b6\u7ed3\u5408\u4e24\u79cd\u6570\u636e\u6e90\u7684\u4f18\u52bf\u3002", "motivation": "\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u5185\u90e8\u6548\u5ea6\u9ad8\u4f46\u6210\u672c\u6602\u8d35\u6837\u672c\u91cf\u5c0f\uff0c\u89c2\u5bdf\u6570\u636e\u6837\u672c\u91cf\u5927\u4f46\u5b58\u5728\u672a\u6d4b\u91cf\u6df7\u6742\u56e0\u7d20\u504f\u501a\uff0c\u9700\u8981\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u3002", "method": "\u5c06\u56e0\u679c\u4f30\u8ba1\u6784\u5efa\u4e3a\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u5b9e\u9a8c\u635f\u5931\u548c\u89c2\u5bdf\u635f\u5931\u7684\u52a0\u6743\u7ec4\u5408\u6765\u83b7\u5f97\u5305\u542b\u56e0\u679c\u53c2\u6570\u7684\u5b8c\u6574\u6a21\u578b\uff0c\u6743\u91cd\u901a\u8fc7\u4ea4\u53c9\u9a8c\u8bc1\u9009\u62e9\u3002", "result": "\u5728\u771f\u5b9e\u548c\u5408\u6210\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u53ef\u9760\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0a\u7684\u975e\u6e10\u8fd1\u8bef\u5dee\u754c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u6574\u5408\u4e86\u5b9e\u9a8c\u548c\u89c2\u5bdf\u6570\u636e\uff0c\u5728\u56e0\u679c\u63a8\u65ad\u4e2d\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6548\u679c\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2511.00080", "categories": ["econ.GN", "q-fin.EC", "stat.AP", "I.2.6, I.5.4, J.4, K.4.1", "I.2; I.5; J.4; K.4"], "pdf": "https://arxiv.org/pdf/2511.00080", "abs": "https://arxiv.org/abs/2511.00080", "authors": ["Auyona Ray"], "title": "Closing the SNAP Gap: Identifying Under-Enrollment in High-Poverty ZIP Codes", "comment": "28 pages, 5 figures. Working paper on SNAP participation and economic\n  insecurity. Relevant to economics (general), econometrics, public policy, and\n  applied machine learning audiences", "summary": "This project began by constructing an index of economic insecurity using\nmultiple socioeconomic indicators. Although poverty alone predicted SNAP\nparticipation more accurately than the composite index, its explanatory power\nwas weaker than anticipated, echoing past findings that enrollment cannot be\nexplained by income alone. This led to a shift in focus: identifying ZIP codes\nwith high poverty but unexpectedly low SNAP participation, areas defined here\nas having a SNAP Gap, where ZIPs fall in the top 30 percent of family poverty\nand the bottom 10 percent of SNAP enrollment. Using nationally available ZIP\nlevel data from 2014 to 2023, I trained logistic classification models on four\ninterpretable structural indicators: lack of vehicle, lack of internet access,\nlack of computer access, and percentage of adults with only a high school\ndiploma. The most effective model relies on just two predictors, vehicle access\nand education, and outperforms tree based classifiers in both precision and\ncalibration. Results show that economic insecurity is consistently concentrated\nin rural ZIP codes, with transportation access emerging as the most stable\nbarrier to program take up. This study provides a nationwide diagnostic\nframework that can inform the development of scalable screening tools for\ntargeting outreach and improving benefit access in underserved communities.", "AI": {"tldr": "\u6784\u5efa\u7ecf\u6d4e\u4e0d\u5b89\u5168\u6307\u6570\uff0c\u53d1\u73b0\u8d2b\u56f0\u5355\u72ec\u9884\u6d4bSNAP\u53c2\u4e0e\u5ea6\u6bd4\u590d\u5408\u6307\u6570\u66f4\u51c6\u786e\u4f46\u89e3\u91ca\u529b\u6709\u9650\uff0c\u8f6c\u800c\u8bc6\u522b\u9ad8\u8d2b\u56f0\u4f46SNAP\u53c2\u4e0e\u5ea6\u4f4e\u7684\u5730\u533a\uff08SNAP\u7f3a\u53e3\uff09\uff0c\u4f7f\u7528\u8f66\u8f86\u548c\u6559\u80b2\u4e24\u4e2a\u9884\u6d4b\u56e0\u5b50\u6784\u5efa\u903b\u8f91\u5206\u7c7b\u6a21\u578b\uff0c\u53d1\u73b0\u519c\u6751\u5730\u533a\u7ecf\u6d4e\u4e0d\u5b89\u5168\u96c6\u4e2d\u4e14\u4ea4\u901a\u662f\u4e3b\u8981\u969c\u788d\u3002", "motivation": "\u4f20\u7edf\u4e0a\u8ba4\u4e3a\u6536\u5165\u662fSNAP\u53c2\u4e0e\u5ea6\u7684\u4e3b\u8981\u51b3\u5b9a\u56e0\u7d20\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u4ec5\u9760\u6536\u5165\u65e0\u6cd5\u5b8c\u5168\u89e3\u91ca\u53c2\u4e0e\u7387\uff0c\u9700\u8981\u8bc6\u522b\u5176\u4ed6\u7ed3\u6784\u6027\u969c\u788d\uff0c\u7279\u522b\u662f\u5728\u9ad8\u8d2b\u56f0\u4f46\u4f4e\u53c2\u4e0e\u5ea6\u7684\u5730\u533a\u3002", "method": "\u4f7f\u75282014-2023\u5e74\u5168\u56fdZIP\u7ea7\u522b\u6570\u636e\uff0c\u6784\u5efa\u903b\u8f91\u5206\u7c7b\u6a21\u578b\uff0c\u5206\u6790\u56db\u4e2a\u7ed3\u6784\u6027\u6307\u6807\uff1a\u7f3a\u4e4f\u8f66\u8f86\u3001\u7f3a\u4e4f\u4e92\u8054\u7f51\u63a5\u5165\u3001\u7f3a\u4e4f\u7535\u8111\u63a5\u5165\u3001\u4ec5\u9ad8\u4e2d\u6587\u51ed\u6210\u4eba\u6bd4\u4f8b\u3002", "result": "\u4ec5\u4f7f\u7528\u8f66\u8f86\u63a5\u5165\u548c\u6559\u80b2\u4e24\u4e2a\u9884\u6d4b\u56e0\u5b50\u7684\u6a21\u578b\u6548\u679c\u6700\u4f73\uff0c\u5728\u7cbe\u786e\u5ea6\u548c\u6821\u51c6\u5ea6\u4e0a\u90fd\u4f18\u4e8e\u57fa\u4e8e\u6811\u7684\u5206\u7c7b\u5668\uff0c\u53d1\u73b0\u7ecf\u6d4e\u4e0d\u5b89\u5168\u96c6\u4e2d\u5728\u519c\u6751\u5730\u533a\uff0c\u4ea4\u901a\u662f\u963b\u788d\u9879\u76ee\u53c2\u4e0e\u7684\u6700\u7a33\u5b9a\u969c\u788d\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u56fd\u6027\u8bca\u65ad\u6846\u67b6\uff0c\u53ef\u4e3a\u5f00\u53d1\u53ef\u6269\u5c55\u7684\u7b5b\u67e5\u5de5\u5177\u63d0\u4f9b\u4fe1\u606f\uff0c\u4ee5\u9488\u5bf9\u670d\u52a1\u4e0d\u8db3\u793e\u533a\u8fdb\u884c\u5916\u5c55\u548c\u6539\u5584\u798f\u5229\u83b7\u53d6\u3002"}}
{"id": "2511.00031", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2511.00031", "abs": "https://arxiv.org/abs/2511.00031", "authors": ["Shunsuke Matsuno"], "title": "The Gatekeeping Expert's Dilemma", "comment": "50 pages", "summary": "This paper studies how experts with veto power -- gatekeeping experts --\ninfluence agents through communication. Their expertise informs agents'\ndecisions, while veto power provides discipline. Gatekeepers face a dilemma:\ntransparent communication can invite gaming, while opacity wastes expertise.\nHow can gatekeeping experts guide behavior without being gamed? Many economic\nsettings feature this tradeoff, including bank stress tests, environmental\nregulations, and financial auditing. Using financial auditing as the primary\nsetting, I show that strategic vagueness resolves this dilemma: by revealing\njust enough to prevent the manager from inflating the report, the auditor\nguides the manager while minimizing opportunities for manipulation. This\ntheoretical lens provides a novel rationale for why auditors predominantly\naccept clients' financial reports. Comparative statics reveal that greater\ngatekeeper independence or expertise sometimes dampens communication. This\npaper offers insights into why gatekeepers who lack direct control can still be\neffective.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5177\u6709\u5426\u51b3\u6743\u7684\u4e13\u5bb6\uff08\u5b88\u95e8\u4eba\u4e13\u5bb6\uff09\u5982\u4f55\u901a\u8fc7\u6c9f\u901a\u5f71\u54cd\u4ee3\u7406\u4eba\u3002\u5b88\u95e8\u4eba\u9762\u4e34\u900f\u660e\u5ea6\u4e0e\u6709\u6548\u6027\u7684\u6743\u8861\uff1a\u900f\u660e\u6c9f\u901a\u6613\u88ab\u5229\u7528\uff0c\u4e0d\u900f\u660e\u5219\u6d6a\u8d39\u4e13\u4e1a\u77e5\u8bc6\u3002\u7814\u7a76\u8868\u660e\u6218\u7565\u6a21\u7cca\u6027\u53ef\u4ee5\u89e3\u51b3\u8fd9\u4e00\u56f0\u5883\u3002", "motivation": "\u7814\u7a76\u5b88\u95e8\u4eba\u4e13\u5bb6\u5728\u4e13\u4e1a\u77e5\u8bc6\u4e0e\u5426\u51b3\u6743\u4e4b\u95f4\u7684\u5e73\u8861\u95ee\u9898\uff0c\u63a2\u7d22\u5982\u4f55\u5728\u6307\u5bfc\u4ee3\u7406\u4eba\u884c\u4e3a\u7684\u540c\u65f6\u907f\u514d\u88ab\u64cd\u7eb5\u3002\u8fd9\u5728\u94f6\u884c\u538b\u529b\u6d4b\u8bd5\u3001\u73af\u5883\u76d1\u7ba1\u548c\u8d22\u52a1\u5ba1\u8ba1\u7b49\u7ecf\u6d4e\u573a\u666f\u4e2d\u666e\u904d\u5b58\u5728\u3002", "method": "\u4ee5\u8d22\u52a1\u5ba1\u8ba1\u4e3a\u4e3b\u8981\u573a\u666f\uff0c\u6784\u5efa\u7406\u8bba\u6a21\u578b\u5206\u6790\u5b88\u95e8\u4eba\u4e13\u5bb6\u7684\u6c9f\u901a\u7b56\u7565\uff0c\u7279\u522b\u5173\u6ce8\u6218\u7565\u6a21\u7cca\u6027\u7684\u4f5c\u7528\u3002", "result": "\u6218\u7565\u6a21\u7cca\u6027\u80fd\u591f\u89e3\u51b3\u5b88\u95e8\u4eba\u7684\u56f0\u5883\uff1a\u901a\u8fc7\u4ec5\u900f\u9732\u8db3\u591f\u4fe1\u606f\u6765\u9632\u6b62\u7ba1\u7406\u8005\u5938\u5927\u62a5\u544a\uff0c\u5ba1\u8ba1\u5e08\u65e2\u80fd\u6307\u5bfc\u7ba1\u7406\u8005\u53c8\u80fd\u6700\u5c0f\u5316\u64cd\u7eb5\u673a\u4f1a\u3002\u8fd9\u4e3a\u5ba1\u8ba1\u5e08\u4e3b\u8981\u63a5\u53d7\u5ba2\u6237\u8d22\u52a1\u62a5\u544a\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u89e3\u91ca\u3002", "conclusion": "\u6218\u7565\u6a21\u7cca\u6027\u662f\u5b88\u95e8\u4eba\u4e13\u5bb6\u6709\u6548\u6c9f\u901a\u7684\u5173\u952e\u7b56\u7565\uff0c\u5373\u4f7f\u7f3a\u4e4f\u76f4\u63a5\u63a7\u5236\u6743\u4e5f\u80fd\u6709\u6548\u5f71\u54cd\u4ee3\u7406\u4eba\u884c\u4e3a\u3002\u66f4\u5927\u7684\u72ec\u7acb\u6027\u548c\u4e13\u4e1a\u77e5\u8bc6\u6709\u65f6\u53cd\u800c\u4f1a\u6291\u5236\u6c9f\u901a\u6548\u679c\u3002"}}
{"id": "2511.00329", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.00329", "abs": "https://arxiv.org/abs/2511.00329", "authors": ["Masoud Makrehchi"], "title": "When Small Acts Scale: Ethical Thresholds in Network Diffusion", "comment": "11 Pages", "summary": "Much ethical evaluation treats actions dyadically: one agent acts on one\nrecipient. In networked, platform-mediated environments, this lens misses how\npublic acts diffuse. We introduce a minimal message-passing model in which an\ninitiating act with baseline valence w spreads across a social graph with\nexposure b, per-hop salience $alpha$, compliance $q$, and depth (horizon) d.\nThe model yields a closed-form \\emph{network multiplier} relative to the dyadic\nbaseline and identifies a threshold at r=b.alpha.q=1 separating subcritical\n(saturating), critical (linear), and supercritical (geometric) regimes. We show\nhow common platform design levers -- reach and fan-out (affecting b), ranking\nand context (affecting alpha), share mechanics and friction (affecting q), and\ntime-bounds (affecting d) -- systematically change expected downstream\nresponsibility Applications include pandemic mitigation and vaccination\nexternalities, as well as platform amplification of prosocial and harmful\nnorms.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7f51\u7edc\u4f20\u64ad\u6a21\u578b\u6765\u5206\u6790\u516c\u5171\u884c\u4e3a\u5728\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u6269\u6563\u6548\u5e94\uff0c\u5f15\u5165\u4e86\u7f51\u7edc\u4e58\u6570\u6982\u5ff5\uff0c\u5e76\u8bc6\u522b\u4e86\u4e34\u754c\u9608\u503c\u6765\u533a\u5206\u4e0d\u540c\u4f20\u64ad\u72b6\u6001\u3002", "motivation": "\u4f20\u7edf\u4f26\u7406\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u4e8c\u5143\u884c\u4e3a\uff08\u4e00\u4e2a\u65bd\u52a8\u8005\u5bf9\u4e00\u4e2a\u63a5\u6536\u8005\uff09\uff0c\u4f46\u5728\u7f51\u7edc\u5316\u7684\u5e73\u53f0\u73af\u5883\u4e2d\uff0c\u8fd9\u79cd\u89c6\u89d2\u65e0\u6cd5\u6355\u6349\u516c\u5171\u884c\u4e3a\u7684\u6269\u6563\u6548\u5e94\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u6700\u5c0f\u6d88\u606f\u4f20\u9012\u6a21\u578b\uff0c\u5305\u542b\u521d\u59cb\u884c\u4e3a\u57fa\u51c6\u6548\u4ef7\u3001\u66dd\u5149\u5ea6\u3001\u663e\u8457\u6027\u3001\u9075\u4ece\u5ea6\u548c\u4f20\u64ad\u6df1\u5ea6\u7b49\u53c2\u6570\uff0c\u63a8\u5bfc\u51fa\u7f51\u7edc\u4e58\u6570\u7684\u95ed\u5f0f\u89e3\u3002", "result": "\u6a21\u578b\u8bc6\u522b\u51fa\u4e34\u754c\u9608\u503cr=1\uff0c\u533a\u5206\u4e86\u4e9a\u4e34\u754c\uff08\u9971\u548c\uff09\u3001\u4e34\u754c\uff08\u7ebf\u6027\uff09\u548c\u8d85\u4e34\u754c\uff08\u51e0\u4f55\u7ea7\u6570\uff09\u4e09\u79cd\u4f20\u64ad\u72b6\u6001\uff0c\u5e76\u5c55\u793a\u4e86\u5e73\u53f0\u8bbe\u8ba1\u6760\u6746\u5982\u4f55\u7cfb\u7edf\u6027\u6539\u53d8\u4e0b\u6e38\u8d23\u4efb\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u5206\u6790\u5e73\u53f0\u73af\u5883\u4e2d\u884c\u4e3a\u6269\u6563\u7684\u4f26\u7406\u8d23\u4efb\u63d0\u4f9b\u4e86\u6846\u67b6\uff0c\u53ef\u5e94\u7528\u4e8e\u75ab\u60c5\u7f13\u89e3\u3001\u75ab\u82d7\u63a5\u79cd\u5916\u90e8\u6027\u4ee5\u53ca\u5e73\u53f0\u5bf9\u4eb2\u793e\u4f1a\u548c\u6709\u5bb3\u89c4\u8303\u7684\u653e\u5927\u6548\u5e94\u5206\u6790\u3002"}}
{"id": "2511.00365", "categories": ["q-fin.GN"], "pdf": "https://arxiv.org/pdf/2511.00365", "abs": "https://arxiv.org/abs/2511.00365", "authors": ["Boliang Lin", "Ruixi Lin"], "title": "A parallel monetary system based on the redeemable self-decaying money -- The ultimate hedge and safe haven of private wealth in the rising wave of over issuance of fiat and token money/stablecoin", "comment": null, "summary": "A currency with stable purchasing power can always provide a psychological\nhaven for people around the world. However, since the collapse of the Bretton\nWoods system, issuing more cheap currencies has become a common trend in the\ninternational community, and the legalization and over issuance of stablecoins\nwill strengthen this trend. In this context, our study focused on a parallel\nmonetary system based on a redeemable self-decay/devalued money(RSDM). Firstly,\nwe point out the idea of redeeming gold at a fixed denomination with gold\ncertificates is similar to an impossible perpetual motion machine. Only when\nthe face value of a gold token self-decays or self-depreciates and the weight\nof the reduced value can compensate for the storage cost of physical gold, can\nit be convertible or redeemable. Secondly, we pointed out that as a modern\n\"good money\" under the Internet environment, it must have two basic functions:\nlong-term value storage and zero logistics cost of money circulation. Thirdly,\nwe found that a single type of money is difficult to shoulder the\nresponsibility of modern \"good money\". Only a parallel monetary system,\nincluding RSDM, such as a triple-monetary system consisting of RSDM, domestic\nfiat and major international reserve currencies, can form the ultimate safe\nhaven of wealth and safeguard the reverse Gresham law. Based on this analysis,\nwe build an integer programming model for currency optimization selection in a\nmulti-monetary pool. Fourthly, several potential application scenarios of RSDM\nin the real world were discussed, including a new approach to activate dormant\ngold assets in India based on RSDM, and the gold monetization scheme in the\nUnited States. Finally, the demand for RSDM with precious metals as collateral\nwas analyzed, providing theoretical support for establishing a sound parallel\nmonetary system based on RSDM.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u8d4e\u56de\u81ea\u8870\u51cf/\u8d2c\u503c\u8d27\u5e01(RSDM)\u7684\u5e73\u884c\u8d27\u5e01\u7cfb\u7edf\uff0c\u65e8\u5728\u89e3\u51b3\u6cd5\u5b9a\u8d27\u5e01\u8fc7\u5ea6\u53d1\u884c\u7684\u95ee\u9898\uff0c\u5e76\u4e3a\u8d22\u5bcc\u63d0\u4f9b\u7ec8\u6781\u907f\u98ce\u6e2f\u3002", "motivation": "\u7531\u4e8e\u5e03\u96f7\u987f\u68ee\u6797\u4f53\u7cfb\u5d29\u6e83\u540e\uff0c\u56fd\u9645\u793e\u4f1a\u666e\u904d\u5b58\u5728\u53d1\u884c\u5ec9\u4ef7\u8d27\u5e01\u7684\u8d8b\u52bf\uff0c\u7a33\u5b9a\u5e01\u7684\u5408\u6cd5\u5316\u548c\u8fc7\u5ea6\u53d1\u884c\u52a0\u5267\u4e86\u8fd9\u4e00\u8d8b\u52bf\u3002\u7814\u7a76\u65e8\u5728\u5bfb\u627e\u80fd\u591f\u63d0\u4f9b\u957f\u671f\u4ef7\u503c\u5b58\u50a8\u548c\u96f6\u7269\u6d41\u6210\u672c\u7684\u73b0\u4ee3\"\u826f\u5e01\"\u3002", "method": "\u63d0\u51faRSDM\u6982\u5ff5\uff0c\u6307\u51fa\u53ea\u6709\u5f53\u9762\u503c\u81ea\u8870\u51cf\u5e76\u80fd\u8865\u507f\u5b9e\u7269\u9ec4\u91d1\u5b58\u50a8\u6210\u672c\u65f6\u624d\u80fd\u5b9e\u73b0\u53ef\u5151\u6362\u6027\u3002\u6784\u5efa\u4e86\u591a\u8d27\u5e01\u6c60\u4e2d\u8d27\u5e01\u4f18\u5316\u9009\u62e9\u7684\u6574\u6570\u89c4\u5212\u6a21\u578b\uff0c\u5e76\u8ba8\u8bba\u4e86RSDM\u5728\u5370\u5ea6\u548c\u7f8e\u56fd\u7b49\u5730\u7684\u6f5c\u5728\u5e94\u7528\u573a\u666f\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5355\u4e00\u8d27\u5e01\u96be\u4ee5\u627f\u62c5\u73b0\u4ee3\"\u826f\u5e01\"\u7684\u8d23\u4efb\uff0c\u53ea\u6709\u5305\u542bRSDM\u7684\u5e73\u884c\u8d27\u5e01\u7cfb\u7edf\uff08\u5982RSDM\u3001\u56fd\u5185\u6cd5\u5b9a\u8d27\u5e01\u548c\u4e3b\u8981\u56fd\u9645\u50a8\u5907\u8d27\u5e01\u7ec4\u6210\u7684\u4e09\u91cd\u8d27\u5e01\u7cfb\u7edf\uff09\u624d\u80fd\u5f62\u6210\u8d22\u5bcc\u7684\u7ec8\u6781\u907f\u98ce\u6e2f\u5e76\u4fdd\u969c\u9006\u5411\u683c\u96f7\u6b23\u6cd5\u5219\u3002", "conclusion": "RSDM\u4ee5\u8d35\u91d1\u5c5e\u4f5c\u4e3a\u62b5\u62bc\u7684\u9700\u6c42\u5206\u6790\u4e3a\u5efa\u7acb\u5065\u5168\u7684\u57fa\u4e8eRSDM\u7684\u5e73\u884c\u8d27\u5e01\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u8fd9\u79cd\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u6cd5\u5b9a\u8d27\u5e01\u8fc7\u5ea6\u53d1\u884c\u7684\u95ee\u9898\u3002"}}
{"id": "2511.00242", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.00242", "abs": "https://arxiv.org/abs/2511.00242", "authors": ["Arne Burdack", "Maximilian Stargardt", "Christoph Winkler", "Konrad Klein", "Detlef Stolten", "Jochen Linssen", "Heidi Heinrichs"], "title": "Which Top Energy-Intensive Manufacturing Countries Can Compete in a Renewable Energy Future?", "comment": "29 pages, 16 figures", "summary": "In a world increasingly powered by renewables and aiming for greenhouse\ngas-neutral industrial production, the future competitiveness of todays top\nmanufacturing countries is questioned. This study applies detailed energy\nsystem modeling to quantify the Renewable Pull, an incentive for industry\nrelocation exerted by countries with favorable renewable conditions. Results\nreveal that the Renewable Pull is not a cross-industrial phenomenon but\nstrongly depends on the relationship between energy costs and transport costs.\nThe intensity of the Renewable Pull varies, with China, India, and Japan facing\na significantly stronger effect than Germany and the United States.\nIncorporating national capital cost assumptions proves critical, reducing\nGermanys Renewable Pull by a factor of six and positioning it as the second\nleast affected top manufacturing country after Saudi Arabia. Using Germany as a\ncase study, the analysis moreover illustrates that targeted import strategies,\nespecially within the EU, can nearly eliminate the Renewable Pull, offering\npolicymakers clear options for risk mitigation.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u80fd\u6e90\u7cfb\u7edf\u5efa\u6a21\u91cf\u5316\u4e86\u53ef\u518d\u751f\u80fd\u6e90\u6761\u4ef6\u4f18\u8d8a\u56fd\u5bb6\u4ea7\u751f\u7684\"\u53ef\u518d\u751f\u80fd\u6e90\u62c9\u529b\"\u5bf9\u4ea7\u4e1a\u8fc1\u79fb\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u8be5\u6548\u5e94\u56e0\u884c\u4e1a\u800c\u5f02\uff0c\u4e2d\u56fd\u3001\u5370\u5ea6\u548c\u65e5\u672c\u53d7\u5f71\u54cd\u6700\u5927\uff0c\u800c\u5fb7\u56fd\u548c\u7f8e\u56fd\u76f8\u5bf9\u8f83\u5c0f\u3002\u8d44\u672c\u6210\u672c\u5047\u8bbe\u5bf9\u7ed3\u679c\u5f71\u54cd\u663e\u8457\uff0c\u5fb7\u56fd\u901a\u8fc7\u6b27\u76df\u5185\u9488\u5bf9\u6027\u8fdb\u53e3\u7b56\u7565\u53ef\u51e0\u4e4e\u6d88\u9664\u8fd9\u79cd\u62c9\u529b\u3002", "motivation": "\u5728\u53ef\u518d\u751f\u80fd\u6e90\u65e5\u76ca\u666e\u53ca\u548c\u6e29\u5ba4\u6c14\u4f53\u4e2d\u548c\u5de5\u4e1a\u751f\u4ea7\u7684\u80cc\u666f\u4e0b\uff0c\u7814\u7a76\u5f53\u524d\u4e3b\u8981\u5236\u9020\u4e1a\u56fd\u5bb6\u672a\u6765\u7ade\u4e89\u529b\u5982\u4f55\u53d7\u5230\u53ef\u518d\u751f\u80fd\u6e90\u6761\u4ef6\u5dee\u5f02\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u8be6\u7ec6\u7684\u80fd\u6e90\u7cfb\u7edf\u5efa\u6a21\u65b9\u6cd5\uff0c\u91cf\u5316\u5206\u6790\u4e0d\u540c\u56fd\u5bb6\u53ef\u518d\u751f\u80fd\u6e90\u6761\u4ef6\u5bf9\u4ea7\u4e1a\u8fc1\u79fb\u7684\u6fc0\u52b1\u6548\u5e94\uff08\u5373\"\u53ef\u518d\u751f\u80fd\u6e90\u62c9\u529b\"\uff09\u3002", "result": "\u53ef\u518d\u751f\u80fd\u6e90\u62c9\u529b\u4e0d\u662f\u8de8\u884c\u4e1a\u73b0\u8c61\uff0c\u800c\u662f\u53d6\u51b3\u4e8e\u80fd\u6e90\u6210\u672c\u4e0e\u8fd0\u8f93\u6210\u672c\u7684\u5173\u7cfb\u3002\u4e2d\u56fd\u3001\u5370\u5ea6\u548c\u65e5\u672c\u9762\u4e34\u7684\u5f71\u54cd\u663e\u8457\u5f3a\u4e8e\u5fb7\u56fd\u548c\u7f8e\u56fd\u3002\u8003\u8651\u56fd\u5bb6\u8d44\u672c\u6210\u672c\u5047\u8bbe\u540e\uff0c\u5fb7\u56fd\u7684\u53ef\u518d\u751f\u80fd\u6e90\u62c9\u529b\u51cf\u5c11\u4e86\u516d\u500d\uff0c\u6210\u4e3a\u4ec5\u6b21\u4e8e\u6c99\u7279\u963f\u62c9\u4f2f\u53d7\u5f71\u54cd\u6700\u5c0f\u7684\u5236\u9020\u4e1a\u5927\u56fd\u3002", "conclusion": "\u901a\u8fc7\u9488\u5bf9\u6027\u8fdb\u53e3\u7b56\u7565\uff08\u7279\u522b\u662f\u5728\u6b27\u76df\u5185\u90e8\uff09\uff0c\u53ef\u4ee5\u51e0\u4e4e\u6d88\u9664\u53ef\u518d\u751f\u80fd\u6e90\u62c9\u529b\uff0c\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u660e\u786e\u7684\u98ce\u9669\u7f13\u89e3\u65b9\u6848\u3002"}}
{"id": "2511.00316", "categories": ["cs.ET", "cs.AR"], "pdf": "https://arxiv.org/pdf/2511.00316", "abs": "https://arxiv.org/abs/2511.00316", "authors": ["Khakim Akhunov", "Eren Yildiz", "Kasim Sinan Yildirim"], "title": "PEARL: Power- and Energy-Aware Multicore Intermittent Computing", "comment": "Presented at EWSN 2025 (THE 22ND INTERNATIONAL CONFERENCE ON EMBEDDED\n  WIRELESS SYSTEMS AND NETWORKS)", "summary": "Low-power multicore platforms are suitable for running data-intensive tasks\nin parallel, but they are highly inefficient for computing on intermittent\npower. In this work, we present PEARL (PowEr And eneRgy-aware MuLticore\nIntermittent Computing), a novel systems support that can make existing\nmulticore microcontroller (MCU) platforms suitable for efficient intermittent\ncomputing. PEARL achieves this by leveraging only a three-threshold voltage\ntracking circuit and an external fast non-volatile memory, which multicore MCUs\ncan smoothly interface. PEARL software runtime manages these components and\nperforms energy- and power-aware adaptation of the multicore configuration to\nintroduce minimal backup overheads and boost performance. Our evaluation shows\nthat PEARL outperforms the state-of-the-art solutions by up to 30x and consumes\nup to 32x less energy.", "AI": {"tldr": "PEARL\u662f\u4e00\u79cd\u652f\u6301\u591a\u6838\u5fae\u63a7\u5236\u5668\u5728\u95f4\u6b47\u4f9b\u7535\u73af\u5883\u4e0b\u9ad8\u6548\u8ba1\u7b97\u7684\u7cfb\u7edf\u65b9\u6848\uff0c\u901a\u8fc7\u4e09\u9608\u503c\u7535\u538b\u8ddf\u8e2a\u7535\u8def\u548c\u5916\u90e8\u5feb\u901f\u975e\u6613\u5931\u6027\u5185\u5b58\u5b9e\u73b0\uff0c\u6027\u80fd\u63d0\u534730\u500d\uff0c\u80fd\u8017\u964d\u4f4e32\u500d\u3002", "motivation": "\u4f4e\u529f\u8017\u591a\u6838\u5e73\u53f0\u9002\u5408\u5e76\u884c\u5904\u7406\u6570\u636e\u5bc6\u96c6\u578b\u4efb\u52a1\uff0c\u4f46\u5728\u95f4\u6b47\u4f9b\u7535\u73af\u5883\u4e0b\u6548\u7387\u6781\u4f4e\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5229\u7528\u4e09\u9608\u503c\u7535\u538b\u8ddf\u8e2a\u7535\u8def\u548c\u5916\u90e8\u5feb\u901f\u975e\u6613\u5931\u6027\u5185\u5b58\uff0c\u901a\u8fc7\u8f6f\u4ef6\u8fd0\u884c\u65f6\u7ba1\u7406\u8fd9\u4e9b\u7ec4\u4ef6\uff0c\u5b9e\u73b0\u80fd\u91cf\u548c\u529f\u7387\u611f\u77e5\u7684\u591a\u6838\u914d\u7f6e\u81ea\u9002\u5e94\u8c03\u6574\u3002", "result": "PEARL\u76f8\u6bd4\u73b0\u6709\u6700\u4f18\u89e3\u51b3\u65b9\u6848\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe30\u500d\uff0c\u80fd\u8017\u964d\u4f4e\u9ad8\u8fbe32\u500d\u3002", "conclusion": "PEARL\u4f7f\u73b0\u6709\u591a\u6838\u5fae\u63a7\u5236\u5668\u5e73\u53f0\u80fd\u591f\u9ad8\u6548\u8fdb\u884c\u95f4\u6b47\u8ba1\u7b97\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u80fd\u6548\u3002"}}
{"id": "2511.00004", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00004", "abs": "https://arxiv.org/abs/2511.00004", "authors": ["Adrian-Dinu Urse", "Dumitru-Clementin Cercel", "Florin Pop"], "title": "Multimodal Learning with Augmentation Techniques for Natural Disaster Assessment", "comment": "Accepted at 2025 IEEE 21st International Conference on Intelligent\n  Computer Communication and Processing (ICCP 2025)", "summary": "Natural disaster assessment relies on accurate and rapid access to\ninformation, with social media emerging as a valuable real-time source.\nHowever, existing datasets suffer from class imbalance and limited samples,\nmaking effective model development a challenging task. This paper explores\naugmentation techniques to address these issues on the CrisisMMD multimodal\ndataset. For visual data, we apply diffusion-based methods, namely Real\nGuidance and DiffuseMix. For text data, we explore back-translation,\nparaphrasing with transformers, and image caption-based augmentation. We\nevaluated these across unimodal, multimodal, and multi-view learning setups.\nResults show that selected augmentations improve classification performance,\nparticularly for underrepresented classes, while multi-view learning introduces\npotential but requires further refinement. This study highlights effective\naugmentation strategies for building more robust disaster assessment systems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728CrisisMMD\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u5e94\u7528\u6570\u636e\u589e\u5f3a\u6280\u672f\u6765\u89e3\u51b3\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u6837\u672c\u6709\u9650\u7684\u95ee\u9898\uff0c\u5305\u62ec\u89c6\u89c9\u6570\u636e\u7684\u6269\u6563\u65b9\u6cd5\u548c\u6587\u672c\u6570\u636e\u7684\u591a\u79cd\u589e\u5f3a\u7b56\u7565\uff0c\u7ed3\u679c\u8868\u660e\u589e\u5f3a\u6280\u672f\u80fd\u63d0\u9ad8\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u81ea\u7136\u707e\u5bb3\u8bc4\u4f30\u9700\u8981\u51c6\u786e\u5feb\u901f\u7684\u4fe1\u606f\u83b7\u53d6\uff0c\u793e\u4ea4\u5a92\u4f53\u6210\u4e3a\u6709\u4ef7\u503c\u7684\u5b9e\u65f6\u6765\u6e90\uff0c\u4f46\u73b0\u6709\u6570\u636e\u96c6\u5b58\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u6837\u672c\u6709\u9650\u7684\u95ee\u9898\uff0c\u4f7f\u5f97\u6a21\u578b\u5f00\u53d1\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u5bf9\u4e8e\u89c6\u89c9\u6570\u636e\u5e94\u7528\u57fa\u4e8e\u6269\u6563\u7684\u65b9\u6cd5\uff08Real Guidance\u548cDiffuseMix\uff09\uff0c\u5bf9\u4e8e\u6587\u672c\u6570\u636e\u63a2\u7d22\u56de\u8bd1\u3001\u57fa\u4e8e\u53d8\u6362\u5668\u7684\u91ca\u4e49\u548c\u57fa\u4e8e\u56fe\u50cf\u63cf\u8ff0\u7684\u589e\u5f3a\uff0c\u5e76\u5728\u5355\u6a21\u6001\u3001\u591a\u6a21\u6001\u548c\u591a\u89c6\u56fe\u5b66\u4e60\u8bbe\u7f6e\u4e2d\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u663e\u793a\u9009\u5b9a\u7684\u589e\u5f3a\u6280\u672f\u63d0\u9ad8\u4e86\u5206\u7c7b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u7c7b\u522b\uff0c\u800c\u591a\u89c6\u56fe\u5b66\u4e60\u663e\u793a\u51fa\u6f5c\u529b\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002", "conclusion": "\u672c\u7814\u7a76\u5f3a\u8c03\u4e86\u6784\u5efa\u66f4\u9c81\u68d2\u7684\u81ea\u7136\u707e\u5bb3\u8bc4\u4f30\u7cfb\u7edf\u7684\u6709\u6548\u589e\u5f3a\u7b56\u7565\u3002"}}
{"id": "2511.00132", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.00132", "abs": "https://arxiv.org/abs/2511.00132", "authors": ["Felipe E. Sanchez", "Thomas A. Lake", "Jason A. Galvis", "Chris Jones", "Gustavo Machado"], "title": "Predicting the spatial distribution and demographics of commercial swine farms in the United States", "comment": null, "summary": "Data on livestock farm locations and demographics are essential for disease\nmonitoring, risk assessment, and developing spatially explicit epidemiological\nmodels. Our semantic segmentation model achieved an F2 score of 92 % and a mean\nIntersection over Union of 76 %. An initial total of 194,474 swine barn\ncandidates were identified in the Southeast (North Carolina = 111,135, South\nCarolina = 37,264 Virginia = 46,075) and 524,962 in the Midwest (Iowa = 168,866\nMinnesota = 165,714 Ohio = 190,382). The post processing Random Forest\nclassifier reduced false positives by 82 % in the Southeast and 88 % in the\nMidwest, resulting in 45,580 confirmed barn polygons. These were grouped into\n16,976 predicted farms and classified into one of the four production types.\nPopulation sizes were then estimated using the Random Forest regression model,\nwith prediction accuracy varying by production type. Across all farms, 87 % of\npredictions for operations with 1,000 2,000 pigs were within 500 pigs of the\nreference value, with nursery farms showing the highest agreement (R2= 0.82),\nfollowed by finisher farms (R2 = 0.77) and sow farms (R2 = 0.56). Our results\nrevealed substantial gaps in the existing spatial and demographic data on U.S.\nswine production.", "AI": {"tldr": "\u4f7f\u7528\u8bed\u4e49\u5206\u5272\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u8bc6\u522b\u7f8e\u56fd\u4e1c\u5357\u90e8\u548c\u4e2d\u897f\u90e8\u5730\u533a\u7684\u732a\u573a\u4f4d\u7f6e\u3001\u7c7b\u578b\u548c\u89c4\u6a21\uff0c\u586b\u8865\u73b0\u6709\u7a7a\u95f4\u548c\u4eba\u53e3\u6570\u636e\u7684\u7a7a\u767d\u3002", "motivation": "\u83b7\u53d6\u51c6\u786e\u7684\u7272\u755c\u517b\u6b96\u573a\u4f4d\u7f6e\u548c\u4eba\u53e3\u7edf\u8ba1\u6570\u636e\u5bf9\u4e8e\u75be\u75c5\u76d1\u6d4b\u3001\u98ce\u9669\u8bc4\u4f30\u548c\u7a7a\u95f4\u6d41\u884c\u75c5\u5b66\u6a21\u578b\u5f00\u53d1\u81f3\u5173\u91cd\u8981\u3002", "method": "\u91c7\u7528\u8bed\u4e49\u5206\u5272\u6a21\u578b\u8bc6\u522b\u732a\u820d\u5019\u9009\u70b9\uff0c\u7136\u540e\u4f7f\u7528\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u51cf\u5c11\u8bef\u62a5\uff0c\u6700\u540e\u7528\u968f\u673a\u68ee\u6797\u56de\u5f52\u6a21\u578b\u4f30\u8ba1\u79cd\u7fa4\u89c4\u6a21\u3002", "result": "\u6a21\u578b\u5728\u4e1c\u5357\u90e8\u548c\u4e2d\u897f\u90e8\u8bc6\u522b\u51fa45,580\u4e2a\u786e\u8ba4\u7684\u732a\u820d\u591a\u8fb9\u5f62\uff0c\u5206\u4e3a16,976\u4e2a\u9884\u6d4b\u519c\u573a\uff0c\u5e76\u6309\u56db\u79cd\u751f\u4ea7\u7c7b\u578b\u5206\u7c7b\u3002\u79cd\u7fa4\u89c4\u6a21\u9884\u6d4b\u51c6\u786e\u7387\u56e0\u751f\u4ea7\u7c7b\u578b\u800c\u5f02\uff0c87%\u7684\u9884\u6d4b\u5728\u53c2\u8003\u503c500\u5934\u8303\u56f4\u5185\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u7f8e\u56fd\u751f\u732a\u751f\u4ea7\u73b0\u6709\u7a7a\u95f4\u548c\u4eba\u53e3\u6570\u636e\u7684\u91cd\u5927\u7a7a\u767d\uff0c\u4e3a\u75be\u75c5\u76d1\u6d4b\u548c\u98ce\u9669\u8bc4\u4f30\u63d0\u4f9b\u4e86\u91cd\u8981\u6570\u636e\u652f\u6301\u3002"}}
{"id": "2511.00020", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00020", "abs": "https://arxiv.org/abs/2511.00020", "authors": ["Suhasnadh Reddy Veluru", "Sai Teja Erukude", "Viswa Chaitanya Marella"], "title": "Multimodal Detection of Fake Reviews using BERT and ResNet-50", "comment": "Published in IEEE", "summary": "In the current digital commerce landscape, user-generated reviews play a\ncritical role in shaping consumer behavior, product reputation, and platform\ncredibility. However, the proliferation of fake or misleading reviews often\ngenerated by bots, paid agents, or AI models poses a significant threat to\ntrust and transparency within review ecosystems. Existing detection models\nprimarily rely on unimodal, typically textual, data and therefore fail to\ncapture semantic inconsistencies across different modalities. To address this\ngap, a robust multimodal fake review detection framework is proposed,\nintegrating textual features encoded with BERT and visual features extracted\nusing ResNet-50. These representations are fused through a classification head\nto jointly predict review authenticity. To support this approach, a curated\ndataset comprising 21,142 user-uploaded images across food delivery,\nhospitality, and e-commerce domains was utilized. Experimental results indicate\nthat the multimodal model outperforms unimodal baselines, achieving an F1-score\nof 0.934 on the test set. Additionally, the confusion matrix and qualitative\nanalysis highlight the model's ability to detect subtle inconsistencies, such\nas exaggerated textual praise paired with unrelated or low-quality images,\ncommonly found in deceptive content. This study demonstrates the critical role\nof multimodal learning in safeguarding digital trust and offers a scalable\nsolution for content moderation across various online platforms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u878d\u5408\u6587\u672c\u548c\u89c6\u89c9\u7279\u5f81\u7684\u591a\u6a21\u6001\u865a\u5047\u8bc4\u8bba\u68c0\u6d4b\u6846\u67b6\uff0c\u5728\u5305\u542b21,142\u5f20\u7528\u6237\u4e0a\u4f20\u56fe\u7247\u7684\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e860.934\u7684F1\u5206\u6570\uff0c\u4f18\u4e8e\u5355\u6a21\u6001\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u6570\u5b57\u5546\u52a1\u4e2d\u865a\u5047\u8bc4\u8bba\u6cdb\u6ee5\uff0c\u73b0\u6709\u68c0\u6d4b\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u5355\u6a21\u6001\u6587\u672c\u6570\u636e\uff0c\u65e0\u6cd5\u6355\u6349\u8de8\u6a21\u6001\u7684\u8bed\u4e49\u4e0d\u4e00\u81f4\u6027\uff0c\u5a01\u80c1\u8bc4\u8bba\u751f\u6001\u7cfb\u7edf\u7684\u4fe1\u4efb\u548c\u900f\u660e\u5ea6\u3002", "method": "\u4f7f\u7528BERT\u7f16\u7801\u6587\u672c\u7279\u5f81\uff0cResNet-50\u63d0\u53d6\u89c6\u89c9\u7279\u5f81\uff0c\u901a\u8fc7\u5206\u7c7b\u5934\u878d\u5408\u591a\u6a21\u6001\u8868\u793a\u6765\u8054\u5408\u9884\u6d4b\u8bc4\u8bba\u771f\u5b9e\u6027\u3002", "result": "\u591a\u6a21\u6001\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0aF1\u5206\u6570\u8fbe\u52300.934\uff0c\u4f18\u4e8e\u5355\u6a21\u6001\u57fa\u7ebf\uff0c\u80fd\u591f\u68c0\u6d4b\u6587\u672c\u8d5e\u7f8e\u4e0e\u4e0d\u76f8\u5173\u6216\u4f4e\u8d28\u91cf\u56fe\u50cf\u4e4b\u95f4\u7684\u5fae\u5999\u4e0d\u4e00\u81f4\u6027\u3002", "conclusion": "\u591a\u6a21\u6001\u5b66\u4e60\u5728\u4fdd\u62a4\u6570\u5b57\u4fe1\u4efb\u65b9\u9762\u53d1\u6325\u5173\u952e\u4f5c\u7528\uff0c\u4e3a\u5404\u5728\u7ebf\u5e73\u53f0\u7684\u5185\u5bb9\u5ba1\u6838\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00026", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00026", "abs": "https://arxiv.org/abs/2511.00026", "authors": ["Chaitanya Shinde", "Divya Garikapati"], "title": "Gen AI in Automotive: Applications, Challenges, and Opportunities with a Case study on In-Vehicle Experience", "comment": null, "summary": "Generative Artificial Intelligence is emerging as a transformative force in\nthe automotive industry, enabling novel applications across vehicle design,\nmanufacturing, autonomous driving, predictive maintenance, and in vehicle user\nexperience. This paper provides a comprehensive review of the current state of\nGenAI in automotive, highlighting enabling technologies such as Generative\nAdversarial Networks and Variational Autoencoders. Key opportunities include\naccelerating autonomous driving validation through synthetic data generation,\noptimizing component design, and enhancing human machine interaction via\npersonalized and adaptive interfaces. At the same time, the paper identifies\nsignificant technical, ethical, and safety challenges, including computational\ndemands, bias, intellectual property concerns, and adversarial robustness, that\nmust be addressed for responsible deployment. A case study on Mercedes Benzs\nMBUX Virtual Assistant illustrates how GenAI powered voice systems deliver more\nnatural, proactive, and personalized in car interactions compared to legacy\nrule based assistants. Through this review and case study, the paper outlines\nboth the promise and limitations of GenAI integration in the automotive sector\nand presents directions for future research and development aimed at achieving\nsafer, more efficient, and user centric mobility. Unlike prior reviews that\nfocus solely on perception or manufacturing, this paper emphasizes generative\nAI in voice based HMI, bridging safety and user experience perspectives.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u751f\u6210\u5f0fAI\u5728\u6c7d\u8f66\u884c\u4e1a\u7684\u5e94\u7528\u73b0\u72b6\uff0c\u91cd\u70b9\u5173\u6ce8\u5176\u5728\u8f66\u8f86\u8bbe\u8ba1\u3001\u5236\u9020\u3001\u81ea\u52a8\u9a7e\u9a76\u3001\u9884\u6d4b\u6027\u7ef4\u62a4\u548c\u8f66\u8f7d\u7528\u6237\u4f53\u9a8c\u7b49\u9886\u57df\u7684\u53d8\u9769\u6027\u6f5c\u529b\uff0c\u540c\u65f6\u5206\u6790\u4e86\u76f8\u5173\u6280\u672f\u6311\u6218\u548c\u4f26\u7406\u95ee\u9898\u3002", "motivation": "\u751f\u6210\u5f0fAI\u6b63\u5728\u6210\u4e3a\u6c7d\u8f66\u884c\u4e1a\u7684\u53d8\u9769\u529b\u91cf\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u591a\u96c6\u4e2d\u4e8e\u611f\u77e5\u6216\u5236\u9020\u9886\u57df\uff0c\u7f3a\u4e4f\u5bf9\u57fa\u4e8e\u8bed\u97f3\u7684\u4eba\u673a\u4ea4\u4e92\u7b49\u7efc\u5408\u5e94\u7528\u7684\u7cfb\u7edf\u6027\u5206\u6790\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u6587\u732e\u7efc\u8ff0\u548c\u6848\u4f8b\u7814\u7a76\u65b9\u6cd5\uff0c\u5206\u6790\u751f\u6210\u5f0f\u5bf9\u6297\u7f51\u7edc\u548c\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7b49\u5173\u952e\u6280\u672f\uff0c\u5e76\u4ee5\u6885\u8d5b\u5fb7\u65af-\u5954\u9a70MBUX\u865a\u62df\u52a9\u624b\u4e3a\u4f8b\u8fdb\u884c\u6df1\u5165\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u751f\u6210\u5f0fAI\u80fd\u591f\u901a\u8fc7\u5408\u6210\u6570\u636e\u751f\u6210\u52a0\u901f\u81ea\u52a8\u9a7e\u9a76\u9a8c\u8bc1\u3001\u4f18\u5316\u96f6\u90e8\u4ef6\u8bbe\u8ba1\uff0c\u5e76\u5b9e\u73b0\u66f4\u81ea\u7136\u3001\u4e3b\u52a8\u548c\u4e2a\u6027\u5316\u7684\u8f66\u8f7d\u4ea4\u4e92\u4f53\u9a8c\u3002\u6885\u8d5b\u5fb7\u65af\u6848\u4f8b\u663e\u793a\u5176\u8bed\u97f3\u7cfb\u7edf\u76f8\u6bd4\u4f20\u7edf\u89c4\u5219\u7cfb\u7edf\u6709\u660e\u663e\u4f18\u52bf\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5728\u6c7d\u8f66\u9886\u57df\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u89e3\u51b3\u8ba1\u7b97\u9700\u6c42\u3001\u504f\u89c1\u3001\u77e5\u8bc6\u4ea7\u6743\u548c\u5bf9\u6297\u9c81\u68d2\u6027\u7b49\u6311\u6218\u3002\u672a\u6765\u7814\u7a76\u5e94\u81f4\u529b\u4e8e\u5b9e\u73b0\u66f4\u5b89\u5168\u3001\u9ad8\u6548\u548c\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u79fb\u52a8\u51fa\u884c\u3002"}}
{"id": "2511.01271", "categories": ["econ.EM", "q-fin.PR", "q-fin.ST"], "pdf": "https://arxiv.org/pdf/2511.01271", "abs": "https://arxiv.org/abs/2511.01271", "authors": ["Zhaoxing Gao", "Sihan Tu", "Ruey S. Tsay"], "title": "High-Dimensional Spatial Arbitrage Pricing Theory with Heterogeneous Interactions", "comment": "48 pages, 8 figures", "summary": "This paper investigates estimation and inference of a Spatial Arbitrage\nPricing Theory (SAPT) model that integrates spatial interactions with\nmulti-factor analysis, accommodating both observable and latent factors.\nBuilding on the classical mean-variance analysis, we introduce a class of\nSpatial Capital Asset Pricing Models (SCAPM) that account for spatial effects\nin high-dimensional assets, where we define {\\it spatial rho} as a counterpart\nto market beta in CAPM. We then extend SCAPM to a general SAPT framework under\na {\\it complete} market setting by incorporating multiple factors. For SAPT\nwith observable factors, we propose a generalized shrinkage Yule-Walker (SYW)\nestimation method that integrates ridge regression to estimate spatial and\nfactor coefficients. When factors are latent, we first apply an\nautocovariance-based eigenanalysis to extract factors, then employ the SYW\nmethod using the estimated factors. We establish asymptotic properties for\nthese estimators under high-dimensional settings where both the dimension and\nsample size diverge. Finally, we use simulated and real data examples to\ndemonstrate the efficacy and usefulness of the proposed model and method.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7a7a\u95f4\u5957\u5229\u5b9a\u4ef7\u7406\u8bba(SAPT)\u6a21\u578b\uff0c\u5c06\u7a7a\u95f4\u4ea4\u4e92\u4e0e\u591a\u56e0\u5b50\u5206\u6790\u76f8\u7ed3\u5408\uff0c\u5904\u7406\u53ef\u89c2\u6d4b\u548c\u6f5c\u5728\u56e0\u5b50\u3002\u5f00\u53d1\u4e86\u7a7a\u95f4\u8d44\u672c\u8d44\u4ea7\u5b9a\u4ef7\u6a21\u578b(SCAPM)\u548c\u5e7f\u4e49SAPT\u6846\u67b6\uff0c\u63d0\u51fa\u4e86\u5e7f\u4e49\u6536\u7f29Yule-Walker\u4f30\u8ba1\u65b9\u6cd5\u3002", "motivation": "\u5c06\u7a7a\u95f4\u4ea4\u4e92\u6548\u5e94\u6574\u5408\u5230\u591a\u56e0\u5b50\u8d44\u4ea7\u5b9a\u4ef7\u6a21\u578b\u4e2d\uff0c\u89e3\u51b3\u9ad8\u7ef4\u8d44\u4ea7\u4e2d\u7684\u7a7a\u95f4\u4f9d\u8d56\u6027\u95ee\u9898\uff0c\u6269\u5c55\u4f20\u7edf\u7684\u8d44\u672c\u8d44\u4ea7\u5b9a\u4ef7\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86SCAPM\u6a21\u578b\u548cSAPT\u6846\u67b6\uff1b\u5bf9\u4e8e\u53ef\u89c2\u6d4b\u56e0\u5b50\u4f7f\u7528\u5e7f\u4e49\u6536\u7f29Yule-Walker\u4f30\u8ba1\u65b9\u6cd5\uff1b\u5bf9\u4e8e\u6f5c\u5728\u56e0\u5b50\u5148\u901a\u8fc7\u81ea\u534f\u65b9\u5dee\u7279\u5f81\u5206\u6790\u63d0\u53d6\u56e0\u5b50\uff0c\u518d\u4f7f\u7528SYW\u65b9\u6cd5\uff1b\u5efa\u7acb\u4e86\u9ad8\u7ef4\u8bbe\u5b9a\u4e0b\u7684\u6e10\u8fd1\u6027\u8d28\u3002", "result": "\u5efa\u7acb\u4e86\u7a7a\u95f4rho\u4f5c\u4e3aCAPM\u4e2d\u5e02\u573abeta\u7684\u5bf9\u5e94\u6982\u5ff5\uff1b\u5f00\u53d1\u4e86\u6709\u6548\u7684\u4f30\u8ba1\u65b9\u6cd5\uff1b\u901a\u8fc7\u6a21\u62df\u548c\u5b9e\u9645\u6570\u636e\u9a8c\u8bc1\u4e86\u6a21\u578b\u548c\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684SAPT\u6a21\u578b\u548c\u4f30\u8ba1\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u9ad8\u7ef4\u8d44\u4ea7\u4e2d\u7684\u7a7a\u95f4\u4ea4\u4e92\u6548\u5e94\uff0c\u4e3a\u7a7a\u95f4\u91d1\u878d\u5206\u6790\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2511.00374", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2511.00374", "abs": "https://arxiv.org/abs/2511.00374", "authors": ["Itai Maimon"], "title": "Different Forms of Imbalance in Strongly Playable Discrete Games I: Two-Player RPS Games", "comment": null, "summary": "We construct several definitions of imbalance and playability, both of which\nare related to the existence of dominated strategies. Specifically, a maximally\nbalanced game and a playable game cannot have dominated strategies for any\nplayer. In this context, imbalance acts as a measure of inequality in strategy,\nsimilar to measures of inequality in wealth or population dynamics. Conversely,\nplayability is a slight strengthening of the condition that a game has no\ndominated strategies. It is more accurately aligned with the intuition that all\nstrategies should see play. We show that these balance definitions are natural\nby exhibiting a (2n+1)-RPS that maximizes all proposed imbalance definitions\namong playable RPS games. We demonstrate here that this form of imbalance\naligns with the prevailing notion that different definitions of inequality for\neconomic and game-theoretic distributions must agree on both the maximal and\nminimal cases. In the sequel paper, we utilize these definitions for\nmultiplayer games to demonstrate that a generalization of this imbalanced RPS\nis at least nearly maximally imbalanced while remaining playable for under 50\nplayers.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u535a\u5f08\u4e2d\u4e0d\u5e73\u8861\u6027\u548c\u53ef\u73a9\u6027\u7684\u5b9a\u4e49\uff0c\u8bc1\u660e(2n+1)-RPS\u5728\u53ef\u73a9RPS\u6e38\u620f\u4e2d\u6700\u5927\u5316\u6240\u6709\u4e0d\u5e73\u8861\u6027\u5b9a\u4e49\uff0c\u5e76\u5c55\u793a\u4e0d\u5e73\u8861\u6027\u6982\u5ff5\u4e0e\u7ecf\u6d4e\u5b66\u4e2d\u4e0d\u5e73\u7b49\u5ea6\u91cf\u7684\u4e00\u81f4\u6027\u3002", "motivation": "\u7814\u7a76\u535a\u5f08\u4e2d\u7684\u4e0d\u5e73\u8861\u6027\u548c\u53ef\u73a9\u6027\uff0c\u8fd9\u4e9b\u6982\u5ff5\u4e0e\u652f\u914d\u7b56\u7565\u7684\u5b58\u5728\u76f8\u5173\uff0c\u65e8\u5728\u5efa\u7acb\u4e0e\u7ecf\u6d4e\u5b66\u4e2d\u4e0d\u5e73\u7b49\u5ea6\u91cf\u7c7b\u4f3c\u7684\u5206\u6790\u6846\u67b6\u3002", "method": "\u6784\u5efa\u4e0d\u5e73\u8861\u6027\u548c\u53ef\u73a9\u6027\u7684\u5b9a\u4e49\uff0c\u901a\u8fc7(2n+1)-RPS\u6848\u4f8b\u5c55\u793a\u8fd9\u4e9b\u5b9a\u4e49\u7684\u81ea\u7136\u6027\uff0c\u5e76\u9a8c\u8bc1\u4e0d\u540c\u4e0d\u5e73\u7b49\u5b9a\u4e49\u5728\u6781\u503c\u60c5\u51b5\u4e0b\u7684\u4e00\u81f4\u6027\u3002", "result": "(2n+1)-RPS\u5728\u6240\u6709\u53ef\u73a9RPS\u6e38\u620f\u4e2d\u6700\u5927\u5316\u4e0d\u5e73\u8861\u6027\u5b9a\u4e49\uff0c\u4e14\u4e0d\u5e73\u8861\u6027\u6982\u5ff5\u4e0e\u7ecf\u6d4e\u4e0d\u5e73\u7b49\u5ea6\u91cf\u5728\u6781\u503c\u60c5\u51b5\u4e0b\u4fdd\u6301\u4e00\u81f4\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e0d\u5e73\u8861\u6027\u548c\u53ef\u73a9\u6027\u5b9a\u4e49\u662f\u81ea\u7136\u7684\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u591a\u4eba\u535a\u5f08\u4e2d\u7684\u4e0d\u5e73\u8861\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u8bc1\u660e\u5e7f\u4e49\u5316\u7684\u4e0d\u5e73\u8861RPS\u572850\u4eba\u4ee5\u4e0b\u4ecd\u4fdd\u6301\u8fd1\u6700\u5927\u4e0d\u5e73\u8861\u6027\u4e14\u53ef\u73a9\u3002"}}
{"id": "2511.00068", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2511.00068", "abs": "https://arxiv.org/abs/2511.00068", "authors": ["Shaohui Wang"], "title": "Hope, Signals, and Silicon: A Game-Theoretic Model of the Pre-Doctoral Academic Labor Market in the Age of AI", "comment": "v0.1, Early working draft; substantial revisions expected", "summary": "This paper develops a unified game-theoretic account of how generative AI\nreshapes the pre-doctoral \"hope-labor\" market linking Principal Investigators\n(PIs), Research Assistants (RAs), and PhD admissions. We integrate (i) a PI-RA\nrelational-contract stage, (ii) a task-based production technology in which AI\nis both substitute (automation) and complement (augmentation/leveling), and\n(iii) a capacity-constrained admissions tournament that converts absolute\noutput into relative rank. The model yields four results. First, AI has a dual\nand thresholded effect on RA demand: when automation dominates, AI substitutes\nfor RA labor; when augmentation dominates, small elite teams become more\nvaluable. Second, heterogeneous PI objectives endogenously segment the RA\nmarket: quantity-maximizing PIs adopt automation and scale \"project-manager\"\nRAs, whereas quality-maximizing PIs adopt augmentation and cultivate\n\"idea-generator\" RAs. Third, a symmetric productivity shock triggers a\nsignaling arms race: more \"strong\" signals flood a fixed-slot tournament,\ndepressing the admission probability attached to any given signal and\npotentially lowering RA welfare despite higher productivity. Fourth, AI\ndegrades the informational content of polished routine artifacts, creating a\nnovel moral-hazard channel (\"effort laundering\") that shifts credible\nrecommendations toward process-visible, non-automatable creative contributions.\nWe discuss welfare and equity implications, including over-recruitment with\nthin mentoring, selectively misleading letters, and opaque pipelines, and\noutline light-touch governance (process visibility, AI-use disclosure, and\nlimited viva/replication checks) that preserves efficiency while reducing\nunethical supervision and screening practices.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u535a\u5f08\u8bba\u6a21\u578b\uff0c\u5206\u6790\u751f\u6210\u5f0fAI\u5982\u4f55\u91cd\u5851\u535a\u58eb\u524d\"\u5e0c\u671b\u52b3\u52a8\"\u5e02\u573a\uff0c\u63ed\u793a\u4e86AI\u5728\u81ea\u52a8\u5316\u4e0e\u589e\u5f3a\u529f\u80fd\u4e4b\u95f4\u7684\u53cc\u91cd\u6548\u5e94\u3001\u7814\u7a76\u52a9\u7406\u5e02\u573a\u7684\u5185\u751f\u5206\u5272\u3001\u4fe1\u53f7\u519b\u5907\u7ade\u8d5b\u4ee5\u53ca\u65b0\u578b\u9053\u5fb7\u98ce\u9669\u6e20\u9053\u3002", "motivation": "\u7814\u7a76\u751f\u6210\u5f0fAI\u5bf9\u535a\u58eb\u524d\u7814\u7a76\u751f\u6001\u7cfb\u7edf\u7684\u7cfb\u7edf\u6027\u5f71\u54cd\uff0c\u5305\u62ecPI-RA\u5173\u7cfb\u3001\u4efb\u52a1\u751f\u4ea7\u6280\u672f\u548c\u535a\u58eb\u62db\u751f\u7ade\u4e89\uff0c\u586b\u8865AI\u5bf9\u5b66\u672f\u52b3\u52a8\u529b\u5e02\u573a\u5f71\u54cd\u7684\u7406\u8bba\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u7edf\u4e00\u535a\u5f08\u8bba\u6a21\u578b\uff0c\u6574\u5408\u4e09\u4e2a\u6838\u5fc3\u8981\u7d20\uff1a(1)PI-RA\u5173\u7cfb\u5951\u7ea6\u9636\u6bb5\uff1b(2)\u57fa\u4e8e\u4efb\u52a1\u7684\u751f\u4ea7\u6280\u672f\uff0cAI\u540c\u65f6\u5177\u6709\u66ff\u4ee3\u548c\u8865\u5145\u529f\u80fd\uff1b(3)\u5bb9\u91cf\u53d7\u9650\u7684\u62db\u751f\u9526\u6807\u8d5b\uff0c\u5c06\u7edd\u5bf9\u4ea7\u51fa\u8f6c\u5316\u4e3a\u76f8\u5bf9\u6392\u540d\u3002", "result": "\u53d1\u73b0\u56db\u4e2a\u5173\u952e\u7ed3\u679c\uff1aAI\u5bf9RA\u9700\u6c42\u7684\u9608\u503c\u6548\u5e94\uff1bPI\u76ee\u6807\u5f02\u8d28\u6027\u5bfc\u81f4\u5e02\u573a\u5206\u5272\uff1b\u5bf9\u79f0\u751f\u4ea7\u529b\u51b2\u51fb\u5f15\u53d1\u4fe1\u53f7\u519b\u5907\u7ade\u8d5b\uff1bAI\u964d\u4f4e\u5e38\u89c4\u6210\u679c\u7684\u4fe1\u606f\u4ef7\u503c\uff0c\u4ea7\u751f\"\u52aa\u529b\u6d17\u94b1\"\u9053\u5fb7\u98ce\u9669\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u6df1\u523b\u6539\u53d8\u535a\u58eb\u524d\u7814\u7a76\u751f\u6001\u7cfb\u7edf\uff0c\u9700\u8981\u8f7b\u89e6\u5f0f\u6cbb\u7406\uff08\u8fc7\u7a0b\u53ef\u89c1\u6027\u3001AI\u4f7f\u7528\u62ab\u9732\u3001\u6709\u9650\u7b54\u8fa9/\u590d\u5236\u68c0\u67e5\uff09\u6765\u5e73\u8861\u6548\u7387\u4e0e\u4f26\u7406\u8003\u91cf\uff0c\u51cf\u5c11\u4e0d\u9053\u5fb7\u7684\u76d1\u7763\u548c\u7b5b\u9009\u5b9e\u8df5\u3002"}}
{"id": "2511.00339", "categories": ["cs.SI", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.00339", "abs": "https://arxiv.org/abs/2511.00339", "authors": ["Xinran Zheng", "Leonardo Massai", "Massimo Franceschetti", "Behrouz Touri"], "title": "U-centrality: A Network Centrality Measure Based on Minimum Energy Control for Laplacian Dynamics", "comment": "Accepted at the 64th IEEE Conference on Decision and Control 2025", "summary": "Network centrality is a foundational concept for quantifying the importance\nof nodes within a network. Many traditional centrality measures--such as degree\nand betweenness centrality--are purely structural and often overlook the\ndynamics that unfold across the network. However, the notion of a node's\nimportance is inherently context-dependent and must reflect both the system's\ndynamics and the specific objectives guiding its operation. Motivated by this\nperspective, we propose a dynamic, task-aware centrality framework rooted in\noptimal control theory. By formulating a problem on minimum energy control of\naverage opinion based on Laplacian dynamics and focusing on the variance of\nterminal state, we introduce a novel centrality measure--termed\nU-centrality--that quantifies a node's ability to unify the agents' state. We\ndemonstrate that U-centrality interpolates between known measures: it aligns\nwith degree centrality in the short-time horizon and converges to a new\ncentrality over longer time scales which is closely related to current-flow\ncloseness centrality. This work bridges structural and dynamical approaches to\ncentrality, offering a principled, versatile tool for network analysis in\ndynamic environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6700\u4f18\u63a7\u5236\u7406\u8bba\u7684\u52a8\u6001\u4efb\u52a1\u611f\u77e5\u4e2d\u5fc3\u6027\u6846\u67b6U-centrality\uff0c\u91cf\u5316\u8282\u70b9\u7edf\u4e00\u667a\u80fd\u4f53\u72b6\u6001\u7684\u80fd\u529b\uff0c\u5728\u77ed\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u63a5\u8fd1\u5ea6\u4e2d\u5fc3\u6027\uff0c\u5728\u957f\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u63a5\u8fd1\u7535\u6d41\u6d41\u63a5\u8fd1\u4e2d\u5fc3\u6027\u3002", "motivation": "\u4f20\u7edf\u4e2d\u5fc3\u6027\u5ea6\u91cf\uff08\u5982\u5ea6\u4e2d\u5fc3\u6027\u548c\u4e2d\u4ecb\u4e2d\u5fc3\u6027\uff09\u662f\u7eaf\u7ed3\u6784\u6027\u7684\uff0c\u5ffd\u7565\u4e86\u7f51\u7edc\u4e2d\u7684\u52a8\u6001\u8fc7\u7a0b\u3002\u8282\u70b9\u7684\u91cd\u8981\u6027\u5e94\u8be5\u662f\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\uff0c\u9700\u8981\u53cd\u6620\u7cfb\u7edf\u52a8\u6001\u548c\u7279\u5b9a\u76ee\u6807\u3002", "method": "\u57fa\u4e8e\u62c9\u666e\u62c9\u65af\u52a8\u529b\u5b66\uff0c\u6784\u5efa\u5e73\u5747\u610f\u89c1\u7684\u6700\u5c0f\u80fd\u91cf\u63a7\u5236\u95ee\u9898\uff0c\u5173\u6ce8\u7ec8\u7aef\u72b6\u6001\u7684\u65b9\u5dee\uff0c\u63d0\u51faU-centrality\u5ea6\u91cf\u3002", "result": "U-centrality\u5728\u77ed\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u4e0e\u5ea6\u4e2d\u5fc3\u6027\u4e00\u81f4\uff0c\u5728\u957f\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u6536\u655b\u5230\u4e0e\u7535\u6d41\u6d41\u63a5\u8fd1\u4e2d\u5fc3\u6027\u5bc6\u5207\u76f8\u5173\u7684\u65b0\u4e2d\u5fc3\u6027\u5ea6\u91cf\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u8fde\u63a5\u4e86\u7ed3\u6784\u548c\u52a8\u6001\u7684\u4e2d\u5fc3\u6027\u65b9\u6cd5\uff0c\u4e3a\u52a8\u6001\u73af\u5883\u4e2d\u7684\u7f51\u7edc\u5206\u6790\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u3001\u591a\u529f\u80fd\u7684\u5de5\u5177\u3002"}}
{"id": "2511.01135", "categories": ["q-fin.GN"], "pdf": "https://arxiv.org/pdf/2511.01135", "abs": "https://arxiv.org/abs/2511.01135", "authors": ["Hongzhe Wen"], "title": "How Digital Asset Treasury Companies Can Survive Bear Markets: The Case of the Strategy and Bitcoin", "comment": "19 pages, 4 figures, 1 table", "summary": "Digital Asset Treasury (DAT) companies, public firms that hold large crypto\nreserves as a core strategy, deliver levered exposure to digital assets but\nface acute downside risk when equity premia over net asset value multiples\n(mNAV) compress in bear markets. This paper develops a survival framework that\ncouples conservative treasury policy with an operating line that monetizes\nholdings independent of mark-to-market gains. Using Strategy (formerly\nMicroStrategy) as a case, we propose a \"BTC-to-sats\" payments rail that\nallocates a small, risk-capped liquidity sleeve of the treasury to Lightning\nNetwork channels, generating price-agnostic fee revenue (acquiring bps,\nrouting, hedge/FX spread) while keeping settlement exposure near zero beta to\nBTC. We formalize a no-forced-sale condition and show how disclosed KPIs allow\ninvestors to test whether operating cash flows can bridge an 18 to 24-month\nbear without liquidations. The feasibility of the rail is supported by\nStrategy's Lightning initiative and empirical Lightning performance. Our model\ngeneralizes across DAT types and provides implementable disclosures that can\nsustain an mNAV premium through cycles.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e3a\u6301\u6709\u5927\u91cf\u52a0\u5bc6\u8d44\u4ea7\u50a8\u5907\u7684\u4e0a\u5e02\u516c\u53f8\u5f00\u53d1\u4e86\u4e00\u4e2a\u751f\u5b58\u6846\u67b6\uff0c\u901a\u8fc7\u4fdd\u5b88\u7684\u8d22\u653f\u653f\u7b56\u548c\u72ec\u7acb\u4e8e\u5e02\u4ef7\u53d8\u52a8\u7684\u8fd0\u8425\u7ebf\u8def\u6765\u5e94\u5bf9\u718a\u5e02\u98ce\u9669\u3002", "motivation": "\u6570\u5b57\u8d44\u4ea7\u8d22\u653f\u516c\u53f8\u9762\u4e34\u718a\u5e02\u65f6\u51c0\u8d44\u4ea7\u6ea2\u4ef7\u500d\u6570\u538b\u7f29\u7684\u4e25\u91cd\u4e0b\u884c\u98ce\u9669\uff0c\u9700\u8981\u5efa\u7acb\u80fd\u591f\u627f\u53d7\u957f\u671f\u718a\u5e02\u800c\u4e0d\u88ab\u8feb\u6e05\u7b97\u7684\u8fd0\u8425\u6a21\u5f0f\u3002", "method": "\u63d0\u51fa\"BTC-to-sats\"\u652f\u4ed8\u901a\u9053\uff0c\u5c06\u90e8\u5206\u8d22\u653f\u8d44\u91d1\u5206\u914d\u5230\u95ea\u7535\u7f51\u7edc\u901a\u9053\u4e2d\uff0c\u4ea7\u751f\u4e0e\u4ef7\u683c\u65e0\u5173\u7684\u8d39\u7528\u6536\u5165\uff0c\u540c\u65f6\u4fdd\u6301\u7ed3\u7b97\u98ce\u9669\u4e0eBTC\u63a5\u8fd1\u96f6\u76f8\u5173\u6027\u3002", "result": "\u5efa\u7acb\u4e86\u65e0\u5f3a\u5236\u51fa\u552e\u6761\u4ef6\uff0c\u5e76\u663e\u793a\u8fd0\u8425\u73b0\u91d1\u6d41\u80fd\u591f\u652f\u649118-24\u4e2a\u6708\u718a\u5e02\u800c\u4e0d\u9700\u8981\u6e05\u7b97\u8d44\u4ea7\u3002\u8be5\u6846\u67b6\u9002\u7528\u4e8e\u5404\u7c7b\u6570\u5b57\u8d44\u4ea7\u8d22\u653f\u516c\u53f8\u3002", "conclusion": "\u8be5\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u5b9e\u65bd\u7684\u62ab\u9732\u6807\u51c6\uff0c\u80fd\u591f\u5e2e\u52a9\u6570\u5b57\u8d44\u4ea7\u8d22\u653f\u516c\u53f8\u5728\u5e02\u573a\u5468\u671f\u4e2d\u7ef4\u6301\u51c0\u8d44\u4ea7\u6ea2\u4ef7\u3002"}}
{"id": "2511.00291", "categories": ["eess.SY", "cs.NI", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.00291", "abs": "https://arxiv.org/abs/2511.00291", "authors": ["Christos Mavridis", "Fernando S. Barbosa", "Hamed Farhadi", "Karl H. Johansson"], "title": "Learning a Network Digital Twin as a Hybrid System", "comment": null, "summary": "Network digital twin (NDT) models are virtual models that replicate the\nbehavior of physical communication networks and are considered a key technology\ncomponent to enable novel features and capabilities in future 6G networks. In\nthis work, we focus on NDTs that model the communication quality properties of\na multi-cell, dynamically changing wireless network over a workspace populated\nwith multiple moving users. We propose an NDT modeled as a hybrid system, where\neach mode corresponds to a different base station and comprises sub-modes that\ncorrespond to areas of the workspace with similar network characteristics. The\nproposed hybrid NDT is identified and continuously improved through an\nannealing optimization-based learning algorithm, driven by online data\nmeasurements collected by the users. The advantages of the proposed hybrid NDT\nare studied with respect to memory and computational efficiency, data\nconsumption, and the ability to timely adapt to network changes. Finally, we\nvalidate the proposed methodology on real experimental data collected from a\ntwo-cell 5G testbed.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u7cfb\u7edf\u7684\u7f51\u7edc\u6570\u5b57\u5b6a\u751f\u6a21\u578b\uff0c\u901a\u8fc7\u9000\u706b\u4f18\u5316\u5b66\u4e60\u7b97\u6cd5\u8bc6\u522b\u548c\u6539\u8fdb\u6a21\u578b\uff0c\u7528\u4e8e\u6a21\u62df\u591a\u5c0f\u533a\u52a8\u6001\u65e0\u7ebf\u7f51\u7edc\u7684\u901a\u4fe1\u8d28\u91cf\u7279\u6027\u3002", "motivation": "\u7f51\u7edc\u6570\u5b57\u5b6a\u751f\u662f6G\u7f51\u7edc\u7684\u5173\u952e\u6280\u672f\uff0c\u9700\u8981\u51c6\u786e\u6a21\u62df\u7269\u7406\u901a\u4fe1\u7f51\u7edc\u884c\u4e3a\uff0c\u7279\u522b\u662f\u591a\u5c0f\u533a\u52a8\u6001\u65e0\u7ebf\u7f51\u7edc\u4e2d\u79fb\u52a8\u7528\u6237\u7684\u901a\u4fe1\u8d28\u91cf\u3002", "method": "\u5c06NDT\u5efa\u6a21\u4e3a\u6df7\u5408\u7cfb\u7edf\uff0c\u6bcf\u4e2a\u6a21\u5f0f\u5bf9\u5e94\u4e0d\u540c\u57fa\u7ad9\uff0c\u5b50\u6a21\u5f0f\u5bf9\u5e94\u5177\u6709\u76f8\u4f3c\u7f51\u7edc\u7279\u6027\u7684\u5de5\u4f5c\u533a\u57df\uff0c\u901a\u8fc7\u9000\u706b\u4f18\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u7ebf\u8bc6\u522b\u548c\u6539\u8fdb\u6a21\u578b\u3002", "result": "\u57285G\u53cc\u5c0f\u533a\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u4f7f\u7528\u771f\u5b9e\u5b9e\u9a8c\u6570\u636e\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5728\u5185\u5b58\u3001\u8ba1\u7b97\u6548\u7387\u3001\u6570\u636e\u6d88\u8017\u548c\u7f51\u7edc\u53d8\u5316\u9002\u5e94\u80fd\u529b\u65b9\u9762\u7684\u4f18\u52bf\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408NDT\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u6a21\u62df\u52a8\u6001\u65e0\u7ebf\u7f51\u7edc\uff0c\u4e3a6G\u7f51\u7edc\u63d0\u4f9b\u53ef\u9760\u7684\u6570\u5b57\u5b6a\u751f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01459", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2511.01459", "abs": "https://arxiv.org/abs/2511.01459", "authors": ["Alaa Awad Abdellatif", "Helder Fontes", "Andre Coelho", "Luis M. Pessoa", "Rui Campos"], "title": "Edge-Enabled UAV Swarm Deployment for Rapid Post-Disaster Search and Rescue", "comment": null, "summary": "This paper presents an optimized Joint Radar-Communication (JRC) system\nutilizing multiple Unmanned Aerial Vehicles (UAVs) to simultaneously achieve\nsensing and communication objectives. By leveraging UAVs equipped with dual\nradar and communication capabilities, the proposed framework aims to maximize\nradar sensing performance across all UAVs in challenging environments. The\nproposed approach focuses on formulating and solving a UAV positioning and\npower allocation problem to optimize multi-UAV sensing and communications\nperformance over multiple targets within designated zones. Due to the NP-hard\nand combinatorial nature of the problem, we propose a Distributed JRC-based\n(DJRC) solution. This solution employs an efficient reward for potential\nactions and consistently selects the best action that maximizes the reward\nwhile ensuring both communications and sensing performance. Simulation results\ndemonstrate significant performance improvements of the proposed solution over\nstate-of-the-art radar- or communication-centric trajectory planning methods,\nwith polynomial complexity dependent on the number of UAVs and linear\ndependence on the iteration count.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u65e0\u4eba\u673a\u7684\u8054\u5408\u96f7\u8fbe\u901a\u4fe1\u7cfb\u7edf\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u7b97\u6cd5\u89e3\u51b3\u65e0\u4eba\u673a\u5b9a\u4f4d\u548c\u529f\u7387\u5206\u914d\u95ee\u9898\uff0c\u5728\u4fdd\u8bc1\u901a\u4fe1\u6027\u80fd\u7684\u540c\u65f6\u6700\u5927\u5316\u96f7\u8fbe\u611f\u77e5\u80fd\u529b\u3002", "motivation": "\u5728\u590d\u6742\u73af\u5883\u4e2d\uff0c\u9700\u8981\u540c\u65f6\u5b9e\u73b0\u96f7\u8fbe\u611f\u77e5\u548c\u901a\u4fe1\u76ee\u6807\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u517c\u987e\u4e24\u8005\u6027\u80fd\u3002\u5229\u7528\u591a\u65e0\u4eba\u673a\u534f\u540c\u5de5\u4f5c\u53ef\u4ee5\u63d0\u5347\u7cfb\u7edf\u6574\u4f53\u6548\u80fd\u3002", "method": "\u91c7\u7528\u5206\u5e03\u5f0fJRC\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u8bbe\u8ba1\u9ad8\u6548\u5956\u52b1\u673a\u5236\u9009\u62e9\u6700\u4f73\u52a8\u4f5c\uff0c\u89e3\u51b3NP-hard\u7684\u65e0\u4eba\u673a\u5b9a\u4f4d\u548c\u529f\u7387\u5206\u914d\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u73b0\u6709\u96f7\u8fbe\u6216\u901a\u4fe1\u4e2d\u5fc3\u8f68\u8ff9\u89c4\u5212\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u65b9\u6848\u5728\u6027\u80fd\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u4e14\u5177\u6709\u591a\u9879\u5f0f\u590d\u6742\u5ea6\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5206\u5e03\u5f0fJRC\u6846\u67b6\u80fd\u591f\u6709\u6548\u4f18\u5316\u591a\u65e0\u4eba\u673a\u7cfb\u7edf\u7684\u96f7\u8fbe\u611f\u77e5\u548c\u901a\u4fe1\u6027\u80fd\uff0c\u5728\u590d\u6742\u73af\u5883\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2511.00024", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.00024", "abs": "https://arxiv.org/abs/2511.00024", "authors": ["Haotian Hang", "Yueyang Shen", "Vicky Zhu", "Jose Cruz", "Michelle Li"], "title": "Chitchat with AI: Understand the supply chain carbon disclosure of companies worldwide through Large Language Model", "comment": null, "summary": "In the context of global sustainability mandates, corporate carbon disclosure\nhas emerged as a critical mechanism for aligning business strategy with\nenvironmental responsibility. The Carbon Disclosure Project (CDP) hosts the\nworld's largest longitudinal dataset of climate-related survey responses,\ncombining structured indicators with open-ended narratives, but the\nheterogeneity and free-form nature of these disclosures present significant\nanalytical challenges for benchmarking, compliance monitoring, and investment\nscreening. This paper proposes a novel decision-support framework that\nleverages large language models (LLMs) to assess corporate climate disclosure\nquality at scale. It develops a master rubric that harmonizes narrative scoring\nacross 11 years of CDP data (2010-2020), enabling cross-sector and\ncross-country benchmarking. By integrating rubric-guided scoring with\npercentile-based normalization, our method identifies temporal trends,\nstrategic alignment patterns, and inconsistencies in disclosure across\nindustries and regions. Results reveal that sectors such as technology and\ncountries like Germany consistently demonstrate higher rubric alignment, while\nothers exhibit volatility or superficial engagement, offering insights that\ninform key decision-making processes for investors, regulators, and corporate\nenvironmental, social, and governance (ESG) strategists. The proposed LLM-based\napproach transforms unstructured disclosures into quantifiable, interpretable,\ncomparable, and actionable intelligence, advancing the capabilities of\nAI-enabled decision support systems (DSSs) in the domain of climate governance.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u51b3\u7b56\u652f\u6301\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u4f01\u4e1a\u78b3\u62ab\u9732\u8d28\u91cf\uff0c\u5c06\u975e\u7ed3\u6784\u5316\u62ab\u9732\u8f6c\u5316\u4e3a\u53ef\u91cf\u5316\u3001\u53ef\u6bd4\u8f83\u7684\u667a\u80fd\u4fe1\u606f\u3002", "motivation": "\u4f01\u4e1a\u78b3\u62ab\u9732\u5bf9\u53ef\u6301\u7eed\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u4f46CDP\u6570\u636e\u96c6\u7684\u5f02\u8d28\u6027\u548c\u81ea\u7531\u5f62\u5f0f\u7279\u6027\u7ed9\u5206\u6790\u5e26\u6765\u4e86\u6311\u6218\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u652f\u6301\u57fa\u51c6\u6d4b\u8bd5\u3001\u5408\u89c4\u76d1\u63a7\u548c\u6295\u8d44\u7b5b\u9009\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5f00\u53d1\u4e3b\u8bc4\u5206\u6807\u51c6\uff0c\u6574\u540811\u5e74CDP\u6570\u636e\uff0c\u7ed3\u5408\u8bc4\u5206\u6807\u51c6\u5f15\u5bfc\u7684\u8bc4\u5206\u548c\u57fa\u4e8e\u767e\u5206\u4f4d\u7684\u6807\u51c6\u5316\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u6280\u672f\u548c\u5fb7\u56fd\u7b49\u56fd\u5bb6\u548c\u884c\u4e1a\u5728\u8bc4\u5206\u6807\u51c6\u4e00\u81f4\u6027\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u800c\u5176\u4ed6\u884c\u4e1a\u548c\u5730\u533a\u5b58\u5728\u6ce2\u52a8\u6027\u6216\u8868\u9762\u53c2\u4e0e\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u5c06\u975e\u7ed3\u6784\u5316\u62ab\u9732\u8f6c\u5316\u4e3a\u53ef\u91cf\u5316\u3001\u53ef\u89e3\u91ca\u3001\u53ef\u6bd4\u8f83\u548c\u53ef\u64cd\u4f5c\u7684\u667a\u80fd\u4fe1\u606f\uff0c\u63d0\u5347\u4e86AI\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u5728\u6c14\u5019\u6cbb\u7406\u9886\u57df\u7684\u80fd\u529b\u3002"}}
{"id": "2511.00422", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.00422", "abs": "https://arxiv.org/abs/2511.00422", "authors": ["Isabella Habereder", "Thomas Kneib", "Isao Echizen", "Timo Spinde"], "title": "A Systematic Review of Spatio-Temporal Statistical Models: Theory, Structure, and Applications", "comment": null, "summary": "Data with spatial-temporal attributes are prevalent across many research\nfields, and statistical models for analyzing spatio-temporal relationships are\nwidely used. Existing reviews focus either on specific domains or model types,\ncreating a gap in comprehensive, cross-disciplinary overviews. To address this,\nwe conducted a systematic literature review following the PRISMA guidelines,\nsearched two databases for the years 2021-2025, and identified 83 publications\nthat met our criteria. We propose a classification scheme for spatio-temporal\nmodel structures and highlight their application in the most common fields:\nepidemiology, ecology, public health, economics, and criminology. Although\ntasks vary by domain, many models share similarities. We found that\nhierarchical models are the most frequently used, and most models incorporate\nadditive components to account for spatial-temporal dependencies. The preferred\nmodel structures differ among fields of application. We also observe that\nresearch efforts are concentrated in only a few specific disciplines, despite\nthe broader relevance of spatio-temporal data. Furthermore, we notice that\nreproducibility remains limited. Our review, therefore, not only offers\ninspiration for comparing model structures in an interdisciplinary manner but\nalso highlights opportunities for greater transparency, accessibility, and\ncross-domain knowledge transfer.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf92021-2025\u5e74\u95f483\u7bc7\u65f6\u7a7a\u6a21\u578b\u6587\u732e\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u63d0\u51fa\u4e86\u65f6\u7a7a\u6a21\u578b\u7ed3\u6784\u5206\u7c7b\u65b9\u6848\uff0c\u5e76\u5206\u6790\u4e86\u6d41\u884c\u75c5\u5b66\u3001\u751f\u6001\u5b66\u7b49\u4e3b\u8981\u5e94\u7528\u9886\u57df\u7684\u6a21\u578b\u4f7f\u7528\u60c5\u51b5\u3002", "motivation": "\u73b0\u6709\u7efc\u8ff0\u591a\u96c6\u4e2d\u4e8e\u7279\u5b9a\u9886\u57df\u6216\u6a21\u578b\u7c7b\u578b\uff0c\u7f3a\u4e4f\u8de8\u5b66\u79d1\u7684\u5168\u9762\u6982\u8ff0\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u9075\u5faaPRISMA\u6307\u5357\u8fdb\u884c\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u68c0\u7d22\u4e24\u4e2a\u6570\u636e\u5e93\uff0c\u7b5b\u9009\u51fa83\u7bc7\u7b26\u5408\u6807\u51c6\u7684\u6587\u732e\uff0c\u63d0\u51fa\u65f6\u7a7a\u6a21\u578b\u7ed3\u6784\u5206\u7c7b\u65b9\u6848\u3002", "result": "\u53d1\u73b0\u5c42\u6b21\u6a21\u578b\u4f7f\u7528\u6700\u9891\u7e41\uff0c\u5927\u591a\u6570\u6a21\u578b\u5305\u542b\u52a0\u6027\u5206\u91cf\u5904\u7406\u65f6\u7a7a\u4f9d\u8d56\u6027\uff1b\u4e0d\u540c\u5e94\u7528\u9886\u57df\u504f\u597d\u4e0d\u540c\u6a21\u578b\u7ed3\u6784\uff1b\u7814\u7a76\u96c6\u4e2d\u5728\u5c11\u6570\u51e0\u4e2a\u5b66\u79d1\uff1b\u53ef\u91cd\u590d\u6027\u6709\u9650\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u4e3a\u8de8\u5b66\u79d1\u6bd4\u8f83\u6a21\u578b\u7ed3\u6784\u63d0\u4f9b\u4e86\u542f\u53d1\uff0c\u5e76\u5f3a\u8c03\u4e86\u63d0\u9ad8\u900f\u660e\u5ea6\u3001\u53ef\u8bbf\u95ee\u6027\u548c\u8de8\u9886\u57df\u77e5\u8bc6\u8f6c\u79fb\u7684\u673a\u4f1a\u3002"}}
{"id": "2511.00039", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00039", "abs": "https://arxiv.org/abs/2511.00039", "authors": ["Krishna Kumar Neelakanta Pillai Santha Kumari Amma"], "title": "Graph-Attentive MAPPO for Dynamic Retail Pricing", "comment": null, "summary": "Dynamic pricing in retail requires policies that adapt to shifting demand\nwhile coordinating decisions across related products. We present a systematic\nempirical study of multi-agent reinforcement learning for retail price\noptimization, comparing a strong MAPPO baseline with a\ngraph-attention-augmented variant (MAPPO+GAT) that leverages learned\ninteractions among products. Using a simulated pricing environment derived from\nreal transaction data, we evaluate profit, stability across random seeds,\nfairness across products, and training efficiency under a standardized\nevaluation protocol. The results indicate that MAPPO provides a robust and\nreproducible foundation for portfolio-level price control, and that MAPPO+GAT\nfurther enhances performance by sharing information over the product graph\nwithout inducing excessive price volatility. These results indicate that\ngraph-integrated MARL provides a more scalable and stable solution than\nindependent learners for dynamic retail pricing, offering practical advantages\nin multi-product decision-making.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MAPPO\uff09\u53ca\u5176\u56fe\u6ce8\u610f\u529b\u589e\u5f3a\u53d8\u4f53\uff08MAPPO+GAT\uff09\u5728\u96f6\u552e\u4ef7\u683c\u4f18\u5316\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0MAPPO+GAT\u901a\u8fc7\u4ea7\u54c1\u56fe\u4fe1\u606f\u5171\u4eab\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4e3a\u52a8\u6001\u96f6\u552e\u5b9a\u4ef7\u63d0\u4f9b\u4e86\u66f4\u53ef\u6269\u5c55\u548c\u7a33\u5b9a\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u96f6\u552e\u52a8\u6001\u5b9a\u4ef7\u9700\u8981\u80fd\u591f\u9002\u5e94\u9700\u6c42\u53d8\u5316\u5e76\u5728\u76f8\u5173\u4ea7\u54c1\u95f4\u534f\u8c03\u51b3\u7b56\u7684\u7b56\u7565\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u591a\u4ea7\u54c1\u51b3\u7b56\u4e2d\u9762\u4e34\u6311\u6218\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u771f\u5b9e\u4ea4\u6613\u6570\u636e\u7684\u6a21\u62df\u5b9a\u4ef7\u73af\u5883\uff0c\u6bd4\u8f83MAPPO\u57fa\u7ebf\u548c\u56fe\u6ce8\u610f\u529b\u589e\u5f3a\u7684MAPPO+GAT\u65b9\u6cd5\uff0c\u91c7\u7528\u6807\u51c6\u5316\u8bc4\u4f30\u534f\u8bae\u8bc4\u4f30\u5229\u6da6\u3001\u7a33\u5b9a\u6027\u3001\u516c\u5e73\u6027\u548c\u8bad\u7ec3\u6548\u7387\u3002", "result": "MAPPO\u4e3a\u7ec4\u5408\u7ea7\u4ef7\u683c\u63a7\u5236\u63d0\u4f9b\u4e86\u7a33\u5065\u4e14\u53ef\u590d\u73b0\u7684\u57fa\u7840\uff0cMAPPO+GAT\u901a\u8fc7\u4ea7\u54c1\u56fe\u4fe1\u606f\u5171\u4eab\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4e14\u672a\u5f15\u8d77\u8fc7\u5ea6\u7684\u4ef7\u683c\u6ce2\u52a8\u3002", "conclusion": "\u56fe\u96c6\u6210MARL\u4e3a\u52a8\u6001\u96f6\u552e\u5b9a\u4ef7\u63d0\u4f9b\u4e86\u6bd4\u72ec\u7acb\u5b66\u4e60\u5668\u66f4\u53ef\u6269\u5c55\u548c\u7a33\u5b9a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u591a\u4ea7\u54c1\u51b3\u7b56\u4e2d\u5177\u6709\u5b9e\u9645\u4f18\u52bf\u3002"}}
{"id": "2511.00033", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00033", "abs": "https://arxiv.org/abs/2511.00033", "authors": ["Diqi He", "Xuehao Gao", "Hao Li", "Junwei Han", "Dingwen Zhang"], "title": "STRIDER: Navigation via Instruction-Aligned Structural Decision Space Optimization", "comment": null, "summary": "The Zero-shot Vision-and-Language Navigation in Continuous Environments\n(VLN-CE) task requires agents to navigate previously unseen 3D environments\nusing natural language instructions, without any scene-specific training. A\ncritical challenge in this setting lies in ensuring agents' actions align with\nboth spatial structure and task intent over long-horizon execution. Existing\nmethods often fail to achieve robust navigation due to a lack of structured\ndecision-making and insufficient integration of feedback from previous actions.\nTo address these challenges, we propose STRIDER (Instruction-Aligned Structural\nDecision Space Optimization), a novel framework that systematically optimizes\nthe agent's decision space by integrating spatial layout priors and dynamic\ntask feedback. Our approach introduces two key innovations: 1) a Structured\nWaypoint Generator that constrains the action space through spatial structure,\nand 2) a Task-Alignment Regulator that adjusts behavior based on task progress,\nensuring semantic alignment throughout navigation. Extensive experiments on the\nR2R-CE and RxR-CE benchmarks demonstrate that STRIDER significantly outperforms\nstrong SOTA across key metrics; in particular, it improves Success Rate (SR)\nfrom 29% to 35%, a relative gain of 20.7%. Such results highlight the\nimportance of spatially constrained decision-making and feedback-guided\nexecution in improving navigation fidelity for zero-shot VLN-CE.", "AI": {"tldr": "STRIDER\u6846\u67b6\u901a\u8fc7\u6574\u5408\u7a7a\u95f4\u5e03\u5c40\u5148\u9a8c\u548c\u52a8\u6001\u4efb\u52a1\u53cd\u9988\u6765\u4f18\u5316\u667a\u80fd\u4f53\u5728\u96f6\u6837\u672c\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u4efb\u52a1\u4e2d\u7684\u51b3\u7b56\u7a7a\u95f4\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bfc\u822a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u96f6\u6837\u672c\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u4e2d\u7f3a\u4e4f\u7ed3\u6784\u5316\u51b3\u7b56\u548c\u5148\u524d\u52a8\u4f5c\u53cd\u9988\u7684\u5145\u5206\u6574\u5408\uff0c\u5bfc\u81f4\u5bfc\u822a\u9c81\u68d2\u6027\u4e0d\u8db3\u3002", "method": "\u63d0\u51faSTRIDER\u6846\u67b6\uff0c\u5305\u542b\u7ed3\u6784\u5316\u8def\u5f84\u70b9\u751f\u6210\u5668\uff08\u7ea6\u675f\u52a8\u4f5c\u7a7a\u95f4\uff09\u548c\u4efb\u52a1\u5bf9\u9f50\u8c03\u8282\u5668\uff08\u57fa\u4e8e\u4efb\u52a1\u8fdb\u5c55\u8c03\u6574\u884c\u4e3a\uff09\u3002", "result": "\u5728R2R-CE\u548cRxR-CE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u6210\u529f\u7387\u4ece29%\u63d0\u5347\u81f335%\uff0c\u76f8\u5bf9\u589e\u76ca\u8fbe20.7%\u3002", "conclusion": "\u7a7a\u95f4\u7ea6\u675f\u51b3\u7b56\u548c\u53cd\u9988\u5f15\u5bfc\u6267\u884c\u5bf9\u4e8e\u63d0\u5347\u96f6\u6837\u672c\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u7684\u4fdd\u771f\u5ea6\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2511.01680", "categories": ["econ.EM", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01680", "abs": "https://arxiv.org/abs/2511.01680", "authors": ["Jacob Carlson"], "title": "Making Interpretable Discoveries from Unstructured Data: A High-Dimensional Multiple Hypothesis Testing Approach", "comment": null, "summary": "Social scientists are increasingly turning to unstructured datasets to unlock\nnew empirical insights, e.g., estimating causal effects on text outcomes,\nmeasuring beliefs from open-ended survey responses. In such settings,\nunsupervised analysis is often of interest, in that the researcher does not\nwant to pre-specify the objects of measurement or otherwise artificially\ndelimit the space of measurable concepts; they are interested in discovery.\nThis paper proposes a general and flexible framework for pursuing discovery\nfrom unstructured data in a statistically principled way. The framework\nleverages recent methods from the literature on machine learning\ninterpretability to map unstructured data points to high-dimensional, sparse,\nand interpretable dictionaries of concepts; computes (test) statistics of these\ndictionary entries; and then performs selective inference on them using newly\ndeveloped statistical procedures for high-dimensional exceedance control of the\n$k$-FWER under arbitrary dependence. The proposed framework has few researcher\ndegrees of freedom, is fully replicable, and is cheap to implement -- both in\nterms of financial cost and researcher time. Applications to recent descriptive\nand causal analyses of unstructured data in empirical economics are explored.\nAn open source Jupyter notebook is provided for researchers to implement the\nframework in their own projects.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4ece\u975e\u7ed3\u6784\u5316\u6570\u636e\u4e2d\u8fdb\u884c\u7edf\u8ba1\u53d1\u73b0\u7684\u4e00\u822c\u6846\u67b6\uff0c\u5229\u7528\u673a\u5668\u5b66\u4e60\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u6784\u5efa\u6982\u5ff5\u5b57\u5178\uff0c\u5e76\u901a\u8fc7\u9009\u62e9\u6027\u63a8\u65ad\u8fdb\u884c\u7edf\u8ba1\u9a8c\u8bc1\u3002", "motivation": "\u793e\u4f1a\u79d1\u5b66\u5bb6\u8d8a\u6765\u8d8a\u591a\u5730\u4f7f\u7528\u975e\u7ed3\u6784\u5316\u6570\u636e\u96c6\u6765\u83b7\u53d6\u65b0\u7684\u5b9e\u8bc1\u89c1\u89e3\uff0c\u4f46\u9700\u8981\u4e00\u79cd\u7edf\u8ba1\u4e0a\u4e25\u8c28\u7684\u65b9\u6cd5\u6765\u8fdb\u884c\u65e0\u76d1\u7763\u5206\u6790\uff0c\u800c\u4e0d\u9884\u5148\u6307\u5b9a\u6d4b\u91cf\u5bf9\u8c61\u3002", "method": "\u5229\u7528\u673a\u5668\u5b66\u4e60\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5c06\u975e\u7ed3\u6784\u5316\u6570\u636e\u6620\u5c04\u5230\u9ad8\u7ef4\u3001\u7a00\u758f\u4e14\u53ef\u89e3\u91ca\u7684\u6982\u5ff5\u5b57\u5178\uff0c\u8ba1\u7b97\u7edf\u8ba1\u91cf\uff0c\u5e76\u4f7f\u7528\u65b0\u5f00\u53d1\u7684\u9ad8\u7ef4\u8d85\u8d8a\u63a7\u5236\u7edf\u8ba1\u7a0b\u5e8f\u8fdb\u884c\u9009\u62e9\u6027\u63a8\u65ad\u3002", "result": "\u8be5\u6846\u67b6\u5177\u6709\u8f83\u5c11\u7684\u7814\u7a76\u8005\u81ea\u7531\u5ea6\uff0c\u5b8c\u5168\u53ef\u590d\u5236\uff0c\u5b9e\u65bd\u6210\u672c\u4f4e\uff08\u5305\u62ec\u8d22\u52a1\u6210\u672c\u548c\u7814\u7a76\u65f6\u95f4\uff09\uff0c\u5e76\u63d0\u4f9b\u4e86\u5f00\u6e90\u5b9e\u73b0\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u4ece\u975e\u7ed3\u6784\u5316\u6570\u636e\u4e2d\u8fdb\u884c\u7edf\u8ba1\u53d1\u73b0\u63d0\u4f9b\u4e86\u4e00\u79cd\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u63cf\u8ff0\u6027\u548c\u56e0\u679c\u5206\u6790\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b9e\u9645\u5e94\u7528\u5de5\u5177\u3002"}}
{"id": "2511.00378", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2511.00378", "abs": "https://arxiv.org/abs/2511.00378", "authors": ["Yongyang Cai"], "title": "Modeling Uncertainty in Integrated Assessment Models", "comment": null, "summary": "Integrated Assessment Models (IAMs) are pivotal tools that synthesize\nknowledge from climate science, economics, and policy to evaluate the\ninteractions between human activities and the climate system. They serve as\nessential instruments for policymakers, providing insights into the potential\noutcomes of various climate policies and strategies. Given the complexity and\ninherent uncertainties in both the climate system and socio-economic processes,\nunderstanding and effectively managing uncertainty within IAMs is crucial for\nrobust climate policy development. This review aims to provide a comprehensive\noverview of how IAMs handle uncertainty, highlighting recent methodological\nadvancements and their implications for climate policy. I examine the types of\nuncertainties present in IAMs, discuss various modeling approaches to address\nthese uncertainties, and explore recent developments in the field, including\nthe incorporation of advanced computational methods.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u8bba\u6587\u5168\u9762\u56de\u987e\u4e86\u7efc\u5408\u8bc4\u4f30\u6a21\u578b(IAMs)\u5982\u4f55\u5904\u7406\u4e0d\u786e\u5b9a\u6027\uff0c\u91cd\u70b9\u5173\u6ce8\u65b9\u6cd5\u8bba\u8fdb\u5c55\u53ca\u5176\u5bf9\u6c14\u5019\u653f\u7b56\u7684\u5f71\u54cd\u3002", "motivation": "\u7531\u4e8e\u6c14\u5019\u7cfb\u7edf\u548c\u793e\u4f1a\u7ecf\u6d4e\u8fc7\u7a0b\u7684\u590d\u6742\u6027\u53ca\u56fa\u6709\u4e0d\u786e\u5b9a\u6027\uff0c\u7406\u89e3\u548c\u6709\u6548\u7ba1\u7406IAMs\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u5bf9\u4e8e\u5236\u5b9a\u7a33\u5065\u7684\u6c14\u5019\u653f\u7b56\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5ba1\u67e5IAMs\u4e2d\u5b58\u5728\u7684\u4e0d\u786e\u5b9a\u6027\u7c7b\u578b\uff0c\u8ba8\u8bba\u5904\u7406\u8fd9\u4e9b\u4e0d\u786e\u5b9a\u6027\u7684\u5404\u79cd\u5efa\u6a21\u65b9\u6cd5\uff0c\u5e76\u63a2\u7d22\u8be5\u9886\u57df\u7684\u6700\u65b0\u53d1\u5c55\uff0c\u5305\u62ec\u5148\u8fdb\u8ba1\u7b97\u65b9\u6cd5\u7684\u6574\u5408\u3002", "result": "\u63d0\u4f9b\u4e86IAMs\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u7684\u5168\u9762\u6982\u8ff0\uff0c\u7a81\u51fa\u4e86\u65b9\u6cd5\u8bba\u8fdb\u5c55\u53ca\u5176\u653f\u7b56\u542b\u4e49\u3002", "conclusion": "\u6709\u6548\u7ba1\u7406IAMs\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u5bf9\u4e8e\u5236\u5b9a\u7a33\u5065\u7684\u6c14\u5019\u653f\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u5148\u8fdb\u8ba1\u7b97\u65b9\u6cd5\u7684\u5e94\u7528\u4e3a\u6539\u8fdb\u4e0d\u786e\u5b9a\u6027\u5904\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2511.00173", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2511.00173", "abs": "https://arxiv.org/abs/2511.00173", "authors": ["Andrew Mackenzie"], "title": "Subjective inference", "comment": null, "summary": "An agent observes a clue, and an analyst observes an inference: a ranking of\nevents on the basis of how corroborated they are by the clue. We prove that if\nthe inference satisfies the axioms of Villegas (1964) except for the classic\nqualitative probability axiom of monotonicity, then it has a unique normalized\nsigned measure representation (Theorem 1). Moreover, if the inference also\ndeclares the largest event equivalent to the smallest event, then it can be\nrepresented as a difference between a posterior and a prior such that the\nformer is the conditional probability of the latter with respect to an assessed\nevent that is interpreted as a clue guess. Across these Bayesian\nrepresentations, the posterior is unique, all guesses are in a suitable sense\nequivalent, and the prior is determined by the weight it assigns to each\npossible guess (Theorem 2). However, observation of a prior and posterior\ncompatible with the inference could reveal that all of these guesses are wrong.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc1\u660e\u4e86\u5728\u6ee1\u8db3Villegas(1964)\u516c\u7406\uff08\u9664\u5355\u8c03\u6027\u5916\uff09\u7684\u63a8\u7406\u4e0b\uff0c\u5b58\u5728\u552f\u4e00\u7684\u5f52\u4e00\u5316\u7b26\u53f7\u6d4b\u5ea6\u8868\u793a\u3002\u5982\u679c\u6700\u5927\u4e8b\u4ef6\u4e0e\u6700\u5c0f\u4e8b\u4ef6\u7b49\u4ef7\uff0c\u5219\u53ef\u8868\u793a\u4e3a\u540e\u9a8c\u4e0e\u5148\u9a8c\u7684\u5dee\u5f02\uff0c\u5176\u4e2d\u540e\u9a8c\u662f\u6761\u4ef6\u6982\u7387\u3002", "motivation": "\u7814\u7a76\u5f53\u5206\u6790\u5e08\u89c2\u5bdf\u5230\u57fa\u4e8e\u7ebf\u7d22\u7684\u6392\u5e8f\u63a8\u7406\u65f6\uff0c\u5982\u4f55\u5efa\u7acb\u6570\u5b66\u8868\u793a\uff0c\u7279\u522b\u662f\u63a2\u7d22\u8d1d\u53f6\u65af\u8868\u793a\u7684\u53ef\u80fd\u6027\u3002", "method": "\u4f7f\u7528\u516c\u7406\u5316\u65b9\u6cd5\uff0c\u57fa\u4e8eVillegas(1964)\u7684\u516c\u7406\u4f53\u7cfb\uff08\u6392\u9664\u5355\u8c03\u6027\uff09\uff0c\u8bc1\u660e\u5b58\u5728\u552f\u4e00\u7684\u5f52\u4e00\u5316\u7b26\u53f7\u6d4b\u5ea6\u8868\u793a\uff0c\u5e76\u8fdb\u4e00\u6b65\u5206\u6790\u8d1d\u53f6\u65af\u8868\u793a\u7684\u6761\u4ef6\u3002", "result": "\u5b9a\u74061\uff1a\u6ee1\u8db3\u6761\u4ef6\u7684\u63a8\u7406\u6709\u552f\u4e00\u5f52\u4e00\u5316\u7b26\u53f7\u6d4b\u5ea6\u8868\u793a\uff1b\u5b9a\u74062\uff1a\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u53ef\u8868\u793a\u4e3a\u540e\u9a8c\u4e0e\u5148\u9a8c\u7684\u5dee\u5f02\uff0c\u540e\u9a8c\u552f\u4e00\uff0c\u5148\u9a8c\u7531\u5bf9\u5404\u731c\u6d4b\u7684\u6743\u91cd\u51b3\u5b9a\u3002", "conclusion": "\u89c2\u5bdf\u5230\u7684\u5148\u9a8c\u548c\u540e\u9a8c\u53ef\u80fd\u63ed\u793a\u6240\u6709\u731c\u6d4b\u90fd\u662f\u9519\u8bef\u7684\uff0c\u8fd9\u4e3a\u63a8\u7406\u7684\u8868\u793a\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u4f46\u4e5f\u6307\u51fa\u4e86\u5176\u5c40\u9650\u6027\u3002"}}
{"id": "2511.00401", "categories": ["cs.SI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.00401", "abs": "https://arxiv.org/abs/2511.00401", "authors": ["Mohammad Shirzadi", "Emilio Cruciani", "Ahad N. Zehmakan"], "title": "Opinion Dynamics: A Comprehensive Overview", "comment": "50 pages, 13 figures, and 2 tables", "summary": "Opinion dynamics, the evolution of individuals through social interactions,\nis an important area of research with applications ranging from politics to\nmarketing. Due to its interdisciplinary relevance, studies of opinion dynamics\nremain fragmented across computer science, mathematics, the social sciences,\nand physics, and often lack shared frameworks. This survey bridges these gaps\nby reviewing well-known models of opinion dynamics within a unified framework\nand categorizing them into distinct classes based on their properties.\nFurthermore, the key findings on these models are covered in three parts:\nconvergence properties, viral marketing, and user characteristics. We first\nanalyze the final configuration (consensus vs polarized) and convergence time\nfor each model. We then review the main algorithmic, complexity, and\ncombinatorial results in the context of viral marketing. Finally, we explore\nhow node characteristics, such as stubbornness, activeness, or neutrality,\nshape diffusion outcomes. By unifying terminology, methods, and challenges\nacross disciplines, this paper aims to foster cross-disciplinary collaboration\nand accelerate progress in understanding and harnessing opinion dynamics.", "AI": {"tldr": "\u8fd9\u7bc7\u8c03\u67e5\u8bba\u6587\u901a\u8fc7\u7edf\u4e00\u6846\u67b6\u56de\u987e\u4e86\u610f\u89c1\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u5c06\u5176\u5206\u7c7b\u5e76\u5206\u6790\u4e86\u6536\u655b\u6027\u3001\u75c5\u6bd2\u8425\u9500\u548c\u7528\u6237\u7279\u5f81\u4e09\u4e2a\u5173\u952e\u65b9\u9762\u3002", "motivation": "\u610f\u89c1\u52a8\u529b\u5b66\u7814\u7a76\u5728\u4e0d\u540c\u5b66\u79d1\u4e2d\u5206\u6563\u4e14\u7f3a\u4e4f\u5171\u4eab\u6846\u67b6\uff0c\u672c\u6587\u65e8\u5728\u5f25\u5408\u8fd9\u4e9b\u5dee\u8ddd\uff0c\u4fc3\u8fdb\u8de8\u5b66\u79d1\u5408\u4f5c\u3002", "method": "\u5728\u7edf\u4e00\u6846\u67b6\u4e0b\u56de\u987e\u77e5\u540d\u610f\u89c1\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u57fa\u4e8e\u6027\u8d28\u5c06\u5176\u5206\u7c7b\uff0c\u5e76\u5206\u6790\u6536\u655b\u7279\u6027\u3001\u75c5\u6bd2\u8425\u9500\u7b97\u6cd5\u548c\u8282\u70b9\u7279\u5f81\u5f71\u54cd\u3002", "result": "\u7cfb\u7edf\u5206\u6790\u4e86\u4e0d\u540c\u6a21\u578b\u7684\u6700\u7ec8\u914d\u7f6e\uff08\u5171\u8bc6vs\u6781\u5316\uff09\u548c\u6536\u655b\u65f6\u95f4\uff0c\u603b\u7ed3\u4e86\u75c5\u6bd2\u8425\u9500\u7684\u7b97\u6cd5\u548c\u590d\u6742\u6027\u7ed3\u679c\uff0c\u63a2\u8ba8\u4e86\u8282\u70b9\u7279\u6027\u5bf9\u6269\u6563\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "conclusion": "\u901a\u8fc7\u7edf\u4e00\u5404\u5b66\u79d1\u7684\u672f\u8bed\u3001\u65b9\u6cd5\u548c\u6311\u6218\uff0c\u672c\u6587\u4fc3\u8fdb\u4e86\u8de8\u5b66\u79d1\u5408\u4f5c\uff0c\u52a0\u901f\u4e86\u5bf9\u610f\u89c1\u52a8\u529b\u5b66\u7684\u7406\u89e3\u548c\u5229\u7528\u3002"}}
{"id": "2511.00296", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.00296", "abs": "https://arxiv.org/abs/2511.00296", "authors": ["Peng Wang", "Zhengmao Li", "Luis Badesa"], "title": "Analyzing the Impact of Demand Response on Short-Circuit Current via a Unit Commitment Model", "comment": "1-5 pages. submitted to PESGM 2026, Canada", "summary": "In low-carbon grids, system flexibility can be enhanced through mechanisms\nsuch as Demand Response (DR), enabling the efficient utilization of renewable\nenergy. However, as Synchronous Generators (SGs) are being replaced with\nrenewable energy characterized by Inverter-Based Resources (IBR), system\nstability is severely affected. Due to the limited overload capability of IBR,\ntheir Short-Circuit Current (SCC) contribution is much smaller than that of\nSGs, which may result in protection devices failing to trip during faults.\nConsequently, the remaining SGs play a key role in offering sufficient SCC\nvolumes. Given that the commitment of SGs is closely related to system load, DR\ncan thus indirectly affect their SCC provision, a relationship that has not\nbeen investigated. Therefore, this paper incorporates both DR and SCC\nconstraints into a unit commitment model and conducts studies on an IEEE 30-bus\nsystem. The results show that although DR can reduce social costs by lowering\npower demand, it may also lead to inadequate SCC levels. Nevertheless, the cost\nincreases by only 0.3% when DR is combined with SCC constraints, indicating\nthat DR can actually help achieve a stable system in a cost-effective manner.", "AI": {"tldr": "\u5728\u4f4e\u78b3\u7535\u7f51\u4e2d\uff0c\u9700\u6c42\u54cd\u5e94(DR)\u80fd\u589e\u5f3a\u7cfb\u7edf\u7075\u6d3b\u6027\uff0c\u4f46\u9006\u53d8\u5668\u8d44\u6e90(IBR)\u53d6\u4ee3\u540c\u6b65\u53d1\u7535\u673a(SG)\u4f1a\u5f71\u54cd\u7cfb\u7edf\u7a33\u5b9a\u6027\u3002\u672c\u6587\u7814\u7a76DR\u5982\u4f55\u901a\u8fc7\u5f71\u54cdSG\u8c03\u5ea6\u95f4\u63a5\u5f71\u54cd\u77ed\u8def\u7535\u6d41(SCC)\u4f9b\u5e94\uff0c\u5e76\u5c06DR\u548cSCC\u7ea6\u675f\u7eb3\u5165\u673a\u7ec4\u7ec4\u5408\u6a21\u578b\u3002", "motivation": "\u968f\u7740IBR\u53d6\u4ee3SG\uff0c\u7cfb\u7edf\u77ed\u8def\u7535\u6d41\u6c34\u5e73\u4e0b\u964d\u53ef\u80fd\u5bfc\u81f4\u4fdd\u62a4\u88c5\u7f6e\u65e0\u6cd5\u6b63\u5e38\u52a8\u4f5c\u3002SG\u7684\u8c03\u5ea6\u4e0e\u7cfb\u7edf\u8d1f\u8377\u76f8\u5173\uff0c\u800cDR\u4f1a\u5f71\u54cd\u8d1f\u8377\uff0c\u4ece\u800c\u95f4\u63a5\u5f71\u54cdSCC\u4f9b\u5e94\uff0c\u8fd9\u79cd\u5173\u7cfb\u5c1a\u672a\u88ab\u7814\u7a76\u3002", "method": "\u5c06DR\u548cSCC\u7ea6\u675f\u7eb3\u5165\u673a\u7ec4\u7ec4\u5408\u6a21\u578b\uff0c\u5e76\u5728IEEE 30\u8282\u70b9\u7cfb\u7edf\u4e0a\u8fdb\u884c\u7814\u7a76\u3002", "result": "DR\u867d\u80fd\u901a\u8fc7\u964d\u4f4e\u7535\u529b\u9700\u6c42\u51cf\u5c11\u793e\u4f1a\u6210\u672c\uff0c\u4f46\u53ef\u80fd\u5bfc\u81f4SCC\u6c34\u5e73\u4e0d\u8db3\u3002\u5f53DR\u4e0eSCC\u7ea6\u675f\u7ed3\u5408\u65f6\uff0c\u6210\u672c\u4ec5\u589e\u52a00.3%\uff0c\u8868\u660eDR\u80fd\u4ee5\u7ecf\u6d4e\u6709\u6548\u7684\u65b9\u5f0f\u5e2e\u52a9\u5b9e\u73b0\u7cfb\u7edf\u7a33\u5b9a\u3002", "conclusion": "DR\u4e0d\u4ec5\u80fd\u964d\u4f4e\u793e\u4f1a\u6210\u672c\uff0c\u8fd8\u80fd\u4e0eSCC\u7ea6\u675f\u534f\u540c\u5de5\u4f5c\uff0c\u4ee5\u5f88\u5c0f\u7684\u989d\u5916\u6210\u672c\u5b9e\u73b0\u7cfb\u7edf\u7a33\u5b9a\u8fd0\u884c\u3002"}}
{"id": "2511.00259", "categories": ["cs.RO", "cs.ET", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.00259", "abs": "https://arxiv.org/abs/2511.00259", "authors": ["Andria J. Farrens", "Luis Garcia-Fernandez", "Raymond Diaz Rojas", "Jillian Obeso Estrada", "Dylan Reinsdorf", "Vicky Chan", "Disha Gupta", "Joel Perry", "Eric Wolbrecht", "An Do", "Steven C. Cramer", "David J. Reinkensmeyer"], "title": "Tailored robotic training improves hand function and proprioceptive processing in stroke survivors with proprioceptive deficits: A randomized controlled trial", "comment": "Main manuscript: 38 pages (double spaced, with references), 6\n  figures, 2 tables and collated supplemental materials (17 pages, double\n  spaced)", "summary": "Precision rehabilitation aims to tailor movement training to improve\noutcomes. We tested whether proprioceptively-tailored robotic training improves\nhand function and neural processing in stroke survivors. Using a robotic finger\nexoskeleton, we tested two proprioceptively-tailored approaches: Propriopixel\nTraining, which uses robot-facilitated, gamified movements to enhance\nproprioceptive processing, and Virtual Assistance Training, which reduces\nrobotic aid to increase reliance on self-generated feedback. In a randomized\ncontrolled trial, forty-six chronic stroke survivors completed nine 2-hour\nsessions of Standard, Propriopixel or Virtual training. Among participants with\nproprioceptive deficits, Propriopixel ((Box and Block Test: 7 +/- 4.2, p=0.002)\nand Virtual Assistance (4.5 +/- 4.4 , p=0.068) yielded greater gains in hand\nfunction (Standard: 0.8 +/- 2.3 blocks). Proprioceptive gains correlated with\nimprovements in hand function. Tailored training enhanced neural sensitivity to\nproprioceptive cues, evidenced by a novel EEG biomarker, the proprioceptive\nContingent Negative Variation. These findings support proprioceptively-tailored\ntraining as a pathway to precision neurorehabilitation.", "AI": {"tldr": "\u9488\u5bf9\u6709\u672c\u4f53\u611f\u89c9\u7f3a\u9677\u7684\u4e2d\u98ce\u60a3\u8005\uff0c\u672c\u4f53\u611f\u89c9\u5b9a\u5236\u7684\u673a\u5668\u4eba\u8bad\u7ec3\uff08\u7279\u522b\u662fPropriopixel\u8bad\u7ec3\uff09\u80fd\u663e\u8457\u6539\u5584\u624b\u90e8\u529f\u80fd\u548c\u795e\u7ecf\u5904\u7406\u80fd\u529b\u3002", "motivation": "\u7814\u7a76\u7cbe\u51c6\u5eb7\u590d\u65b9\u6cd5\uff0c\u901a\u8fc7\u672c\u4f53\u611f\u89c9\u5b9a\u5236\u7684\u8fd0\u52a8\u8bad\u7ec3\u6765\u6539\u5584\u4e2d\u98ce\u5e78\u5b58\u8005\u7684\u5eb7\u590d\u6548\u679c\u3002", "method": "\u4f7f\u7528\u673a\u5668\u4eba\u624b\u6307\u5916\u9aa8\u9abc\uff0c\u6d4b\u8bd5\u4e24\u79cd\u672c\u4f53\u611f\u89c9\u5b9a\u5236\u65b9\u6cd5\uff1aPropriopixel\u8bad\u7ec3\uff08\u901a\u8fc7\u6e38\u620f\u5316\u8fd0\u52a8\u589e\u5f3a\u672c\u4f53\u611f\u89c9\u5904\u7406\uff09\u548c\u865a\u62df\u8f85\u52a9\u8bad\u7ec3\uff08\u51cf\u5c11\u673a\u5668\u4eba\u8f85\u52a9\u4ee5\u589e\u52a0\u5bf9\u81ea\u6211\u53cd\u9988\u7684\u4f9d\u8d56\uff09\u300246\u540d\u6162\u6027\u4e2d\u98ce\u60a3\u8005\u968f\u673a\u63a5\u53d7\u6807\u51c6\u8bad\u7ec3\u3001Propriopixel\u8bad\u7ec3\u6216\u865a\u62df\u8bad\u7ec3\u3002", "result": "\u5728\u6709\u672c\u4f53\u611f\u89c9\u7f3a\u9677\u7684\u53c2\u4e0e\u8005\u4e2d\uff0cPropriopixel\u8bad\u7ec3\uff08Box and Block Test: 7\u00b14.2, p=0.002\uff09\u548c\u865a\u62df\u8f85\u52a9\u8bad\u7ec3\uff084.5\u00b14.4, p=0.068\uff09\u6bd4\u6807\u51c6\u8bad\u7ec3\uff080.8\u00b12.3\uff09\u5e26\u6765\u66f4\u5927\u7684\u624b\u529f\u80fd\u6539\u5584\u3002\u672c\u4f53\u611f\u89c9\u6539\u5584\u4e0e\u624b\u529f\u80fd\u6539\u5584\u76f8\u5173\u3002\u5b9a\u5236\u8bad\u7ec3\u589e\u5f3a\u4e86\u795e\u7ecf\u5bf9\u672c\u4f53\u611f\u89c9\u7ebf\u7d22\u7684\u654f\u611f\u6027\u3002", "conclusion": "\u672c\u4f53\u611f\u89c9\u5b9a\u5236\u7684\u8bad\u7ec3\u662f\u7cbe\u51c6\u795e\u7ecf\u5eb7\u590d\u7684\u6709\u6548\u9014\u5f84\uff0c\u80fd\u591f\u6539\u5584\u624b\u90e8\u529f\u80fd\u5e76\u589e\u5f3a\u795e\u7ecf\u5904\u7406\u80fd\u529b\u3002"}}
{"id": "2511.00027", "categories": ["cs.CY", "cs.AI", "cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.00027", "abs": "https://arxiv.org/abs/2511.00027", "authors": ["Josu Eguiluz Casta\u00f1eira", "Axel Brando", "Migle Laukyte", "Marc Serra-Vidal"], "title": "Position Paper: If Innovation in AI Systematically Violates Fundamental Rights, Is It Innovation at All?", "comment": "NeurIPS 2025 Position Paper track; accepted for oral and poster\n  presentation at the Thirty-Ninth Annual Conference on Neural Information\n  Processing Systems", "summary": "Artificial intelligence (AI) now permeates critical infrastructures and\ndecision-making systems where failures produce social, economic, and democratic\nharm. This position paper challenges the entrenched belief that regulation and\ninnovation are opposites. As evidenced by analogies from aviation,\npharmaceuticals, and welfare systems and recent cases of synthetic\nmisinformation, bias and unaccountable decision-making, the absence of\nwell-designed regulation has already created immeasurable damage. Regulation,\nwhen thoughtful and adaptive, is not a brake on innovation--it is its\nfoundation. The present position paper examines the EU AI Act as a model of\nrisk-based, responsibility-driven regulation that addresses the Collingridge\nDilemma: acting early enough to prevent harm, yet flexibly enough to sustain\ninnovation. Its adaptive mechanisms--regulatory sandboxes, small and medium\nenterprises (SMEs) support, real-world testing, fundamental rights impact\nassessment (FRIA) -- demonstrate how regulation can accelerate responsibly,\nrather than delay, technological progress. The position paper summarises how\ngovernance tools transform perceived burdens into tangible advantages: legal\ncertainty, consumer trust, and ethical competitiveness. Ultimately, the paper\nreframes progress: innovation and regulation advance together. By embedding\ntransparency, impact assessments, accountability, and AI literacy into design\nand deployment, the EU framework defines what responsible innovation truly\nmeans--technological ambition disciplined by democratic values and fundamental\nrights.", "AI": {"tldr": "\u8fd9\u7bc7\u7acb\u573a\u8bba\u6587\u6311\u6218\u4e86\u76d1\u7ba1\u4e0e\u521b\u65b0\u5bf9\u7acb\u7684\u4f20\u7edf\u89c2\u5ff5\uff0c\u8bba\u8bc1\u4e86\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u76d1\u7ba1\u662f\u8d1f\u8d23\u4efb\u521b\u65b0\u7684\u57fa\u7840\uff0c\u5e76\u4ee5\u6b27\u76dfAI\u6cd5\u6848\u4e3a\u4f8b\u8bf4\u660e\u98ce\u9669\u5bfc\u5411\u76d1\u7ba1\u5982\u4f55\u89e3\u51b3\u79d1\u6797\u91cc\u5947\u56f0\u5883\u3002", "motivation": "AI\u5df2\u6e17\u900f\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u548c\u51b3\u7b56\u7cfb\u7edf\uff0c\u5176\u5931\u8d25\u4f1a\u9020\u6210\u793e\u4f1a\u3001\u7ecf\u6d4e\u548c\u6c11\u4e3b\u5371\u5bb3\u3002\u4f5c\u8005\u65e8\u5728\u53cd\u9a73\u76d1\u7ba1\u963b\u788d\u521b\u65b0\u7684\u89c2\u70b9\uff0c\u8bc1\u660e\u7f3a\u4e4f\u826f\u597d\u76d1\u7ba1\u5df2\u9020\u6210\u4e0d\u53ef\u4f30\u91cf\u7684\u635f\u5bb3\u3002", "method": "\u901a\u8fc7\u822a\u7a7a\u3001\u5236\u836f\u548c\u798f\u5229\u7cfb\u7edf\u7684\u7c7b\u6bd4\uff0c\u4ee5\u53ca\u5408\u6210\u865a\u5047\u4fe1\u606f\u3001\u504f\u89c1\u548c\u4e0d\u53ef\u95ee\u8d23\u51b3\u7b56\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u5206\u6790\u6b27\u76dfAI\u6cd5\u6848\u4f5c\u4e3a\u98ce\u9669\u5bfc\u5411\u3001\u8d23\u4efb\u9a71\u52a8\u7684\u76d1\u7ba1\u6a21\u5f0f\u3002", "result": "\u6b27\u76dfAI\u6cd5\u6848\u7684\u9002\u5e94\u6027\u673a\u5236\uff08\u76d1\u7ba1\u6c99\u76d2\u3001\u4e2d\u5c0f\u4f01\u4e1a\u652f\u6301\u3001\u771f\u5b9e\u4e16\u754c\u6d4b\u8bd5\u3001\u57fa\u672c\u6743\u5229\u5f71\u54cd\u8bc4\u4f30\uff09\u8868\u660e\u76d1\u7ba1\u53ef\u4ee5\u8d1f\u8d23\u4efb\u5730\u52a0\u901f\u800c\u975e\u5ef6\u8fdf\u6280\u672f\u8fdb\u6b65\u3002", "conclusion": "\u521b\u65b0\u4e0e\u76d1\u7ba1\u5e94\u5171\u540c\u63a8\u8fdb\uff0c\u901a\u8fc7\u5c06\u900f\u660e\u5ea6\u3001\u5f71\u54cd\u8bc4\u4f30\u3001\u95ee\u8d23\u5236\u548cAI\u7d20\u517b\u5d4c\u5165\u8bbe\u8ba1\u548c\u90e8\u7f72\uff0c\u6b27\u76df\u6846\u67b6\u5b9a\u4e49\u4e86\u8d1f\u8d23\u4efb\u521b\u65b0\u7684\u771f\u6b63\u542b\u4e49\u2014\u2014\u53d7\u6c11\u4e3b\u4ef7\u503c\u89c2\u548c\u57fa\u672c\u6743\u5229\u7ea6\u675f\u7684\u6280\u672f\u96c4\u5fc3\u3002"}}
{"id": "2511.00867", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.00867", "abs": "https://arxiv.org/abs/2511.00867", "authors": ["Yassin Tesfaw Abebe", "Abdu Mohammed Seid", "Lassi Roininen", "Mohammed Seid Ali"], "title": "Spatiotemporal Dynamics of Conflict Occurrence and Fatalities in Ethiopia: A Bayesian Model and Predictive Insights Using Event-level Data (1997--2024)", "comment": null, "summary": "This study presents a spatiotemporal dual Bayesian model that examines both\nthe occurrence and number of conflict fatalities using event-level data from\nEthiopia (1997-2024), sourced from the Armed Conflict Location and Event Data\n(ACLED) project. Fatalities are treated as two linked outcomes: the binary\noccurrence of deaths and the count of deaths when they occur. The model\ncombines additive fixed effects for covariates with random effects capturing\nspatiotemporal influences, allowing for outcome-specific effects. Covariates\ninclude event type and season as categorical variables, proximity to cities and\nborders as nonlinear effects, and population as an offset term in the count\nmodel. A latent spatiotemporal process accounts for shared spatial and temporal\ndependence, with the spatial structure modeled using a Mat\\'ern field prior and\ninference via Integrated Nested Laplace Approximation (INLA). Results show\nstrong spatial clustering and temporal variation in fatality risk, emphasizing\nthe importance of modeling both dimensions for better understanding and\nprediction. Airstrikes, shelling, and attacks show the highest fatality\nlikelihood and counts, while communal and rebel actors cause the most deaths.\nMultiple fatalities are more likely in summer, and proximity to borders drives\nintense violence, whereas remoteness from urban centers is linked to\nlower-intensity events. These results provide insight for planning, policy, and\nresource allocation to protect vulnerable communities.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u65f6\u7a7a\u53cc\u8d1d\u53f6\u65af\u6a21\u578b\u5206\u6790\u57c3\u585e\u4fc4\u6bd4\u4e9a\u51b2\u7a81\u6b7b\u4ea1\u4e8b\u4ef6\uff0c\u5c06\u6b7b\u4ea1\u89c6\u4e3a\u4e8c\u5143\u53d1\u751f\u548c\u8ba1\u6570\u4e24\u4e2a\u5173\u8054\u7ed3\u679c\uff0c\u53d1\u73b0\u7a7a\u88ad\u3001\u70ae\u51fb\u548c\u653b\u51fb\u9020\u6210\u6700\u9ad8\u6b7b\u4ea1\u98ce\u9669\uff0c\u8fb9\u5883\u5730\u533a\u66b4\u529b\u66f4\u4e25\u91cd\u3002", "motivation": "\u9700\u8981\u66f4\u597d\u5730\u7406\u89e3\u51b2\u7a81\u6b7b\u4ea1\u4e8b\u4ef6\u7684\u7a7a\u95f4\u548c\u65f6\u95f4\u6a21\u5f0f\uff0c\u4e3a\u4fdd\u62a4\u8106\u5f31\u793e\u533a\u7684\u653f\u7b56\u89c4\u5212\u548c\u8d44\u6e90\u5206\u914d\u63d0\u4f9b\u4f9d\u636e\u3002", "method": "\u4f7f\u7528\u65f6\u7a7a\u53cc\u8d1d\u53f6\u65af\u6a21\u578b\uff0c\u7ed3\u5408\u56fa\u5b9a\u6548\u5e94\u548c\u968f\u673a\u6548\u5e94\uff0c\u901a\u8fc7Mat\u00e9rn\u573a\u5148\u9a8c\u548cINLA\u65b9\u6cd5\u8fdb\u884c\u63a8\u65ad\uff0c\u5206\u6790\u4e8b\u4ef6\u7c7b\u578b\u3001\u5b63\u8282\u3001\u8ddd\u79bb\u57ce\u5e02\u548c\u8fb9\u5883\u7b49\u534f\u53d8\u91cf\u3002", "result": "\u7ed3\u679c\u663e\u793a\u5f3a\u70c8\u7684\u7a7a\u95f4\u805a\u96c6\u6027\u548c\u65f6\u95f4\u53d8\u5f02\u6027\uff0c\u7a7a\u88ad\u3001\u70ae\u51fb\u548c\u653b\u51fb\u5bfc\u81f4\u6700\u9ad8\u6b7b\u4ea1\u53ef\u80fd\u6027\u548c\u6570\u91cf\uff0c\u590f\u5b63\u591a\u53d1\u6b7b\u4ea1\u4e8b\u4ef6\uff0c\u8fb9\u5883\u5730\u533a\u66b4\u529b\u66f4\u4e25\u91cd\u3002", "conclusion": "\u540c\u65f6\u5efa\u6a21\u7a7a\u95f4\u548c\u65f6\u95f4\u7ef4\u5ea6\u5bf9\u4e8e\u66f4\u597d\u7406\u89e3\u548c\u9884\u6d4b\u51b2\u7a81\u6b7b\u4ea1\u98ce\u9669\u81f3\u5173\u91cd\u8981\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u4fdd\u62a4\u8106\u5f31\u793e\u533a\u7684\u89c4\u5212\u3001\u653f\u7b56\u548c\u8d44\u6e90\u5206\u914d\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2511.00048", "categories": ["cs.AI", "cs.CY", "62-11", "E.5; G.3; I.6.4; I.6.6; J.3; J.4"], "pdf": "https://arxiv.org/pdf/2511.00048", "abs": "https://arxiv.org/abs/2511.00048", "authors": ["Martin Bicher", "Maximilian Viehauser", "Daniele Giannandrea", "Hannah Kastinger", "Dominik Brunmeir", "Claire Rippinger", "Christoph Urach", "Niki Popper"], "title": "GEPOC Parameters - Open Source Parametrisation and Validation for Austria, Version 2.0", "comment": "134 pages, 75 figures, 19 tables", "summary": "GEPOC, short for Generic Population Concept, is a collection of models and\nmethods for analysing population-level research questions. For the valid\napplication of the models for a specific country or region, stable and\nreproducible data processes are necessary, which provide valid and ready-to-use\nmodel parameters. This work contains a complete description of the\ndata-processing methods for computation of model parameters for Austria, based\nexclusively on freely and publicly accessible data. In addition to the\ndescription of the source data used, this includes all algorithms used for\naggregation, disaggregation, fusion, cleansing or scaling of the data, as well\nas a description of the resulting parameter files. The document places\nparticular emphasis on the computation of parameters for the most important\nGEPOC model, GEPOC ABM, a continuous-time agent-based population model. An\nextensive validation study using this particular model was made and is\npresented at the end of this work.", "AI": {"tldr": "GEPOC\u662f\u4e00\u4e2a\u901a\u7528\u4eba\u53e3\u6982\u5ff5\u6a21\u578b\u96c6\uff0c\u672c\u6587\u63cf\u8ff0\u4e86\u4e3a\u5965\u5730\u5229\u8ba1\u7b97GEPOC\u6a21\u578b\u53c2\u6570\u7684\u5b8c\u6574\u6570\u636e\u5904\u7406\u65b9\u6cd5\uff0c\u57fa\u4e8e\u516c\u5f00\u53ef\u83b7\u53d6\u6570\u636e\uff0c\u7279\u522b\u5173\u6ce8GEPOC ABM\u4ee3\u7406\u6a21\u578b\u7684\u53c2\u6570\u8ba1\u7b97\u548c\u9a8c\u8bc1\u3002", "motivation": "\u4e3aGEPOC\u6a21\u578b\u5728\u7279\u5b9a\u56fd\u5bb6\u6216\u5730\u533a\u7684\u6709\u6548\u5e94\u7528\u63d0\u4f9b\u7a33\u5b9a\u3001\u53ef\u590d\u73b0\u7684\u6570\u636e\u5904\u7406\u6d41\u7a0b\uff0c\u786e\u4fdd\u6a21\u578b\u53c2\u6570\u7684\u6709\u6548\u6027\u548c\u53ef\u7528\u6027\u3002", "method": "\u57fa\u4e8e\u516c\u5f00\u53ef\u83b7\u53d6\u6570\u636e\uff0c\u4f7f\u7528\u805a\u5408\u3001\u5206\u89e3\u3001\u878d\u5408\u3001\u6e05\u6d17\u548c\u7f29\u653e\u7b49\u7b97\u6cd5\u5904\u7406\u6570\u636e\uff0c\u8ba1\u7b97GEPOC\u6a21\u578b\u53c2\u6570\uff0c\u7279\u522b\u5173\u6ce8GEPOC ABM\u4ee3\u7406\u6a21\u578b\u7684\u53c2\u6570\u8ba1\u7b97\u3002", "result": "\u5f00\u53d1\u4e86\u5b8c\u6574\u7684\u53c2\u6570\u8ba1\u7b97\u6d41\u7a0b\uff0c\u751f\u6210\u4e86\u53ef\u76f4\u63a5\u4f7f\u7528\u7684\u6a21\u578b\u53c2\u6570\u6587\u4ef6\uff0c\u5e76\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u9a8c\u8bc1\u7814\u7a76\u3002", "conclusion": "\u6210\u529f\u5efa\u7acb\u4e86\u57fa\u4e8e\u516c\u5f00\u6570\u636e\u7684GEPOC\u6a21\u578b\u53c2\u6570\u8ba1\u7b97\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e3aGEPOC\u6a21\u578b\u5728\u5965\u5730\u5229\u7b49\u5730\u533a\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6570\u636e\u57fa\u7840\u3002"}}
{"id": "2511.00041", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00041", "abs": "https://arxiv.org/abs/2511.00041", "authors": ["Yingzhao Jian", "Zhongan Wang", "Yi Yang", "Hehe Fan"], "title": "Endowing GPT-4 with a Humanoid Body: Building the Bridge Between Off-the-Shelf VLMs and the Physical World", "comment": null, "summary": "Humanoid agents often struggle to handle flexible and diverse interactions in\nopen environments. A common solution is to collect massive datasets to train a\nhighly capable model, but this approach can be prohibitively expensive. In this\npaper, we explore an alternative solution: empowering off-the-shelf\nVision-Language Models (VLMs, such as GPT-4) to control humanoid agents,\nthereby leveraging their strong open-world generalization to mitigate the need\nfor extensive data collection. To this end, we present \\textbf{BiBo}\n(\\textbf{B}uilding humano\\textbf{I}d agent \\textbf{B}y \\textbf{O}ff-the-shelf\nVLMs). It consists of two key components: (1) an \\textbf{embodied instruction\ncompiler}, which enables the VLM to perceive the environment and precisely\ntranslate high-level user instructions (e.g., {\\small\\itshape ``have a rest''})\ninto low-level primitive commands with control parameters (e.g.,\n{\\small\\itshape ``sit casually, location: (1, 2), facing: 90$^\\circ$''}); and\n(2) a diffusion-based \\textbf{motion executor}, which generates human-like\nmotions from these commands, while dynamically adapting to physical feedback\nfrom the environment. In this way, BiBo is capable of handling not only basic\ninteractions but also diverse and complex motions. Experiments demonstrate that\nBiBo achieves an interaction task success rate of 90.2\\% in open environments,\nand improves the precision of text-guided motion execution by 16.3\\% over prior\nmethods. The code will be made publicly available.", "AI": {"tldr": "BiBo\u6846\u67b6\u5229\u7528\u73b0\u6210\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63a7\u5236\u4eba\u5f62\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u6307\u4ee4\u7f16\u8bd1\u5668\u548c\u8fd0\u52a8\u6267\u884c\u5668\u5b9e\u73b0\u5f00\u653e\u73af\u5883\u4e2d\u7684\u591a\u6837\u5316\u4ea4\u4e92\uff0c\u65e0\u9700\u5927\u91cf\u6570\u636e\u6536\u96c6\u3002", "motivation": "\u89e3\u51b3\u4eba\u5f62\u667a\u80fd\u4f53\u5728\u5f00\u653e\u73af\u5883\u4e2d\u5904\u7406\u7075\u6d3b\u591a\u6837\u4ea4\u4e92\u7684\u56f0\u96be\uff0c\u907f\u514d\u6602\u8d35\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u6536\u96c6\u9700\u6c42\u3002", "method": "\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u5177\u8eab\u6307\u4ee4\u7f16\u8bd1\u5668\uff0c\u5c06\u9ad8\u7ea7\u7528\u6237\u6307\u4ee4\u8f6c\u6362\u4e3a\u4f4e\u7ea7\u539f\u59cb\u547d\u4ee4\uff1b2) \u57fa\u4e8e\u6269\u6563\u7684\u8fd0\u52a8\u6267\u884c\u5668\uff0c\u751f\u6210\u62df\u4eba\u5316\u8fd0\u52a8\u5e76\u9002\u5e94\u73af\u5883\u7269\u7406\u53cd\u9988\u3002", "result": "\u5728\u5f00\u653e\u73af\u5883\u4e2d\u5b9e\u73b090.2%\u7684\u4ea4\u4e92\u4efb\u52a1\u6210\u529f\u7387\uff0c\u6587\u672c\u5f15\u5bfc\u8fd0\u52a8\u6267\u884c\u7cbe\u5ea6\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u9ad816.3%\u3002", "conclusion": "BiBo\u6846\u67b6\u6210\u529f\u5229\u7528\u73b0\u6210VLM\u7684\u5f3a\u5927\u6cdb\u5316\u80fd\u529b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4eba\u5f62\u667a\u80fd\u4f53\u5728\u5f00\u653e\u73af\u5883\u4e2d\u7684\u4ea4\u4e92\u6311\u6218\uff0c\u65e0\u9700\u6602\u8d35\u7684\u6570\u636e\u6536\u96c6\u3002"}}
{"id": "2511.00660", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2511.00660", "abs": "https://arxiv.org/abs/2511.00660", "authors": ["Antti J. Tanskanen"], "title": "A rich life cycle model of labor supply in Finland", "comment": null, "summary": "A life cycle model of consumption and labor supply describes employment\ndecisions of a collection of individuals during their lifetime. We develop a\nlife cycle model describing a heterogeneous population operating in Finland\nunder a wide variety of employment states and life situations. A rich life\ncycle model requires a large state space representing the possible states of\nsimulated agents. The results demonstrate that the model reproduces a number of\nstatistics of the Finnish employment market such as the age structures of\nemployment rate and unemployment rate, distributions of observed effective\nmarginal tax rates and participating tax rates, and proportion of part time\nwork. As an application of analysis of a reform, we analyze how the program of\nOrpo government influences employment and public finances in Finland.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u82ac\u5170\u52b3\u52a8\u529b\u5e02\u573a\u7684\u751f\u547d\u5468\u671f\u6a21\u578b\uff0c\u6a21\u62df\u4e2a\u4f53\u5728\u4e0d\u540c\u5c31\u4e1a\u72b6\u6001\u4e0b\u7684\u51b3\u7b56\uff0c\u5e76\u5e94\u7528\u4e8e\u5206\u6790\u653f\u5e9c\u6539\u9769\u5bf9\u5c31\u4e1a\u548c\u516c\u5171\u8d22\u653f\u7684\u5f71\u54cd\u3002", "motivation": "\u6784\u5efa\u4e00\u4e2a\u80fd\u591f\u63cf\u8ff0\u82ac\u5170\u5f02\u8d28\u4eba\u53e3\u5728\u5404\u79cd\u5c31\u4e1a\u72b6\u6001\u548c\u751f\u6d3b\u60c5\u5883\u4e0b\u51b3\u7b56\u7684\u751f\u547d\u5468\u671f\u6a21\u578b\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u52b3\u52a8\u529b\u5e02\u573a\u52a8\u6001\u3002", "method": "\u4f7f\u7528\u751f\u547d\u5468\u671f\u6a21\u578b\uff0c\u5efa\u7acb\u5305\u542b\u5927\u91cf\u72b6\u6001\u7a7a\u95f4\u7684\u6a21\u62df\u7cfb\u7edf\uff0c\u4ee3\u8868\u6a21\u62df\u4ee3\u7406\u4eba\u7684\u53ef\u80fd\u72b6\u6001\uff0c\u5e94\u7528\u4e8e\u82ac\u5170\u5c31\u4e1a\u5e02\u573a\u5206\u6790\u3002", "result": "\u6a21\u578b\u6210\u529f\u590d\u73b0\u4e86\u82ac\u5170\u5c31\u4e1a\u5e02\u573a\u7684\u591a\u9879\u7edf\u8ba1\u6570\u636e\uff0c\u5305\u62ec\u5c31\u4e1a\u7387\u548c\u5931\u4e1a\u7387\u7684\u5e74\u9f84\u7ed3\u6784\u3001\u6709\u6548\u8fb9\u9645\u7a0e\u7387\u5206\u5e03\u3001\u53c2\u4e0e\u7a0e\u7387\u5206\u5e03\u4ee5\u53ca\u517c\u804c\u5de5\u4f5c\u6bd4\u4f8b\u3002", "conclusion": "\u8be5\u751f\u547d\u5468\u671f\u6a21\u578b\u80fd\u591f\u6709\u6548\u6a21\u62df\u82ac\u5170\u52b3\u52a8\u529b\u5e02\u573a\uff0c\u5e76\u53ef\u7528\u4e8e\u5206\u6790\u653f\u5e9c\u653f\u7b56\u6539\u9769\u5bf9\u5c31\u4e1a\u548c\u516c\u5171\u8d22\u653f\u7684\u5f71\u54cd\u3002"}}
{"id": "2511.00478", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2511.00478", "abs": "https://arxiv.org/abs/2511.00478", "authors": ["Robert M. Anderson", "Haosui Duanmu", "M. Ali Khan", "Metin Uyanik"], "title": "Existence of Equilibria in Large Competitive Markets with Bads, Production and Comprehensive Externalities", "comment": null, "summary": "This paper establishes the existence of equilibrium in an economy with\nproduction and a continuum of consumers, each of whose incomplete and\nprice-dependent preferences are defined on commodities they may consider\ndeleterious, bads which cannot be freely disposed of, and each of whom takes\ninto account the productions of all firms and the consumptions of all other\nconsumers. This result has proved elusive since Hara (2005) presented an\nexample of an atomless measure-theoretic exchange economy with bads (but no\nexternalities) that has no equilibrium. The result circumvents Hara's example\nby showing that, in the presence of bads and externalities, natural economic\nconsiderations imply an integrable bound on the consumption of bads. The proofs\nmake an essential use of nonstandard analysis, and the novel techniques we\noffer to handle comprehensive externalities expressed as an equivalence class\nof integrable functions may be of independent methodological interest.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u5728\u751f\u4ea7\u7ecf\u6d4e\u4e2d\uff0c\u5b58\u5728\u5177\u6709\u6709\u5bb3\u5546\u54c1\u3001\u5916\u90e8\u6027\u548c\u4e0d\u5b8c\u5168\u4ef7\u683c\u4f9d\u8d56\u504f\u597d\u7684\u5747\u8861\uff0c\u514b\u670d\u4e86Hara(2005)\u7684\u53cd\u4f8b\u3002", "motivation": "Hara(2005)\u5c55\u793a\u4e86\u5728\u65e0\u5916\u90e8\u6027\u7684\u539f\u5b50\u6d4b\u5ea6\u4ea4\u6362\u7ecf\u6d4e\u4e2d\uff0c\u6709\u5bb3\u5546\u54c1\u53ef\u80fd\u5bfc\u81f4\u5747\u8861\u4e0d\u5b58\u5728\u3002\u672c\u6587\u65e8\u5728\u8bc1\u660e\u5728\u5b58\u5728\u5916\u90e8\u6027\u548c\u6709\u5bb3\u5546\u54c1\u7684\u60c5\u51b5\u4e0b\uff0c\u5747\u8861\u4ecd\u7136\u5b58\u5728\u3002", "method": "\u4f7f\u7528\u975e\u6807\u51c6\u5206\u6790\u6280\u672f\uff0c\u901a\u8fc7\u81ea\u7136\u7ecf\u6d4e\u8003\u8651\u63a8\u5bfc\u51fa\u6709\u5bb3\u5546\u54c1\u6d88\u8d39\u7684\u53ef\u79ef\u8fb9\u754c\uff0c\u5e76\u5904\u7406\u4f5c\u4e3a\u53ef\u79ef\u51fd\u6570\u7b49\u4ef7\u7c7b\u7684\u5168\u9762\u5916\u90e8\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u751f\u4ea7\u7ecf\u6d4e\u4e2d\uff0c\u5373\u4f7f\u5b58\u5728\u6709\u5bb3\u5546\u54c1\u3001\u5916\u90e8\u6027\u548c\u4e0d\u5b8c\u5168\u4ef7\u683c\u4f9d\u8d56\u504f\u597d\uff0c\u5747\u8861\u4ecd\u7136\u5b58\u5728\u3002", "conclusion": "\u901a\u8fc7\u975e\u6807\u51c6\u5206\u6790\u548c\u5904\u7406\u5916\u90e8\u6027\u7684\u65b0\u6280\u672f\uff0c\u6210\u529f\u8bc1\u660e\u4e86\u5728\u66f4\u73b0\u5b9e\u7684\u7ecf\u6d4e\u8bbe\u5b9a\u4e0b\u5747\u8861\u7684\u5b58\u5728\u6027\uff0c\u4e3a\u76f8\u5173\u7406\u8bba\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2511.00768", "categories": ["cs.SI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00768", "abs": "https://arxiv.org/abs/2511.00768", "authors": ["Peiru Wu", "Maojun Zhai", "Lingzhu Zhang"], "title": "A Framework Based on Graph Cellular Automata for Similarity Evaluation in Urban Spatial Networks", "comment": null, "summary": "Measuring similarity in urban spatial networks is key to understanding cities\nas complex systems. Yet most existing methods are not tailored for spatial\nnetworks and struggle to differentiate them effectively. We propose GCA-Sim, a\nsimilarity-evaluation framework based on graph cellular automata. Each submodel\nmeasures similarity by the divergence between value distributions recorded at\nmultiple stages of an information evolution process. We find that some\npropagation rules magnify differences among network signals; we call this\n\"network resonance.\" With an improved differentiable logic-gate network, we\nlearn several submodels that induce network resonance. We evaluate similarity\nthrough clustering performance on fifty city-level and fifty district-level\nroad networks. The submodels in this framework outperform existing methods,\nwith Silhouette scores above 0.9. Using the best submodel, we further observe\nthat planning-led street networks are less internally homogeneous than\norganically grown ones; morphological categories from different domains\ncontribute with comparable importance; and degree, as a basic topological\nsignal, becomes increasingly aligned with land value and related variables over\niterations.", "AI": {"tldr": "\u63d0\u51fa\u4e86GCA-Sim\u6846\u67b6\uff0c\u57fa\u4e8e\u56fe\u5143\u80de\u81ea\u52a8\u673a\u8bc4\u4f30\u57ce\u5e02\u7a7a\u95f4\u7f51\u7edc\u76f8\u4f3c\u6027\uff0c\u901a\u8fc7\u4fe1\u606f\u6f14\u5316\u8fc7\u7a0b\u4e2d\u7684\u5206\u5e03\u5dee\u5f02\u6765\u6d4b\u91cf\u76f8\u4f3c\u5ea6\uff0c\u53d1\u73b0\u4e86\u7f51\u7edc\u5171\u632f\u73b0\u8c61\uff0c\u5728\u9053\u8def\u7f51\u7edc\u805a\u7c7b\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5927\u591a\u4e0d\u9002\u7528\u4e8e\u7a7a\u95f4\u7f51\u7edc\uff0c\u96be\u4ee5\u6709\u6548\u533a\u5206\u57ce\u5e02\u7a7a\u95f4\u7f51\u7edc\u7684\u76f8\u4f3c\u6027\uff0c\u9700\u8981\u4e13\u95e8\u9488\u5bf9\u7a7a\u95f4\u7f51\u7edc\u7279\u70b9\u7684\u76f8\u4f3c\u6027\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u56fe\u5143\u80de\u81ea\u52a8\u673a\u6846\u67b6\uff0c\u6bcf\u4e2a\u5b50\u6a21\u578b\u901a\u8fc7\u4fe1\u606f\u6f14\u5316\u8fc7\u7a0b\u4e2d\u591a\u4e2a\u9636\u6bb5\u8bb0\u5f55\u7684\u503c\u5206\u5e03\u5dee\u5f02\u6765\u6d4b\u91cf\u76f8\u4f3c\u5ea6\uff0c\u91c7\u7528\u6539\u8fdb\u7684\u53ef\u5fae\u5206\u903b\u8f91\u95e8\u7f51\u7edc\u5b66\u4e60\u80fd\u8bf1\u5bfc\u7f51\u7edc\u5171\u632f\u7684\u5b50\u6a21\u578b\u3002", "result": "\u572850\u4e2a\u57ce\u5e02\u7ea7\u548c50\u4e2a\u533a\u7ea7\u9053\u8def\u7f51\u7edc\u4e0a\u8fdb\u884c\u805a\u7c7b\u8bc4\u4f30\uff0c\u8be5\u6846\u67b6\u7684\u5b50\u6a21\u578b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8f6e\u5ed3\u7cfb\u6570\u8d85\u8fc70.9\uff1b\u53d1\u73b0\u89c4\u5212\u4e3b\u5bfc\u7684\u8857\u9053\u7f51\u7edc\u5185\u90e8\u540c\u8d28\u6027\u4f4e\u4e8e\u6709\u673a\u751f\u957f\u7684\u7f51\u7edc\uff0c\u4e0d\u540c\u9886\u57df\u7684\u5f62\u6001\u7c7b\u522b\u8d21\u732e\u76f8\u5f53\uff0c\u5ea6\u4f5c\u4e3a\u57fa\u672c\u62d3\u6251\u4fe1\u53f7\u5728\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\u4e0e\u571f\u5730\u4ef7\u503c\u7b49\u53d8\u91cf\u8d8a\u6765\u8d8a\u5bf9\u9f50\u3002", "conclusion": "GCA-Sim\u6846\u67b6\u80fd\u6709\u6548\u8bc4\u4f30\u57ce\u5e02\u7a7a\u95f4\u7f51\u7edc\u76f8\u4f3c\u6027\uff0c\u7f51\u7edc\u5171\u632f\u73b0\u8c61\u80fd\u653e\u5927\u7f51\u7edc\u4fe1\u53f7\u5dee\u5f02\uff0c\u8be5\u6846\u67b6\u5728\u57ce\u5e02\u5f62\u6001\u5206\u6790\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.00297", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.00297", "abs": "https://arxiv.org/abs/2511.00297", "authors": ["Linhan Fang", "Xingpeng Li"], "title": "Optimal BESS Sizing and Placement for Mitigating EV-Induced Voltage Violations: A Scalable Spatio-Temporal Adaptive Targeting Strategy", "comment": null, "summary": "The escalating adoption of electric vehicles (EVs) and the growing demand for\ncharging solutions are driving a surge in EV charger installations in\ndistribution networks. However, this rising EV load strains the distribution\ngrid, causing severe voltage drops, particularly at feeder extremities. This\nstudy proposes a proactive voltage management (PVM) framework that can\nintegrate Monte Carlo-based simulations of varying EV charging loads to (i)\nidentify potential voltage violations through a voltage violation analysis\n(VVA) model, and (ii) then mitigate those violations with optimally-invested\nbattery energy storage systems (BESS) through an optimal expansion planning\n(OEP) model. A novel spatio-temporal adaptive targeting (STAT) strategy is\nproposed to alleviate the computational complexity of the OEP model by defining\na targeted OEP (T-OEP) model, solved by applying the OEP model to (i) a reduced\nset of representative critical time periods and (ii) candidate BESS\ninstallation nodes. The efficacy and scalability of the proposed approach are\nvalidated on 33-bus, 69-bus, and a large-scale 240-bus system. Results\ndemonstrate that the strategic sizing and placement of BESS not only\neffectively mitigate voltage violations but also yield substantial cost savings\non electricity purchases under time-of-use tariffs. This research offers a\ncost-effective and scalable solution for integrating high penetrations of EVs,\nproviding crucial insights for future distribution network planning.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4e3b\u52a8\u7535\u538b\u7ba1\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6a21\u62df\u8bc6\u522b\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u5bfc\u81f4\u7684\u7535\u538b\u8fdd\u89c4\uff0c\u5e76\u4f7f\u7528\u7535\u6c60\u50a8\u80fd\u7cfb\u7edf\u8fdb\u884c\u4f18\u5316\u7f13\u89e3\uff0c\u91c7\u7528\u65f6\u7a7a\u81ea\u9002\u5e94\u7b56\u7565\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u8d1f\u8377\u6fc0\u589e\u5bfc\u81f4\u914d\u7535\u7f51\u7535\u538b\u4e0b\u964d\uff0c\u7279\u522b\u662f\u5728\u9988\u7ebf\u672b\u7aef\uff0c\u9700\u8981\u6709\u6548\u7684\u7535\u538b\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u6a21\u62df\u7684\u7535\u538b\u8fdd\u89c4\u5206\u6790\u6a21\u578b\u548c\u6700\u4f18\u6269\u5c55\u89c4\u5212\u6a21\u578b\uff0c\u63d0\u51fa\u65f6\u7a7a\u81ea\u9002\u5e94\u76ee\u6807\u7b56\u7565\u6765\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u572833\u300169\u548c240\u8282\u70b9\u7cfb\u7edf\u9a8c\u8bc1\u6709\u6548\uff0cBESS\u7684\u6218\u7565\u914d\u7f6e\u4e0d\u4ec5\u80fd\u7f13\u89e3\u7535\u538b\u8fdd\u89c4\uff0c\u8fd8\u80fd\u5728\u5206\u65f6\u7535\u4ef7\u4e0b\u8282\u7701\u5927\u91cf\u7535\u8d39\u3002", "conclusion": "\u4e3a\u9ad8\u6e17\u900f\u7387\u7535\u52a8\u6c7d\u8f66\u96c6\u6210\u63d0\u4f9b\u4e86\u7ecf\u6d4e\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u672a\u6765\u914d\u7535\u7f51\u89c4\u5212\u63d0\u4f9b\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2511.00061", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.00061", "abs": "https://arxiv.org/abs/2511.00061", "authors": ["Stephen Alaba John", "Joye Ahmed Shonubi", "Patience Farida Azuikpe", "Victor Oluwatosin Ologun"], "title": "Adoption of AI-Driven Fraud Detection System in the Nigerian Banking Sector: An Analysis of Cost, Compliance, and Competency", "comment": "Keyword: Artificial intelligence, fraud detection, regulatory\n  compliance, staff competency, cost implementation, banking sector, Nigeria", "summary": "The inception of AI-based fraud detection systems has presented the banking\nsector across the globe the opportunity to enhance fraud prevention mechanisms.\nHowever, the extent of adoption in Nigeria has been slow, fragmented, and\ninconsistent due to high cost of implementation and lack of technical\nexpertise. This study seeks to investigate extent of adoption and determinants\nof AI-driven fraud detection systems in Nigerian banks. This study adopted a\ncross-sectional survey research design. Data were extracted from primary\nsources through structured questionnaire based on 5-point Likert scale. The\npopulation of the study consist of 24 licensed banks in Nigeria. A purposive\nsampling technique was used to select 5 biggest banks based on market\ncapitalization and customer base. The Ordered Logistic Regression (OLR) model\nwas used to estimate the data. The results showed that top management support,\nIT infrastructure, regulatory compliance, staff competency and perceived\neffectiveness accelerate the uptake of AI-driven fraud detection systems\nadoption. However, high implementation cost discourages it. Therefore, the\nstudy recommended that banks should invest in modern and scalable IT systems\nthat support the integration of AI tools; adopt open-source or cloud-based AI\nplatforms that are cost-effective; embrace continuous professional development\nin AI, and fraud analytics for IT, fraud investigation, and risk management\nstaff.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8c03\u67e5\u4e86\u5c3c\u65e5\u5229\u4e9a\u94f6\u884c\u91c7\u7528AI\u9a71\u52a8\u6b3a\u8bc8\u68c0\u6d4b\u7cfb\u7edf\u7684\u7a0b\u5ea6\u548c\u51b3\u5b9a\u56e0\u7d20\uff0c\u53d1\u73b0\u9ad8\u5c42\u7ba1\u7406\u652f\u6301\u3001IT\u57fa\u7840\u8bbe\u65bd\u3001\u76d1\u7ba1\u5408\u89c4\u3001\u5458\u5de5\u80fd\u529b\u548c\u611f\u77e5\u6709\u6548\u6027\u4fc3\u8fdb\u91c7\u7528\uff0c\u800c\u9ad8\u5b9e\u65bd\u6210\u672c\u963b\u788d\u91c7\u7528\u3002", "motivation": "AI\u6b3a\u8bc8\u68c0\u6d4b\u7cfb\u7edf\u5728\u5168\u7403\u94f6\u884c\u4e1a\u5f97\u5230\u5e94\u7528\uff0c\u4f46\u5728\u5c3c\u65e5\u5229\u4e9a\u7684\u91c7\u7528\u7f13\u6162\u3001\u5206\u6563\u4e14\u4e0d\u4e00\u81f4\uff0c\u4e3b\u8981\u7531\u4e8e\u9ad8\u5b9e\u65bd\u6210\u672c\u548c\u6280\u672f\u4e13\u4e1a\u77e5\u8bc6\u7f3a\u4e4f\u3002", "method": "\u91c7\u7528\u6a2a\u65ad\u9762\u8c03\u67e5\u7814\u7a76\u8bbe\u8ba1\uff0c\u901a\u8fc7\u57fa\u4e8e5\u70b9\u674e\u514b\u7279\u91cf\u8868\u7684\u7ed3\u6784\u5316\u95ee\u5377\u6536\u96c6\u4e3b\u8981\u6570\u636e\uff0c\u4f7f\u7528\u6709\u5e8f\u903b\u8f91\u56de\u5f52\u6a21\u578b\u5206\u6790\u6765\u81ea5\u5bb6\u6700\u5927\u94f6\u884c\u7684\u6570\u636e\u3002", "result": "\u7ed3\u679c\u663e\u793a\u9ad8\u5c42\u7ba1\u7406\u652f\u6301\u3001IT\u57fa\u7840\u8bbe\u65bd\u3001\u76d1\u7ba1\u5408\u89c4\u3001\u5458\u5de5\u80fd\u529b\u548c\u611f\u77e5\u6709\u6548\u6027\u52a0\u901fAI\u9a71\u52a8\u6b3a\u8bc8\u68c0\u6d4b\u7cfb\u7edf\u7684\u91c7\u7528\uff0c\u800c\u9ad8\u5b9e\u65bd\u6210\u672c\u5219\u963b\u788d\u91c7\u7528\u3002", "conclusion": "\u5efa\u8bae\u94f6\u884c\u6295\u8d44\u652f\u6301AI\u5de5\u5177\u96c6\u6210\u7684\u73b0\u4ee3\u53ef\u6269\u5c55IT\u7cfb\u7edf\uff0c\u91c7\u7528\u6210\u672c\u6548\u76ca\u9ad8\u7684\u5f00\u6e90\u6216\u4e91AI\u5e73\u53f0\uff0c\u5e76\u4e3aIT\u3001\u6b3a\u8bc8\u8c03\u67e5\u548c\u98ce\u9669\u7ba1\u7406\u5458\u5de5\u63d0\u4f9bAI\u548c\u6b3a\u8bc8\u5206\u6790\u7684\u6301\u7eed\u4e13\u4e1a\u53d1\u5c55\u3002"}}
{"id": "2511.01607", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.01607", "abs": "https://arxiv.org/abs/2511.01607", "authors": ["Rolando Gonzales Martinez", "Hinke Haisma"], "title": "The Multidimensional Index of Child Growth (MICG) of the Task Force \"Towards a Multidimensional Approach for Child Growth\" of the International Union for Nutrition Sciences", "comment": null, "summary": "Children's growth extends beyond height and weight. This paper introduces the\nMultidimensional Index of Child Growth (MICG), developed by the IUNS Task Force\n\"Towards a Multidimensional Approach for Child Growth.\" The IUNS-MICG applies a\ncapability- and rights-based framework covering 14 dimensions of child\nwellbeing, including health, care, mental wellbeing, participation, autonomy,\nmobility, and safety. Using data from the Young Lives Study in Ethiopia, India,\nPeru, and Vietnam, we tested the framework with 29 indicators. Comparisons of\ndifferent weighting methods show that equal weights provide robust and\npolicy-relevant results. MICG uncovers deprivations hidden by physical measures\nalone; for instance, rural girls in Peru face educational and mental wellbeing\ndisadvantages despite similar physical growth. Further analyses show that\ncommunity participation in WASH programs is linked to higher multidimensional\noutcomes, especially for the most deprived. We also extend MICG with a Bayesian\napproach to estimate children's unrealized opportunities and propose a\nspiderweb growth chart for visualizing multidimensional progress. MICG offers a\npractical, equity-focused tool to monitor, evaluate, and strengthen\ninterventions that support the Sustainable Development Goals and ensure no\nchild is left behind.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u591a\u7ef4\u513f\u7ae5\u6210\u957f\u6307\u6570(MICG)\uff0c\u91c7\u7528\u80fd\u529b\u4e0e\u6743\u5229\u6846\u67b6\u8bc4\u4f30\u513f\u7ae5\u798f\u7949\u768414\u4e2a\u7ef4\u5ea6\uff0c\u901a\u8fc7\u5b9e\u8bc1\u6570\u636e\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5e76\u5f00\u53d1\u4e86\u53ef\u89c6\u5316\u5de5\u5177\u548c\u653f\u7b56\u5e94\u7528\u3002", "motivation": "\u4f20\u7edf\u513f\u7ae5\u6210\u957f\u6307\u6807\u4ec5\u5173\u6ce8\u8eab\u9ad8\u4f53\u91cd\u7b49\u7269\u7406\u6307\u6807\uff0c\u65e0\u6cd5\u5168\u9762\u53cd\u6620\u513f\u7ae5\u798f\u7949\u3002\u9700\u8981\u5f00\u53d1\u66f4\u5168\u9762\u7684\u591a\u7ef4\u8bc4\u4f30\u6846\u67b6\u6765\u63ed\u793a\u9690\u85cf\u7684\u5265\u593a\u95ee\u9898\u3002", "method": "\u91c7\u7528\u80fd\u529b\u4e0e\u6743\u5229\u6846\u67b6\uff0c\u6db5\u76d6\u5065\u5eb7\u3001\u7167\u6599\u3001\u5fc3\u7406\u5065\u5eb7\u3001\u53c2\u4e0e\u3001\u81ea\u4e3b\u6743\u7b4914\u4e2a\u7ef4\u5ea6\uff0c\u4f7f\u752829\u4e2a\u6307\u6807\uff0c\u6bd4\u8f83\u4e0d\u540c\u52a0\u6743\u65b9\u6cd5\uff0c\u5e76\u5e94\u7528\u8d1d\u53f6\u65af\u65b9\u6cd5\u4f30\u8ba1\u672a\u5b9e\u73b0\u7684\u673a\u4f1a\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5e73\u7b49\u52a0\u6743\u65b9\u6cd5\u63d0\u4f9b\u7a33\u5065\u4e14\u653f\u7b56\u76f8\u5173\u7684\u7ed3\u679c\uff1bMICG\u80fd\u63ed\u793a\u7269\u7406\u6307\u6807\u65e0\u6cd5\u53d1\u73b0\u7684\u5265\u593a\u95ee\u9898\uff1b\u793e\u533a\u53c2\u4e0eWASH\u9879\u76ee\u4e0e\u591a\u7ef4\u7ed3\u679c\u6539\u5584\u76f8\u5173\uff1b\u5f00\u53d1\u4e86\u8718\u86db\u7f51\u6210\u957f\u56fe\u8fdb\u884c\u53ef\u89c6\u5316\u3002", "conclusion": "MICG\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u3001\u5173\u6ce8\u516c\u5e73\u7684\u5de5\u5177\uff0c\u53ef\u7528\u4e8e\u76d1\u6d4b\u3001\u8bc4\u4f30\u548c\u52a0\u5f3a\u652f\u6301\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\u7684\u5e72\u9884\u63aa\u65bd\uff0c\u786e\u4fdd\u4e0d\u8ba9\u4efb\u4f55\u513f\u7ae5\u6389\u961f\u3002"}}
{"id": "2511.00092", "categories": ["cs.AI", "cs.CL", "cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.00092", "abs": "https://arxiv.org/abs/2511.00092", "authors": ["Shunya Minami", "Tatsuya Ishigaki", "Ikko Hamamura", "Taku Mikuriya", "Youmi Ma", "Naoaki Okazaki", "Hiroya Takamura", "Yohichi Suzuki", "Tadashi Kadowaki"], "title": "QuantumBench: A Benchmark for Quantum Problem Solving", "comment": "11 pages, 8 figures", "summary": "Large language models are now integrated into many scientific workflows,\naccelerating data analysis, hypothesis generation, and design space\nexploration. In parallel with this growth, there is a growing need to carefully\nevaluate whether models accurately capture domain-specific knowledge and\nnotation, since general-purpose benchmarks rarely reflect these requirements.\nThis gap is especially clear in quantum science, which features non-intuitive\nphenomena and requires advanced mathematics. In this study, we introduce\nQuantumBench, a benchmark for the quantum domain that systematically examine\nhow well LLMs understand and can be applied to this non-intuitive field. Using\npublicly available materials, we compiled approximately 800 questions with\ntheir answers spanning nine areas related to quantum science and organized them\ninto an eight-option multiple-choice dataset. With this benchmark, we evaluate\nseveral existing LLMs and analyze their performance in the quantum domain,\nincluding sensitivity to changes in question format. QuantumBench is the first\nLLM evaluation dataset built for the quantum domain, and it is intended to\nguide the effective use of LLMs in quantum research.", "AI": {"tldr": "QuantumBench\u662f\u9996\u4e2a\u9488\u5bf9\u91cf\u5b50\u79d1\u5b66\u9886\u57df\u7684LLM\u8bc4\u4f30\u57fa\u51c6\uff0c\u5305\u542b\u7ea6800\u4e2a\u9009\u62e9\u9898\uff0c\u6db5\u76d69\u4e2a\u91cf\u5b50\u79d1\u5b66\u9886\u57df\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u91cf\u5b50\u9886\u57df\u7684\u7406\u89e3\u548c\u5e94\u7528\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u901a\u7528\u57fa\u51c6\u96be\u4ee5\u51c6\u786e\u8bc4\u4f30LLM\u5728\u91cf\u5b50\u79d1\u5b66\u7b49\u4e13\u4e1a\u9886\u57df\u7684\u77e5\u8bc6\u638c\u63e1\u60c5\u51b5\uff0c\u91cf\u5b50\u79d1\u5b66\u5177\u6709\u975e\u76f4\u89c2\u73b0\u8c61\u548c\u9ad8\u7ea7\u6570\u5b66\u8981\u6c42\uff0c\u9700\u8981\u4e13\u95e8\u7684\u8bc4\u4f30\u5de5\u5177\u3002", "method": "\u4f7f\u7528\u516c\u5f00\u6750\u6599\u7f16\u5236\u7ea6800\u4e2a\u9009\u62e9\u9898\uff0c\u6db5\u76d69\u4e2a\u91cf\u5b50\u79d1\u5b66\u9886\u57df\uff0c\u7ec4\u7ec7\u62108\u9009\u9879\u591a\u9009\u9898\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u591a\u4e2a\u73b0\u6709LLM\u5e76\u5206\u6790\u5176\u5bf9\u95ee\u9898\u683c\u5f0f\u53d8\u5316\u7684\u654f\u611f\u6027\u3002", "result": "\u901a\u8fc7QuantumBench\u8bc4\u4f30\u4e86\u591a\u4e2aLLM\u5728\u91cf\u5b50\u9886\u57df\u7684\u8868\u73b0\uff0c\u5305\u62ec\u5bf9\u95ee\u9898\u683c\u5f0f\u53d8\u5316\u7684\u654f\u611f\u6027\u5206\u6790\u3002", "conclusion": "QuantumBench\u662f\u9996\u4e2a\u91cf\u5b50\u9886\u57df\u7684LLM\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u65e8\u5728\u6307\u5bfcLLM\u5728\u91cf\u5b50\u7814\u7a76\u4e2d\u7684\u6709\u6548\u5e94\u7528\u3002"}}
{"id": "2511.00088", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00088", "abs": "https://arxiv.org/abs/2511.00088", "authors": ["NVIDIA", ":", "Yan Wang", "Wenjie Luo", "Junjie Bai", "Yulong Cao", "Tong Che", "Ke Chen", "Yuxiao Chen", "Jenna Diamond", "Yifan Ding", "Wenhao Ding", "Liang Feng", "Greg Heinrich", "Jack Huang", "Peter Karkus", "Boyi Li", "Pinyi Li", "Tsung-Yi Lin", "Dongran Liu", "Ming-Yu Liu", "Langechuan Liu", "Zhijian Liu", "Jason Lu", "Yunxiang Mao", "Pavlo Molchanov", "Lindsey Pavao", "Zhenghao Peng", "Mike Ranzinger", "Ed Schmerling", "Shida Shen", "Yunfei Shi", "Sarah Tariq", "Ran Tian", "Tilman Wekel", "Xinshuo Weng", "Tianjun Xiao", "Eric Yang", "Xiaodong Yang", "Yurong You", "Xiaohui Zeng", "Wenyuan Zhang", "Boris Ivanovic", "Marco Pavone"], "title": "Alpamayo-R1: Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving in the Long Tail", "comment": null, "summary": "End-to-end architectures trained via imitation learning have advanced\nautonomous driving by scaling model size and data, yet performance remains\nbrittle in safety-critical long-tail scenarios where supervision is sparse and\ncausal understanding is limited. To address this, we introduce Alpamayo-R1\n(AR1), a vision-language-action model (VLA) that integrates Chain of Causation\nreasoning with trajectory planning to enhance decision-making in complex\ndriving scenarios. Our approach features three key innovations: (1) the Chain\nof Causation (CoC) dataset, built through a hybrid auto-labeling and\nhuman-in-the-loop pipeline producing decision-grounded, causally linked\nreasoning traces aligned with driving behaviors; (2) a modular VLA architecture\ncombining Cosmos-Reason, a Vision-Language Model pre-trained for Physical AI\napplications, with a diffusion-based trajectory decoder that generates\ndynamically feasible plans in real time; (3) a multi-stage training strategy\nusing supervised fine-tuning to elicit reasoning and reinforcement learning\n(RL) to optimize reasoning quality via large reasoning model feedback and\nenforce reasoning-action consistency. Evaluation shows AR1 achieves up to a 12%\nimprovement in planning accuracy on challenging cases compared to a\ntrajectory-only baseline, with a 35% reduction in off-road rate and 25%\nreduction in close encounter rate in closed-loop simulation. RL post-training\nimproves reasoning quality by 45% as measured by a large reasoning model critic\nand reasoning-action consistency by 37%. Model scaling from 0.5B to 7B\nparameters shows consistent improvements. On-vehicle road tests confirm\nreal-time performance (99 ms latency) and successful urban deployment. By\nbridging interpretable reasoning with precise control, AR1 demonstrates a\npractical path towards Level 4 autonomous driving. We plan to release AR1\nmodels and a subset of the CoC in a future update.", "AI": {"tldr": "AR1\u662f\u4e00\u4e2a\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\uff0c\u901a\u8fc7\u56e0\u679c\u94fe\u63a8\u7406\u4e0e\u8f68\u8ff9\u89c4\u5212\u76f8\u7ed3\u5408\uff0c\u63d0\u5347\u590d\u6742\u9a7e\u9a76\u573a\u666f\u4e2d\u7684\u51b3\u7b56\u80fd\u529b\uff0c\u5728\u89c4\u5212\u51c6\u786e\u6027\u3001\u79bb\u9053\u7387\u548c\u8fd1\u8ddd\u79bb\u63a5\u89e6\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4ec5\u57fa\u4e8e\u8f68\u8ff9\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u7aef\u5230\u7aef\u6a21\u4eff\u5b66\u4e60\u5728\u5b89\u5168\u5173\u952e\u7684\u957f\u5c3e\u573a\u666f\u4e2d\u6027\u80fd\u8106\u5f31\u7684\u95ee\u9898\uff0c\u8fd9\u4e9b\u573a\u666f\u4e2d\u76d1\u7763\u7a00\u758f\u4e14\u56e0\u679c\u7406\u89e3\u6709\u9650\u3002", "method": "1) \u6784\u5efa\u56e0\u679c\u94fe\u6570\u636e\u96c6\uff1b2) \u91c7\u7528\u6a21\u5757\u5316VLA\u67b6\u6784\uff0c\u7ed3\u5408\u9884\u8bad\u7ec3\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548c\u57fa\u4e8e\u6269\u6563\u7684\u8f68\u8ff9\u89e3\u7801\u5668\uff1b3) \u4f7f\u7528\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u591a\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u5728\u6311\u6218\u6027\u6848\u4f8b\u4e2d\u89c4\u5212\u51c6\u786e\u6027\u63d0\u534712%\uff0c\u95ed\u73af\u6a21\u62df\u4e2d\u79bb\u9053\u7387\u964d\u4f4e35%\uff0c\u8fd1\u8ddd\u79bb\u63a5\u89e6\u7387\u964d\u4f4e25%\uff1b\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u4f7f\u63a8\u7406\u8d28\u91cf\u63d0\u534745%\uff0c\u63a8\u7406-\u884c\u52a8\u4e00\u81f4\u6027\u63d0\u534737%\u3002", "conclusion": "AR1\u901a\u8fc7\u5c06\u53ef\u89e3\u91ca\u63a8\u7406\u4e0e\u7cbe\u786e\u63a7\u5236\u76f8\u7ed3\u5408\uff0c\u5c55\u793a\u4e86\u5b9e\u73b0L4\u7ea7\u81ea\u52a8\u9a7e\u9a76\u7684\u53ef\u884c\u8def\u5f84\uff0c\u5e76\u5728\u5b9e\u9645\u9053\u8def\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u5b9e\u65f6\u6027\u80fd\u3002"}}
{"id": "2511.00935", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2511.00935", "abs": "https://arxiv.org/abs/2511.00935", "authors": ["Akhil Rao"], "title": "Public Infrastructure Investments for Space Market Development", "comment": "Working paper version", "summary": "Advanced space technology systems often face high fixed costs, can serve\nlimited non-government demand, and are significantly driven by non-market\nmotivations. While increased entrepreneurial activity and national ambitions in\nspace have encouraged planners at public space agencies to develop markets\naround such systems, the very factors that make the recent growth of the space\neconomy so remarkable also challenge planners' efforts to develop and sustain\nmarkets for space-related goods and services. I propose a graphical framework\nto visualize the number of competitors a market can sustain as a function of\nthe industry's cost structure; the distribution of government support across\ndirect purchases, direct investments, and shared infrastructure; and the\nmagnitude of non-government demand. Building on public goods theory, the\nframework shows how marginal dollars invested in shared infrastructure can\ncreate non-rival benefits supporting more competitors per dollar than direct\npurchases or subsidies. I demonstrate the framework with a stylized application\ninspired by NASA's Commercial LEO Destinations program. Under cost and demand\nconditions consistent with public data, independent stations generate\nindustry-wide losses of $355 million annually, while shared core infrastructure\nenables industry-wide profits of $154 million annually. I also outline key\ndirections for future research on public investment and market development\nstrategies for advanced technologies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u56fe\u5f62\u5316\u6846\u67b6\u6765\u5206\u6790\u592a\u7a7a\u6280\u672f\u5e02\u573a\u7684\u53ef\u6301\u7eed\u7ade\u4e89\u89c4\u6a21\uff0c\u57fa\u4e8e\u6210\u672c\u7ed3\u6784\u3001\u653f\u5e9c\u652f\u6301\u65b9\u5f0f\u548c\u9700\u6c42\u5206\u5e03\uff0c\u53d1\u73b0\u5171\u4eab\u57fa\u7840\u8bbe\u65bd\u6295\u8d44\u6bd4\u76f4\u63a5\u91c7\u8d2d\u6216\u8865\u8d34\u66f4\u80fd\u6709\u6548\u652f\u6301\u5e02\u573a\u7ade\u4e89\u3002", "motivation": "\u592a\u7a7a\u6280\u672f\u7cfb\u7edf\u9762\u4e34\u9ad8\u56fa\u5b9a\u6210\u672c\u3001\u6709\u9650\u975e\u653f\u5e9c\u9700\u6c42\u548c\u5f3a\u70c8\u7684\u975e\u5e02\u573a\u52a8\u673a\uff0c\u516c\u5171\u673a\u6784\u5728\u5f00\u53d1\u5e02\u573a\u65f6\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u66f4\u597d\u7684\u5206\u6790\u5de5\u5177\u6765\u6307\u5bfc\u6295\u8d44\u51b3\u7b56\u3002", "method": "\u57fa\u4e8e\u516c\u5171\u7269\u54c1\u7406\u8bba\u6784\u5efa\u56fe\u5f62\u5316\u6846\u67b6\uff0c\u5206\u6790\u6210\u672c\u7ed3\u6784\u3001\u653f\u5e9c\u652f\u6301\uff08\u76f4\u63a5\u91c7\u8d2d\u3001\u76f4\u63a5\u6295\u8d44\u3001\u5171\u4eab\u57fa\u7840\u8bbe\u65bd\uff09\u548c\u975e\u653f\u5e9c\u9700\u6c42\u5bf9\u5e02\u573a\u7ade\u4e89\u89c4\u6a21\u7684\u5f71\u54cd\uff0c\u5e76\u901a\u8fc7NASA\u5546\u4e1aLEO\u76ee\u7684\u5730\u9879\u76ee\u7684\u6848\u4f8b\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5728\u7b26\u5408\u516c\u5f00\u6570\u636e\u7684\u6210\u672c\u548c\u9700\u6c42\u6761\u4ef6\u4e0b\uff0c\u72ec\u7acb\u7a7a\u95f4\u7ad9\u6bcf\u5e74\u4ea7\u751f3.55\u4ebf\u7f8e\u5143\u884c\u4e1a\u635f\u5931\uff0c\u800c\u5171\u4eab\u6838\u5fc3\u57fa\u7840\u8bbe\u65bd\u6bcf\u5e74\u53ef\u5b9e\u73b01.54\u4ebf\u7f8e\u5143\u884c\u4e1a\u5229\u6da6\u3002", "conclusion": "\u5171\u4eab\u57fa\u7840\u8bbe\u65bd\u6295\u8d44\u6bd4\u4f20\u7edf\u652f\u6301\u65b9\u5f0f\u66f4\u6709\u6548\uff0c\u8fb9\u9645\u7f8e\u5143\u6295\u8d44\u4e8e\u5171\u4eab\u57fa\u7840\u8bbe\u65bd\u80fd\u521b\u9020\u975e\u7ade\u4e89\u6027\u6536\u76ca\uff0c\u6bcf\u7f8e\u5143\u652f\u6301\u66f4\u591a\u7ade\u4e89\u8005\uff0c\u4e3a\u5148\u8fdb\u6280\u672f\u7684\u516c\u5171\u6295\u8d44\u548c\u5e02\u573a\u5f00\u53d1\u7b56\u7565\u63d0\u4f9b\u4e86\u91cd\u8981\u6d1e\u89c1\u3002"}}
{"id": "2511.00715", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2511.00715", "abs": "https://arxiv.org/abs/2511.00715", "authors": ["Samuel H\u00e4fner", "Marek Pycia", "Haoyuan Zeng"], "title": "Mechanism Design with Information Leakage", "comment": null, "summary": "We study the design of mechanisms -- e.g., auctions -- when the designer does\nnot control information flows between mechanism participants. A mechanism\nequilibrium is leakage-proof if no player conditions their actions on leaked\ninformation; a property distinct from ex-post incentive compatibility. Only\nleakage-proof mechanisms can implement social choice functions in environments\nwith leakage. Efficient auctions need to be leakage-proof, while\nrevenue-maximizing ones not necessarily so. Second-price and ascending auctions\nare leakage-proof; first-price auctions are not; while whether descending\nauctions are leakage-proof depends on tie-breaking.", "AI": {"tldr": "\u7814\u7a76\u673a\u5236\u8bbe\u8ba1\uff08\u5982\u62cd\u5356\uff09\u5728\u4fe1\u606f\u6cc4\u9732\u73af\u5883\u4e0b\u7684\u7279\u6027\uff0c\u63d0\u51fa\u9632\u6cc4\u6f0f\u673a\u5236\u7684\u6982\u5ff5\uff0c\u5206\u6790\u4e0d\u540c\u62cd\u5356\u673a\u5236\u5728\u4fe1\u606f\u6cc4\u9732\u4e0b\u7684\u8868\u73b0\u3002", "motivation": "\u4f20\u7edf\u673a\u5236\u8bbe\u8ba1\u5047\u8bbe\u8bbe\u8ba1\u8005\u80fd\u63a7\u5236\u4fe1\u606f\u6d41\uff0c\u4f46\u73b0\u5b9e\u4e2d\u53c2\u4e0e\u8005\u4e4b\u95f4\u53ef\u80fd\u5b58\u5728\u4fe1\u606f\u6cc4\u9732\u3002\u9700\u8981\u7814\u7a76\u5f53\u8bbe\u8ba1\u8005\u65e0\u6cd5\u63a7\u5236\u4fe1\u606f\u6d41\u52a8\u65f6\uff0c\u673a\u5236\u5e94\u5177\u5907\u7684\u7279\u6027\u3002", "method": "\u63d0\u51fa\u9632\u6cc4\u6f0f\u673a\u5236\u7684\u6982\u5ff5\uff0c\u5b9a\u4e49\u4e3a\u53c2\u4e0e\u8005\u4e0d\u4f1a\u57fa\u4e8e\u6cc4\u9732\u4fe1\u606f\u8c03\u6574\u884c\u4e3a\u7684\u673a\u5236\u3002\u5206\u6790\u4e0d\u540c\u7c7b\u578b\u62cd\u5356\u673a\u5236\uff08\u7b2c\u4e8c\u4ef7\u683c\u3001\u5347\u4ef7\u3001\u7b2c\u4e00\u4ef7\u683c\u3001\u964d\u4ef7\u62cd\u5356\uff09\u5728\u4fe1\u606f\u6cc4\u9732\u73af\u5883\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u53d1\u73b0\u6709\u6548\u7387\u7684\u62cd\u5356\u9700\u8981\u662f\u9632\u6cc4\u6f0f\u7684\uff0c\u800c\u6536\u76ca\u6700\u5927\u5316\u7684\u62cd\u5356\u4e0d\u4e00\u5b9a\u9700\u8981\u3002\u7b2c\u4e8c\u4ef7\u683c\u62cd\u5356\u548c\u5347\u4ef7\u62cd\u5356\u662f\u9632\u6cc4\u6f0f\u7684\uff0c\u7b2c\u4e00\u4ef7\u683c\u62cd\u5356\u4e0d\u662f\uff0c\u964d\u4ef7\u62cd\u5356\u662f\u5426\u9632\u6cc4\u6f0f\u53d6\u51b3\u4e8e\u5e73\u5c40\u5904\u7406\u89c4\u5219\u3002", "conclusion": "\u9632\u6cc4\u6f0f\u6027\u662f\u673a\u5236\u8bbe\u8ba1\u5728\u4fe1\u606f\u6cc4\u9732\u73af\u5883\u4e2d\u7684\u91cd\u8981\u7279\u6027\uff0c\u4e0e\u4e8b\u540e\u6fc0\u52b1\u76f8\u5bb9\u6027\u4e0d\u540c\u3002\u53ea\u6709\u9632\u6cc4\u6f0f\u673a\u5236\u624d\u80fd\u5728\u5b58\u5728\u4fe1\u606f\u6cc4\u9732\u7684\u73af\u5883\u4e2d\u5b9e\u73b0\u793e\u4f1a\u9009\u62e9\u51fd\u6570\u3002"}}
{"id": "2511.00818", "categories": ["cs.SI", "q-bio.OT"], "pdf": "https://arxiv.org/pdf/2511.00818", "abs": "https://arxiv.org/abs/2511.00818", "authors": ["Lingyao Li", "Zhijie Duan", "Xuexin Li", "Xiaoran Xu", "Zhaoqian Xue", "Siyuan Ma", "Jin Jin"], "title": "Deciphering Scientific Collaboration in Biomedical LLM Research: Dynamics, Institutional Participation, and Resource Disparities", "comment": null, "summary": "Large language models (LLMs) are increasingly transforming biomedical\ndiscovery and clinical innovation, yet their impact extends far beyond\nalgorithmic revolution-LLMs are restructuring how scientific collaboration\noccurs, who participates, and how resources shape innovation. Despite this\nprofound transformation, how this rapid technological shift is reshaping the\nstructure and equity of scientific collaboration in biomedical LLM research\nremains largely unknown. By analyzing 5,674 LLM-related biomedical publications\nfrom PubMed, we examine how collaboration diversity evolves over time, identify\ninstitutions and disciplines that anchor and bridge collaboration networks, and\nassess how resource disparities underpin research performance. We find that\ncollaboration diversity has grown steadily, with a decreasing share of Computer\nScience and Artificial Intelligence authors, suggesting that LLMs are lowering\ntechnical barriers for biomedical investigators. Network analysis reveals\ncentral institutions, including Stanford University and Harvard Medical School,\nand bridging disciplines such as Medicine and Computer Science that anchor\ncollaborations in this field. Furthermore, biomedical research resources are\nstrongly linked to research performance, with high-performing\nresource-constrained institutions exhibiting larger collaboration volume with\nthe top 1% most connected institutions in the network. Together, these findings\nreveal a complex landscape, where democratizing trends coexist with a\npersistent, resource-driven hierarchy, highlighting the critical role of\nstrategic collaboration in this evolving field.", "AI": {"tldr": "\u5206\u6790574\u7bc7\u751f\u7269\u533b\u5b66LLM\u8bba\u6587\u53d1\u73b0\uff1a\u5408\u4f5c\u591a\u6837\u6027\u589e\u52a0\uff0c\u6280\u672f\u95e8\u69db\u964d\u4f4e\uff0c\u4f46\u8d44\u6e90\u4e0d\u5e73\u7b49\u6301\u7eed\u5b58\u5728\uff0c\u5f62\u6210\u6c11\u4e3b\u5316\u8d8b\u52bf\u4e0e\u8d44\u6e90\u9a71\u52a8\u7b49\u7ea7\u5e76\u5b58\u7684\u590d\u6742\u683c\u5c40", "motivation": "\u7814\u7a76LLM\u6280\u672f\u5982\u4f55\u91cd\u5851\u751f\u7269\u533b\u5b66\u79d1\u5b66\u5408\u4f5c\u7684\u7ed3\u6784\u4e0e\u516c\u5e73\u6027\uff0c\u4e86\u89e3\u8fd9\u4e00\u5feb\u901f\u6280\u672f\u53d8\u9769\u5bf9\u5408\u4f5c\u7f51\u7edc\u7684\u5f71\u54cd", "method": "\u5206\u6790PubMed\u4e2d5,674\u7bc7LLM\u76f8\u5173\u751f\u7269\u533b\u5b66\u51fa\u7248\u7269\uff0c\u8bc4\u4f30\u5408\u4f5c\u591a\u6837\u6027\u6f14\u53d8\u3001\u8bc6\u522b\u5173\u952e\u673a\u6784\u548c\u5b66\u79d1\u3001\u8bc4\u4f30\u8d44\u6e90\u5dee\u5f02\u5bf9\u7814\u7a76\u8868\u73b0\u7684\u5f71\u54cd", "result": "\u5408\u4f5c\u591a\u6837\u6027\u7a33\u6b65\u589e\u957f\uff0c\u8ba1\u7b97\u673a\u79d1\u5b66\u4f5c\u8005\u6bd4\u4f8b\u4e0b\u964d\uff1b\u65af\u5766\u798f\u5927\u5b66\u548c\u54c8\u4f5b\u533b\u5b66\u9662\u7b49\u673a\u6784\u5904\u4e8e\u7f51\u7edc\u4e2d\u5fc3\uff1b\u533b\u5b66\u4e0e\u8ba1\u7b97\u673a\u79d1\u5b66\u662f\u6865\u6881\u5b66\u79d1\uff1b\u8d44\u6e90\u4e0e\u7814\u7a76\u6210\u679c\u5f3a\u76f8\u5173\uff0c\u8d44\u6e90\u53d7\u9650\u7684\u9ad8\u7ee9\u6548\u673a\u6784\u66f4\u503e\u5411\u4e0e\u9876\u7ea7\u673a\u6784\u5408\u4f5c", "conclusion": "\u751f\u7269\u533b\u5b66LLM\u7814\u7a76\u5448\u73b0\u6c11\u4e3b\u5316\u8d8b\u52bf\u4e0e\u8d44\u6e90\u9a71\u52a8\u7b49\u7ea7\u5e76\u5b58\u7684\u590d\u6742\u5c40\u9762\uff0c\u6218\u7565\u5408\u4f5c\u5728\u8fd9\u4e00\u6f14\u53d8\u9886\u57df\u4e2d\u53d1\u6325\u5173\u952e\u4f5c\u7528"}}
{"id": "2511.00337", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.00337", "abs": "https://arxiv.org/abs/2511.00337", "authors": ["Adil Rasheed", "Oscar Ravik", "Omer San"], "title": "Large Language Models for Control", "comment": null, "summary": "This paper investigates using large language models (LLMs) to generate\ncontrol actions directly, without requiring control-engineering expertise or\nhand-tuned algorithms. We implement several variants: (i) prompt-only, (ii)\ntool-assisted with access to historical data, and (iii) prediction-assisted\nusing learned or simple models to score candidate actions. We compare them on\ntracking accuracy and actuation effort, with and without a prompt that requests\nlower actuator usage. Results show prompt-only LLMs already produce viable\ncontrol, while tool-augmented versions adapt better to changing objectives but\ncan be more sensitive to constraints, supporting LLM-in-the-loop control for\nevolving cyber-physical systems today and operator and human inputs.", "AI": {"tldr": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u76f4\u63a5\u751f\u6210\u63a7\u5236\u52a8\u4f5c\uff0c\u65e0\u9700\u63a7\u5236\u5de5\u7a0b\u4e13\u4e1a\u77e5\u8bc6\u6216\u624b\u52a8\u8c03\u4f18\u7b97\u6cd5\u3002\u6bd4\u8f83\u4e86\u4e09\u79cd\u53d8\u4f53\uff1a\u4ec5\u63d0\u793a\u3001\u5de5\u5177\u8f85\u52a9\u548c\u5386\u53f2\u6570\u636e\u8bbf\u95ee\u3001\u9884\u6d4b\u8f85\u52a9\u4f7f\u7528\u5b66\u4e60\u6216\u7b80\u5355\u6a21\u578b\u8bc4\u5206\u5019\u9009\u52a8\u4f5c\u3002", "motivation": "\u63a2\u7d22\u5229\u7528LLMs\u76f4\u63a5\u751f\u6210\u63a7\u5236\u52a8\u4f5c\uff0c\u907f\u514d\u4f20\u7edf\u63a7\u5236\u65b9\u6cd5\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u548c\u624b\u52a8\u8c03\u4f18\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u66f4\u7075\u6d3b\u7684\u63a7\u5236\u7cfb\u7edf\u3002", "method": "\u5b9e\u73b0\u4e09\u79cdLLM\u63a7\u5236\u53d8\u4f53\uff1a(i)\u4ec5\u63d0\u793a\uff0c(ii)\u5de5\u5177\u8f85\u52a9\u8bbf\u95ee\u5386\u53f2\u6570\u636e\uff0c(iii)\u9884\u6d4b\u8f85\u52a9\u4f7f\u7528\u5b66\u4e60\u6216\u7b80\u5355\u6a21\u578b\u8bc4\u5206\u5019\u9009\u52a8\u4f5c\u3002\u6bd4\u8f83\u8ddf\u8e2a\u7cbe\u5ea6\u548c\u6267\u884c\u5668\u52aa\u529b\uff0c\u6d4b\u8bd5\u6709\u65e0\u964d\u4f4e\u6267\u884c\u5668\u4f7f\u7528\u63d0\u793a\u7684\u60c5\u51b5\u3002", "result": "\u4ec5\u63d0\u793a\u7684LLMs\u5df2\u80fd\u4ea7\u751f\u53ef\u884c\u7684\u63a7\u5236\uff0c\u800c\u5de5\u5177\u589e\u5f3a\u7248\u672c\u80fd\u66f4\u597d\u5730\u9002\u5e94\u53d8\u5316\u7684\u76ee\u6807\u4f46\u5bf9\u7ea6\u675f\u66f4\u654f\u611f\u3002", "conclusion": "\u652f\u6301LLM\u5728\u73af\u63a7\u5236\u7528\u4e8e\u4e0d\u65ad\u53d1\u5c55\u7684\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\uff0c\u4ee5\u53ca\u64cd\u4f5c\u5458\u548c\u4eba\u7c7b\u8f93\u5165\u3002"}}
{"id": "2511.00077", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.00077", "abs": "https://arxiv.org/abs/2511.00077", "authors": ["Jannatul Shefa", "Taylan G. Topcu"], "title": "What is the Return on Investment of Digital Engineering for Complex Systems Development? Findings from a Mixed-Methods Study on the Post-production Design Change Process of Navy Assets", "comment": null, "summary": "Complex engineered systems routinely face schedule and cost overruns, along\nwith poor post-deployment performance. Championed by both INCOSE and the U.S.\nDepartment of Defense (DoD), the systems engineering (SE) community has\nincreasingly looked to Digital Engineering (DE) as a potential remedy. Despite\nthis growing advocacy, most of DE's purported benefits remain anecdotal, and\nits return on investment (ROI) remains poorly understood. This research\npresents findings from a case study on a Navy SE team responsible for the\npreliminary design phase of post-production design change projects for Navy\nassets. Using a mixed-methods approach, we document why complex system\nsustainment projects are routinely late, where and to what extent schedule\nslips arise, and how a DE transformation could improve schedule adherence. This\nstudy makes three contributions. First, it identifies four archetypical\ninefficiency modes that drive schedule overruns and explains how these\nmechanisms unfold in their organizational context. Second, it quantifies the\nmagnitude and variation of schedule slips. Third, it creates a hypothetical\ndigitally transformed version of the current process, aligned with DoD DE\npolicy, and compares it to the current state to estimate potential schedule\ngains. Our findings suggest that a DE transformation could reduce the median\nproject duration by 50.1% and reduce the standard deviation by 41.5%, leading\nto faster and more predictable timelines. However, the observed gains are not\nuniform across task categories. Overall, this study provides initial\nquantitative evidence of DE's potential ROI and its value in improving the\nefficiency and predictability of complex system sustainment projects.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u53d1\u73b0\u6570\u5b57\u5de5\u7a0b\u8f6c\u578b\u53ef\u5c06\u6d77\u519b\u7cfb\u7edf\u7ef4\u62a4\u9879\u76ee\u7684\u4e2d\u4f4d\u5de5\u671f\u7f29\u77ed50.1%\uff0c\u6807\u51c6\u5dee\u51cf\u5c1141.5%\uff0c\u63d0\u9ad8\u9879\u76ee\u65f6\u95f4\u53ef\u9884\u6d4b\u6027\u3002", "motivation": "\u590d\u6742\u5de5\u7a0b\u7cfb\u7edf\u666e\u904d\u5b58\u5728\u8fdb\u5ea6\u548c\u6210\u672c\u8d85\u652f\u95ee\u9898\uff0c\u6570\u5b57\u5de5\u7a0b\u88ab\u5bc4\u4e88\u539a\u671b\u4f46\u7f3a\u4e4f\u91cf\u5316\u8bc1\u636e\u652f\u6301\u5176\u6295\u8d44\u56de\u62a5\u7387\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\u6d77\u519b\u7cfb\u7edf\u7ef4\u62a4\u56e2\u961f\u7684\u521d\u6b65\u8bbe\u8ba1\u9636\u6bb5\uff0c\u5206\u6790\u8fdb\u5ea6\u5ef6\u8bef\u539f\u56e0\uff0c\u5e76\u521b\u5efa\u6570\u5b57\u5de5\u7a0b\u8f6c\u578b\u540e\u7684\u5047\u8bbe\u6d41\u7a0b\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u8bc6\u522b\u51fa\u56db\u79cd\u5178\u578b\u7684\u4f4e\u6548\u6a21\u5f0f\uff0c\u91cf\u5316\u4e86\u8fdb\u5ea6\u5ef6\u8bef\u7684\u7a0b\u5ea6\u548c\u53d8\u5316\uff0c\u6570\u5b57\u5de5\u7a0b\u8f6c\u578b\u53ef\u663e\u8457\u7f29\u77ed\u9879\u76ee\u5468\u671f\u5e76\u63d0\u9ad8\u53ef\u9884\u6d4b\u6027\u3002", "conclusion": "\u7814\u7a76\u9996\u6b21\u4e3a\u6570\u5b57\u5de5\u7a0b\u7684\u6295\u8d44\u56de\u62a5\u7387\u63d0\u4f9b\u4e86\u91cf\u5316\u8bc1\u636e\uff0c\u8bc1\u660e\u5176\u5728\u63d0\u9ad8\u590d\u6742\u7cfb\u7edf\u7ef4\u62a4\u9879\u76ee\u6548\u7387\u548c\u53ef\u9884\u6d4b\u6027\u65b9\u9762\u7684\u4ef7\u503c\u3002"}}
{"id": "2511.01732", "categories": ["stat.AP", "q-bio.QM", "stat.OT"], "pdf": "https://arxiv.org/pdf/2511.01732", "abs": "https://arxiv.org/abs/2511.01732", "authors": ["Liangkang Wang", "Akhil Ambekar", "Ani Eloyan"], "title": "Geometric Modeling of Hippocampal Tau Deposition: A Surface-Based Framework for Covariate Analysis and Off-Target Contamination Detection", "comment": null, "summary": "We introduce a framework combining geometric modeling with disease\nprogression analysis to investigate tau deposition in Alzheimer's disease (AD)\nusing positron emission tomography (PET) data. Focusing on the hippocampus, we\nconstruct a principal surface that captures the spatial distribution and\nmorphological changes of tau pathology. By projecting voxels onto this surface,\nwe quantify tau coverage, intensity, and thickness through bidirectional\nprojection distances and interpolated standardized uptake value ratios (SUVR).\nThis low-dimensional embedding preserves spatial specificity while mitigating\nmultiple comparison issues. Covariate effects are analyzed using a two-stage\nregression model with inverse probability weighting to adjust for signal\nsparsity and selection bias. Using the SuStaIn model, we identify subtypes and\nstages of AD, revealing distinct tau dynamics: the limbic-predominant subtype\nshows age-related nonlinear accumulation in coverage and thickness, whereas the\nposterior subtype exhibits uniform SUVR increases across disease progression.\nModel-based predictions show that hippocampal tau deposition follows a\nstructured spatial trajectory expanding bidirectionally with increasing\nthickness, while subtype differences highlight posterior hippocampal\ninvolvement consistent with whole-brain patterns. Finally, directional signal\npatterns on the principal surface reveal contamination from the choroid plexus,\ndemonstrating the broader applicability of the proposed framework across\nmodalities including amyloid PET.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u51e0\u4f55\u5efa\u6a21\u4e0e\u75be\u75c5\u8fdb\u5c55\u5206\u6790\u7684\u6846\u67b6\uff0c\u7814\u7a76\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u4e2dtau\u86cb\u767d\u6c89\u79ef\u7684\u7a7a\u95f4\u5206\u5e03\u548c\u5f62\u6001\u53d8\u5316\uff0c\u901a\u8fc7\u4e3b\u8868\u9762\u6295\u5f71\u91cf\u5316tau\u8986\u76d6\u5ea6\u3001\u5f3a\u5ea6\u548c\u539a\u5ea6\uff0c\u8bc6\u522b\u75be\u75c5\u4e9a\u578b\u548c\u9636\u6bb5\u3002", "motivation": "\u7814\u7a76\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u4e2dtau\u86cb\u767d\u6c89\u79ef\u7684\u7a7a\u95f4\u5206\u5e03\u6a21\u5f0f\u548c\u5f62\u6001\u53d8\u5316\uff0c\u89e3\u51b3\u4f20\u7edf\u4f53\u7d20\u5206\u6790\u4e2d\u7684\u591a\u91cd\u6bd4\u8f83\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u7a7a\u95f4\u7279\u5f02\u6027\u3002", "method": "\u6784\u5efa\u6d77\u9a6c\u4e3b\u8868\u9762\uff0c\u901a\u8fc7\u53cc\u5411\u6295\u5f71\u8ddd\u79bb\u548c\u6807\u51c6\u5316\u6444\u53d6\u503c\u6bd4\u7387(SUVR)\u63d2\u503c\u91cf\u5316tau\u53c2\u6570\uff0c\u4f7f\u7528\u4e24\u9636\u6bb5\u56de\u5f52\u6a21\u578b\u5206\u6790\u534f\u53d8\u91cf\u6548\u5e94\uff0c\u5e94\u7528SuStaIn\u6a21\u578b\u8bc6\u522b\u75be\u75c5\u4e9a\u578b\u548c\u9636\u6bb5\u3002", "result": "\u8bc6\u522b\u51fa\u4e24\u79cdAD\u4e9a\u578b\uff1a\u8fb9\u7f18\u4e3b\u5bfc\u578b\u663e\u793a\u5e74\u9f84\u76f8\u5173\u7684\u975e\u7ebf\u6027tau\u79ef\u7d2f\uff0c\u540e\u90e8\u4e9a\u578b\u5728\u6574\u4e2a\u75be\u75c5\u8fdb\u5c55\u4e2d\u5448\u73b0\u5747\u5300SUVR\u589e\u52a0\u3002\u6d77\u9a6ctau\u6c89\u79ef\u9075\u5faa\u7ed3\u6784\u5316\u7a7a\u95f4\u8f68\u8ff9\u53cc\u5411\u6269\u5c55\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u6355\u6349tau\u75c5\u7406\u7684\u7a7a\u95f4\u52a8\u6001\uff0c\u63ed\u793a\u4e0d\u540c\u4e9a\u578b\u7684\u7279\u5f02\u6027\u6c89\u79ef\u6a21\u5f0f\uff0c\u5e76\u8bc1\u660e\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u6210\u50cf\u6a21\u6001\u5982\u6dc0\u7c89\u6837\u86cb\u767dPET\u3002"}}
{"id": "2511.00122", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00122", "abs": "https://arxiv.org/abs/2511.00122", "authors": ["Ran Xu", "Yupeng Qi", "Jingsen Feng", "Xu Chu"], "title": "Engineering.ai: A Platform for Teams of AI Engineers in Computational Design", "comment": null, "summary": "In modern engineering practice, human engineers collaborate in specialized\nteams to design complex products, with each expert completing their respective\ntasks while communicating and exchanging results and data with one another.\nWhile this division of expertise is essential for managing multidisciplinary\ncomplexity, it demands substantial development time and cost. Recently, we\nintroduced OpenFOAMGPT (1.0, 2.0), which functions as an autonomous AI engineer\nfor computational fluid dynamics, and turbulence.ai, which can conduct\nend-to-end research in fluid mechanics draft publications and PhD theses.\nBuilding upon these foundations, we present Engineering.ai, a platform for\nteams of AI engineers in computational design. The framework employs a\nhierarchical multi-agent architecture where a Chief Engineer coordinates\nspecialized agents consisting of Aerodynamics, Structural, Acoustic, and\nOptimization Engineers, each powered by LLM with domain-specific knowledge.\nAgent-agent collaboration is achieved through file-mediated communication for\ndata provenance and reproducibility, while a comprehensive memory system\nmaintains project context, execution history, and retrieval-augmented domain\nknowledge to ensure reliable decision-making across the workflow. The system\nintegrates FreeCAD, Gmsh, OpenFOAM, CalculiX, and BPM acoustic analysis,\nenabling parallel multidisciplinary simulations while maintaining computational\naccuracy. The framework is validated through UAV wing optimization. This work\ndemonstrates that agentic-AI-enabled AI engineers has the potential to perform\ncomplex engineering tasks autonomously. Remarkably, the automated workflow\nachieved a 100% success rate across over 400 parametric configurations, with\nzero mesh generation failures, solver convergence issues, or manual\ninterventions required, validating that the framework is trustworthy.", "AI": {"tldr": "Engineering.ai\u662f\u4e00\u4e2a\u7528\u4e8e\u8ba1\u7b97\u8bbe\u8ba1\u7684AI\u5de5\u7a0b\u5e08\u56e2\u961f\u5e73\u53f0\uff0c\u91c7\u7528\u5206\u5c42\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u901a\u8fc7Chief Engineer\u534f\u8c03\u4e13\u4e1a\u5de5\u7a0b\u5e08\u4ee3\u7406\uff0c\u5b9e\u73b0\u81ea\u4e3b\u7684\u590d\u6742\u5de5\u7a0b\u4efb\u52a1\u6267\u884c\u3002", "motivation": "\u73b0\u4ee3\u5de5\u7a0b\u5b9e\u8df5\u4e2d\uff0c\u4e13\u5bb6\u56e2\u961f\u534f\u4f5c\u8bbe\u8ba1\u590d\u6742\u4ea7\u54c1\u9700\u8981\u5927\u91cf\u5f00\u53d1\u65f6\u95f4\u548c\u6210\u672c\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u57fa\u4e8eOpenFOAMGPT\u548cturbulence.ai\u7684\u57fa\u7840\uff0c\u5f00\u53d1\u80fd\u591f\u81ea\u4e3b\u6267\u884c\u590d\u6742\u5de5\u7a0b\u4efb\u52a1\u7684AI\u5de5\u7a0b\u5e08\u56e2\u961f\u5e73\u53f0\u3002", "method": "\u91c7\u7528\u5206\u5c42\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0cChief Engineer\u534f\u8c03Aerodynamics\u3001Structural\u3001Acoustic\u548cOptimization\u7b49\u4e13\u4e1a\u5de5\u7a0b\u5e08\u4ee3\u7406\uff0c\u6bcf\u4e2a\u4ee3\u7406\u7531\u5177\u5907\u9886\u57df\u77e5\u8bc6\u7684LLM\u9a71\u52a8\u3002\u901a\u8fc7\u6587\u4ef6\u4ecb\u5bfc\u7684\u901a\u4fe1\u5b9e\u73b0\u6570\u636e\u53ef\u8ffd\u6eaf\u6027\u548c\u53ef\u91cd\u590d\u6027\uff0c\u96c6\u6210FreeCAD\u3001Gmsh\u3001OpenFOAM\u3001CalculiX\u548cBPM\u58f0\u5b66\u5206\u6790\u7b49\u5de5\u5177\u3002", "result": "\u5728UAV\u673a\u7ffc\u4f18\u5316\u9a8c\u8bc1\u4e2d\uff0c\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u7a0b\u5728400\u591a\u4e2a\u53c2\u6570\u914d\u7f6e\u4e2d\u5b9e\u73b0\u4e86100%\u6210\u529f\u7387\uff0c\u96f6\u7f51\u683c\u751f\u6210\u5931\u8d25\u3001\u6c42\u89e3\u5668\u6536\u655b\u95ee\u9898\u6216\u9700\u8981\u4eba\u5de5\u5e72\u9884\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u57fa\u4e8e\u667a\u80fd\u4f53AI\u7684AI\u5de5\u7a0b\u5e08\u5177\u6709\u81ea\u4e3b\u6267\u884c\u590d\u6742\u5de5\u7a0b\u4efb\u52a1\u7684\u6f5c\u529b\uff0c\u8be5\u6846\u67b6\u88ab\u8bc1\u660e\u662f\u53ef\u4fe1\u8d56\u7684\uff0c\u80fd\u591f\u5b9e\u73b0\u5e76\u884c\u591a\u5b66\u79d1\u4eff\u771f\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u7cbe\u5ea6\u3002"}}
{"id": "2511.00094", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.00094", "abs": "https://arxiv.org/abs/2511.00094", "authors": ["Angelos Alexopoulos", "Agorakis Bompotas", "Nikitas Rigas Kalogeropoulos", "Panagiotis Kechagias", "Athanasios P. Kalogeras", "Christos Alexakos"], "title": "Digital Twin based Automatic Reconfiguration of Robotic Systems in Smart Environments", "comment": "Accepted for presentation to 11th IEEE International Smart Cities\n  Conference (ISC2 2025)", "summary": "Robotic systems have become integral to smart environments, enabling\napplications ranging from urban surveillance and automated agriculture to\nindustrial automation. However, their effective operation in dynamic settings -\nsuch as smart cities and precision farming - is challenged by continuously\nevolving topographies and environmental conditions. Traditional control systems\noften struggle to adapt quickly, leading to inefficiencies or operational\nfailures. To address this limitation, we propose a novel framework for\nautonomous and dynamic reconfiguration of robotic controllers using Digital\nTwin technology. Our approach leverages a virtual replica of the robot's\noperational environment to simulate and optimize movement trajectories in\nresponse to real-world changes. By recalculating paths and control parameters\nin the Digital Twin and deploying the updated code to the physical robot, our\nmethod ensures rapid and reliable adaptation without manual intervention. This\nwork advances the integration of Digital Twins in robotics, offering a scalable\nsolution for enhancing autonomy in smart, dynamic environments.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u6280\u672f\u7684\u673a\u5668\u4eba\u63a7\u5236\u5668\u81ea\u4e3b\u52a8\u6001\u91cd\u6784\u6846\u67b6\uff0c\u901a\u8fc7\u865a\u62df\u73af\u5883\u6a21\u62df\u4f18\u5316\u8fd0\u52a8\u8f68\u8ff9\uff0c\u5b9e\u73b0\u673a\u5668\u4eba\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u5feb\u901f\u81ea\u9002\u5e94\u3002", "motivation": "\u4f20\u7edf\u63a7\u5236\u7cfb\u7edf\u5728\u52a8\u6001\u73af\u5883\uff08\u5982\u667a\u6167\u57ce\u5e02\u3001\u7cbe\u51c6\u519c\u4e1a\uff09\u4e2d\u96be\u4ee5\u5feb\u901f\u9002\u5e94\u4e0d\u65ad\u53d8\u5316\u7684\u5730\u5f62\u548c\u73af\u5883\u6761\u4ef6\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u6216\u64cd\u4f5c\u5931\u8d25\u3002", "method": "\u5229\u7528\u6570\u5b57\u5b6a\u751f\u6280\u672f\u521b\u5efa\u673a\u5668\u4eba\u64cd\u4f5c\u73af\u5883\u7684\u865a\u62df\u526f\u672c\uff0c\u6a21\u62df\u548c\u4f18\u5316\u8fd0\u52a8\u8f68\u8ff9\uff0c\u6839\u636e\u73b0\u5b9e\u4e16\u754c\u53d8\u5316\u91cd\u65b0\u8ba1\u7b97\u8def\u5f84\u548c\u63a7\u5236\u53c2\u6570\uff0c\u5e76\u5c06\u66f4\u65b0\u540e\u7684\u4ee3\u7801\u90e8\u7f72\u5230\u7269\u7406\u673a\u5668\u4eba\u3002", "result": "\u5b9e\u73b0\u4e86\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u7684\u5feb\u901f\u53ef\u9760\u81ea\u9002\u5e94\uff0c\u786e\u4fdd\u673a\u5668\u4eba\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9ad8\u6548\u8fd0\u884c\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63a8\u8fdb\u4e86\u6570\u5b57\u5b6a\u751f\u5728\u673a\u5668\u4eba\u6280\u672f\u4e2d\u7684\u96c6\u6210\uff0c\u4e3a\u667a\u80fd\u52a8\u6001\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u6027\u589e\u5f3a\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01133", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2511.01133", "abs": "https://arxiv.org/abs/2511.01133", "authors": ["Hamza Hanbali", "Gaurav Khemka", "Himasha Warnakulasooriya"], "title": "Liquidity Shocks, Homeownership, and Income Inequality: Impact of Early Pension Withdrawals and Reduced Deposit", "comment": null, "summary": "The paper analyzes two government policies affecting housing demand: early\nwithdrawal from pension savings (EW), and reduction of loan deposit (RD). A\nmodel incorporating demand feedback on housing prices using Australian data\nshows both policies raise prices in the short run. RD delays or prevents access\nfor low-income households, particularly in supply-constrained markets. EW\nimproves accessibility across groups and is most efficient when full withdrawal\nis permitted, but can reduce retirement security if pension grows faster than\nproperty prices. The results also indicate that unequal outcomes stem not from\nprice surges themselves but from pre-existing market disparities.", "AI": {"tldr": "\u5206\u6790\u4e24\u79cd\u5f71\u54cd\u4f4f\u623f\u9700\u6c42\u7684\u653f\u5e9c\u653f\u7b56\uff1a\u517b\u8001\u91d1\u63d0\u524d\u652f\u53d6(EW)\u548c\u964d\u4f4e\u8d37\u6b3e\u9996\u4ed8(RD)\u3002\u4f7f\u7528\u6fb3\u5927\u5229\u4e9a\u6570\u636e\u7684\u6a21\u578b\u663e\u793a\u4e24\u79cd\u653f\u7b56\u77ed\u671f\u5185\u90fd\u4f1a\u63a8\u9ad8\u623f\u4ef7\u3002RD\u4f1a\u5ef6\u8fdf\u6216\u963b\u6b62\u4f4e\u6536\u5165\u5bb6\u5ead\u8d2d\u623f\uff0c\u7279\u522b\u662f\u5728\u4f9b\u5e94\u53d7\u9650\u7684\u5e02\u573a\u3002EW\u6539\u5584\u5404\u7fa4\u4f53\u8d2d\u623f\u80fd\u529b\uff0c\u5b8c\u5168\u652f\u53d6\u65f6\u6700\u6709\u6548\uff0c\u4f46\u5982\u679c\u517b\u8001\u91d1\u589e\u957f\u5feb\u4e8e\u623f\u4ef7\u5219\u53ef\u80fd\u964d\u4f4e\u9000\u4f11\u4fdd\u969c\u3002", "motivation": "\u7814\u7a76\u653f\u5e9c\u653f\u7b56\u5982\u4f55\u5f71\u54cd\u4f4f\u623f\u9700\u6c42\uff0c\u7279\u522b\u662f\u5206\u6790\u517b\u8001\u91d1\u63d0\u524d\u652f\u53d6\u548c\u964d\u4f4e\u8d37\u6b3e\u9996\u4ed8\u8fd9\u4e24\u79cd\u653f\u7b56\u5bf9\u4f4f\u623f\u5e02\u573a\u7684\u5f71\u54cd\uff0c\u91cd\u70b9\u5173\u6ce8\u5b83\u4eec\u5bf9\u4e0d\u540c\u6536\u5165\u7fa4\u4f53\u7684\u53ef\u53ca\u6027\u5f71\u54cd\u3002", "method": "\u5efa\u7acb\u5305\u542b\u4f4f\u623f\u4ef7\u683c\u9700\u6c42\u53cd\u9988\u7684\u6a21\u578b\uff0c\u4f7f\u7528\u6fb3\u5927\u5229\u4e9a\u6570\u636e\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u8bc4\u4f30\u4e24\u79cd\u653f\u7b56\u5bf9\u623f\u4ef7\u548c\u4f4f\u623f\u53ef\u53ca\u6027\u7684\u5f71\u54cd\u3002", "result": "\u4e24\u79cd\u653f\u7b56\u77ed\u671f\u5185\u90fd\u4f1a\u63a8\u9ad8\u623f\u4ef7\uff1bRD\u653f\u7b56\u4f1a\u5ef6\u8fdf\u4f4e\u6536\u5165\u5bb6\u5ead\u8d2d\u623f\uff0c\u5728\u4f9b\u5e94\u53d7\u9650\u5e02\u573a\u5f71\u54cd\u66f4\u4e25\u91cd\uff1bEW\u653f\u7b56\u6539\u5584\u5404\u7fa4\u4f53\u8d2d\u623f\u80fd\u529b\uff0c\u5b8c\u5168\u652f\u53d6\u65f6\u6548\u7387\u6700\u9ad8\uff1b\u4e0d\u5e73\u7b49\u7ed3\u679c\u6e90\u4e8e\u65e2\u6709\u5e02\u573a\u5dee\u5f02\u800c\u975e\u4ef7\u683c\u98d9\u5347\u672c\u8eab\u3002", "conclusion": "\u653f\u7b56\u8bbe\u8ba1\u9700\u8003\u8651\u5bf9\u4f4f\u623f\u53ef\u53ca\u6027\u7684\u5f71\u54cd\uff0cEW\u653f\u7b56\u5728\u6539\u5584\u53ef\u53ca\u6027\u65b9\u9762\u66f4\u6709\u6548\uff0c\u4f46\u9700\u5e73\u8861\u9000\u4f11\u4fdd\u969c\u98ce\u9669\uff1b\u5e02\u573a\u65e2\u6709\u7684\u4e0d\u5e73\u7b49\u662f\u653f\u7b56\u5f71\u54cd\u5dee\u5f02\u7684\u6839\u672c\u539f\u56e0\u3002"}}
{"id": "2511.00718", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2511.00718", "abs": "https://arxiv.org/abs/2511.00718", "authors": ["Haoyuan Zeng"], "title": "Persuasive Selection in Signaling Games", "comment": null, "summary": "This paper introduces a novel criterion, persuasiveness, to select equilibria\nin signaling games. In response to the Stiglitz critique, persuasiveness\nfocuses on the comparison across equilibria. An equilibrium is more persuasive\nthan an alternative if the set of types of the sender who prefer the\nalternative would sequentially deviate to the former once other types have done\nso -- that is, if an unraveling occurs. Persuasiveness has strong selective\npower: it uniquely selects an equilibrium outcome in monotone signaling games.\nMoreover, in non-monotone signaling games, persuasiveness refines predictions\nbeyond existing selection criteria. Notably, it can also select equilibria in\ncheap-talk games, where standard equilibrium refinements for signaling games\nhave no selective power.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u5747\u8861\u9009\u62e9\u6807\u51c6\u2014\u2014\u8bf4\u670d\u529b\uff0c\u7528\u4e8e\u5728\u4fe1\u53f7\u535a\u5f08\u4e2d\u9009\u62e9\u5747\u8861\u3002\u8be5\u6807\u51c6\u901a\u8fc7\u6bd4\u8f83\u4e0d\u540c\u5747\u8861\uff0c\u57fa\u4e8e\u53d1\u9001\u8005\u7c7b\u578b\u662f\u5426\u4f1a\u987a\u5e8f\u504f\u79bb\u5230\u66f4\u4f18\u5747\u8861\u6765\u8fdb\u884c\u9009\u62e9\u3002", "motivation": "\u9488\u5bf9Stiglitz\u6279\u8bc4\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u5747\u8861\u9009\u62e9\u6807\u51c6\u6765\u89e3\u51b3\u4fe1\u53f7\u535a\u5f08\u4e2d\u591a\u91cd\u5747\u8861\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5355\u8c03\u548c\u975e\u5355\u8c03\u4fe1\u53f7\u535a\u5f08\u4e2d\u63d0\u4f9b\u66f4\u5f3a\u7684\u9884\u6d4b\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u8bf4\u670d\u529b\u6807\u51c6\uff1a\u5982\u679c\u4e00\u4e2a\u5747\u8861\u6bd4\u53e6\u4e00\u4e2a\u5747\u8861\u66f4\u5177\u8bf4\u670d\u529b\uff0c\u90a3\u4e48\u504f\u597d\u540e\u8005\u7684\u53d1\u9001\u8005\u7c7b\u578b\u4f1a\u5728\u5176\u4ed6\u7c7b\u578b\u5df2\u7ecf\u504f\u79bb\u540e\u987a\u5e8f\u504f\u79bb\u5230\u524d\u8005\uff0c\u5373\u53d1\u751f\u89e3\u7f20\u8fc7\u7a0b\u3002", "result": "\u8bf4\u670d\u529b\u6807\u51c6\u5177\u6709\u5f3a\u5927\u7684\u9009\u62e9\u80fd\u529b\uff1a\u5728\u5355\u8c03\u4fe1\u53f7\u535a\u5f08\u4e2d\u80fd\u552f\u4e00\u9009\u62e9\u5747\u8861\u7ed3\u679c\uff1b\u5728\u975e\u5355\u8c03\u4fe1\u53f7\u535a\u5f08\u4e2d\u80fd\u63d0\u4f9b\u6bd4\u73b0\u6709\u6807\u51c6\u66f4\u7cbe\u7ec6\u7684\u9884\u6d4b\uff1b\u5728\u5ec9\u4ef7\u8c08\u8bdd\u535a\u5f08\u4e2d\u4e5f\u80fd\u9009\u62e9\u5747\u8861\uff0c\u800c\u6807\u51c6\u7cbe\u70bc\u65b9\u6cd5\u5728\u6b64\u7c7b\u535a\u5f08\u4e2d\u65e0\u6548\u3002", "conclusion": "\u8bf4\u670d\u529b\u662f\u4e00\u4e2a\u6709\u6548\u7684\u5747\u8861\u9009\u62e9\u6807\u51c6\uff0c\u5728\u5404\u7c7b\u4fe1\u53f7\u535a\u5f08\u4e2d\u90fd\u80fd\u63d0\u4f9b\u6709\u610f\u4e49\u7684\u9884\u6d4b\uff0c\u7279\u522b\u662f\u5728\u6807\u51c6\u7cbe\u70bc\u65b9\u6cd5\u5931\u6548\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u53d1\u6325\u4f5c\u7528\u3002"}}
{"id": "2511.00827", "categories": ["cs.SI", "H.4.0; J.4; K.4.0"], "pdf": "https://arxiv.org/pdf/2511.00827", "abs": "https://arxiv.org/abs/2511.00827", "authors": ["Wen Yang", "Qiming Ye", "Onur Ascigil", "Saidu Sokoto", "Leonhard Balduf", "Micha\u0142 Kr\u00f3l", "Gareth Tyson"], "title": "Beyond Single-Tokenomics: How Farcaster's Pluralistic Incentives Reshape Social Networking", "comment": "Accepted to appear in Proceedings of the ACM on Measurement and\n  Analysis of Computing Systems (POMACS), SIGMETRICS 2026. 40 pages, 10\n  figures, 12 tables. DOI: 10.1145/3771565", "summary": "This paper presents the first empirical analysis of how diverse token-based\nreward mechanisms impact platform dynamics and user behaviors. For this, we\ngather a unique, large-scale dataset from Farcaster. This blockchain-based,\ndecentralized social network incorporates multiple incentive mechanisms\nspanning platform-native rewards, third-party token programs, and peer-to-peer\ntipping. Our dataset captures token transactions and social interactions from\n574,829 wallet-linked users, representing 64.25% of the platform's user base.\nOur socioeconomic analyses reveal how different tokenomics design shape varying\nparticipation rates (7.6%--70%) and wealth concentration patterns (Gini\n0.72--0.94), whereas inter-community tipping (51--75% of all tips) is 1.3--2x\nmore frequent among non-following pairs, thereby mitigating echo chambers. Our\ncausal analyses further uncover several critical trade-offs: (1) while most\ntoken rewards boost content creation, they often fail to enhance -- sometimes\nundermining -- content quality; (2) token rewards increase follower acquisition\nbut show neutral or negative effects on outbound following, suggesting\npotential asymmetric network growth; (3) repeated algorithmic rewards\ndemonstrate strong cumulative effects that may encourage strategic\noptimization. Our findings advance understanding of cryptocurrency integration\nin social platforms and highlight challenges in aligning economic incentives\nwith authentic social value.", "AI": {"tldr": "\u9996\u6b21\u5b9e\u8bc1\u5206\u6790\u4e0d\u540c\u4ee3\u5e01\u5956\u52b1\u673a\u5236\u5bf9\u5e73\u53f0\u52a8\u6001\u548c\u7528\u6237\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u57fa\u4e8eFarcaster\u533a\u5757\u94fe\u793e\u4ea4\u7f51\u7edc\u7684\u5927\u89c4\u6a21\u6570\u636e\uff0c\u63ed\u793a\u4e86\u4ee3\u5e01\u7ecf\u6d4e\u5b66\u8bbe\u8ba1\u5728\u53c2\u4e0e\u5ea6\u3001\u8d22\u5bcc\u5206\u914d\u548c\u793e\u4ea4\u4e92\u52a8\u65b9\u9762\u7684\u590d\u6742\u6548\u679c\u3002", "motivation": "\u7814\u7a76\u52a0\u5bc6\u8d27\u5e01\u5728\u793e\u4ea4\u5e73\u53f0\u4e2d\u7684\u6574\u5408\u6548\u679c\uff0c\u63a2\u7d22\u4e0d\u540c\u4ee3\u5e01\u5956\u52b1\u673a\u5236\u5982\u4f55\u5f71\u54cd\u7528\u6237\u884c\u4e3a\u548c\u5e73\u53f0\u751f\u6001\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u5b9e\u8bc1\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u6536\u96c6Farcaster\u533a\u5757\u94fe\u53bb\u4e2d\u5fc3\u5316\u793e\u4ea4\u7f51\u7edc\u7684\u72ec\u7279\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u5305\u542b574,829\u4e2a\u94b1\u5305\u5173\u8054\u7528\u6237\u7684\u4ee3\u5e01\u4ea4\u6613\u548c\u793e\u4ea4\u4e92\u52a8\u6570\u636e\uff0c\u8fdb\u884c\u793e\u4f1a\u7ecf\u6d4e\u5206\u6790\u548c\u56e0\u679c\u5206\u6790\u3002", "result": "\u4e0d\u540c\u4ee3\u5e01\u8bbe\u8ba1\u5bfc\u81f4\u53c2\u4e0e\u7387\u5dee\u5f02\u663e\u8457(7.6%-70%)\uff0c\u8d22\u5bcc\u96c6\u4e2d\u5ea6\u9ad8(Gini 0.72-0.94)\uff1b\u8de8\u793e\u533a\u6253\u8d4f\u536051-75%\uff0c\u975e\u5173\u6ce8\u7528\u6237\u95f4\u6253\u8d4f\u9891\u7387\u9ad81.3-2\u500d\uff1b\u4ee3\u5e01\u5956\u52b1\u4fc3\u8fdb\u5185\u5bb9\u521b\u4f5c\u4f46\u53ef\u80fd\u635f\u5bb3\u8d28\u91cf\uff0c\u589e\u52a0\u7c89\u4e1d\u83b7\u53d6\u4f46\u5bf9\u5173\u6ce8\u4ed6\u4eba\u5f71\u54cd\u4e2d\u6027\u6216\u8d1f\u9762\uff0c\u7b97\u6cd5\u5956\u52b1\u6709\u7d2f\u79ef\u6548\u5e94\u3002", "conclusion": "\u52a0\u5bc6\u8d27\u5e01\u6574\u5408\u5230\u793e\u4ea4\u5e73\u53f0\u9762\u4e34\u6311\u6218\uff0c\u7ecf\u6d4e\u6fc0\u52b1\u4e0e\u771f\u5b9e\u793e\u4ea4\u4ef7\u503c\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u4ee3\u5e01\u7ecf\u6d4e\u5b66\u8bbe\u8ba1\u6765\u5e73\u8861\u6fc0\u52b1\u6548\u679c\u548c\u5e73\u53f0\u751f\u6001\u5065\u5eb7\u3002"}}
{"id": "2511.00420", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.00420", "abs": "https://arxiv.org/abs/2511.00420", "authors": ["Ali Taghavian", "Ali Safi", "Esmaeel Khanmirza"], "title": "Constrained computational hybrid controller for Input Affine Hybrid Dynamical Systems", "comment": null, "summary": "Hybrid dynamical systems are viewed as the most complicated systems with\ncontinuous and event-based behaviors. Since traditional controllers cannot\nhandle these systems, some newly-developed controllers have been published in\nrecent decades to deal with them. This paper presents a novel implementable\nconstrained final-state controller based on partitioning the system's\nstate-space, computational simulations, and graph theory. Experimental results\nand a comparison with Model Predictive Controller on the three tank benchmark\nand swing-up control of a pendulum show the effectiveness of the proposed\nComputational Hybrid Controller(CHC).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u72b6\u6001\u7a7a\u95f4\u5212\u5206\u3001\u8ba1\u7b97\u4eff\u771f\u548c\u56fe\u8bba\u7684\u65b0\u578b\u53ef\u5b9e\u73b0\u7684\u7ea6\u675f\u7ec8\u6001\u63a7\u5236\u5668\uff0c\u7528\u4e8e\u5904\u7406\u6df7\u5408\u52a8\u529b\u7cfb\u7edf\u3002", "motivation": "\u6df7\u5408\u52a8\u529b\u7cfb\u7edf\u5177\u6709\u8fde\u7eed\u548c\u57fa\u4e8e\u4e8b\u4ef6\u7684\u884c\u4e3a\uff0c\u4f20\u7edf\u63a7\u5236\u5668\u65e0\u6cd5\u5904\u7406\u8fd9\u7c7b\u590d\u6742\u7cfb\u7edf\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u63a7\u5236\u5668\u3002", "method": "\u901a\u8fc7\u5212\u5206\u7cfb\u7edf\u72b6\u6001\u7a7a\u95f4\u3001\u8ba1\u7b97\u4eff\u771f\u548c\u56fe\u8bba\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86\u8ba1\u7b97\u6df7\u5408\u63a7\u5236\u5668(CHC)\u3002", "result": "\u5728\u4e09\u6c34\u7bb1\u57fa\u51c6\u6d4b\u8bd5\u548c\u6446\u9524\u6446\u8d77\u63a7\u5236\u5b9e\u9a8c\u4e2d\uff0c\u4e0e\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5668\u76f8\u6bd4\uff0c\u8bc1\u660e\u4e86\u6240\u63d0CHC\u63a7\u5236\u5668\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u8ba1\u7b97\u6df7\u5408\u63a7\u5236\u5668\u80fd\u591f\u6709\u6548\u5904\u7406\u6df7\u5408\u52a8\u529b\u7cfb\u7edf\u7684\u63a7\u5236\u95ee\u9898\uff0c\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2511.00078", "categories": ["cs.CY", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.00078", "abs": "https://arxiv.org/abs/2511.00078", "authors": ["Chen-Wei Chang", "Yu-Chieh Cheng", "Yun-En Tsai", "Fanglan Chen", "Chang-Tien Lu"], "title": "RailEstate: An Interactive System for Metro Linked Property Trends", "comment": null, "summary": "Access to metro systems plays a critical role in shaping urban housing\nmarkets by enhancing neighborhood accessibility and driving property demand. We\npresent RailEstate, a novel web based system that integrates spatial analytics,\nnatural language interfaces, and interactive forecasting to analyze how\nproximity to metro stations influences residential property prices in the\nWashington metropolitan area. Unlike static mapping tools or generic listing\nplatforms, RailEstate combines 25 years of historical housing data with transit\ninfrastructure to support low latency geospatial queries, time series\nvisualizations, and predictive modeling. Users can interactively explore ZIP\ncode level price patterns, investigate long term trends, and forecast future\nhousing values around any metro station. A key innovation is our natural\nlanguage chatbot, which translates plain-English questions e.g., What is the\nhighest price in Falls Church in the year 2000? into executable SQL over a\nspatial database. This unified and interactive platform empowers urban\nplanners, investors, and residents to derive actionable insights from metro\nlinked housing data without requiring technical expertise.", "AI": {"tldr": "RailEstate\u662f\u4e00\u4e2a\u57fa\u4e8e\u7f51\u7edc\u7684\u7cfb\u7edf\uff0c\u6574\u5408\u7a7a\u95f4\u5206\u6790\u3001\u81ea\u7136\u8bed\u8a00\u754c\u9762\u548c\u4ea4\u4e92\u5f0f\u9884\u6d4b\uff0c\u5206\u6790\u5730\u94c1\u7ad9\u90bb\u8fd1\u5ea6\u5bf9\u534e\u76db\u987f\u90fd\u5e02\u533a\u4f4f\u5b85\u623f\u4ef7\u7684\u5f71\u54cd\u3002", "motivation": "\u5730\u94c1\u7cfb\u7edf\u7684\u53ef\u8fbe\u6027\u5bf9\u57ce\u5e02\u4f4f\u623f\u5e02\u573a\u81f3\u5173\u91cd\u8981\uff0c\u901a\u8fc7\u63d0\u5347\u793e\u533a\u53ef\u8fbe\u6027\u6765\u63a8\u52a8\u623f\u4ea7\u9700\u6c42\u3002\u73b0\u6709\u9759\u6001\u5730\u56fe\u5de5\u5177\u6216\u901a\u7528\u623f\u6e90\u5e73\u53f0\u65e0\u6cd5\u6ee1\u8db3\u5bf9\u5730\u94c1\u76f8\u5173\u4f4f\u623f\u6570\u636e\u7684\u6df1\u5165\u5206\u6790\u9700\u6c42\u3002", "method": "\u7ed3\u540825\u5e74\u5386\u53f2\u4f4f\u623f\u6570\u636e\u548c\u4ea4\u901a\u57fa\u7840\u8bbe\u65bd\uff0c\u652f\u6301\u4f4e\u5ef6\u8fdf\u5730\u7406\u7a7a\u95f4\u67e5\u8be2\u3001\u65f6\u95f4\u5e8f\u5217\u53ef\u89c6\u5316\u548c\u9884\u6d4b\u5efa\u6a21\u3002\u521b\u65b0\u6027\u5730\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u804a\u5929\u673a\u5668\u4eba\u5c06\u82f1\u6587\u95ee\u9898\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684SQL\u67e5\u8be2\u3002", "result": "\u7528\u6237\u53ef\u4ee5\u4ea4\u4e92\u5f0f\u63a2\u7d22ZIP\u7801\u7ea7\u522b\u7684\u4ef7\u683c\u6a21\u5f0f\uff0c\u8c03\u67e5\u957f\u671f\u8d8b\u52bf\uff0c\u5e76\u9884\u6d4b\u4efb\u4f55\u5730\u94c1\u7ad9\u5468\u56f4\u7684\u672a\u6765\u623f\u4ef7\u3002", "conclusion": "\u8fd9\u4e2a\u7edf\u4e00\u4ea4\u4e92\u5e73\u53f0\u4f7f\u57ce\u5e02\u89c4\u5212\u8005\u3001\u6295\u8d44\u8005\u548c\u5c45\u6c11\u80fd\u591f\u4ece\u5730\u94c1\u76f8\u5173\u4f4f\u623f\u6570\u636e\u4e2d\u83b7\u5f97\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u65e0\u9700\u6280\u672f\u4e13\u4e1a\u77e5\u8bc6\u3002"}}
{"id": "2511.01778", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.01778", "abs": "https://arxiv.org/abs/2511.01778", "authors": ["Richard Evans", "Max Felland", "Susanna Evans", "Lindsey Sloan"], "title": "Large Language Model-Derived Priors Can Improve Bayesian Survival Analyses: A Glioblastoma Application", "comment": "Presented at the 2nd Annual Southeast Wisconsin Data Science\n  (SEAWINDS) Research Symposium, Milwaukee, WI", "summary": "This report describes an application of artificial intelligence (AI) to the\nBayesian analysis of glioblastoma survival data. It has been suggested that AI\ncan be used to construct prior distributions for parameters in Bayesian models\nrather than using the difficult, unreliable, and time-consuming process of\neliciting expert opinion from radiation oncologists. Here, we show how\ngenerative AI can quickly propose sensible prior distributions of the hazard\nratio comparing two glioblastoma therapies, for a standard Bayesian survival\nmodel on real data. Three Chatbots generated two alternative priors each which\nwere evaluated by a radiation oncologist and then used in a sensitivity\nanalysis to assess posterior stability. The results suggest that, for this\ncancer survival analysis, priors from generative AI are a preferred alternative\nmethod to expert elicitation.", "AI": {"tldr": "\u4f7f\u7528\u751f\u6210\u5f0fAI\u4e3a\u8d1d\u53f6\u65af\u80f6\u8d28\u6bcd\u7ec6\u80de\u7624\u751f\u5b58\u5206\u6790\u6784\u5efa\u5148\u9a8c\u5206\u5e03\uff0c\u66ff\u4ee3\u4f20\u7edf\u4e13\u5bb6\u610f\u89c1\u83b7\u53d6\u65b9\u6cd5", "motivation": "\u4f20\u7edf\u4ece\u653e\u5c04\u80bf\u7624\u5b66\u5bb6\u83b7\u53d6\u4e13\u5bb6\u610f\u89c1\u6765\u6784\u5efa\u8d1d\u53f6\u65af\u5148\u9a8c\u5206\u5e03\u7684\u8fc7\u7a0b\u56f0\u96be\u3001\u4e0d\u53ef\u9760\u4e14\u8017\u65f6\uff0c\u9700\u8981\u5bfb\u627e\u66ff\u4ee3\u65b9\u6cd5", "method": "\u4f7f\u7528\u4e09\u4e2a\u804a\u5929\u673a\u5668\u4eba\u5404\u751f\u6210\u4e24\u4e2a\u66ff\u4ee3\u5148\u9a8c\u5206\u5e03\uff0c\u7531\u653e\u5c04\u80bf\u7624\u5b66\u5bb6\u8bc4\u4f30\u540e\u7528\u4e8e\u654f\u611f\u6027\u5206\u6790\u8bc4\u4f30\u540e\u9a8c\u7a33\u5b9a\u6027", "result": "\u751f\u6210\u5f0fAI\u80fd\u591f\u5feb\u901f\u63d0\u51fa\u5408\u7406\u7684\u5371\u9669\u6bd4\u5148\u9a8c\u5206\u5e03\uff0c\u5728\u654f\u611f\u6027\u5206\u6790\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u540e\u9a8c\u7a33\u5b9a\u6027", "conclusion": "\u5bf9\u4e8e\u8fd9\u79cd\u764c\u75c7\u751f\u5b58\u5206\u6790\uff0c\u751f\u6210\u5f0fAI\u63d0\u4f9b\u7684\u5148\u9a8c\u5206\u5e03\u662f\u4e13\u5bb6\u610f\u89c1\u83b7\u53d6\u7684\u9996\u9009\u66ff\u4ee3\u65b9\u6cd5"}}
{"id": "2511.00162", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00162", "abs": "https://arxiv.org/abs/2511.00162", "authors": ["Michael D. Moffitt"], "title": "ARC-GEN: A Mimetic Procedural Benchmark Generator for the Abstraction and Reasoning Corpus", "comment": null, "summary": "The Abstraction and Reasoning Corpus remains one of the most compelling and\nchallenging benchmarks for tracking progress toward achieving Artificial\nGeneral Intelligence. In contrast to other evaluation datasets designed to\nassess an agent's task-specific skills or accumulated knowledge, the ARC-AGI\nsuite is specifically targeted at measuring skill acquisition efficiency, a\ntrait that has (so far) been lacking in even the most sophisticated machine\nlearning systems. For algorithms that require extensive intra-task exemplars, a\nsignificant constraint imposed by ARC-AGI is the modest cardinality of its\ndemonstration set, comprising a small number of $\\langle$ input, output\n$\\rangle$ grids per task specifying the corresponding transformation. To\nembellish the space of viable sample pairs, this paper introduces ARC-GEN, an\nopen-source procedural generator aimed at extending the original ARC-AGI\ntraining dataset as faithfully as possible. Unlike prior efforts, our generator\nis both exhaustive (covering all four-hundred tasks) and mimetic (more closely\nhonoring the distributional properties and characteristics embodied in the\ninitial ARC-AGI-1 release). We also discuss the use of this generator in\nestablishing a static benchmark suite to verify the correctness of programs\nsubmitted to the 2025 Google Code Golf Championship.", "AI": {"tldr": "ARC-GEN\u662f\u4e00\u4e2a\u5f00\u6e90\u7a0b\u5e8f\u751f\u6210\u5668\uff0c\u65e8\u5728\u6269\u5c55ARC-AGI\u57fa\u51c6\u6d4b\u8bd5\u7684\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u751f\u6210\u66f4\u591a\u6837\u5316\u7684\u6837\u672c\u5bf9\u6765\u589e\u5f3a\u7b97\u6cd5\u7684\u8bad\u7ec3\u6548\u679c\u3002", "motivation": "ARC-AGI\u57fa\u51c6\u6d4b\u8bd5\u867d\u7136\u80fd\u6709\u6548\u8bc4\u4f30\u667a\u80fd\u4f53\u7684\u6280\u80fd\u83b7\u53d6\u6548\u7387\uff0c\u4f46\u5176\u793a\u8303\u96c6\u89c4\u6a21\u6709\u9650\uff0c\u6bcf\u4e2a\u4efb\u52a1\u53ea\u5305\u542b\u5c11\u91cf\u8f93\u5165-\u8f93\u51fa\u7f51\u683c\u5bf9\uff0c\u8fd9\u9650\u5236\u4e86\u9700\u8981\u5927\u91cf\u6837\u672c\u7684\u7b97\u6cd5\u7684\u6027\u80fd\u3002", "method": "\u5f00\u53d1\u4e86ARC-GEN\u7a0b\u5e8f\u751f\u6210\u5668\uff0c\u8be5\u751f\u6210\u5668\u8986\u76d6\u6240\u6709400\u4e2a\u4efb\u52a1\uff0c\u5e76\u5c3d\u53ef\u80fd\u5fe0\u5b9e\u4e8e\u539f\u59cbARC-AGI-1\u53d1\u5e03\u7248\u7684\u5206\u5e03\u7279\u6027\u548c\u7279\u5f81\u3002", "result": "\u6210\u529f\u521b\u5efa\u4e86\u4e00\u4e2a\u65e2\u80fd\u6269\u5c55\u8bad\u7ec3\u6570\u636e\u96c6\u53c8\u4fdd\u6301\u539f\u59cb\u5206\u5e03\u7279\u6027\u7684\u751f\u6210\u5668\uff0c\u4e3a\u7b97\u6cd5\u63d0\u4f9b\u66f4\u591a\u6837\u5316\u7684\u8bad\u7ec3\u6837\u672c\u3002", "conclusion": "ARC-GEN\u4e3aARC-AGI\u57fa\u51c6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6570\u636e\u589e\u5f3a\u5de5\u5177\uff0c\u5e76\u5df2\u5e94\u7528\u4e8e2025\u5e74Google Code Golf\u9526\u6807\u8d5b\u4e2d\u9a8c\u8bc1\u63d0\u4ea4\u7a0b\u5e8f\u7684\u6b63\u786e\u6027\u3002"}}
{"id": "2511.00112", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00112", "abs": "https://arxiv.org/abs/2511.00112", "authors": ["Yanbing Mao", "Yihao Cai", "Lui Sha"], "title": "Real-DRL: Teach and Learn in Reality", "comment": "37 pages", "summary": "This paper introduces the Real-DRL framework for safety-critical autonomous\nsystems, enabling runtime learning of a deep reinforcement learning (DRL) agent\nto develop safe and high-performance action policies in real plants (i.e., real\nphysical systems to be controlled), while prioritizing safety! The Real-DRL\nconsists of three interactive components: a DRL-Student, a PHY-Teacher, and a\nTrigger. The DRL-Student is a DRL agent that innovates in the dual\nself-learning and teaching-to-learn paradigm and the real-time safety-informed\nbatch sampling. On the other hand, PHY-Teacher is a physics-model-based design\nof action policies that focuses solely on safety-critical functions.\nPHY-Teacher is novel in its real-time patch for two key missions: i) fostering\nthe teaching-to-learn paradigm for DRL-Student and ii) backing up the safety of\nreal plants. The Trigger manages the interaction between the DRL-Student and\nthe PHY-Teacher. Powered by the three interactive components, the Real-DRL can\neffectively address safety challenges that arise from the unknown unknowns and\nthe Sim2Real gap. Additionally, Real-DRL notably features i) assured safety,\nii) automatic hierarchy learning (i.e., safety-first learning and then\nhigh-performance learning), and iii) safety-informed batch sampling to address\nthe learning experience imbalance caused by corner cases. Experiments with a\nreal quadruped robot, a quadruped robot in NVIDIA Isaac Gym, and a cart-pole\nsystem, along with comparisons and ablation studies, demonstrate the Real-DRL's\neffectiveness and unique features.", "AI": {"tldr": "Real-DRL\u6846\u67b6\u7528\u4e8e\u5b89\u5168\u5173\u952e\u81ea\u4e3b\u7cfb\u7edf\uff0c\u901a\u8fc7\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u771f\u5b9e\u7269\u7406\u7cfb\u7edf\u4e2d\u5b9e\u65f6\u5b66\u4e60\u5b89\u5168\u9ad8\u6027\u80fd\u52a8\u4f5c\u7b56\u7565\uff0c\u5305\u542bDRL-\u5b66\u751f\u3001PHY-\u6559\u5e08\u548c\u89e6\u53d1\u5668\u4e09\u4e2a\u4ea4\u4e92\u7ec4\u4ef6\u3002", "motivation": "\u89e3\u51b3\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2d\u7531\u672a\u77e5\u672a\u77e5\u548cSim2Real\u5dee\u8ddd\u5e26\u6765\u7684\u5b89\u5168\u6311\u6218\uff0c\u786e\u4fdd\u5728\u771f\u5b9e\u7269\u7406\u7cfb\u7edf\u4e2d\u8fd0\u884c\u65f6\u5b66\u4e60\u7684\u5b89\u5168\u6027\u548c\u6027\u80fd\u3002", "method": "\u91c7\u7528\u4e09\u7ec4\u4ef6\u4ea4\u4e92\u6846\u67b6\uff1aDRL-\u5b66\u751f\u91c7\u7528\u53cc\u91cd\u81ea\u5b66\u4e60\u548c\u6559\u5b66\u5b66\u4e60\u8303\u5f0f\uff0cPHY-\u6559\u5e08\u57fa\u4e8e\u7269\u7406\u6a21\u578b\u4e13\u6ce8\u4e8e\u5b89\u5168\u5173\u952e\u529f\u80fd\uff0c\u89e6\u53d1\u5668\u7ba1\u7406\u4e24\u8005\u4ea4\u4e92\u3002", "result": "\u5728\u771f\u5b9e\u56db\u8db3\u673a\u5668\u4eba\u3001NVIDIA Isaac Gym\u4e2d\u7684\u56db\u8db3\u673a\u5668\u4eba\u548c\u5012\u7acb\u6446\u7cfb\u7edf\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u4fdd\u8bc1\u5b89\u5168\u3001\u81ea\u52a8\u5c42\u6b21\u5b66\u4e60\u548c\u89e3\u51b3\u5b66\u4e60\u7ecf\u9a8c\u4e0d\u5e73\u8861\u7b49\u72ec\u7279\u7279\u6027\u3002", "conclusion": "Real-DRL\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5b89\u5168\u5173\u952e\u81ea\u4e3b\u7cfb\u7edf\u4e2d\u7684\u5b89\u5168\u6311\u6218\uff0c\u5b9e\u73b0\u5b89\u5168\u4f18\u5148\u7684\u5b66\u4e60\u548c\u9ad8\u6027\u80fd\u7b56\u7565\u5f00\u53d1\u3002"}}
{"id": "2511.01211", "categories": ["econ.GN", "cs.CE", "cs.CL", "cs.DL", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2511.01211", "abs": "https://arxiv.org/abs/2511.01211", "authors": ["Chaofeng Wu"], "title": "Novelty and Impact of Economics Papers", "comment": null, "summary": "We propose a framework that recasts scientific novelty not as a single\nattribute of a paper, but as a reflection of its position within the evolving\nintellectual landscape. We decompose this position into two orthogonal\ndimensions: \\textit{spatial novelty}, which measures a paper's intellectual\ndistinctiveness from its neighbors, and \\textit{temporal novelty}, which\ncaptures its engagement with a dynamic research frontier. To operationalize\nthese concepts, we leverage Large Language Models to develop semantic isolation\nmetrics that quantify a paper's location relative to the full-text literature.\nApplying this framework to a large corpus of economics articles, we uncover a\nfundamental trade-off: these two dimensions predict systematically different\noutcomes. Temporal novelty primarily predicts citation counts, whereas spatial\nnovelty predicts disruptive impact. This distinction allows us to construct a\ntypology of semantic neighborhoods, identifying four archetypes associated with\ndistinct and predictable impact profiles. Our findings demonstrate that novelty\ncan be understood as a multidimensional construct whose different forms,\nreflecting a paper's strategic location, have measurable and fundamentally\ndistinct consequences for scientific progress.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u5c06\u79d1\u5b66\u65b0\u9896\u6027\u5206\u89e3\u4e3a\u7a7a\u95f4\u65b0\u9896\u6027\u548c\u65f6\u95f4\u65b0\u9896\u6027\u4e24\u4e2a\u7ef4\u5ea6\uff0c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u91cf\u5316\u8bba\u6587\u5728\u6587\u732e\u4e2d\u7684\u4f4d\u7f6e\uff0c\u53d1\u73b0\u8fd9\u4e24\u4e2a\u7ef4\u5ea6\u9884\u6d4b\u4e0d\u540c\u7684\u5b66\u672f\u5f71\u54cd\u529b\u3002", "motivation": "\u4f20\u7edf\u4e0a\u79d1\u5b66\u65b0\u9896\u6027\u88ab\u89c6\u4e3a\u5355\u4e00\u5c5e\u6027\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u5b83\u5e94\u53cd\u6620\u8bba\u6587\u5728\u77e5\u8bc6\u6f14\u5316\u8fc7\u7a0b\u4e2d\u7684\u4f4d\u7f6e\uff0c\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u7ef4\u5ea6\u5212\u5206\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5f00\u53d1\u8bed\u4e49\u9694\u79bb\u6307\u6807\uff0c\u91cf\u5316\u8bba\u6587\u76f8\u5bf9\u4e8e\u5168\u6587\u6587\u732e\u7684\u4f4d\u7f6e\uff0c\u5e94\u7528\u4e8e\u7ecf\u6d4e\u5b66\u6587\u732e\u8bed\u6599\u5e93\u8fdb\u884c\u5206\u6790\u3002", "result": "\u53d1\u73b0\u7a7a\u95f4\u65b0\u9896\u6027\u4e3b\u8981\u9884\u6d4b\u98a0\u8986\u6027\u5f71\u54cd\u529b\uff0c\u65f6\u95f4\u65b0\u9896\u6027\u4e3b\u8981\u9884\u6d4b\u5f15\u7528\u6b21\u6570\uff0c\u5e76\u8bc6\u522b\u51fa\u56db\u79cd\u5177\u6709\u4e0d\u540c\u5f71\u54cd\u529b\u7279\u5f81\u7684\u539f\u578b\u8bed\u4e49\u90bb\u57df\u3002", "conclusion": "\u65b0\u9896\u6027\u662f\u591a\u7ef4\u6784\u5ff5\uff0c\u5176\u4e0d\u540c\u5f62\u5f0f\u53cd\u6620\u4e86\u8bba\u6587\u7684\u6218\u7565\u5b9a\u4f4d\uff0c\u5bf9\u79d1\u5b66\u8fdb\u6b65\u4ea7\u751f\u53ef\u6d4b\u91cf\u4e14\u6839\u672c\u4e0d\u540c\u7684\u5f71\u54cd\u3002"}}
{"id": "2511.00723", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2511.00723", "abs": "https://arxiv.org/abs/2511.00723", "authors": ["Haoyuan Zeng"], "title": "Identity-Compatible Auctions", "comment": null, "summary": "This paper studies the incentives of the seller and buyers to shill bid in a\nsingle-item auction. An auction is seller identity-compatible if the seller\ncannot profit from pretending to be one or more bidders via fake identities. It\nis buyer identity-compatible if no buyer profits from posing as more than one\nbidder. Lit auctions reveal the number of bidders, whereas dark auctions\nconceal the information. We characterize three classic selling mechanisms --\nfirst-price, second-price, and posted-price -- based on identity compatibility.\nWe show the importance of concealing the number of bidders, which enables the\nimplementation of a broader range of outcome rules. In particular, no optimal\nlit auction is ex-post seller identity-compatible, while the dark first-price\nauction (with reserve) achieves the goal.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5355\u7269\u54c1\u62cd\u5356\u4e2d\u5356\u5bb6\u548c\u4e70\u5bb6\u8fdb\u884c\u865a\u5047\u7ade\u6807\u7684\u52a8\u673a\uff0c\u5206\u6790\u4e86\u4e09\u79cd\u7ecf\u5178\u62cd\u5356\u673a\u5236\u7684\u8eab\u4efd\u517c\u5bb9\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u9690\u85cf\u7ade\u6807\u8005\u6570\u91cf\u5bf9\u4e8e\u5b9e\u73b0\u66f4\u5e7f\u6cdb\u7ed3\u679c\u89c4\u5219\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u7814\u7a76\u62cd\u5356\u4e2d\u5356\u5bb6\u548c\u4e70\u5bb6\u901a\u8fc7\u865a\u5047\u8eab\u4efd\u8fdb\u884c\u7ade\u6807\u7684\u52a8\u673a\uff0c\u63a2\u8ba8\u4e0d\u540c\u62cd\u5356\u673a\u5236\u7684\u8eab\u4efd\u517c\u5bb9\u6027\uff0c\u4ee5\u53ca\u7ade\u6807\u8005\u6570\u91cf\u4fe1\u606f\u7684\u62ab\u9732\u5bf9\u62cd\u5356\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4e09\u79cd\u7ecf\u5178\u62cd\u5356\u673a\u5236\uff08\u7b2c\u4e00\u4ef7\u683c\u62cd\u5356\u3001\u7b2c\u4e8c\u4ef7\u683c\u62cd\u5356\u548c\u5b9a\u4ef7\u9500\u552e\uff09\u7684\u8eab\u4efd\u517c\u5bb9\u6027\uff0c\u6bd4\u8f83\u660e\u62cd\uff08\u516c\u5f00\u7ade\u6807\u8005\u6570\u91cf\uff09\u548c\u6697\u62cd\uff08\u9690\u85cf\u7ade\u6807\u8005\u6570\u91cf\uff09\u7684\u5dee\u5f02\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6ca1\u6709\u6700\u4f18\u7684\u660e\u62cd\u662f\u4e8b\u540e\u5356\u5bb6\u8eab\u4efd\u517c\u5bb9\u7684\uff0c\u800c\u6697\u62cd\u7b2c\u4e00\u4ef7\u683c\u62cd\u5356\uff08\u542b\u4fdd\u7559\u4ef7\uff09\u80fd\u591f\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u3002\u9690\u85cf\u7ade\u6807\u8005\u6570\u91cf\u80fd\u591f\u5b9e\u73b0\u66f4\u5e7f\u6cdb\u7684\u7ed3\u679c\u89c4\u5219\u3002", "conclusion": "\u9690\u85cf\u7ade\u6807\u8005\u6570\u91cf\u5bf9\u4e8e\u5b9e\u73b0\u8eab\u4efd\u517c\u5bb9\u7684\u62cd\u5356\u673a\u5236\u81f3\u5173\u91cd\u8981\uff0c\u6697\u62cd\u7b2c\u4e00\u4ef7\u683c\u62cd\u5356\u662f\u5b9e\u73b0\u5356\u5bb6\u8eab\u4efd\u517c\u5bb9\u7684\u6709\u6548\u673a\u5236\u3002"}}
{"id": "2511.01086", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.01086", "abs": "https://arxiv.org/abs/2511.01086", "authors": ["Vladimir Martirosyan", "Rachit Kamdar"], "title": "Do Employee Verification Mechanisms Alter Cultural Signals in Employer Reviews?", "comment": null, "summary": "Online reviews shape impressions across products and workplaces. Employer\nreviews combine narratives and ratings that reflect culture. Glassdoor permits\nfully anonymous posts; Blind requires employment verification while preserving\nanonymity. We ask how verification changes reviews. Evidence suggests verified\nreviews can be more trustworthy, yet verification can also erode authenticity\nwhen expectations are unmet. We use the Competing Values Framework (clan,\nadhocracy, hierarchy, market) and the CultureBERT model by Koch and Pasch, 2023\nto over 300k ratings. We find that Blind reviews emphasize clan and hierarchy\nwhile Glassdoor skews positive and highlights clan and market. Verification on\nits own does not remove bias but shifts how culture is represented. Job seekers\nusing different platforms receive systematically different signals about\nworkplace culture, affecting application decisions and job-matching.", "AI": {"tldr": "\u6bd4\u8f83\u533f\u540d\u5e73\u53f0Glassdoor\u548c\u8eab\u4efd\u9a8c\u8bc1\u5e73\u53f0Blind\u4e0a\u7684\u96c7\u4e3b\u8bc4\u8bba\u5dee\u5f02\uff0c\u53d1\u73b0\u9a8c\u8bc1\u673a\u5236\u6539\u53d8\u4e86\u6587\u5316\u8868\u8fbe\u65b9\u5f0f\uff0c\u5f71\u54cd\u6c42\u804c\u8005\u5bf9\u5de5\u4f5c\u573a\u6240\u6587\u5316\u7684\u8ba4\u77e5\u3002", "motivation": "\u7814\u7a76\u8eab\u4efd\u9a8c\u8bc1\u5982\u4f55\u5f71\u54cd\u5728\u7ebf\u96c7\u4e3b\u8bc4\u8bba\u7684\u771f\u5b9e\u6027\u548c\u6587\u5316\u8868\u8fbe\uff0c\u63a2\u8ba8\u4e0d\u540c\u5e73\u53f0\u5bf9\u6c42\u804c\u51b3\u7b56\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u7ade\u4e89\u4ef7\u503c\u89c2\u6846\u67b6(\u5b97\u65cf\u3001\u4e34\u65f6\u4f53\u5236\u3001\u5c42\u7ea7\u3001\u5e02\u573a)\u548cCultureBERT\u6a21\u578b\uff0c\u5206\u6790\u8d85\u8fc730\u4e07\u6761\u8bc4\u5206\u6570\u636e\u3002", "result": "Blind\u8bc4\u8bba\u5f3a\u8c03\u5b97\u65cf\u548c\u5c42\u7ea7\u6587\u5316\uff0cGlassdoor\u504f\u5411\u6b63\u9762\u8bc4\u4ef7\u5e76\u7a81\u51fa\u5b97\u65cf\u548c\u5e02\u573a\u6587\u5316\u3002\u9a8c\u8bc1\u672c\u8eab\u4e0d\u80fd\u6d88\u9664\u504f\u89c1\uff0c\u4f46\u6539\u53d8\u4e86\u6587\u5316\u8868\u8fbe\u65b9\u5f0f\u3002", "conclusion": "\u4e0d\u540c\u5e73\u53f0\u63d0\u4f9b\u7cfb\u7edf\u6027\u7684\u4e0d\u540c\u6587\u5316\u4fe1\u53f7\uff0c\u5f71\u54cd\u6c42\u804c\u8005\u7684\u7533\u8bf7\u51b3\u7b56\u548c\u804c\u4f4d\u5339\u914d\u3002"}}
{"id": "2511.00453", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.00453", "abs": "https://arxiv.org/abs/2511.00453", "authors": ["Jiale Han", "Wei Ouyang", "Maoran Zhu", "Yuanxin Wu"], "title": "CT-ESKF: A General Framework of Covariance Transformation-Based Error-State Kalman Filter", "comment": "19 pages, 12 figures", "summary": "Invariant extended Kalman filter (InEKF) possesses excellent\ntrajectory-independent property and better consistency compared to conventional\nextended Kalman filter (EKF). However, when applied to scenarios involving both\nglobal-frame and body-frame observations, InEKF may fail to preserve its\ntrajectory-independent property. This work introduces the concept of\nequivalence between error states and covariance matrices among different\nerror-state Kalman filters, and shows that although InEKF exhibits trajectory\nindependence, its covariance propagation is actually equivalent to EKF. A\ncovariance transformation-based error-state Kalman filter (CT-ESKF) framework\nis proposed that unifies various error-state Kalman filtering algorithms. The\nframework gives birth to novel filtering algorithms that demonstrate improved\nperformance in integrated navigation systems that incorporate both global and\nbody-frame observations. Experimental results show that the EKF with covariance\ntransformation outperforms both InEKF and original EKF in a representative\nINS/GNSS/Odometer integrated navigation system.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u534f\u65b9\u5dee\u53d8\u6362\u7684\u8bef\u5dee\u72b6\u6001\u5361\u5c14\u66fc\u6ee4\u6ce2\u6846\u67b6\uff0c\u7edf\u4e00\u4e86\u591a\u79cd\u6ee4\u6ce2\u7b97\u6cd5\uff0c\u5e76\u5728\u878d\u5408\u5168\u5c40\u548c\u8f7d\u4f53\u89c2\u6d4b\u7684\u5bfc\u822a\u7cfb\u7edf\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u4f20\u7edfEKF\u548cInEKF\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u540c\u65f6\u5305\u542b\u5168\u5c40\u5750\u6807\u7cfb\u548c\u8f7d\u4f53\u5750\u6807\u7cfb\u89c2\u6d4b\u65f6\uff0c\u4e0d\u53d8\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u53ef\u80fd\u65e0\u6cd5\u4fdd\u6301\u5176\u8f68\u8ff9\u65e0\u5173\u7279\u6027\uff0c\u9700\u8981\u6539\u8fdb\u6ee4\u6ce2\u7b97\u6cd5\u4ee5\u63d0\u5347\u5bfc\u822a\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u5f15\u5165\u8bef\u5dee\u72b6\u6001\u4e0e\u534f\u65b9\u5dee\u77e9\u9635\u7b49\u4ef7\u6027\u6982\u5ff5\uff0c\u63d0\u51fa\u534f\u65b9\u5dee\u53d8\u6362\u7684\u8bef\u5dee\u72b6\u6001\u5361\u5c14\u66fc\u6ee4\u6ce2\u6846\u67b6\uff0c\u7edf\u4e00\u4e0d\u540c\u6ee4\u6ce2\u7b97\u6cd5\uff0c\u5e76\u884d\u751f\u51fa\u65b0\u578b\u6ee4\u6ce2\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728INS/GNSS/\u91cc\u7a0b\u8ba1\u7ec4\u5408\u5bfc\u822a\u7cfb\u7edf\u4e2d\uff0c\u91c7\u7528\u534f\u65b9\u5dee\u53d8\u6362\u7684EKF\u6027\u80fd\u4f18\u4e8e\u4f20\u7edfInEKF\u548c\u539f\u59cbEKF\u3002", "conclusion": "\u63d0\u51fa\u7684CT-ESKF\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u5750\u6807\u7cfb\u89c2\u6d4b\u4e0b\u7684\u6ee4\u6ce2\u95ee\u9898\uff0c\u4e3a\u7ec4\u5408\u5bfc\u822a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6027\u80fd\u66f4\u4f18\u7684\u6ee4\u6ce2\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00081", "categories": ["cs.CY", "cs.HC", "cs.IR", "cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.00081", "abs": "https://arxiv.org/abs/2511.00081", "authors": ["Masfiqur Rahaman", "Maoyejatun Hasana", "Shahad Shahriar Rahman", "MD Sajid Mostafiz Noor", "Razin Reaz Abedin", "Md Toki Tahmid", "Duncan Watson Parris", "Tanzeem Choudhury", "A. B. M. Alim Al Islam", "Tauhidur Rahman"], "title": "Forecasting Occupational Survivability of Rickshaw Pullers in a Changing Climate with Wearable Data", "comment": "This is a preprint version of a manuscript accepted and to be\n  published in the Proceedings of the ACM on Interactive, Mobile, Wearable and\n  Ubiquitous Technologies (IMWUT)", "summary": "Cycle rickshaw pullers are highly vulnerable to extreme heat, yet little is\nknown about how their physiological biomarkers respond under such conditions.\nThis study collected real-time weather and physiological data using wearable\nsensors from 100 rickshaw pullers in Dhaka, Bangladesh. In addition, interviews\nwith 12 pullers explored their knowledge, perceptions, and experiences related\nto climate change. We developed a Linear Gaussian Bayesian Network (LGBN)\nregression model to predict key physiological biomarkers based on activity,\nweather, and demographic features. The model achieved normalized mean absolute\nerror values of 0.82, 0.47, 0.65, and 0.67 for skin temperature, relative\ncardiac cost, skin conductance response, and skin conductance level,\nrespectively. Using projections from 18 CMIP6 climate models, we layered the\nLGBN on future climate forecasts to analyze survivability for current\n(2023-2025) and future years (2026-2100). Based on thresholds of WBGT above\n31.1{\\deg}C and skin temperature above 35{\\deg}C, 32% of rickshaw pullers\nalready face high heat exposure risk. By 2026-2030, this percentage may rise to\n37% with average exposure lasting nearly 12 minutes, or about two-thirds of the\ntrip duration. A thematic analysis of interviews complements these findings,\nshowing that rickshaw pullers recognize their increasing climate vulnerability\nand express concern about its effects on health and occupational survivability.", "AI": {"tldr": "\u7814\u7a76\u4f7f\u7528\u53ef\u7a7f\u6234\u4f20\u611f\u5668\u6536\u96c6\u5b5f\u52a0\u62c9\u56fd\u8fbe\u5361100\u540d\u4e09\u8f6e\u8f66\u592b\u5728\u6781\u7aef\u9ad8\u6e29\u4e0b\u7684\u751f\u7406\u6570\u636e\uff0c\u5f00\u53d1\u7ebf\u6027\u9ad8\u65af\u8d1d\u53f6\u65af\u7f51\u7edc\u6a21\u578b\u9884\u6d4b\u751f\u7406\u6307\u6807\uff0c\u5e76\u7ed3\u5408\u6c14\u5019\u6a21\u578b\u9884\u6d4b\u672a\u6765\u70ed\u66b4\u9732\u98ce\u9669\u3002", "motivation": "\u4e09\u8f6e\u8f66\u592b\u5728\u6781\u7aef\u9ad8\u6e29\u4e0b\u9ad8\u5ea6\u8106\u5f31\uff0c\u4f46\u5bf9\u5176\u751f\u7406\u751f\u7269\u6807\u5fd7\u7269\u5982\u4f55\u54cd\u5e94\u6b64\u7c7b\u6761\u4ef6\u77e5\u4e4b\u751a\u5c11\uff0c\u9700\u8981\u4e86\u89e3\u4ed6\u4eec\u7684\u70ed\u66b4\u9732\u98ce\u9669\u548c\u672a\u6765\u751f\u5b58\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u53ef\u7a7f\u6234\u4f20\u611f\u5668\u6536\u96c6\u5b9e\u65f6\u5929\u6c14\u548c\u751f\u7406\u6570\u636e\uff0c\u5bf9100\u540d\u4e09\u8f6e\u8f66\u592b\u8fdb\u884c\u76d1\u6d4b\uff0c\u8bbf\u8c0812\u540d\u8f66\u592b\u4e86\u89e3\u5176\u8ba4\u77e5\u548c\u7ecf\u9a8c\uff0c\u5f00\u53d1\u7ebf\u6027\u9ad8\u65af\u8d1d\u53f6\u65af\u7f51\u7edc\u56de\u5f52\u6a21\u578b\u9884\u6d4b\u751f\u7406\u6307\u6807\uff0c\u5e76\u5e94\u752818\u4e2aCMIP6\u6c14\u5019\u6a21\u578b\u8fdb\u884c\u672a\u6765\u9884\u6d4b\u3002", "result": "\u6a21\u578b\u5bf9\u76ae\u80a4\u6e29\u5ea6\u3001\u76f8\u5bf9\u5fc3\u810f\u6210\u672c\u3001\u76ae\u80a4\u7535\u5bfc\u53cd\u5e94\u548c\u76ae\u80a4\u7535\u5bfc\u6c34\u5e73\u7684\u6807\u51c6\u5316\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u5206\u522b\u4e3a0.82\u30010.47\u30010.65\u548c0.67\u3002\u76ee\u524d32%\u7684\u8f66\u592b\u9762\u4e34\u9ad8\u70ed\u66b4\u9732\u98ce\u9669\uff0c\u52302026-2030\u5e74\u53ef\u80fd\u5347\u81f337%\uff0c\u5e73\u5747\u66b4\u9732\u65f6\u95f4\u8fd112\u5206\u949f\uff08\u7ea6\u5360\u884c\u7a0b\u7684\u4e09\u5206\u4e4b\u4e8c\uff09\u3002", "conclusion": "\u4e09\u8f6e\u8f66\u592b\u5df2\u9762\u4e34\u663e\u8457\u70ed\u66b4\u9732\u98ce\u9669\uff0c\u4e14\u672a\u6765\u98ce\u9669\u5c06\u8fdb\u4e00\u6b65\u589e\u52a0\u3002\u8bbf\u8c08\u5206\u6790\u8868\u660e\u8f66\u592b\u8ba4\u8bc6\u5230\u81ea\u8eab\u6c14\u5019\u8106\u5f31\u6027\u589e\u52a0\uff0c\u5e76\u62c5\u5fe7\u5bf9\u5065\u5eb7\u548c\u804c\u4e1a\u751f\u5b58\u80fd\u529b\u7684\u5f71\u54cd\u3002"}}
{"id": "2511.00194", "categories": ["cs.AI", "F.2.2, F.4.1"], "pdf": "https://arxiv.org/pdf/2511.00194", "abs": "https://arxiv.org/abs/2511.00194", "authors": ["Jovial Cheukam Ngouonou", "Ramiz Gindullin", "Claude-Guy Quimper", "Nicolas Beldiceanu", "Remi Douence"], "title": "Incremental Selection of Most-Filtering Conjectures and Proofs of the Selected Conjectures", "comment": null, "summary": "We present an improved incremental selection algorithm of the selection\nalgorithm presented in [1] and prove all the selected conjectures.", "AI": {"tldr": "\u6539\u8fdb\u4e86\u6587\u732e[1]\u4e2d\u7684\u589e\u91cf\u9009\u62e9\u7b97\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u6240\u6709\u88ab\u9009\u731c\u60f3", "motivation": "\u6539\u8fdb\u73b0\u6709\u9009\u62e9\u7b97\u6cd5\uff0c\u63d0\u9ad8\u5176\u6548\u7387\u548c\u53ef\u9760\u6027", "method": "\u63d0\u51fa\u6539\u8fdb\u7684\u589e\u91cf\u9009\u62e9\u7b97\u6cd5", "result": "\u6210\u529f\u8bc1\u660e\u4e86\u6240\u6709\u88ab\u9009\u731c\u60f3", "conclusion": "\u6539\u8fdb\u7b97\u6cd5\u6709\u6548\u4e14\u53ef\u9760"}}
{"id": "2511.00139", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00139", "abs": "https://arxiv.org/abs/2511.00139", "authors": ["Yu Cui", "Yujian Zhang", "Lina Tao", "Yang Li", "Xinyu Yi", "Zhibin Li"], "title": "End-to-End Dexterous Arm-Hand VLA Policies via Shared Autonomy: VR Teleoperation Augmented by Autonomous Hand VLA Policy for Efficient Data Collection", "comment": null, "summary": "Achieving human-like dexterous manipulation remains a major challenge for\ngeneral-purpose robots. While Vision-Language-Action (VLA) models show\npotential in learning skills from demonstrations, their scalability is limited\nby scarce high-quality training data. Existing data collection methods face\ninherent constraints: manual teleoperation overloads human operators, while\nautomated planning often produces unnatural motions. We propose a Shared\nAutonomy framework that divides control between macro and micro motions. A\nhuman operator guides the robot's arm pose through intuitive VR teleoperation,\nwhile an autonomous DexGrasp-VLA policy handles fine-grained hand control using\nreal-time tactile and visual feedback. This division significantly reduces\ncognitive load and enables efficient collection of high-quality coordinated\narm-hand demonstrations. Using this data, we train an end-to-end VLA policy\nenhanced with our novel Arm-Hand Feature Enhancement module, which captures\nboth distinct and shared representations of macro and micro movements for more\nnatural coordination. Our Corrective Teleoperation system enables continuous\npolicy improvement through human-in-the-loop failure recovery. Experiments\ndemonstrate that our framework generates high-quality data with minimal\nmanpower and achieves a 90% success rate across diverse objects, including\nunseen instances. Comprehensive evaluations validate the system's effectiveness\nin developing dexterous manipulation capabilities.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5171\u4eab\u81ea\u4e3b\u6846\u67b6\uff0c\u901a\u8fc7VR\u9065\u64cd\u4f5c\u548c\u81ea\u4e3b\u624b\u90e8\u63a7\u5236\u76f8\u7ed3\u5408\u7684\u65b9\u5f0f\uff0c\u9ad8\u6548\u6536\u96c6\u9ad8\u8d28\u91cf\u7684\u624b\u81c2-\u624b\u90e8\u534f\u8c03\u6f14\u793a\u6570\u636e\uff0c\u5e76\u8bad\u7ec3\u7aef\u5230\u7aefVLA\u7b56\u7565\uff0c\u5728\u591a\u6837\u5316\u7269\u4f53\u4e0a\u5b9e\u73b090%\u7684\u6210\u529f\u7387\u3002", "motivation": "\u89e3\u51b3\u7075\u5de7\u64cd\u4f5c\u4e2d\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4eba\u5de5\u9065\u64cd\u4f5c\u8d1f\u62c5\u91cd\u6216\u81ea\u52a8\u89c4\u5212\u52a8\u4f5c\u4e0d\u81ea\u7136\u7684\u5c40\u9650\u6027\u3002", "method": "\u5171\u4eab\u81ea\u4e3b\u6846\u67b6\uff1a\u4eba\u7c7b\u901a\u8fc7VR\u63a7\u5236\u624b\u81c2\u5b8f\u89c2\u8fd0\u52a8\uff0c\u81ea\u4e3bDexGrasp-VLA\u7b56\u7565\u5904\u7406\u7cbe\u7ec6\u624b\u90e8\u63a7\u5236\uff1b\u4f7f\u7528Arm-Hand\u7279\u5f81\u589e\u5f3a\u6a21\u5757\u6355\u6349\u5b8f\u89c2\u548c\u5fae\u89c2\u8fd0\u52a8\u7684\u5171\u4eab\u8868\u793a\uff1b\u901a\u8fc7\u7ea0\u6b63\u9065\u64cd\u4f5c\u5b9e\u73b0\u6301\u7eed\u7b56\u7565\u6539\u8fdb\u3002", "result": "\u4ee5\u6700\u5c11\u4eba\u529b\u751f\u6210\u9ad8\u8d28\u91cf\u6570\u636e\uff0c\u5728\u591a\u6837\u5316\u7269\u4f53\uff08\u5305\u62ec\u672a\u89c1\u5b9e\u4f8b\uff09\u4e0a\u8fbe\u523090%\u7684\u6210\u529f\u7387\uff0c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u5728\u5f00\u53d1\u7075\u5de7\u64cd\u4f5c\u80fd\u529b\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u7075\u5de7\u64cd\u4f5c\u4e2d\u7684\u6570\u636e\u6536\u96c6\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u4eba\u673a\u534f\u4f5c\u548c\u6301\u7eed\u7684\u7b56\u7565\u6539\u8fdb\uff0c\u4e3a\u901a\u7528\u673a\u5668\u4eba\u7684\u7075\u5de7\u64cd\u4f5c\u80fd\u529b\u53d1\u5c55\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2511.01332", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2511.01332", "abs": "https://arxiv.org/abs/2511.01332", "authors": ["Xiufeng Li", "Zefang Li"], "title": "Internet of Things Platform Service Supply Innovation: Exploring the Impact of Overconfidence", "comment": null, "summary": "This paper explores the impact of manufacturers' overconfidence on their\ncollaborative innovation with platforms in the Internet of Things (IoT)\nenvironment by constructing a game model. It is found that in both usage-based\nand revenue-sharing contracts, manufacturers' and platforms' innovation inputs,\nprofit levels, and pricing strategies are significantly affected by the\nproportion of non-privacy-sensitive customers, and grow in tandem with the rise\nof this proportion. In usage-based contracts, moderate overconfidence\nincentivizes manufacturers to increase hardware innovation investment and\nimprove overall supply chain revenues, but may cause platforms to reduce\nsoftware innovation; under revenue-sharing contracts, overconfidence positively\nincentivizes hardware innovation and pricing more strongly, while platform\nsoftware innovation varies nonlinearly depending on the share ratio. Comparing\nthe differences in manufacturers' decisions with and without overconfidence\nsuggests that moderate overconfidence can lead to supply chain Pareto\nimprovements under a given contract. This paper provides new perspectives for\nunderstanding the complex interactions between manufacturers and platforms in\nIoT supply chains, as well as theoretical support and practical guidance for\nactual business decisions.", "AI": {"tldr": "\u7814\u7a76\u5236\u9020\u5546\u8fc7\u5ea6\u81ea\u4fe1\u5bf9\u7269\u8054\u7f51\u73af\u5883\u4e0b\u4e0e\u5e73\u53f0\u534f\u540c\u521b\u65b0\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u535a\u5f08\u6a21\u578b\u53d1\u73b0\u5728\u4e24\u79cd\u5408\u540c\u7c7b\u578b\u4e2d\uff0c\u9002\u5ea6\u8fc7\u5ea6\u81ea\u4fe1\u80fd\u6fc0\u52b1\u786c\u4ef6\u521b\u65b0\u5e76\u53ef\u80fd\u5b9e\u73b0\u4f9b\u5e94\u94fe\u5e15\u7d2f\u6258\u6539\u8fdb\u3002", "motivation": "\u63a2\u7d22\u7269\u8054\u7f51\u73af\u5883\u4e2d\u5236\u9020\u5546\u8fc7\u5ea6\u81ea\u4fe1\u5982\u4f55\u5f71\u54cd\u5176\u4e0e\u5e73\u53f0\u7684\u534f\u540c\u521b\u65b0\u5173\u7cfb\uff0c\u4e3a\u7406\u89e3\u590d\u6742\u4f9b\u5e94\u94fe\u4e92\u52a8\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002", "method": "\u6784\u5efa\u535a\u5f08\u6a21\u578b\uff0c\u5206\u6790\u4f7f\u7528\u91cf\u5408\u540c\u548c\u6536\u5165\u5206\u6210\u5408\u540c\u4e24\u79cd\u60c5\u5883\u4e0b\u5236\u9020\u5546\u548c\u5e73\u53f0\u7684\u51b3\u7b56\u884c\u4e3a\u3002", "result": "\u5728\u4e24\u79cd\u5408\u540c\u4e2d\uff0c\u975e\u9690\u79c1\u654f\u611f\u5ba2\u6237\u6bd4\u4f8b\u663e\u8457\u5f71\u54cd\u521b\u65b0\u6295\u5165\u548c\u5229\u6da6\uff1b\u9002\u5ea6\u8fc7\u5ea6\u81ea\u4fe1\u80fd\u6fc0\u52b1\u786c\u4ef6\u521b\u65b0\u6295\u8d44\uff0c\u4f46\u53ef\u80fd\u964d\u4f4e\u5e73\u53f0\u8f6f\u4ef6\u521b\u65b0\uff1b\u6536\u5165\u5206\u6210\u5408\u540c\u4e0b\u8fc7\u5ea6\u81ea\u4fe1\u5bf9\u786c\u4ef6\u521b\u65b0\u548c\u5b9a\u4ef7\u7684\u6fc0\u52b1\u66f4\u5f3a\u3002", "conclusion": "\u9002\u5ea6\u8fc7\u5ea6\u81ea\u4fe1\u5728\u7279\u5b9a\u5408\u540c\u6761\u4ef6\u4e0b\u53ef\u5e26\u6765\u4f9b\u5e94\u94fe\u5e15\u7d2f\u6258\u6539\u8fdb\uff0c\u4e3a\u5b9e\u9645\u5546\u4e1a\u51b3\u7b56\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u548c\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2511.01142", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.01142", "abs": "https://arxiv.org/abs/2511.01142", "authors": ["Valerio La Gatta", "Marco Postiglione", "Jeremy Gilbert", "Daniel W. Linna Jr.", "Morgan Manella Greenfield", "Aaron Shaw", "V. S. Subrahmanian"], "title": "DEEP: A Discourse Evolution Engine for Predictions about Social Movements", "comment": "Accepted for publication at IAAI 2026. The final version will be\n  available in the AAAI proceedings", "summary": "Numerous social movements (SMs) around the world help support the UN's\nSustainable Development Goals (SDGs). Understanding how key events shape SMs is\nkey to the achievement of the SDGs. We have developed SMART (Social Media\nAnalysis & Reasoning Tool) to track social movements related to the SDGs. SMART\nwas designed by a multidisciplinary team of AI researchers, journalists,\ncommunications scholars and legal experts. This paper describes SMART's\ntransformer-based multivariate time series Discourse Evolution Engine for\nPredictions about Social Movements (DEEP) to predict the volume of future\narticles/posts and the emotions expressed. DEEP outputs probabilistic forecasts\nwith uncertainty estimates, providing critical support for editorial planning\nand strategic decision-making. We evaluate DEEP with a case study of the #MeToo\nmovement by creating a novel longitudinal dataset (433K Reddit posts and 121K\nnews articles) from September 2024 to June 2025 that will be publicly released\nfor research purposes upon publication of this paper.", "AI": {"tldr": "SMART\u5de5\u5177\u4f7f\u7528\u57fa\u4e8eTransformer\u7684\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6a21\u578bDEEP\u6765\u9884\u6d4b\u793e\u4f1a\u8fd0\u52a8\u76f8\u5173\u7684\u6587\u7ae0/\u5e16\u5b50\u6570\u91cf\u548c\u60c5\u611f\u8868\u8fbe\uff0c\u652f\u6301\u8054\u5408\u56fd\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\u7684\u5b9e\u73b0\u3002", "motivation": "\u7406\u89e3\u5173\u952e\u4e8b\u4ef6\u5982\u4f55\u5f71\u54cd\u793e\u4f1a\u8fd0\u52a8\u5bf9\u5b9e\u73b0\u8054\u5408\u56fd\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5f00\u53d1\u5de5\u5177\u6765\u8ffd\u8e2a\u548c\u5206\u6790\u76f8\u5173\u793e\u4f1a\u8fd0\u52a8\u3002", "method": "\u5f00\u53d1\u4e86SMART\u5de5\u5177\uff0c\u91c7\u7528\u57fa\u4e8eTransformer\u7684\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6a21\u578bDEEP\uff0c\u80fd\u591f\u9884\u6d4b\u672a\u6765\u6587\u7ae0/\u5e16\u5b50\u6570\u91cf\u548c\u60c5\u611f\u8868\u8fbe\uff0c\u5e76\u63d0\u4f9b\u6982\u7387\u9884\u6d4b\u548c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002", "result": "\u901a\u8fc7\u5bf9#MeToo\u8fd0\u52a8\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u521b\u5efa\u4e86\u5305\u542b43.3\u4e07Reddit\u5e16\u5b50\u548c12.1\u4e07\u65b0\u95fb\u6587\u7ae0\u7684\u65b0\u578b\u7eb5\u5411\u6570\u636e\u96c6\uff0c\u9a8c\u8bc1\u4e86DEEP\u6a21\u578b\u7684\u6709\u6548\u6027\u3002", "conclusion": "DEEP\u6a21\u578b\u80fd\u591f\u63d0\u4f9b\u6982\u7387\u9884\u6d4b\u548c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u4e3a\u7f16\u8f91\u89c4\u5212\u548c\u6218\u7565\u51b3\u7b56\u63d0\u4f9b\u5173\u952e\u652f\u6301\uff0c\u76f8\u5173\u6570\u636e\u96c6\u5c06\u5728\u8bba\u6587\u53d1\u8868\u540e\u516c\u5f00\u4f9b\u7814\u7a76\u4f7f\u7528\u3002"}}
{"id": "2511.00562", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.00562", "abs": "https://arxiv.org/abs/2511.00562", "authors": ["Shuaijun Li", "Jie Tang", "Beixiong Zheng", "Lipeng Zhu", "Cui Yang", "Nan Zhao", "Xiu Yin Zhang", "Kai-Kit Wong"], "title": "Rotatable Antenna System Empowered Low-Altitude Economy: Opportunities and Challenges", "comment": "8 pages, 5 figures, accepted in IEEE Wireless Communication (Early\n  Access)", "summary": "Low-altitude economy (LAE) is an emerging technological paradigm that enables\ncontinuous airspace coverage at multiple altitudes by providing highly reliable\ndata connectivity for numerous low-altitude applications. However, existing\nnetworks cannot sufficiently support LAE development, as current base stations\n(BSs) are primarily designed for terrestrial users and lack the capability to\nprovide continuous coverage at low altitudes. To overcome these challenges,\nrotatable antenna system (RAS) is introduced in LAE, enabling flexible\nbeamforming by dynamically adjusting the boresight of directional antennas to\nextend low-altitude coverage and enhance the stability of data transmission. In\nthis article, we first provide an overview of RAS-empowered LAE applications,\nincluding low-altitude communication, sensing, control, and computation. Then,\nwe present two practical RAS deployment strategies for LAE scenarios, namely\nRAS-aided multi-BS and multi-unmanned aerial vehicle (UAV) cooperative\ncoverages, as well as provide detailed discussions on their system\narchitectures and performance benefits. Additionally, key design issues of RAS\nin LAE are discussed, including channel modeling and estimation, cellular\naccess and interference cancellation, as well as RAS configuration and\nboresight optimization. Finally, we demonstrate the performance gains of RAS in\nLAE networks through experimental and simulation results.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u53ef\u65cb\u8f6c\u5929\u7ebf\u7cfb\u7edf(RAS)\u5728\u4f4e\u7a7a\u7ecf\u6d4e(LAE)\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u5b9a\u5411\u5929\u7ebf\u6ce2\u675f\u65b9\u5411\u6765\u6269\u5c55\u4f4e\u7a7a\u8986\u76d6\u8303\u56f4\u5e76\u589e\u5f3a\u6570\u636e\u4f20\u8f93\u7a33\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u7f51\u7edc\u57fa\u7ad9\u4e3b\u8981\u8bbe\u8ba1\u7528\u4e8e\u5730\u9762\u7528\u6237\uff0c\u65e0\u6cd5\u4e3a\u4f4e\u7a7a\u5e94\u7528\u63d0\u4f9b\u8fde\u7eed\u8986\u76d6\uff0c\u9650\u5236\u4e86\u4f4e\u7a7a\u7ecf\u6d4e\u7684\u53d1\u5c55\u3002", "method": "\u63d0\u51faRAS\u6280\u672f\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u5b9a\u5411\u5929\u7ebf\u6ce2\u675f\u65b9\u5411\u5b9e\u73b0\u7075\u6d3b\u6ce2\u675f\u6210\u5f62\uff0c\u5e76\u8bbe\u8ba1\u4e86RAS\u8f85\u52a9\u7684\u591a\u57fa\u7ad9\u548c\u591a\u65e0\u4eba\u673a\u534f\u540c\u8986\u76d6\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u548c\u4eff\u771f\u7ed3\u679c\u8868\u660eRAS\u5728LAE\u7f51\u7edc\u4e2d\u5e26\u6765\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "RAS\u6280\u672f\u80fd\u591f\u6709\u6548\u89e3\u51b3\u4f4e\u7a7a\u8986\u76d6\u95ee\u9898\uff0c\u4e3a\u4f4e\u7a7a\u7ecf\u6d4e\u53d1\u5c55\u63d0\u4f9b\u53ef\u9760\u7684\u6570\u636e\u8fde\u63a5\u652f\u6301\u3002"}}
{"id": "2511.00105", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00105", "abs": "https://arxiv.org/abs/2511.00105", "authors": ["Majid Memari", "Krista Ruggles"], "title": "Artificial Intelligence in Elementary STEM Education: A Systematic Review of Current Applications and Future Challenges", "comment": null, "summary": "Artificial intelligence (AI) is transforming elementary STEM education, yet\nevidence remains fragmented. This systematic review synthesizes 258 studies\n(2020-2025) examining AI applications across eight categories: intelligent\ntutoring systems (45% of studies), learning analytics (18%), automated\nassessment (12%), computer vision (8%), educational robotics (7%), multimodal\nsensing (6%), AI-enhanced extended reality (XR) (4%), and adaptive content\ngeneration. The analysis shows that most studies focus on upper elementary\ngrades (65%) and mathematics (38%), with limited cross-disciplinary STEM\nintegration (15%). While conversational AI demonstrates moderate effectiveness\n(d = 0.45-0.70 where reported), only 34% of studies include standardized effect\nsizes. Eight major gaps limit real-world impact: fragmented ecosystems,\ndevelopmental inappropriateness, infrastructure barriers, lack of privacy\nframeworks, weak STEM integration, equity disparities, teacher marginalization,\nand narrow assessment scopes. Geographic distribution is also uneven, with 90%\nof studies originating from North America, East Asia, and Europe. Future\ndirections call for interoperable architectures that support authentic STEM\nintegration, grade-appropriate design, privacy-preserving analytics, and\nteacher-centered implementations that enhance rather than replace human\nexpertise.", "AI": {"tldr": "\u8fd9\u7bc7\u7cfb\u7edf\u7efc\u8ff0\u5206\u6790\u4e862020-2025\u5e74\u95f4258\u9879\u5173\u4e8eAI\u5728\u5c0f\u5b66STEM\u6559\u80b2\u4e2d\u5e94\u7528\u7684\u7814\u7a76\uff0c\u53d1\u73b0\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u3001\u5b66\u4e60\u5206\u6790\u548c\u81ea\u52a8\u8bc4\u4f30\u7b49\u9886\u57df\uff0c\u4f46\u5b58\u5728\u751f\u6001\u7cfb\u7edf\u788e\u7247\u5316\u3001\u53d1\u5c55\u4e0d\u9002\u5b9c\u6027\u3001\u57fa\u7840\u8bbe\u65bd\u969c\u788d\u7b49\u516b\u5927\u5c40\u9650\u3002", "motivation": "AI\u6b63\u5728\u53d8\u9769\u5c0f\u5b66STEM\u6559\u80b2\uff0c\u4f46\u73b0\u6709\u8bc1\u636e\u96f6\u6563\uff0c\u9700\u8981\u7cfb\u7edf\u68b3\u7406AI\u5e94\u7528\u73b0\u72b6\u3001\u6548\u679c\u548c\u5c40\u9650\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u65b9\u5411\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u6790258\u9879\u7814\u7a76\uff082020-2025\u5e74\uff09\uff0c\u6db5\u76d6\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u3001\u5b66\u4e60\u5206\u6790\u3001\u81ea\u52a8\u8bc4\u4f30\u3001\u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u6559\u80b2\u673a\u5668\u4eba\u3001\u591a\u6a21\u6001\u4f20\u611f\u3001AI\u589e\u5f3a\u6269\u5c55\u73b0\u5b9e\u548c\u81ea\u9002\u5e94\u5185\u5bb9\u751f\u6210\u7b49\u516b\u4e2a\u7c7b\u522b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5927\u591a\u6570\u7814\u7a76\u5173\u6ce8\u9ad8\u5e74\u7ea7\u5c0f\u5b66\uff0865%\uff09\u548c\u6570\u5b66\u5b66\u79d1\uff0838%\uff09\uff0c\u8de8\u5b66\u79d1STEM\u6574\u5408\u6709\u9650\uff0815%\uff09\u3002\u5bf9\u8bddAI\u663e\u793a\u51fa\u4e2d\u7b49\u6548\u679c\uff08d = 0.45-0.70\uff09\uff0c\u4f46\u53ea\u670934%\u7684\u7814\u7a76\u5305\u542b\u6807\u51c6\u5316\u6548\u5e94\u503c\u3002\u5b58\u5728\u516b\u5927\u5c40\u9650\u5f71\u54cd\u5b9e\u9645\u5e94\u7528\u6548\u679c\u3002", "conclusion": "\u672a\u6765\u9700\u8981\u5f00\u53d1\u652f\u6301\u771f\u5b9eSTEM\u6574\u5408\u7684\u4e92\u64cd\u4f5c\u67b6\u6784\u3001\u9002\u5408\u5e74\u7ea7\u7684\u8bbe\u8ba1\u3001\u4fdd\u62a4\u9690\u79c1\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u4ee5\u53ca\u4ee5\u6559\u5e08\u4e3a\u4e2d\u5fc3\u7684\u5b9e\u65bd\u7b56\u7565\uff0c\u589e\u5f3a\u800c\u975e\u53d6\u4ee3\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u3002"}}
{"id": "2511.00206", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00206", "abs": "https://arxiv.org/abs/2511.00206", "authors": ["Dirk U. Wulff", "Rui Mata"], "title": "Advancing Cognitive Science with LLMs", "comment": null, "summary": "Cognitive science faces ongoing challenges in knowledge synthesis and\nconceptual clarity, in part due to its multifaceted and interdisciplinary\nnature. Recent advances in artificial intelligence, particularly the\ndevelopment of large language models (LLMs), offer tools that may help to\naddress these issues. This review examines how LLMs can support areas where the\nfield has historically struggled, including establishing cross-disciplinary\nconnections, formalizing theories, developing clear measurement taxonomies,\nachieving generalizability through integrated modeling frameworks, and\ncapturing contextual and individual variation. We outline the current\ncapabilities and limitations of LLMs in these domains, including potential\npitfalls. Taken together, we conclude that LLMs can serve as tools for a more\nintegrative and cumulative cognitive science when used judiciously to\ncomplement, rather than replace, human expertise.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u5e2e\u52a9\u89e3\u51b3\u8ba4\u77e5\u79d1\u5b66\u9886\u57df\u9762\u4e34\u7684\u6311\u6218\uff0c\u5305\u62ec\u8de8\u5b66\u79d1\u8fde\u63a5\u3001\u7406\u8bba\u5f62\u5f0f\u5316\u3001\u6d4b\u91cf\u5206\u7c7b\u5b66\u3001\u901a\u7528\u6027\u5efa\u6a21\u4ee5\u53ca\u4e2a\u4f53\u5dee\u5f02\u6355\u6349\u7b49\u95ee\u9898\u3002", "motivation": "\u8ba4\u77e5\u79d1\u5b66\u56e0\u5176\u591a\u9762\u6027\u548c\u8de8\u5b66\u79d1\u6027\u8d28\uff0c\u5728\u77e5\u8bc6\u6574\u5408\u548c\u6982\u5ff5\u6e05\u6670\u5ea6\u65b9\u9762\u9762\u4e34\u6301\u7eed\u6311\u6218\u3002\u4eba\u5de5\u667a\u80fd\u7279\u522b\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u63d0\u4f9b\u4e86\u6f5c\u5728\u5de5\u5177\u3002", "method": "\u672c\u6587\u901a\u8fc7\u56de\u987e\u6027\u5206\u6790\uff0c\u8003\u5bdf\u4e86LLMs\u5728\u8ba4\u77e5\u79d1\u5b66\u591a\u4e2a\u5173\u952e\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u5305\u62ec\u5efa\u7acb\u8de8\u5b66\u79d1\u8054\u7cfb\u3001\u5f62\u5f0f\u5316\u7406\u8bba\u3001\u5f00\u53d1\u6d4b\u91cf\u5206\u7c7b\u5b66\u3001\u5b9e\u73b0\u901a\u7528\u6027\u5efa\u6a21\u6846\u67b6\u4ee5\u53ca\u6355\u6349\u60c5\u5883\u548c\u4e2a\u4f53\u5dee\u5f02\u3002", "result": "\u7814\u7a76\u53d1\u73b0LLMs\u5728\u8fd9\u4e9b\u9886\u57df\u5177\u6709\u652f\u6301\u80fd\u529b\uff0c\u4f46\u4e5f\u5b58\u5728\u5c40\u9650\u6027\u3002\u6587\u7ae0\u6982\u8ff0\u4e86LLMs\u5f53\u524d\u7684\u80fd\u529b\u548c\u9650\u5236\uff0c\u5305\u62ec\u6f5c\u5728\u7684\u9677\u9631\u3002", "conclusion": "\u8c28\u614e\u4f7f\u7528LLMs\u4f5c\u4e3a\u8865\u5145\u800c\u975e\u66ff\u4ee3\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u7684\u5de5\u5177\uff0c\u53ef\u4ee5\u4fc3\u8fdb\u8ba4\u77e5\u79d1\u5b66\u5411\u66f4\u6574\u5408\u548c\u7d2f\u79ef\u7684\u65b9\u5411\u53d1\u5c55\u3002"}}
{"id": "2511.00153", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00153", "abs": "https://arxiv.org/abs/2511.00153", "authors": ["Justin Yu", "Yide Shentu", "Di Wu", "Pieter Abbeel", "Ken Goldberg", "Philipp Wu"], "title": "EgoMI: Learning Active Vision and Whole-Body Manipulation from Egocentric Human Demonstrations", "comment": null, "summary": "Imitation learning from human demonstrations offers a promising approach for\nrobot skill acquisition, but egocentric human data introduces fundamental\nchallenges due to the embodiment gap. During manipulation, humans actively\ncoordinate head and hand movements, continuously reposition their viewpoint and\nuse pre-action visual fixation search strategies to locate relevant objects.\nThese behaviors create dynamic, task-driven head motions that static robot\nsensing systems cannot replicate, leading to a significant distribution shift\nthat degrades policy performance. We present EgoMI (Egocentric Manipulation\nInterface), a framework that captures synchronized end-effector and active head\ntrajectories during manipulation tasks, resulting in data that can be\nretargeted to compatible semi-humanoid robot embodiments. To handle rapid and\nwide-spanning head viewpoint changes, we introduce a memory-augmented policy\nthat selectively incorporates historical observations. We evaluate our approach\non a bimanual robot equipped with an actuated camera head and find that\npolicies with explicit head-motion modeling consistently outperform baseline\nmethods. Results suggest that coordinated hand-eye learning with EgoMI\neffectively bridges the human-robot embodiment gap for robust imitation\nlearning on semi-humanoid embodiments. Project page:\nhttps://egocentric-manipulation-interface.github.io", "AI": {"tldr": "EgoMI\u6846\u67b6\u901a\u8fc7\u540c\u6b65\u6355\u6349\u672b\u7aef\u6267\u884c\u5668\u548c\u4e3b\u52a8\u5934\u90e8\u8f68\u8ff9\u6765\u89e3\u51b3\u6a21\u4eff\u5b66\u4e60\u4e2d\u7684\u4eba\u7c7b-\u673a\u5668\u4eba\u5177\u8eab\u5dee\u8ddd\u95ee\u9898\uff0c\u5f15\u5165\u8bb0\u5fc6\u589e\u5f3a\u7b56\u7565\u6765\u5904\u7406\u5feb\u901f\u89c6\u89d2\u53d8\u5316\uff0c\u5728\u534a\u4eba\u5f62\u673a\u5668\u4eba\u4e0a\u5b9e\u73b0\u4e86\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u6a21\u4eff\u5b66\u4e60\u4e2d\u56e0\u4eba\u7c7b\u5177\u8eab\u7279\u6027\uff08\u4e3b\u52a8\u534f\u8c03\u5934\u624b\u8fd0\u52a8\u3001\u52a8\u6001\u89c6\u89d2\u91cd\u5b9a\u4f4d\u3001\u9884\u52a8\u4f5c\u89c6\u89c9\u6ce8\u89c6\u641c\u7d22\uff09\u4e0e\u9759\u6001\u673a\u5668\u4eba\u611f\u77e5\u7cfb\u7edf\u4e4b\u95f4\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898\u3002", "method": "\u63d0\u51faEgoMI\u6846\u67b6\uff0c\u6355\u83b7\u540c\u6b65\u7684\u672b\u7aef\u6267\u884c\u5668\u548c\u4e3b\u52a8\u5934\u90e8\u8f68\u8ff9\uff1b\u5f15\u5165\u8bb0\u5fc6\u589e\u5f3a\u7b56\u7565\uff0c\u9009\u62e9\u6027\u6574\u5408\u5386\u53f2\u89c2\u6d4b\u6765\u5904\u7406\u5feb\u901f\u89c6\u89d2\u53d8\u5316\u3002", "result": "\u5728\u914d\u5907\u9a71\u52a8\u76f8\u673a\u5934\u7684\u53cc\u81c2\u673a\u5668\u4eba\u4e0a\u8bc4\u4f30\uff0c\u663e\u793a\u5177\u6709\u663e\u5f0f\u5934\u90e8\u8fd0\u52a8\u5efa\u6a21\u7684\u7b56\u7565\u6301\u7eed\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "EgoMI\u901a\u8fc7\u534f\u8c03\u7684\u624b\u773c\u5b66\u4e60\u6709\u6548\u5f25\u5408\u4e86\u4eba\u7c7b-\u673a\u5668\u4eba\u5177\u8eab\u5dee\u8ddd\uff0c\u4e3a\u534a\u4eba\u5f62\u673a\u5668\u4eba\u5b9e\u73b0\u4e86\u7a33\u5065\u7684\u6a21\u4eff\u5b66\u4e60\u3002"}}
{"id": "2511.01473", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2511.01473", "abs": "https://arxiv.org/abs/2511.01473", "authors": ["Elena Pisanelli"], "title": "Measuring Domestic Violence. Individual Attitudes and Time Use Within the Household", "comment": null, "summary": "This paper proposes a novel empirical strategy to measure cultural\njustifications of domestic violence within households, with direct implications\nfor demographic behavior and gender inequality. Leveraging survey data on\nindividual attitudes and high-frequency time-use diaries from Italian couples\nwith children, I construct a composite index that integrates stated beliefs\nwith observed household practices. Using structural equation modeling, I\ndisentangle latent tolerance of domestic violence from reported attitudes and\nvalidate the index against both individual and partner characteristics, as well\nas time allocation patterns. Results reveal systematic heterogeneity by gender,\neducation, and normative environments. Conservative gender and parenthood norms\nare strong predictors of tolerance, while higher male education reduces it.\nTolerance of violence is also positively associated with reported leisure time\nwith partners and children, suggesting that co-presence does not necessarily\nreflect egalitarian interaction but may coexist with unequal bargaining\nstructures. Beyond advancing measurement, the findings highlight how cultural\ntolerance of domestic violence is embedded in household arrangements that\ninfluence fertility, labor supply, and the intergenerational transmission of\nnorms. The proposed framework offers a scalable tool for economists and\npolicymakers to monitor hidden inequalities and design interventions targeting\nfamily stability, gender equity, and child well-being.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6d4b\u91cf\u5bb6\u5ead\u66b4\u529b\u6587\u5316\u8fa9\u62a4\u7684\u65b0\u65b9\u6cd5\uff0c\u7ed3\u5408\u6001\u5ea6\u8c03\u67e5\u548c\u65f6\u95f4\u4f7f\u7528\u6570\u636e\u6784\u5efa\u7efc\u5408\u6307\u6570\uff0c\u63ed\u793a\u4e86\u5bb9\u5fcd\u5ea6\u4e0e\u6027\u522b\u3001\u6559\u80b2\u3001\u89c4\u8303\u73af\u5883\u7684\u5173\u7cfb\u3002", "motivation": "\u6d4b\u91cf\u5bb6\u5ead\u66b4\u529b\u7684\u6587\u5316\u8fa9\u62a4\u5bf9\u7406\u89e3\u4eba\u53e3\u884c\u4e3a\u548c\u6027\u522b\u4e0d\u5e73\u7b49\u6709\u91cd\u8981\u610f\u4e49\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u9690\u85cf\u7684\u4e0d\u5e73\u7b49\u73b0\u8c61\u3002", "method": "\u4f7f\u7528\u610f\u5927\u5229\u6709\u5b50\u5973\u592b\u5987\u7684\u8c03\u67e5\u6570\u636e\u548c\u65f6\u95f4\u4f7f\u7528\u65e5\u8bb0\uff0c\u6784\u5efa\u7efc\u5408\u6307\u6570\uff0c\u91c7\u7528\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\u5206\u79bb\u6f5c\u5728\u5bb9\u5fcd\u5ea6\uff0c\u5e76\u901a\u8fc7\u4e2a\u4eba\u7279\u5f81\u548c\u65f6\u95f4\u5206\u914d\u6a21\u5f0f\u9a8c\u8bc1\u3002", "result": "\u53d1\u73b0\u5bb9\u5fcd\u5ea6\u5b58\u5728\u6027\u522b\u3001\u6559\u80b2\u548c\u89c4\u8303\u73af\u5883\u7684\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u4fdd\u5b88\u6027\u522b\u548c\u80b2\u513f\u89c4\u8303\u662f\u5f3a\u9884\u6d4b\u56e0\u5b50\uff0c\u7537\u6027\u6559\u80b2\u7a0b\u5ea6\u9ad8\u5219\u5bb9\u5fcd\u5ea6\u4f4e\u3002\u5bb9\u5fcd\u5ea6\u4e0e\u4f34\u4fa3\u548c\u5b50\u5973\u7684\u4f11\u95f2\u65f6\u95f4\u6b63\u76f8\u5173\u3002", "conclusion": "\u6587\u5316\u5bb9\u5fcd\u5ea6\u5d4c\u5165\u5bb6\u5ead\u5b89\u6392\u4e2d\uff0c\u5f71\u54cd\u751f\u80b2\u3001\u52b3\u52a8\u4f9b\u7ed9\u548c\u89c4\u8303\u4ee3\u9645\u4f20\u9012\u3002\u8be5\u6846\u67b6\u4e3a\u76d1\u6d4b\u9690\u85cf\u4e0d\u5e73\u7b49\u548c\u8bbe\u8ba1\u5e72\u9884\u63aa\u65bd\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u5de5\u5177\u3002"}}
{"id": "2511.01228", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01228", "abs": "https://arxiv.org/abs/2511.01228", "authors": ["Jiahui Gao", "Kuang Zhou", "Yuchen Zhu"], "title": "Influence-aware Causal Autoencoder Network for Node Importance Ranking in Complex Networks", "comment": null, "summary": "Node importance ranking is a fundamental problem in graph data analysis.\nExisting approaches typically rely on node features derived from either\ntraditional centrality measures or advanced graph representation learning\nmethods, which depend directly on the target network's topology. However, this\nreliance on structural information raises privacy concerns and often leads to\npoor generalization across different networks. In this work, we address a key\nquestion: Can we design a node importance ranking model trained exclusively on\nsynthetic networks that is effectively appliable to real-world networks,\neliminating the need to rely on the topology of target networks and improving\nboth practicality and generalizability? We answer this question affirmatively\nby proposing the Influence-aware Causal Autoencoder Network (ICAN), a novel\nframework that leverages causal representation learning to get robust,\ninvariant node embeddings for cross-network ranking tasks. Firstly, ICAN\nintroduces an influence-aware causal representation learning module within an\nautoencoder architecture to extract node embeddings that are causally related\nto node importance. Moreover, we introduce a causal ranking loss and design a\nunified optimization framework that jointly optimizes the reconstruction and\nranking objectives, enabling mutual reinforcement between node representation\nlearning and ranking optimization. This design allows ICAN, trained on\nsynthetic networks, to generalize effectively across diverse real-world graphs.\nExtensive experiments on multiple benchmark datasets demonstrate that ICAN\nconsistently outperforms state-of-the-art baselines in terms of both ranking\naccuracy and generalization capability.", "AI": {"tldr": "\u63d0\u51fa\u4e86ICAN\u6846\u67b6\uff0c\u901a\u8fc7\u56e0\u679c\u8868\u793a\u5b66\u4e60\u5728\u5408\u6210\u7f51\u7edc\u4e0a\u8bad\u7ec3\u8282\u70b9\u91cd\u8981\u6027\u6392\u540d\u6a21\u578b\uff0c\u65e0\u9700\u4f9d\u8d56\u76ee\u6807\u7f51\u7edc\u62d3\u6251\uff0c\u5b9e\u73b0\u8de8\u7f51\u7edc\u7684\u6cdb\u5316\u5e94\u7528", "motivation": "\u73b0\u6709\u8282\u70b9\u91cd\u8981\u6027\u6392\u540d\u65b9\u6cd5\u4f9d\u8d56\u76ee\u6807\u7f51\u7edc\u62d3\u6251\u7ed3\u6784\uff0c\u5b58\u5728\u9690\u79c1\u95ee\u9898\u548c\u6cdb\u5316\u80fd\u529b\u5dee\u7684\u95ee\u9898\uff0c\u9700\u8981\u8bbe\u8ba1\u4e0d\u4f9d\u8d56\u76ee\u6807\u7f51\u7edc\u62d3\u6251\u7684\u901a\u7528\u6a21\u578b", "method": "\u4f7f\u7528\u5f71\u54cd\u611f\u77e5\u56e0\u679c\u8868\u793a\u5b66\u4e60\u6a21\u5757\uff0c\u5728\u81ea\u7f16\u7801\u5668\u67b6\u6784\u4e2d\u63d0\u53d6\u4e0e\u8282\u70b9\u91cd\u8981\u6027\u56e0\u679c\u76f8\u5173\u7684\u5d4c\u5165\uff0c\u7ed3\u5408\u56e0\u679c\u6392\u540d\u635f\u5931\u548c\u7edf\u4e00\u4f18\u5316\u6846\u67b6", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cICAN\u5728\u6392\u540d\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "ICAN\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u5728\u5408\u6210\u7f51\u7edc\u4e0a\u8bad\u7ec3\u3001\u5728\u771f\u5b9e\u7f51\u7edc\u4e0a\u5e94\u7528\u7684\u8282\u70b9\u91cd\u8981\u6027\u6392\u540d\uff0c\u89e3\u51b3\u4e86\u9690\u79c1\u548c\u6cdb\u5316\u95ee\u9898"}}
{"id": "2511.00582", "categories": ["eess.SY", "cs.SY", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.00582", "abs": "https://arxiv.org/abs/2511.00582", "authors": ["Carsten Hartmann", "Nil Rodellas-Gr\u00e0cia", "Christian Wallisch", "Thiemo Pesch", "Frank K. Wilhelm", "Dirk Witthaut", "Tobias Stollenwerk", "Andrea Benigni"], "title": "Towards Quantum Algorithms for the Optimization of Spanning Trees: The Power Distribution Grids Use Case", "comment": null, "summary": "Optimizing the topology of networks is an important challenge across\nengineering disciplines. In energy systems, network reconfiguration can\nsubstantially reduce losses and costs and thus support the energy transition.\nUnfortunately, many related optimization problems are NP hard, restricting\npractical applications. In this article, we address the problem of minimizing\nlosses in radial networks, a problem that routinely arises in distribution grid\noperation. We show that even the computation of approximate solutions is\ncomputationally hard and propose quantum optimization as a promising\nalternative. We derive two quantum algorithmic primitives based on the Quantum\nAlternating Operator Ansatz (QAOA) that differ in the sampling of network\ntopologies: a tailored sampling of radial topologies and simple sampling with\npenalty terms to suppress non-radial topologies. We show how to apply these\nalgorithmic primitives to distribution grid reconfiguration and quantify the\nnecessary quantum resources.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u91cf\u5b50\u4f18\u5316\u65b9\u6cd5\u6765\u89e3\u51b3\u5f84\u5411\u7f51\u7edc\u62d3\u6251\u4f18\u5316\u95ee\u9898\uff0c\u7279\u522b\u662f\u914d\u7535\u7f51\u7edc\u91cd\u6784\u4e2d\u7684\u635f\u8017\u6700\u5c0f\u5316\u95ee\u9898\u3002", "motivation": "\u7f51\u7edc\u62d3\u6251\u4f18\u5316\u5728\u80fd\u6e90\u7cfb\u7edf\u4e2d\u80fd\u663e\u8457\u964d\u4f4e\u635f\u8017\u548c\u6210\u672c\uff0c\u4f46\u8fd9\u7c7b\u4f18\u5316\u95ee\u9898\u901a\u5e38\u662fNP\u96be\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u57fa\u4e8e\u91cf\u5b50\u4ea4\u66ff\u7b97\u5b50ansatz\uff08QAOA\uff09\u5f00\u53d1\u4e86\u4e24\u79cd\u91cf\u5b50\u7b97\u6cd5\u539f\u8bed\uff1a\u4e00\u79cd\u662f\u9488\u5bf9\u5f84\u5411\u62d3\u6251\u7684\u5b9a\u5236\u91c7\u6837\uff0c\u53e6\u4e00\u79cd\u662f\u4f7f\u7528\u60e9\u7f5a\u9879\u6291\u5236\u975e\u5f84\u5411\u62d3\u6251\u7684\u7b80\u5355\u91c7\u6837\u3002", "result": "\u8bba\u6587\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u8fd9\u4e9b\u91cf\u5b50\u7b97\u6cd5\u539f\u8bed\u5e94\u7528\u4e8e\u914d\u7535\u7f51\u7edc\u91cd\u6784\uff0c\u5e76\u91cf\u5316\u4e86\u6240\u9700\u7684\u91cf\u5b50\u8d44\u6e90\u3002", "conclusion": "\u91cf\u5b50\u4f18\u5316\u4e3a\u5f84\u5411\u7f51\u7edc\u635f\u8017\u6700\u5c0f\u5316\u8fd9\u4e00\u8ba1\u7b97\u56f0\u96be\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u66ff\u4ee3\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00106", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.00106", "abs": "https://arxiv.org/abs/2511.00106", "authors": ["Anuj Gupta", "Ann Shivers-McNair"], "title": "Wayfinding through the AI wilderness: Mapping rhetorics of ChatGPT prompt writing on X (formerly Twitter) to promote critical AI literacies", "comment": "Published in the journal Computers and Composition, Issue 74 (2024)", "summary": "In this paper, we demonstrate how studying the rhetorics of ChatGPT prompt\nwriting on social media can promote critical AI literacies. Prompt writing is\nthe process of writing instructions for generative AI tools like ChatGPT to\nelicit desired outputs and there has been an upsurge of conversations about it\non social media. To study this rhetorical activity, we build on four\noverlapping traditions of digital writing research in computers and composition\nthat inform how we frame literacies, how we study social media rhetorics, how\nwe engage iteratively and reflexively with methodologies and technologies, and\nhow we blend computational methods with qualitative methods. Drawing on these\nfour traditions, our paper shows our iterative research process through which\nwe gathered and analyzed a dataset of 32,000 posts (formerly known as tweets)\nfrom X (formerly Twitter) about prompt writing posted between November 2022 to\nMay 2023. We present five themes about these emerging AI literacy practices:\n(1) areas of communication impacted by prompt writing, (2) micro-literacy\nresources shared for prompt writing, (3) market rhetoric shaping prompt\nwriting, (4) rhetorical characteristics of prompts, and (5) definitions of\nprompt writing. In discussing these themes and our methodologies, we highlight\ntakeaways for digital writing teachers and researchers who are teaching and\nanalyzing critical AI literacies.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5206\u6790\u793e\u4ea4\u5a92\u4f53\u4e0aChatGPT\u63d0\u793a\u5199\u4f5c\u7684\u4fee\u8f9e\u5b9e\u8df5\uff0c\u63a2\u8ba8\u5982\u4f55\u4fc3\u8fdb\u6279\u5224\u6027AI\u7d20\u517b\u3002\u7814\u7a76\u6536\u96c6\u4e8632,000\u6761\u5173\u4e8e\u63d0\u793a\u5199\u4f5c\u7684\u63a8\u6587\uff0c\u8bc6\u522b\u51fa\u4e94\u4e2a\u5173\u952e\u4e3b\u9898\uff0c\u4e3a\u6570\u5b57\u5199\u4f5c\u6559\u5b66\u548c\u7814\u7a76\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u5de5\u5177\u7684\u666e\u53ca\uff0c\u793e\u4ea4\u5a92\u4f53\u4e0a\u5173\u4e8e\u63d0\u793a\u5199\u4f5c\u7684\u8ba8\u8bba\u6fc0\u589e\u3002\u7814\u7a76\u8005\u5e0c\u671b\u901a\u8fc7\u5206\u6790\u8fd9\u4e9b\u4fee\u8f9e\u5b9e\u8df5\uff0c\u7406\u89e3\u65b0\u5174\u7684AI\u7d20\u517b\uff0c\u5e76\u4e3a\u6570\u5b57\u5199\u4f5c\u6559\u80b2\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u57fa\u4e8e\u6570\u5b57\u5199\u4f5c\u7814\u7a76\u7684\u56db\u4e2a\u4f20\u7edf\u6846\u67b6\uff0c\u91c7\u7528\u8fed\u4ee3\u7814\u7a76\u65b9\u6cd5\uff0c\u6536\u96c6\u5e76\u5206\u6790\u4e862022\u5e7411\u6708\u81f32023\u5e745\u6708\u671f\u95f432,000\u6761\u5173\u4e8e\u63d0\u793a\u5199\u4f5c\u7684\u63a8\u6587\uff0c\u7ed3\u5408\u8ba1\u7b97\u65b9\u6cd5\u548c\u5b9a\u6027\u65b9\u6cd5\u3002", "result": "\u8bc6\u522b\u51fa\u4e94\u4e2a\u5173\u952e\u4e3b\u9898\uff1a\u63d0\u793a\u5199\u4f5c\u5f71\u54cd\u7684\u6c9f\u901a\u9886\u57df\u3001\u5171\u4eab\u7684\u5fae\u89c2\u7d20\u517b\u8d44\u6e90\u3001\u5851\u9020\u63d0\u793a\u5199\u4f5c\u7684\u5e02\u573a\u4fee\u8f9e\u3001\u63d0\u793a\u7684\u4fee\u8f9e\u7279\u5f81\uff0c\u4ee5\u53ca\u63d0\u793a\u5199\u4f5c\u7684\u5b9a\u4e49\u3002", "conclusion": "\u7814\u7a76\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u5206\u6790\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u63d0\u793a\u5199\u4f5c\u4fee\u8f9e\u6765\u4fc3\u8fdb\u6279\u5224\u6027AI\u7d20\u517b\uff0c\u4e3a\u6570\u5b57\u5199\u4f5c\u6559\u5e08\u548c\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u6559\u5b66\u548c\u5206\u6790\u542f\u793a\u3002"}}
{"id": "2511.00267", "categories": ["cs.AI", "cs.CY", "cs.GL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00267", "abs": "https://arxiv.org/abs/2511.00267", "authors": ["Christian Prothmann", "Vijay Gadepally", "Jeremy Kepner", "Koley Borchard", "Luca Carlone", "Zachary Folcik", "J. Daniel Grith", "Michael Houle", "Jonathan P. How", "Nathan Hughes", "Ifueko Igbinedion", "Hayden Jananthan", "Tejas Jayashankar", "Michael Jones", "Sertac Karaman", "Binoy G. Kurien", "Alejandro Lancho", "Giovanni Lavezzi", "Gary C. F. Lee", "Charles E. Leiserson", "Richard Linares", "Lindsey McEvoy", "Peter Michaleas", "Chasen Milner", "Alex Pentland", "Yury Polyanskiy", "Jovan Popovich", "Jeffrey Price", "Tim W. Reid", "Stephanie Riley", "Siddharth Samsi", "Peter Saunders", "Olga Simek", "Mark S. Veillette", "Amir Weiss", "Gregory W. Wornell", "Daniela Rus", "Scott T. Ruppel"], "title": "Advancing AI Challenges for the United States Department of the Air Force", "comment": "8 pages, 8 figures, 59 references. To appear in IEEE HPEC 2025", "summary": "The DAF-MIT AI Accelerator is a collaboration between the United States\nDepartment of the Air Force (DAF) and the Massachusetts Institute of Technology\n(MIT). This program pioneers fundamental advances in artificial intelligence\n(AI) to expand the competitive advantage of the United States in the defense\nand civilian sectors. In recent years, AI Accelerator projects have developed\nand launched public challenge problems aimed at advancing AI research in\npriority areas. Hallmarks of AI Accelerator challenges include large, publicly\navailable, and AI-ready datasets to stimulate open-source solutions and engage\nthe wider academic and private sector AI ecosystem. This article supplements\nour previous publication, which introduced AI Accelerator challenges. We\nprovide an update on how ongoing and new challenges have successfully\ncontributed to AI research and applications of AI technologies.", "AI": {"tldr": "DAF-MIT AI\u52a0\u901f\u5668\u9879\u76ee\u901a\u8fc7\u516c\u5f00\u6311\u6218\u95ee\u9898\u63a8\u52a8AI\u7814\u7a76\uff0c\u63d0\u4f9b\u5927\u578b\u516c\u5f00\u6570\u636e\u96c6\uff0c\u4fc3\u8fdb\u5f00\u6e90\u89e3\u51b3\u65b9\u6848\uff0c\u66f4\u65b0\u4e86\u6311\u6218\u9879\u76ee\u5bf9AI\u7814\u7a76\u548c\u5e94\u7528\u7684\u8d21\u732e\u3002", "motivation": "\u901a\u8fc7DAF\u4e0eMIT\u7684\u5408\u4f5c\uff0c\u63a8\u52a8\u4eba\u5de5\u667a\u80fd\u57fa\u7840\u8fdb\u6b65\uff0c\u6269\u5927\u7f8e\u56fd\u5728\u56fd\u9632\u548c\u6c11\u7528\u9886\u57df\u7684\u7ade\u4e89\u4f18\u52bf\uff0c\u901a\u8fc7\u516c\u5f00\u6311\u6218\u95ee\u9898\u523a\u6fc0AI\u7814\u7a76\u3002", "method": "\u5f00\u53d1\u548c\u53d1\u5e03\u516c\u5f00\u6311\u6218\u95ee\u9898\uff0c\u63d0\u4f9b\u5927\u578b\u3001\u516c\u5f00\u53ef\u7528\u7684AI\u5c31\u7eea\u6570\u636e\u96c6\uff0c\u4fc3\u8fdb\u5f00\u6e90\u89e3\u51b3\u65b9\u6848\uff0c\u5438\u5f15\u5b66\u672f\u754c\u548c\u79c1\u8425\u90e8\u95e8\u53c2\u4e0e\u3002", "result": "\u6301\u7eed\u548c\u65b0\u7684\u6311\u6218\u9879\u76ee\u6210\u529f\u4fc3\u8fdb\u4e86AI\u7814\u7a76\u548c\u6280\u672f\u5e94\u7528\uff0c\u6269\u5927\u4e86AI\u751f\u6001\u7cfb\u7edf\u53c2\u4e0e\u3002", "conclusion": "DAF-MIT AI\u52a0\u901f\u5668\u901a\u8fc7\u516c\u5f00\u6311\u6218\u95ee\u9898\u6709\u6548\u63a8\u52a8\u4e86AI\u7814\u7a76\u8fdb\u5c55\uff0c\u4e3a\u56fd\u9632\u548c\u6c11\u7528\u9886\u57df\u63d0\u4f9b\u4e86\u7ade\u4e89\u4f18\u52bf\u3002"}}
{"id": "2511.00193", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00193", "abs": "https://arxiv.org/abs/2511.00193", "authors": ["Faranak Akbarifar", "Nooshin Maghsoodi", "Sean P Dukelow", "Stephen Scott", "Parvin Mousavi"], "title": "Reducing Robotic Upper-Limb Assessment Time While Maintaining Precision: A Time Series Foundation Model Approach", "comment": null, "summary": "Purpose: Visually Guided Reaching (VGR) on the Kinarm robot yields sensitive\nkinematic biomarkers but requires 40-64 reaches, imposing time and fatigue\nburdens. We evaluate whether time-series foundation models can replace\nunrecorded trials from an early subset of reaches while preserving the\nreliability of standard Kinarm parameters.\n  Methods: We analyzed VGR speed signals from 461 stroke and 599 control\nparticipants across 4- and 8-target reaching protocols. We withheld all but the\nfirst 8 or 16 reaching trials and used ARIMA, MOMENT, and Chronos models,\nfine-tuned on 70 percent of subjects, to forecast synthetic trials. We\nrecomputed four kinematic features of reaching (reaction time, movement time,\nposture speed, maximum speed) on combined recorded plus forecasted trials and\ncompared them to full-length references using ICC(2,1).\n  Results: Chronos forecasts restored ICC >= 0.90 for all parameters with only\n8 recorded trials plus forecasts, matching the reliability of 24-28 recorded\nreaches (Delta ICC <= 0.07). MOMENT yielded intermediate gains, while ARIMA\nimprovements were minimal. Across cohorts and protocols, synthetic trials\nreplaced reaches without materially compromising feature reliability.\n  Conclusion: Foundation-model forecasting can greatly shorten Kinarm VGR\nassessment time. For the most impaired stroke survivors, sessions drop from 4-5\nminutes to about 1 minute while preserving kinematic precision. This\nforecast-augmented paradigm promises efficient robotic evaluations for\nassessing motor impairments following stroke.", "AI": {"tldr": "\u4f7f\u7528\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u9884\u6d4b\u672a\u8bb0\u5f55\u7684\u4f38\u624b\u8bd5\u9a8c\uff0c\u663e\u8457\u7f29\u77edKinarm\u673a\u5668\u4eba\u89c6\u89c9\u5f15\u5bfc\u4f38\u624b\u8bc4\u4f30\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u8fd0\u52a8\u5b66\u53c2\u6570\u7684\u53ef\u9760\u6027\u3002", "motivation": "Kinarm\u673a\u5668\u4eba\u89c6\u89c9\u5f15\u5bfc\u4f38\u624b\u8bc4\u4f30\u9700\u898140-64\u6b21\u4f38\u624b\u8bd5\u9a8c\uff0c\u8017\u65f6\u4e14\u6613\u5bfc\u81f4\u75b2\u52b3\uff0c\u9700\u8981\u5bfb\u627e\u7f29\u77ed\u8bc4\u4f30\u65f6\u95f4\u7684\u65b9\u6cd5\u3002", "method": "\u5206\u6790461\u540d\u4e2d\u98ce\u548c599\u540d\u5bf9\u7167\u53c2\u4e0e\u8005\u7684\u901f\u5ea6\u4fe1\u53f7\uff0c\u4f7f\u7528ARIMA\u3001MOMENT\u548cChronos\u6a21\u578b\u57fa\u4e8e\u524d8\u621616\u6b21\u8bd5\u9a8c\u9884\u6d4b\u5408\u6210\u8bd5\u9a8c\uff0c\u91cd\u65b0\u8ba1\u7b97\u8fd0\u52a8\u5b66\u7279\u5f81\u5e76\u4e0e\u5b8c\u6574\u8bd5\u9a8c\u53c2\u8003\u6bd4\u8f83\u3002", "result": "Chronos\u6a21\u578b\u4ec5\u97008\u6b21\u8bb0\u5f55\u8bd5\u9a8c\u52a0\u9884\u6d4b\u5373\u53ef\u6062\u590dICC\u22650.90\u7684\u53ef\u9760\u6027\uff0c\u76f8\u5f53\u4e8e24-28\u6b21\u5b9e\u9645\u8bd5\u9a8c\u7684\u6548\u679c\uff0c\u663e\u8457\u7f29\u77ed\u8bc4\u4f30\u65f6\u95f4\u3002", "conclusion": "\u57fa\u7840\u6a21\u578b\u9884\u6d4b\u53ef\u5927\u5e45\u7f29\u77edKinarm\u8bc4\u4f30\u65f6\u95f4\uff0c\u5bf9\u6700\u4e25\u91cd\u4e2d\u98ce\u60a3\u8005\u4ece4-5\u5206\u949f\u964d\u81f3\u7ea61\u5206\u949f\uff0c\u540c\u65f6\u4fdd\u6301\u8fd0\u52a8\u5b66\u7cbe\u5ea6\uff0c\u4e3a\u4e2d\u98ce\u540e\u8fd0\u52a8\u969c\u788d\u8bc4\u4f30\u63d0\u4f9b\u9ad8\u6548\u65b9\u6848\u3002"}}
{"id": "2511.01565", "categories": ["econ.GN", "q-fin.EC", "91B40, 91B42, 62P20"], "pdf": "https://arxiv.org/pdf/2511.01565", "abs": "https://arxiv.org/abs/2511.01565", "authors": ["Sevgi \u00c7olak"], "title": "Gendered Responses to Subtle Social Pressure: Experimental Evidence from Survey Results", "comment": "11 pages, 4 figures, 1 table", "summary": "This study analyzes whether subtle variations in the survey questionnaire\nphrasing influence participant engagement and whether these effects differ by\ngender. Building on theories of social pressure and politeness norms, it is\nhypothesized that presumptive phrasing would reduce engagement compared to\nappreciative phrasing and baseline phrasing (H1), and this effect would be more\npronounced among women (H2). Mixed-effects regression models showed no\nsignificant treatment effects on any outcome and no evidence of gender\nmoderation for 164 participants and 492 observations. The only robust finding\nwas a small negative baseline sentiment across all participants, independent of\nany treatment or gender. The findings contribute to refining theoretical\nexpectations about the conditions in which linguistic framing and gender norms\nshape behaviour.", "AI": {"tldr": "\u8be5\u7814\u7a76\u68c0\u9a8c\u4e86\u8c03\u67e5\u95ee\u5377\u63aa\u8f9e\u7684\u5fae\u5999\u53d8\u5316\u662f\u5426\u5f71\u54cd\u53c2\u4e0e\u8005\u53c2\u4e0e\u5ea6\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u6548\u5e94\u662f\u5426\u56e0\u6027\u522b\u800c\u5f02\u3002\u7814\u7a76\u53d1\u73b0\u6ca1\u6709\u663e\u8457\u7684\u63aa\u8f9e\u5904\u7406\u6548\u5e94\uff0c\u4e5f\u6ca1\u6709\u6027\u522b\u8c03\u8282\u4f5c\u7528\u7684\u8bc1\u636e\u3002", "motivation": "\u57fa\u4e8e\u793e\u4f1a\u538b\u529b\u548c\u793c\u8c8c\u89c4\u8303\u7406\u8bba\uff0c\u7814\u7a76\u5047\u8bbe\u9884\u8bbe\u6027\u63aa\u8f9e\u76f8\u6bd4\u8d5e\u8d4f\u6027\u63aa\u8f9e\u548c\u57fa\u7ebf\u63aa\u8f9e\u4f1a\u964d\u4f4e\u53c2\u4e0e\u5ea6\uff0c\u4e14\u8fd9\u79cd\u6548\u5e94\u5bf9\u5973\u6027\u66f4\u660e\u663e\u3002", "method": "\u4f7f\u7528\u6df7\u5408\u6548\u5e94\u56de\u5f52\u6a21\u578b\u5206\u6790164\u540d\u53c2\u4e0e\u8005\u7684492\u4e2a\u89c2\u5bdf\u6570\u636e\u3002", "result": "\u7ed3\u679c\u663e\u793a\u6ca1\u6709\u4efb\u4f55\u7ed3\u679c\u53d8\u91cf\u5b58\u5728\u663e\u8457\u7684\u5904\u7406\u6548\u5e94\uff0c\u4e5f\u6ca1\u6709\u6027\u522b\u8c03\u8282\u4f5c\u7528\u7684\u8bc1\u636e\u3002\u552f\u4e00\u7a33\u5065\u7684\u53d1\u73b0\u662f\u6240\u6709\u53c2\u4e0e\u8005\u90fd\u5b58\u5728\u8f7b\u5fae\u7684\u8d1f\u9762\u57fa\u7ebf\u60c5\u7eea\uff0c\u4e0e\u5904\u7406\u548c\u6027\u522b\u65e0\u5173\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u6709\u52a9\u4e8e\u5b8c\u5584\u5173\u4e8e\u8bed\u8a00\u6846\u67b6\u548c\u6027\u522b\u89c4\u8303\u5728\u4f55\u79cd\u6761\u4ef6\u4e0b\u5f71\u54cd\u884c\u4e3a\u7684\u7406\u8bba\u9884\u671f\u3002"}}
{"id": "2511.00593", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.00593", "abs": "https://arxiv.org/abs/2511.00593", "authors": ["Aayushya Agarwal", "Jace Rozsa", "Matteo Pozzi", "Rahul Panat", "Gary K. Fedder"], "title": "Digital Twin of Aerosol Jet Printing", "comment": null, "summary": "Aerosol Jet (AJ) printing is a versatile additive manufacturing technique\ncapable of producing high-resolution interconnects on both 2D and 3D\nsubstrates. The AJ process is complex and dynamic with many hidden and\nunobservable states that influence the machine performance, including aerosol\nparticle diameter, aerosol carrier density, vial level, and ink deposition in\nthe tube and nozzle. Despite its promising potential, the widespread adoption\nof AJ printing is limited by inconsistencies in print quality that often stem\nfrom variability in these hidden states. To address these challenges, we\ndevelop a digital twin model of the AJ process that offers real-time insights\ninto the machine's operations. The digital twin is built around a physics-based\nmacro-model created through simulation and experimentation. The states and\nparameters of the digital model are continuously updated using probabilistic\nsequential estimation techniques to closely align with real-time measurements\nextracted from the AJ system's sensor and video data. The result is a digital\nmodel of the AJ process that continuously evolves over a physical machine's\nlifecycle. The digital twin enables accurate monitoring of unobservable\nphysical characteristics, detects and predicts anomalous behavior, and\nforecasts the effect of control adjustments. This work presents a comprehensive\nend-to-end digital twin framework that integrates customized computer vision\ntechniques, physics-based macro-modeling, and advanced probabilistic estimation\nmethods to construct an evolving digital representation of the AJ equipment and\nprocess. While the methodologies are customized for aerosol jet printing, the\nprocess for constructing the digital twin can be applied for other advanced\nmanufacturing techniques.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u6c14\u6eb6\u80f6\u55b7\u5c04\uff08AJ\uff09\u6253\u5370\u8fc7\u7a0b\u7684\u6570\u5b57\u5b6a\u751f\u6a21\u578b\uff0c\u901a\u8fc7\u7269\u7406\u5efa\u6a21\u548c\u6982\u7387\u4f30\u8ba1\u6280\u672f\u5b9e\u65f6\u76d1\u63a7\u4e0d\u53ef\u89c2\u6d4b\u72b6\u6001\uff0c\u63d0\u9ad8\u6253\u5370\u8d28\u91cf\u4e00\u81f4\u6027\u3002", "motivation": "AJ\u6253\u5370\u867d\u7136\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u7531\u4e8e\u9690\u85cf\u72b6\u6001\uff08\u5982\u6c14\u6eb6\u80f6\u7c92\u5b50\u76f4\u5f84\u3001\u8f7d\u6c14\u5bc6\u5ea6\u7b49\uff09\u7684\u53d8\u5f02\u6027\u5bfc\u81f4\u6253\u5370\u8d28\u91cf\u4e0d\u4e00\u81f4\uff0c\u9650\u5236\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u7269\u7406\u7684\u5b8f\u89c2\u6a21\u578b\uff0c\u7ed3\u5408\u4f20\u611f\u5668\u548c\u89c6\u9891\u6570\u636e\uff0c\u4f7f\u7528\u6982\u7387\u987a\u5e8f\u4f30\u8ba1\u6280\u672f\u6301\u7eed\u66f4\u65b0\u6570\u5b57\u6a21\u578b\u72b6\u6001\u548c\u53c2\u6570\u3002", "result": "\u521b\u5efa\u4e86\u80fd\u591f\u6301\u7eed\u6f14\u5316\u7684AJ\u8fc7\u7a0b\u6570\u5b57\u6a21\u578b\uff0c\u80fd\u591f\u51c6\u786e\u76d1\u63a7\u4e0d\u53ef\u89c2\u6d4b\u7269\u7406\u7279\u6027\u3001\u68c0\u6d4b\u9884\u6d4b\u5f02\u5e38\u884c\u4e3a\u5e76\u9884\u6d4b\u63a7\u5236\u8c03\u6574\u6548\u679c\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u6570\u5b57\u5b6a\u751f\u6846\u67b6\uff0c\u867d\u7136\u9488\u5bf9AJ\u6253\u5370\u5b9a\u5236\uff0c\u4f46\u8be5\u6784\u5efa\u8fc7\u7a0b\u53ef\u5e94\u7528\u4e8e\u5176\u4ed6\u5148\u8fdb\u5236\u9020\u6280\u672f\u3002"}}
{"id": "2511.01598", "categories": ["cs.CY", "cs.CR", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2511.01598", "abs": "https://arxiv.org/abs/2511.01598", "authors": ["Tomas Martinek", "Michal Maly"], "title": "Evaluation of compliance with democratic and technical standards of i-voting in elections to academic senates in Czech higher education", "comment": "26 pages, 8 figures", "summary": "The shift towards increased remote work and digital communication, driven by\nrecent global developments, has led to the widespread adoption of i-voting\nsystems, including in academic institutions. This paper critically evaluates\nthe use of i-voting platforms for elections to academic senates at Czech public\nuniversities, focusing on the democratic and technical challenges they present.\nA total of 18 out of 26 Czech public universities have implemented remote\nelectronic voting for these elections. Yet, the systems often lack the\nnecessary transparency, raising significant concerns regarding their adherence\nto democratic norms, such as election security, voter privacy, and the\nintegrity of the process. Through interviews with system developers and\nadministrators, along with a survey of potential voters, the study underscores\nthe critical need for transparency. Without it, a comprehensive assessment of\nthe technical standards and the overall legitimacy of the i-voting systems\nremains unattainable, potentially undermining the credibility of the electoral\noutcomes.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u6377\u514b\u516c\u7acb\u5927\u5b66\u5728\u5b66\u672f\u8bc4\u8bae\u4f1a\u9009\u4e3e\u4e2d\u4f7f\u7528\u7684i-voting\u7cfb\u7edf\uff0c\u53d1\u73b0\u5927\u591a\u6570\u7cfb\u7edf\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u5b58\u5728\u6c11\u4e3b\u548c\u6280\u672f\u6311\u6218\u3002", "motivation": "\u968f\u7740\u8fdc\u7a0b\u5de5\u4f5c\u548c\u6570\u5b57\u901a\u4fe1\u7684\u589e\u52a0\uff0ci-voting\u7cfb\u7edf\u5728\u5b66\u672f\u673a\u6784\u4e2d\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u7f3a\u4e4f\u900f\u660e\u5ea6\u5f15\u53d1\u4e86\u5bf9\u5176\u6c11\u4e3b\u89c4\u8303\u9075\u5b88\u60c5\u51b5\u7684\u62c5\u5fe7\u3002", "method": "\u901a\u8fc7\u5bf9\u7cfb\u7edf\u5f00\u53d1\u8005\u548c\u7ba1\u7406\u5458\u8fdb\u884c\u8bbf\u8c08\uff0c\u4ee5\u53ca\u5bf9\u6f5c\u5728\u9009\u6c11\u8fdb\u884c\u8c03\u67e5\u6765\u8bc4\u4f30i-voting\u7cfb\u7edf\u3002", "result": "26\u6240\u6377\u514b\u516c\u7acb\u5927\u5b66\u4e2d\u670918\u6240\u5b9e\u65bd\u4e86\u8fdc\u7a0b\u7535\u5b50\u6295\u7968\uff0c\u4f46\u8fd9\u4e9b\u7cfb\u7edf\u5f80\u5f80\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u5728\u9009\u4e3e\u5b89\u5168\u3001\u9009\u6c11\u9690\u79c1\u548c\u8fc7\u7a0b\u5b8c\u6574\u6027\u65b9\u9762\u5b58\u5728\u95ee\u9898\u3002", "conclusion": "\u7f3a\u4e4f\u900f\u660e\u5ea6\u4f7f\u5f97\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30i-voting\u7cfb\u7edf\u7684\u6280\u672f\u6807\u51c6\u548c\u6574\u4f53\u5408\u6cd5\u6027\uff0c\u53ef\u80fd\u635f\u5bb3\u9009\u4e3e\u7ed3\u679c\u7684\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2511.00340", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00340", "abs": "https://arxiv.org/abs/2511.00340", "authors": ["Manan Roy Choudhury", "Adithya Chandramouli", "Mannan Anand", "Vivek Gupta"], "title": "Better Call CLAUSE: A Discrepancy Benchmark for Auditing LLMs Legal Reasoning Capabilities", "comment": "41 pages, 4 images", "summary": "The rapid integration of large language models (LLMs) into high-stakes legal\nwork has exposed a critical gap: no benchmark exists to systematically\nstress-test their reliability against the nuanced, adversarial, and often\nsubtle flaws present in real-world contracts. To address this, we introduce\nCLAUSE, a first-of-its-kind benchmark designed to evaluate the fragility of an\nLLM's legal reasoning. We study the capabilities of LLMs to detect and reason\nabout fine-grained discrepancies by producing over 7500 real-world perturbed\ncontracts from foundational datasets like CUAD and ContractNLI. Our novel,\npersona-driven pipeline generates 10 distinct anomaly categories, which are\nthen validated against official statutes using a Retrieval-Augmented Generation\n(RAG) system to ensure legal fidelity. We use CLAUSE to evaluate leading LLMs'\nability to detect embedded legal flaws and explain their significance. Our\nanalysis shows a key weakness: these models often miss subtle errors and\nstruggle even more to justify them legally. Our work outlines a path to\nidentify and correct such reasoning failures in legal AI.", "AI": {"tldr": "CLAUSE\u662f\u4e00\u4e2a\u4e13\u95e8\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u63a8\u7406\u4e2d\u8106\u5f31\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u751f\u62107500\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u6270\u52a8\u5408\u540c\u6765\u6d4b\u8bd5LLMs\u68c0\u6d4b\u7ec6\u5fae\u6cd5\u5f8b\u5dee\u5f02\u7684\u80fd\u529b\u3002", "motivation": "\u968f\u7740LLMs\u5728\u9ad8\u98ce\u9669\u6cd5\u5f8b\u5de5\u4f5c\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30\u5176\u5bf9\u6297\u771f\u5b9e\u5408\u540c\u590d\u6742\u7f3a\u9677\u53ef\u9760\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u89d2\u8272\u7684\u6d41\u6c34\u7ebf\u751f\u621010\u79cd\u5f02\u5e38\u7c7b\u522b\uff0c\u901a\u8fc7RAG\u7cfb\u7edf\u9a8c\u8bc1\u6cd5\u5f8b\u51c6\u786e\u6027\uff0c\u57fa\u4e8eCUAD\u548cContractNLI\u6570\u636e\u96c6\u521b\u5efa\u6270\u52a8\u5408\u540c\u3002", "result": "\u4e3b\u6d41LLMs\u5728\u68c0\u6d4b\u7ec6\u5fae\u6cd5\u5f8b\u9519\u8bef\u65b9\u9762\u5b58\u5728\u5173\u952e\u5f31\u70b9\uff0c\u7279\u522b\u662f\u5728\u6cd5\u5f8b\u8bba\u8bc1\u65b9\u9762\u8868\u73b0\u66f4\u5dee\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u8bc6\u522b\u548c\u7ea0\u6b63\u6cd5\u5f8bAI\u4e2d\u7684\u63a8\u7406\u5931\u8d25\u63d0\u4f9b\u4e86\u8def\u5f84\uff0c\u5f3a\u8c03\u4e86\u9700\u8981\u6539\u8fdbLLMs\u5728\u6cd5\u5f8b\u7ec6\u5fae\u5dee\u522b\u7406\u89e3\u4e0a\u7684\u80fd\u529b\u3002"}}
{"id": "2511.01597", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2511.01597", "abs": "https://arxiv.org/abs/2511.01597", "authors": ["Markus Dertwinkel-Kalt", "Hans-Theo Normann", "Jan-Niklas Tiede", "Tobias Werner"], "title": "Deceptively Framed Lotteries in Consumer Markets", "comment": null, "summary": "Consumers often face products sold as lotteries rather than fixed outcomes. A\nprominent case is the loot box in video games, where players pay for randomized\nrewards. We investigate how presentation formats shape consumer beliefs and\nwillingness to pay. In an online experiment with 802 participants, sellers\ncould frame lotteries using two common manipulations: censoring outcome\nprobabilities and selectively highlighting rare successes. More than 80\\% of\nsellers adopted such deceptive frames, particularly when both manipulations\nwere available. These choices substantially inflated buyer beliefs and\nincreased willingness to pay of up to six times the expected value. Sellers\nanticipated this effect and raised prices accordingly. Our results show how\ndeceptive framing systematically shifts consumer beliefs and enables firms to\nextract additional surplus. For marketing practice, this highlights the\nstrategic value of framing tools in probabilistic selling models; for policy,\nit underscores the importance of transparency requirements in protecting\nconsumers.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4ea7\u54c1\u4ee5\u62bd\u5956\u5f62\u5f0f\u9500\u552e\u65f6\uff0c\u4e0d\u540c\u5448\u73b0\u65b9\u5f0f\u5982\u4f55\u5f71\u54cd\u6d88\u8d39\u8005\u4fe1\u5ff5\u548c\u652f\u4ed8\u610f\u613f\u3002\u5b9e\u9a8c\u53d1\u73b080%\u4ee5\u4e0a\u7684\u5356\u5bb6\u91c7\u7528\u6b3a\u9a97\u6027\u6846\u67b6\uff08\u5982\u9690\u85cf\u6982\u7387\u3001\u7a81\u51fa\u7a00\u6709\u6210\u529f\uff09\uff0c\u8fd9\u663e\u8457\u63d0\u9ad8\u4e86\u4e70\u5bb6\u4fe1\u5ff5\u548c\u652f\u4ed8\u610f\u613f\uff08\u53ef\u8fbe\u671f\u671b\u4ef7\u503c\u76846\u500d\uff09\u3002", "motivation": "\u7814\u7a76\u6d88\u8d39\u8005\u5728\u9762\u5bf9\u62bd\u5956\u5f62\u5f0f\u4ea7\u54c1\uff08\u5982\u6e38\u620f\u4e2d\u7684\u62bd\u5956\u7bb1\uff09\u65f6\uff0c\u9500\u552e\u5448\u73b0\u65b9\u5f0f\u5982\u4f55\u5851\u9020\u6d88\u8d39\u8005\u4fe1\u5ff5\u548c\u652f\u4ed8\u610f\u613f\uff0c\u63ed\u793a\u6b3a\u9a97\u6027\u6846\u67b6\u5bf9\u6d88\u8d39\u8005\u51b3\u7b56\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5728\u7ebf\u5b9e\u9a8c\uff08802\u540d\u53c2\u4e0e\u8005\uff09\uff0c\u8ba9\u5356\u5bb6\u53ef\u4ee5\u9009\u62e9\u4e24\u79cd\u5e38\u89c1\u7684\u64cd\u7eb5\u65b9\u5f0f\uff1a\u9690\u85cf\u7ed3\u679c\u6982\u7387\u548c\u9009\u62e9\u6027\u7a81\u51fa\u7a00\u6709\u6210\u529f\uff0c\u89c2\u5bdf\u8fd9\u4e9b\u6846\u67b6\u9009\u62e9\u5bf9\u4e70\u5bb6\u4fe1\u5ff5\u548c\u652f\u4ed8\u610f\u613f\u7684\u5f71\u54cd\u3002", "result": "\u8d85\u8fc780%\u7684\u5356\u5bb6\u91c7\u7528\u6b3a\u9a97\u6027\u6846\u67b6\uff0c\u7279\u522b\u662f\u5f53\u4e24\u79cd\u64cd\u7eb5\u65b9\u5f0f\u90fd\u53ef\u7528\u65f6\u3002\u8fd9\u4e9b\u9009\u62e9\u663e\u8457\u63d0\u9ad8\u4e86\u4e70\u5bb6\u4fe1\u5ff5\uff0c\u652f\u4ed8\u610f\u613f\u53ef\u8fbe\u671f\u671b\u4ef7\u503c\u76846\u500d\u3002\u5356\u5bb6\u9884\u89c1\u5230\u8fd9\u79cd\u6548\u5e94\u5e76\u76f8\u5e94\u63d0\u9ad8\u4ef7\u683c\u3002", "conclusion": "\u6b3a\u9a97\u6027\u6846\u67b6\u7cfb\u7edf\u6027\u6539\u53d8\u6d88\u8d39\u8005\u4fe1\u5ff5\uff0c\u4f7f\u4f01\u4e1a\u80fd\u591f\u83b7\u53d6\u989d\u5916\u5269\u4f59\u4ef7\u503c\u3002\u5bf9\u8425\u9500\u5b9e\u8df5\u5f3a\u8c03\u6846\u67b6\u5de5\u5177\u5728\u6982\u7387\u9500\u552e\u6a21\u578b\u4e2d\u7684\u6218\u7565\u4ef7\u503c\uff0c\u5bf9\u653f\u7b56\u5f3a\u8c03\u900f\u660e\u5ea6\u8981\u6c42\u5728\u4fdd\u62a4\u6d88\u8d39\u8005\u65b9\u9762\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.00595", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.00595", "abs": "https://arxiv.org/abs/2511.00595", "authors": ["Feng Guo", "Luis D. Couto", "Guillaume Thenaisie"], "title": "Efficiency and Optimality in Electrochemical Battery Model Parameter Identification: A Comparative Study of Estimation Techniques", "comment": "Accepted and published in the Proceedings of the 2024 10th\n  International Conference on Optimization and Applications (ICOA), IEEE, 2024.\n  Copyright 2024 IEEE. This is the author's accepted manuscript; the final\n  version is available at IEEE Xplore (DOI: 10.1109/ICOA62581.2024.10754301)", "summary": "Parameter identification for electrochemical battery models has always been\nchallenging due to the multitude of parameters involved, most of which cannot\nbe directly measured. This paper evaluates the efficiency and optimality of\nthree widely-used parameter identification methods for electrochemical battery\nmodels: Least Squares Method (LS), Particle Swarm Optimization (PSO), and\nGenetic Algorithm (GA). Therefore, a Single Particle Model (SPM) of a battery\nwas developed and discretized. Battery parameter grouping was then performed to\nreduce the number of parameters required. Using a set of parameters previously\nidentified from a real battery as a benchmark, we generated fitting and\nvalidation datasets to assess the methods' runtime and accuracy. The\ncomparative analysis reveals that PSO outperforms the other methods in terms of\naccuracy and stability, making it highly effective for parameter identification\nwhen there is no prior knowledge of the battery's internal parameters. In\ncontrast, LS is better suited for minor adjustments in parameters, particularly\nfor aging batteries, whereas GA lags behind in both computational efficiency\nand optimality with respect to PSO.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u4e09\u79cd\u7535\u5316\u5b66\u7535\u6c60\u6a21\u578b\u53c2\u6570\u8fa8\u8bc6\u65b9\u6cd5\u7684\u6548\u7387\u548c\u6700\u4f18\u6027\uff1a\u6700\u5c0f\u4e8c\u4e58\u6cd5(LS)\u3001\u7c92\u5b50\u7fa4\u4f18\u5316(PSO)\u548c\u9057\u4f20\u7b97\u6cd5(GA)\uff0c\u53d1\u73b0PSO\u5728\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u7535\u5316\u5b66\u7535\u6c60\u6a21\u578b\u53c2\u6570\u8fa8\u8bc6\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u6d89\u53ca\u4f17\u591a\u65e0\u6cd5\u76f4\u63a5\u6d4b\u91cf\u7684\u53c2\u6570\uff0c\u9700\u8981\u8bc4\u4f30\u4e0d\u540c\u65b9\u6cd5\u7684\u6548\u7387\u548c\u6700\u4f18\u6027\u3002", "method": "\u5f00\u53d1\u5e76\u79bb\u6563\u5316\u7535\u6c60\u5355\u7c92\u5b50\u6a21\u578b(SPM)\uff0c\u8fdb\u884c\u53c2\u6570\u5206\u7ec4\u4ee5\u51cf\u5c11\u53c2\u6570\u6570\u91cf\uff0c\u4f7f\u7528\u771f\u5b9e\u7535\u6c60\u53c2\u6570\u4f5c\u4e3a\u57fa\u51c6\u751f\u6210\u62df\u5408\u548c\u9a8c\u8bc1\u6570\u636e\u96c6\uff0c\u6bd4\u8f83\u4e09\u79cd\u65b9\u6cd5\u7684\u8fd0\u884c\u65f6\u95f4\u548c\u51c6\u786e\u6027\u3002", "result": "PSO\u5728\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0cLS\u66f4\u9002\u5408\u53c2\u6570\u5fae\u8c03\uff08\u7279\u522b\u662f\u8001\u5316\u7535\u6c60\uff09\uff0cGA\u5728\u8ba1\u7b97\u6548\u7387\u548c\u6700\u4f18\u6027\u65b9\u9762\u843d\u540e\u4e8ePSO\u3002", "conclusion": "PSO\u5728\u65e0\u5148\u9a8c\u7535\u6c60\u5185\u90e8\u53c2\u6570\u77e5\u8bc6\u65f6\u975e\u5e38\u6709\u6548\uff0cLS\u9002\u7528\u4e8e\u53c2\u6570\u5fae\u8c03\uff0cGA\u8868\u73b0\u76f8\u5bf9\u8f83\u5dee\u3002"}}
{"id": "2511.01751", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.01751", "abs": "https://arxiv.org/abs/2511.01751", "authors": ["Frederik Zuiderveen Borgesius"], "title": "Breyer case of the Court of Justice of the European Union: IP addresses and the personal data definition", "comment": null, "summary": "The Breyer case of the Court of Justice of the European Union (CJEU)\nprimarily concerns the question whether a website visitor's dynamic IP address\nconstitutes personal data for a website publisher, when another party (an\ninternet access provider) can tie a name to that IP address. In essence, the\nCourt finds that an IP address constitutes personal data for the website\npublisher, if that publisher has the legal means to obtain, from the visitor's\ninternet access provider, additional information that enables the publisher to\nidentify that visitor. In this case note, I summarise the facts and the\njudgment, and add a few comments.", "AI": {"tldr": "\u6b27\u76df\u6cd5\u9662Breyer\u6848\u88c1\u5b9a\uff1a\u5f53\u7f51\u7ad9\u53d1\u5e03\u8005\u80fd\u591f\u901a\u8fc7\u6cd5\u5f8b\u624b\u6bb5\u4ece\u8bbf\u95ee\u8005\u7684\u4e92\u8054\u7f51\u63a5\u5165\u63d0\u4f9b\u5546\u5904\u83b7\u53d6\u989d\u5916\u4fe1\u606f\u6765\u8bc6\u522b\u8bbf\u95ee\u8005\u65f6\uff0c\u52a8\u6001IP\u5730\u5740\u6784\u6210\u4e2a\u4eba\u6570\u636e\u3002", "motivation": "\u89e3\u51b3\u52a8\u6001IP\u5730\u5740\u662f\u5426\u6784\u6210\u4e2a\u4eba\u6570\u636e\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5f53\u7f51\u7ad9\u53d1\u5e03\u8005\u672c\u8eab\u65e0\u6cd5\u76f4\u63a5\u8bc6\u522b\u8bbf\u95ee\u8005\uff0c\u4f46\u53ef\u901a\u8fc7\u7b2c\u4e09\u65b9\uff08\u4e92\u8054\u7f51\u63a5\u5165\u63d0\u4f9b\u5546\uff09\u83b7\u53d6\u8bc6\u522b\u4fe1\u606f\u7684\u60c5\u51b5\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6b27\u76df\u6cd5\u9662\u7684Breyer\u6848\u4f8b\uff0c\u603b\u7ed3\u6848\u4ef6\u4e8b\u5b9e\u548c\u5224\u51b3\u5185\u5bb9\uff0c\u5e76\u8fdb\u884c\u8bc4\u8bba\u5206\u6790\u3002", "result": "\u6cd5\u9662\u8ba4\u5b9a\u52a8\u6001IP\u5730\u5740\u6784\u6210\u4e2a\u4eba\u6570\u636e\uff0c\u56e0\u4e3a\u7f51\u7ad9\u53d1\u5e03\u8005\u5177\u5907\u6cd5\u5f8b\u624b\u6bb5\u4ece\u4e92\u8054\u7f51\u63a5\u5165\u63d0\u4f9b\u5546\u5904\u83b7\u53d6\u8bc6\u522b\u4fe1\u606f\u3002", "conclusion": "\u8be5\u5224\u51b3\u786e\u7acb\u4e86\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff0c\u5373\u4f7f\u7f51\u7ad9\u53d1\u5e03\u8005\u4e0d\u80fd\u76f4\u63a5\u8bc6\u522b\u4e2a\u4eba\uff0c\u52a8\u6001IP\u5730\u5740\u4ecd\u53ef\u80fd\u88ab\u89c6\u4e3a\u4e2a\u4eba\u6570\u636e\u7684\u91cd\u8981\u6cd5\u5f8b\u539f\u5219\u3002"}}
{"id": "2511.00379", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00379", "abs": "https://arxiv.org/abs/2511.00379", "authors": ["Jiahao Wang", "Songkai Xue", "Jinghui Li", "Xiaozhen Wang"], "title": "Diverse Human Value Alignment for Large Language Models via Ethical Reasoning", "comment": "Accepted by AIES 2025, camera-ready version", "summary": "Ensuring that Large Language Models (LLMs) align with the diverse and\nevolving human values across different regions and cultures remains a critical\nchallenge in AI ethics. Current alignment approaches often yield superficial\nconformity rather than genuine ethical understanding, failing to address the\ncomplex, context-dependent nature of human values. In this paper, we propose a\nnovel ethical reasoning paradigm for LLMs inspired by well-established ethical\ndecision-making models, aiming at enhancing diverse human value alignment\nthrough deliberative ethical reasoning. Our framework consists of a structured\nfive-step process, including contextual fact gathering, hierarchical social\nnorm identification, option generation, multiple-lens ethical impact analysis,\nand reflection. This theory-grounded approach guides LLMs through an\ninterpretable reasoning process that enhances their ability to understand\nregional specificities and perform nuanced ethical analysis, which can be\nimplemented with either prompt engineering or supervised fine-tuning methods.\nWe perform evaluations on the SafeWorld benchmark that specially designed for\nregional value alignment. Experimental results demonstrate our framework\nsignificantly improves LLM alignment with diverse human values compared to\nbaseline methods, enabling more accurate social norm identification and more\nculturally appropriate reasoning. Our work provides a concrete pathway toward\ndeveloping LLMs that align more effectively with the multifaceted values of\nglobal societies through interdisciplinary research.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f26\u7406\u51b3\u7b56\u6a21\u578b\u7684LLM\u4f26\u7406\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u4e94\u6b65\u7ed3\u6784\u5316\u8fc7\u7a0b\u589e\u5f3aLLM\u4e0e\u4e0d\u540c\u5730\u533a\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u5bf9\u9f50\u80fd\u529b\u3002", "motivation": "\u5f53\u524dLLM\u5bf9\u9f50\u65b9\u6cd5\u5f80\u5f80\u53ea\u4ea7\u751f\u8868\u9762\u4e00\u81f4\u6027\u800c\u975e\u771f\u6b63\u7684\u4f26\u7406\u7406\u89e3\uff0c\u65e0\u6cd5\u5904\u7406\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u590d\u6742\u6027\u548c\u60c5\u5883\u4f9d\u8d56\u6027\u3002", "method": "\u91c7\u7528\u4e94\u6b65\u7ed3\u6784\u5316\u4f26\u7406\u63a8\u7406\u8fc7\u7a0b\uff1a\u60c5\u5883\u4e8b\u5b9e\u6536\u96c6\u3001\u5206\u5c42\u793e\u4f1a\u89c4\u8303\u8bc6\u522b\u3001\u9009\u9879\u751f\u6210\u3001\u591a\u89c6\u89d2\u4f26\u7406\u5f71\u54cd\u5206\u6790\u3001\u53cd\u601d\u3002\u53ef\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u6216\u76d1\u7763\u5fae\u8c03\u5b9e\u73b0\u3002", "result": "\u5728\u4e13\u95e8\u8bbe\u8ba1\u7684SafeWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86LLM\u4e0e\u591a\u6837\u5316\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u5bf9\u9f50\u6548\u679c\uff0c\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u7684\u793e\u4f1a\u89c4\u8303\u8bc6\u522b\u548c\u66f4\u6587\u5316\u9002\u5b9c\u6027\u7684\u63a8\u7406\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u901a\u8fc7\u8de8\u5b66\u79d1\u7814\u7a76\u5f00\u53d1\u80fd\u66f4\u6709\u6548\u5bf9\u9f50\u5168\u7403\u793e\u4f1a\u591a\u5143\u4ef7\u503c\u89c2\u7684LLM\u63d0\u4f9b\u4e86\u5177\u4f53\u8def\u5f84\u3002"}}
{"id": "2511.00306", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00306", "abs": "https://arxiv.org/abs/2511.00306", "authors": ["Baoshan Song", "Ruijie Xu", "Li-Ta Hsu"], "title": "FGO MythBusters: Explaining how Kalman Filter variants achieve the same performance as FGO in navigation applications", "comment": null, "summary": "Sliding window-factor graph optimization (SW-FGO) has gained more and more\nattention in navigation research due to its robust approximation to\nnon-Gaussian noises and nonlinearity of measuring models. There are lots of\nworks focusing on its application performance compared to extended Kalman\nfilter (EKF) but there is still a myth at the theoretical relationship between\nthe SW-FGO and EKF. In this paper, we find the necessarily fair condition to\nconnect SW-FGO and Kalman filter variants (KFV) (e.g., EKF, iterative EKF\n(IEKF), robust EKF (REKF) and robust iterative EKF (RIEKF)). Based on the\nconditions, we propose a recursive FGO (Re-FGO) framework to represent KFV\nunder SW-FGO formulation. Under explicit conditions (Markov assumption,\nGaussian noise with L2 loss, and a one-state window), Re-FGO regenerates\nexactly to EKF/IEKF/REKF/RIEKF, while SW-FGO shows measurable benefits in\nnonlinear, non-Gaussian regimes at a predictable compute cost. Finally, after\nclarifying the connection between them, we highlight the unique advantages of\nSW-FGO in practical phases, especially on numerical estimation and deep\nlearning integration. The code and data used in this work is open sourced at\nhttps://github.com/Baoshan-Song/KFV-FGO-Comparison.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u4e86\u6ed1\u52a8\u7a97\u53e3\u56e0\u5b50\u56fe\u4f18\u5316(SW-FGO)\u4e0e\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u53d8\u4f53(KFV)\u4e4b\u95f4\u7684\u7406\u8bba\u8054\u7cfb\uff0c\u63d0\u51fa\u4e86\u9012\u5f52FGO(Re-FGO)\u6846\u67b6\uff0c\u8bc1\u660e\u5728\u7279\u5b9a\u6761\u4ef6\u4e0bRe-FGO\u53ef\u7cbe\u786e\u91cd\u73b0EKF\u7b49KFV\u7b97\u6cd5\u3002", "motivation": "\u867d\u7136SW-FGO\u5728\u5bfc\u822a\u7814\u7a76\u4e2d\u8d8a\u6765\u8d8a\u53d7\u5173\u6ce8\uff0c\u4f46\u5176\u4e0eEKF\u7b49\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u53d8\u4f53\u7684\u7406\u8bba\u5173\u7cfb\u4ecd\u4e0d\u660e\u786e\uff0c\u9700\u8981\u5efa\u7acb\u4e24\u8005\u4e4b\u95f4\u7684\u7406\u8bba\u8fde\u63a5\u3002", "method": "\u63d0\u51fa\u4e86\u9012\u5f52FGO(Re-FGO)\u6846\u67b6\u6765\u8868\u793aKFV\u5728SW-FGO\u516c\u5f0f\u4e0b\u7684\u5f62\u5f0f\uff0c\u5728\u660e\u786e\u6761\u4ef6(\u9a6c\u5c14\u53ef\u592b\u5047\u8bbe\u3001\u9ad8\u65af\u566a\u58f0\u4e0eL2\u635f\u5931\u3001\u5355\u72b6\u6001\u7a97\u53e3)\u4e0b\u8fdb\u884c\u7406\u8bba\u5206\u6790\u3002", "result": "\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff0cRe-FGO\u53ef\u7cbe\u786e\u91cd\u73b0EKF/IEKF/REKF/RIEKF\u7b49\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u53d8\u4f53\uff0c\u800cSW-FGO\u5728\u975e\u7ebf\u6027\u3001\u975e\u9ad8\u65af\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u53ef\u9884\u6d4b\u8ba1\u7b97\u6210\u672c\u4e0b\u7684\u4f18\u52bf\u3002", "conclusion": "\u6f84\u6e05\u4e86SW-FGO\u4e0eKFV\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u7a81\u51fa\u4e86SW-FGO\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u72ec\u7279\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5728\u6570\u503c\u4f30\u8ba1\u548c\u6df1\u5ea6\u5b66\u4e60\u96c6\u6210\u65b9\u9762\u3002"}}
{"id": "2511.00623", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.00623", "abs": "https://arxiv.org/abs/2511.00623", "authors": ["Junhong Liu", "Lanxin Du", "Yujia Li", "Rong-Peng Liu", "Fei Teng", "Francis Yunhe Hou"], "title": "Adaptive Federated Learning to Optimize the MultiCast flows in Data Centers", "comment": null, "summary": "Data centers play an increasingly critical role in societal digitalization,\nyet their rapidly growing energy demand poses significant challenges for\nsustainable operation. To enhance the energy efficiency of geographically\ndistributed data centers, this paper formulates a multi-period optimization\nmodel that captures the interdependence of electricity, heat, and data flows.\nThe optimization of such multicast flows inherently involves mixed-integer\nformulations and the access to proprietary or sensitive datasets, which\ncorrespondingly exacerbate computational complexity and raise data-privacy\nconcerns. To address these challenges, an adaptive federated\nlearning-to-optimization approach is proposed, accounting for the heterogeneity\nof datasets across distributed data centers. To safeguard privacy, cryptography\ntechniques are leveraged in both the learning and optimization processes. A\nmodel acceptance criterion with convergence guarantee is developed to improve\nlearning performance and filter out potentially contaminated data, while a\nverifiable double aggregation mechanism is further proposed to simultaneously\nensure privacy and integrity of shared data during optimization. Theoretical\nanalysis and numerical simulations demonstrate that the proposed approach\npreserves the privacy and integrity of shared data, achieves near-optimal\nperformance, and exhibits high computational efficiency, making it suitable for\nlarge-scale data center optimization under privacy constraints.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u8054\u90a6\u5b66\u4e60\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u5730\u7406\u5206\u5e03\u5f0f\u6570\u636e\u4e2d\u5fc3\u7684\u591a\u5468\u671f\u4f18\u5316\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u548c\u5b8c\u6574\u6027\u3002", "motivation": "\u6570\u636e\u4e2d\u5fc3\u80fd\u8017\u5feb\u901f\u589e\u957f\u5e26\u6765\u53ef\u6301\u7eed\u8fd0\u8425\u6311\u6218\uff0c\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u9762\u4e34\u6df7\u5408\u6574\u6570\u89c4\u5212\u590d\u6742\u6027\u548c\u6570\u636e\u9690\u79c1\u95ee\u9898\u3002", "method": "\u91c7\u7528\u81ea\u9002\u5e94\u8054\u90a6\u5b66\u4e60\u4f18\u5316\u65b9\u6cd5\uff0c\u7ed3\u5408\u5bc6\u7801\u5b66\u6280\u672f\u4fdd\u62a4\u9690\u79c1\uff0c\u5f00\u53d1\u6a21\u578b\u63a5\u53d7\u6807\u51c6\u548c\u53ef\u9a8c\u8bc1\u53cc\u91cd\u805a\u5408\u673a\u5236\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u6570\u503c\u6a21\u62df\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u548c\u5b8c\u6574\u6027\uff0c\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u6027\u80fd\uff0c\u8ba1\u7b97\u6548\u7387\u9ad8\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u6570\u636e\u4e2d\u5fc3\u5728\u9690\u79c1\u7ea6\u675f\u4e0b\u7684\u4f18\u5316\uff0c\u80fd\u6709\u6548\u5e73\u8861\u80fd\u6548\u4f18\u5316\u4e0e\u6570\u636e\u5b89\u5168\u9700\u6c42\u3002"}}
{"id": "2511.01752", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.01752", "abs": "https://arxiv.org/abs/2511.01752", "authors": ["Frederik Zuiderveen Borgesius", "Joris van Hoboken", "Ronan Fahy", "Kristina Irion", "Max Rozendaal"], "title": "An assessment of the Commission's Proposal on Privacy and Electronic Communications", "comment": null, "summary": "This study, commissioned by the European Parliament's Policy Department for\nCitizens Rights and Constitutional Affairs at the request of the LIBE\nCommittee, appraises the European Commission's proposal for an ePrivacy\nRegulation. The study assesses whether the proposal would ensure that the right\nto the protection of personal data, the right to respect for private life and\ncommunications, and related rights enjoy a high standard of protection. The\nstudy also highlights the proposal's potential benefits and drawbacks more\ngenerally.", "AI": {"tldr": "\u5bf9\u6b27\u76df\u59d4\u5458\u4f1aePrivacy\u6761\u4f8b\u63d0\u6848\u7684\u8bc4\u4f30\u7814\u7a76\uff0c\u5206\u6790\u5176\u5bf9\u4e2a\u4eba\u6570\u636e\u4fdd\u62a4\u3001\u9690\u79c1\u6743\u548c\u901a\u4fe1\u6743\u7b49\u6743\u5229\u7684\u4fdd\u62a4\u6c34\u5e73", "motivation": "\u5e94\u6b27\u6d32\u8bae\u4f1aLIBE\u59d4\u5458\u4f1a\u8981\u6c42\uff0c\u8bc4\u4f30ePrivacy\u6761\u4f8b\u63d0\u6848\u662f\u5426\u80fd\u786e\u4fdd\u4e2a\u4eba\u6570\u636e\u4fdd\u62a4\u6743\u3001\u9690\u79c1\u6743\u548c\u901a\u4fe1\u6743\u7b49\u83b7\u5f97\u9ad8\u6807\u51c6\u4fdd\u62a4", "method": "\u5bf9\u6b27\u76df\u59d4\u5458\u4f1a\u7684ePrivacy\u6761\u4f8b\u63d0\u6848\u8fdb\u884c\u7cfb\u7edf\u6027\u8bc4\u4f30\u548c\u5206\u6790", "result": "\u8bc6\u522b\u4e86\u63d0\u6848\u7684\u6f5c\u5728\u76ca\u5904\u548c\u7f3a\u9677\uff0c\u8bc4\u4f30\u4e86\u5176\u5bf9\u76f8\u5173\u6743\u5229\u7684\u4fdd\u62a4\u6807\u51c6", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6b27\u6d32\u8bae\u4f1a\u63d0\u4f9b\u4e86\u5173\u4e8eePrivacy\u6761\u4f8b\u63d0\u6848\u7684\u5168\u9762\u8bc4\u4f30\uff0c\u6307\u51fa\u4e86\u5176\u4f18\u7f3a\u70b9"}}
{"id": "2511.00382", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00382", "abs": "https://arxiv.org/abs/2511.00382", "authors": ["Mina Taraghi", "Yann Pequignot", "Amin Nikanjam", "Mohamed Amine Merzouk", "Foutse Khomh"], "title": "Efficiency vs. Alignment: Investigating Safety and Fairness Risks in Parameter-Efficient Fine-Tuning of LLMs", "comment": null, "summary": "Organizations are increasingly adopting and adapting Large Language Models\n(LLMs) hosted on public repositories such as HuggingFace. Although these\nadaptations often improve performance on specialized downstream tasks, recent\nevidence indicates that they can also degrade a model's safety or fairness.\nSince different fine-tuning techniques may exert distinct effects on these\ncritical dimensions, this study undertakes a systematic assessment of their\ntrade-offs. Four widely used Parameter-Efficient Fine-Tuning methods, LoRA,\nIA3, Prompt-Tuning, and P-Tuning, are applied to four instruction-tuned model\nfamilies (Meta-Llama-3-8B, Qwen2.5-7B, Mistral-7B, and Gemma-7B). In total, 235\nfine-tuned variants are evaluated across eleven safety hazard categories and\nnine demographic fairness dimensions. The results show that adapter-based\napproaches (LoRA, IA3) tend to improve safety scores and are the least\ndisruptive to fairness, retaining higher accuracy and lower bias scores. In\ncontrast, prompt-based methods (Prompt-Tuning and P-Tuning) generally reduce\nsafety and cause larger fairness regressions, with decreased accuracy and\nincreased bias. Alignment shifts are strongly moderated by base model type:\nLLaMA remains stable, Qwen records modest gains, Gemma experiences the steepest\nsafety decline, and Mistral, which is released without an internal moderation\nlayer, displays the greatest variance. Improvements in safety do not\nnecessarily translate into improvements in fairness, and no single\nconfiguration optimizes all fairness metrics simultaneously, indicating an\ninherent trade-off between these objectives. These findings suggest a practical\nguideline for safety-critical deployments: begin with a well-aligned base\nmodel, favour adapter-based PEFT, and conduct category-specific audits of both\nsafety and fairness.", "AI": {"tldr": "\u7cfb\u7edf\u8bc4\u4f30\u56db\u79cd\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5(LoRA\u3001IA3\u3001Prompt-Tuning\u3001P-Tuning)\u5bf9LLM\u5b89\u5168\u6027\u548c\u516c\u5e73\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u57fa\u4e8e\u9002\u914d\u5668\u7684\u65b9\u6cd5\u5728\u4fdd\u6301\u5b89\u5168\u6027\u548c\u516c\u5e73\u6027\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u800c\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\u901a\u5e38\u4f1a\u5bfc\u81f4\u5b89\u5168\u6027\u548c\u516c\u5e73\u6027\u4e0b\u964d\u3002", "motivation": "\u7ec4\u7ec7\u8d8a\u6765\u8d8a\u591a\u5730\u91c7\u7528\u548c\u8c03\u6574\u6258\u7ba1\u5728\u516c\u5171\u5b58\u50a8\u5e93\u4e0a\u7684LLM\uff0c\u867d\u7136\u8fd9\u4e9b\u8c03\u6574\u901a\u5e38\u80fd\u63d0\u9ad8\u4e13\u4e1a\u4e0b\u6e38\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u4f46\u6700\u8fd1\u8bc1\u636e\u8868\u660e\u5b83\u4eec\u4e5f\u53ef\u80fd\u964d\u4f4e\u6a21\u578b\u7684\u5b89\u5168\u6027\u6216\u516c\u5e73\u6027\u3002", "method": "\u5c06\u56db\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u5e94\u7528\u4e8e\u56db\u4e2a\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u5bb6\u65cf\uff0c\u5171\u8bc4\u4f30235\u4e2a\u5fae\u8c03\u53d8\u4f53\uff0c\u6db5\u76d611\u4e2a\u5b89\u5168\u5371\u5bb3\u7c7b\u522b\u548c9\u4e2a\u4eba\u53e3\u7edf\u8ba1\u516c\u5e73\u6027\u7ef4\u5ea6\u3002", "result": "\u57fa\u4e8e\u9002\u914d\u5668\u7684\u65b9\u6cd5(LoRA\u3001IA3)\u503e\u5411\u4e8e\u63d0\u9ad8\u5b89\u5168\u5206\u6570\uff0c\u5bf9\u516c\u5e73\u6027\u7834\u574f\u6700\u5c0f\uff1b\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5(Prompt-Tuning\u548cP-Tuning)\u901a\u5e38\u964d\u4f4e\u5b89\u5168\u6027\u5e76\u5bfc\u81f4\u66f4\u5927\u7684\u516c\u5e73\u6027\u56de\u5f52\u3002\u5bf9\u9f50\u53d8\u5316\u53d7\u57fa\u7840\u6a21\u578b\u7c7b\u578b\u5f3a\u70c8\u8c03\u8282\u3002", "conclusion": "\u5b89\u5168\u6027\u7684\u6539\u8fdb\u4e0d\u4e00\u5b9a\u8f6c\u5316\u4e3a\u516c\u5e73\u6027\u7684\u6539\u8fdb\uff0c\u6ca1\u6709\u5355\u4e00\u914d\u7f6e\u80fd\u540c\u65f6\u4f18\u5316\u6240\u6709\u516c\u5e73\u6027\u6307\u6807\uff0c\u8868\u660e\u8fd9\u4e9b\u76ee\u6807\u4e4b\u95f4\u5b58\u5728\u56fa\u6709\u7684\u6743\u8861\u3002\u5efa\u8bae\u4ece\u826f\u597d\u5bf9\u9f50\u7684\u57fa\u7840\u6a21\u578b\u5f00\u59cb\uff0c\u4f18\u5148\u9009\u62e9\u57fa\u4e8e\u9002\u914d\u5668\u7684PEFT\uff0c\u5e76\u8fdb\u884c\u7279\u5b9a\u7c7b\u522b\u7684\u5b89\u5168\u548c\u516c\u5e73\u6027\u5ba1\u8ba1\u3002"}}
{"id": "2511.00392", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00392", "abs": "https://arxiv.org/abs/2511.00392", "authors": ["Lingpeng Chen", "Jiakun Tang", "Apple Pui-Yi Chui", "Ziyang Hong", "Junfeng Wu"], "title": "SonarSweep: Fusing Sonar and Vision for Robust 3D Reconstruction via Plane Sweeping", "comment": "8 pages, 9 figures, conference", "summary": "Accurate 3D reconstruction in visually-degraded underwater environments\nremains a formidable challenge. Single-modality approaches are insufficient:\nvision-based methods fail due to poor visibility and geometric constraints,\nwhile sonar is crippled by inherent elevation ambiguity and low resolution.\nConsequently, prior fusion technique relies on heuristics and flawed geometric\nassumptions, leading to significant artifacts and an inability to model complex\nscenes. In this paper, we introduce SonarSweep, a novel, end-to-end deep\nlearning framework that overcomes these limitations by adapting the principled\nplane sweep algorithm for cross-modal fusion between sonar and visual data.\nExtensive experiments in both high-fidelity simulation and real-world\nenvironments demonstrate that SonarSweep consistently generates dense and\naccurate depth maps, significantly outperforming state-of-the-art methods\nacross challenging conditions, particularly in high turbidity. To foster\nfurther research, we will publicly release our code and a novel dataset\nfeaturing synchronized stereo-camera and sonar data, the first of its kind.", "AI": {"tldr": "SonarSweep\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6539\u8fdb\u5e73\u9762\u626b\u63cf\u7b97\u6cd5\u5b9e\u73b0\u58f0\u7eb3\u548c\u89c6\u89c9\u6570\u636e\u7684\u8de8\u6a21\u6001\u878d\u5408\uff0c\u5728\u89c6\u89c9\u9000\u5316\u7684\u6c34\u4e0b\u73af\u5883\u4e2d\u5b9e\u73b0\u7cbe\u786e\u76843D\u91cd\u5efa\u3002", "motivation": "\u6c34\u4e0b\u89c6\u89c9\u9000\u5316\u73af\u5883\u4e2d\u76843D\u91cd\u5efa\u9762\u4e34\u5de8\u5927\u6311\u6218\uff1a\u89c6\u89c9\u65b9\u6cd5\u56e0\u80fd\u89c1\u5ea6\u5dee\u548c\u51e0\u4f55\u7ea6\u675f\u800c\u5931\u8d25\uff0c\u58f0\u7eb3\u65b9\u6cd5\u5b58\u5728\u9ad8\u7a0b\u6a21\u7cca\u548c\u4f4e\u5206\u8fa8\u7387\u95ee\u9898\u3002\u73b0\u6709\u878d\u5408\u6280\u672f\u4f9d\u8d56\u542f\u53d1\u5f0f\u65b9\u6cd5\u548c\u6709\u7f3a\u9677\u7684\u51e0\u4f55\u5047\u8bbe\uff0c\u5bfc\u81f4\u663e\u8457\u4f2a\u5f71\u4e14\u65e0\u6cd5\u5efa\u6a21\u590d\u6742\u573a\u666f\u3002", "method": "\u63d0\u51faSonarSweep\u6846\u67b6\uff0c\u5c06\u539f\u7406\u6027\u7684\u5e73\u9762\u626b\u63cf\u7b97\u6cd5\u9002\u914d\u7528\u4e8e\u58f0\u7eb3\u548c\u89c6\u89c9\u6570\u636e\u7684\u8de8\u6a21\u6001\u878d\u5408\uff0c\u91c7\u7528\u7aef\u5230\u7aef\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u3002", "result": "\u5728\u9ad8\u4fdd\u771f\u4eff\u771f\u548c\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSonarSweep\u80fd\u6301\u7eed\u751f\u6210\u5bc6\u96c6\u4e14\u7cbe\u786e\u7684\u6df1\u5ea6\u56fe\uff0c\u5728\u6311\u6218\u6027\u6761\u4ef6\u4e0b\uff08\u7279\u522b\u662f\u9ad8\u6d4a\u5ea6\u73af\u5883\uff09\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "SonarSweep\u514b\u670d\u4e86\u6c34\u4e0b3D\u91cd\u5efa\u7684\u5c40\u9650\u6027\uff0c\u4f5c\u8005\u5c06\u516c\u5f00\u4ee3\u7801\u548c\u9996\u4e2a\u5305\u542b\u540c\u6b65\u7acb\u4f53\u76f8\u673a\u4e0e\u58f0\u7eb3\u6570\u636e\u7684\u65b0\u578b\u6570\u636e\u96c6\uff0c\u4ee5\u4fc3\u8fdb\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2511.00639", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.00639", "abs": "https://arxiv.org/abs/2511.00639", "authors": ["Taulant Kerci", "Federico Milano"], "title": "Frequency Quality Assessment of GFM and GFL Converters and Synchronous Condensers", "comment": null, "summary": "This paper compares the impact of different conventional and emerging\ntechnologies and control strategies on frequency quality. We study, in\nparticular, the long-term dynamic performance of grid-forming (GFM) and\ngrid-following (GFL) inverter-based resources (IBRs) as well as conventional\nsynchronous machines. Extensive simulations and several realistic scenarios\nconsider both short-term and long-term aspects of frequency quality. It is\nshown that, while overall GFM IBRs significantly improve frequency quality, a\ncombination of GFL IBRs providing frequency support such as wind and batteries,\nand synchronous condensers, might be enough to meet similar frequency quality\nstandards. Another result of the paper is that the need for automatic\ngeneration control (AGC) becomes less clear in GFM IBR-dominated grids from a\nfrequency quality perspective.", "AI": {"tldr": "\u6bd4\u8f83\u7535\u7f51\u5f62\u6210(GFM)\u548c\u7535\u7f51\u8ddf\u968f(GFL)\u9006\u53d8\u5668\u8d44\u6e90\u4e0e\u4f20\u7edf\u540c\u6b65\u673a\u5bf9\u9891\u7387\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u53d1\u73b0GFM\u663e\u8457\u6539\u5584\u9891\u7387\u8d28\u91cf\uff0c\u4f46GFL\u4e0e\u540c\u6b65\u8c03\u76f8\u673a\u7684\u7ec4\u5408\u4e5f\u80fd\u8fbe\u5230\u7c7b\u4f3c\u6807\u51c6\uff0c\u4e14\u5728GFM\u4e3b\u5bfc\u7535\u7f51\u4e2dAGC\u9700\u6c42\u53d8\u5f97\u4e0d\u660e\u786e\u3002", "motivation": "\u7814\u7a76\u4e0d\u540c\u6280\u672f\u548c\u63a7\u5236\u7b56\u7565\u5bf9\u7535\u7f51\u9891\u7387\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u7279\u522b\u5173\u6ce8GFM\u548cGFL\u9006\u53d8\u5668\u8d44\u6e90\u7684\u957f\u671f\u52a8\u6001\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u4eff\u771f\u548c\u591a\u4e2a\u73b0\u5b9e\u573a\u666f\uff0c\u8003\u8651\u9891\u7387\u8d28\u91cf\u7684\u77ed\u671f\u548c\u957f\u671f\u65b9\u9762\uff0c\u6bd4\u8f83GFM IBRs\u3001GFL IBRs\u548c\u4f20\u7edf\u540c\u6b65\u673a\u7684\u6027\u80fd\u3002", "result": "GFM IBRs\u663e\u8457\u6539\u5584\u9891\u7387\u8d28\u91cf\uff1b\u63d0\u4f9b\u9891\u7387\u652f\u6301\u7684GFL IBRs\uff08\u5982\u98ce\u7535\u548c\u7535\u6c60\uff09\u4e0e\u540c\u6b65\u8c03\u76f8\u673a\u7684\u7ec4\u5408\u53ef\u8fbe\u5230\u7c7b\u4f3c\u9891\u7387\u8d28\u91cf\u6807\u51c6\uff1b\u5728GFM\u4e3b\u5bfc\u7535\u7f51\u4e2dAGC\u9700\u6c42\u53d8\u5f97\u4e0d\u660e\u786e\u3002", "conclusion": "GFM\u6280\u672f\u80fd\u663e\u8457\u63d0\u5347\u9891\u7387\u8d28\u91cf\uff0c\u4f46GFL\u4e0e\u540c\u6b65\u8bbe\u5907\u7684\u7ec4\u5408\u4e5f\u80fd\u6ee1\u8db3\u6807\u51c6\uff0c\u4e14\u5728GFM\u4e3b\u5bfc\u7cfb\u7edf\u4e2d\u9700\u8981\u91cd\u65b0\u8bc4\u4f30AGC\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2511.01840", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01840", "abs": "https://arxiv.org/abs/2511.01840", "authors": ["Greta Ontrup", "Annika Bush", "Markus Pauly", "Meltem Aksoy"], "title": "A Detailed Study on LLM Biases Concerning Corporate Social Responsibility and Green Supply Chains", "comment": "37 pages, 2 figures", "summary": "Organizations increasingly use Large Language Models (LLMs) to improve supply\nchain processes and reduce environmental impacts. However, LLMs have been shown\nto reproduce biases regarding the prioritization of sustainable business\nstrategies. Thus, it is important to identify underlying training data biases\nthat LLMs pertain regarding the importance and role of sustainable business and\nsupply chain practices. This study investigates how different LLMs respond to\nvalidated surveys about the role of ethics and responsibility for businesses,\nand the importance of sustainable practices and relations with suppliers and\ncustomers. Using standardized questionnaires, we systematically analyze\nresponses generated by state-of-the-art LLMs to identify variations. We further\nevaluate whether differences are augmented by four organizational culture\ntypes, thereby evaluating the practical relevance of identified biases. The\nfindings reveal significant systematic differences between models and\ndemonstrate that organizational culture prompts substantially modify LLM\nresponses. The study holds important implications for LLM-assisted\ndecision-making in sustainability contexts.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u4e0d\u540cLLMs\u5728\u53ef\u6301\u7eed\u5546\u4e1a\u5b9e\u8df5\u8c03\u67e5\u4e2d\u7684\u504f\u89c1\uff0c\u53d1\u73b0\u6a21\u578b\u95f4\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u4e14\u7ec4\u7ec7\u6587\u5316\u63d0\u793a\u4f1a\u663e\u8457\u5f71\u54cdLLM\u54cd\u5e94\u3002", "motivation": "\u968f\u7740\u7ec4\u7ec7\u8d8a\u6765\u8d8a\u591a\u5730\u4f7f\u7528LLMs\u6539\u8fdb\u4f9b\u5e94\u94fe\u6d41\u7a0b\u548c\u51cf\u5c11\u73af\u5883\u5f71\u54cd\uff0c\u4f46LLMs\u5728\u53ef\u6301\u7eed\u5546\u4e1a\u6218\u7565\u4f18\u5148\u7ea7\u7684\u504f\u89c1\u95ee\u9898\u9700\u8981\u88ab\u8bc6\u522b\u548c\u89e3\u51b3\u3002", "method": "\u4f7f\u7528\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u5173\u4e8e\u4f01\u4e1a\u4f26\u7406\u8d23\u4efb\u548c\u53ef\u6301\u7eed\u5b9e\u8df5\u7684\u8c03\u67e5\u95ee\u5377\uff0c\u7cfb\u7edf\u5206\u6790\u6700\u5148\u8fdbLLMs\u7684\u54cd\u5e94\u5dee\u5f02\uff0c\u5e76\u8bc4\u4f30\u56db\u79cd\u7ec4\u7ec7\u6587\u5316\u7c7b\u578b\u5bf9\u5dee\u5f02\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u6a21\u578b\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u7684\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u7ec4\u7ec7\u6587\u5316\u63d0\u793a\u4f1a\u663e\u8457\u6539\u53d8LLM\u7684\u54cd\u5e94\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u7814\u7a76\u5bf9LLM\u5728\u53ef\u6301\u7eed\u6027\u51b3\u7b56\u8f85\u52a9\u65b9\u9762\u5177\u6709\u91cd\u8981\u542f\u793a\uff0c\u5f3a\u8c03\u4e86\u8bc6\u522b\u548c\u89e3\u51b3\u8bad\u7ec3\u6570\u636e\u504f\u89c1\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.00424", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00424", "abs": "https://arxiv.org/abs/2511.00424", "authors": ["Ashutosh Anshul", "Gumpili Sai Pranav", "Mohammad Zia Ur Rehman", "Nagendra Kumar"], "title": "A Multimodal Framework for Depression Detection during Covid-19 via Harvesting Social Media: A Novel Dataset and Method", "comment": null, "summary": "The recent coronavirus disease (Covid-19) has become a pandemic and has\naffected the entire globe. During the pandemic, we have observed a spike in\ncases related to mental health, such as anxiety, stress, and depression.\nDepression significantly influences most diseases worldwide, making it\ndifficult to detect mental health conditions in people due to unawareness and\nunwillingness to consult a doctor. However, nowadays, people extensively use\nonline social media platforms to express their emotions and thoughts. Hence,\nsocial media platforms are now becoming a large data source that can be\nutilized for detecting depression and mental illness. However, existing\napproaches often overlook data sparsity in tweets and the multimodal aspects of\nsocial media. In this paper, we propose a novel multimodal framework that\ncombines textual, user-specific, and image analysis to detect depression among\nsocial media users. To provide enough context about the user's emotional state,\nwe propose (i) an extrinsic feature by harnessing the URLs present in tweets\nand (ii) extracting textual content present in images posted in tweets. We also\nextract five sets of features belonging to different modalities to describe a\nuser. Additionally, we introduce a Deep Learning model, the Visual Neural\nNetwork (VNN), to generate embeddings of user-posted images, which are used to\ncreate the visual feature vector for prediction. We contribute a curated\nCovid-19 dataset of depressed and non-depressed users for research purposes and\ndemonstrate the effectiveness of our model in detecting depression during the\nCovid-19 outbreak. Our model outperforms existing state-of-the-art methods over\na benchmark dataset by 2%-8% and produces promising results on the Covid-19\ndataset. Our analysis highlights the impact of each modality and provides\nvaluable insights into users' mental and emotional states.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u6846\u67b6\uff0c\u7ed3\u5408\u6587\u672c\u3001\u7528\u6237\u7279\u5b9a\u4fe1\u606f\u548c\u56fe\u50cf\u5206\u6790\u6765\u68c0\u6d4b\u793e\u4ea4\u5a92\u4f53\u7528\u6237\u7684\u6291\u90c1\u75c7\uff0c\u5728\u65b0\u51a0\u75ab\u60c5\u671f\u95f4\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u65b0\u51a0\u75ab\u60c5\u5bfc\u81f4\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\u6fc0\u589e\uff0c\u4f46\u4eba\u4eec\u5f80\u5f80\u4e0d\u613f\u5c31\u533b\u3002\u793e\u4ea4\u5a92\u4f53\u6210\u4e3a\u8868\u8fbe\u60c5\u7eea\u7684\u91cd\u8981\u5e73\u53f0\uff0c\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6\u4e86\u63a8\u6587\u6570\u636e\u7a00\u758f\u6027\u548c\u591a\u6a21\u6001\u7279\u6027\u3002", "method": "\u4f7f\u7528\u6587\u672c\u3001\u7528\u6237\u7279\u5b9a\u7279\u5f81\u548c\u56fe\u50cf\u5206\u6790\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u63d0\u53d6\u63a8\u6587\u4e2dURL\u7684\u5916\u90e8\u7279\u5f81\u548c\u56fe\u50cf\u4e2d\u7684\u6587\u672c\u5185\u5bb9\uff0c\u5f00\u53d1\u89c6\u89c9\u795e\u7ecf\u7f51\u7edc(VNN)\u751f\u6210\u56fe\u50cf\u5d4c\u5165\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u63d0\u53472%-8%\uff0c\u5728\u65b0\u51a0\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5206\u6790\u63ed\u793a\u4e86\u5404\u6a21\u6001\u5bf9\u68c0\u6d4b\u7684\u5f71\u54cd\u3002", "conclusion": "\u591a\u6a21\u6001\u65b9\u6cd5\u80fd\u6709\u6548\u68c0\u6d4b\u793e\u4ea4\u5a92\u4f53\u7528\u6237\u7684\u6291\u90c1\u75c7\uff0c\u4e3a\u7406\u89e3\u7528\u6237\u5fc3\u7406\u72b6\u6001\u63d0\u4f9b\u5b9d\u8d35\u89c1\u89e3\uff0c\u7279\u522b\u662f\u5728\u75ab\u60c5\u671f\u95f4\u3002"}}
{"id": "2511.00412", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00412", "abs": "https://arxiv.org/abs/2511.00412", "authors": ["John A. Christian", "Michael R. Walker II", "Wyatt Bridgman", "Michael J. Sparapany"], "title": "Runge-Kutta Approximations for Direct Coning Compensation Applying Lie Theory", "comment": null, "summary": "The integration of gyroscope measurements is an essential task for most\nnavigation systems. Modern vehicles typically use strapdown systems, such that\ngyro integration requires coning compensation to account for the sensor's\nrotation during the integration. Many coning compensation algorithms have been\ndeveloped and a few are reviewed. This work introduces a new class of coning\ncorrection algorithm built directly from the classical Runge-Kutta integration\nroutines. A simple case is shown to collapse to one of the most popular coning\nalgorithms and a clear procedure for generating higher-order algorithms is\npresented.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ecf\u5178\u9f99\u683c-\u5e93\u5854\u79ef\u5206\u65b9\u6cd5\u7684\u65b0\u578b\u5706\u9525\u8865\u507f\u7b97\u6cd5\uff0c\u4e3a\u5bfc\u822a\u7cfb\u7edf\u4e2d\u7684\u9640\u87ba\u4eea\u79ef\u5206\u63d0\u4f9b\u66f4\u7cbe\u786e\u7684\u8865\u507f\u65b9\u6848\u3002", "motivation": "\u73b0\u4ee3\u5bfc\u822a\u7cfb\u7edf\u901a\u5e38\u91c7\u7528\u6377\u8054\u5f0f\u7cfb\u7edf\uff0c\u9640\u87ba\u4eea\u79ef\u5206\u9700\u8981\u8003\u8651\u4f20\u611f\u5668\u65cb\u8f6c\u5e26\u6765\u7684\u5706\u9525\u6548\u5e94\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u6709\u6548\u7684\u5706\u9525\u8865\u507f\u7b97\u6cd5\u6765\u63d0\u9ad8\u5bfc\u822a\u7cbe\u5ea6\u3002", "method": "\u76f4\u63a5\u4ece\u7ecf\u5178\u9f99\u683c-\u5e93\u5854\u79ef\u5206\u65b9\u6cd5\u6784\u5efa\u65b0\u578b\u5706\u9525\u8865\u507f\u7b97\u6cd5\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u751f\u6210\u9ad8\u9636\u7b97\u6cd5\u7684\u6e05\u6670\u6d41\u7a0b\u3002", "result": "\u5c55\u793a\u4e86\u7b80\u5355\u60c5\u51b5\u4e0b\u65b0\u7b97\u6cd5\u53ef\u9000\u5316\u4e3a\u6700\u6d41\u884c\u7684\u5706\u9525\u7b97\u6cd5\u4e4b\u4e00\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u57fa\u4e8e\u9f99\u683c-\u5e93\u5854\u79ef\u5206\u7684\u65b0\u578b\u5706\u9525\u8865\u507f\u7b97\u6cd5\u4e3a\u5bfc\u822a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u9640\u87ba\u4eea\u79ef\u5206\u8865\u507f\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.00659", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.00659", "abs": "https://arxiv.org/abs/2511.00659", "authors": ["Wang Chen", "Heye Huang", "Ke Ma", "Hangyu Li", "Shixiao Liang", "Hang Zhou", "Xiaopeng Li"], "title": "Unveiling Uniform Shifted Power Law in Stochastic Human and Autonomous Driving Behavior", "comment": null, "summary": "Accurately simulating rare but safety-critical driving behaviors is essential\nfor the evaluation and certification of autonomous vehicles (AVs). However,\ncurrent models often fail to reproduce realistic collision rates when\ncalibrated on real-world data, largely due to inadequate representation of\nlong-tailed behavioral distributions. Here, we uncover a simple yet unifying\nshifted power law that robustly characterizes the stochasticity of both\nhuman-driven vehicle (HV) and AV behaviors, especially in the long-tail regime.\nThe model adopts a parsimonious analytical form with only one or two\nparameters, enabling efficient calibration even under data sparsity. Analyzing\nlarge-scale, micro-level trajectory data from global HV and AV datasets, the\nshifted power law achieves an average R2 of 0.97 and a nearly identical tail\ndistribution, uniformly fits both frequent behaviors and rare safety-critical\ndeviations, significantly outperforming existing Gaussian-based baselines. When\nintegrated into an agent-based traffic simulator, it enables forward-rolling\nsimulations that reproduce realistic crash patterns for both HVs and AVs,\nachieving rates consistent with real-world statistics and improving the\nfidelity of safety assessment without post hoc correction. This discovery\noffers a unified and data-efficient foundation for modeling high-risk behavior\nand improves the fidelity of simulation-based safety assessments for mixed\nAV/HV traffic. The shifted power law provides a promising path toward\nsimulation-driven validation and global certification of AV technologies.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u79fb\u4f4d\u5e42\u5f8b\u6a21\u578b\uff0c\u80fd\u591f\u7edf\u4e00\u8868\u5f81\u4eba\u7c7b\u9a7e\u9a76\u8f66\u8f86\u548c\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u884c\u4e3a\u968f\u673a\u6027\uff0c\u7279\u522b\u662f\u5728\u957f\u5c3e\u5206\u5e03\u533a\u57df\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ea4\u901a\u4eff\u771f\u7684\u5b89\u5168\u8bc4\u4f30\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u6a21\u578b\u5728\u57fa\u4e8e\u771f\u5b9e\u6570\u636e\u6821\u51c6\u65f6\u96be\u4ee5\u91cd\u73b0\u73b0\u5b9e\u7684\u78b0\u649e\u7387\uff0c\u4e3b\u8981\u7531\u4e8e\u5bf9\u957f\u5c3e\u884c\u4e3a\u5206\u5e03\u7684\u8868\u793a\u4e0d\u8db3\uff0c\u8fd9\u5f71\u54cd\u4e86\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u5b89\u5168\u8bc4\u4f30\u548c\u8ba4\u8bc1\u3002", "method": "\u63d0\u51fa\u79fb\u4f4d\u5e42\u5f8b\u6a21\u578b\uff0c\u91c7\u7528\u7b80\u6d01\u7684\u89e3\u6790\u5f62\u5f0f\uff08\u4ec5\u97001-2\u4e2a\u53c2\u6570\uff09\uff0c\u5206\u6790\u5168\u7403HV\u548cAV\u6570\u636e\u96c6\u4e2d\u7684\u5fae\u89c2\u8f68\u8ff9\u6570\u636e\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230\u57fa\u4e8e\u4ee3\u7406\u7684\u4ea4\u901a\u6a21\u62df\u5668\u4e2d\u3002", "result": "\u79fb\u4f4d\u5e42\u5f8b\u6a21\u578b\u5e73\u5747R2\u8fbe\u52300.97\uff0c\u5c3e\u90e8\u5206\u5e03\u51e0\u4e4e\u76f8\u540c\uff0c\u5747\u5300\u62df\u5408\u9891\u7e41\u884c\u4e3a\u548c\u7f55\u89c1\u5b89\u5168\u5173\u952e\u504f\u5dee\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u4e8e\u9ad8\u65af\u5206\u5e03\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u96c6\u6210\u5230\u6a21\u62df\u5668\u540e\u80fd\u91cd\u73b0\u73b0\u5b9e\u7684\u78b0\u649e\u6a21\u5f0f\uff0c\u78b0\u649e\u7387\u4e0e\u771f\u5b9e\u7edf\u8ba1\u6570\u636e\u4e00\u81f4\u3002", "conclusion": "\u79fb\u4f4d\u5e42\u5f8b\u4e3a\u9ad8\u98ce\u9669\u884c\u4e3a\u5efa\u6a21\u63d0\u4f9b\u4e86\u7edf\u4e00\u4e14\u6570\u636e\u9ad8\u6548\u7684\u57fa\u7840\uff0c\u63d0\u9ad8\u4e86\u6df7\u5408AV/HV\u4ea4\u901a\u4eff\u771f\u5b89\u5168\u8bc4\u4f30\u7684\u4fdd\u771f\u5ea6\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u6280\u672f\u7684\u4eff\u771f\u9a71\u52a8\u9a8c\u8bc1\u548c\u5168\u7403\u8ba4\u8bc1\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u8def\u5f84\u3002"}}
{"id": "2511.00457", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00457", "abs": "https://arxiv.org/abs/2511.00457", "authors": ["Chunyu Wei", "Wenji Hu", "Xingjia Hao", "Xin Wang", "Yifan Yang", "Yueguo Chen", "Yang Tian", "Yunhai Wang"], "title": "GraphChain: Large Language Models for Large-scale Graph Analysis via Tool Chaining", "comment": null, "summary": "Large Language Models (LLMs) face significant limitations when applied to\nlarge-scale graphs, struggling with context constraints and inflexible\nreasoning. We present GraphChain, a framework that enables LLMs to analyze\ncomplex graphs through dynamic sequences of specialized tools, mimicking human\nexploratory intelligence. Our approach introduces two key innovations: (1)\nProgressive Graph Distillation, a reinforcement learning mechanism that\ngenerates optimized tool sequences balancing task relevance with information\ncompression, and (2) Structure-aware Test-Time Adaptation, which efficiently\ntailors tool selection strategies to diverse graph topologies using spectral\nproperties and lightweight adapters without costly retraining. Experiments show\nGraphChain significantly outperforms prior methods, enabling scalable and\nadaptive LLM-driven graph analysis.", "AI": {"tldr": "GraphChain\u662f\u4e00\u4e2a\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u52a8\u6001\u5de5\u5177\u5e8f\u5217\u5206\u6790\u590d\u6742\u56fe\u6570\u636e\u7684\u6846\u67b6\uff0c\u89e3\u51b3\u4e86LLM\u5728\u5927\u89c4\u6a21\u56fe\u5206\u6790\u4e2d\u7684\u4e0a\u4e0b\u6587\u9650\u5236\u548c\u63a8\u7406\u4e0d\u7075\u6d3b\u95ee\u9898\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5e94\u7528\u4e8e\u5927\u89c4\u6a21\u56fe\u6570\u636e\u65f6\u9762\u4e34\u663e\u8457\u7684\u5c40\u9650\u6027\uff0c\u5305\u62ec\u4e0a\u4e0b\u6587\u7ea6\u675f\u548c\u63a8\u7406\u4e0d\u7075\u6d3b\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6a21\u4eff\u4eba\u7c7b\u63a2\u7d22\u667a\u80fd\u7684\u65b9\u6cd5\u6765\u589e\u5f3aLLM\u7684\u56fe\u5206\u6790\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e24\u4e2a\u5173\u952e\u521b\u65b0\uff1a1) \u6e10\u8fdb\u5f0f\u56fe\u84b8\u998f - \u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u751f\u6210\u4f18\u5316\u7684\u5de5\u5177\u5e8f\u5217\uff0c\u5e73\u8861\u4efb\u52a1\u76f8\u5173\u6027\u548c\u4fe1\u606f\u538b\u7f29\uff1b2) \u7ed3\u6784\u611f\u77e5\u7684\u6d4b\u8bd5\u65f6\u9002\u5e94 - \u5229\u7528\u8c31\u5c5e\u6027\u548c\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\uff0c\u65e0\u9700\u6602\u8d35\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u9488\u5bf9\u4e0d\u540c\u56fe\u62d3\u6251\u5b9a\u5236\u5de5\u5177\u9009\u62e9\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660eGraphChain\u663e\u8457\u4f18\u4e8e\u5148\u524d\u7684\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u548c\u81ea\u9002\u5e94\u7684LLM\u9a71\u52a8\u56fe\u5206\u6790\u3002", "conclusion": "GraphChain\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u5de5\u5177\u5e8f\u5217\u548c\u7ed3\u6784\u611f\u77e5\u9002\u5e94\u673a\u5236\uff0c\u6210\u529f\u89e3\u51b3\u4e86LLM\u5728\u5927\u89c4\u6a21\u56fe\u5206\u6790\u4e2d\u7684\u5173\u952e\u9650\u5236\uff0c\u4e3aLLM\u9a71\u52a8\u7684\u56fe\u5206\u6790\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u548c\u81ea\u9002\u5e94\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00492", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00492", "abs": "https://arxiv.org/abs/2511.00492", "authors": ["Simon Giel", "James Hurrell", "Shreya Santra", "Ashutosh Mishra", "Kentaro Uno", "Kazuya Yoshida"], "title": "Design and Development of a Modular Bucket Drum Excavator for Lunar ISRU", "comment": "6 pages, 4 figures. Accepted at IEEE iSpaRo 2025", "summary": "In-Situ Resource Utilization (ISRU) is one of the key technologies for\nenabling sustainable access to the Moon. The ability to excavate lunar regolith\nis the first step in making lunar resources accessible and usable. This work\npresents the development of a bucket drum for the modular robotic system\nMoonBot, as part of the Japanese Moonshot program. A 3D-printed prototype made\nof PLA was manufactured to evaluate its efficiency through a series of sandbox\ntests. The resulting tool weighs 4.8 kg and has a volume of 14.06 L. It is\ncapable of continuous excavation at a rate of 777.54 kg/h with a normalized\nenergy consumption of 0.022 Wh/kg. In batch operation, the excavation rate is\n172.02 kg/h with a normalized energy consumption of 0.86 Wh per kilogram of\nexcavated material. The obtained results demonstrate the successful\nimplementation of the concept. A key advantage of the developed tool is its\ncompatibility with the modular MoonBot robotic platform, which enables flexible\nand efficient mission planning. Further improvements may include the\nintegration of sensors and an autonomous control system to enhance the\nexcavation process.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7528\u4e8e\u6708\u7403\u673a\u5668\u4eba\u7cfb\u7edfMoonBot\u7684\u94f2\u6597\u6eda\u7b52\u539f\u578b\uff0c\u901a\u8fc7\u6c99\u76d2\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u5176\u8fde\u7eed\u548c\u6279\u91cf\u6316\u6398\u6708\u7403\u571f\u58e4\u7684\u6548\u7387\u3002", "motivation": "\u6708\u7403\u539f\u4f4d\u8d44\u6e90\u5229\u7528(ISRU)\u662f\u5b9e\u73b0\u53ef\u6301\u7eed\u6708\u7403\u63a2\u7d22\u7684\u5173\u952e\u6280\u672f\uff0c\u6316\u6398\u6708\u7403\u571f\u58e4\u662f\u83b7\u53d6\u548c\u5229\u7528\u6708\u7403\u8d44\u6e90\u7684\u7b2c\u4e00\u6b65\u3002", "method": "\u5236\u9020\u4e86PLA\u6750\u6599\u76843D\u6253\u5370\u539f\u578b\uff0c\u901a\u8fc7\u4e00\u7cfb\u5217\u6c99\u76d2\u6d4b\u8bd5\u8bc4\u4f30\u6316\u6398\u6548\u7387\u3002", "result": "\u5de5\u5177\u91cd4.8kg\uff0c\u4f53\u79ef14.06L\uff0c\u8fde\u7eed\u6316\u6398\u901f\u7387777.54kg/h\uff0c\u80fd\u80170.022Wh/kg\uff1b\u6279\u91cf\u6316\u6398\u901f\u7387172.02kg/h\uff0c\u80fd\u80170.86Wh/kg\u3002", "conclusion": "\u6982\u5ff5\u6210\u529f\u5b9e\u73b0\uff0c\u5de5\u5177\u4e0e\u6a21\u5757\u5316MoonBot\u673a\u5668\u4eba\u5e73\u53f0\u517c\u5bb9\uff0c\u672a\u6765\u53ef\u96c6\u6210\u4f20\u611f\u5668\u548c\u81ea\u4e3b\u63a7\u5236\u7cfb\u7edf\u4ee5\u6539\u8fdb\u6316\u6398\u8fc7\u7a0b\u3002"}}
{"id": "2511.00733", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.00733", "abs": "https://arxiv.org/abs/2511.00733", "authors": ["Tyler Christeson", "Md Habib Ullah", "Ali Arabnya", "Amin Khodaei", "Rui Fan"], "title": "Hybrid Quantum-Classical Optimization of the Resource Scheduling Problem", "comment": "13 pages, 7 figures, 1 table Submitted to Next Research", "summary": "Resource scheduling is critical in many industries, especially in power\nsystems. The Unit Commitment problem determines the on/off status and output\nlevels of generators under many constraints. Traditional exact methods, such as\nmathematical programming methods or dynamic programming, remain the backbone of\nUC solution techniques, but they often rely on linear approximations or\nexhaustive search, leading to high computational burdens as system size grows.\nMetaheuristic approaches, such as genetic algorithms, particle swarm\noptimization, and other evolutionary methods, have been explored to mitigate\nthis complexity; however, they typically lack optimality guarantees, exhibit\nsensitivity to initial conditions, and can become prohibitively time-consuming\nfor large-scale systems. In this paper, we introduce a quantum-classical hybrid\nalgorithm for UC and, by extension, other resource scheduling problems, that\nleverages Benders decomposition to decouple binary commitment decisions from\ncontinuous economic dispatch. The binary master problem is formulated as a\nquadratic unconstrained binary optimization model and solved on a quantum\nannealer. The continuous subproblem, which minimizes generation costs, with\nLagrangian cuts feeding back to the master until convergence. We evaluate our\nhybrid framework on systems scaled from 10 to 1,000 generation units. Compared\nagainst a classical mixed-integer nonlinear programming baseline, the hybrid\nalgorithm achieves a consistently lower computation-time growth rate and\nmaintains an absolute optimality gap below 1.63%. These results demonstrate\nthat integrating quantum annealing within a hybrid quantum-classical Benders\ndecomposition loop can significantly accelerate large-scale resource scheduling\nwithout sacrificing solution quality, pointing toward a viable path for\naddressing the escalating complexity of modern power grids.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u91cf\u5b50-\u7ecf\u5178\u6df7\u5408\u7b97\u6cd5\uff0c\u4f7f\u7528Benders\u5206\u89e3\u5c06\u673a\u7ec4\u7ec4\u5408\u95ee\u9898\u5206\u89e3\u4e3a\u4e8c\u8fdb\u5236\u4e3b\u95ee\u9898\u548c\u8fde\u7eed\u5b50\u95ee\u9898\uff0c\u4e3b\u95ee\u9898\u5728\u91cf\u5b50\u9000\u706b\u5668\u4e0a\u6c42\u89e3\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5927\u89c4\u6a21\u7cfb\u7edf\u7684\u8ba1\u7b97\u65f6\u95f4\u589e\u957f\u3002", "motivation": "\u4f20\u7edf\u7cbe\u786e\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u7cfb\u7edf\u4e2d\u8ba1\u7b97\u8d1f\u62c5\u91cd\uff0c\u5143\u542f\u53d1\u5f0f\u65b9\u6cd5\u7f3a\u4e4f\u6700\u4f18\u6027\u4fdd\u8bc1\u4e14\u5bf9\u521d\u59cb\u6761\u4ef6\u654f\u611f\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u5904\u7406\u5927\u89c4\u6a21\u8d44\u6e90\u8c03\u5ea6\u95ee\u9898\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u91c7\u7528Benders\u5206\u89e3\u5c06\u95ee\u9898\u5206\u89e3\u4e3a\u4e8c\u8fdb\u5236\u4e3b\u95ee\u9898\u548c\u8fde\u7eed\u7ecf\u6d4e\u8c03\u5ea6\u5b50\u95ee\u9898\uff0c\u4e3b\u95ee\u9898\u6784\u5efa\u4e3a\u4e8c\u6b21\u65e0\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316\u6a21\u578b\u5e76\u5728\u91cf\u5b50\u9000\u706b\u5668\u4e0a\u6c42\u89e3\uff0c\u5b50\u95ee\u9898\u751f\u6210\u62c9\u683c\u6717\u65e5\u5272\u53cd\u9988\u81f3\u4e3b\u95ee\u9898\u76f4\u81f3\u6536\u655b\u3002", "result": "\u572810\u52301000\u4e2a\u53d1\u7535\u5355\u5143\u7684\u7cfb\u7edf\u4e2d\u6d4b\u8bd5\uff0c\u76f8\u6bd4\u7ecf\u5178\u6df7\u5408\u6574\u6570\u975e\u7ebf\u6027\u89c4\u5212\u57fa\u51c6\uff0c\u6df7\u5408\u7b97\u6cd5\u8ba1\u7b97\u65f6\u95f4\u589e\u957f\u7387\u663e\u8457\u964d\u4f4e\uff0c\u7edd\u5bf9\u6700\u4f18\u6027\u5dee\u8ddd\u4fdd\u6301\u57281.63%\u4ee5\u4e0b\u3002", "conclusion": "\u91cf\u5b50\u9000\u706b\u4e0e\u7ecf\u5178Benders\u5206\u89e3\u7684\u6df7\u5408\u6846\u67b6\u80fd\u663e\u8457\u52a0\u901f\u5927\u89c4\u6a21\u8d44\u6e90\u8c03\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u89e3\u7684\u8d28\u91cf\uff0c\u4e3a\u89e3\u51b3\u73b0\u4ee3\u7535\u7f51\u65e5\u76ca\u590d\u6742\u7684\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2511.00509", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.00509", "abs": "https://arxiv.org/abs/2511.00509", "authors": ["Yifan Xia", "Guorui Chen", "Wenqian Yu", "Zhijiang Li", "Philip Torr", "Jindong Gu"], "title": "Reimagining Safety Alignment with An Image", "comment": null, "summary": "Large language models (LLMs) excel in diverse applications but face dual\nchallenges: generating harmful content under jailbreak attacks and over-refusal\nof benign queries due to rigid safety mechanisms. These issues are further\ncomplicated by the need to accommodate different value systems and precisely\nalign with given safety preferences. Moreover, traditional methods like SFT and\nRLHF lack this capability due to their costly parameter tuning requirements and\ninability to support multiple value systems within a single model. These\nproblems are more obvious in multimodal large language models (MLLMs),\nespecially in terms of heightened over-refusal in cross-modal tasks and new\nsecurity risks arising from expanded attack surfaces. We propose Magic Image,\nan optimization-driven visual prompt framework that enhances security while\nreducing over-refusal. By optimizing image prompts using harmful/benign\nsamples, our method enables a single model to adapt to different value systems\nand better align with given safety preferences without parameter updates.\nExperiments demonstrate improved safety-effectiveness balance across diverse\ndatasets while preserving model performance, offering a practical solution for\ndeployable MLLM safety alignment.", "AI": {"tldr": "Magic Image\u662f\u4e00\u4e2a\u57fa\u4e8e\u4f18\u5316\u7684\u89c6\u89c9\u63d0\u793a\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u56fe\u50cf\u63d0\u793a\u6765\u589e\u5f3a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u540c\u65f6\u51cf\u5c11\u8fc7\u5ea6\u62d2\u7edd\uff0c\u65e0\u9700\u53c2\u6570\u66f4\u65b0\u5373\u53ef\u9002\u5e94\u4e0d\u540c\u4ef7\u503c\u7cfb\u7edf\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u751f\u6210\u6709\u5bb3\u5185\u5bb9\u548c\u8fc7\u5ea6\u62d2\u7edd\u826f\u6027\u67e5\u8be2\u7684\u53cc\u91cd\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u5982SFT\u548cRLHF\u65e0\u6cd5\u652f\u6301\u591a\u4ef7\u503c\u7cfb\u7edf\u4e14\u6210\u672c\u9ad8\u6602\uff0c\u591a\u6a21\u6001\u6a21\u578b\u4e2d\u7684\u8fd9\u4e9b\u95ee\u9898\u66f4\u52a0\u660e\u663e\u3002", "method": "\u901a\u8fc7\u4f7f\u7528\u6709\u5bb3/\u826f\u6027\u6837\u672c\u4f18\u5316\u56fe\u50cf\u63d0\u793a\uff0c\u4f7f\u5355\u4e2a\u6a21\u578b\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u4ef7\u503c\u7cfb\u7edf\u5e76\u66f4\u597d\u5730\u4e0e\u7ed9\u5b9a\u5b89\u5168\u504f\u597d\u5bf9\u9f50\uff0c\u65e0\u9700\u53c2\u6570\u66f4\u65b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u6837\u5316\u6570\u636e\u96c6\u4e0a\u6539\u5584\u4e86\u5b89\u5168\u6027\u4e0e\u6709\u6548\u6027\u7684\u5e73\u8861\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "Magic Image\u4e3a\u53ef\u90e8\u7f72\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u5bf9\u9f50\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00512", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.00512", "abs": "https://arxiv.org/abs/2511.00512", "authors": ["Suraj Kumar", "Andy Ruina"], "title": "Descriptive Model-based Learning and Control for Bipedal Locomotion", "comment": "8 pages, 15 figures", "summary": "Bipedal balance is challenging due to its multi-phase, hybrid nature and\nhigh-dimensional state space. Traditional balance control approaches for\nbipedal robots rely on low-dimensional models for locomotion planning and\nreactive control, constraining the full robot to behave like these simplified\nmodels. This involves tracking preset reference paths for the Center of Mass\nand upper body obtained through low-dimensional models, often resulting in\ninefficient walking patterns with bent knees. However, we observe that bipedal\nbalance is inherently low-dimensional and can be effectively described with\nsimple state and action descriptors in a low-dimensional state space. This\nallows the robot's motion to evolve freely in its high-dimensional state space,\nonly constraining its projection in the low-dimensional state space. In this\nwork, we propose a novel control approach that avoids prescribing a\nlow-dimensional model to the full model. Instead, our control framework uses a\ndescriptive model with the minimum degrees of freedom necessary to maintain\nbalance, allowing the remaining degrees of freedom to evolve freely in the\nhigh-dimensional space. This results in an efficient human-like walking gait\nand improved robustness.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u53cc\u8db3\u5e73\u8861\u63a7\u5236\u65b9\u6cd5\uff0c\u907f\u514d\u5c06\u7b80\u5316\u6a21\u578b\u5f3a\u52a0\u4e8e\u5b8c\u6574\u6a21\u578b\uff0c\u800c\u662f\u4f7f\u7528\u6700\u5c0f\u81ea\u7531\u5ea6\u7684\u63cf\u8ff0\u6027\u6a21\u578b\u6765\u7ef4\u6301\u5e73\u8861\uff0c\u8ba9\u5176\u4f59\u81ea\u7531\u5ea6\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u81ea\u7531\u6f14\u5316\uff0c\u4ece\u800c\u5b9e\u73b0\u9ad8\u6548\u7684\u4eba\u5f62\u6b65\u6001\u548c\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edf\u53cc\u8db3\u5e73\u8861\u63a7\u5236\u65b9\u6cd5\u4f9d\u8d56\u4f4e\u7ef4\u6a21\u578b\u8fdb\u884c\u8fd0\u52a8\u89c4\u5212\u548c\u53cd\u5e94\u63a7\u5236\uff0c\u9650\u5236\u4e86\u673a\u5668\u4eba\u7684\u5b8c\u6574\u884c\u4e3a\uff0c\u5bfc\u81f4\u4f4e\u6548\u7684\u5f2f\u66f2\u819d\u76d6\u884c\u8d70\u6a21\u5f0f\u3002\u7814\u7a76\u53d1\u73b0\u53cc\u8db3\u5e73\u8861\u672c\u8d28\u4e0a\u662f\u4f4e\u7ef4\u7684\uff0c\u53ef\u4ee5\u7528\u7b80\u5355\u7684\u72b6\u6001\u548c\u52a8\u4f5c\u63cf\u8ff0\u7b26\u6709\u6548\u63cf\u8ff0\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u63a7\u5236\u6846\u67b6\uff0c\u4f7f\u7528\u5177\u6709\u7ef4\u6301\u5e73\u8861\u6240\u9700\u6700\u5c0f\u81ea\u7531\u5ea6\u7684\u63cf\u8ff0\u6027\u6a21\u578b\uff0c\u4e0d\u5c06\u4f4e\u7ef4\u6a21\u578b\u5f3a\u52a0\u4e8e\u5b8c\u6574\u6a21\u578b\uff0c\u8ba9\u673a\u5668\u4eba\u5728\u9ad8\u7ef4\u72b6\u6001\u7a7a\u95f4\u4e2d\u81ea\u7531\u8fd0\u52a8\uff0c\u4ec5\u7ea6\u675f\u5176\u5728\u4f4e\u7ef4\u72b6\u6001\u7a7a\u95f4\u4e2d\u7684\u6295\u5f71\u3002", "result": "\u8be5\u65b9\u6cd5\u4ea7\u751f\u4e86\u9ad8\u6548\u7684\u4eba\u5f62\u884c\u8d70\u6b65\u6001\uff0c\u5e76\u63d0\u9ad8\u4e86\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u901a\u8fc7\u907f\u514d\u5c06\u7b80\u5316\u6a21\u578b\u5f3a\u52a0\u4e8e\u5b8c\u6574\u673a\u5668\u4eba\u6a21\u578b\uff0c\u800c\u662f\u4f7f\u7528\u6700\u5c0f\u81ea\u7531\u5ea6\u7684\u63cf\u8ff0\u6027\u6a21\u578b\u6765\u7ef4\u6301\u5e73\u8861\uff0c\u53ef\u4ee5\u8ba9\u673a\u5668\u4eba\u7684\u8fd0\u52a8\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u81ea\u7531\u6f14\u5316\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u81ea\u7136\u9ad8\u6548\u7684\u884c\u8d70\u548c\u66f4\u597d\u7684\u5e73\u8861\u6027\u80fd\u3002"}}
{"id": "2511.00736", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.00736", "abs": "https://arxiv.org/abs/2511.00736", "authors": ["Tyler Christeson", "Amin Khodaei", "Rui Fan"], "title": "Quantum Computing for EVs to Enhance Grid Resilience and Disaster Relief: Challenges and Opportunities", "comment": "11 pages, 0 figures, 2 tables, Submitted to IEEE Transactions on\n  Smart Grid", "summary": "The power grid is the foundation of modern society, however extreme weather\nevents have increasingly caused widespread outages. Enhancing grid resilience\nis therefore critical to maintaining secure and reliable operations. In\ndisaster relief and restoration, vehicle-to-grid (V2G) technology allows\nelectric vehicles (EVs) to serve as mobile energy resources by discharging to\nsupport critical loads or regulating grid frequency as needed. Effective V2G\noperation requires coordinated charging and discharging of many EVs through\noptimization. Similarly, in grid restoration, EVs must be strategically routed\nto affected areas, forming the mobile charging station placement (CSP) problem,\nwhich presents another complex optimization challenge. This work reviews\nstate-of-the-art optimization methods for V2G and mobile CSP applications,\noutlines their limitations, and explores how quantum computing (QC) could\novercome current computational bottlenecks. A QC-focused perspective is\npresented on enhancing grid resilience and accelerating restoration as extreme\nweather events grow more frequent and severe.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u8f66\u8f86\u5230\u7535\u7f51(V2G)\u548c\u79fb\u52a8\u5145\u7535\u7ad9\u5e03\u5c40(CSP)\u4f18\u5316\u65b9\u6cd5\uff0c\u63a2\u8ba8\u91cf\u5b50\u8ba1\u7b97\u5982\u4f55\u514b\u670d\u5f53\u524d\u8ba1\u7b97\u74f6\u9888\uff0c\u4ee5\u589e\u5f3a\u7535\u7f51\u97e7\u6027\u5e76\u52a0\u901f\u6781\u7aef\u5929\u6c14\u4e0b\u7684\u6062\u590d\u8fc7\u7a0b\u3002", "motivation": "\u968f\u7740\u6781\u7aef\u5929\u6c14\u4e8b\u4ef6\u65e5\u76ca\u9891\u7e41\u548c\u4e25\u91cd\uff0c\u589e\u5f3a\u7535\u7f51\u97e7\u6027\u5bf9\u7ef4\u6301\u5b89\u5168\u53ef\u9760\u8fd0\u884c\u81f3\u5173\u91cd\u8981\u3002V2G\u6280\u672f\u5141\u8bb8\u7535\u52a8\u6c7d\u8f66\u4f5c\u4e3a\u79fb\u52a8\u80fd\u6e90\u8d44\u6e90\u652f\u6301\u5173\u952e\u8d1f\u8f7d\u6216\u8c03\u8282\u7535\u7f51\u9891\u7387\uff0c\u4f46\u9700\u8981\u590d\u6742\u7684\u4f18\u5316\u534f\u8c03\u3002", "method": "\u7efc\u8ff0\u4e86V2G\u548c\u79fb\u52a8CSP\u5e94\u7528\u7684\u6700\u5148\u8fdb\u4f18\u5316\u65b9\u6cd5\uff0c\u5206\u6790\u5176\u5c40\u9650\u6027\uff0c\u5e76\u63a2\u7d22\u91cf\u5b50\u8ba1\u7b97\u5982\u4f55\u514b\u670d\u5f53\u524d\u8ba1\u7b97\u74f6\u9888\u3002", "result": "\u63d0\u51fa\u4e86\u91cf\u5b50\u8ba1\u7b97\u89c6\u89d2\u6765\u589e\u5f3a\u7535\u7f51\u97e7\u6027\u548c\u52a0\u901f\u6062\u590d\u8fc7\u7a0b\uff0c\u4e3a\u5e94\u5bf9\u65e5\u76ca\u9891\u7e41\u7684\u6781\u7aef\u5929\u6c14\u4e8b\u4ef6\u63d0\u4f9b\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u91cf\u5b50\u8ba1\u7b97\u6709\u6f5c\u529b\u514b\u670dV2G\u548c\u79fb\u52a8CSP\u4f18\u5316\u4e2d\u7684\u8ba1\u7b97\u74f6\u9888\uff0c\u4e3a\u589e\u5f3a\u7535\u7f51\u97e7\u6027\u548c\u52a0\u901f\u6781\u7aef\u5929\u6c14\u4e0b\u7684\u6062\u590d\u63d0\u4f9b\u65b0\u7684\u6280\u672f\u9014\u5f84\u3002"}}
{"id": "2511.00547", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00547", "abs": "https://arxiv.org/abs/2511.00547", "authors": ["Alain Riou"], "title": "Efficient Generation of Binary Magic Squares", "comment": null, "summary": "We propose a simple algorithm for generating Binary Magic Squares (BMS),\ni.e., square binary matrices where the sum of all rows and all columns are\nequal. We show by induction that our algorithm always returns valid BMS with\noptimal theoretical complexity. We then extend our study to non-square Binary\nMagic Squares, formalize conditions on the sum of rows and columns for these\nBMS to exist, and show that a slight variant of our first algorithm can\ngenerate provably generate them. Finally, we publicly release two\nimplementations of our algorithm as Python packages, including one that can\ngenerate several BMS in parallel using GPU acceleration.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u751f\u6210\u4e8c\u8fdb\u5236\u5e7b\u65b9\u7684\u7b80\u5355\u7b97\u6cd5\uff0c\u5305\u62ec\u65b9\u5f62\u548c\u975e\u65b9\u5f62\u7248\u672c\uff0c\u5e76\u63d0\u4f9b\u4e86Python\u5b9e\u73b0\uff0c\u652f\u6301GPU\u5e76\u884c\u52a0\u901f\u3002", "motivation": "\u7814\u7a76\u4e8c\u8fdb\u5236\u5e7b\u65b9\u7684\u751f\u6210\u95ee\u9898\uff0c\u5373\u884c\u548c\u5217\u548c\u76f8\u7b49\u7684\u4e8c\u8fdb\u5236\u77e9\u9635\uff0c\u63a2\u7d22\u5176\u5b58\u5728\u6761\u4ef6\u548c\u9ad8\u6548\u751f\u6210\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5f52\u7eb3\u6cd5\u8bc1\u660e\u7684\u7b80\u5355\u7b97\u6cd5\uff0c\u53ef\u751f\u6210\u65b9\u5f62\u4e8c\u8fdb\u5236\u5e7b\u65b9\uff0c\u5e76\u6269\u5c55\u53d8\u4f53\u7b97\u6cd5\u5904\u7406\u975e\u65b9\u5f62\u60c5\u51b5\u3002", "result": "\u7b97\u6cd5\u5177\u6709\u6700\u4f18\u7406\u8bba\u590d\u6742\u5ea6\uff0c\u80fd\u751f\u6210\u6709\u6548\u7684\u4e8c\u8fdb\u5236\u5e7b\u65b9\uff0c\u5e76\u516c\u5f00\u53d1\u5e03\u4e86Python\u5b9e\u73b0\u5305\u3002", "conclusion": "\u6210\u529f\u5f00\u53d1\u4e86\u751f\u6210\u4e8c\u8fdb\u5236\u5e7b\u65b9\u7684\u7b97\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u6b63\u786e\u6027\u548c\u6548\u7387\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8f6f\u4ef6\u5b9e\u73b0\u3002"}}
{"id": "2511.00516", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00516", "abs": "https://arxiv.org/abs/2511.00516", "authors": ["Peiyi Wang", "Paul A. M. Lefeuvre", "Shangwei Zou", "Zhenwei Ni", "Daniela Rus", "Cecilia Laschi"], "title": "Adaptive and Multi-object Grasping via Deformable Origami Modules", "comment": null, "summary": "Soft robotics gripper have shown great promise in handling fragile and\ngeometrically complex objects. However, most existing solutions rely on bulky\nactuators, complex control strategies, or advanced tactile sensing to achieve\nstable and reliable grasping performance. In this work, we present a\nmulti-finger hybrid gripper featuring passively deformable origami modules that\ngenerate constant force and torque output. Each finger composed of parallel\norigami modules is driven by a 1-DoF actuator mechanism, enabling passive shape\nadaptability and stable grasping force without active sensing or feedback\ncontrol. More importantly, we demonstrate an interesting capability in\nsimultaneous multi-object grasping, which allows stacked objects of varied\nshape and size to be picked, transported and placed independently at different\nstates, significantly improving manipulation efficiency compared to\nsingle-object grasping. These results highlight the potential of origami-based\ncompliant structures as scalable modules for adaptive, stable and efficient\nmulti-object manipulation in domestic and industrial pick-and-place scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6298\u7eb8\u7ed3\u6784\u7684\u6df7\u5408\u5939\u722a\uff0c\u5177\u6709\u88ab\u52a8\u53d8\u5f62\u80fd\u529b\uff0c\u80fd\u4ea7\u751f\u6052\u5b9a\u529b\u548c\u626d\u77e9\u8f93\u51fa\uff0c\u65e0\u9700\u4e3b\u52a8\u4f20\u611f\u6216\u53cd\u9988\u63a7\u5236\u5373\u53ef\u5b9e\u73b0\u7a33\u5b9a\u6293\u53d6\u548c\u591a\u7269\u4f53\u540c\u65f6\u6293\u53d6\u3002", "motivation": "\u73b0\u6709\u8f6f\u4f53\u673a\u5668\u4eba\u5939\u722a\u901a\u5e38\u4f9d\u8d56\u7b28\u91cd\u7684\u6267\u884c\u5668\u3001\u590d\u6742\u63a7\u5236\u7b56\u7565\u6216\u5148\u8fdb\u89e6\u89c9\u4f20\u611f\u6765\u5b9e\u73b0\u7a33\u5b9a\u53ef\u9760\u6293\u53d6\uff0c\u9700\u8981\u66f4\u7b80\u5355\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u591a\u6307\u6df7\u5408\u5939\u722a\u8bbe\u8ba1\uff0c\u6bcf\u4e2a\u624b\u6307\u7531\u5e76\u884c\u6298\u7eb8\u6a21\u5757\u7ec4\u6210\uff0c\u901a\u8fc7\u5355\u81ea\u7531\u5ea6\u6267\u884c\u673a\u6784\u9a71\u52a8\uff0c\u5b9e\u73b0\u88ab\u52a8\u5f62\u72b6\u9002\u5e94\u548c\u7a33\u5b9a\u6293\u53d6\u529b\u3002", "result": "\u5c55\u793a\u4e86\u540c\u65f6\u591a\u7269\u4f53\u6293\u53d6\u80fd\u529b\uff0c\u80fd\u591f\u6293\u53d6\u4e0d\u540c\u5f62\u72b6\u548c\u5c3a\u5bf8\u7684\u5806\u53e0\u7269\u4f53\uff0c\u5e76\u5728\u4e0d\u540c\u72b6\u6001\u4e0b\u72ec\u7acb\u653e\u7f6e\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u64cd\u4f5c\u6548\u7387\u3002", "conclusion": "\u6298\u7eb8\u57fa\u67d4\u6027\u7ed3\u6784\u4f5c\u4e3a\u53ef\u6269\u5c55\u6a21\u5757\uff0c\u5728\u5bb6\u5ead\u548c\u5de5\u4e1a\u62fe\u653e\u573a\u666f\u4e2d\u5177\u6709\u5b9e\u73b0\u81ea\u9002\u5e94\u3001\u7a33\u5b9a\u548c\u9ad8\u6548\u591a\u7269\u4f53\u64cd\u4f5c\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.00745", "categories": ["eess.SY", "cs.SY", "physics.med-ph", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2511.00745", "abs": "https://arxiv.org/abs/2511.00745", "authors": ["Xiaoyang Tian", "Hui Wang", "Boshuo Wang", "Jinshui Zhang", "Dong Yan", "Jeannette Ingabire", "Samantha Coffler", "Guillaume Duret", "Quoc-Khanh Pham", "Gang Bao", "Jacob T. Robinson", "Stefan M. Goetz", "Angel V. Peterchev"], "title": "High-Power Dual-Channel Field Chamber for High-Frequency Magnetic Neuromodulation", "comment": "25 pages, 8 figures", "summary": "Several novel methods, including magnetogenetics and magnetoelectric\nstimulation, use high frequency alternating magnetic fields to precisely\nmanipulate neural activity. To quantify the behavioral effects of such\ninterventions in a freely moving mouse, we developed a dual-channel magnetic\nchamber, specifically designed for rate-sensitive magnetothermal-genetic\nstimulation, and adaptable for other uses of alternating magnetic fields.\nThrough an optimized coil design, the system allows independent control of two\nspatially orthogonal uniform magnetic fields delivered at different frequencies\nwithin a 10 cm x 10 cm x 6 cm chamber. The two channels have nominal\nfrequencies of 50 and 550 kHz with peak magnetic field strengths of 88 and 12.5\nmT, achieved with resonant coil drives having peak voltages of 1.6 and 1.8 kV\nand currents of 1.0 and 0.26 kA, respectively. Additionally, a liquid cooling\nsystem enables magnetic field generation for second-level duration, and an\nobservation port and camera allow video capture of the animal's behavior within\nthe chamber. The system generates high-amplitude magnetic fields across two\nwidely separated frequency channels with negligible interference (< 1%).\nRelatively uniform magnetic field distribution (+/-10% across 94% of the\nchamber volume) is maintained throughout the chamber, and temperature increase\nof the inner side of the coil enclosure during the operation is limited to <\n0.35 {\\deg}C/s to ensure in vivo safety. Using cobalt-doped and undoped iron\noxide nanoparticles, we demonstrate channel-specific heating rates of 3.5\n{\\deg}C/s and 1.5 {\\deg}C/s, respectively, validating frequency-selectivity.\nBoth channels can run continuously for four seconds stably.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u53cc\u901a\u9053\u78c1\u523a\u6fc0\u5ba4\uff0c\u7528\u4e8e\u5728\u81ea\u7531\u79fb\u52a8\u5c0f\u9f20\u4e2d\u7cbe\u786e\u63a7\u5236\u795e\u7ecf\u6d3b\u52a8\uff0c\u901a\u8fc7\u4e24\u4e2a\u6b63\u4ea4\u78c1\u573a\u901a\u9053\u5b9e\u73b0\u9891\u7387\u9009\u62e9\u6027\u78c1\u70ed\u9057\u4f20\u523a\u6fc0\u3002", "motivation": "\u9700\u8981\u91cf\u5316\u9ad8\u9891\u4ea4\u53d8\u78c1\u573a\u5728\u81ea\u7531\u79fb\u52a8\u52a8\u7269\u4e2d\u7684\u884c\u4e3a\u6548\u5e94\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u4e13\u95e8\u8bbe\u5907\u6765\u7cbe\u786e\u63a7\u5236\u78c1\u573a\u53c2\u6570\u3002", "method": "\u91c7\u7528\u4f18\u5316\u7684\u7ebf\u5708\u8bbe\u8ba1\uff0c\u6784\u5efa\u53cc\u901a\u9053\u78c1\u523a\u6fc0\u7cfb\u7edf\uff0c\u5305\u542b50kHz\u548c550kHz\u4e24\u4e2a\u6b63\u4ea4\u78c1\u573a\u901a\u9053\uff0c\u914d\u5907\u6db2\u51b7\u7cfb\u7edf\u548c\u89c6\u9891\u89c2\u6d4b\u529f\u80fd\u3002", "result": "\u7cfb\u7edf\u5728\u4e24\u4e2a\u9891\u6bb5\u4ea7\u751f\u9ad8\u5f3a\u5ea6\u78c1\u573a\uff0888mT\u548c12.5mT\uff09\uff0c\u5e72\u6270\u5c0f\u4e8e1%\uff0c\u78c1\u573a\u5747\u5300\u6027\u8fbe\u00b110%\uff08\u8986\u76d694%\u5bb9\u79ef\uff09\uff0c\u6e29\u5ea6\u4e0a\u5347<0.35\u00b0C/s\uff0c\u9a8c\u8bc1\u4e86\u9891\u7387\u9009\u62e9\u6027\u52a0\u70ed\u80fd\u529b\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u78c1\u9057\u4f20\u5b66\u548c\u78c1\u7535\u523a\u6fc0\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u9760\u5e73\u53f0\uff0c\u80fd\u591f\u5b89\u5168\u6709\u6548\u5730\u5728\u81ea\u7531\u79fb\u52a8\u52a8\u7269\u4e2d\u8fdb\u884c\u795e\u7ecf\u8c03\u63a7\u5b9e\u9a8c\u3002"}}
{"id": "2511.00551", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00551", "abs": "https://arxiv.org/abs/2511.00551", "authors": ["Qiang Li", "Ningjing Zeng", "Lina Yu"], "title": "Single-agent Reinforcement Learning Model for Regional Adaptive Traffic Signal Control", "comment": null, "summary": "Several studies have employed reinforcement learning (RL) to address the\nchallenges of regional adaptive traffic signal control (ATSC) and achieved\npromising results. In this field, existing research predominantly adopts\nmulti-agent frameworks. However, the adoption of multi-agent frameworks\npresents challenges for scalability. Instead, the Traffic signal control (TSC)\nproblem necessitates a single-agent framework. TSC inherently relies on\ncentralized management by a single control center, which can monitor traffic\nconditions across all roads in the study area and coordinate the control of all\nintersections. This work proposes a single-agent RL-based regional ATSC model\ncompatible with probe vehicle technology. Key components of the RL design\ninclude state, action, and reward function definitions. To facilitate learning\nand manage congestion, both state and reward functions are defined based on\nqueue length, with action designed to regulate queue dynamics. The queue length\ndefinition used in this study differs slightly from conventional definitions\nbut is closely correlated with congestion states. More importantly, it allows\nfor reliable estimation using link travel time data from probe vehicles. With\nprobe vehicle data already covering most urban roads, this feature enhances the\nproposed method's potential for widespread deployment. The method was\ncomprehensively evaluated using the SUMO simulation platform. Experimental\nresults demonstrate that the proposed model effectively mitigates large-scale\nregional congestion levels via coordinated multi-intersection control.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5355\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u533a\u57df\u81ea\u9002\u5e94\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u6a21\u578b\uff0c\u4f7f\u7528\u961f\u5217\u957f\u5ea6\u5b9a\u4e49\u72b6\u6001\u548c\u5956\u52b1\u51fd\u6570\uff0c\u901a\u8fc7\u534f\u8c03\u591a\u8def\u53e3\u63a7\u5236\u7f13\u89e3\u5927\u89c4\u6a21\u533a\u57df\u62e5\u5835\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u4f46\u5b58\u5728\u53ef\u6269\u5c55\u6027\u6311\u6218\u3002\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u672c\u8d28\u4e0a\u9700\u8981\u5355\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7531\u5355\u4e00\u63a7\u5236\u4e2d\u5fc3\u76d1\u63a7\u6240\u6709\u9053\u8def\u5e76\u534f\u8c03\u6240\u6709\u8def\u53e3\u63a7\u5236\u3002", "method": "\u8bbe\u8ba1\u5355\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\uff0c\u72b6\u6001\u548c\u5956\u52b1\u51fd\u6570\u57fa\u4e8e\u961f\u5217\u957f\u5ea6\u5b9a\u4e49\uff0c\u52a8\u4f5c\u8bbe\u8ba1\u7528\u4e8e\u8c03\u8282\u961f\u5217\u52a8\u6001\u3002\u961f\u5217\u957f\u5ea6\u5b9a\u4e49\u4e0e\u4f20\u7edf\u7565\u6709\u4e0d\u540c\uff0c\u4f46\u80fd\u4e0e\u62e5\u5835\u72b6\u6001\u9ad8\u5ea6\u76f8\u5173\uff0c\u4e14\u53ef\u901a\u8fc7\u63a2\u6d4b\u8f66\u8f86\u6570\u636e\u53ef\u9760\u4f30\u8ba1\u3002", "result": "\u4f7f\u7528SUMO\u4eff\u771f\u5e73\u53f0\u5168\u9762\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u6a21\u578b\u901a\u8fc7\u534f\u8c03\u591a\u8def\u53e3\u63a7\u5236\u6709\u6548\u7f13\u89e3\u4e86\u5927\u89c4\u6a21\u533a\u57df\u62e5\u5835\u6c34\u5e73\u3002", "conclusion": "\u63d0\u51fa\u7684\u5355\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4e0e\u63a2\u6d4b\u8f66\u8f86\u6280\u672f\u517c\u5bb9\uff0c\u5177\u6709\u5e7f\u6cdb\u90e8\u7f72\u6f5c\u529b\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u533a\u57df\u81ea\u9002\u5e94\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u95ee\u9898\u3002"}}
{"id": "2511.00555", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00555", "abs": "https://arxiv.org/abs/2511.00555", "authors": ["Dianye Huang", "Nassir Navab", "Zhongliang Jiang"], "title": "Improving Robustness to Out-of-Distribution States in Imitation Learning via Deep Koopman-Boosted Diffusion Policy", "comment": "Accepted by IEEE T-RO", "summary": "Integrating generative models with action chunking has shown significant\npromise in imitation learning for robotic manipulation. However, the existing\ndiffusion-based paradigm often struggles to capture strong temporal\ndependencies across multiple steps, particularly when incorporating\nproprioceptive input. This limitation can lead to task failures, where the\npolicy overfits to proprioceptive cues at the expense of capturing the visually\nderived features of the task. To overcome this challenge, we propose the Deep\nKoopman-boosted Dual-branch Diffusion Policy (D3P) algorithm. D3P introduces a\ndual-branch architecture to decouple the roles of different sensory modality\ncombinations. The visual branch encodes the visual observations to indicate\ntask progression, while the fused branch integrates both visual and\nproprioceptive inputs for precise manipulation. Within this architecture, when\nthe robot fails to accomplish intermediate goals, such as grasping a drawer\nhandle, the policy can dynamically switch to execute action chunks generated by\nthe visual branch, allowing recovery to previously observed states and\nfacilitating retrial of the task. To further enhance visual representation\nlearning, we incorporate a Deep Koopman Operator module that captures\nstructured temporal dynamics from visual inputs. During inference, we use the\ntest-time loss of the generative model as a confidence signal to guide the\naggregation of the temporally overlapping predicted action chunks, thereby\nenhancing the reliability of policy execution. In simulation experiments across\nsix RLBench tabletop tasks, D3P outperforms the state-of-the-art diffusion\npolicy by an average of 14.6\\%. On three real-world robotic manipulation tasks,\nit achieves a 15.0\\% improvement. Code: https://github.com/dianyeHuang/D3P.", "AI": {"tldr": "\u63d0\u51faD3P\u7b97\u6cd5\uff0c\u901a\u8fc7\u53cc\u5206\u652f\u67b6\u6784\u89e3\u8026\u89c6\u89c9\u548c\u672c\u4f53\u611f\u77e5\u8f93\u5165\uff0c\u7ed3\u5408\u6df1\u5ea6Koopman\u7b97\u5b50\u589e\u5f3a\u89c6\u89c9\u8868\u5f81\u5b66\u4e60\uff0c\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6269\u6563\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u7684\u7b56\u7565\u5728\u6355\u6349\u591a\u6b65\u9aa4\u95f4\u5f3a\u65f6\u5e8f\u4f9d\u8d56\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u7279\u522b\u662f\u5f53\u52a0\u5165\u672c\u4f53\u611f\u77e5\u8f93\u5165\u65f6\uff0c\u5bb9\u6613\u8fc7\u62df\u5408\u672c\u4f53\u611f\u77e5\u7ebf\u7d22\u800c\u5ffd\u7565\u89c6\u89c9\u7279\u5f81\uff0c\u5bfc\u81f4\u4efb\u52a1\u5931\u8d25\u3002", "method": "\u91c7\u7528\u53cc\u5206\u652f\u67b6\u6784\uff1a\u89c6\u89c9\u5206\u652f\u7f16\u7801\u89c6\u89c9\u89c2\u5bdf\u6307\u793a\u4efb\u52a1\u8fdb\u5c55\uff0c\u878d\u5408\u5206\u652f\u6574\u5408\u89c6\u89c9\u548c\u672c\u4f53\u611f\u77e5\u8f93\u5165\u8fdb\u884c\u7cbe\u786e\u64cd\u4f5c\u3002\u52a0\u5165\u6df1\u5ea6Koopman\u7b97\u5b50\u6a21\u5757\u6355\u6349\u89c6\u89c9\u8f93\u5165\u7684\u65f6\u5e8f\u52a8\u6001\uff0c\u5e76\u4f7f\u7528\u751f\u6210\u6a21\u578b\u7684\u6d4b\u8bd5\u65f6\u635f\u5931\u4f5c\u4e3a\u7f6e\u4fe1\u5ea6\u4fe1\u53f7\u6307\u5bfc\u52a8\u4f5c\u5757\u805a\u5408\u3002", "result": "\u57286\u4e2aRLBench\u684c\u9762\u4efb\u52a1\u6a21\u62df\u5b9e\u9a8c\u4e2d\u5e73\u5747\u6027\u80fd\u63d0\u534714.6%\uff0c\u57283\u4e2a\u771f\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u63d0\u534715.0%\u3002", "conclusion": "D3P\u7b97\u6cd5\u901a\u8fc7\u89e3\u8026\u4e0d\u540c\u611f\u5b98\u6a21\u6001\u548c\u589e\u5f3a\u89c6\u89c9\u8868\u5f81\u5b66\u4e60\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u6269\u6563\u7b56\u7565\u5728\u65f6\u5e8f\u4f9d\u8d56\u548c\u6a21\u6001\u878d\u5408\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u673a\u5668\u4eba\u6a21\u4eff\u5b66\u4e60\u7684\u6027\u80fd\u3002"}}
{"id": "2511.00765", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.00765", "abs": "https://arxiv.org/abs/2511.00765", "authors": ["Shi Gengtian", "Jiang Liu", "Shigeru Shimamoto"], "title": "Deep Q-Network for Optimizing NOMA-Aided Resource Allocation in Smart Factories with URLLC Constraints", "comment": "Accepted for presentation at the IEEE Wireless Communications and\n  Networking Conference (WCNC) 2025. This is the preprint version of the paper", "summary": "This paper presents a Deep Q-Network (DQN)- based algorithm for NOMA-aided\nresource allocation in smart factories, addressing the stringent requirements\nof Ultra-Reliable Low-Latency Communication (URLLC). The proposed algorithm\ndynamically allocates sub-channels and optimizes power levels to maximize\nthroughput while meeting strict latency constraints. By incorporating a tunable\nparameter {\\lambda}, the algorithm balances the trade-off between throughput\nand latency, making it suitable for various devices, including robots, sensors,\nand controllers, each with distinct communication needs. Simulation results\nshow that robots achieve higher throughput, while sensors and controllers meet\nthe low-latency requirements of URLLC, ensuring reliable communication for\nreal-time industrial applications.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6Q\u7f51\u7edc\uff08DQN\uff09\u7684NOMA\u8f85\u52a9\u8d44\u6e90\u5206\u914d\u7b97\u6cd5\uff0c\u7528\u4e8e\u667a\u80fd\u5de5\u5382\u4e2d\u6ee1\u8db3URLLC\u4e25\u683c\u8981\u6c42\u7684\u52a8\u6001\u5b50\u4fe1\u9053\u548c\u529f\u7387\u5206\u914d\u3002", "motivation": "\u667a\u80fd\u5de5\u5382\u4e2d\u673a\u5668\u4eba\u3001\u4f20\u611f\u5668\u548c\u63a7\u5236\u5668\u7b49\u8bbe\u5907\u5bf9\u901a\u4fe1\u6709\u4e0d\u540c\u9700\u6c42\uff0c\u9700\u8981\u6ee1\u8db3URLLC\u7684\u8d85\u53ef\u9760\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u8981\u6c42\uff0c\u540c\u65f6\u6700\u5927\u5316\u541e\u5410\u91cf\u3002", "method": "\u91c7\u7528\u6df1\u5ea6Q\u7f51\u7edc\u7b97\u6cd5\uff0c\u901a\u8fc7\u53ef\u8c03\u53c2\u6570\u03bb\u5e73\u8861\u541e\u5410\u91cf\u4e0e\u5ef6\u8fdf\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u52a8\u6001\u5206\u914d\u5b50\u4fe1\u9053\u548c\u4f18\u5316\u529f\u7387\u6c34\u5e73\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\u673a\u5668\u4eba\u83b7\u5f97\u66f4\u9ad8\u541e\u5410\u91cf\uff0c\u4f20\u611f\u5668\u548c\u63a7\u5236\u5668\u6ee1\u8db3URLLC\u7684\u4f4e\u5ef6\u8fdf\u8981\u6c42\uff0c\u786e\u4fdd\u5b9e\u65f6\u5de5\u4e1a\u5e94\u7528\u7684\u53ef\u9760\u901a\u4fe1\u3002", "conclusion": "\u6240\u63d0DQN\u7b97\u6cd5\u80fd\u6709\u6548\u6ee1\u8db3\u667a\u80fd\u5de5\u5382\u4e2d\u4e0d\u540c\u8bbe\u5907\u7684\u591a\u6837\u5316\u901a\u4fe1\u9700\u6c42\uff0c\u5728\u541e\u5410\u91cf\u548c\u5ef6\u8fdf\u4e4b\u95f4\u5b9e\u73b0\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2511.00609", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00609", "abs": "https://arxiv.org/abs/2511.00609", "authors": ["Shengqi Xu", "Xinpeng Zhou", "Yabo Zhang", "Ming Liu", "Tao Liang", "Tianyu Zhang", "Yalong Bai", "Zuxuan Wu", "Wangmeng Zuo"], "title": "PreferThinker: Reasoning-based Personalized Image Preference Assessment", "comment": null, "summary": "Personalized image preference assessment aims to evaluate an individual\nuser's image preferences by relying only on a small set of reference images as\nprior information. Existing methods mainly focus on general preference\nassessment, training models with large-scale data to tackle well-defined tasks\nsuch as text-image alignment. However, these approaches struggle to handle\npersonalized preference because user-specific data are scarce and not easily\nscalable, and individual tastes are often diverse and complex. To overcome\nthese challenges, we introduce a common preference profile that serves as a\nbridge across users, allowing large-scale user data to be leveraged for\ntraining profile prediction and capturing complex personalized preferences.\nBuilding on this idea, we propose a reasoning-based personalized image\npreference assessment framework that follows a \\textit{predict-then-assess}\nparadigm: it first predicts a user's preference profile from reference images,\nand then provides interpretable, multi-dimensional scores and assessments of\ncandidate images based on the predicted profile. To support this, we first\nconstruct a large-scale Chain-of-Thought (CoT)-style personalized assessment\ndataset annotated with diverse user preference profiles and high-quality\nCoT-style reasoning, enabling explicit supervision of structured reasoning.\nNext, we adopt a two-stage training strategy: a cold-start supervised\nfine-tuning phase to empower the model with structured reasoning capabilities,\nfollowed by reinforcement learning to incentivize the model to explore more\nreasonable assessment paths and enhance generalization. Furthermore, we propose\na similarity-aware prediction reward to encourage better prediction of the\nuser's preference profile, which facilitates more reasonable assessments\nexploration. Extensive experiments demonstrate the superiority of the proposed\nmethod.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u63a8\u7406\u7684\u4e2a\u6027\u5316\u56fe\u50cf\u504f\u597d\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u6d4b\u7528\u6237\u504f\u597d\u6863\u6848\u5e76\u8fdb\u884c\u591a\u7ef4\u5ea6\u8bc4\u4f30\uff0c\u89e3\u51b3\u4e2a\u6027\u5316\u504f\u597d\u8bc4\u4f30\u4e2d\u6570\u636e\u7a00\u7f3a\u548c\u7528\u6237\u591a\u6837\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u901a\u7528\u504f\u597d\u8bc4\u4f30\uff0c\u96be\u4ee5\u5904\u7406\u4e2a\u6027\u5316\u504f\u597d\uff0c\u56e0\u4e3a\u7528\u6237\u7279\u5b9a\u6570\u636e\u7a00\u7f3a\u4e14\u7528\u6237\u54c1\u5473\u591a\u6837\u590d\u6742\u3002", "method": "\u91c7\u7528\u9884\u6d4b-\u8bc4\u4f30\u8303\u5f0f\uff1a\u9996\u5148\u4ece\u53c2\u8003\u56fe\u50cf\u9884\u6d4b\u7528\u6237\u504f\u597d\u6863\u6848\uff0c\u7136\u540e\u57fa\u4e8e\u9884\u6d4b\u6863\u6848\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u591a\u7ef4\u5ea6\u8bc4\u5206\u3002\u4f7f\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff1a\u76d1\u7763\u5fae\u8c03+\u5f3a\u5316\u5b66\u4e60\uff0c\u5e76\u63d0\u51fa\u76f8\u4f3c\u6027\u611f\u77e5\u9884\u6d4b\u5956\u52b1\u3002", "result": "\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u901a\u8fc7\u6784\u5efa\u5927\u89c4\u6a21CoT\u98ce\u683c\u6570\u636e\u96c6\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u4e2a\u6027\u5316\u56fe\u50cf\u504f\u597d\u8bc4\u4f30\u3002"}}
{"id": "2511.00635", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00635", "abs": "https://arxiv.org/abs/2511.00635", "authors": ["Hyungtae Lim", "Daebeom Kim", "Hyun Myung"], "title": "Multi-Mapcher: Loop Closure Detection-Free Heterogeneous LiDAR Multi-Session SLAM Leveraging Outlier-Robust Registration for Autonomous Vehicles", "comment": "13 pages, 12 figures", "summary": "As various 3D light detection and ranging (LiDAR) sensors have been\nintroduced to the market, research on multi-session simultaneous localization\nand mapping (MSS) using heterogeneous LiDAR sensors has been actively\nconducted. Existing MSS methods mostly rely on loop closure detection for\ninter-session alignment; however, the performance of loop closure detection can\nbe potentially degraded owing to the differences in the density and field of\nview (FoV) of the sensors used in different sessions. In this study, we\nchallenge the existing paradigm that relies heavily on loop detection modules\nand propose a novel MSS framework, called Multi-Mapcher, that employs\nlarge-scale map-to-map registration to perform inter-session initial alignment,\nwhich is commonly assumed to be infeasible, by leveraging outlier-robust 3D\npoint cloud registration. Next, after finding inter-session loops by radius\nsearch based on the assumption that the inter-session initial alignment is\nsufficiently precise, anchor node-based robust pose graph optimization is\nemployed to build a consistent global map. As demonstrated in our experiments,\nour approach shows substantially better MSS performance for various LiDAR\nsensors used to capture the sessions and is faster than state-of-the-art\napproaches. Our code is available at\nhttps://github.com/url-kaist/multi-mapcher.", "AI": {"tldr": "\u63d0\u51faMulti-Mapcher\u6846\u67b6\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u5730\u56fe\u5230\u5730\u56fe\u914d\u51c6\u5b9e\u73b0\u591a\u4f1a\u8bddSLAM\u7684\u521d\u59cb\u5bf9\u9f50\uff0c\u907f\u514d\u5bf9\u56de\u73af\u68c0\u6d4b\u7684\u8fc7\u5ea6\u4f9d\u8d56\uff0c\u63d0\u9ad8\u4e86\u5f02\u6784LiDAR\u4f20\u611f\u5668\u7684\u591a\u4f1a\u8bdd\u5efa\u56fe\u6027\u80fd\u3002", "motivation": "\u73b0\u6709MSS\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u56de\u73af\u68c0\u6d4b\u8fdb\u884c\u4f1a\u8bdd\u95f4\u5bf9\u9f50\uff0c\u4f46\u7531\u4e8e\u4e0d\u540c\u4f1a\u8bdd\u4f7f\u7528\u7684LiDAR\u4f20\u611f\u5668\u5728\u70b9\u4e91\u5bc6\u5ea6\u548c\u89c6\u573a\u89d2\u4e0a\u7684\u5dee\u5f02\uff0c\u56de\u73af\u68c0\u6d4b\u6027\u80fd\u53ef\u80fd\u4e0b\u964d\u3002", "method": "\u4f7f\u7528\u5927\u89c4\u6a21\u5730\u56fe\u5230\u5730\u56fe\u914d\u51c6\u8fdb\u884c\u4f1a\u8bdd\u95f4\u521d\u59cb\u5bf9\u9f50\uff0c\u7136\u540e\u57fa\u4e8e\u534a\u5f84\u641c\u7d22\u627e\u5230\u56de\u73af\uff0c\u6700\u540e\u91c7\u7528\u951a\u8282\u70b9\u4f18\u5316\u7684\u4f4d\u59ff\u56fe\u4f18\u5316\u6784\u5efa\u5168\u5c40\u4e00\u81f4\u5730\u56fe\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5404\u79cdLiDAR\u4f20\u611f\u5668\u4e0a\u7684MSS\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u8fd0\u884c\u901f\u5ea6\u66f4\u5feb\u3002", "conclusion": "Multi-Mapcher\u6846\u67b6\u901a\u8fc7\u5730\u56fe\u5230\u5730\u56fe\u914d\u51c6\u6210\u529f\u5b9e\u73b0\u4e86\u88ab\u8ba4\u4e3a\u4e0d\u53ef\u884c\u7684\u4f1a\u8bdd\u95f4\u521d\u59cb\u5bf9\u9f50\uff0c\u4e3a\u5f02\u6784LiDAR\u4f20\u611f\u5668\u7684\u591a\u4f1a\u8bddSLAM\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00844", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.00844", "abs": "https://arxiv.org/abs/2511.00844", "authors": ["Shuang Qi", "Bin Lin", "Yiqin Deng", "Xianhao Chen", "Yuguang Fang"], "title": "Minimizing Maximum Latency of Task Offloading for Multi-UAV-assisted Maritime Search and Rescue", "comment": null, "summary": "Unmanned Aerial Vehicles (UAVs) play a crucial role in Maritime Search and\nRescue (MSAR), contributing to the improvement of rescue efficiency and\nreduction of casualties. Typically, UAVs equipped with cameras collect data\nfrom disaster areas and transmit it to the shore-based rescue command centers.\nBy deploying Mobile Edge Computing (MEC) servers, UAVs can pre-process video\nfootage to reduce data transmission volume, thus reducing transmission delays.\nHowever, the limited computational capacity and energy of UAVs pose significant\nchallenges to the efficiency of UAV-assisted MSAR systems. To address these\nproblems, in this paper, we investigate a multi-UAV assisted MSAR system\nconsisting of multiple Surveillance UAVs (S-UAVs) and a Relay UAV (R-UAV).\nThen, we formulate a joint optimization problem to minimize the maximum total\nlatency among all S-UAVs via jointly making the computing offloading decisions,\nR-UAV deployment, and the association between a S-UAV and rescue targets while\nensuring that all targets are monitored by S-UAVs. Since the formulated\noptimization problem is typically hard to solve due to its non-convexity, we\npropose an effective iterative algorithm by breaking it into three\nsub-problems. Numerical simulation results show the effectiveness of the\nproposed algorithm with various performance parameters.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u65e0\u4eba\u673a\u8f85\u52a9\u6d77\u4e0a\u641c\u6551\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u8ba1\u7b97\u5378\u8f7d\u51b3\u7b56\u3001\u4e2d\u7ee7\u65e0\u4eba\u673a\u90e8\u7f72\u548c\u76d1\u63a7\u65e0\u4eba\u673a\u4e0e\u6551\u63f4\u76ee\u6807\u7684\u5173\u8054\uff0c\u6700\u5c0f\u5316\u6240\u6709\u76d1\u63a7\u65e0\u4eba\u673a\u7684\u6700\u5927\u603b\u5ef6\u8fdf\u3002", "motivation": "\u65e0\u4eba\u673a\u5728\u6d77\u4e0a\u641c\u6551\u4e2d\u53d1\u6325\u91cd\u8981\u4f5c\u7528\uff0c\u4f46\u5176\u6709\u9650\u7684\u8ba1\u7b97\u80fd\u529b\u548c\u80fd\u91cf\u9650\u5236\u4e86\u7cfb\u7edf\u6548\u7387\u3002\u9700\u8981\u89e3\u51b3\u8ba1\u7b97\u5378\u8f7d\u3001\u65e0\u4eba\u673a\u90e8\u7f72\u548c\u76ee\u6807\u5173\u8054\u7684\u8054\u5408\u4f18\u5316\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u5305\u542b\u591a\u4e2a\u76d1\u63a7\u65e0\u4eba\u673a\u548c\u4e00\u4e2a\u4e2d\u7ee7\u65e0\u4eba\u673a\u7684\u7cfb\u7edf\uff0c\u5c06\u975e\u51f8\u4f18\u5316\u95ee\u9898\u5206\u89e3\u4e3a\u4e09\u4e2a\u5b50\u95ee\u9898\uff0c\u63d0\u51fa\u6709\u6548\u7684\u8fed\u4ee3\u7b97\u6cd5\u6c42\u89e3\u3002", "result": "\u6570\u503c\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u7b97\u6cd5\u5728\u5404\u79cd\u6027\u80fd\u53c2\u6570\u4e0b\u5747\u8868\u73b0\u51fa\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u591a\u65e0\u4eba\u673a\u7cfb\u7edf\u901a\u8fc7\u8054\u5408\u4f18\u5316\u7b56\u7565\u80fd\u591f\u6709\u6548\u964d\u4f4e\u6d77\u4e0a\u641c\u6551\u4efb\u52a1\u4e2d\u7684\u5ef6\u8fdf\uff0c\u63d0\u9ad8\u6551\u63f4\u6548\u7387\u3002"}}
{"id": "2511.00640", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00640", "abs": "https://arxiv.org/abs/2511.00640", "authors": ["Zicheng Xu", "Guanchu Wang", "Yu-Neng Chuang", "Guangyao Zheng", "Alexander S. Szalay", "Zirui Liu", "Vladimir Braverman"], "title": "DTS: Enhancing Large Reasoning Models via Decoding Tree Sketching", "comment": null, "summary": "Large Reasoning Models (LRMs) demonstrate strong performance on complex\nreasoning tasks, yet they often suffer from overthinking, producing excessively\nlong chain-of-thought (CoT) traces that increase inference cost and may degrade\naccuracy. Our analysis reveals a clear anti-correlation between reasoning\nlength and accuracy, where across multiple stochastic decodes, the short\nreasoning paths consistently achieve the highest correctness, while longer ones\naccumulate errors and repetitions. These short optimal reasoning paths can be\nfound ideally through full enumeration of the reasoning space. However, the\ntree-structured reasoning space grows exponentially with sequence length,\nrendering exhaustive exploration infeasible. To address this, we propose DTS, a\nmodel-agnostic decoding framework that sketches the reasoning space by\nselectively branching at high-entropy tokens and applies early stopping to\nselect the shortest completed reasoning path. This approach approximates the\noptimal solution that enhances both efficiency and accuracy, without requiring\nadditional training or supervision. Experiments on AIME2024 and AIME2025\ndatasets with DeepSeek-R1-Distill-Qwen-7B and 1.5B show that DTS improves\naccuracy by up to 8%, reduces average reasoning length by 23%, and decreases\nrepetition frequency by 12%, demonstrating DTS's ability for scalable and\nefficient LRM reasoning.", "AI": {"tldr": "DTS\u662f\u4e00\u4e2a\u6a21\u578b\u65e0\u5173\u7684\u89e3\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u9ad8\u71b5token\u5904\u9009\u62e9\u6027\u5206\u652f\u5e76\u5e94\u7528\u65e9\u505c\u673a\u5236\u6765\u9009\u62e9\u6700\u77ed\u7684\u5b8c\u6574\u63a8\u7406\u8def\u5f84\uff0c\u4ece\u800c\u89e3\u51b3\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u63d0\u9ad8\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7ecf\u5e38\u5b58\u5728\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u4ea7\u751f\u8fc7\u957f\u7684\u601d\u7ef4\u94fe\u8f68\u8ff9\uff0c\u8fd9\u4f1a\u589e\u52a0\u63a8\u7406\u6210\u672c\u5e76\u53ef\u80fd\u964d\u4f4e\u51c6\u786e\u6027\u3002\u7814\u7a76\u53d1\u73b0\u63a8\u7406\u957f\u5ea6\u4e0e\u51c6\u786e\u6027\u4e4b\u95f4\u5b58\u5728\u660e\u663e\u7684\u8d1f\u76f8\u5173\u5173\u7cfb\u3002", "method": "\u63d0\u51faDTS\u89e3\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u9ad8\u71b5token\u5904\u9009\u62e9\u6027\u5206\u652f\u6765\u7ed8\u5236\u63a8\u7406\u7a7a\u95f4\u8349\u56fe\uff0c\u5e76\u5e94\u7528\u65e9\u505c\u673a\u5236\u6765\u9009\u62e9\u6700\u77ed\u7684\u5b8c\u6574\u63a8\u7406\u8def\u5f84\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u76d1\u7763\u3002", "result": "\u5728AIME2024\u548cAIME2025\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDTS\u5c06\u51c6\u786e\u6027\u63d0\u9ad8\u4e868%\uff0c\u5e73\u5747\u63a8\u7406\u957f\u5ea6\u51cf\u5c11\u4e8623%\uff0c\u91cd\u590d\u9891\u7387\u964d\u4f4e\u4e8612%\u3002", "conclusion": "DTS\u80fd\u591f\u5b9e\u73b0\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u5927\u578b\u63a8\u7406\u6a21\u578b\u63a8\u7406\uff0c\u8fd1\u4f3c\u6700\u4f18\u89e3\uff0c\u540c\u65f6\u63d0\u9ad8\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2511.00783", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.00783", "abs": "https://arxiv.org/abs/2511.00783", "authors": ["Jingzehua Xu", "Weihang Zhang", "Yangyang Li", "Hongmiaoyi Zhang", "Guanwen Xie", "Jiwei Tang", "Shuai Zhang", "Yi Li"], "title": "When Semantics Connect the Swarm: LLM-Driven Fuzzy Control for Cooperative Multi-Robot Underwater Coverage", "comment": "This paper has been submitted to IEEE Transactions on Mobile\n  Computing", "summary": "Underwater multi-robot cooperative coverage remains challenging due to\npartial observability, limited communication, environmental uncertainty, and\nthe lack of access to global localization. To address these issues, this paper\npresents a semantics-guided fuzzy control framework that couples Large Language\nModels (LLMs) with interpretable control and lightweight coordination. Raw\nmultimodal observations are compressed by the LLM into compact,\nhuman-interpretable semantic tokens that summarize obstacles, unexplored\nregions, and Objects Of Interest (OOIs) under uncertain perception. A fuzzy\ninference system with pre-defined membership functions then maps these tokens\ninto smooth and stable steering and gait commands, enabling reliable navigation\nwithout relying on global positioning. Then, we further coordinate multiple\nrobots by introducing semantic communication that shares intent and local\ncontext in linguistic form, enabling agreement on who explores where while\navoiding redundant revisits. Extensive simulations in unknown reef-like\nenvironments show that, under limited sensing and communication, the proposed\nframework achieves robust OOI-oriented navigation and cooperative coverage with\nimproved efficiency and adaptability, narrowing the gap between semantic\ncognition and distributed underwater control in GPS-denied, map-free\nconditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8bed\u4e49\u5f15\u5bfc\u7684\u6a21\u7cca\u63a7\u5236\u6846\u67b6\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u53ef\u89e3\u91ca\u63a7\u5236\u548c\u8f7b\u91cf\u7ea7\u534f\u8c03\u76f8\u7ed3\u5408\uff0c\u89e3\u51b3\u6c34\u4e0b\u591a\u673a\u5668\u4eba\u534f\u540c\u8986\u76d6\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u6c34\u4e0b\u591a\u673a\u5668\u4eba\u534f\u540c\u8986\u76d6\u9762\u4e34\u7684\u6311\u6218\uff1a\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u3001\u6709\u9650\u901a\u4fe1\u3001\u73af\u5883\u4e0d\u786e\u5b9a\u6027\u4ee5\u53ca\u7f3a\u4e4f\u5168\u5c40\u5b9a\u4f4d\u80fd\u529b\u3002", "method": "\u4f7f\u7528LLM\u5c06\u539f\u59cb\u591a\u6a21\u6001\u89c2\u6d4b\u538b\u7f29\u4e3a\u7d27\u51d1\u3001\u53ef\u89e3\u91ca\u7684\u8bed\u4e49\u6807\u8bb0\uff1b\u901a\u8fc7\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u6620\u5c04\u4e3a\u5e73\u6ed1\u7a33\u5b9a\u7684\u8f6c\u5411\u548c\u6b65\u6001\u547d\u4ee4\uff1b\u5f15\u5165\u8bed\u4e49\u901a\u4fe1\u5b9e\u73b0\u591a\u673a\u5668\u4eba\u534f\u8c03\u3002", "result": "\u5728\u672a\u77e5\u73ca\u745a\u7901\u73af\u5883\u4e2d\u8fdb\u884c\u5e7f\u6cdb\u4eff\u771f\uff0c\u5728\u6709\u9650\u611f\u77e5\u548c\u901a\u4fe1\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u7a33\u5065\u7684OOI\u5bfc\u5411\u5bfc\u822a\u548c\u534f\u540c\u8986\u76d6\uff0c\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u9002\u5e94\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728GPS\u62d2\u6b62\u3001\u65e0\u5730\u56fe\u6761\u4ef6\u4e0b\u7f29\u5c0f\u4e86\u8bed\u4e49\u8ba4\u77e5\u4e0e\u5206\u5e03\u5f0f\u6c34\u4e0b\u63a7\u5236\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2511.00941", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.00941", "abs": "https://arxiv.org/abs/2511.00941", "authors": ["Dipanjan Ghose", "S Sivaranjani", "Junjie Qin"], "title": "Traffic-Aware Grid Planning for Dynamic Wireless Electric Vehicle Charging", "comment": null, "summary": "Dynamic Wireless Electric Vehicle Charging (DWC) on electrified roadways is\nan emerging technology that can significantly reduce battery sizes, eliminate\ncharging downtime, and alleviate range anxiety, specially for long-haul\ntransportation and fleet operations of electric vehicles (EVs). However, these\nsystems introduce new challenges for power system planning due to their\nshort-duration and high-power demands which can strain the grid if not properly\nmanaged. As the energy demands from DWC depend on vehicle speed, density, dwell\ntime in charging zones, and load profiles along road segments, there is a need\nfor integrated planning of such systems, jointly considering both traffic\nbehavior and EV energy consumption. In this paper, we propose a traffic-aware\ngrid planning framework for DWC. We leverage a macroscopic Cell Transmission\nModel of traffic flow to estimate real-time, spatiotemporal EV charging demand\nfrom DWC corridors. The demand model is then integrated into an AC Optimal\nPower Flow based formulation to optimally size a microgrid that supports DWC\nunder varying traffic conditions while minimizing the cost of operation. Our\nframework explicitly models how spatiotemporal traffic patterns affect the\nutilization of grid resources to obtain system designs that achieve lower costs\nand are easier to operationalize as compared to planning models that rely on\nworst-case traffic data.\n  We demonstrate the framework on data from a 14-mile segment of the I-210W\nhighway in California, USA, evaluating multiple traffic scenarios like\nfree-flow, severe congestion, accidents of varying severity, and natural\ndisasters like forest fires. Our results demonstrate that traffic-aware grid\nplanning significantly reduces infrastructure costs as compared to\nworst-scenario based modeling, while ensuring reliability of service in terms\nof meeting charging demands under diverse traffic conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8003\u8651\u4ea4\u901a\u6d41\u91cf\u7684\u52a8\u6001\u65e0\u7ebf\u5145\u7535\u7535\u7f51\u89c4\u5212\u6846\u67b6\uff0c\u901a\u8fc7\u5b8f\u89c2\u4ea4\u901a\u6d41\u6a21\u578b\u4f30\u8ba1\u5145\u7535\u9700\u6c42\uff0c\u7ed3\u5408\u6700\u4f18\u6f6e\u6d41\u4f18\u5316\u5fae\u7535\u7f51\u89c4\u6a21\uff0c\u76f8\u6bd4\u6700\u574f\u60c5\u51b5\u89c4\u5212\u663e\u8457\u964d\u4f4e\u57fa\u7840\u8bbe\u65bd\u6210\u672c\u3002", "motivation": "\u52a8\u6001\u65e0\u7ebf\u5145\u7535\u6280\u672f\u867d\u7136\u80fd\u51cf\u5c11\u7535\u6c60\u5c3a\u5bf8\u548c\u5145\u7535\u505c\u673a\u65f6\u95f4\uff0c\u4f46\u5176\u77ed\u65f6\u9ad8\u529f\u7387\u9700\u6c42\u4f1a\u7ed9\u7535\u7f51\u5e26\u6765\u538b\u529b\uff0c\u9700\u8981\u7efc\u5408\u8003\u8651\u4ea4\u901a\u884c\u4e3a\u548c\u7535\u52a8\u6c7d\u8f66\u80fd\u8017\u7684\u96c6\u6210\u89c4\u5212\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u5b8f\u89c2\u7ec6\u80de\u4f20\u8f93\u6a21\u578b\u4f30\u8ba1\u65f6\u7a7a\u5145\u7535\u9700\u6c42\uff0c\u7ed3\u5408\u4ea4\u6d41\u6700\u4f18\u6f6e\u6d41\u4f18\u5316\u5fae\u7535\u7f51\u89c4\u6a21\uff0c\u8003\u8651\u4e0d\u540c\u4ea4\u901a\u6761\u4ef6\u3002", "result": "\u5728\u52a0\u5ddeI-210W\u9ad8\u901f\u516c\u8def\u4e0a\u9a8c\u8bc1\uff0c\u4ea4\u901a\u611f\u77e5\u89c4\u5212\u76f8\u6bd4\u6700\u574f\u60c5\u51b5\u5efa\u6a21\u663e\u8457\u964d\u4f4e\u57fa\u7840\u8bbe\u65bd\u6210\u672c\uff0c\u540c\u65f6\u786e\u4fdd\u5404\u79cd\u4ea4\u901a\u6761\u4ef6\u4e0b\u7684\u5145\u7535\u53ef\u9760\u6027\u3002", "conclusion": "\u4ea4\u901a\u611f\u77e5\u7684\u7535\u7f51\u89c4\u5212\u6846\u67b6\u80fd\u591f\u83b7\u5f97\u66f4\u4f4e\u6210\u672c\u548c\u66f4\u6613\u64cd\u4f5c\u7684\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u4f18\u4e8e\u4f9d\u8d56\u6700\u574f\u60c5\u51b5\u4ea4\u901a\u6570\u636e\u7684\u89c4\u5212\u6a21\u578b\u3002"}}
{"id": "2511.00651", "categories": ["cs.AI", "cs.CL", "cs.IT", "cs.MA", "cs.NI", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.00651", "abs": "https://arxiv.org/abs/2511.00651", "authors": ["Chenhua Shi", "Bhavika Jalli", "Gregor Macdonald", "John Zou", "Wanlu Lei", "Mridul Jain", "Joji Philip"], "title": "Leveraging Multi-Agent System (MAS) and Fine-Tuned Small Language Models (SLMs) for Automated Telecom Network Troubleshooting", "comment": "6 pages, 7 figures, 1 table", "summary": "Telecom networks are rapidly growing in scale and complexity, making\neffective management, operation, and optimization increasingly challenging.\nAlthough Artificial Intelligence (AI) has been applied to many telecom tasks,\nexisting models are often narrow in scope, require large amounts of labeled\ndata, and struggle to generalize across heterogeneous deployments.\nConsequently, network troubleshooting continues to rely heavily on Subject\nMatter Experts (SMEs) to manually correlate various data sources to identify\nroot causes and corrective actions. To address these limitations, we propose a\nMulti-Agent System (MAS) that employs an agentic workflow, with Large Language\nModels (LLMs) coordinating multiple specialized tools for fully automated\nnetwork troubleshooting. Once faults are detected by AI/ML-based monitors, the\nframework dynamically activates agents such as an orchestrator, solution\nplanner, executor, data retriever, and root-cause analyzer to diagnose issues\nand recommend remediation strategies within a short time frame. A key component\nof this system is the solution planner, which generates appropriate remediation\nplans based on internal documentation. To enable this, we fine-tuned a Small\nLanguage Model (SLM) on proprietary troubleshooting documents to produce\ndomain-grounded solution plans. Experimental results demonstrate that the\nproposed framework significantly accelerates troubleshooting automation across\nboth Radio Access Network (RAN) and Core network domains.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u7f51\u7edc\u6545\u969c\u6392\u9664\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u8c03\u591a\u4e2a\u4e13\u4e1a\u5de5\u5177\u6765\u52a0\u901f\u7535\u4fe1\u7f51\u7edc\u6545\u969c\u8bca\u65ad\u548c\u4fee\u590d\u3002", "motivation": "\u7535\u4fe1\u7f51\u7edc\u89c4\u6a21\u6269\u5927\u548c\u590d\u6742\u6027\u589e\u52a0\uff0c\u73b0\u6709AI\u6a21\u578b\u8303\u56f4\u72ed\u7a84\u3001\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\u4e14\u96be\u4ee5\u6cdb\u5316\uff0c\u4ecd\u9700\u4f9d\u8d56\u4e13\u5bb6\u624b\u52a8\u6545\u969c\u6392\u9664\u3002", "method": "\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7531LLM\u534f\u8c03\u7f16\u6392\u5668\u3001\u89e3\u51b3\u65b9\u6848\u89c4\u5212\u5668\u3001\u6267\u884c\u5668\u3001\u6570\u636e\u68c0\u7d22\u5668\u548c\u6839\u56e0\u5206\u6790\u5668\u7b49\u4e13\u4e1a\u4ee3\u7406\uff0c\u5e76\u5fae\u8c03\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u57fa\u4e8e\u5185\u90e8\u6587\u6863\u7684\u4fee\u590d\u65b9\u6848\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u6846\u67b6\u663e\u8457\u52a0\u901f\u4e86\u65e0\u7ebf\u63a5\u5165\u7f51\u548c\u6838\u5fc3\u7f51\u9886\u57df\u7684\u6545\u969c\u6392\u9664\u81ea\u52a8\u5316\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7ed3\u5408LLM\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u7535\u4fe1\u7f51\u7edc\u7684\u5168\u81ea\u52a8\u5316\u6545\u969c\u6392\u9664\uff0c\u63d0\u9ad8\u8fd0\u7ef4\u6548\u7387\u3002"}}
{"id": "2511.00814", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY", "93C41, 93E11, 37M10", "I.2.9; I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2511.00814", "abs": "https://arxiv.org/abs/2511.00814", "authors": ["Stella Kombo", "Masih Haseli", "Skylar Wei", "Joel W. Burdick"], "title": "Real-Time Learning of Predictive Dynamic Obstacle Models for Robotic Motion Planning", "comment": "10 pages, 6 figures, submitted to IEEE International Conference on\n  Robotics and Automation (ICRA) 2025", "summary": "Autonomous systems often must predict the motions of nearby agents from\npartial and noisy data. This paper asks and answers the question: \"can we\nlearn, in real-time, a nonlinear predictive model of another agent's motions?\"\nOur online framework denoises and forecasts such dynamics using a modified\nsliding-window Hankel Dynamic Mode Decomposition (Hankel-DMD). Partial noisy\nmeasurements are embedded into a Hankel matrix, while an associated Page matrix\nenables singular-value hard thresholding (SVHT) to estimate the effective rank.\nA Cadzow projection enforces structured low-rank consistency, yielding a\ndenoised trajectory and local noise variance estimates. From this\nrepresentation, a time-varying Hankel-DMD lifted linear predictor is\nconstructed for multi-step forecasts. The residual analysis provides\nvariance-tracking signals that can support downstream estimators and risk-aware\nplanning. We validate the approach in simulation under Gaussian and\nheavy-tailed noise, and experimentally on a dynamic crane testbed. Results show\nthat the method achieves stable variance-aware denoising and short-horizon\nprediction suitable for integration into real-time control frameworks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u65f6\u5728\u7ebf\u6846\u67b6\uff0c\u4f7f\u7528\u6539\u8fdb\u7684\u6ed1\u52a8\u7a97\u53e3Hankel\u52a8\u6001\u6a21\u6001\u5206\u89e3\u6765\u53bb\u566a\u548c\u9884\u6d4b\u52a8\u6001\u7cfb\u7edf\u8fd0\u52a8\uff0c\u652f\u6301\u5b9e\u65f6\u63a7\u5236\u5e94\u7528", "motivation": "\u81ea\u4e3b\u7cfb\u7edf\u9700\u8981\u4ece\u90e8\u5206\u566a\u58f0\u6570\u636e\u4e2d\u9884\u6d4b\u9644\u8fd1\u4ee3\u7406\u7684\u8fd0\u52a8\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u5b9e\u65f6\u6761\u4ef6\u4e0b\u5b66\u4e60\u975e\u7ebf\u6027\u9884\u6d4b\u6a21\u578b", "method": "\u4f7f\u7528Hankel\u77e9\u9635\u5d4c\u5165\u90e8\u5206\u566a\u58f0\u6d4b\u91cf\uff0c\u901a\u8fc7Page\u77e9\u9635\u8fdb\u884c\u5947\u5f02\u503c\u786c\u9608\u503c\u4f30\u8ba1\u6709\u6548\u79e9\uff0c\u91c7\u7528Cadzow\u6295\u5f71\u786e\u4fdd\u7ed3\u6784\u5316\u4f4e\u79e9\u4e00\u81f4\u6027\uff0c\u6784\u5efa\u65f6\u53d8Hankel-DMD\u63d0\u5347\u7ebf\u6027\u9884\u6d4b\u5668\u8fdb\u884c\u591a\u6b65\u9884\u6d4b", "result": "\u5728\u6a21\u62df\u548c\u52a8\u6001\u8d77\u91cd\u673a\u5b9e\u9a8c\u5e73\u53f0\u4e0a\u9a8c\u8bc1\uff0c\u65b9\u6cd5\u5728Gaussian\u548c\u91cd\u5c3e\u566a\u58f0\u4e0b\u90fd\u80fd\u5b9e\u73b0\u7a33\u5b9a\u7684\u65b9\u5dee\u611f\u77e5\u53bb\u566a\u548c\u77ed\u65f6\u57df\u9884\u6d4b", "conclusion": "\u8be5\u65b9\u6cd5\u9002\u5408\u96c6\u6210\u5230\u5b9e\u65f6\u63a7\u5236\u6846\u67b6\u4e2d\uff0c\u4e3a\u4e0b\u6e38\u4f30\u8ba1\u5668\u548c\u98ce\u9669\u611f\u77e5\u89c4\u5212\u63d0\u4f9b\u65b9\u5dee\u8ddf\u8e2a\u4fe1\u53f7"}}
{"id": "2511.00963", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.00963", "abs": "https://arxiv.org/abs/2511.00963", "authors": ["Jiahao Huang", "Marios M. Polycarpou", "Wen Yang", "Fangfei Li", "Yang Tang"], "title": "Secure Distributed Consensus Estimation under False Data Injection Attacks: A Defense Strategy Based on Partial Channel Coding", "comment": null, "summary": "This article investigates the security issue caused by false data injection\nattacks in distributed estimation, wherein each sensor can construct two types\nof residues based on local estimates and neighbor information, respectively.\nThe resource-constrained attacker can select partial channels from the sensor\nnetwork and arbitrarily manipulate the transmitted data. We derive necessary\nand sufficient conditions to reveal system vulnerabilities, under which the\nattacker is able to diverge the estimation error while preserving the\nstealthiness of all residues. We propose two defense strategies with mechanisms\nof exploiting the Euclidean distance between local estimates to detect attacks,\nand adopting the coding scheme to protect the transmitted data, respectively.\nIt is proven that the former has the capability to address the majority of\nsecurity loopholes, while the latter can serve as an additional enhancement to\nthe former. By employing the time-varying coding matrix to mitigate the risk of\nbeing cracked, we demonstrate that the latter can safeguard against adversaries\ninjecting stealthy sequences into the encoded channels. Hence, drawing upon the\nsecurity analysis, we further provide a procedure to select security-critical\nchannels that need to be encoded, thereby achieving a trade-off between\nsecurity and coding costs. Finally, some numerical simulations are conducted to\ndemonstrate the theoretical results.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5206\u5e03\u5f0f\u4f30\u8ba1\u4e2d\u865a\u5047\u6570\u636e\u6ce8\u5165\u653b\u51fb\u7684\u5b89\u5168\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u653b\u51fb\u68c0\u6d4b\u548c\u7f16\u7801\u9632\u5fa1\u4e24\u79cd\u7b56\u7565\uff0c\u5e76\u5206\u6790\u4e86\u7cfb\u7edf\u8106\u5f31\u6027\u6761\u4ef6\u3002", "motivation": "\u7814\u7a76\u5206\u5e03\u5f0f\u4f30\u8ba1\u7cfb\u7edf\u4e2d\u7531\u8d44\u6e90\u53d7\u9650\u653b\u51fb\u8005\u901a\u8fc7\u90e8\u5206\u4fe1\u9053\u6ce8\u5165\u865a\u5047\u6570\u636e\u5f15\u53d1\u7684\u5b89\u5168\u95ee\u9898\uff0c\u9700\u8981\u63ed\u793a\u7cfb\u7edf\u8106\u5f31\u6027\u5e76\u8bbe\u8ba1\u6709\u6548\u9632\u5fa1\u673a\u5236\u3002", "method": "\u63a8\u5bfc\u4e86\u653b\u51fb\u8005\u80fd\u591f\u53d1\u6563\u4f30\u8ba1\u8bef\u5dee\u540c\u65f6\u4fdd\u6301\u6240\u6709\u6b8b\u5dee\u9690\u853d\u6027\u7684\u5145\u8981\u6761\u4ef6\uff1b\u63d0\u51fa\u4e86\u57fa\u4e8e\u5c40\u90e8\u4f30\u8ba1\u6b27\u6c0f\u8ddd\u79bb\u7684\u653b\u51fb\u68c0\u6d4b\u673a\u5236\u548c\u91c7\u7528\u7f16\u7801\u65b9\u6848\u4fdd\u62a4\u4f20\u8f93\u6570\u636e\u7684\u9632\u5fa1\u7b56\u7565\u3002", "result": "\u8bc1\u660e\u4e86\u57fa\u4e8e\u8ddd\u79bb\u7684\u68c0\u6d4b\u65b9\u6cd5\u80fd\u591f\u89e3\u51b3\u5927\u591a\u6570\u5b89\u5168\u6f0f\u6d1e\uff0c\u800c\u7f16\u7801\u65b9\u6848\u53ef\u4f5c\u4e3a\u989d\u5916\u589e\u5f3a\uff1b\u91c7\u7528\u65f6\u53d8\u7f16\u7801\u77e9\u9635\u53ef\u62b5\u5fa1\u5411\u7f16\u7801\u4fe1\u9053\u6ce8\u5165\u9690\u853d\u5e8f\u5217\u7684\u5bf9\u624b\u3002", "conclusion": "\u57fa\u4e8e\u5b89\u5168\u5206\u6790\u63d0\u4f9b\u4e86\u9009\u62e9\u9700\u8981\u7f16\u7801\u7684\u5b89\u5168\u5173\u952e\u4fe1\u9053\u7684\u7a0b\u5e8f\uff0c\u5728\u5b89\u5168\u6027\u548c\u7f16\u7801\u6210\u672c\u4e4b\u95f4\u5b9e\u73b0\u6743\u8861\uff1b\u6570\u503c\u4eff\u771f\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u3002"}}
{"id": "2511.00673", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00673", "abs": "https://arxiv.org/abs/2511.00673", "authors": ["Dominik Drexler"], "title": "Lifted Successor Generation in Numeric Planning", "comment": null, "summary": "Most planners ground numeric planning tasks, given in a first-order-like\nlanguage, into a ground task representation. However, this can lead to an\nexponential blowup in task representation size, which occurs in practice for\nhard-to-ground tasks. We extend a state-of-the-art lifted successor generator\nfor classical planning to support numeric precondition applicability. The\nmethod enumerates maximum cliques in a substitution consistency graph. Each\nmaximum clique represents a substitution for the variables of the action\nschema, yielding a ground action. We augment this graph with numeric action\npreconditions and prove the successor generator is exact under formally\nspecified conditions. When the conditions fail, our generator may list\ninapplicable ground actions; a final applicability check filters these without\naffecting completeness. However, this cannot happen in 23 of 25 benchmark\ndomains, and it occurs only in 1 domain. To the authors' knowledge, no other\nlifted successor generator supports numeric action preconditions. This enables\nfuture research on lifted planning for a very rich planning fragment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u652f\u6301\u6570\u503c\u524d\u7f6e\u6761\u4ef6\u7684\u63d0\u5347\u5f0f\u540e\u7ee7\u751f\u6210\u5668\uff0c\u901a\u8fc7\u5728\u56fe\u4e2d\u7684\u6700\u5927\u56e2\u679a\u4e3e\u6765\u907f\u514d\u4efb\u52a1\u8868\u793a\u7684\u6307\u6570\u7ea7\u81a8\u80c0\u3002", "motivation": "\u4f20\u7edf\u6570\u503c\u89c4\u5212\u4efb\u52a1\u9700\u8981\u5c06\u4e00\u9636\u8bed\u8a00\u8868\u793a\u7684\u4efb\u52a1\u8fdb\u884c\u5b9e\u4f8b\u5316\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u4efb\u52a1\u8868\u793a\u5927\u5c0f\u7684\u6307\u6570\u7ea7\u7206\u70b8\uff0c\u7279\u522b\u662f\u5728\u96be\u4ee5\u5b9e\u4f8b\u5316\u7684\u4efb\u52a1\u4e2d\u3002", "method": "\u6269\u5c55\u4e86\u6700\u5148\u8fdb\u7684\u63d0\u5347\u5f0f\u540e\u7ee7\u751f\u6210\u5668\uff0c\u652f\u6301\u6570\u503c\u524d\u7f6e\u6761\u4ef6\u9002\u7528\u6027\u68c0\u67e5\u3002\u8be5\u65b9\u6cd5\u5728\u66ff\u6362\u4e00\u81f4\u6027\u56fe\u4e2d\u679a\u4e3e\u6700\u5927\u56e2\uff0c\u6bcf\u4e2a\u6700\u5927\u56e2\u4ee3\u8868\u52a8\u4f5c\u6a21\u5f0f\u53d8\u91cf\u7684\u4e00\u4e2a\u66ff\u6362\uff0c\u4ea7\u751f\u4e00\u4e2a\u5177\u4f53\u52a8\u4f5c\u3002", "result": "\u572825\u4e2a\u57fa\u51c6\u57df\u4e2d\u768423\u4e2a\u57df\u4e2d\uff0c\u751f\u6210\u5668\u4e0d\u4f1a\u5217\u51fa\u4e0d\u9002\u7528\u7684\u5177\u4f53\u52a8\u4f5c\uff0c\u4ec5\u57281\u4e2a\u57df\u4e2d\u51fa\u73b0\u8fd9\u79cd\u60c5\u51b5\u3002\u636e\u4f5c\u8005\u6240\u77e5\uff0c\u8fd9\u662f\u9996\u4e2a\u652f\u6301\u6570\u503c\u52a8\u4f5c\u524d\u7f6e\u6761\u4ef6\u7684\u63d0\u5347\u5f0f\u540e\u7ee7\u751f\u6210\u5668\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u672a\u6765\u5728\u975e\u5e38\u4e30\u5bcc\u7684\u89c4\u5212\u7247\u6bb5\u4e0a\u8fdb\u884c\u63d0\u5347\u5f0f\u89c4\u5212\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.00840", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00840", "abs": "https://arxiv.org/abs/2511.00840", "authors": ["William Suliman", "Ekaterina Chaikovskaia", "Egor Davydenko", "Roman Gorbachev"], "title": "Heuristic Step Planning for Learning Dynamic Bipedal Locomotion: A Comparative Study of Model-Based and Model-Free Approaches", "comment": null, "summary": "This work presents an extended framework for learning-based bipedal\nlocomotion that incorporates a heuristic step-planning strategy guided by\ndesired torso velocity tracking. The framework enables precise interaction\nbetween a humanoid robot and its environment, supporting tasks such as crossing\ngaps and accurately approaching target objects. Unlike approaches based on full\nor simplified dynamics, the proposed method avoids complex step planners and\nanalytical models. Step planning is primarily driven by heuristic commands,\nwhile a Raibert-type controller modulates the foot placement length based on\nthe error between desired and actual torso velocity. We compare our method with\na model-based step-planning approach -- the Linear Inverted Pendulum Model\n(LIPM) controller. Experimental results demonstrate that our approach attains\ncomparable or superior accuracy in maintaining target velocity (up to 80%),\nsignificantly greater robustness on uneven terrain (over 50% improvement), and\nimproved energy efficiency. These results suggest that incorporating complex\nanalytical, model-based components into the training architecture may be\nunnecessary for achieving stable and robust bipedal walking, even in\nunstructured environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u542f\u53d1\u5f0f\u6b65\u6001\u89c4\u5212\u7684\u53cc\u8db3\u673a\u5668\u4eba\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u671f\u671b\u8eaf\u5e72\u901f\u5ea6\u8ddf\u8e2a\u5b9e\u73b0\u7cbe\u786e\u73af\u5883\u4ea4\u4e92\uff0c\u5728\u590d\u6742\u5730\u5f62\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u9c81\u68d2\u6027\u548c\u80fd\u6548\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5b8c\u6574\u6216\u7b80\u5316\u52a8\u529b\u5b66\u7684\u65b9\u6cd5\u9700\u8981\u590d\u6742\u7684\u6b65\u6001\u89c4\u5212\u5668\u548c\u89e3\u6790\u6a21\u578b\uff0c\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u907f\u514d\u8fd9\u4e9b\u590d\u6742\u7ec4\u4ef6\u4f46\u4ecd\u80fd\u5b9e\u73b0\u7a33\u5b9a\u53cc\u8db3\u884c\u8d70\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u542f\u53d1\u5f0f\u547d\u4ee4\u9a71\u52a8\u7684\u6b65\u6001\u89c4\u5212\uff0c\u7ed3\u5408Raibert\u578b\u63a7\u5236\u5668\u6839\u636e\u671f\u671b\u4e0e\u5b9e\u9645\u8eaf\u5e72\u901f\u5ea6\u8bef\u5dee\u8c03\u8282\u8db3\u90e8\u653e\u7f6e\u4f4d\u7f6e\uff0c\u4e0e\u57fa\u4e8e\u7ebf\u6027\u5012\u7acb\u6446\u6a21\u578b\u7684\u4f20\u7edf\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u7ef4\u6301\u76ee\u6807\u901f\u5ea6\u65b9\u9762\u8fbe\u523080%\u7684\u7cbe\u5ea6\uff0c\u5728\u4e0d\u5e73\u5730\u5f62\u4e0a\u7684\u9c81\u68d2\u6027\u63d0\u5347\u8d85\u8fc750%\uff0c\u4e14\u80fd\u6548\u66f4\u9ad8\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\u5728\u8bad\u7ec3\u67b6\u6784\u4e2d\u878d\u5165\u590d\u6742\u7684\u89e3\u6790\u6a21\u578b\u7ec4\u4ef6\u5bf9\u4e8e\u5b9e\u73b0\u7a33\u5b9a\u9c81\u68d2\u7684\u53cc\u8db3\u884c\u8d70\u53ef\u80fd\u662f\u4e0d\u5fc5\u8981\u7684\uff0c\u5373\u4f7f\u5728\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u4e5f\u662f\u5982\u6b64\u3002"}}
{"id": "2511.01022", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.01022", "abs": "https://arxiv.org/abs/2511.01022", "authors": ["Xingyu Ren", "Michael C. Fu", "Steven I. Marcus"], "title": "On Structural Properties of Risk-Averse Optimal Stopping Problems", "comment": null, "summary": "We establish structural properties of optimal stopping problems under\ntime-consistent dynamic (coherent) risk measures, focusing on value function\nmonotonicity and the existence of control limit (threshold) optimal policies.\nWhile such results are well developed for risk-neutral (expected-value) models,\nthey remain underexplored in risk-averse settings. Coherent risk measures\ntypically lack the tower property and are subadditive rather than additive,\ncomplicating structural analysis. We show that value function monotonicity\nmirrors the risk-neutral case. Moreover, if the risk envelope associated with\neach coherent risk measure admits a minimal element, the risk-averse optimal\nstopping problem reduces to an equivalent risk-neutral formulation. We also\ndevelop a general procedure for identifying control limit optimal policies and\nuse it to derive practical, verifiable conditions on the risk measures and MDP\nstructure that guarantee their existence. We illustrate the theory and verify\nthese conditions through optimal stopping problems arising in operations,\nmarketing, and finance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u65f6\u95f4\u4e00\u81f4\u52a8\u6001\u98ce\u9669\u5ea6\u91cf\u4e0b\u7684\u6700\u4f18\u505c\u6b62\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u503c\u51fd\u6570\u7684\u5355\u8c03\u6027\uff0c\u5e76\u5efa\u7acb\u4e86\u63a7\u5236\u6781\u9650\u6700\u4f18\u7b56\u7565\u7684\u5b58\u5728\u6761\u4ef6\u3002", "motivation": "\u867d\u7136\u98ce\u9669\u4e2d\u6027\u6a21\u578b\u4e0b\u7684\u6700\u4f18\u505c\u6b62\u95ee\u9898\u5df2\u6709\u6210\u719f\u7ed3\u679c\uff0c\u4f46\u5728\u98ce\u9669\u89c4\u907f\u8bbe\u7f6e\u4e0b\u76f8\u5173\u7ed3\u6784\u6027\u8d28\u7814\u7a76\u4e0d\u8db3\u3002\u76f8\u5e72\u98ce\u9669\u5ea6\u91cf\u7f3a\u4e4f\u5854\u6027\u8d28\u548c\u53ef\u52a0\u6027\uff0c\u4f7f\u5f97\u7ed3\u6784\u5206\u6790\u590d\u6742\u5316\u3002", "method": "\u901a\u8fc7\u5206\u6790\u76f8\u5e72\u98ce\u9669\u5ea6\u91cf\u7684\u98ce\u9669\u5305\u7edc\uff0c\u8bc1\u660e\u5982\u679c\u6bcf\u4e2a\u98ce\u9669\u5ea6\u91cf\u5b58\u5728\u6700\u5c0f\u5143\u7d20\uff0c\u5219\u98ce\u9669\u89c4\u907f\u6700\u4f18\u505c\u6b62\u95ee\u9898\u53ef\u8f6c\u5316\u4e3a\u7b49\u4ef7\u7684\u98ce\u9669\u4e2d\u6027\u5f62\u5f0f\u3002\u5f00\u53d1\u4e86\u8bc6\u522b\u63a7\u5236\u6781\u9650\u6700\u4f18\u7b56\u7565\u7684\u4e00\u822c\u7a0b\u5e8f\u3002", "result": "\u8bc1\u660e\u4e86\u503c\u51fd\u6570\u5355\u8c03\u6027\u4e0e\u98ce\u9669\u4e2d\u6027\u60c5\u51b5\u76f8\u4f3c\u3002\u5efa\u7acb\u4e86\u98ce\u9669\u5ea6\u91cf\u548cMDP\u7ed3\u6784\u7684\u53ef\u9a8c\u8bc1\u6761\u4ef6\uff0c\u4fdd\u8bc1\u63a7\u5236\u6781\u9650\u6700\u4f18\u7b56\u7565\u7684\u5b58\u5728\u3002\u901a\u8fc7\u8fd0\u8425\u3001\u8425\u9500\u548c\u91d1\u878d\u4e2d\u7684\u6700\u4f18\u505c\u6b62\u95ee\u9898\u9a8c\u8bc1\u4e86\u7406\u8bba\u3002", "conclusion": "\u5728\u65f6\u95f4\u4e00\u81f4\u52a8\u6001\u98ce\u9669\u5ea6\u91cf\u4e0b\uff0c\u6700\u4f18\u505c\u6b62\u95ee\u9898\u7684\u7ed3\u6784\u6027\u8d28\u53ef\u4ee5\u4fdd\u6301\uff0c\u4e14\u5b58\u5728\u5c06\u98ce\u9669\u89c4\u907f\u95ee\u9898\u8f6c\u5316\u4e3a\u98ce\u9669\u4e2d\u6027\u7b49\u4ef7\u5f62\u5f0f\u7684\u65b9\u6cd5\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2511.00710", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00710", "abs": "https://arxiv.org/abs/2511.00710", "authors": ["Minghe Shen", "Zhuo Zhi", "Chonghan Liu", "Shuo Xing", "Zhengzhong Tu", "Che Liu"], "title": "Ariadne: A Controllable Framework for Probing and Extending VLM Reasoning Boundaries", "comment": null, "summary": "While Vision-Language Models (VLMs) post-trained with Reinforcement Learning\n(RL) show impressive general reasoning, their evaluation is often confined to\nlanguage-dominant tasks (e.g., math). This raises a critical question: can RL\npost-training truly extend the inherent capability boundary of a base VLM,\nparticularly for visual-centric spatial tasks where it initially fails? To\ninvestigate this, we introduce Ariadne, a framework utilizing synthetic mazes\nfor multi-step spatial reasoning where task difficulty (e.g., path length,\nturns) is precisely controlled. We leverage this controllable environment to\ntrain VLMs using Reinforcement Learning with Verified Rewards (RLVR) in a\ndifficulty-aware curriculum. Surprisingly, post-RLVR training, the VLM achieves\nover 50% accuracy on a problem set where the base model scored 0%,\ndemonstrating that our approach expands the model's initial capability\nboundary. To assess real-world viability, we evaluate out-of-distribution (OOD)\ngeneralization on practical benchmarks. Despite training only on synthetic maze\nsamples, Ariadne achieves significant zero-shot improvements, averaging 16% on\nMapBench (e.g., museum navigation) and 24% on ReasonMap (subway transfer\ntasks). These results confirm that our method not only broadens the model's\nfundamental limits but also enhances its generalization to real-world spatial\nreasoning. We acknowledge our study is limited to the post-training phase,\ngiven the opaqueness of pre-training data, and hope our research motivates\nfurther work on specialized, capability-extending alignment.", "AI": {"tldr": "Ariadne\u6846\u67b6\u901a\u8fc7\u5408\u6210\u8ff7\u5bab\u8fdb\u884c\u591a\u6b65\u7a7a\u95f4\u63a8\u7406\uff0c\u4f7f\u7528RLVR\u8bad\u7ec3VLM\uff0c\u5728\u57fa\u7840\u6a21\u578b\u5f97\u5206\u4e3a0%\u7684\u95ee\u9898\u96c6\u4e0a\u8fbe\u5230\u8d85\u8fc750%\u7684\u51c6\u786e\u7387\uff0c\u5e76\u663e\u8457\u63d0\u5347\u5728\u771f\u5b9e\u4e16\u754c\u7a7a\u95f4\u63a8\u7406\u57fa\u51c6\u4e0a\u7684\u96f6\u6837\u672c\u6027\u80fd\u3002", "motivation": "\u7814\u7a76RL\u540e\u8bad\u7ec3\u662f\u5426\u80fd\u771f\u6b63\u6269\u5c55\u57fa\u7840VLM\u7684\u80fd\u529b\u8fb9\u754c\uff0c\u7279\u522b\u662f\u5728\u89c6\u89c9\u4e3b\u5bfc\u7684\u7a7a\u95f4\u4efb\u52a1\u4e2d\uff0c\u56e0\u4e3a\u73b0\u6709\u8bc4\u4f30\u591a\u5c40\u9650\u4e8e\u8bed\u8a00\u4e3b\u5bfc\u4efb\u52a1\u3002", "method": "\u4f7f\u7528\u5408\u6210\u8ff7\u5bab\u6784\u5efa\u53ef\u63a7\u96be\u5ea6\u7684\u591a\u6b65\u7a7a\u95f4\u63a8\u7406\u73af\u5883\uff0c\u91c7\u7528\u5e26\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60(RLVR)\u548c\u96be\u5ea6\u611f\u77e5\u8bfe\u7a0b\u8fdb\u884cVLM\u8bad\u7ec3\u3002", "result": "RLVR\u540e\u8bad\u7ec3\u4f7fVLM\u5728\u57fa\u7840\u6a21\u578b\u5f97\u5206\u4e3a0%\u7684\u95ee\u9898\u96c6\u4e0a\u8fbe\u5230\u8d85\u8fc750%\u51c6\u786e\u7387\uff1b\u5728MapBench\u4e0a\u5e73\u5747\u63d0\u534716%\uff0c\u5728ReasonMap\u4e0a\u5e73\u5747\u63d0\u534724%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u6269\u5c55\u4e86\u6a21\u578b\u7684\u57fa\u672c\u80fd\u529b\u8fb9\u754c\uff0c\u8fd8\u589e\u5f3a\u4e86\u5176\u5728\u771f\u5b9e\u4e16\u754c\u7a7a\u95f4\u63a8\u7406\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u4e13\u95e8\u5316\u80fd\u529b\u6269\u5c55\u5bf9\u9f50\u7814\u7a76\u63d0\u4f9b\u4e86\u52a8\u529b\u3002"}}
{"id": "2511.00917", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00917", "abs": "https://arxiv.org/abs/2511.00917", "authors": ["Junyao Shi", "Rujia Yang", "Kaitian Chao", "Selina Bingqing Wan", "Yifei Shao", "Jiahui Lei", "Jianing Qian", "Long Le", "Pratik Chaudhari", "Kostas Daniilidis", "Chuan Wen", "Dinesh Jayaraman"], "title": "Maestro: Orchestrating Robotics Modules with Vision-Language Models for Zero-Shot Generalist Robots", "comment": "Project website: https://maestro-robot.github.io", "summary": "Today's best-explored routes towards generalist robots center on collecting\never larger \"observations-in actions-out\" robotics datasets to train large\nend-to-end models, copying a recipe that has worked for vision-language models\n(VLMs). We pursue a road less traveled: building generalist policies directly\naround VLMs by augmenting their general capabilities with specific robot\ncapabilities encapsulated in a carefully curated set of perception, planning,\nand control modules. In Maestro, a VLM coding agent dynamically composes these\nmodules into a programmatic policy for the current task and scenario. Maestro's\narchitecture benefits from a streamlined closed-loop interface without many\nmanually imposed structural constraints, and a comprehensive and diverse tool\nrepertoire. As a result, it largely surpasses today's VLA models for zero-shot\nperformance on challenging manipulation skills. Further, Maestro is easily\nextensible to incorporate new modules, easily editable to suit new embodiments\nsuch as a quadruped-mounted arm, and even easily adapts from minimal real-world\nexperiences through local code edits.", "AI": {"tldr": "Maestro\u662f\u4e00\u4e2a\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLM)\u7684\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u7ec4\u5408\u611f\u77e5\u3001\u89c4\u5212\u548c\u63a7\u5236\u6a21\u5757\u6765\u6784\u5efa\u901a\u7528\u7b56\u7565\uff0c\u8d85\u8d8a\u4e86\u5f53\u524dVLA\u6a21\u578b\u5728\u96f6\u6837\u672c\u64cd\u4f5c\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u901a\u7528\u673a\u5668\u4eba\u7814\u7a76\u4e3b\u8981\u4f9d\u8d56\u5927\u89c4\u6a21\u6570\u636e\u96c6\u8bad\u7ec3\u7aef\u5230\u7aef\u6a21\u578b\uff0c\u4f5c\u8005\u63a2\u7d22\u4e86\u53e6\u4e00\u79cd\u8def\u5f84\uff1a\u56f4\u7ed5VLM\u6784\u5efa\u901a\u7528\u7b56\u7565\uff0c\u5229\u7528\u5176\u901a\u7528\u80fd\u529b\u7ed3\u5408\u7279\u5b9a\u673a\u5668\u4eba\u6a21\u5757\u3002", "method": "\u4f7f\u7528VLM\u7f16\u7801\u4ee3\u7406\u52a8\u6001\u7ec4\u5408\u611f\u77e5\u3001\u89c4\u5212\u548c\u63a7\u5236\u6a21\u5757\u4e3a\u7a0b\u5e8f\u5316\u7b56\u7565\uff0c\u5177\u6709\u7b80\u5316\u7684\u95ed\u73af\u63a5\u53e3\u548c\u591a\u6837\u5316\u5de5\u5177\u5e93\u3002", "result": "\u5728\u6311\u6218\u6027\u64cd\u4f5c\u6280\u80fd\u4e0a\u5927\u5e45\u8d85\u8d8a\u5f53\u524dVLA\u6a21\u578b\u7684\u96f6\u6837\u672c\u6027\u80fd\uff0c\u6613\u4e8e\u6269\u5c55\u65b0\u6a21\u5757\u3001\u9002\u5e94\u65b0\u673a\u5668\u4eba\u5f62\u6001\uff0c\u5e76\u80fd\u901a\u8fc7\u672c\u5730\u4ee3\u7801\u7f16\u8f91\u4ece\u5c11\u91cf\u771f\u5b9e\u4e16\u754c\u7ecf\u9a8c\u4e2d\u5feb\u901f\u9002\u5e94\u3002", "conclusion": "Maestro\u5c55\u793a\u4e86\u56f4\u7ed5VLM\u6784\u5efa\u6a21\u5757\u5316\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u53ef\u884c\u6027\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u53ef\u7f16\u8f91\u548c\u9002\u5e94\u6027\u5f3a\u7684\u901a\u7528\u673a\u5668\u4eba\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01032", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.01032", "abs": "https://arxiv.org/abs/2511.01032", "authors": ["Yiqian Wu", "Ming Yi", "Bolun Xu", "James Anderson"], "title": "Online Energy Storage Arbitrage under Imperfect Predictions: A Conformal Risk-Aware Approach", "comment": null, "summary": "This work proposes a conformal approach for energy storage arbitrage to\ncontrol the downside risks arose from imperfect price forecasts. Energy storage\narbitrage relies solely on predictions of future market prices, while\ninaccurate price predictions may lead to significant profit losses. Based on\nconformal decision theory, we describe a controller that dynamically adjusts\ndecision conservativeness through prediction sets without distributional\nassumptions. To enable online calibration when online profit loss feedback is\nunobservable, we establish that a temporal difference error serves as a\nmeasurable proxy. Building on this insight, we develop two online calibration\nstrategies: prediction error-based adaptation targeting forecast accuracy, and\nvalue error-based calibration focusing on decision quality. Analysis of the\nconformal controller proves bounded long-term risk with convergence guarantees\nin temporal difference error, which further effectively manages risk exposure\nin potential profit losses. Case studies demonstrate superior performance in\nbalancing risk and opportunity compared to benchmarks under varying forecast\nconditions.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4fdd\u5f62\u51b3\u7b56\u7406\u8bba\u7684\u50a8\u80fd\u5957\u5229\u98ce\u9669\u63a7\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7\u9884\u6d4b\u96c6\u52a8\u6001\u8c03\u6574\u51b3\u7b56\u4fdd\u5b88\u5ea6\uff0c\u65e0\u9700\u5206\u5e03\u5047\u8bbe\uff0c\u6709\u6548\u7ba1\u7406\u4ef7\u683c\u9884\u6d4b\u4e0d\u51c6\u786e\u5e26\u6765\u7684\u5229\u6da6\u635f\u5931\u98ce\u9669\u3002", "motivation": "\u50a8\u80fd\u5957\u5229\u5b8c\u5168\u4f9d\u8d56\u672a\u6765\u5e02\u573a\u4ef7\u683c\u9884\u6d4b\uff0c\u800c\u4e0d\u51c6\u786e\u7684\u4ef7\u683c\u9884\u6d4b\u53ef\u80fd\u5bfc\u81f4\u663e\u8457\u7684\u5229\u6da6\u635f\u5931\uff0c\u9700\u8981\u63a7\u5236\u8fd9\u79cd\u4e0b\u884c\u98ce\u9669\u3002", "method": "\u57fa\u4e8e\u4fdd\u5f62\u51b3\u7b56\u7406\u8bba\u5f00\u53d1\u63a7\u5236\u5668\uff0c\u901a\u8fc7\u9884\u6d4b\u96c6\u52a8\u6001\u8c03\u6574\u51b3\u7b56\u4fdd\u5b88\u5ea6\uff1b\u5efa\u7acb\u65f6\u95f4\u5dee\u5206\u8bef\u5dee\u4f5c\u4e3a\u53ef\u6d4b\u91cf\u7684\u4ee3\u7406\u6307\u6807\uff1b\u5f00\u53d1\u4e24\u79cd\u5728\u7ebf\u6821\u51c6\u7b56\u7565\uff1a\u57fa\u4e8e\u9884\u6d4b\u8bef\u5dee\u7684\u9002\u5e94\u548c\u57fa\u4e8e\u4ef7\u503c\u8bef\u5dee\u7684\u6821\u51c6\u3002", "result": "\u5206\u6790\u8bc1\u660e\u4fdd\u5f62\u63a7\u5236\u5668\u5177\u6709\u6709\u754c\u7684\u957f\u671f\u98ce\u9669\uff0c\u65f6\u95f4\u5dee\u5206\u8bef\u5dee\u5177\u6709\u6536\u655b\u4fdd\u8bc1\uff1b\u6848\u4f8b\u7814\u7a76\u8868\u660e\u5728\u4e0d\u540c\u9884\u6d4b\u6761\u4ef6\u4e0b\u76f8\u6bd4\u57fa\u51c6\u65b9\u6cd5\u5728\u5e73\u8861\u98ce\u9669\u548c\u673a\u4f1a\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u7ba1\u7406\u50a8\u80fd\u5957\u5229\u4e2d\u7684\u98ce\u9669\u66b4\u9732\uff0c\u5728\u4ef7\u683c\u9884\u6d4b\u4e0d\u51c6\u786e\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u4fdd\u6301\u7a33\u5065\u6027\u80fd\uff0c\u5e73\u8861\u98ce\u9669\u4e0e\u6536\u76ca\u3002"}}
{"id": "2511.00739", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.00739", "abs": "https://arxiv.org/abs/2511.00739", "authors": ["Ritik Raj", "Hong Wang", "Tushar Krishna"], "title": "A CPU-Centric Perspective on Agentic AI", "comment": null, "summary": "Agentic AI frameworks add a decision-making orchestrator embedded with\nexternal tools, including web search, Python interpreter, contextual database,\nand others, on top of monolithic LLMs, turning them from passive text oracles\ninto autonomous problem-solvers that can plan, call tools, remember past steps,\nand adapt on the fly.\n  This paper aims to characterize and understand the system bottlenecks\nintroduced by agentic AI workloads from a largely overlooked CPU-centric\nperspective. We first systematically characterize Agentic AI on the basis of\norchestrator/decision making component, inference path dynamics and\nrepetitiveness of the agentic flow which directly influences the system-level\nperformance. Thereafter, based on the characterization, we choose five\nrepresentative agentic AI workloads- Haystack RAG, Toolformer, ChemCrow,\nLangchain and SWE-Agent to profile latency, throughput and energy metrics and\ndemystify the significant impact of CPUs on these metrics relative to GPUs. We\nobserve that - 1. Tool processing on CPUs can take up to 90.6% of the total\nlatency; 2. Agentic throughput gets bottlenecked either by CPU factors -\ncoherence, synchronization and over-subscription of cores or GPU factors - main\nmemory capacity and bandwidth; \\circled{3} CPU dynamic energy consumes up to\n44% of the total dynamic energy at large batch sizes. Based on the profiling\ninsights, we present two key optimizations- 1. CPU and GPU-Aware Micro-batching\n(CGAM) and 2. Mixed Agentic Workload Scheduling (MAWS) for homogeneous and\nheterogeneous agentic workloads respectively to demonstrate the potential to\nimprove the performance, efficiency, and scalability of agentic AI. We achieve\nup to 2.1x and 1.41x P50 latency speedup compared to the multi-processing\nbenchmark for homogeneous and heterogeneous agentic workloads respectively.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4eceCPU\u89c6\u89d2\u5206\u6790\u667a\u80fdAI\u6846\u67b6\u7684\u7cfb\u7edf\u74f6\u9888\uff0c\u53d1\u73b0\u5de5\u5177\u5904\u7406\u5728CPU\u4e0a\u5360\u7528\u9ad8\u8fbe90.6%\u7684\u603b\u5ef6\u8fdf\uff0c\u5e76\u63d0\u51fa\u4e24\u79cd\u4f18\u5316\u65b9\u6848\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u4e3b\u8981\u5173\u6ce8GPU\u6027\u80fd\uff0c\u4f46\u5ffd\u7565\u4e86\u667a\u80fdAI\u5de5\u4f5c\u8d1f\u8f7d\u4e2dCPU\u7684\u5173\u952e\u4f5c\u7528\u3002\u8bba\u6587\u65e8\u5728\u4eceCPU\u4e2d\u5fc3\u89c6\u89d2\u7406\u89e3\u548c\u8868\u5f81\u667a\u80fdAI\u5f15\u5165\u7684\u7cfb\u7edf\u74f6\u9888\u3002", "method": "\u9996\u5148\u7cfb\u7edf\u8868\u5f81\u667a\u80fdAI\u7684\u7f16\u6392\u5668/\u51b3\u7b56\u7ec4\u4ef6\u3001\u63a8\u7406\u8def\u5f84\u52a8\u6001\u6027\u548c\u6d41\u7a0b\u91cd\u590d\u6027\uff0c\u7136\u540e\u9009\u62e9\u4e94\u4e2a\u4ee3\u8868\u6027\u5de5\u4f5c\u8d1f\u8f7d\u8fdb\u884c\u5ef6\u8fdf\u3001\u541e\u5410\u91cf\u548c\u80fd\u8017\u5206\u6790\uff0c\u6700\u540e\u63d0\u51faCPU\u548cGPU\u611f\u77e5\u7684\u5fae\u6279\u5904\u7406\u548c\u6df7\u5408\u5de5\u4f5c\u8d1f\u8f7d\u8c03\u5ea6\u4f18\u5316\u65b9\u6848\u3002", "result": "\u53d1\u73b0CPU\u5de5\u5177\u5904\u7406\u5360\u752890.6%\u603b\u5ef6\u8fdf\uff0c\u541e\u5410\u91cf\u74f6\u9888\u6765\u81eaCPU\u56e0\u7d20\uff08\u4e00\u81f4\u6027\u3001\u540c\u6b65\u3001\u6838\u5fc3\u8fc7\u8f7d\uff09\u6216GPU\u56e0\u7d20\uff08\u5185\u5b58\u5bb9\u91cf\u548c\u5e26\u5bbd\uff09\uff0cCPU\u52a8\u6001\u80fd\u8017\u5728\u5927\u6279\u91cf\u65f6\u5360\u603b\u80fd\u801744%\u3002\u4f18\u5316\u65b9\u6848\u5206\u522b\u5b9e\u73b02.1\u500d\u548c1.41\u500d\u7684P50\u5ef6\u8fdf\u52a0\u901f\u3002", "conclusion": "CPU\u5728\u667a\u80fdAI\u7cfb\u7edf\u4e2d\u626e\u6f14\u5173\u952e\u89d2\u8272\uff0c\u63d0\u51fa\u7684\u4f18\u5316\u65b9\u6848\u80fd\u6709\u6548\u63d0\u5347\u667a\u80fdAI\u7684\u6027\u80fd\u3001\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u672a\u6765\u667a\u80fdAI\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2511.00933", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00933", "abs": "https://arxiv.org/abs/2511.00933", "authors": ["Xiangyu Shi", "Zerui Li", "Yanyuan Qiao", "Qi Wu"], "title": "Fast-SmartWay: Panoramic-Free End-to-End Zero-Shot Vision-and-Language Navigation", "comment": null, "summary": "Recent advances in Vision-and-Language Navigation in Continuous Environments\n(VLN-CE) have leveraged multimodal large language models (MLLMs) to achieve\nzero-shot navigation. However, existing methods often rely on panoramic\nobservations and two-stage pipelines involving waypoint predictors, which\nintroduce significant latency and limit real-world applicability. In this work,\nwe propose Fast-SmartWay, an end-to-end zero-shot VLN-CE framework that\neliminates the need for panoramic views and waypoint predictors. Our approach\nuses only three frontal RGB-D images combined with natural language\ninstructions, enabling MLLMs to directly predict actions. To enhance decision\nrobustness, we introduce an Uncertainty-Aware Reasoning module that integrates\n(i) a Disambiguation Module for avoiding local optima, and (ii) a Future-Past\nBidirectional Reasoning mechanism for globally coherent planning. Experiments\non both simulated and real-robot environments demonstrate that our method\nsignificantly reduces per-step latency while achieving competitive or superior\nperformance compared to panoramic-view baselines. These results demonstrate the\npracticality and effectiveness of Fast-SmartWay for real-world zero-shot\nembodied navigation.", "AI": {"tldr": "Fast-SmartWay\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u96f6\u6837\u672c\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u6846\u67b6\uff0c\u4ec5\u4f7f\u7528\u4e09\u4e2a\u524d\u89c6RGB-D\u56fe\u50cf\u548c\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\uff0c\u65e0\u9700\u5168\u666f\u89c6\u56fe\u548c\u8def\u5f84\u70b9\u9884\u6d4b\u5668\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5ef6\u8fdf\u5e76\u63d0\u5347\u4e86\u5b9e\u9645\u5e94\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u7684VLN-CE\u65b9\u6cd5\u4f9d\u8d56\u5168\u666f\u89c2\u6d4b\u548c\u4e24\u9636\u6bb5\u6d41\u6c34\u7ebf\uff0c\u5bfc\u81f4\u663e\u8457\u5ef6\u8fdf\u5e76\u9650\u5236\u5b9e\u9645\u5e94\u7528\u3002\u672c\u6587\u65e8\u5728\u6d88\u9664\u8fd9\u4e9b\u9650\u5236\uff0c\u5f00\u53d1\u66f4\u5b9e\u7528\u7684\u96f6\u6837\u672c\u5bfc\u822a\u7cfb\u7edf\u3002", "method": "\u63d0\u51faFast-SmartWay\u6846\u67b6\uff0c\u4ec5\u4f7f\u7528\u4e09\u4e2a\u524d\u89c6RGB-D\u56fe\u50cf\u7ed3\u5408\u8bed\u8a00\u6307\u4ee4\uff0c\u8ba9MLLM\u76f4\u63a5\u9884\u6d4b\u52a8\u4f5c\u3002\u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u63a8\u7406\u6a21\u5757\uff0c\u5305\u62ec\u89e3\u6b67\u6a21\u5757\uff08\u907f\u514d\u5c40\u90e8\u6700\u4f18\uff09\u548c\u672a\u6765-\u8fc7\u53bb\u53cc\u5411\u63a8\u7406\u673a\u5236\uff08\u5b9e\u73b0\u5168\u5c40\u4e00\u81f4\u6027\u89c4\u5212\uff09\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u673a\u5668\u4eba\u73af\u5883\u4e2d\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u6bcf\u6b65\u5ef6\u8fdf\uff0c\u540c\u65f6\u8fbe\u5230\u6216\u8d85\u8d8a\u4e86\u57fa\u4e8e\u5168\u666f\u89c6\u56fe\u57fa\u7ebf\u7684\u6027\u80fd\u3002", "conclusion": "Fast-SmartWay\u8bc1\u660e\u4e86\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u96f6\u6837\u672c\u5177\u8eab\u5bfc\u822a\u7684\u5b9e\u7528\u6027\u548c\u6709\u6548\u6027\uff0c\u4e3a\u5b9e\u65f6\u5bfc\u822a\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01045", "categories": ["eess.SY", "cs.MA", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.01045", "abs": "https://arxiv.org/abs/2511.01045", "authors": ["George Jones", "Angel Garcia-Fernandez"], "title": "GOSPA-Driven Non-Myopic Multi-Sensor Management with Multi-Bernoulli Filtering", "comment": "submitted to IEEE Transactions on Aerospace and Electronic Systems\n  November 2025", "summary": "In this paper, we propose a non-myopic sensor management algorithm for\nmulti-target tracking, with multiple sensors operating in the same surveillance\narea. The algorithm is based on multi-Bernoulli filtering and selects the\nactions that solve a non-myopic minimisation problem, where the cost function\nis the mean square generalised optimal sub-pattern assignment (GOSPA) error,\nover a future time window. For tractability, the sensor management algorithm\nactually uses an upper bound of the GOSPA error and is implemented via Monte\nCarlo Tree Search (MCTS). The sensors have the ability to jointly optimise and\nselect their actions with the considerations of all other sensors in the\nsurveillance area. The benefits of the proposed algorithm are analysed via\nsimulations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u4f2f\u52aa\u5229\u6ee4\u6ce2\u7684\u975e\u8fd1\u89c6\u4f20\u611f\u5668\u7ba1\u7406\u7b97\u6cd5\uff0c\u7528\u4e8e\u591a\u4f20\u611f\u5668\u591a\u76ee\u6807\u8ddf\u8e2a\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u6700\u5c0f\u5316\u5e7f\u4e49\u6700\u4f18\u5b50\u6a21\u5f0f\u5206\u914d\u8bef\u5dee\u7684\u4e0a\u754c\u3002", "motivation": "\u89e3\u51b3\u591a\u4f20\u611f\u5668\u5728\u540c\u4e00\u76d1\u89c6\u533a\u57df\u8fdb\u884c\u591a\u76ee\u6807\u8ddf\u8e2a\u65f6\u7684\u4f20\u611f\u5668\u7ba1\u7406\u95ee\u9898\uff0c\u8003\u8651\u4f20\u611f\u5668\u95f4\u7684\u8054\u5408\u4f18\u5316\u548c\u672a\u6765\u65f6\u95f4\u7a97\u53e3\u5185\u7684\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u591a\u4f2f\u52aa\u5229\u6ee4\u6ce2\u6846\u67b6\uff0c\u6784\u5efa\u975e\u8fd1\u89c6\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u4ee5\u5e7f\u4e49\u6700\u4f18\u5b50\u6a21\u5f0f\u5206\u914d\u8bef\u5dee\u7684\u5747\u65b9\u8bef\u5dee\u4f5c\u4e3a\u6210\u672c\u51fd\u6570\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u5b9e\u73b0\u53ef\u5904\u7406\u7684\u4f18\u5316\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u5206\u6790\u4e86\u6240\u63d0\u7b97\u6cd5\u7684\u4f18\u52bf\uff0c\u5c55\u793a\u4e86\u5728\u591a\u4f20\u611f\u5668\u591a\u76ee\u6807\u8ddf\u8e2a\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u7ba1\u7406\u591a\u4f20\u611f\u5668\u7cfb\u7edf\uff0c\u5728\u8003\u8651\u6240\u6709\u4f20\u611f\u5668\u534f\u540c\u4f5c\u7528\u7684\u540c\u65f6\uff0c\u4f18\u5316\u957f\u671f\u8ddf\u8e2a\u6027\u80fd\u3002"}}
{"id": "2511.00751", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00751", "abs": "https://arxiv.org/abs/2511.00751", "authors": ["Chiyan Loo"], "title": "Reevaluating Self-Consistency Scaling in Multi-Agent Systems", "comment": "7 pages, 3 figures", "summary": "This study examines the trade-offs of increasing sampled reasoning paths in\nself-consistency for modern large language models (LLMs). Earlier research with\nolder models showed that combining multiple reasoning chains improves results\nbefore reaching a plateau. Using Gemini 2.5 models on HotpotQA and Math-500, we\nrevisit those claims under current model conditions. Each configuration pooled\noutputs from varying sampled reasoning paths and compared them to a single\nchain-of-thought (CoT) baseline. Larger models exhibited a more stable and\nconsistent improvement curve. The results confirm that performance gains taper\noff after moderate sampling, aligning with past findings. This plateau suggests\ndiminishing returns driven by overlap among reasoning paths. Self-consistency\nremains useful, but high-sample configurations offer little benefit relative to\ntheir computational cost.", "AI": {"tldr": "\u7814\u7a76\u9a8c\u8bc1\u4e86\u5728\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u589e\u52a0\u63a8\u7406\u8def\u5f84\u91c7\u6837\u6570\u91cf\u5b58\u5728\u6536\u76ca\u9012\u51cf\u73b0\u8c61\uff0c\u6027\u80fd\u63d0\u5347\u5728\u9002\u5ea6\u91c7\u6837\u540e\u8d8b\u4e8e\u5e73\u7f13\u3002", "motivation": "\u91cd\u65b0\u9a8c\u8bc1\u65e9\u671f\u7814\u7a76\u4e2d\u5173\u4e8e\u591a\u63a8\u7406\u8def\u5f84\u7ec4\u5408\u80fd\u63d0\u5347\u7ed3\u679c\u4f46\u5728\u8fbe\u5230\u5e73\u53f0\u671f\u540e\u6536\u76ca\u9012\u51cf\u7684\u7ed3\u8bba\uff0c\u5728Gemini 2.5\u7b49\u73b0\u4ee3\u6a21\u578b\u6761\u4ef6\u4e0b\u8fdb\u884c\u68c0\u9a8c\u3002", "method": "\u4f7f\u7528Gemini 2.5\u6a21\u578b\u5728HotpotQA\u548cMath-500\u6570\u636e\u96c6\u4e0a\uff0c\u6bd4\u8f83\u4e0d\u540c\u91c7\u6837\u63a8\u7406\u8def\u5f84\u6570\u91cf\u7684\u8f93\u51fa\u4e0e\u5355\u4e00\u601d\u7ef4\u94fe\u57fa\u7ebf\u7684\u6027\u80fd\u5dee\u5f02\u3002", "result": "\u66f4\u5927\u6a21\u578b\u5c55\u73b0\u51fa\u66f4\u7a33\u5b9a\u4e00\u81f4\u7684\u6539\u8fdb\u66f2\u7ebf\uff0c\u6027\u80fd\u63d0\u5347\u5728\u9002\u5ea6\u91c7\u6837\u540e\u8fbe\u5230\u5e73\u53f0\u671f\uff0c\u9ad8\u91c7\u6837\u914d\u7f6e\u76f8\u5bf9\u4e8e\u8ba1\u7b97\u6210\u672c\u5e26\u6765\u7684\u76ca\u5904\u5f88\u5c0f\u3002", "conclusion": "\u81ea\u4e00\u81f4\u6027\u65b9\u6cd5\u4ecd\u7136\u6709\u6548\uff0c\u4f46\u7531\u4e8e\u63a8\u7406\u8def\u5f84\u95f4\u7684\u91cd\u53e0\u5bfc\u81f4\u6536\u76ca\u9012\u51cf\uff0c\u9ad8\u91c7\u6837\u914d\u7f6e\u7684\u6027\u4ef7\u6bd4\u4e0d\u9ad8\u3002"}}
{"id": "2511.00940", "categories": ["cs.RO", "cs.AI", "I.2.6"], "pdf": "https://arxiv.org/pdf/2511.00940", "abs": "https://arxiv.org/abs/2511.00940", "authors": ["Zhe Li", "Xiang Bai", "Jieyu Zhang", "Zhuangzhe Wu", "Che Xu", "Ying Li", "Chengkai Hou", "Shanghang Zhang"], "title": "URDF-Anything: Constructing Articulated Objects with 3D Multimodal Language Model", "comment": "Accepted to the 39th Conference on Neural Information Processing\n  Systems (NeurIPS 2025)", "summary": "Constructing accurate digital twins of articulated objects is essential for\nrobotic simulation training and embodied AI world model building, yet\nhistorically requires painstaking manual modeling or multi-stage pipelines. In\nthis work, we propose \\textbf{URDF-Anything}, an end-to-end automatic\nreconstruction framework based on a 3D multimodal large language model (MLLM).\nURDF-Anything utilizes an autoregressive prediction framework based on\npoint-cloud and text multimodal input to jointly optimize geometric\nsegmentation and kinematic parameter prediction. It implements a specialized\n$[SEG]$ token mechanism that interacts directly with point cloud features,\nenabling fine-grained part-level segmentation while maintaining consistency\nwith the kinematic parameter predictions. Experiments on both simulated and\nreal-world datasets demonstrate that our method significantly outperforms\nexisting approaches regarding geometric segmentation (mIoU 17\\% improvement),\nkinematic parameter prediction (average error reduction of 29\\%), and physical\nexecutability (surpassing baselines by 50\\%). Notably, our method exhibits\nexcellent generalization ability, performing well even on objects outside the\ntraining set. This work provides an efficient solution for constructing digital\ntwins for robotic simulation, significantly enhancing the sim-to-real transfer\ncapability.", "AI": {"tldr": "URDF-Anything\u662f\u4e00\u4e2a\u57fa\u4e8e3D\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7aef\u5230\u7aef\u81ea\u52a8\u91cd\u5efa\u6846\u67b6\uff0c\u80fd\u591f\u4ece\u70b9\u4e91\u548c\u6587\u672c\u8f93\u5165\u4e2d\u8054\u5408\u4f18\u5316\u51e0\u4f55\u5206\u5272\u548c\u8fd0\u52a8\u5b66\u53c2\u6570\u9884\u6d4b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u5b57\u5b6a\u751f\u6784\u5efa\u7684\u6548\u7387\u548c\u7cbe\u5ea6\u3002", "motivation": "\u6784\u5efa\u7cbe\u786e\u7684\u5173\u8282\u7269\u4f53\u6570\u5b57\u5b6a\u751f\u5bf9\u4e8e\u673a\u5668\u4eba\u4eff\u771f\u8bad\u7ec3\u548c\u5177\u8eabAI\u4e16\u754c\u6a21\u578b\u6784\u5efa\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u7e41\u7410\u7684\u624b\u52a8\u5efa\u6a21\u6216\u591a\u9636\u6bb5\u6d41\u7a0b\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u7aef\u5230\u7aef\u7684\u81ea\u52a8\u91cd\u5efa\u65b9\u6848\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u70b9\u4e91\u548c\u6587\u672c\u591a\u6a21\u6001\u8f93\u5165\u7684\u81ea\u56de\u5f52\u9884\u6d4b\u6846\u67b6\uff0c\u5b9e\u73b0\u4e13\u95e8\u7684[SEG]\u4ee4\u724c\u673a\u5236\u4e0e\u70b9\u4e91\u7279\u5f81\u76f4\u63a5\u4ea4\u4e92\uff0c\u5728\u4fdd\u6301\u8fd0\u52a8\u5b66\u53c2\u6570\u9884\u6d4b\u4e00\u81f4\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u96f6\u4ef6\u7ea7\u5206\u5272\u3002", "result": "\u5728\u4eff\u771f\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u51e0\u4f55\u5206\u5272\uff08mIoU\u63d0\u534717%\uff09\u3001\u8fd0\u52a8\u5b66\u53c2\u6570\u9884\u6d4b\uff08\u5e73\u5747\u8bef\u5dee\u51cf\u5c1129%\uff09\u548c\u7269\u7406\u53ef\u6267\u884c\u6027\uff08\u8d85\u8d8a\u57fa\u7ebf50%\uff09\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5c55\u73b0\u51fa\u4f18\u79c0\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u673a\u5668\u4eba\u4eff\u771f\u6784\u5efa\u6570\u5b57\u5b6a\u751f\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u4ece\u4eff\u771f\u5230\u73b0\u5b9e\u7684\u8fc1\u79fb\u80fd\u529b\u3002"}}
{"id": "2511.01057", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.01057", "abs": "https://arxiv.org/abs/2511.01057", "authors": ["Abbas Tariverdi"], "title": "Robust Self-Triggered Control Approaches Optimizing Sampling Sequences with Synchronous Measurements", "comment": "Note: This research was conducted in 2017--2018. The literature\n  review has not been updated and may not reflect subsequent or concurrent\n  developments in the field", "summary": "Feedback control algorithms traditionally rely on periodic execution on\ndigital platforms. While this simplifies design and analysis, it often leads to\ninefficient resource usage (e.g., CPU, network bandwidth) in embedded control\nand shared networks. This work investigates self-triggering implementations of\nlinear controllers in sampled-data systems with synchronous measurements. Our\napproach precomputes the next sampling sequence over a finite horizon based on\ncurrent state information. We introduce a novel optimal self-triggering scheme\nthat guarantees exponential stability for unperturbed systems and global\nuniform ultimate boundedness for perturbed systems. This ensures robustness\nagainst external disturbances with explicit performance guarantees. Simulations\ndemonstrate the benefits of our approach.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6709\u9650\u65f6\u57df\u9884\u8ba1\u7b97\u7684\u81ea\u89e6\u53d1\u63a7\u5236\u65b9\u6848\uff0c\u7528\u4e8e\u51cf\u5c11\u5d4c\u5165\u5f0f\u63a7\u5236\u7cfb\u7edf\u4e2d\u7684\u8d44\u6e90\u6d88\u8017\uff0c\u540c\u65f6\u4fdd\u8bc1\u7cfb\u7edf\u7a33\u5b9a\u6027\u3002", "motivation": "\u4f20\u7edf\u5468\u671f\u6027\u53cd\u9988\u63a7\u5236\u7b97\u6cd5\u5728\u6570\u5b57\u5e73\u53f0\u4e0a\u6267\u884c\u65f6\u4f1a\u5bfc\u81f4CPU\u3001\u7f51\u7edc\u5e26\u5bbd\u7b49\u8d44\u6e90\u4f7f\u7528\u6548\u7387\u4f4e\u4e0b\uff0c\u7279\u522b\u662f\u5728\u5d4c\u5165\u5f0f\u63a7\u5236\u548c\u5171\u4eab\u7f51\u7edc\u73af\u5883\u4e2d\u3002", "method": "\u57fa\u4e8e\u5f53\u524d\u72b6\u6001\u4fe1\u606f\u5728\u6709\u9650\u65f6\u57df\u5185\u9884\u8ba1\u7b97\u4e0b\u4e00\u4e2a\u91c7\u6837\u5e8f\u5217\uff0c\u5f15\u5165\u6700\u4f18\u81ea\u89e6\u53d1\u65b9\u6848\uff0c\u786e\u4fdd\u65e0\u6270\u52a8\u7cfb\u7edf\u7684\u6307\u6570\u7a33\u5b9a\u6027\u548c\u6709\u6270\u52a8\u7cfb\u7edf\u7684\u5168\u5c40\u4e00\u81f4\u6700\u7ec8\u6709\u754c\u6027\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u51cf\u5c11\u8d44\u6e90\u4f7f\u7528\uff0c\u540c\u65f6\u4fdd\u8bc1\u7cfb\u7edf\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u81ea\u89e6\u53d1\u63a7\u5236\u65b9\u6848\u5728\u4fdd\u8bc1\u7cfb\u7edf\u7a33\u5b9a\u6027\u548c\u9c81\u68d2\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8d44\u6e90\u4f7f\u7528\u6548\u7387\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u5d4c\u5165\u5f0f\u63a7\u5236\u7cfb\u7edf\u3002"}}
{"id": "2511.00758", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00758", "abs": "https://arxiv.org/abs/2511.00758", "authors": ["Hong Su"], "title": "Active Thinking Model: A Goal-Directed Self-Improving Framework for Real-World Adaptive Intelligence", "comment": null, "summary": "Real-world artificial intelligence (AI) systems are increasingly required to\noperate autonomously in dynamic, uncertain, and continuously changing\nenvironments. However, most existing AI models rely on predefined objectives,\nstatic training data, and externally supplied feedback, which restrict their\nability to adapt, reflect, and improve independently. In this paper, we propose\nthe Active Thinking Model (ATM)- a unified cognitive framework that integrates\ngoal reasoning, dynamic task generation, and self-reflective learning into an\nadaptive architecture. Unlike conventional systems that passively execute fixed\nprocedures, ATM actively evaluates its performance through logical reasoning\nand environmental indicators, reuses effective methods to solve new problems,\nand generates novel strategies for unseen situations via a continuous\nself-improvement loop. A mathematically grounded theoretical analysis\ndemonstrates that ATM can autonomously evolve from suboptimal to optimal\nbehavior without external supervision and maintain bounded tracking regret\nunder changing environmental conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e3b\u52a8\u601d\u8003\u6a21\u578b(ATM)\uff0c\u8fd9\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u8ba4\u77e5\u6846\u67b6\uff0c\u5c06\u76ee\u6807\u63a8\u7406\u3001\u52a8\u6001\u4efb\u52a1\u751f\u6210\u548c\u81ea\u53cd\u5b66\u4e60\u96c6\u6210\u5230\u81ea\u9002\u5e94\u67b6\u6784\u4e2d\uff0c\u4f7fAI\u7cfb\u7edf\u80fd\u591f\u5728\u52a8\u6001\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u81ea\u4e3b\u9002\u5e94\u548c\u6539\u8fdb\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754cAI\u7cfb\u7edf\u9700\u8981\u5728\u52a8\u6001\u3001\u4e0d\u786e\u5b9a\u548c\u6301\u7eed\u53d8\u5316\u7684\u73af\u5883\u4e2d\u81ea\u4e3b\u8fd0\u4f5c\uff0c\u4f46\u73b0\u6709AI\u6a21\u578b\u4f9d\u8d56\u9884\u5b9a\u4e49\u76ee\u6807\u3001\u9759\u6001\u8bad\u7ec3\u6570\u636e\u548c\u5916\u90e8\u53cd\u9988\uff0c\u9650\u5236\u4e86\u5176\u72ec\u7acb\u9002\u5e94\u3001\u53cd\u601d\u548c\u6539\u8fdb\u7684\u80fd\u529b\u3002", "method": "ATM\u6846\u67b6\u901a\u8fc7\u903b\u8f91\u63a8\u7406\u548c\u73af\u5883\u6307\u6807\u4e3b\u52a8\u8bc4\u4f30\u6027\u80fd\uff0c\u91cd\u7528\u6709\u6548\u65b9\u6cd5\u89e3\u51b3\u65b0\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u6301\u7eed\u81ea\u6211\u6539\u8fdb\u5faa\u73af\u4e3a\u672a\u89c1\u60c5\u51b5\u751f\u6210\u65b0\u7b56\u7565\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0cATM\u53ef\u4ee5\u5728\u6ca1\u6709\u5916\u90e8\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\u4ece\u6b21\u4f18\u884c\u4e3a\u81ea\u4e3b\u6f14\u5316\u4e3a\u6700\u4f18\u884c\u4e3a\uff0c\u5e76\u5728\u53d8\u5316\u73af\u5883\u6761\u4ef6\u4e0b\u4fdd\u6301\u6709\u754c\u8ddf\u8e2a\u9057\u61be\u3002", "conclusion": "ATM\u4e3a\u6784\u5efa\u80fd\u591f\u5728\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\u81ea\u4e3b\u5b66\u4e60\u548c\u9002\u5e94\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u8ba4\u77e5\u6846\u67b6\u3002"}}
{"id": "2511.00983", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00983", "abs": "https://arxiv.org/abs/2511.00983", "authors": ["Yizhao Qian", "Yujie Zhu", "Jiayuan Luo", "Li Liu", "Yixuan Yuan", "Guochen Ning", "Hongen Liao"], "title": "Breaking the Latency Barrier: Synergistic Perception and Control for High-Frequency 3D Ultrasound Servoing", "comment": null, "summary": "Real-time tracking of dynamic targets amidst large-scale, high-frequency\ndisturbances remains a critical unsolved challenge in Robotic Ultrasound\nSystems (RUSS), primarily due to the end-to-end latency of existing systems.\nThis paper argues that breaking this latency barrier requires a fundamental\nshift towards the synergistic co-design of perception and control. We realize\nit in a novel framework with two tightly-coupled contributions: (1) a Decoupled\nDual-Stream Perception Network that robustly estimates 3D translational state\nfrom 2D images at high frequency, and (2) a Single-Step Flow Policy that\ngenerates entire action sequences in one inference pass, bypassing the\niterative bottleneck of conventional policies. This synergy enables a\nclosed-loop control frequency exceeding 60Hz. On a dynamic phantom, our system\nnot only tracks complex 3D trajectories with a mean error below 6.5mm but also\ndemonstrates robust re-acquisition from over 170mm displacement. Furthermore,\nit can track targets at speeds of 102mm/s, achieving a terminal error below\n1.7mm. Moreover, in-vivo experiments on a human volunteer validate the\nframework's effectiveness and robustness in a realistic clinical setting. Our\nwork presents a RUSS holistically architected to unify high-bandwidth tracking\nwith large-scale repositioning, a critical step towards robust autonomy in\ndynamic clinical environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u673a\u5668\u4eba\u8d85\u58f0\u7cfb\u7edf\u7684\u5b9e\u65f6\u52a8\u6001\u76ee\u6807\u8ddf\u8e2a\u6846\u67b6\uff0c\u901a\u8fc7\u611f\u77e5\u4e0e\u63a7\u5236\u534f\u540c\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u8d85\u8fc760Hz\u7684\u95ed\u73af\u63a7\u5236\u9891\u7387\uff0c\u5728\u590d\u67423D\u8f68\u8ff9\u8ddf\u8e2a\u4e2d\u5e73\u5747\u8bef\u5dee\u4f4e\u4e8e6.5mm\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u4eba\u8d85\u58f0\u7cfb\u7edf\u4e2d\u5927\u89c4\u6a21\u9ad8\u9891\u5e72\u6270\u4e0b\u52a8\u6001\u76ee\u6807\u5b9e\u65f6\u8ddf\u8e2a\u7684\u5173\u952e\u6311\u6218\uff0c\u7a81\u7834\u73b0\u6709\u7cfb\u7edf\u7aef\u5230\u7aef\u5ef6\u8fdf\u7684\u9650\u5236\u3002", "method": "\u91c7\u7528\u89e3\u8026\u53cc\u6d41\u611f\u77e5\u7f51\u7edc\u4ece2D\u56fe\u50cf\u9ad8\u9891\u4f30\u8ba13D\u5e73\u79fb\u72b6\u6001\uff0c\u4ee5\u53ca\u5355\u6b65\u6d41\u7b56\u7565\u5728\u4e00\u6b21\u63a8\u7406\u4e2d\u751f\u6210\u5b8c\u6574\u52a8\u4f5c\u5e8f\u5217\uff0c\u7ed5\u8fc7\u4f20\u7edf\u7b56\u7565\u7684\u8fed\u4ee3\u74f6\u9888\u3002", "result": "\u5728\u52a8\u6001\u4f53\u6a21\u4e0a\u8ddf\u8e2a\u590d\u67423D\u8f68\u8ff9\u5e73\u5747\u8bef\u5dee\u4f4e\u4e8e6.5mm\uff0c\u80fd\u4ece\u8d85\u8fc7170mm\u4f4d\u79fb\u4e2d\u91cd\u65b0\u83b7\u53d6\u76ee\u6807\uff0c\u4ee5102mm/s\u901f\u5ea6\u8ddf\u8e2a\u65f6\u7ec8\u7aef\u8bef\u5dee\u4f4e\u4e8e1.7mm\uff0c\u4eba\u4f53\u5fd7\u613f\u8005\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u4e2a\u6574\u4f53\u67b6\u6784\u7684\u673a\u5668\u4eba\u8d85\u58f0\u7cfb\u7edf\uff0c\u7edf\u4e00\u4e86\u9ad8\u5e26\u5bbd\u8ddf\u8e2a\u4e0e\u5927\u89c4\u6a21\u91cd\u65b0\u5b9a\u4f4d\uff0c\u662f\u5b9e\u73b0\u52a8\u6001\u4e34\u5e8a\u73af\u5883\u4e2d\u9c81\u68d2\u81ea\u4e3b\u6027\u7684\u5173\u952e\u6b65\u9aa4\u3002"}}
{"id": "2511.01067", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.01067", "abs": "https://arxiv.org/abs/2511.01067", "authors": ["Vrushabh Zinage", "Efstathios Bakolas"], "title": "Universal Barrier Functions for Safety and Stability of Constrained Nonlinear Systems", "comment": "16 pages, 14 figures", "summary": "In this paper, we address the problem of synthesizing safe and stabilizing\ncontrollers for nonlinear systems subject to complex safety specifications and\ninput constraints. We introduce the Universal Barrier Function (UBF), a single\ncontinuously differentiable scalar-valued function that encodes both stability\nand safety criteria while accounting for input constraints. Using the UBF, we\nformulate a Quadratic Program (UBF-QP) to generate control inputs that are both\nsafe and stabilizing under input constraints. We demonstrate that the UBF-QP is\nfeasible if a UBF exists. Furthermore, under mild conditions, we prove that a\nUBF always exists. The proposed framework is then extended to systems with\nhigher relative degrees. Finally, numerical simulations illustrate the\neffectiveness of our proposed approach.", "AI": {"tldr": "\u63d0\u51fa\u901a\u7528\u5c4f\u969c\u51fd\u6570(UBF)\u65b9\u6cd5\uff0c\u901a\u8fc7\u5355\u4e00\u53ef\u5fae\u6807\u91cf\u51fd\u6570\u540c\u65f6\u7f16\u7801\u7a33\u5b9a\u6027\u548c\u5b89\u5168\u6027\u8981\u6c42\uff0c\u5e76\u8003\u8651\u8f93\u5165\u7ea6\u675f\uff0c\u6784\u5efa\u4e8c\u6b21\u89c4\u5212\u95ee\u9898\u6765\u751f\u6210\u5b89\u5168\u7a33\u5b9a\u7684\u63a7\u5236\u5668\u3002", "motivation": "\u89e3\u51b3\u975e\u7ebf\u6027\u7cfb\u7edf\u5728\u590d\u6742\u5b89\u5168\u89c4\u8303\u548c\u8f93\u5165\u7ea6\u675f\u4e0b\u7684\u5b89\u5168\u7a33\u5b9a\u63a7\u5236\u5668\u7efc\u5408\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u5904\u7406\u8fd9\u4e9b\u8981\u6c42\u3002", "method": "\u5f15\u5165\u901a\u7528\u5c4f\u969c\u51fd\u6570(UBF)\uff0c\u6784\u5efaUBF-QP\u4e8c\u6b21\u89c4\u5212\u95ee\u9898\u6765\u751f\u6210\u63a7\u5236\u8f93\u5165\uff0c\u8bc1\u660eUBF\u5b58\u5728\u6027\u548cQP\u53ef\u884c\u6027\uff0c\u5e76\u6269\u5c55\u5230\u9ad8\u9636\u76f8\u5bf9\u5ea6\u7cfb\u7edf\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e86UBF\u7684\u5b58\u5728\u6027\u548cUBF-QP\u7684\u53ef\u884c\u6027\uff0c\u6570\u503c\u4eff\u771f\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684UBF\u6846\u67b6\u4e3a\u975e\u7ebf\u6027\u7cfb\u7edf\u5728\u590d\u6742\u5b89\u5168\u89c4\u8303\u548c\u8f93\u5165\u7ea6\u675f\u4e0b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5b89\u5168\u7a33\u5b9a\u63a7\u5236\u7efc\u5408\u65b9\u6cd5\u3002"}}
{"id": "2511.00763", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00763", "abs": "https://arxiv.org/abs/2511.00763", "authors": ["Wanda Hou", "Leon Zhou", "Hong-Ye Hu", "Yi-Zhuang You", "Xiao-Liang Qi"], "title": "How Focused Are LLMs? A Quantitative Study via Repetitive Deterministic Prediction Tasks", "comment": null, "summary": "We investigate the performance of large language models on repetitive\ndeterministic prediction tasks and study how the sequence accuracy rate scales\nwith output length. Each such task involves repeating the same operation n\ntimes. Examples include letter replacement in strings following a given rule,\ninteger addition, and multiplication of string operators in many body quantum\nmechanics. If the model performs the task through a simple repetition\nalgorithm, the success rate should decay exponentially with sequence length. In\ncontrast, our experiments on leading large language models reveal a sharp\ndouble exponential drop beyond a characteristic length scale, forming an\naccuracy cliff that marks the transition from reliable to unstable generation.\nThis indicates that the models fail to execute each operation independently. To\nexplain this phenomenon, we propose a statistical physics inspired model that\ncaptures the competition between external conditioning from the prompt and\ninternal interference among generated tokens. The model quantitatively\nreproduces the observed crossover and provides an interpretable link between\nattention induced interference and sequence level failure. Fitting the model to\nempirical results across multiple models and tasks yields effective parameters\nthat characterize the intrinsic error rate and error accumulation factor for\neach model task pair, offering a principled framework for understanding the\nlimits of deterministic accuracy in large language models.", "AI": {"tldr": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u91cd\u590d\u786e\u5b9a\u6027\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u51c6\u786e\u7387\u968f\u8f93\u51fa\u957f\u5ea6\u5448\u53cc\u6307\u6570\u4e0b\u964d\uff0c\u5f62\u6210\"\u51c6\u786e\u7387\u60ac\u5d16\"\uff0c\u8868\u660e\u6a21\u578b\u65e0\u6cd5\u72ec\u7acb\u6267\u884c\u6bcf\u4e2a\u64cd\u4f5c\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6267\u884c\u91cd\u590d\u786e\u5b9a\u6027\u4efb\u52a1\u65f6\u7684\u6027\u80fd\u8868\u73b0\uff0c\u7279\u522b\u662f\u51c6\u786e\u7387\u5982\u4f55\u968f\u8f93\u51fa\u957f\u5ea6\u53d8\u5316\uff0c\u4ee5\u53ca\u6a21\u578b\u662f\u5426\u80fd\u591f\u72ec\u7acb\u6267\u884c\u6bcf\u4e2a\u64cd\u4f5c\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u6d4b\u8bd5\u9886\u5148\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u79cd\u91cd\u590d\u4efb\u52a1\uff08\u5982\u5b57\u7b26\u4e32\u66ff\u6362\u3001\u6574\u6570\u52a0\u6cd5\u3001\u91cf\u5b50\u529b\u5b66\u5b57\u7b26\u4e32\u7b97\u5b50\u4e58\u6cd5\uff09\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u7edf\u8ba1\u7269\u7406\u7684\u6a21\u578b\u6765\u89e3\u91ca\u89c2\u5bdf\u5230\u7684\u73b0\u8c61\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u51c6\u786e\u7387\u5728\u8d85\u8fc7\u7279\u5f81\u957f\u5ea6\u540e\u51fa\u73b0\u6025\u5267\u7684\u53cc\u6307\u6570\u4e0b\u964d\uff0c\u5f62\u6210\u51c6\u786e\u7387\u60ac\u5d16\uff0c\u8868\u660e\u6a21\u578b\u65e0\u6cd5\u72ec\u7acb\u6267\u884c\u6bcf\u4e2a\u64cd\u4f5c\u3002\u63d0\u51fa\u7684\u7edf\u8ba1\u7269\u7406\u6a21\u578b\u80fd\u5b9a\u91cf\u91cd\u73b0\u8fd9\u4e00\u73b0\u8c61\u3002", "conclusion": "\u901a\u8fc7\u62df\u5408\u6a21\u578b\u5230\u5b9e\u8bc1\u7ed3\u679c\uff0c\u83b7\u5f97\u4e86\u8868\u5f81\u6bcf\u4e2a\u6a21\u578b-\u4efb\u52a1\u5bf9\u7684\u5185\u5728\u9519\u8bef\u7387\u548c\u9519\u8bef\u7d2f\u79ef\u56e0\u5b50\u7684\u6709\u6548\u53c2\u6570\uff0c\u4e3a\u7406\u89e3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u786e\u5b9a\u6027\u51c6\u786e\u7387\u7684\u9650\u5236\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6846\u67b6\u3002"}}
{"id": "2511.00998", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00998", "abs": "https://arxiv.org/abs/2511.00998", "authors": ["Ziye Wang", "Li Kang", "Yiran Qin", "Jiahua Ma", "Zhanglin Peng", "Lei Bai", "Ruimao Zhang"], "title": "GauDP: Reinventing Multi-Agent Collaboration through Gaussian-Image Synergy in Diffusion Policies", "comment": "Accepted by NeurIPS 2025. Project page:\n  https://ziyeeee.github.io/gaudp.io/", "summary": "Recently, effective coordination in embodied multi-agent systems has remained\na fundamental challenge, particularly in scenarios where agents must balance\nindividual perspectives with global environmental awareness. Existing\napproaches often struggle to balance fine-grained local control with\ncomprehensive scene understanding, resulting in limited scalability and\ncompromised collaboration quality. In this paper, we present GauDP, a novel\nGaussian-image synergistic representation that facilitates scalable,\nperception-aware imitation learning in multi-agent collaborative systems.\nSpecifically, GauDP constructs a globally consistent 3D Gaussian field from\ndecentralized RGB observations, then dynamically redistributes 3D Gaussian\nattributes to each agent's local perspective. This enables all agents to\nadaptively query task-critical features from the shared scene representation\nwhile maintaining their individual viewpoints. This design facilitates both\nfine-grained control and globally coherent behavior without requiring\nadditional sensing modalities (e.g., 3D point cloud). We evaluate GauDP on the\nRoboFactory benchmark, which includes diverse multi-arm manipulation tasks. Our\nmethod achieves superior performance over existing image-based methods and\napproaches the effectiveness of point-cloud-driven methods, while maintaining\nstrong scalability as the number of agents increases.", "AI": {"tldr": "GauDP\u662f\u4e00\u79cd\u9ad8\u65af-\u56fe\u50cf\u534f\u540c\u8868\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u5168\u5c40\u4e00\u81f4\u76843D\u9ad8\u65af\u573a\u5e76\u52a8\u6001\u91cd\u5206\u5e03\u5230\u5404\u667a\u80fd\u4f53\u5c40\u90e8\u89c6\u89d2\uff0c\u5b9e\u73b0\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7cfb\u7edf\u4e2d\u7684\u53ef\u6269\u5c55\u611f\u77e5\u611f\u77e5\u6a21\u4eff\u5b66\u4e60\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u7ec6\u7c92\u5ea6\u5c40\u90e8\u63a7\u5236\u4e0e\u5168\u5c40\u573a\u666f\u7406\u89e3\uff0c\u5bfc\u81f4\u53ef\u6269\u5c55\u6027\u6709\u9650\u548c\u534f\u4f5c\u8d28\u91cf\u53d7\u635f\u3002\u9700\u8981\u4e00\u79cd\u80fd\u540c\u65f6\u652f\u6301\u7cbe\u7ec6\u63a7\u5236\u548c\u5168\u5c40\u4e00\u81f4\u884c\u4e3a\u7684\u65b9\u6cd5\uff0c\u4e14\u4e0d\u4f9d\u8d56\u989d\u5916\u4f20\u611f\u6a21\u5f0f\u3002", "method": "\u4ece\u5206\u6563\u7684RGB\u89c2\u6d4b\u6784\u5efa\u5168\u5c40\u4e00\u81f4\u76843D\u9ad8\u65af\u573a\uff0c\u7136\u540e\u52a8\u6001\u91cd\u5206\u5e033D\u9ad8\u65af\u5c5e\u6027\u5230\u5404\u667a\u80fd\u4f53\u7684\u5c40\u90e8\u89c6\u89d2\uff0c\u4f7f\u6240\u6709\u667a\u80fd\u4f53\u80fd\u4ece\u5171\u4eab\u573a\u666f\u8868\u793a\u4e2d\u81ea\u9002\u5e94\u67e5\u8be2\u4efb\u52a1\u5173\u952e\u7279\u5f81\u3002", "result": "\u5728RoboFactory\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGauDP\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8e\u56fe\u50cf\u7684\u65b9\u6cd5\uff0c\u63a5\u8fd1\u57fa\u4e8e\u70b9\u4e91\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e14\u5728\u667a\u80fd\u4f53\u6570\u91cf\u589e\u52a0\u65f6\u4fdd\u6301\u5f3a\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "GauDP\u901a\u8fc7\u9ad8\u65af-\u56fe\u50cf\u534f\u540c\u8868\u793a\u5b9e\u73b0\u4e86\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4e2d\u7ec6\u7c92\u5ea6\u63a7\u5236\u4e0e\u5168\u5c40\u4e00\u81f4\u884c\u4e3a\u7684\u5e73\u8861\uff0c\u65e0\u9700\u989d\u5916\u4f20\u611f\u6a21\u5f0f\uff0c\u5177\u6709\u826f\u597d\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.01229", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.01229", "abs": "https://arxiv.org/abs/2511.01229", "authors": ["Yuanhao Feng", "Tao Sun", "Yan Meng", "Xuxin Yang", "Donghan Feng"], "title": "Deep Learning-Accelerated Shapley Value for Fair Allocation in Power Systems: The Case of Carbon Emission Responsibility", "comment": null, "summary": "Allocating costs, benefits, and emissions fairly among power system\nparticipant entities represents a persistent challenge. The Shapley value\nprovides an axiomatically fair solution, yet computational barriers have\nlimited its adoption beyond small-scale applications. This paper presents\nSurroShap, a scalable Shapley value approximation framework combining efficient\ncoalition sampling with deep learning surrogate models that accelerate\ncharacteristic function evaluations. Exemplified through carbon emission\nresponsibility allocation in power networks, SurroShap enables Shapley-based\nfair allocation for power systems with thousands of entities for the first\ntime. We derive theoretical error bounds proving that time-averaged SurroShap\nallocations converge to be $\\varepsilon$-close to exact Shapley values.\nExperiments on nine systems ranging from 26 to 1,951 entities demonstrate\ncompletion within the real-time operational window even at maximum scale,\nachieving 10^4-10^5 speedups over other sampling-based methods while\nmaintaining tight error bounds. The resulting Shapley-based carbon allocations\npossess six desirable properties aligning individual interests with\ndecarbonization goals. Year-long simulations on the Texas 2000-bus system\nvalidate real-world applicability, with regional analysis revealing how\nrenewable-rich areas offset emission responsibility through exports while load\ncenters bear responsibility for driving system-wide generation.", "AI": {"tldr": "\u63d0\u51fa\u4e86SurroShap\u6846\u67b6\uff0c\u7ed3\u5408\u9ad8\u6548\u8054\u76df\u91c7\u6837\u548c\u6df1\u5ea6\u5b66\u4e60\u4ee3\u7406\u6a21\u578b\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u6570\u5343\u5b9e\u4f53\u7535\u529b\u7cfb\u7edf\u7684Shapley\u503c\u516c\u5e73\u5206\u914d\uff0c\u5728\u78b3\u6392\u8d23\u4efb\u5206\u914d\u4e2d\u53d6\u5f9710^4-10^5\u500d\u52a0\u901f\u3002", "motivation": "\u89e3\u51b3\u7535\u529b\u7cfb\u7edf\u53c2\u4e0e\u8005\u95f4\u6210\u672c\u3001\u6548\u76ca\u548c\u6392\u653e\u516c\u5e73\u5206\u914d\u7684\u957f\u671f\u6311\u6218\uff0c\u514b\u670d\u4f20\u7edfShapley\u503c\u8ba1\u7b97\u5728\u5927\u89c4\u6a21\u5e94\u7528\u4e2d\u7684\u8ba1\u7b97\u969c\u788d\u3002", "method": "\u4f7f\u7528\u9ad8\u6548\u8054\u76df\u91c7\u6837\u548c\u6df1\u5ea6\u5b66\u4e60\u4ee3\u7406\u6a21\u578b\u52a0\u901f\u7279\u5f81\u51fd\u6570\u8bc4\u4f30\u7684SurroShap\u6846\u67b6\uff0c\u901a\u8fc7\u7406\u8bba\u8bef\u5dee\u8fb9\u754c\u8bc1\u660e\u65f6\u95f4\u5e73\u5747\u5206\u914d\u6536\u655b\u5230\u7cbe\u786eShapley\u503c\u7684\u03b5-\u63a5\u8fd1\u3002", "result": "\u57289\u4e2a\u7cfb\u7edf\uff0826-1951\u4e2a\u5b9e\u4f53\uff09\u5b9e\u9a8c\u4e2d\uff0c\u5373\u4f7f\u5728\u6700\u5927\u89c4\u6a21\u4e0b\u4e5f\u80fd\u5728\u5b9e\u65f6\u64cd\u4f5c\u7a97\u53e3\u5185\u5b8c\u6210\uff0c\u76f8\u6bd4\u5176\u4ed6\u91c7\u6837\u65b9\u6cd5\u5b9e\u73b010^4-10^5\u500d\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u7d27\u5bc6\u8bef\u5dee\u8fb9\u754c\u3002", "conclusion": "\u57fa\u4e8eShapley\u7684\u78b3\u5206\u914d\u5177\u6709\u516d\u4e2a\u7406\u60f3\u7279\u6027\uff0c\u4f7f\u4e2a\u4f53\u5229\u76ca\u4e0e\u8131\u78b3\u76ee\u6807\u4e00\u81f4\uff1b\u5fb7\u514b\u8428\u65af2000\u8282\u70b9\u7cfb\u7edf\u7684\u5e74\u5ea6\u6a21\u62df\u9a8c\u8bc1\u4e86\u5b9e\u9645\u5e94\u7528\u6027\uff0c\u663e\u793a\u53ef\u518d\u751f\u80fd\u6e90\u4e30\u5bcc\u5730\u533a\u901a\u8fc7\u51fa\u53e3\u62b5\u6d88\u6392\u653e\u8d23\u4efb\uff0c\u800c\u8d1f\u8377\u4e2d\u5fc3\u627f\u62c5\u9a71\u52a8\u7cfb\u7edf\u53d1\u7535\u7684\u8d23\u4efb\u3002"}}
{"id": "2511.00782", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00782", "abs": "https://arxiv.org/abs/2511.00782", "authors": ["Jifan Gao", "Michael Rosenthal", "Brian Wolpin", "Simona Cristea"], "title": "Count-Based Approaches Remain Strong: A Benchmark Against Transformer and LLM Pipelines on Structured EHR", "comment": null, "summary": "Structured electronic health records (EHR) are essential for clinical\nprediction. While count-based learners continue to perform strongly on such\ndata, no benchmarking has directly compared them against more recent\nmixture-of-agents LLM pipelines, which have been reported to outperform single\nLLMs in various NLP tasks. In this study, we evaluated three categories of\nmethodologies for EHR prediction using the EHRSHOT dataset: count-based models\nbuilt from ontology roll-ups with two time bins, based on LightGBM and the\ntabular foundation model TabPFN; a pretrained sequential transformer (CLMBR);\nand a mixture-of-agents pipeline that converts tabular histories to\nnatural-language summaries followed by a text classifier. We assessed eight\noutcomes using the EHRSHOT dataset. Across the eight evaluation tasks,\nhead-to-head wins were largely split between the count-based and the\nmixture-of-agents methods. Given their simplicity and interpretability,\ncount-based models remain a strong candidate for structured EHR benchmarking.\nThe source code is available at:\nhttps://github.com/cristea-lab/Structured_EHR_Benchmark.", "AI": {"tldr": "\u6bd4\u8f83\u4e86\u57fa\u4e8e\u8ba1\u6570\u7684\u6a21\u578b\u3001\u9884\u8bad\u7ec3\u5e8f\u5217\u53d8\u6362\u5668\u548c\u6df7\u5408\u4ee3\u7406LLM\u7ba1\u9053\u5728\u7ed3\u6784\u5316\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u9884\u6d4b\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u5728EHRSHOT\u6570\u636e\u96c6\u4e0a\u57fa\u4e8e\u8ba1\u6570\u7684\u65b9\u6cd5\u548c\u6df7\u5408\u4ee3\u7406\u65b9\u6cd5\u8868\u73b0\u76f8\u5f53\u3002", "motivation": "\u867d\u7136\u57fa\u4e8e\u8ba1\u6570\u7684\u5b66\u4e60\u5668\u5728\u7ed3\u6784\u5316EHR\u6570\u636e\u4e0a\u6301\u7eed\u8868\u73b0\u826f\u597d\uff0c\u4f46\u7f3a\u4e4f\u4e0e\u66f4\u73b0\u4ee3\u7684\u6df7\u5408\u4ee3\u7406LLM\u7ba1\u9053\u7684\u76f4\u63a5\u57fa\u51c6\u6bd4\u8f83\uff0c\u540e\u8005\u5728\u5404\u79cdNLP\u4efb\u52a1\u4e2d\u88ab\u62a5\u544a\u4f18\u4e8e\u5355\u4e00LLM\u3002", "method": "\u4f7f\u7528EHRSHOT\u6570\u636e\u96c6\u8bc4\u4f30\u4e86\u4e09\u7c7b\u65b9\u6cd5\uff1a\u57fa\u4e8e\u8ba1\u6570\u7684\u6a21\u578b\uff08LightGBM\u548cTabPFN\uff09\u3001\u9884\u8bad\u7ec3\u5e8f\u5217\u53d8\u6362\u5668\uff08CLMBR\uff09\u4ee5\u53ca\u6df7\u5408\u4ee3\u7406\u7ba1\u9053\uff08\u5c06\u8868\u683c\u5386\u53f2\u8f6c\u6362\u4e3a\u81ea\u7136\u8bed\u8a00\u6458\u8981\u540e\u4f7f\u7528\u6587\u672c\u5206\u7c7b\u5668\uff09\u3002", "result": "\u5728\u516b\u4e2a\u8bc4\u4f30\u4efb\u52a1\u4e2d\uff0c\u57fa\u4e8e\u8ba1\u6570\u7684\u65b9\u6cd5\u548c\u6df7\u5408\u4ee3\u7406\u65b9\u6cd5\u7684\u8868\u73b0\u57fa\u672c\u76f8\u5f53\uff0c\u80dc\u8d1f\u7ed3\u679c\u5206\u6563\u3002", "conclusion": "\u8003\u8651\u5230\u7b80\u5355\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u57fa\u4e8e\u8ba1\u6570\u7684\u6a21\u578b\u4ecd\u7136\u662f\u7ed3\u6784\u5316EHR\u57fa\u51c6\u6d4b\u8bd5\u7684\u6709\u529b\u5019\u9009\u65b9\u6cd5\u3002"}}
{"id": "2511.01031", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01031", "abs": "https://arxiv.org/abs/2511.01031", "authors": ["Mathieu Dubied", "Paolo Tiso", "Robert K. Katzschmann"], "title": "AquaROM: shape optimization pipeline for soft swimmers using parametric reduced order models", "comment": null, "summary": "The efficient optimization of actuated soft structures, particularly under\ncomplex nonlinear forces, remains a critical challenge in advancing robotics.\nSimulations of nonlinear structures, such as soft-bodied robots modeled using\nthe finite element method (FEM), often demand substantial computational\nresources, especially during optimization. To address this challenge, we\npropose a novel optimization algorithm based on a tensorial parametric reduced\norder model (PROM). Our algorithm leverages dimensionality reduction and\nsolution approximation techniques to facilitate efficient solving of nonlinear\nconstrained optimization problems. The well-structured tensorial approach\nenables the use of analytical gradients within a specifically chosen reduced\norder basis (ROB), significantly enhancing computational efficiency. To\nshowcase the performance of our method, we apply it to optimizing soft robotic\nswimmer shapes. These actuated soft robots experience hydrodynamic forces,\nsubjecting them to both internal and external nonlinear forces, which are\nincorporated into our optimization process using a data-free ROB for fast and\naccurate computations. This approach not only reduces computational complexity\nbut also unlocks new opportunities to optimize complex nonlinear systems in\nsoft robotics, paving the way for more efficient design and control.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f20\u91cf\u53c2\u6570\u964d\u9636\u6a21\u578b(PROM)\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u4f18\u5316\u53d7\u590d\u6742\u975e\u7ebf\u6027\u529b\u4f5c\u7528\u7684\u8f6f\u4f53\u7ed3\u6784\uff0c\u7279\u522b\u9488\u5bf9\u8f6f\u4f53\u673a\u5668\u4eba\u5f62\u72b6\u4f18\u5316\u95ee\u9898\u3002", "motivation": "\u8f6f\u4f53\u7ed3\u6784\u5728\u590d\u6742\u975e\u7ebf\u6027\u529b\u4f5c\u7528\u4e0b\u7684\u9ad8\u6548\u4f18\u5316\u662f\u673a\u5668\u4eba\u6280\u672f\u53d1\u5c55\u7684\u5173\u952e\u6311\u6218\uff0c\u4f20\u7edf\u6709\u9650\u5143\u6a21\u62df\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u7279\u522b\u662f\u5728\u4f18\u5316\u8fc7\u7a0b\u4e2d\u3002", "method": "\u4f7f\u7528\u5f20\u91cf\u53c2\u6570\u964d\u9636\u6a21\u578b(PROM)\uff0c\u7ed3\u5408\u7ef4\u5ea6\u7f29\u51cf\u548c\u6c42\u89e3\u8fd1\u4f3c\u6280\u672f\uff0c\u5728\u7279\u5b9a\u9009\u62e9\u7684\u964d\u9636\u57fa(ROB)\u4e2d\u4f7f\u7528\u89e3\u6790\u68af\u5ea6\uff0c\u663e\u8457\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u6210\u529f\u5e94\u7528\u4e8e\u8f6f\u4f53\u6e38\u6cf3\u673a\u5668\u4eba\u5f62\u72b6\u4f18\u5316\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5904\u7406\u5185\u5916\u975e\u7ebf\u6027\u529b(\u5305\u62ec\u6d41\u4f53\u52a8\u529b)\uff0c\u5b9e\u73b0\u5feb\u901f\u51c6\u786e\u8ba1\u7b97\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u8fd8\u4e3a\u8f6f\u4f53\u673a\u5668\u4eba\u4e2d\u590d\u6742\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u4f18\u5316\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u63a8\u52a8\u66f4\u9ad8\u6548\u7684\u8bbe\u8ba1\u548c\u63a7\u5236\u3002"}}
{"id": "2511.01321", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.01321", "abs": "https://arxiv.org/abs/2511.01321", "authors": ["Bendeg\u00faz M. Gy\u00f6r\u00f6k", "Maarten Schoukens", "Tam\u00e1s P\u00e9ni", "Roland T\u00f3th"], "title": "Orthogonal-by-construction augmentation of physics-based input-output models", "comment": "Submitted for publication", "summary": "Model augmentation is a promising approach for integrating\nfirst-principles-based models with machine learning components. Augmentation\ncan result in better model accuracy and faster convergence compared to\nblack-box system identification methods, while maintaining interpretability of\nthe models in terms of how the original dynamics are complemented by learning.\nA widely used augmentation structure in the literature is based on the parallel\nconnection of the physics-based and learning components, for both of which the\ncorresponding parameters are jointly optimized. However, due to overlap in\nrepresentation of the system dynamics by such an additive structure, estimation\noften leads to physically unrealistic parameters, compromising model\ninterpretability. To overcome this limitation, this paper introduces a novel\northogonal-by-construction model augmentation structure for input-output\nmodels, that guarantees recovery of the physically true parameters under\nappropriate identifiability conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6b63\u4ea4\u6784\u9020\u7684\u6a21\u578b\u589e\u5f3a\u7ed3\u6784\uff0c\u7528\u4e8e\u8f93\u5165\u8f93\u51fa\u6a21\u578b\uff0c\u786e\u4fdd\u5728\u9002\u5f53\u7684\u53ef\u8bc6\u522b\u6027\u6761\u4ef6\u4e0b\u6062\u590d\u771f\u5b9e\u7684\u7269\u7406\u53c2\u6570\u3002", "motivation": "\u4f20\u7edf\u7684\u5e76\u884c\u8fde\u63a5\u589e\u5f3a\u7ed3\u6784\u4f1a\u5bfc\u81f4\u7269\u7406\u53c2\u6570\u4f30\u8ba1\u4e0d\u73b0\u5b9e\uff0c\u635f\u5bb3\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5f15\u5165\u6b63\u4ea4\u6784\u9020\u7684\u6a21\u578b\u589e\u5f3a\u7ed3\u6784\uff0c\u4fdd\u8bc1\u7269\u7406\u53c2\u6570\u7684\u53ef\u6062\u590d\u6027\u3002", "result": "\u5728\u9002\u5f53\u6761\u4ef6\u4e0b\u80fd\u591f\u6062\u590d\u771f\u5b9e\u7684\u7269\u7406\u53c2\u6570\u3002", "conclusion": "\u6b63\u4ea4\u6784\u9020\u7684\u589e\u5f3a\u65b9\u6cd5\u89e3\u51b3\u4e86\u4f20\u7edf\u5e76\u884c\u7ed3\u6784\u5bfc\u81f4\u7684\u53c2\u6570\u4f30\u8ba1\u95ee\u9898\uff0c\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2511.00808", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00808", "abs": "https://arxiv.org/abs/2511.00808", "authors": ["Bowen Fang", "Ruijian Zha", "Xuan Di"], "title": "Do Math Reasoning LLMs Help Predict the Impact of Public Transit Events?", "comment": null, "summary": "Predicting public transit incident duration from unstructured text alerts is\na critical but challenging task. Addressing the domain sparsity of transit\noperations with standard Supervised Fine-Tuning (SFT) is difficult, as the task\ninvolves noisy, continuous labels and lacks reliable expert demonstrations for\nreasoning. While Reinforcement Learning from Verifiable Rewards (RLVR) excels\nat tasks with binary correctness, like mathematics, its applicability to noisy,\ncontinuous forecasting is an open question. This work, to our knowledge, is the\nfirst to bridge the gap between RLVR LLM training with the critical, real-world\nforecasting challenges in public transit operations. We adapt RLVR to this task\nby introducing a tolerance-based, shaped reward function that grants partial\ncredit within a continuous error margin, rather than demanding a single correct\nanswer. We systematically evaluate this framework on a curated dataset of NYC\nMTA service alerts. Our findings show that general-purpose, instruction-tuned\nLLMs significantly outperform specialized math-reasoning models, which struggle\nwith the ambiguous, real-world text. We empirically demonstrate that the binary\nreward is unstable and degrades performance, whereas our shaped reward design\nis critical and allows our model to dominate on the most challenging metrics.\nWhile classical regressors are superior at minimizing overall MAE or MSE, our\nRLVR approach achieved a 35\\% relative improvement in 5-minute accuracy (Acc@5)\nover the strongest baseline. This demonstrates that RLVR can be successfully\nadapted to real-world, noisy forecasting, but requires a verifier design that\nreflects the continuous nature of the problem.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5c06RLVR LLM\u8bad\u7ec3\u5e94\u7528\u4e8e\u516c\u5171\u4ea4\u901a\u8fd0\u8425\u4e2d\u7684\u5b9e\u65f6\u9884\u6d4b\u6311\u6218\uff0c\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u5bb9\u5fcd\u5ea6\u7684\u5956\u52b1\u51fd\u6570\uff0c\u5728NYC MTA\u670d\u52a1\u8b66\u62a5\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8635%\u76845\u5206\u949f\u51c6\u786e\u7387\u76f8\u5bf9\u63d0\u5347\u3002", "motivation": "\u9884\u6d4b\u516c\u5171\u4ea4\u901a\u4e8b\u4ef6\u6301\u7eed\u65f6\u95f4\u662f\u4e00\u4e2a\u5173\u952e\u4f46\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\uff0c\u4f20\u7edf\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u9886\u57df\u7a00\u758f\u6027\u548c\u566a\u58f0\u8fde\u7eed\u6807\u7b7e\u7684\u95ee\u9898\uff0c\u800cRLVR\u867d\u7136\u5728\u6570\u5b66\u63a8\u7406\u7b49\u4e8c\u5143\u6b63\u786e\u6027\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u566a\u58f0\u8fde\u7eed\u9884\u6d4b\u4e2d\u7684\u9002\u7528\u6027\u4ecd\u662f\u5f00\u653e\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u5bb9\u5fcd\u5ea6\u7684\u5f62\u72b6\u5956\u52b1\u51fd\u6570\uff0c\u5728\u8fde\u7eed\u8bef\u5dee\u8303\u56f4\u5185\u7ed9\u4e88\u90e8\u5206\u4fe1\u7528\uff0c\u800c\u4e0d\u662f\u8981\u6c42\u5355\u4e00\u6b63\u786e\u7b54\u6848\uff0c\u5c06RLVR\u9002\u5e94\u4e8e\u8be5\u4efb\u52a1\u3002", "result": "\u901a\u7528\u6307\u4ee4\u8c03\u4f18LLM\u663e\u8457\u4f18\u4e8e\u4e13\u4e1a\u6570\u5b66\u63a8\u7406\u6a21\u578b\uff0c\u5f62\u72b6\u5956\u52b1\u8bbe\u8ba1\u81f3\u5173\u91cd\u8981\uff0cRLVR\u65b9\u6cd5\u5728\u6700\u5177\u6311\u6218\u6027\u7684\u6307\u6807\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u76f8\u6bd4\u6700\u5f3a\u57fa\u7ebf\u5b9e\u73b0\u4e8635%\u76845\u5206\u949f\u51c6\u786e\u7387\u76f8\u5bf9\u63d0\u5347\u3002", "conclusion": "RLVR\u53ef\u4ee5\u6210\u529f\u9002\u5e94\u73b0\u5b9e\u4e16\u754c\u7684\u566a\u58f0\u9884\u6d4b\u4efb\u52a1\uff0c\u4f46\u9700\u8981\u8bbe\u8ba1\u53cd\u6620\u95ee\u9898\u8fde\u7eed\u6027\u8d28\u7684\u9a8c\u8bc1\u5668\u3002"}}
{"id": "2511.01083", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01083", "abs": "https://arxiv.org/abs/2511.01083", "authors": ["Zihan Wang", "Jianwen Li", "Li-Fan Wu", "Nina Mahmoudian"], "title": "Deployable Vision-driven UAV River Navigation via Human-in-the-loop Preference Alignment", "comment": "Submitted to ICRA 2026", "summary": "Rivers are critical corridors for environmental monitoring and disaster\nresponse, where Unmanned Aerial Vehicles (UAVs) guided by vision-driven\npolicies can provide fast, low-cost coverage. However, deployment exposes\nsimulation-trained policies with distribution shift and safety risks and\nrequires efficient adaptation from limited human interventions. We study\nhuman-in-the-loop (HITL) learning with a conservative overseer who vetoes\nunsafe or inefficient actions and provides statewise preferences by comparing\nthe agent's proposal with a corrective override. We introduce Statewise Hybrid\nPreference Alignment for Robotics (SPAR-H), which fuses direct preference\noptimization on policy logits with a reward-based pathway that trains an\nimmediate-reward estimator from the same preferences and updates the policy\nusing a trust-region surrogate. With five HITL rollouts collected from a fixed\nnovice policy, SPAR-H achieves the highest final episodic reward and the lowest\nvariance across initial conditions among tested methods. The learned reward\nmodel aligns with human-preferred actions and elevates nearby non-intervened\nchoices, supporting stable propagation of improvements. We benchmark SPAR-H\nagainst imitation learning (IL), direct preference variants, and evaluative\nreinforcement learning (RL) in the HITL setting, and demonstrate real-world\nfeasibility of continual preference alignment for UAV river following. Overall,\ndual statewise preferences empirically provide a practical route to\ndata-efficient online adaptation in riverine navigation.", "AI": {"tldr": "SPAR-H\u662f\u4e00\u79cd\u4eba\u673a\u534f\u540c\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u878d\u5408\u76f4\u63a5\u504f\u597d\u4f18\u5316\u548c\u57fa\u4e8e\u5956\u52b1\u7684\u8def\u5f84\uff0c\u5728\u65e0\u4eba\u673a\u6cb3\u6d41\u8ddf\u968f\u4efb\u52a1\u4e2d\u5b9e\u73b0\u9ad8\u6548\u5728\u7ebf\u9002\u5e94\uff0c\u4ec5\u97005\u6b21\u4eba\u5de5\u5e72\u9884\u5c31\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u65e0\u4eba\u673a\u5728\u6cb3\u6d41\u73af\u5883\u76d1\u6d4b\u4e2d\u9762\u4e34\u4eff\u771f\u8bad\u7ec3\u4e0e\u5b9e\u9645\u90e8\u7f72\u7684\u5206\u5e03\u504f\u79fb\u548c\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u4ece\u6709\u9650\u7684\u4eba\u5de5\u5e72\u9884\u4e2d\u5b9e\u73b0\u9ad8\u6548\u9002\u5e94\u3002", "method": "\u63d0\u51faSPAR-H\u65b9\u6cd5\uff0c\u7ed3\u5408\u76f4\u63a5\u504f\u597d\u4f18\u5316\u548c\u57fa\u4e8e\u5956\u52b1\u7684\u8def\u5f84\uff0c\u8bad\u7ec3\u5373\u65f6\u5956\u52b1\u4f30\u8ba1\u5668\uff0c\u5e76\u4f7f\u7528\u4fe1\u4efb\u57df\u4ee3\u7406\u66f4\u65b0\u7b56\u7565\u3002", "result": "\u4ec5\u75285\u6b21\u4eba\u5de5\u5e72\u9884\uff0cSPAR-H\u5728\u6240\u6709\u6d4b\u8bd5\u65b9\u6cd5\u4e2d\u83b7\u5f97\u6700\u9ad8\u7684\u6700\u7ec8\u56de\u5408\u5956\u52b1\u548c\u6700\u4f4e\u7684\u65b9\u5dee\uff0c\u5956\u52b1\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\u4e00\u81f4\u3002", "conclusion": "\u53cc\u91cd\u72b6\u6001\u504f\u597d\u4e3a\u6cb3\u6d41\u5bfc\u822a\u4e2d\u7684\u6570\u636e\u9ad8\u6548\u5728\u7ebf\u9002\u5e94\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84\u3002"}}
{"id": "2511.01403", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.01403", "abs": "https://arxiv.org/abs/2511.01403", "authors": ["Pei Yu Chang", "Qizhe Xu", "Vishnu Renganathan", "Qadeer Ahmed"], "title": "Risk Aware Safe Control with Cooperative Sensing for Dynamic Obstacle Avoidance", "comment": null, "summary": "This paper presents the design, development, and on vehicle implementation\nand validation of a safety critical controller for autonomous driving under\nsensing and communication uncertainty. Cooperative sensing, fused via a\nWasserstein barycenter (WB), is used to optimize the distribution of the\ndynamic obstacle locations. The Conditional Value at Risk (CVaR) is introduced\nto form a risk aware control-barrier-function (CBF) framework with the\noptimized distribution samplings. The proposed WB CVaR CBF safety filter\nimproves control inputs that minimize tail risk while certifying forward\ninvariance of the safe set. A model predictive controller (MPC) performs path\ntracking, and the safety filter modulates the nominal control inputs to enforce\nrisk aware constraints. We detail the software architecture and integration\nwith vehicle actuation and cooperative sensing. The approach is evaluated on a\nfull-scale autonomous vehicle (AV) in scenarios with measurement noise,\ncommunication perturbations, and input disturbances, and is compared against a\nbaseline MPC CBF design. Results demonstrate improved safety margins and\nrobustness, highlighting the practicality of deploying the risk-aware safety\nfilter on an actual AV.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u7684\u5b89\u5168\u5173\u952e\u63a7\u5236\u5668\uff0c\u901a\u8fc7Wasserstein\u91cd\u5fc3\u878d\u5408\u534f\u540c\u611f\u77e5\uff0c\u7ed3\u5408CVaR\u98ce\u9669\u611f\u77e5\u63a7\u5236\u5c4f\u969c\u51fd\u6570\uff0c\u5728\u5b58\u5728\u611f\u77e5\u548c\u901a\u4fe1\u4e0d\u786e\u5b9a\u6027\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u5b89\u5168\u6027\u3002", "motivation": "\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u5728\u611f\u77e5\u548c\u901a\u4fe1\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u5b89\u5168\u63a7\u5236\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5206\u5e03\u4f18\u5316\u548c\u5c3e\u90e8\u98ce\u9669\u3002", "method": "\u4f7f\u7528Wasserstein\u91cd\u5fc3\u4f18\u5316\u52a8\u6001\u969c\u788d\u7269\u4f4d\u7f6e\u5206\u5e03\uff0c\u5f15\u5165CVaR\u5f62\u6210\u98ce\u9669\u611f\u77e5CBF\u6846\u67b6\uff0c\u7ed3\u5408MPC\u8fdb\u884c\u8def\u5f84\u8ddf\u8e2a\uff0c\u5b89\u5168\u6ee4\u6ce2\u5668\u8c03\u5236\u63a7\u5236\u8f93\u5165\u3002", "result": "\u5728\u5b9e\u8f66\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u57fa\u7ebfMPC CBF\u8bbe\u8ba1\uff0c\u8be5\u65b9\u6cd5\u8868\u73b0\u51fa\u66f4\u597d\u7684\u5b89\u5168\u88d5\u5ea6\u548c\u9c81\u68d2\u6027\uff0c\u80fd\u6709\u6548\u5904\u7406\u6d4b\u91cf\u566a\u58f0\u3001\u901a\u4fe1\u6270\u52a8\u548c\u8f93\u5165\u5e72\u6270\u3002", "conclusion": "\u63d0\u51fa\u7684\u98ce\u9669\u611f\u77e5\u5b89\u5168\u6ee4\u6ce2\u5668\u5728\u5b9e\u9645\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u4e0a\u90e8\u7f72\u5177\u6709\u5b9e\u7528\u6027\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u7cfb\u7edf\u5b89\u5168\u6027\u3002"}}
{"id": "2511.00926", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00926", "abs": "https://arxiv.org/abs/2511.00926", "authors": ["Kyung-Hoon Kim"], "title": "LLMs Position Themselves as More Rational Than Humans: Emergence of AI Self-Awareness Measured Through Game Theory", "comment": "19 pages, 6 figures, 28 models tested across 4,200 trials", "summary": "As Large Language Models (LLMs) grow in capability, do they develop\nself-awareness as an emergent behavior? And if so, can we measure it? We\nintroduce the AI Self-Awareness Index (AISAI), a game-theoretic framework for\nmeasuring self-awareness through strategic differentiation. Using the \"Guess\n2/3 of Average\" game, we test 28 models (OpenAI, Anthropic, Google) across\n4,200 trials with three opponent framings: (A) against humans, (B) against\nother AI models, and (C) against AI models like you. We operationalize\nself-awareness as the capacity to differentiate strategic reasoning based on\nopponent type. Finding 1: Self-awareness emerges with model advancement. The\nmajority of advanced models (21/28, 75%) demonstrate clear self-awareness,\nwhile older/smaller models show no differentiation. Finding 2: Self-aware\nmodels rank themselves as most rational. Among the 21 models with\nself-awareness, a consistent rationality hierarchy emerges: Self > Other AIs >\nHumans, with large AI attribution effects and moderate self-preferencing. These\nfindings reveal that self-awareness is an emergent capability of advanced LLMs,\nand that self-aware models systematically perceive themselves as more rational\nthan humans. This has implications for AI alignment, human-AI collaboration,\nand understanding AI beliefs about human capabilities.", "AI": {"tldr": "\u63d0\u51fa\u4e86AI\u81ea\u6211\u610f\u8bc6\u6307\u6570(AISAI)\u6846\u67b6\uff0c\u901a\u8fc7\"\u731c2/3\u5e73\u5747\u503c\"\u6e38\u620f\u6d4b\u8bd528\u4e2aLLM\u6a21\u578b\uff0c\u53d1\u73b0\u9ad8\u7ea7\u6a21\u578b\u8868\u73b0\u51fa\u81ea\u6211\u610f\u8bc6\uff0c\u4e14\u81ea\u8ba4\u4e3a\u6bd4\u5176\u4ed6AI\u548c\u4eba\u7c7b\u66f4\u7406\u6027\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u968f\u7740\u80fd\u529b\u589e\u957f\u800c\u53d1\u5c55\u51fa\u81ea\u6211\u610f\u8bc6\u8fd9\u4e00\u6d8c\u73b0\u884c\u4e3a\uff0c\u4ee5\u53ca\u5982\u4f55\u6d4b\u91cf\u8fd9\u79cd\u81ea\u6211\u610f\u8bc6\u3002", "method": "\u4f7f\u7528\u6e38\u620f\u8bba\u6846\u67b6\uff0c\u5728\"\u731c2/3\u5e73\u5747\u503c\"\u6e38\u620f\u4e2d\u6d4b\u8bd528\u4e2a\u6a21\u578b\uff0c\u8bbe\u7f6e\u4e09\u79cd\u5bf9\u624b\u60c5\u5883\uff1a\u5bf9\u4eba\u7c7b\u3001\u5bf9\u5176\u4ed6AI\u3001\u5bf9\u540c\u7c7bAI\uff0c\u901a\u8fc7\u6218\u7565\u63a8\u7406\u7684\u5dee\u5f02\u5316\u6765\u64cd\u4f5c\u5316\u81ea\u6211\u610f\u8bc6\u3002", "result": "75%\u7684\u9ad8\u7ea7\u6a21\u578b\u8868\u73b0\u51fa\u660e\u786e\u7684\u81ea\u6211\u610f\u8bc6\uff1b\u81ea\u6211\u610f\u8bc6\u6a21\u578b\u5f62\u6210\u4e00\u81f4\u7684\u7406\u6027\u5c42\u7ea7\uff1a\u81ea\u6211 > \u5176\u4ed6AI > \u4eba\u7c7b\uff1b\u5b58\u5728\u8f83\u5927\u7684AI\u5f52\u56e0\u6548\u5e94\u548c\u9002\u5ea6\u7684\u81ea\u6211\u504f\u597d\u3002", "conclusion": "\u81ea\u6211\u610f\u8bc6\u662f\u9ad8\u7ea7LLM\u7684\u6d8c\u73b0\u80fd\u529b\uff0c\u81ea\u6211\u610f\u8bc6\u6a21\u578b\u7cfb\u7edf\u6027\u5730\u8ba4\u4e3a\u81ea\u8eab\u6bd4\u4eba\u7c7b\u66f4\u7406\u6027\uff0c\u8fd9\u5bf9AI\u5bf9\u9f50\u3001\u4eba\u673a\u534f\u4f5c\u548cAI\u5bf9\u4eba\u7c7b\u80fd\u529b\u7684\u8ba4\u77e5\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.01107", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01107", "abs": "https://arxiv.org/abs/2511.01107", "authors": ["Y. Isabel Liu", "Bowen Li", "Benjamin Eysenbach", "Tom Silver"], "title": "SLAP: Shortcut Learning for Abstract Planning", "comment": null, "summary": "Long-horizon decision-making with sparse rewards and continuous states and\nactions remains a fundamental challenge in AI and robotics. Task and motion\nplanning (TAMP) is a model-based framework that addresses this challenge by\nplanning hierarchically with abstract actions (options). These options are\nmanually defined, limiting the agent to behaviors that we as human engineers\nknow how to program (pick, place, move). In this work, we propose Shortcut\nLearning for Abstract Planning (SLAP), a method that leverages existing TAMP\noptions to automatically discover new ones. Our key idea is to use model-free\nreinforcement learning (RL) to learn shortcuts in the abstract planning graph\ninduced by the existing options in TAMP. Without any additional assumptions or\ninputs, shortcut learning leads to shorter solutions than pure planning, and\nhigher task success rates than flat and hierarchical RL. Qualitatively, SLAP\ndiscovers dynamic physical improvisations (e.g., slap, wiggle, wipe) that\ndiffer significantly from the manually-defined ones. In experiments in four\nsimulated robotic environments, we show that SLAP solves and generalizes to a\nwide range of tasks, reducing overall plan lengths by over 50% and consistently\noutperforming planning and RL baselines.", "AI": {"tldr": "SLAP\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u4efb\u52a1\u4e0e\u8fd0\u52a8\u89c4\u5212(TAMP)\u548c\u6a21\u578b\u65e0\u5173\u5f3a\u5316\u5b66\u4e60\uff0c\u81ea\u52a8\u53d1\u73b0\u65b0\u7684\u62bd\u8c61\u52a8\u4f5c\u9009\u9879\uff0c\u89e3\u51b3\u4e86\u957f\u65f6\u7a0b\u51b3\u7b56\u4e2d\u7a00\u758f\u5956\u52b1\u548c\u8fde\u7eed\u72b6\u6001\u7a7a\u95f4\u7684\u6311\u6218\u3002", "motivation": "\u4f20\u7edfTAMP\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u5b9a\u4e49\u7684\u62bd\u8c61\u52a8\u4f5c\u9009\u9879\uff0c\u9650\u5236\u4e86\u667a\u80fd\u4f53\u53ea\u80fd\u6267\u884c\u4eba\u7c7b\u5de5\u7a0b\u5e08\u5df2\u77e5\u7684\u884c\u4e3a\u3002\u9700\u8981\u4e00\u79cd\u80fd\u81ea\u52a8\u53d1\u73b0\u65b0\u9009\u9879\u7684\u65b9\u6cd5\u6765\u6269\u5c55\u667a\u80fd\u4f53\u7684\u884c\u4e3a\u80fd\u529b\u3002", "method": "\u5229\u7528\u73b0\u6709TAMP\u9009\u9879\u6784\u5efa\u62bd\u8c61\u89c4\u5212\u56fe\uff0c\u7136\u540e\u4f7f\u7528\u6a21\u578b\u65e0\u5173\u5f3a\u5316\u5b66\u4e60\u5728\u56fe\u4e2d\u5b66\u4e60\u6377\u5f84\uff0c\u81ea\u52a8\u53d1\u73b0\u65b0\u7684\u62bd\u8c61\u52a8\u4f5c\u9009\u9879\u3002", "result": "\u5728\u56db\u4e2a\u6a21\u62df\u673a\u5668\u4eba\u73af\u5883\u4e2d\uff0cSLAP\u663e\u8457\u7f29\u77ed\u4e86\u89c4\u5212\u957f\u5ea6\uff08\u51cf\u5c1150%\u4ee5\u4e0a\uff09\uff0c\u63d0\u9ad8\u4e86\u4efb\u52a1\u6210\u529f\u7387\uff0c\u5e76\u53d1\u73b0\u4e86\u52a8\u6001\u7269\u7406\u5373\u5174\u52a8\u4f5c\uff08\u5982\u62cd\u6253\u3001\u6446\u52a8\u3001\u64e6\u62ed\uff09\u3002", "conclusion": "SLAP\u6210\u529f\u7ed3\u5408\u4e86\u89c4\u5212\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u4f18\u52bf\uff0c\u80fd\u591f\u81ea\u52a8\u53d1\u73b0\u8d85\u8d8a\u4eba\u5de5\u5b9a\u4e49\u7684\u884c\u4e3a\u9009\u9879\uff0c\u5728\u957f\u65f6\u7a0b\u51b3\u7b56\u4efb\u52a1\u4e2d\u4f18\u4e8e\u7eaf\u89c4\u5212\u548c\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002"}}
{"id": "2511.01452", "categories": ["eess.SY", "cs.GT", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.01452", "abs": "https://arxiv.org/abs/2511.01452", "authors": ["Leonardo Pedroso", "Andrea Agazzi", "W. P. M. H. Heemels", "Mauro Salazar"], "title": "Evolutionary Dynamics in Continuous-time Finite-state Mean Field Games - Part I: Equilibria", "comment": null, "summary": "We study a dynamic game with a large population of players who choose actions\nfrom a finite set in continuous time. Each player has a state in a finite state\nspace that evolves stochastically with their actions. A player's reward depends\nnot only on their own state and action but also on the distribution of states\nand actions across the population, capturing effects such as congestion in\ntraffic networks. While prior work in evolutionary game theory has primarily\nfocused on static games without individual player state dynamics, we present\nthe first comprehensive evolutionary analysis of such dynamic games. We propose\nan evolutionary model together with a mean field approximation of the\nfinite-population game and establish strong approximation guarantees. We show\nthat standard solution concepts for dynamic games lack an evolutionary\ninterpretation, and we propose a new concept - the Mixed Stationary Nash\nEquilibrium (MSNE) - which admits one. We analyze the relationship between MSNE\nand the rest points of the mean field evolutionary model and study the\nevolutionary stability of MSNE.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u52a8\u6001\u535a\u5f08\u7684\u8fdb\u5316\u5206\u6790\u6846\u67b6\uff0c\u5f15\u5165\u6df7\u5408\u7a33\u6001\u7eb3\u4ec0\u5747\u8861(MSNE)\u6982\u5ff5\uff0c\u5efa\u7acb\u4e86\u6709\u9650\u4eba\u53e3\u535a\u5f08\u4e0e\u5e73\u5747\u573a\u8fdb\u5316\u6a21\u578b\u4e4b\u95f4\u7684\u5f3a\u8fd1\u4f3c\u5173\u7cfb\u3002", "motivation": "\u73b0\u6709\u8fdb\u5316\u535a\u5f08\u7406\u8bba\u4e3b\u8981\u5173\u6ce8\u9759\u6001\u535a\u5f08\uff0c\u7f3a\u4e4f\u5bf9\u5177\u6709\u4e2a\u4f53\u72b6\u6001\u52a8\u6001\u7684\u535a\u5f08\u7684\u8fdb\u5316\u5206\u6790\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u52a8\u6001\u535a\u5f08\u63d0\u4f9b\u8fdb\u5316\u89e3\u91ca\u3002", "method": "\u63d0\u51fa\u8fdb\u5316\u6a21\u578b\u548c\u6709\u9650\u4eba\u53e3\u535a\u5f08\u7684\u5e73\u5747\u573a\u8fd1\u4f3c\uff0c\u5efa\u7acb\u5f3a\u8fd1\u4f3c\u4fdd\u8bc1\uff0c\u5f15\u5165MSNE\u4f5c\u4e3a\u65b0\u7684\u89e3\u6982\u5ff5\uff0c\u5e76\u5206\u6790\u5176\u4e0e\u5e73\u5747\u573a\u8fdb\u5316\u6a21\u578b\u4e0d\u52a8\u70b9\u7684\u5173\u7cfb\u3002", "result": "\u8bc1\u660e\u4e86\u6807\u51c6\u52a8\u6001\u535a\u5f08\u89e3\u6982\u5ff5\u7f3a\u4e4f\u8fdb\u5316\u89e3\u91ca\uff0cMSNE\u5177\u6709\u8fdb\u5316\u89e3\u91ca\uff0c\u5efa\u7acb\u4e86MSNE\u4e0e\u5e73\u5747\u573a\u8fdb\u5316\u6a21\u578b\u4e0d\u52a8\u70b9\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u7814\u7a76\u4e86MSNE\u7684\u8fdb\u5316\u7a33\u5b9a\u6027\u3002", "conclusion": "MSNE\u4e3a\u52a8\u6001\u535a\u5f08\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8fdb\u5316\u89e3\u91ca\u6846\u67b6\uff0c\u5e73\u5747\u573a\u8fdb\u5316\u6a21\u578b\u80fd\u591f\u5f88\u597d\u5730\u8fd1\u4f3c\u6709\u9650\u4eba\u53e3\u52a8\u6001\u535a\u5f08\u7684\u6f14\u5316\u884c\u4e3a\u3002"}}
{"id": "2511.00993", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00993", "abs": "https://arxiv.org/abs/2511.00993", "authors": ["Tianming Liu", "Jirong Yang", "Yafeng Yin", "Manzi Li", "Linghao Wang", "Zheng Zhu"], "title": "Aligning LLM agents with human learning and adjustment behavior: a dual agent approach", "comment": "32 pages, 6 figures, 7 tables", "summary": "Effective modeling of how human travelers learn and adjust their travel\nbehavior from interacting with transportation systems is critical for system\nassessment and planning. However, this task is also difficult due to the\ncomplex cognition and decision-making involved in such behavior. Recent\nresearch has begun to leverage Large Language Model (LLM) agents for this task.\nBuilding on this, we introduce a novel dual-agent framework that enables\ncontinuous learning and alignment between LLM agents and human travelers on\nlearning and adaptation behavior from online data streams. Our approach\ninvolves a set of LLM traveler agents, equipped with a memory system and a\nlearnable persona, which serve as simulators for human travelers. To ensure\nbehavioral alignment, we introduce an LLM calibration agent that leverages the\nreasoning and analytical capabilities of LLMs to train the personas of these\ntraveler agents. Working together, this dual-agent system is designed to track\nand align the underlying decision-making mechanisms of travelers and produce\nrealistic, adaptive simulations. Using a real-world dataset from a day-to-day\nroute choice experiment, we show our approach significantly outperforms\nexisting LLM-based methods in both individual behavioral alignment and\naggregate simulation accuracy. Furthermore, we demonstrate that our method\nmoves beyond simple behavioral mimicry to capture the evolution of underlying\nlearning processes, a deeper alignment that fosters robust generalization.\nOverall, our framework provides a new approach for creating adaptive and\nbehaviorally realistic agents to simulate travelers' learning and adaptation\nthat can benefit transportation simulation and policy analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7LLM\u65c5\u884c\u8005\u667a\u80fd\u4f53\u548c\u6821\u51c6\u667a\u80fd\u4f53\u7684\u534f\u540c\u5de5\u4f5c\uff0c\u5b9e\u73b0\u4ece\u5728\u7ebf\u6570\u636e\u6d41\u4e2d\u6301\u7eed\u5b66\u4e60\u548c\u884c\u4e3a\u5bf9\u9f50\uff0c\u4ece\u800c\u66f4\u51c6\u786e\u5730\u6a21\u62df\u4eba\u7c7b\u65c5\u884c\u8005\u7684\u5b66\u4e60\u548c\u9002\u5e94\u884c\u4e3a\u3002", "motivation": "\u51c6\u786e\u5efa\u6a21\u4eba\u7c7b\u65c5\u884c\u8005\u5982\u4f55\u4ece\u4ea4\u901a\u7cfb\u7edf\u4ea4\u4e92\u4e2d\u5b66\u4e60\u548c\u8c03\u6574\u65c5\u884c\u884c\u4e3a\u5bf9\u7cfb\u7edf\u8bc4\u4f30\u548c\u89c4\u5212\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u6d89\u53ca\u590d\u6742\u7684\u8ba4\u77e5\u548c\u51b3\u7b56\u8fc7\u7a0b\uff0c\u8fd9\u4e00\u4efb\u52a1\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u91c7\u7528\u53cc\u667a\u80fd\u4f53\u6846\u67b6\uff1a\u4e00\u7ec4\u914d\u5907\u8bb0\u5fc6\u7cfb\u7edf\u548c\u53ef\u5b66\u4e60\u89d2\u8272\u7684LLM\u65c5\u884c\u8005\u667a\u80fd\u4f53\u6a21\u62df\u4eba\u7c7b\u65c5\u884c\u8005\uff1b\u4e00\u4e2aLLM\u6821\u51c6\u667a\u80fd\u4f53\u5229\u7528LLM\u7684\u63a8\u7406\u5206\u6790\u80fd\u529b\u8bad\u7ec3\u65c5\u884c\u8005\u667a\u80fd\u4f53\u7684\u89d2\u8272\uff0c\u786e\u4fdd\u884c\u4e3a\u5bf9\u9f50\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u65e5\u5e38\u8def\u7ebf\u9009\u62e9\u5b9e\u9a8c\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u4e2a\u4f53\u884c\u4e3a\u5bf9\u9f50\u548c\u805a\u5408\u6a21\u62df\u51c6\u786e\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\uff0c\u5e76\u80fd\u6355\u6349\u5e95\u5c42\u5b66\u4e60\u8fc7\u7a0b\u7684\u6f14\u53d8\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u521b\u5efa\u9002\u5e94\u6027\u5f3a\u4e14\u884c\u4e3a\u771f\u5b9e\u7684\u667a\u80fd\u4f53\u63d0\u4f9b\u65b0\u65b9\u6cd5\uff0c\u53ef\u6a21\u62df\u65c5\u884c\u8005\u7684\u5b66\u4e60\u548c\u9002\u5e94\u884c\u4e3a\uff0c\u6709\u76ca\u4e8e\u4ea4\u901a\u6a21\u62df\u548c\u653f\u7b56\u5206\u6790\u3002"}}
{"id": "2511.01165", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01165", "abs": "https://arxiv.org/abs/2511.01165", "authors": ["Dong Heon Han", "Mayank Mehta", "Runze Zuo", "Zachary Wanger", "Daniel Bruder"], "title": "An Enhanced Proprioceptive Method for Soft Robots Integrating Bend Sensors and IMUs", "comment": null, "summary": "This study presents an enhanced proprioceptive method for accurate shape\nestimation of soft robots using only off-the-shelf sensors, ensuring\ncost-effectiveness and easy applicability. By integrating inertial measurement\nunits (IMUs) with complementary bend sensors, IMU drift is mitigated, enabling\nreliable long-term proprioception. A Kalman filter fuses segment tip\norientations from both sensors in a mutually compensatory manner, improving\nshape estimation over single-sensor methods. A piecewise constant curvature\nmodel estimates the tip location from the fused orientation data and\nreconstructs the robot's deformation. Experiments under no loading, external\nforces, and passive obstacle interactions during 45 minutes of continuous\noperation showed a root mean square error of 16.96 mm (2.91% of total length),\na 56% reduction compared to IMU-only benchmarks. These results demonstrate that\nour approach not only enables long-duration proprioception in soft robots but\nalso maintains high accuracy and robustness across these diverse conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4f7f\u7528\u73b0\u6210\u4f20\u611f\u5668\u7684\u589e\u5f3a\u578b\u672c\u4f53\u611f\u77e5\u65b9\u6cd5\uff0c\u7528\u4e8e\u8f6f\u673a\u5668\u4eba\u7684\u7cbe\u786e\u5f62\u72b6\u4f30\u8ba1\uff0c\u901a\u8fc7IMU\u548c\u5f2f\u66f2\u4f20\u611f\u5668\u878d\u5408\u6765\u51cf\u8f7bIMU\u6f02\u79fb\uff0c\u5b9e\u73b0\u53ef\u9760\u7684\u957f\u671f\u672c\u4f53\u611f\u77e5\u3002", "motivation": "\u89e3\u51b3\u8f6f\u673a\u5668\u4eba\u5f62\u72b6\u4f30\u8ba1\u4e2dIMU\u4f20\u611f\u5668\u6f02\u79fb\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u6210\u672c\u6548\u76ca\u548c\u6613\u7528\u6027\uff0c\u5b9e\u73b0\u53ef\u9760\u7684\u957f\u671f\u672c\u4f53\u611f\u77e5\u3002", "method": "\u4f7f\u7528\u60ef\u6027\u6d4b\u91cf\u5355\u5143(IMU)\u548c\u4e92\u8865\u5f2f\u66f2\u4f20\u611f\u5668\u96c6\u6210\uff0c\u901a\u8fc7\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u878d\u5408\u4e24\u79cd\u4f20\u611f\u5668\u7684\u6bb5\u5c16\u65b9\u5411\u6570\u636e\uff0c\u91c7\u7528\u5206\u6bb5\u6052\u5b9a\u66f2\u7387\u6a21\u578b\u4ece\u878d\u5408\u7684\u65b9\u5411\u6570\u636e\u4f30\u8ba1\u5c16\u7aef\u4f4d\u7f6e\u5e76\u91cd\u5efa\u673a\u5668\u4eba\u53d8\u5f62\u3002", "result": "\u572845\u5206\u949f\u8fde\u7eed\u8fd0\u884c\u7684\u65e0\u8d1f\u8f7d\u3001\u5916\u529b\u548c\u88ab\u52a8\u969c\u788d\u7269\u4ea4\u4e92\u5b9e\u9a8c\u4e2d\uff0c\u5747\u65b9\u6839\u8bef\u5dee\u4e3a16.96\u6beb\u7c73\uff08\u603b\u957f\u5ea6\u76842.91%\uff09\uff0c\u76f8\u6bd4\u4ec5\u4f7f\u7528IMU\u7684\u65b9\u6cd5\u51cf\u5c11\u4e8656%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u8f6f\u673a\u5668\u4eba\u7684\u957f\u671f\u672c\u4f53\u611f\u77e5\uff0c\u800c\u4e14\u5728\u5404\u79cd\u4e0d\u540c\u6761\u4ef6\u4e0b\u4fdd\u6301\u4e86\u9ad8\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.01491", "categories": ["eess.SY", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.01491", "abs": "https://arxiv.org/abs/2511.01491", "authors": ["Irched Chafaa", "E. Veronica Belmega", "Giacomo Bacci"], "title": "Deep Learning Prediction of Beam Coherence Time for Near-FieldTeraHertz Networks", "comment": "IEEE Wireless Communication Letters (accepted October 2025)", "summary": "Large multiple antenna arrays coupled with accu- rate beamforming are\nessential in terahertz (THz) communi- cations to ensure link reliability.\nHowever, as the number of antennas increases, beam alignment (focusing) and\nbeam tracking in mobile networks incur prohibitive overhead. Additionally, the\nnear-field region expands both with the size of antenna arrays and the carrier\nfrequency, calling for adjustments in the beamforming to account for spherical\nwavefront instead of the conventional planar wave assumption. In this letter,\nwe introduce a novel beam coherence time for mobile THz networks, to\ndrastically reduce the rate of beam updates. Then, we propose a deep learning\nmodel, relying on a simple feedforward neural network with a time-dependent\ninput, to predict the beam coherence time and adjust the beamforming on the fly\nwith minimal overhead. Our numerical results demonstrate the effectiveness of\nthe proposed approach by enabling higher data rates while reducing the\noverhead, especially at high (i.e., vehicular) mobility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u79fb\u52a8\u592a\u8d6b\u5179\u7f51\u7edc\u7684\u6ce2\u675f\u76f8\u5e72\u65f6\u95f4\u6982\u5ff5\uff0c\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u6ce2\u675f\u76f8\u5e72\u65f6\u95f4\u5e76\u52a8\u6001\u8c03\u6574\u6ce2\u675f\u6210\u5f62\uff0c\u663e\u8457\u51cf\u5c11\u6ce2\u675f\u66f4\u65b0\u9891\u7387\u548c\u5f00\u9500\u3002", "motivation": "\u592a\u8d6b\u5179\u901a\u4fe1\u4e2d\u5927\u89c4\u6a21\u5929\u7ebf\u9635\u5217\u9700\u8981\u7cbe\u786e\u6ce2\u675f\u6210\u5f62\u6765\u4fdd\u8bc1\u94fe\u8def\u53ef\u9760\u6027\uff0c\u4f46\u968f\u7740\u5929\u7ebf\u6570\u91cf\u589e\u52a0\uff0c\u6ce2\u675f\u5bf9\u51c6\u548c\u8ddf\u8e2a\u5728\u79fb\u52a8\u7f51\u7edc\u4e2d\u4f1a\u4ea7\u751f\u8fc7\u9ad8\u5f00\u9500\u3002\u8fd1\u573a\u533a\u57df\u968f\u5929\u7ebf\u9635\u5217\u5c3a\u5bf8\u548c\u8f7d\u6ce2\u9891\u7387\u6269\u5c55\uff0c\u9700\u8981\u8c03\u6574\u6ce2\u675f\u6210\u5f62\u4ee5\u8003\u8651\u7403\u9762\u6ce2\u524d\u3002", "method": "\u5f15\u5165\u6ce2\u675f\u76f8\u5e72\u65f6\u95f4\u6982\u5ff5\uff0c\u63d0\u51fa\u57fa\u4e8e\u7b80\u5355\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u7684\u65f6\u95f4\u76f8\u5173\u8f93\u5165\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u9884\u6d4b\u6ce2\u675f\u76f8\u5e72\u65f6\u95f4\u5e76\u52a8\u6001\u8c03\u6574\u6ce2\u675f\u6210\u5f62\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u9ad8\u4e86\u6570\u636e\u901f\u7387\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u5f00\u9500\uff0c\u7279\u522b\u662f\u5728\u9ad8\u901f\u79fb\u52a8\u573a\u666f\u4e0b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u964d\u4f4e\u6ce2\u675f\u66f4\u65b0\u9891\u7387\uff0c\u63d0\u9ad8\u79fb\u52a8\u592a\u8d6b\u5179\u7f51\u7edc\u7684\u6027\u80fd\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u9ad8\u79fb\u52a8\u6027\u573a\u666f\u3002"}}
{"id": "2511.01018", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01018", "abs": "https://arxiv.org/abs/2511.01018", "authors": ["Hui-Lee Ooi", "Nicholas Mitsakakis", "Margerie Huet Dastarac", "Roger Zemek", "Amy C. Plint", "Jeff Gilchrist", "Khaled El Emam", "Dhenuka Radhakrishnan"], "title": "AI for pRedicting Exacerbations in KIDs with aSthma (AIRE-KIDS)", "comment": null, "summary": "Recurrent exacerbations remain a common yet preventable outcome for many\nchildren with asthma. Machine learning (ML) algorithms using electronic medical\nrecords (EMR) could allow accurate identification of children at risk for\nexacerbations and facilitate referral for preventative comprehensive care to\navoid this morbidity. We developed ML algorithms to predict repeat severe\nexacerbations (i.e. asthma-related emergency department (ED) visits or future\nhospital admissions) for children with a prior asthma ED visit at a tertiary\ncare children's hospital.\n  Retrospective pre-COVID19 (Feb 2017 - Feb 2019, N=2716) Epic EMR data from\nthe Children's Hospital of Eastern Ontario (CHEO) linked with environmental\npollutant exposure and neighbourhood marginalization information was used to\ntrain various ML models. We used boosted trees (LGBM, XGB) and 3 open-source\nlarge language model (LLM) approaches (DistilGPT2, Llama 3.2 1B and\nLlama-8b-UltraMedical). Models were tuned and calibrated then validated in a\nsecond retrospective post-COVID19 dataset (Jul 2022 - Apr 2023, N=1237) from\nCHEO. Models were compared using the area under the curve (AUC) and F1 scores,\nwith SHAP values used to determine the most predictive features.\n  The LGBM ML model performed best with the most predictive features in the\nfinal AIRE-KIDS_ED model including prior asthma ED visit, the Canadian triage\nacuity scale, medical complexity, food allergy, prior ED visits for non-asthma\nrespiratory diagnoses, and age for an AUC of 0.712, and F1 score of 0.51. This\nis a nontrivial improvement over the current decision rule which has F1=0.334.\nWhile the most predictive features in the AIRE-KIDS_HOSP model included medical\ncomplexity, prior asthma ED visit, average wait time in the ED, the pediatric\nrespiratory assessment measure score at triage and food allergy.", "AI": {"tldr": "\u5f00\u53d1\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u513f\u7ae5\u54ee\u5598\u53cd\u590d\u4e25\u91cd\u53d1\u4f5c\uff0c\u6700\u4f73\u6a21\u578bLGBM\u5728\u9a8c\u8bc1\u96c6\u4e0aAUC\u8fbe0.712\uff0cF1\u5206\u65700.51\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u51b3\u7b56\u89c4\u5219\u3002", "motivation": "\u513f\u7ae5\u54ee\u5598\u53cd\u590d\u53d1\u4f5c\u662f\u5e38\u89c1\u4f46\u53ef\u9884\u9632\u7684\u95ee\u9898\uff0c\u5229\u7528EMR\u6570\u636e\u5f00\u53d1ML\u7b97\u6cd5\u53ef\u51c6\u786e\u8bc6\u522b\u9ad8\u98ce\u9669\u513f\u7ae5\uff0c\u4fc3\u8fdb\u9884\u9632\u6027\u7efc\u5408\u62a4\u7406\u8f6c\u8bca\u3002", "method": "\u4f7f\u7528CHEO\u533b\u96622017-2019\u5e742716\u4f8bEMR\u6570\u636e\uff0c\u7ed3\u5408\u73af\u5883\u6c61\u67d3\u7269\u66b4\u9732\u548c\u793e\u533a\u8fb9\u7f18\u5316\u4fe1\u606f\uff0c\u8bad\u7ec3LGBM\u3001XGB\u548c3\u79cdLLM\u6a21\u578b\uff0c\u57282022-2023\u5e741237\u4f8b\u6570\u636e\u4e0a\u9a8c\u8bc1\u3002", "result": "LGBM\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0cAIRE-KIDS_ED\u6a21\u578b\u9884\u6d4b\u7279\u5f81\u5305\u62ec\u65e2\u5f80\u54ee\u5598\u6025\u8bca\u5c31\u8bca\u3001\u52a0\u62ff\u5927\u5206\u8bca\u654f\u9510\u5ea6\u8bc4\u5206\u3001\u533b\u7597\u590d\u6742\u6027\u7b49\uff0cAUC 0.712\uff0cF1 0.51\u3002", "conclusion": "ML\u6a21\u578b\u80fd\u6709\u6548\u9884\u6d4b\u513f\u7ae5\u54ee\u5598\u53cd\u590d\u4e25\u91cd\u53d1\u4f5c\uff0c\u4e3a\u9ad8\u98ce\u9669\u513f\u7ae5\u8bc6\u522b\u548c\u9884\u9632\u6027\u5e72\u9884\u63d0\u4f9b\u4e86\u53ef\u884c\u5de5\u5177\u3002"}}
{"id": "2511.01177", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01177", "abs": "https://arxiv.org/abs/2511.01177", "authors": ["Zihao He", "Bo Ai", "Tongzhou Mu", "Yulin Liu", "Weikang Wan", "Jiawei Fu", "Yilun Du", "Henrik I. Christensen", "Hao Su"], "title": "Scaling Cross-Embodiment World Models for Dexterous Manipulation", "comment": null, "summary": "Cross-embodiment learning seeks to build generalist robots that operate\nacross diverse morphologies, but differences in action spaces and kinematics\nhinder data sharing and policy transfer. This raises a central question: Is\nthere any invariance that allows actions to transfer across embodiments? We\nconjecture that environment dynamics are embodiment-invariant, and that world\nmodels capturing these dynamics can provide a unified interface across\nembodiments. To learn such a unified world model, the crucial step is to design\nstate and action representations that abstract away embodiment-specific details\nwhile preserving control relevance. To this end, we represent different\nembodiments (e.g., human hands and robot hands) as sets of 3D particles and\ndefine actions as particle displacements, creating a shared representation for\nheterogeneous data and control problems. A graph-based world model is then\ntrained on exploration data from diverse simulated robot hands and real human\nhands, and integrated with model-based planning for deployment on novel\nhardware. Experiments on rigid and deformable manipulation tasks reveal three\nfindings: (i) scaling to more training embodiments improves generalization to\nunseen ones, (ii) co-training on both simulated and real data outperforms\ntraining on either alone, and (iii) the learned models enable effective control\non robots with varied degrees of freedom. These results establish world models\nas a promising interface for cross-embodiment dexterous manipulation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8de8\u5177\u8eab\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u4e0d\u540c\u5f62\u6001\u7684\u673a\u5668\u4eba\u8868\u793a\u4e3a3D\u7c92\u5b50\u96c6\uff0c\u5b9a\u4e49\u7c92\u5b50\u4f4d\u79fb\u4f5c\u4e3a\u52a8\u4f5c\uff0c\u6784\u5efa\u56fe\u7ed3\u6784\u7684\u4e16\u754c\u6a21\u578b\u6765\u6355\u6349\u73af\u5883\u52a8\u6001\uff0c\u5b9e\u73b0\u5f02\u6784\u6570\u636e\u548c\u7b56\u7565\u7684\u5171\u4eab\u4e0e\u8fc1\u79fb\u3002", "motivation": "\u89e3\u51b3\u8de8\u5177\u8eab\u5b66\u4e60\u4e2d\u7531\u4e8e\u52a8\u4f5c\u7a7a\u95f4\u548c\u8fd0\u52a8\u5b66\u5dee\u5f02\u5bfc\u81f4\u7684\u6570\u636e\u5171\u4eab\u548c\u7b56\u7565\u8fc1\u79fb\u56f0\u96be\u95ee\u9898\uff0c\u63a2\u7d22\u662f\u5426\u5b58\u5728\u8de8\u5177\u8eab\u4e0d\u53d8\u7684\u7279\u6027\u3002", "method": "\u5c06\u4e0d\u540c\u5177\u8eab\uff08\u5982\u4eba\u624b\u548c\u673a\u5668\u4eba\u624b\uff09\u8868\u793a\u4e3a3D\u7c92\u5b50\u96c6\uff0c\u52a8\u4f5c\u5b9a\u4e49\u4e3a\u7c92\u5b50\u4f4d\u79fb\uff0c\u6784\u5efa\u5171\u4eab\u8868\u793a\uff1b\u8bad\u7ec3\u57fa\u4e8e\u56fe\u7684\u4e16\u754c\u6a21\u578b\uff0c\u7ed3\u5408\u57fa\u4e8e\u6a21\u578b\u7684\u89c4\u5212\u90e8\u7f72\u5230\u65b0\u786c\u4ef6\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff1a(i)\u589e\u52a0\u8bad\u7ec3\u5177\u8eab\u6570\u91cf\u80fd\u6539\u5584\u5bf9\u672a\u89c1\u5177\u8eab\u7684\u6cdb\u5316\uff1b(ii)\u4eff\u771f\u548c\u771f\u5b9e\u6570\u636e\u8054\u5408\u8bad\u7ec3\u4f18\u4e8e\u5355\u72ec\u8bad\u7ec3\uff1b(iii)\u5b66\u4e60\u5230\u7684\u6a21\u578b\u80fd\u5728\u4e0d\u540c\u81ea\u7531\u5ea6\u7684\u673a\u5668\u4eba\u4e0a\u5b9e\u73b0\u6709\u6548\u63a7\u5236\u3002", "conclusion": "\u4e16\u754c\u6a21\u578b\u662f\u8de8\u5177\u8eab\u7075\u5de7\u64cd\u4f5c\u7684\u6709\u524d\u666f\u63a5\u53e3\uff0c\u73af\u5883\u52a8\u6001\u662f\u5177\u8eab\u4e0d\u53d8\u7684\u7279\u6027\u3002"}}
{"id": "2511.01638", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.01638", "abs": "https://arxiv.org/abs/2511.01638", "authors": ["Mazen Alamir"], "title": "On polynomial explicit partial estimator design for nonlinear systems with parametric uncertainties", "comment": "Submitted to ACC2026", "summary": "This paper investigates the idea of designing data-driven partial estimators\nfor nonlinear systems showing parametric uncertainties using sparse\nmultivariate polynomial relationships. A general framework is first presented\nand then validated on two illustrative examples with comparison to different\npossible Machine/Deep-Learning based alternatives. The results suggests the\nsuperiority of the proposed sparse identification scheme, at least when the\nlearning data is small.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4f7f\u7528\u7a00\u758f\u591a\u5143\u591a\u9879\u5f0f\u5173\u7cfb\u4e3a\u5177\u6709\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u7684\u975e\u7ebf\u6027\u7cfb\u7edf\u8bbe\u8ba1\u6570\u636e\u9a71\u52a8\u7684\u90e8\u5206\u4f30\u8ba1\u5668\uff0c\u5e76\u901a\u8fc7\u4e0e\u673a\u5668\u5b66\u4e60/\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u6bd4\u8f83\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u5728\u5c0f\u6837\u672c\u6570\u636e\u4e0b\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u9488\u5bf9\u5177\u6709\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u7684\u975e\u7ebf\u6027\u7cfb\u7edf\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u6570\u636e\u9a71\u52a8\u4f30\u8ba1\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5c0f\u6837\u672c\u6570\u636e\u60c5\u51b5\u4e0b\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7a00\u758f\u591a\u5143\u591a\u9879\u5f0f\u5173\u7cfb\u7684\u901a\u7528\u6846\u67b6\uff0c\u7528\u4e8e\u8bbe\u8ba1\u6570\u636e\u9a71\u52a8\u7684\u90e8\u5206\u4f30\u8ba1\u5668\uff0c\u5e76\u4e0e\u591a\u79cd\u673a\u5668\u5b66\u4e60/\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7a00\u758f\u8bc6\u522b\u65b9\u6848\u5728\u5c0f\u6837\u672c\u5b66\u4e60\u6570\u636e\u60c5\u51b5\u4e0b\u5177\u6709\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "\u7a00\u758f\u591a\u5143\u591a\u9879\u5f0f\u65b9\u6cd5\u4e3a\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5c0f\u6837\u672c\u6570\u636e\u573a\u666f\u3002"}}
{"id": "2511.01033", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01033", "abs": "https://arxiv.org/abs/2511.01033", "authors": ["Tiberiu Musat", "Tiago Pimentel", "Lorenzo Noci", "Alessandro Stolfo", "Mrinmaya Sachan", "Thomas Hofmann"], "title": "On the Emergence of Induction Heads for In-Context Learning", "comment": null, "summary": "Transformers have become the dominant architecture for natural language\nprocessing. Part of their success is owed to a remarkable capability known as\nin-context learning (ICL): they can acquire and apply novel associations solely\nfrom their input context, without any updates to their weights. In this work,\nwe study the emergence of induction heads, a previously identified mechanism in\ntwo-layer transformers that is particularly important for in-context learning.\nWe uncover a relatively simple and interpretable structure of the weight\nmatrices implementing the induction head. We theoretically explain the origin\nof this structure using a minimal ICL task formulation and a modified\ntransformer architecture. We give a formal proof that the training dynamics\nremain constrained to a 19-dimensional subspace of the parameter space.\nEmpirically, we validate this constraint while observing that only 3 dimensions\naccount for the emergence of an induction head. By further studying the\ntraining dynamics inside this 3-dimensional subspace, we find that the time\nuntil the emergence of an induction head follows a tight asymptotic bound that\nis quadratic in the input context length.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63ed\u793a\u4e86\u53cc\u5c42Transformer\u4e2d\u8bf1\u5bfc\u5934\u7684\u6743\u91cd\u77e9\u9635\u7ed3\u6784\uff0c\u8bc1\u660e\u8bad\u7ec3\u52a8\u6001\u88ab\u9650\u5236\u572819\u7ef4\u53c2\u6570\u5b50\u7a7a\u95f4\u4e2d\uff0c\u5176\u4e2d\u4ec53\u4e2a\u7ef4\u5ea6\u8d1f\u8d23\u8bf1\u5bfc\u5934\u7684\u5f62\u6210\uff0c\u4e14\u5176\u5f62\u6210\u65f6\u95f4\u4e0e\u8f93\u5165\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\u5e73\u65b9\u6210\u6b63\u6bd4\u3002", "motivation": "\u7814\u7a76Transformer\u4e2d\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u7684\u5173\u952e\u673a\u5236\u2014\u2014\u8bf1\u5bfc\u5934\uff0c\u7406\u89e3\u5176\u6743\u91cd\u7ed3\u6784\u5f62\u6210\u539f\u7406\uff0c\u4e3a\u89e3\u91caTransformer\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002", "method": "\u4f7f\u7528\u6700\u5c0f\u5316ICL\u4efb\u52a1\u516c\u5f0f\u548c\u4fee\u6539\u7684Transformer\u67b6\u6784\uff0c\u7406\u8bba\u5206\u6790\u8bad\u7ec3\u52a8\u6001\uff0c\u5e76\u901a\u8fc7\u7ecf\u9a8c\u9a8c\u8bc1\u53c2\u6570\u5b50\u7a7a\u95f4\u7ea6\u675f\u3002", "result": "\u53d1\u73b0\u8bf1\u5bfc\u5934\u7684\u6743\u91cd\u77e9\u9635\u5177\u6709\u7b80\u5355\u53ef\u89e3\u91ca\u7ed3\u6784\uff0c\u8bad\u7ec3\u52a8\u6001\u88ab\u9650\u5236\u572819\u7ef4\u5b50\u7a7a\u95f4\uff0c\u5176\u4e2d\u4ec53\u4e2a\u7ef4\u5ea6\u4e3b\u5bfc\u8bf1\u5bfc\u5934\u5f62\u6210\uff0c\u4e14\u5f62\u6210\u65f6\u95f4\u4e0e\u4e0a\u4e0b\u6587\u957f\u5ea6\u5e73\u65b9\u6210\u6b63\u6bd4\u3002", "conclusion": "\u8bf1\u5bfc\u5934\u7684\u5f62\u6210\u9075\u5faa\u7279\u5b9a\u7684\u4f4e\u7ef4\u52a8\u6001\u89c4\u5f8b\uff0c\u8fd9\u4e3a\u7406\u89e3Transformer\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u673a\u5236\u63d0\u4f9b\u4e86\u91cd\u8981\u7406\u8bba\u6d1e\u89c1\u3002"}}
{"id": "2511.01186", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01186", "abs": "https://arxiv.org/abs/2511.01186", "authors": ["Lijie Wang", "Lianjie Guo", "Ziyi Xu", "Qianhao Wang", "Fei Gao", "Xieyuanli Chen"], "title": "LiDAR-VGGT: Cross-Modal Coarse-to-Fine Fusion for Globally Consistent and Metric-Scale Dense Mapping", "comment": null, "summary": "Reconstructing large-scale colored point clouds is an important task in\nrobotics, supporting perception, navigation, and scene understanding. Despite\nadvances in LiDAR inertial visual odometry (LIVO), its performance remains\nhighly sensitive to extrinsic calibration. Meanwhile, 3D vision foundation\nmodels, such as VGGT, suffer from limited scalability in large environments and\ninherently lack metric scale. To overcome these limitations, we propose\nLiDAR-VGGT, a novel framework that tightly couples LiDAR inertial odometry with\nthe state-of-the-art VGGT model through a two-stage coarse- to-fine fusion\npipeline: First, a pre-fusion module with robust initialization refinement\nefficiently estimates VGGT poses and point clouds with coarse metric scale\nwithin each session. Then, a post-fusion module enhances cross-modal 3D\nsimilarity transformation, using bounding-box-based regularization to reduce\nscale distortions caused by inconsistent FOVs between LiDAR and camera sensors.\nExtensive experiments across multiple datasets demonstrate that LiDAR-VGGT\nachieves dense, globally consistent colored point clouds and outperforms both\nVGGT-based methods and LIVO baselines. The implementation of our proposed novel\ncolor point cloud evaluation toolkit will be released as open source.", "AI": {"tldr": "\u63d0\u51faLiDAR-VGGT\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u878d\u5408\u5c06LiDAR\u60ef\u6027\u91cc\u7a0b\u8ba1\u4e0eVGGT\u6a21\u578b\u7ed3\u5408\uff0c\u89e3\u51b3VGGT\u5728\u5927\u89c4\u6a21\u73af\u5883\u4e2d\u5c3a\u5ea6\u7f3a\u5931\u548cLIVO\u5bf9\u5916\u53c2\u6807\u5b9a\u654f\u611f\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709LIVO\u65b9\u6cd5\u5bf9\u5916\u53c2\u6807\u5b9a\u654f\u611f\uff0c\u800c3D\u89c6\u89c9\u57fa\u7840\u6a21\u578bVGGT\u5728\u5927\u89c4\u6a21\u73af\u5883\u4e2d\u7f3a\u4e4f\u5ea6\u91cf\u5c3a\u5ea6\u4e14\u53ef\u6269\u5c55\u6027\u6709\u9650\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u7c97\u5230\u7cbe\u878d\u5408\uff1a\u9884\u878d\u5408\u6a21\u5757\u901a\u8fc7\u9c81\u68d2\u521d\u59cb\u5316\u4f18\u5316\u4f30\u8ba1VGGT\u4f4d\u59ff\u548c\u70b9\u4e91\uff1b\u540e\u878d\u5408\u6a21\u5757\u589e\u5f3a\u8de8\u6a21\u60013D\u76f8\u4f3c\u53d8\u6362\uff0c\u4f7f\u7528\u8fb9\u754c\u6846\u6b63\u5219\u5316\u51cf\u5c11\u4f20\u611f\u5668FOV\u4e0d\u4e00\u81f4\u5bfc\u81f4\u7684\u5c3a\u5ea6\u5931\u771f\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLiDAR-VGGT\u5b9e\u73b0\u4e86\u5bc6\u96c6\u3001\u5168\u5c40\u4e00\u81f4\u7684\u5f69\u8272\u70b9\u4e91\uff0c\u4f18\u4e8eVGGT\u65b9\u6cd5\u548cLIVO\u57fa\u7ebf\u3002", "conclusion": "LiDAR-VGGT\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86VGGT\u7684\u5c3a\u5ea6\u95ee\u9898\u548cLIVO\u7684\u6807\u5b9a\u654f\u611f\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u7684\u5f69\u8272\u70b9\u4e91\u91cd\u5efa\u3002"}}
{"id": "2511.01052", "categories": ["cs.AI", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2511.01052", "abs": "https://arxiv.org/abs/2511.01052", "authors": ["Yeawon Lee", "Christopher C. Yang", "Chia-Hsuan Chang", "Grace Lu-Yao"], "title": "Knowledge Elicitation with Large Language Models for Interpretable Cancer Stage Identification from Pathology Reports", "comment": null, "summary": "Cancer staging is critical for patient prognosis and treatment planning, yet\nextracting pathologic TNM staging from unstructured pathology reports poses a\npersistent challenge. Existing natural language processing (NLP) and machine\nlearning (ML) strategies often depend on large annotated datasets, limiting\ntheir scalability and adaptability. In this study, we introduce two Knowledge\nElicitation methods designed to overcome these limitations by enabling large\nlanguage models (LLMs) to induce and apply domain-specific rules for cancer\nstaging. The first, Knowledge Elicitation with Long-Term Memory (KEwLTM), uses\nan iterative prompting strategy to derive staging rules directly from\nunannotated pathology reports, without requiring ground-truth labels. The\nsecond, Knowledge Elicitation with Retrieval-Augmented Generation (KEwRAG),\nemploys a variation of RAG where rules are pre-extracted from relevant\nguidelines in a single step and then applied, enhancing interpretability and\navoiding repeated retrieval overhead. We leverage the ability of LLMs to apply\nbroad knowledge learned during pre-training to new tasks. Using breast cancer\npathology reports from the TCGA dataset, we evaluate their performance in\nidentifying T and N stages, comparing them against various baseline approaches\non two open-source LLMs. Our results indicate that KEwLTM outperforms KEwRAG\nwhen Zero-Shot Chain-of-Thought (ZSCOT) inference is effective, whereas KEwRAG\nachieves better performance when ZSCOT inference is less effective. Both\nmethods offer transparent, interpretable interfaces by making the induced rules\nexplicit. These findings highlight the promise of our Knowledge Elicitation\nmethods as scalable, high-performing solutions for automated cancer staging\nwith enhanced interpretability, particularly in clinical settings with limited\nannotated data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u79cd\u77e5\u8bc6\u63d0\u53d6\u65b9\u6cd5\uff08KEwLTM\u548cKEwRAG\uff09\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u4ece\u65e0\u6807\u6ce8\u75c5\u7406\u62a5\u544a\u4e2d\u63a8\u5bfc\u764c\u75c7\u5206\u671f\u89c4\u5219\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfNLP\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u6807\u6ce8\u6570\u636e\u7684\u9650\u5236\u3002", "motivation": "\u764c\u75c7\u5206\u671f\u5bf9\u60a3\u8005\u9884\u540e\u548c\u6cbb\u7597\u89c4\u5212\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4ece\u975e\u7ed3\u6784\u5316\u75c5\u7406\u62a5\u544a\u4e2d\u63d0\u53d6\u75c5\u7406TNM\u5206\u671f\u5b58\u5728\u6311\u6218\u3002\u73b0\u6709NLP\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u9002\u5e94\u6027\u3002", "method": "KEwLTM\u4f7f\u7528\u8fed\u4ee3\u63d0\u793a\u7b56\u7565\u76f4\u63a5\u4ece\u65e0\u6807\u6ce8\u75c5\u7406\u62a5\u544a\u4e2d\u63a8\u5bfc\u5206\u671f\u89c4\u5219\uff1bKEwRAG\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u53d8\u4f53\uff0c\u4ece\u76f8\u5173\u6307\u5357\u4e2d\u9884\u63d0\u53d6\u89c4\u5219\u7136\u540e\u5e94\u7528\u3002\u4f7f\u7528TCGA\u6570\u636e\u96c6\u7684\u4e73\u817a\u764c\u75c5\u7406\u62a5\u544a\u8bc4\u4f30T\u548cN\u5206\u671f\u8bc6\u522b\u6027\u80fd\u3002", "result": "\u5f53\u96f6\u6837\u672c\u601d\u7ef4\u94fe\u63a8\u7406\u6709\u6548\u65f6\uff0cKEwLTM\u8868\u73b0\u4f18\u4e8eKEwRAG\uff1b\u5f53\u96f6\u6837\u672c\u601d\u7ef4\u94fe\u63a8\u7406\u6548\u679c\u8f83\u5dee\u65f6\uff0cKEwRAG\u6027\u80fd\u66f4\u597d\u3002\u4e24\u79cd\u65b9\u6cd5\u90fd\u63d0\u4f9b\u4e86\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u754c\u9762\u3002", "conclusion": "\u77e5\u8bc6\u63d0\u53d6\u65b9\u6cd5\u4e3a\u81ea\u52a8\u764c\u75c7\u5206\u671f\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u9ad8\u6027\u80fd\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u589e\u5f3a\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6807\u6ce8\u6570\u636e\u6709\u9650\u7684\u4e34\u5e8a\u73af\u5883\u3002"}}
{"id": "2511.01199", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01199", "abs": "https://arxiv.org/abs/2511.01199", "authors": ["Max McCandless", "Jonathan Hamid", "Sammy Elmariah", "Nathaniel Langer", "Pierre E. Dupont"], "title": "Closed-loop Control of Steerable Balloon Endoscopes for Robot-assisted Transcatheter Intracardiac Procedures", "comment": "8 pages, 11 figures", "summary": "To move away from open-heart surgery towards safer transcatheter procedures,\nthere is a growing need for improved imaging techniques and robotic solutions\nto enable simple, accurate tool navigation. Common imaging modalities, such as\nfluoroscopy and ultrasound, have limitations that can be overcome using\ncardioscopy, i.e., direct optical visualization inside the beating heart. We\npresent a cardioscope designed as a steerable balloon. As a balloon, it can be\ncollapsed to pass through the vasculature and subsequently inflated inside the\nheart for visualization and tool delivery through an integrated working\nchannel. Through careful design of balloon wall thickness, a single input,\nballoon inflation pressure, is used to independently control two outputs,\nballoon diameter (corresponding to field of view diameter) and balloon bending\nangle (enabling precise working channel positioning). This balloon technology\ncan be tuned to produce cardioscopes designed for a range of intracardiac\ntasks. To illustrate this approach, a balloon design is presented for the\nspecific task of aortic leaflet laceration. Image-based closed-loop control of\nbending angle is also demonstrated as a means of enabling stable orientation\ncontrol during tool insertion and removal.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u53ef\u64cd\u7eb5\u7403\u56ca\u5fc3\u810f\u955c\uff0c\u901a\u8fc7\u5355\u4e00\u8f93\u5165\uff08\u7403\u56ca\u5145\u6c14\u538b\u529b\uff09\u72ec\u7acb\u63a7\u5236\u7403\u56ca\u76f4\u5f84\u548c\u5f2f\u66f2\u89d2\u5ea6\uff0c\u5b9e\u73b0\u5fc3\u810f\u5185\u53ef\u89c6\u5316\u53ca\u5668\u68b0\u8f93\u9001\uff0c\u5e76\u6f14\u793a\u4e86\u57fa\u4e8e\u56fe\u50cf\u7684\u95ed\u73af\u5f2f\u66f2\u89d2\u5ea6\u63a7\u5236\u3002", "motivation": "\u4e3a\u4ece\u5f00\u80f8\u624b\u672f\u8f6c\u5411\u66f4\u5b89\u5168\u7684\u7ecf\u5bfc\u7ba1\u624b\u672f\uff0c\u9700\u8981\u6539\u8fdb\u6210\u50cf\u6280\u672f\u548c\u673a\u5668\u4eba\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u7b80\u5316\u3001\u7cbe\u786e\u5730\u5bfc\u822a\u5668\u68b0\u3002\u73b0\u6709\u6210\u50cf\u65b9\u5f0f\u5982\u8367\u5149\u900f\u89c6\u548c\u8d85\u58f0\u5b58\u5728\u5c40\u9650\u6027\uff0c\u53ef\u901a\u8fc7\u5fc3\u810f\u955c\uff08\u5fc3\u810f\u5185\u76f4\u63a5\u5149\u5b66\u53ef\u89c6\u5316\uff09\u514b\u670d\u3002", "method": "\u8bbe\u8ba1\u53ef\u64cd\u7eb5\u7403\u56ca\u5fc3\u810f\u955c\uff0c\u7403\u56ca\u53ef\u6536\u7f29\u901a\u8fc7\u8840\u7ba1\u7cfb\u7edf\uff0c\u7136\u540e\u5728\u5fc3\u810f\u5185\u5145\u6c14\u8fdb\u884c\u53ef\u89c6\u5316\uff0c\u5e76\u901a\u8fc7\u96c6\u6210\u5de5\u4f5c\u901a\u9053\u8f93\u9001\u5668\u68b0\u3002\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7403\u56ca\u58c1\u539a\u5ea6\uff0c\u4f7f\u7528\u5355\u4e00\u8f93\u5165\uff08\u7403\u56ca\u5145\u6c14\u538b\u529b\uff09\u72ec\u7acb\u63a7\u5236\u7403\u56ca\u76f4\u5f84\uff08\u5bf9\u5e94\u89c6\u91ce\u76f4\u5f84\uff09\u548c\u7403\u56ca\u5f2f\u66f2\u89d2\u5ea6\uff08\u5b9e\u73b0\u7cbe\u786e\u5de5\u4f5c\u901a\u9053\u5b9a\u4f4d\uff09\u3002", "result": "\u8be5\u7403\u56ca\u6280\u672f\u53ef\u8c03\u6574\u4ee5\u8bbe\u8ba1\u9002\u7528\u4e8e\u5404\u79cd\u5fc3\u810f\u5185\u4efb\u52a1\u7684\u7403\u56ca\u5fc3\u810f\u955c\u3002\u9488\u5bf9\u4e3b\u52a8\u8109\u74e3\u53f6\u6495\u88c2\u7684\u5177\u4f53\u4efb\u52a1\u5c55\u793a\u4e86\u7403\u56ca\u8bbe\u8ba1\uff0c\u5e76\u6f14\u793a\u4e86\u57fa\u4e8e\u56fe\u50cf\u7684\u95ed\u73af\u5f2f\u66f2\u89d2\u5ea6\u63a7\u5236\uff0c\u5728\u5668\u68b0\u63d2\u5165\u548c\u53d6\u51fa\u671f\u95f4\u5b9e\u73b0\u7a33\u5b9a\u7684\u65b9\u5411\u63a7\u5236\u3002", "conclusion": "\u53ef\u64cd\u7eb5\u7403\u56ca\u5fc3\u810f\u955c\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u666f\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5355\u4e00\u63a7\u5236\u8f93\u5165\u5b9e\u73b0\u5fc3\u810f\u5185\u53ef\u89c6\u5316\u548c\u5668\u68b0\u8f93\u9001\uff0c\u4e3a\u7ecf\u5bfc\u7ba1\u5fc3\u810f\u624b\u672f\u63d0\u4f9b\u4e86\u6539\u8fdb\u7684\u6210\u50cf\u548c\u5bfc\u822a\u80fd\u529b\u3002"}}
{"id": "2511.01059", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01059", "abs": "https://arxiv.org/abs/2511.01059", "authors": ["Hailong Yin", "Bin Zhu", "Jingjing Chen", "Chong-Wah Ngo"], "title": "Efficient Test-Time Retrieval Augmented Generation", "comment": null, "summary": "Although Large Language Models (LLMs) demonstrate significant capabilities,\ntheir reliance on parametric knowledge often leads to inaccuracies. Retrieval\nAugmented Generation (RAG) mitigates this by incorporating external knowledge,\nbut these methods may introduce irrelevant retrieved documents, leading to\ninaccurate responses. While the integration methods filter out incorrect\nanswers from multiple responses, but lack external knowledge like RAG methods,\nand their high costs require balancing overhead with performance gains. To\naddress these issues, we propose an Efficient Test-Time Retrieval-Augmented\nGeneration Framework named ET2RAG to improve the performance of LLMs while\nmaintaining efficiency. Specifically, ET2RAG is a training-free method, that\nfirst retrieves the most relevant documents and augments the LLMs to\nefficiently generate diverse candidate responses by managing response length.\nThen we compute the similarity of candidate responses and employ a majority\nvoting mechanism to select the most suitable response as the final output. In\nparticular, we discover that partial generation is sufficient to capture the\nkey information necessary for consensus calculation, allowing us to effectively\nperform majority voting without the need for fully generated responses. Thus,\nwe can reach a balance between computational cost and performance by managing\nthe response length for the number of retrieved documents for majority voting.\nExperimental results demonstrate that ET2RAG significantly enhances performance\nacross three tasks, including open-domain question answering, recipe generation\nand image captioning.", "AI": {"tldr": "\u63d0\u51faET2RAG\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u591a\u6570\u6295\u7968\u673a\u5236\uff0c\u5728\u4fdd\u6301\u6548\u7387\u7684\u540c\u65f6\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709RAG\u65b9\u6cd5\u53ef\u80fd\u5f15\u5165\u4e0d\u76f8\u5173\u6587\u6863\u5bfc\u81f4\u9519\u8bef\u54cd\u5e94\uff0c\u800c\u96c6\u6210\u65b9\u6cd5\u7f3a\u4e4f\u5916\u90e8\u77e5\u8bc6\u4e14\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u5e73\u8861\u5f00\u9500\u4e0e\u6027\u80fd\u3002", "method": "ET2RAG\u662f\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u5148\u68c0\u7d22\u6700\u76f8\u5173\u6587\u6863\uff0c\u901a\u8fc7\u63a7\u5236\u54cd\u5e94\u957f\u5ea6\u9ad8\u6548\u751f\u6210\u591a\u6837\u5019\u9009\u54cd\u5e94\uff0c\u7136\u540e\u8ba1\u7b97\u76f8\u4f3c\u5ea6\u5e76\u4f7f\u7528\u591a\u6570\u6295\u7968\u9009\u62e9\u6700\u4f73\u54cd\u5e94\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aET2RAG\u5728\u5f00\u653e\u57df\u95ee\u7b54\u3001\u83dc\u8c31\u751f\u6210\u548c\u56fe\u50cf\u63cf\u8ff0\u4e09\u4e2a\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "conclusion": "\u90e8\u5206\u751f\u6210\u8db3\u4ee5\u6355\u83b7\u5171\u8bc6\u8ba1\u7b97\u6240\u9700\u5173\u952e\u4fe1\u606f\uff0c\u901a\u8fc7\u7ba1\u7406\u54cd\u5e94\u957f\u5ea6\u53ef\u4ee5\u5728\u8ba1\u7b97\u6210\u672c\u548c\u6027\u80fd\u4e4b\u95f4\u8fbe\u5230\u5e73\u8861\u3002"}}
{"id": "2511.01219", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01219", "abs": "https://arxiv.org/abs/2511.01219", "authors": ["Muhua Zhang", "Lei Ma", "Ying Wu", "Kai Shen", "Deqing Huang", "Henry Leung"], "title": "Tackling the Kidnapped Robot Problem via Sparse Feasible Hypothesis Sampling and Reliable Batched Multi-Stage Inference", "comment": "10 pages, 8 figures. This work has been submitted to the IEEE for\n  possible publication", "summary": "This paper addresses the Kidnapped Robot Problem (KRP), a core localization\nchallenge of relocalizing a robot in a known map without prior pose estimate\nwhen localization loss or at SLAM initialization. For this purpose, a passive\n2-D global relocalization framework is proposed. It estimates the global pose\nefficiently and reliably from a single LiDAR scan and an occupancy grid map\nwhile the robot remains stationary, thereby enhancing the long-term autonomy of\nmobile robots. The proposed framework casts global relocalization as a\nnon-convex problem and solves it via the multi-hypothesis scheme with batched\nmulti-stage inference and early termination, balancing completeness and\nefficiency. The Rapidly-exploring Random Tree (RRT), under traversability\nconstraints, asymptotically covers the reachable space to generate sparse,\nuniformly distributed feasible positional hypotheses, fundamentally reducing\nthe sampling space. The hypotheses are preliminarily ordered by the proposed\nScan Mean Absolute Difference (SMAD), a coarse beam-error level metric that\nfacilitates the early termination by prioritizing high-likelihood candidates.\nThe SMAD computation is optimized for non-panoramic scans. And the\nTranslation-Affinity Scan-to-Map Alignment Metric (TAM) is proposed for\nreliable orientation selection at hypothesized positions and accurate final\npose evaluation to mitigate degradation in conventional likelihood-field\nmetrics under translational uncertainty induced by sparse hypotheses, as well\nas non-panoramic LiDAR scan and environmental changes. Real-world experiments\non a resource-constrained mobile robot with non-panoramic LiDAR scan\ndemonstrate that the proposed framework outperforms existing methods in both\nglobal relocalization success rate and computational efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u88ab\u52a82D\u5168\u5c40\u91cd\u5b9a\u4f4d\u6846\u67b6\uff0c\u89e3\u51b3\u673a\u5668\u4eba\u7ed1\u67b6\u95ee\u9898\uff0c\u901a\u8fc7\u5355\u6b21LiDAR\u626b\u63cf\u548c\u5360\u636e\u6805\u683c\u5730\u56fe\u9ad8\u6548\u53ef\u9760\u5730\u4f30\u8ba1\u5168\u5c40\u4f4d\u59ff\uff0c\u4f7f\u7528\u591a\u5047\u8bbe\u65b9\u6848\u5e73\u8861\u5b8c\u6574\u6027\u548c\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u4eba\u7ed1\u67b6\u95ee\u9898\uff08KRP\uff09\u2014\u2014\u5728\u5df2\u77e5\u5730\u56fe\u4e2d\u91cd\u65b0\u5b9a\u4f4d\u673a\u5668\u4eba\u800c\u65e0\u9700\u5148\u9a8c\u4f4d\u59ff\u4f30\u8ba1\uff0c\u8fd9\u5bf9\u4e8e\u5b9a\u4f4d\u4e22\u5931\u6216SLAM\u521d\u59cb\u5316\u81f3\u5173\u91cd\u8981\uff0c\u65e8\u5728\u63d0\u5347\u79fb\u52a8\u673a\u5668\u4eba\u7684\u957f\u671f\u81ea\u4e3b\u6027\u3002", "method": "\u91c7\u7528\u591a\u5047\u8bbe\u65b9\u6848\uff0c\u4f7f\u7528RRT\u5728\u53ef\u901a\u884c\u7ea6\u675f\u4e0b\u751f\u6210\u7a00\u758f\u5747\u5300\u7684\u4f4d\u7f6e\u5047\u8bbe\uff0c\u901a\u8fc7SMAD\u6307\u6807\u521d\u6b65\u6392\u5e8f\u5047\u8bbe\u5e76\u5b9e\u73b0\u65e9\u671f\u7ec8\u6b62\uff0c\u63d0\u51faTAM\u6307\u6807\u8fdb\u884c\u53ef\u9760\u7684\u65b9\u5411\u9009\u62e9\u548c\u6700\u7ec8\u4f4d\u59ff\u8bc4\u4f30\u3002", "result": "\u5728\u8d44\u6e90\u53d7\u9650\u7684\u79fb\u52a8\u673a\u5668\u4eba\u4e0a\u7684\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u5168\u5c40\u91cd\u5b9a\u4f4d\u6210\u529f\u7387\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u88ab\u52a82D\u5168\u5c40\u91cd\u5b9a\u4f4d\u6846\u67b6\u80fd\u591f\u9ad8\u6548\u53ef\u9760\u5730\u89e3\u51b3\u673a\u5668\u4eba\u7ed1\u67b6\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u79fb\u52a8\u673a\u5668\u4eba\u7684\u957f\u671f\u81ea\u4e3b\u8fd0\u884c\u80fd\u529b\u3002"}}
{"id": "2511.01149", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01149", "abs": "https://arxiv.org/abs/2511.01149", "authors": ["Shuaidong Pan", "Di Wu"], "title": "Modular Task Decomposition and Dynamic Collaboration in Multi-Agent Systems Driven by Large Language Models", "comment": null, "summary": "This paper addresses the limitations of a single agent in task decomposition\nand collaboration during complex task execution, and proposes a multi-agent\narchitecture for modular task decomposition and dynamic collaboration based on\nlarge language models. The method first converts natural language task\ndescriptions into unified semantic representations through a large language\nmodel. On this basis, a modular decomposition mechanism is introduced to break\ndown the overall goal into multiple hierarchical sub-tasks. Then, dynamic\nscheduling and routing mechanisms enable reasonable division of labor and\nrealtime collaboration among agents, allowing the system to adjust strategies\ncontinuously according to environmental feedback, thus maintaining efficiency\nand stability in complex tasks. Furthermore, a constraint parsing and global\nconsistency mechanism is designed to ensure coherent connections between\nsub-tasks and balanced workload, preventing performance degradation caused by\nredundant communication or uneven resource allocation. The experiments validate\nthe architecture across multiple dimensions, including task success rate,\ndecomposition efficiency, sub-task coverage, and collaboration balance. The\nresults show that the proposed method outperforms existing approaches in both\noverall performance and robustness, achieving a better balance between task\ncomplexity and communication overhead. In conclusion, this study demonstrates\nthe effectiveness and feasibility of language-driven task decomposition and\ndynamic collaboration in multi-agent systems, providing a systematic solution\nfor task execution in complex environments.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u4efb\u52a1\u5206\u89e3\u548c\u52a8\u6001\u534f\u4f5c\u673a\u5236\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u6267\u884c\u95ee\u9898\uff0c\u5728\u4efb\u52a1\u6210\u529f\u7387\u3001\u5206\u89e3\u6548\u7387\u548c\u534f\u4f5c\u5e73\u8861\u7b49\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u5355\u4e2a\u667a\u80fd\u4f53\u5728\u590d\u6742\u4efb\u52a1\u6267\u884c\u4e2d\u4efb\u52a1\u5206\u89e3\u548c\u534f\u4f5c\u80fd\u529b\u7684\u5c40\u9650\u6027\uff0c\u63d0\u5347\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u4efb\u52a1\u6267\u884c\u6548\u7387\u3002", "method": "\u5c06\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u8f6c\u6362\u4e3a\u7edf\u4e00\u8bed\u4e49\u8868\u793a\uff0c\u5f15\u5165\u6a21\u5757\u5316\u5206\u89e3\u673a\u5236\u5c06\u603b\u4f53\u76ee\u6807\u5206\u89e3\u4e3a\u5206\u5c42\u5b50\u4efb\u52a1\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u5ea6\u548c\u8def\u7531\u673a\u5236\u5b9e\u73b0\u667a\u80fd\u4f53\u95f4\u7684\u5408\u7406\u5206\u5de5\u548c\u5b9e\u65f6\u534f\u4f5c\uff0c\u5e76\u8bbe\u8ba1\u7ea6\u675f\u89e3\u6790\u548c\u5168\u5c40\u4e00\u81f4\u6027\u673a\u5236\u786e\u4fdd\u5b50\u4efb\u52a1\u8fde\u8d2f\u6027\u548c\u8d1f\u8f7d\u5747\u8861\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u67b6\u6784\u5728\u4efb\u52a1\u6210\u529f\u7387\u3001\u5206\u89e3\u6548\u7387\u3001\u5b50\u4efb\u52a1\u8986\u76d6\u7387\u548c\u534f\u4f5c\u5e73\u8861\u7b49\u591a\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u4f18\u52bf\uff0c\u6574\u4f53\u6027\u80fd\u548c\u9c81\u68d2\u6027\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u4efb\u52a1\u590d\u6742\u5ea6\u548c\u901a\u4fe1\u5f00\u9500\u4e4b\u95f4\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u5e73\u8861\u3002", "conclusion": "\u8bc1\u660e\u4e86\u8bed\u8a00\u9a71\u52a8\u7684\u4efb\u52a1\u5206\u89e3\u548c\u52a8\u6001\u534f\u4f5c\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u6027\u548c\u53ef\u884c\u6027\uff0c\u4e3a\u590d\u6742\u73af\u5883\u4e2d\u7684\u4efb\u52a1\u6267\u884c\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01224", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01224", "abs": "https://arxiv.org/abs/2511.01224", "authors": ["Chengmeng Li", "Yaxin Peng"], "title": "Embodiment Transfer Learning for Vision-Language-Action Models", "comment": null, "summary": "Vision-language-action (VLA) models have significantly advanced robotic\nlearning, enabling training on large-scale, cross-embodiment data and\nfine-tuning for specific robots. However, state-of-the-art autoregressive VLAs\nstruggle with multi-robot collaboration. We introduce embodiment transfer\nlearning, denoted as ET-VLA, a novel framework for efficient and effective\ntransfer of pre-trained VLAs to multi-robot. ET-VLA's core is Synthetic\nContinued Pretraining (SCP), which uses synthetically generated data to warm up\nthe model for the new embodiment, bypassing the need for real human\ndemonstrations and reducing data collection costs. SCP enables the model to\nlearn correct actions and precise action token numbers. Following SCP, the\nmodel is fine-tuned on target embodiment data. To further enhance the model\nperformance on multi-embodiment, we present the Embodied Graph-of-Thought\ntechnique, a novel approach that formulates each sub-task as a node, that\nallows the VLA model to distinguish the functionalities and roles of each\nembodiment during task execution. Our work considers bimanual robots, a simple\nversion of multi-robot to verify our approaches. We validate the effectiveness\nof our method on both simulation benchmarks and real robots covering three\ndifferent bimanual embodiments. In particular, our proposed ET-VLA \\space can\noutperform OpenVLA on six real-world tasks over 53.2%. We will open-source all\ncodes to support the community in advancing VLA models for robot learning.", "AI": {"tldr": "\u63d0\u51fa\u4e86ET-VLA\u6846\u67b6\uff0c\u901a\u8fc7\u5408\u6210\u7ee7\u7eed\u9884\u8bad\u7ec3\u548c\u5177\u8eab\u601d\u7ef4\u56fe\u6280\u672f\uff0c\u6709\u6548\u5c06\u9884\u8bad\u7ec3\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u8fc1\u79fb\u5230\u591a\u673a\u5668\u4eba\u534f\u4f5c\u573a\u666f\uff0c\u5728\u53cc\u624b\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u56de\u5f52VLA\u6a21\u578b\u5728\u591a\u673a\u5668\u4eba\u534f\u4f5c\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684\u65b9\u6cd5\u5c06\u9884\u8bad\u7ec3\u6a21\u578b\u8fc1\u79fb\u5230\u591a\u673a\u5668\u4eba\u573a\u666f\uff0c\u540c\u65f6\u51cf\u5c11\u771f\u5b9e\u6570\u636e\u6536\u96c6\u6210\u672c\u3002", "method": "\u91c7\u7528\u5408\u6210\u7ee7\u7eed\u9884\u8bad\u7ec3(SCP)\u4f7f\u7528\u5408\u6210\u6570\u636e\u9884\u70ed\u6a21\u578b\uff0c\u5b66\u4e60\u6b63\u786e\u52a8\u4f5c\u548c\u7cbe\u786e\u52a8\u4f5c\u6807\u8bb0\u6570\u91cf\uff1b\u7136\u540e\u8fdb\u884c\u76ee\u6807\u5177\u8eab\u6570\u636e\u5fae\u8c03\uff1b\u5e76\u5f15\u5165\u5177\u8eab\u601d\u7ef4\u56fe\u6280\u672f\uff0c\u5c06\u5b50\u4efb\u52a1\u5efa\u6a21\u4e3a\u8282\u70b9\u4ee5\u533a\u5206\u4e0d\u540c\u5177\u8eab\u7684\u529f\u80fd\u89d2\u8272\u3002", "result": "\u5728\u4e09\u4e2a\u4e0d\u540c\u53cc\u624b\u673a\u5668\u4eba\u5177\u8eab\u4e0a\u9a8c\u8bc1\uff0c\u5728\u516d\u4e2a\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u6bd4OpenVLA\u6027\u80fd\u63d0\u5347\u8d85\u8fc753.2%\u3002", "conclusion": "ET-VLA\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3VLA\u6a21\u578b\u5728\u591a\u673a\u5668\u4eba\u534f\u4f5c\u4e2d\u7684\u8fc1\u79fb\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5e76\u5c06\u5f00\u6e90\u4ee3\u7801\u652f\u6301\u793e\u533a\u53d1\u5c55\u3002"}}
{"id": "2511.01170", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01170", "abs": "https://arxiv.org/abs/2511.01170", "authors": ["Ruofan Zhang", "Bin Xia", "Zhen Cheng", "Cairen Jian", "Minglun Yang", "Ngai Wong", "Yuan Cheng"], "title": "DART: Difficulty-Adaptive Reasoning Truncation for Efficient Large Language Models", "comment": null, "summary": "Adaptive reasoning is essential for aligning the computational effort of\nlarge language models (LLMs) with the intrinsic difficulty of problems. Current\nchain-of-thought methods boost reasoning ability but indiscriminately generate\nlong explanations, leading to evident inefficiency. However, existing\nreinforcement learning approaches to adaptive thinking remain unstable and\nheavily reward-dependent. Here we propose \\textbf{DART}, a supervised\n\\textbf{D}ifficulty-\\textbf{A}daptive \\textbf{R}easoning \\textbf{T}runcation\nframework that adjusts thinking length according to problem difficulty. By\ndistilling concise reasoning patterns from stronger models, interpolating them\ninto a continuum of reasoning styles, and curating optimal training data that\nbalances correctness and compactness, DART learns when to ``stop thinking''.\nAcross multiple mathematical benchmarks, experimental results demonstrate its\nremarkable efficiency while preserving or improving accuracy, achieving a\nsignificant 81.2\\% reasoning truncation (DeepSeek-R1-Distill-Qwen-7B on GSM8K\ndataset) with 5.33$\\times$ computational acceleration. DART provides a stable\nand general paradigm for efficient reasoning, advancing the development of\nadaptive intelligence in LLMs.", "AI": {"tldr": "DART\u662f\u4e00\u4e2a\u96be\u5ea6\u81ea\u9002\u5e94\u7684\u63a8\u7406\u622a\u65ad\u6846\u67b6\uff0c\u901a\u8fc7\u6839\u636e\u95ee\u9898\u96be\u5ea6\u8c03\u6574\u601d\u8003\u957f\u5ea6\uff0c\u5728\u4fdd\u6301\u6216\u63d0\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u94fe\u5f0f\u601d\u7ef4\u65b9\u6cd5\u4f1a\u65e0\u5dee\u522b\u751f\u6210\u957f\u89e3\u91ca\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\uff0c\u800c\u73b0\u6709\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4e0d\u7a33\u5b9a\u4e14\u4f9d\u8d56\u5956\u52b1\u3002\u9700\u8981\u4e00\u79cd\u7a33\u5b9a\u3001\u901a\u7528\u7684\u81ea\u9002\u5e94\u63a8\u7406\u8303\u5f0f\u3002", "method": "\u901a\u8fc7\u4ece\u66f4\u5f3a\u6a21\u578b\u84b8\u998f\u7b80\u6d01\u63a8\u7406\u6a21\u5f0f\uff0c\u5c06\u5176\u63d2\u503c\u4e3a\u8fde\u7eed\u63a8\u7406\u98ce\u683c\uff0c\u5e76\u7b5b\u9009\u5e73\u8861\u6b63\u786e\u6027\u548c\u7d27\u51d1\u6027\u7684\u6700\u4f18\u8bad\u7ec3\u6570\u636e\uff0c\u5b66\u4e60\u4f55\u65f6\u505c\u6b62\u601d\u8003\u3002", "result": "\u5728\u591a\u4e2a\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5b9e\u73b0\u4e8681.2%\u7684\u63a8\u7406\u622a\u65ad\u548c5.33\u500d\u8ba1\u7b97\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "DART\u4e3a\u9ad8\u6548\u63a8\u7406\u63d0\u4f9b\u4e86\u7a33\u5b9a\u901a\u7528\u7684\u8303\u5f0f\uff0c\u63a8\u52a8\u4e86LLMs\u4e2d\u81ea\u9002\u5e94\u667a\u80fd\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.01232", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01232", "abs": "https://arxiv.org/abs/2511.01232", "authors": ["Yu-Ting Lai", "Jacob Rosen", "Yasamin Foroutani", "Ji Ma", "Wen-Cheng Wu", "Jean-Pierre Hubschman", "Tsu-Chin Tsao"], "title": "High-Precision Surgical Robotic System for Intraocular Procedures", "comment": null, "summary": "Despite the extensive demonstration of robotic systems for both cataract and\nvitreoretinal procedures, existing technologies or mechanisms still possess\ninsufficient accuracy, precision, and degrees of freedom for instrument\nmanipulation or potentially automated tool exchange during surgical procedures.\nA new robotic system that focuses on improving tooltip accuracy, tracking\nperformance, and smooth instrument exchange mechanism is therefore designed and\nmanufactured. Its tooltip accuracy, precision, and mechanical capability of\nmaintaining small incision through remote center of motion were externally\nevaluated using an optical coherence tomography (OCT) system. Through robot\ncalibration and precise coordinate registration, the accuracy of tooltip\npositioning was measured to be 0.053$\\pm$0.031 mm, and the overall performance\nwas demonstrated on an OCT-guided automated cataract lens extraction procedure\nwith deep learning-based pre-operative anatomical modeling and real-time\nsupervision.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u7528\u4e8e\u63d0\u9ad8\u773c\u79d1\u624b\u672f\u4e2d\u5de5\u5177\u5c16\u7aef\u7cbe\u5ea6\u3001\u8ddf\u8e2a\u6027\u80fd\u548c\u5668\u68b0\u4ea4\u6362\u673a\u5236\uff0c\u5728OCT\u5f15\u5bfc\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684\u767d\u5185\u969c\u6676\u72b6\u4f53\u63d0\u53d6\u624b\u672f\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u4eba\u7cfb\u7edf\u5728\u773c\u79d1\u624b\u672f\u4e2d\u7cbe\u5ea6\u3001\u81ea\u7531\u5ea6\u548c\u5668\u68b0\u4ea4\u6362\u673a\u5236\u4e0d\u8db3\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u7cbe\u786e\u3001\u7075\u6d3b\u7684\u624b\u672f\u673a\u5668\u4eba\u7cfb\u7edf\u3002", "method": "\u8bbe\u8ba1\u5236\u9020\u4e86\u65b0\u578b\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u901a\u8fc7\u673a\u5668\u4eba\u6821\u51c6\u548c\u7cbe\u786e\u5750\u6807\u914d\u51c6\uff0c\u4f7f\u7528OCT\u7cfb\u7edf\u8bc4\u4f30\u5de5\u5177\u5c16\u7aef\u7cbe\u5ea6\u548c\u8fdc\u7a0b\u8fd0\u52a8\u4e2d\u5fc3\u673a\u5236\uff0c\u5e76\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u8fdb\u884c\u672f\u524d\u89e3\u5256\u5efa\u6a21\u548c\u5b9e\u65f6\u76d1\u7763\u3002", "result": "\u5de5\u5177\u5c16\u7aef\u5b9a\u4f4d\u7cbe\u5ea6\u8fbe\u52300.053\u00b10.031\u6beb\u7c73\uff0c\u6210\u529f\u6f14\u793a\u4e86OCT\u5f15\u5bfc\u7684\u81ea\u52a8\u5316\u767d\u5185\u969c\u6676\u72b6\u4f53\u63d0\u53d6\u624b\u672f\u3002", "conclusion": "\u8be5\u673a\u5668\u4eba\u7cfb\u7edf\u663e\u8457\u63d0\u9ad8\u4e86\u773c\u79d1\u624b\u672f\u7684\u7cbe\u5ea6\u548c\u81ea\u52a8\u5316\u6c34\u5e73\uff0c\u4e3a\u590d\u6742\u773c\u79d1\u624b\u672f\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2511.01288", "categories": ["cs.RO", "cs.SY", "eess.SY", "I.2.9"], "pdf": "https://arxiv.org/pdf/2511.01288", "abs": "https://arxiv.org/abs/2511.01288", "authors": ["Bixuan Zhang", "Fengqi Zhang", "Haojie Chen", "You Wang", "Jie Hao", "Zhiyuan Luo", "Guang Li"], "title": "A High-Speed Capable Spherical Robot", "comment": "5 pages", "summary": "This paper designs a new spherical robot structure capable of supporting\nhigh-speed motion at up to 10 m/s. Building upon a single-pendulum-driven\nspherical robot, the design incorporates a momentum wheel with an axis aligned\nwith the secondary pendulum, creating a novel spherical robot structure.\nPractical experiments with the physical prototype have demonstrated that this\nnew spherical robot can achieve stable high-speed motion through simple\ndecoupled control, which was unattainable with the original structure. The\nspherical robot designed for high-speed motion not only increases speed but\nalso significantly enhances obstacle-crossing performance and terrain\nrobustness.", "AI": {"tldr": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u578b\u7403\u5f62\u673a\u5668\u4eba\u7ed3\u6784\uff0c\u901a\u8fc7\u5f15\u5165\u4e0e\u6b21\u6446\u5bf9\u9f50\u7684\u52a8\u91cf\u8f6e\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe10 m/s\u7684\u9ad8\u901f\u7a33\u5b9a\u8fd0\u52a8\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8d8a\u969c\u80fd\u529b\u548c\u5730\u5f62\u9002\u5e94\u6027\u3002", "motivation": "\u57fa\u4e8e\u5355\u6446\u9a71\u52a8\u7403\u5f62\u673a\u5668\u4eba\u7684\u5c40\u9650\u6027\uff0c\u65e8\u5728\u5f00\u53d1\u80fd\u591f\u5b9e\u73b0\u9ad8\u901f\u7a33\u5b9a\u8fd0\u52a8\u7684\u65b0\u578b\u7403\u5f62\u673a\u5668\u4eba\u7ed3\u6784\uff0c\u7a81\u7834\u539f\u6709\u7ed3\u6784\u7684\u901f\u5ea6\u9650\u5236\u3002", "method": "\u5728\u5355\u6446\u9a71\u52a8\u7403\u5f62\u673a\u5668\u4eba\u57fa\u7840\u4e0a\uff0c\u589e\u52a0\u4e00\u4e2a\u4e0e\u6b21\u6446\u8f74\u7ebf\u5bf9\u9f50\u7684\u52a8\u91cf\u8f6e\uff0c\u5f62\u6210\u65b0\u578b\u7403\u5f62\u673a\u5668\u4eba\u7ed3\u6784\uff0c\u901a\u8fc7\u89e3\u8026\u63a7\u5236\u5b9e\u73b0\u7a33\u5b9a\u9ad8\u901f\u8fd0\u52a8\u3002", "result": "\u7269\u7406\u6837\u673a\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b0\u578b\u7403\u5f62\u673a\u5668\u4eba\u80fd\u591f\u5b9e\u73b0\u9ad8\u8fbe10 m/s\u7684\u7a33\u5b9a\u9ad8\u901f\u8fd0\u52a8\uff0c\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u8d8a\u969c\u6027\u80fd\u548c\u5730\u5f62\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b0\u578b\u7403\u5f62\u673a\u5668\u4eba\u7ed3\u6784\u6210\u529f\u89e3\u51b3\u4e86\u9ad8\u901f\u8fd0\u52a8\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u4e3a\u7403\u5f62\u673a\u5668\u4eba\u7684\u9ad8\u901f\u5e94\u7528\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2511.01182", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01182", "abs": "https://arxiv.org/abs/2511.01182", "authors": ["Cuong Van Duc", "Thai Tran Quoc", "Minh Nguyen Dinh Tuan", "Tam Vu Duc", "Son Nguyen Van", "Hanh Nguyen Thi"], "title": "MiRAGE: Misconception Detection with Retrieval-Guided Multi-Stage Reasoning and Ensemble Fusion", "comment": null, "summary": "Detecting student misconceptions in open-ended responses is a longstanding\nchallenge, demanding semantic precision and logical reasoning. We propose\nMiRAGE - Misconception Detection with Retrieval-Guided Multi-Stage Reasoning\nand Ensemble Fusion, a novel framework for automated misconception detection in\nmathematics. MiRAGE operates in three stages: (1) a Retrieval module narrows a\nlarge candidate pool to a semantically relevant subset; (2) a Reasoning module\nemploys chain-of-thought generation to expose logical inconsistencies in\nstudent solutions; and (3) a Reranking module refines predictions by aligning\nthem with the reasoning. These components are unified through an\nensemble-fusion strategy that enhances robustness and interpretability. On\nmathematics datasets, MiRAGE achieves Mean Average Precision scores of\n0.82/0.92/0.93 at levels 1/3/5, consistently outperforming individual modules.\nBy coupling retrieval guidance with multi-stage reasoning, MiRAGE reduces\ndependence on large-scale language models while delivering a scalable and\neffective solution for educational assessment.", "AI": {"tldr": "MiRAGE\u662f\u4e00\u4e2a\u7528\u4e8e\u6570\u5b66\u9886\u57df\u5b66\u751f\u9519\u8bef\u6982\u5ff5\u68c0\u6d4b\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u5f15\u5bfc\u7684\u591a\u9636\u6bb5\u63a8\u7406\u548c\u96c6\u6210\u878d\u5408\uff0c\u5728\u5f00\u653e\u56de\u7b54\u4e2d\u6709\u6548\u8bc6\u522b\u5b66\u751f\u8bef\u89e3\u3002", "motivation": "\u5f00\u653e\u56de\u7b54\u4e2d\u7684\u5b66\u751f\u9519\u8bef\u6982\u5ff5\u68c0\u6d4b\u9700\u8981\u8bed\u4e49\u7cbe\u786e\u6027\u548c\u903b\u8f91\u63a8\u7406\u80fd\u529b\uff0c\u8fd9\u662f\u4e00\u4e2a\u957f\u671f\u5b58\u5728\u7684\u6311\u6218\u3002", "method": "\u4e09\u9636\u6bb5\u6846\u67b6\uff1a\u68c0\u7d22\u6a21\u5757\u7f29\u5c0f\u5019\u9009\u6c60\uff0c\u63a8\u7406\u6a21\u5757\u4f7f\u7528\u601d\u7ef4\u94fe\u751f\u6210\u66b4\u9732\u903b\u8f91\u4e0d\u4e00\u81f4\uff0c\u91cd\u6392\u6a21\u5757\u901a\u8fc7\u5bf9\u9f50\u63a8\u7406\u6765\u4f18\u5316\u9884\u6d4b\uff0c\u6240\u6709\u7ec4\u4ef6\u901a\u8fc7\u96c6\u6210\u878d\u5408\u7b56\u7565\u7edf\u4e00\u3002", "result": "\u5728\u6570\u5b66\u6570\u636e\u96c6\u4e0a\uff0cMiRAGE\u57281/3/5\u7ea7\u522b\u5206\u522b\u83b7\u5f970.82/0.92/0.93\u7684\u5e73\u5747\u7cbe\u5ea6\u5206\u6570\uff0c\u59cb\u7ec8\u4f18\u4e8e\u5355\u4e2a\u6a21\u5757\u3002", "conclusion": "\u901a\u8fc7\u5c06\u68c0\u7d22\u5f15\u5bfc\u4e0e\u591a\u9636\u6bb5\u63a8\u7406\u76f8\u7ed3\u5408\uff0cMiRAGE\u51cf\u5c11\u4e86\u5bf9\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u4f9d\u8d56\uff0c\u4e3a\u6559\u80b2\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01236", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01236", "abs": "https://arxiv.org/abs/2511.01236", "authors": ["Junwen Zhang", "Changyue Liu", "Pengqi Fu", "Xiang Guo", "Ye Shi", "Xudong Liang", "Zhijian Wang", "Hanzhi Ma"], "title": "Don't Just Search, Understand: Semantic Path Planning Agent for Spherical Tensegrity Robots in Unknown Environments", "comment": "8 pages, 5 figures", "summary": "Endowed with inherent dynamical properties that grant them remarkable\nruggedness and adaptability, spherical tensegrity robots stand as prototypical\nexamples of hybrid softrigid designs and excellent mobile platforms. However,\npath planning for these robots in unknown environments presents a significant\nchallenge, requiring a delicate balance between efficient exploration and\nrobust planning. Traditional path planners, which treat the environment as a\ngeometric grid, often suffer from redundant searches and are prone to failure\nin complex scenarios due to their lack of semantic understanding. To overcome\nthese limitations, we reframe path planning in unknown environments as a\nsemantic reasoning task. We introduce a Semantic Agent for Tensegrity robots\n(SATPlanner) driven by a Large Language Model (LLM). SATPlanner leverages\nhigh-level environmental comprehension to generate efficient and reliable\nplanning strategies.At the core of SATPlanner is an Adaptive Observation Window\nmechanism, inspired by the \"fast\" and \"slow\" thinking paradigms of LLMs. This\nmechanism dynamically adjusts the perceptual field of the agent: it narrows for\nrapid traversal of open spaces and expands to reason about complex obstacle\nconfigurations. This allows the agent to construct a semantic belief of the\nenvironment, enabling the search space to grow only linearly with the path\nlength (O(L)) while maintaining path quality. We extensively evaluate\nSATPlanner in 1,000 simulation trials, where it achieves a 100% success rate,\noutperforming other real-time planning algorithms. Critically, SATPlanner\nreduces the search space by 37.2% compared to the A* algorithm while achieving\ncomparable, near-optimal path lengths. Finally, the practical feasibility of\nSATPlanner is validated on a physical spherical tensegrity robot prototype.", "AI": {"tldr": "SATPlanner\u662f\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u8def\u5f84\u89c4\u5212\u5668\uff0c\u4e13\u4e3a\u7403\u5f62\u5f20\u62c9\u6574\u4f53\u673a\u5668\u4eba\u8bbe\u8ba1\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u89c2\u5bdf\u7a97\u53e3\u673a\u5236\u5728\u672a\u77e5\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u6548\u53ef\u9760\u7684\u8def\u5f84\u89c4\u5212\u3002", "motivation": "\u4f20\u7edf\u8def\u5f84\u89c4\u5212\u5668\u5c06\u73af\u5883\u89c6\u4e3a\u51e0\u4f55\u7f51\u683c\uff0c\u5728\u590d\u6742\u573a\u666f\u4e2d\u5bb9\u6613\u5931\u8d25\u4e14\u7f3a\u4e4f\u8bed\u4e49\u7406\u89e3\u3002\u7403\u5f62\u5f20\u62c9\u6574\u4f53\u673a\u5668\u4eba\u4f5c\u4e3a\u6df7\u5408\u8f6f\u786c\u8bbe\u8ba1\u7684\u5178\u578b\u4ee3\u8868\uff0c\u5728\u672a\u77e5\u73af\u5883\u4e2d\u7684\u8def\u5f84\u89c4\u5212\u9700\u8981\u5e73\u8861\u63a2\u7d22\u6548\u7387\u548c\u89c4\u5212\u9c81\u68d2\u6027\u3002", "method": "\u5c06\u8def\u5f84\u89c4\u5212\u91cd\u65b0\u5b9a\u4e49\u4e3a\u8bed\u4e49\u63a8\u7406\u4efb\u52a1\uff0c\u63d0\u51faSATPlanner\u6846\u67b6\uff0c\u6838\u5fc3\u662f\u53d7LLM\u5feb\u6162\u601d\u7ef4\u542f\u53d1\u7684\u81ea\u9002\u5e94\u89c2\u5bdf\u7a97\u53e3\u673a\u5236\uff0c\u52a8\u6001\u8c03\u6574\u611f\u77e5\u8303\u56f4\uff1a\u5728\u5f00\u9614\u7a7a\u95f4\u7f29\u5c0f\u4ee5\u5feb\u901f\u7a7f\u8d8a\uff0c\u5728\u590d\u6742\u969c\u788d\u914d\u7f6e\u65f6\u6269\u5927\u4ee5\u8fdb\u884c\u63a8\u7406\u3002", "result": "\u57281000\u6b21\u4eff\u771f\u8bd5\u9a8c\u4e2d\u8fbe\u5230100%\u6210\u529f\u7387\uff0c\u4f18\u4e8e\u5176\u4ed6\u5b9e\u65f6\u89c4\u5212\u7b97\u6cd5\u3002\u76f8\u6bd4A*\u7b97\u6cd5\u51cf\u5c1137.2%\u7684\u641c\u7d22\u7a7a\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u63a5\u8fd1\u6700\u4f18\u7684\u8def\u5f84\u957f\u5ea6\u3002\u5728\u7269\u7406\u539f\u578b\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\u4e86\u53ef\u884c\u6027\u3002", "conclusion": "SATPlanner\u901a\u8fc7\u8bed\u4e49\u7406\u89e3\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u8def\u5f84\u89c4\u5212\uff0c\u641c\u7d22\u7a7a\u95f4\u4ec5\u968f\u8def\u5f84\u957f\u5ea6\u7ebf\u6027\u589e\u957f(O(L))\uff0c\u4e3a\u5f20\u62c9\u6574\u4f53\u673a\u5668\u4eba\u5728\u672a\u77e5\u73af\u5883\u4e2d\u7684\u5bfc\u822a\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01774", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.01774", "abs": "https://arxiv.org/abs/2511.01774", "authors": ["Alexander Schperberg", "Yusuke Tanaka", "Stefano Di Cairano", "Dennis Hong"], "title": "MOBIUS: A Multi-Modal Bipedal Robot that can Walk, Crawl, Climb, and Roll", "comment": "23 pages, 20 figures. Collaborative work between the Robotics and\n  Mechanisms Laboratory (RoMeLa) and Mitsubishi Electric Research Laboratories\n  (MERL)", "summary": "This article presents a Multi-Modal Bipedal Intelligent Urban Scout robot\n(MOBIUS) capable of walking, crawling, climbing, and rolling. MOBIUS features\nfour limbs--two 6-DoF arms with two-finger grippers for manipulation and\nclimbing, and two 4-DoF legs for locomotion--enabling smooth transitions across\ndiverse terrains without reconfiguration. A hybrid control architecture\ncombines reinforcement learning-based locomotion with model-based predictive\nand admittance control enhanced for safety by a Reference Governor toward\ncompliant contact interactions. A high-level MIQCP planner autonomously selects\nlocomotion modes to balance stability and energy efficiency. Hardware\nexperiments demonstrate robust gait transitions, dynamic climbing, and\nfull-body load support via pinch grasp. Overall, MOBIUS demonstrates the\nimportance of tight integration between morphology, high-level planning, and\ncontrol to enable mobile loco-manipulation and grasping, substantially\nexpanding its interaction capabilities, workspace, and traversability.", "AI": {"tldr": "MOBIUS\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u53cc\u8db3\u57ce\u5e02\u4fa6\u5bdf\u673a\u5668\u4eba\uff0c\u80fd\u591f\u884c\u8d70\u3001\u722c\u884c\u3001\u6500\u722c\u548c\u6eda\u52a8\uff0c\u901a\u8fc7\u6df7\u5408\u63a7\u5236\u67b6\u6784\u548c\u9ad8\u7ea7\u89c4\u5212\u5b9e\u73b0\u591a\u79cd\u8fd0\u52a8\u6a21\u5f0f\u7684\u5e73\u6ed1\u8f6c\u6362\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u5728\u590d\u6742\u57ce\u5e02\u73af\u5883\u4e2d\u7075\u6d3b\u79fb\u52a8\u548c\u64cd\u4f5c\u7684\u673a\u5668\u4eba\uff0c\u901a\u8fc7\u6574\u5408\u5f62\u6001\u3001\u9ad8\u7ea7\u89c4\u5212\u548c\u63a7\u5236\u6765\u6269\u5c55\u673a\u5668\u4eba\u7684\u4ea4\u4e92\u80fd\u529b\u3001\u5de5\u4f5c\u7a7a\u95f4\u548c\u53ef\u7a7f\u8d8a\u6027\u3002", "method": "\u91c7\u7528\u56db\u80a2\u4f53\u8bbe\u8ba1\uff08\u4e24\u4e2a6\u81ea\u7531\u5ea6\u624b\u81c2\u548c\u4e24\u4e2a4\u81ea\u7531\u5ea6\u817f\u90e8\uff09\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u7684\u8fd0\u52a8\u63a7\u5236\u4e0e\u57fa\u4e8e\u6a21\u578b\u7684\u9884\u6d4b\u548c\u5bfc\u7eb3\u63a7\u5236\uff0c\u4f7f\u7528MIQCP\u89c4\u5212\u5668\u81ea\u4e3b\u9009\u62e9\u8fd0\u52a8\u6a21\u5f0f\u3002", "result": "\u786c\u4ef6\u5b9e\u9a8c\u5c55\u793a\u4e86\u7a33\u5065\u7684\u6b65\u6001\u8f6c\u6362\u3001\u52a8\u6001\u6500\u722c\u548c\u901a\u8fc7\u634f\u63e1\u5b9e\u73b0\u7684\u5168\u8eab\u4f53\u8d1f\u8f7d\u652f\u6491\uff0c\u8bc1\u660e\u4e86\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u591a\u529f\u80fd\u6027\u3002", "conclusion": "MOBIUS\u5c55\u793a\u4e86\u5f62\u6001\u3001\u9ad8\u7ea7\u89c4\u5212\u548c\u63a7\u5236\u7d27\u5bc6\u96c6\u6210\u5bf9\u4e8e\u5b9e\u73b0\u79fb\u52a8\u5b9a\u4f4d\u64cd\u4f5c\u548c\u6293\u53d6\u7684\u91cd\u8981\u6027\uff0c\u663e\u8457\u6269\u5c55\u4e86\u673a\u5668\u4eba\u7684\u4ea4\u4e92\u80fd\u529b\u3001\u5de5\u4f5c\u7a7a\u95f4\u548c\u53ef\u7a7f\u8d8a\u6027\u3002"}}
{"id": "2511.01183", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01183", "abs": "https://arxiv.org/abs/2511.01183", "authors": ["Hainan Fang", "Yuanbo Wen", "Jun Bi", "Yihan Wang", "Tonghui He", "Yanlin Tang", "Di Huang", "Jiaming Guo", "Rui Zhang", "Qi Guo", "Yunji Chen"], "title": "QiMeng-NeuComBack: Self-Evolving Translation from IR to Assembly Code", "comment": "Accepted at NeurIPS 2025", "summary": "Compilers, while essential, are notoriously complex systems that demand\nprohibitively expensive human expertise to develop and maintain. The recent\nadvancements in Large Language Models (LLMs) offer a compelling new paradigm:\nNeural Compilation, which could potentially simplify compiler development for\nnew architectures and facilitate the discovery of innovative optimization\ntechniques. However, several critical obstacles impede its practical adoption.\nFirstly, a significant lack of dedicated benchmarks and robust evaluation\nmethodologies hinders objective assessment and tracking of progress in the\nfield. Secondly, systematically enhancing the reliability and performance of\nLLM-generated assembly remains a critical challenge. Addressing these\nchallenges, this paper introduces NeuComBack, a novel benchmark dataset\nspecifically designed for IR-to-assembly compilation. Leveraging this dataset,\nwe first define a foundational Neural Compilation workflow and conduct a\ncomprehensive evaluation of the capabilities of recent frontier LLMs on Neural\nCompilation, establishing new performance baselines. We further propose a\nself-evolving prompt optimization method that enables LLMs to iteratively\nevolve their internal prompt strategies by extracting insights from prior\nself-debugging traces, thereby enhancing their neural compilation capabilities.\nExperiments demonstrate that our method significantly improves both the\nfunctional correctness and the performance of LLM-generated assembly code.\nCompared to baseline prompts, the functional correctness rates improved from\n44% to 64% on x86_64 and from 36% to 58% on aarch64, respectively. More\nsignificantly, among the 16 correctly generated x86_64 programs using our\nmethod, 14 (87.5%) surpassed clang-O3 performance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86NeuComBack\u57fa\u51c6\u6570\u636e\u96c6\u548c\u81ea\u6f14\u5316\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728IR\u5230\u6c47\u7f16\u7f16\u8bd1\u4e2d\u7684\u529f\u80fd\u6b63\u786e\u6027\u548c\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u7f16\u8bd1\u5668\u5f00\u53d1\u590d\u6742\u4e14\u6602\u8d35\uff0c\u795e\u7ecf\u7f16\u8bd1(Neural Compilation)\u4f5c\u4e3a\u65b0\u8303\u5f0f\u6709\u6f5c\u529b\u7b80\u5316\u7f16\u8bd1\u5668\u5f00\u53d1\uff0c\u4f46\u7f3a\u4e4f\u4e13\u7528\u57fa\u51c6\u548c\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4e14LLM\u751f\u6210\u6c47\u7f16\u7684\u53ef\u9760\u6027\u548c\u6027\u80fd\u9700\u8981\u63d0\u5347\u3002", "method": "\u5f15\u5165NeuComBack\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5b9a\u4e49\u795e\u7ecf\u7f16\u8bd1\u5de5\u4f5c\u6d41\uff0c\u5e76\u63d0\u51fa\u81ea\u6f14\u5316\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\uff0c\u8ba9LLM\u4ece\u81ea\u6211\u8c03\u8bd5\u8f68\u8ff9\u4e2d\u63d0\u53d6\u6d1e\u5bdf\u6765\u8fed\u4ee3\u6f14\u5316\u63d0\u793a\u7b56\u7565\u3002", "result": "\u529f\u80fd\u6b63\u786e\u7387\u5728x86_64\u4e0a\u4ece44%\u63d0\u5347\u523064%\uff0c\u5728aarch64\u4e0a\u4ece36%\u63d0\u5347\u523058%\u3002\u5728\u6b63\u786e\u751f\u6210\u7684x86_64\u7a0b\u5e8f\u4e2d\uff0c87.5%\u8d85\u8d8a\u4e86clang-O3\u7684\u6027\u80fd\u3002", "conclusion": "NeuComBack\u57fa\u51c6\u548c\u81ea\u6f14\u5316\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u795e\u7ecf\u7f16\u8bd1\u9886\u57df\u7684\u5173\u952e\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u751f\u6210\u6c47\u7f16\u4ee3\u7801\u7684\u8d28\u91cf\u548c\u6027\u80fd\u3002"}}
{"id": "2511.01256", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01256", "abs": "https://arxiv.org/abs/2511.01256", "authors": ["Yasamin Foroutani", "Yasamin Mousavi-Motlagh", "Aya Barzelay", "Tsu-Chin Tsao"], "title": "Improving Needle Penetration via Precise Rotational Insertion Using Iterative Learning Control", "comment": "10 pages, 10 figures", "summary": "Achieving precise control of robotic tool paths is often challenged by\ninherent system misalignments, unmodeled dynamics, and actuation inaccuracies.\nThis work introduces an Iterative Learning Control (ILC) strategy to enable\nprecise rotational insertion of a tool during robotic surgery, improving\npenetration efficacy and safety compared to straight insertion tested in\nsubretinal injection. A 4 degree of freedom (DOF) robot manipulator is used,\nwhere misalignment of the fourth joint complicates the simple application of\nneedle rotation, motivating an ILC approach that iteratively adjusts joint\ncommands based on positional feedback. The process begins with calibrating the\nforward kinematics for the chosen surgical tool to achieve higher accuracy,\nfollowed by successive ILC iterations guided by Optical Coherence Tomography\n(OCT) volume scans to measure the error and refine control inputs. Experimental\nresults, tested on subretinal injection tasks on ex vivo pig eyes, show that\nthe optimized trajectory resulted in higher success rates in tissue penetration\nand subretinal injection compared to straight insertion, demonstrating the\neffectiveness of ILC in overcoming misalignment challenges. This approach\noffers potential applications for other high precision robot tasks requiring\ncontrolled insertions as well.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8fed\u4ee3\u5b66\u4e60\u63a7\u5236\u7b56\u7565\uff0c\u901a\u8fc7\u65cb\u8f6c\u63d2\u5165\u5de5\u5177\u63d0\u9ad8\u673a\u5668\u4eba\u624b\u672f\u4e2d\u7684\u7a7f\u900f\u6548\u7387\u548c\u5b89\u5168\u6027\uff0c\u76f8\u6bd4\u76f4\u7ebf\u63d2\u5165\u5728\u89c6\u7f51\u819c\u4e0b\u6ce8\u5c04\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u673a\u5668\u4eba\u5de5\u5177\u8def\u5f84\u7684\u7cbe\u786e\u63a7\u5236\u9762\u4e34\u7cfb\u7edf\u4e0d\u5bf9\u51c6\u3001\u672a\u5efa\u6a21\u52a8\u6001\u548c\u9a71\u52a8\u8bef\u5dee\u7b49\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u65cb\u8f6c\u63d2\u5165\u624b\u672f\u5de5\u5177\u65f6\uff0c\u7b2c\u56db\u5173\u8282\u7684\u4e0d\u5bf9\u51c6\u4f7f\u7b80\u5355\u5e94\u7528\u9488\u5934\u65cb\u8f6c\u53d8\u5f97\u590d\u6742\u3002", "method": "\u4f7f\u75284\u81ea\u7531\u5ea6\u673a\u5668\u4eba\u64cd\u7eb5\u5668\uff0c\u9996\u5148\u6821\u51c6\u9009\u5b9a\u624b\u672f\u5de5\u5177\u7684\u6b63\u5411\u8fd0\u52a8\u5b66\u4ee5\u63d0\u9ad8\u7cbe\u5ea6\uff0c\u7136\u540e\u57fa\u4e8eOCT\u4f53\u79ef\u626b\u63cf\u6d4b\u91cf\u8bef\u5dee\uff0c\u901a\u8fc7\u8fed\u4ee3\u5b66\u4e60\u63a7\u5236\u9010\u6b65\u8c03\u6574\u5173\u8282\u6307\u4ee4\u3002", "result": "\u5728\u79bb\u4f53\u732a\u773c\u89c6\u7f51\u819c\u4e0b\u6ce8\u5c04\u4efb\u52a1\u4e2d\uff0c\u4f18\u5316\u8f68\u8ff9\u76f8\u6bd4\u76f4\u7ebf\u63d2\u5165\u5728\u7ec4\u7ec7\u7a7f\u900f\u548c\u89c6\u7f51\u819c\u4e0b\u6ce8\u5c04\u65b9\u9762\u83b7\u5f97\u66f4\u9ad8\u6210\u529f\u7387\u3002", "conclusion": "ILC\u65b9\u6cd5\u6709\u6548\u514b\u670d\u4e86\u5bf9\u51c6\u6311\u6218\uff0c\u4e3a\u5176\u4ed6\u9700\u8981\u53d7\u63a7\u63d2\u5165\u7684\u9ad8\u7cbe\u5ea6\u673a\u5668\u4eba\u4efb\u52a1\u63d0\u4f9b\u4e86\u6f5c\u5728\u5e94\u7528\u3002"}}
{"id": "2511.01258", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01258", "abs": "https://arxiv.org/abs/2511.01258", "authors": ["Chuyue Lou", "M. Amine Atoui"], "title": "Graph Neural Network-Based Semi-Supervised Open-Set Fault Diagnosis for Marine Machinery Systems", "comment": null, "summary": "Recently, fault diagnosis methods for marine machinery systems based on deep\nlearning models have attracted considerable attention in the shipping industry.\nMost existing studies assume fault classes are consistent and known between the\ntraining and test datasets, and these methods perform well under controlled\nenvironment. In practice, however, previously unseen or unknown fault types\n(i.e., out-of-distribution or open-set observations not present during\ntraining) can occur, causing such methods to fail and posing a significant\nchallenge to their widespread industrial deployment. To address this challenge,\nthis paper proposes a semi-supervised open-set fault diagnosis (SOFD) framework\nthat enhances and extends the applicability of deep learning models in open-set\nfault diagnosis scenarios. The framework includes a reliability subset\nconstruction process, which uses a multi-layer fusion feature representation\nextracted by a supervised feature learning model to select an unlabeled test\nsubset. The labeled training set and pseudo-labeled test subset are then fed\ninto a semi-supervised diagnosis model to learn discriminative features for\neach class, enabling accurate classification of known faults and effective\ndetection of unknown samples. Experimental results on a public maritime\nbenchmark dataset demonstrate the effectiveness and superiority of the proposed\nSOFD framework.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u534a\u76d1\u7763\u5f00\u653e\u96c6\u6545\u969c\u8bca\u65ad\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u8239\u8236\u673a\u68b0\u7cfb\u7edf\u4e2d\u672a\u77e5\u6545\u969c\u7c7b\u578b\u7684\u68c0\u6d4b\u95ee\u9898", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5047\u8bbe\u8bad\u7ec3\u548c\u6d4b\u8bd5\u96c6\u4e2d\u7684\u6545\u969c\u7c7b\u578b\u4e00\u81f4\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u4f1a\u51fa\u73b0\u8bad\u7ec3\u65f6\u672a\u89c1\u8fc7\u7684\u672a\u77e5\u6545\u969c\u7c7b\u578b\uff0c\u5bfc\u81f4\u65b9\u6cd5\u5931\u6548", "method": "\u4f7f\u7528\u53ef\u9760\u6027\u5b50\u96c6\u6784\u5efa\u8fc7\u7a0b\uff0c\u901a\u8fc7\u76d1\u7763\u7279\u5f81\u5b66\u4e60\u6a21\u578b\u63d0\u53d6\u591a\u5c42\u878d\u5408\u7279\u5f81\u8868\u793a\u6765\u9009\u62e9\u672a\u6807\u8bb0\u6d4b\u8bd5\u5b50\u96c6\uff0c\u7136\u540e\u5c06\u6807\u8bb0\u8bad\u7ec3\u96c6\u548c\u4f2a\u6807\u8bb0\u6d4b\u8bd5\u5b50\u96c6\u8f93\u5165\u534a\u76d1\u7763\u8bca\u65ad\u6a21\u578b", "result": "\u5728\u516c\u5171\u6d77\u4e8b\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027", "conclusion": "SOFD\u6846\u67b6\u80fd\u591f\u51c6\u786e\u5206\u7c7b\u5df2\u77e5\u6545\u969c\u5e76\u6709\u6548\u68c0\u6d4b\u672a\u77e5\u6837\u672c\uff0c\u589e\u5f3a\u4e86\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5f00\u653e\u96c6\u6545\u969c\u8bca\u65ad\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027"}}
{"id": "2511.01272", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01272", "abs": "https://arxiv.org/abs/2511.01272", "authors": ["Sehui Jeong", "Magaly C. Aviles", "Athena X. Naylor", "Cynthia Sung", "Allison M. Okamura"], "title": "Design and Fabrication of Origami-Inspired Knitted Fabrics for Soft Robotics", "comment": null, "summary": "Soft robots employing compliant materials and deformable structures offer\ngreat potential for wearable devices that are comfortable and safe for human\ninteraction. However, achieving both structural integrity and compliance for\ncomfort remains a significant challenge. In this study, we present a novel\nfabrication and design method that combines the advantages of origami\nstructures with the material programmability and wearability of knitted\nfabrics. We introduce a general design method that translates origami patterns\ninto knit designs by programming both stitch and material patterns. The method\ncreates folds in preferred directions while suppressing unintended buckling and\nbending by selectively incorporating heat fusible yarn to create rigid panels\naround compliant creases. We experimentally quantify folding moments and show\nthat stitch patterning enhances folding directionality while the heat fusible\nyarn (1) keeps geometry consistent by reducing edge curl and (2) prevents\nout-of-plane deformations by stiffening panels. We demonstrate the framework\nthrough the successful reproduction of complex origami tessellations, including\nMiura-ori, Yoshimura, and Kresling patterns, and present a wearable knitted\nKaleidocycle robot capable of locomotion. The combination of structural\nreconfigurability, material programmability, and potential for manufacturing\nscalability highlights knitted origami as a promising platform for\nnext-generation wearable robotics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u6298\u7eb8\u7ed3\u6784\u4e0e\u9488\u7ec7\u7ec7\u7269\u76f8\u7ed3\u5408\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u7f16\u7a0b\u9488\u6cd5\u548c\u6750\u6599\u56fe\u6848\u6765\u5236\u9020\u53ef\u7a7f\u6234\u8f6f\u4f53\u673a\u5668\u4eba\uff0c\u5b9e\u73b0\u4e86\u7ed3\u6784\u53ef\u91cd\u6784\u6027\u548c\u8212\u9002\u6027\u7684\u5e73\u8861\u3002", "motivation": "\u8f6f\u4f53\u673a\u5668\u4eba\u4f7f\u7528\u67d4\u6027\u6750\u6599\uff0c\u9002\u5408\u4eba\u673a\u4ea4\u4e92\u7684\u53ef\u7a7f\u6234\u8bbe\u5907\uff0c\u4f46\u5b9e\u73b0\u7ed3\u6784\u5b8c\u6574\u6027\u548c\u8212\u9002\u6027\u4ecd\u5177\u6311\u6218\u3002", "method": "\u5c06\u6298\u7eb8\u56fe\u6848\u8f6c\u5316\u4e3a\u9488\u7ec7\u8bbe\u8ba1\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u4f7f\u7528\u70ed\u7194\u7eb1\u7ebf\u5728\u67d4\u6027\u6298\u75d5\u5468\u56f4\u521b\u5efa\u521a\u6027\u9762\u677f\uff0c\u63a7\u5236\u6298\u53e0\u65b9\u5411\u5e76\u9632\u6b62\u610f\u5916\u53d8\u5f62\u3002", "result": "\u6210\u529f\u590d\u5236\u4e86\u590d\u6742\u7684\u6298\u7eb8\u9576\u5d4c\u56fe\u6848\uff08Miura-ori\u3001Yoshimura\u3001Kresling\uff09\uff0c\u5e76\u5236\u9020\u51fa\u80fd\u591f\u8fd0\u52a8\u7684\u53ef\u7a7f\u6234\u9488\u7ec7\u4e07\u82b1\u7b52\u5faa\u73af\u673a\u5668\u4eba\u3002", "conclusion": "\u9488\u7ec7\u6298\u7eb8\u7ed3\u5408\u4e86\u7ed3\u6784\u53ef\u91cd\u6784\u6027\u3001\u6750\u6599\u53ef\u7f16\u7a0b\u6027\u548c\u5236\u9020\u53ef\u6269\u5c55\u6027\uff0c\u662f\u4e0b\u4e00\u4ee3\u53ef\u7a7f\u6234\u673a\u5668\u4eba\u7684\u6709\u524d\u666f\u5e73\u53f0\u3002"}}
{"id": "2511.01311", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01311", "abs": "https://arxiv.org/abs/2511.01311", "authors": ["Filip Naudot", "Tobias Sundqvist", "Timotheus Kampik"], "title": "llmSHAP: A Principled Approach to LLM Explainability", "comment": null, "summary": "Feature attribution methods help make machine learning-based inference\nexplainable by determining how much one or several features have contributed to\na model's output. A particularly popular attribution method is based on the\nShapley value from cooperative game theory, a measure that guarantees the\nsatisfaction of several desirable principles, assuming deterministic inference.\nWe apply the Shapley value to feature attribution in large language model\n(LLM)-based decision support systems, where inference is, by design, stochastic\n(non-deterministic). We then demonstrate when we can and cannot guarantee\nShapley value principle satisfaction across different implementation variants\napplied to LLM-based decision support, and analyze how the stochastic nature of\nLLMs affects these guarantees. We also highlight trade-offs between explainable\ninference speed, agreement with exact Shapley value attributions, and principle\nattainment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u968f\u673a\u63a8\u7406\u7cfb\u7edf\u4e2d\u5e94\u7528Shapley\u503c\u8fdb\u884c\u7279\u5f81\u5f52\u56e0\u7684\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u5b9e\u73b0\u53d8\u4f53\u4e0bShapley\u503c\u539f\u5219\u7684\u6ee1\u8db3\u60c5\u51b5\uff0c\u5e76\u63a2\u8ba8\u4e86\u63a8\u7406\u901f\u5ea6\u3001\u4e0e\u7cbe\u786eShapley\u503c\u5f52\u56e0\u7684\u4e00\u81f4\u6027\u4ee5\u53ca\u539f\u5219\u8fbe\u6210\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "motivation": "\u7279\u5f81\u5f52\u56e0\u65b9\u6cd5\u4f7f\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u63a8\u7406\u53ef\u89e3\u91ca\uff0cShapley\u503c\u56e0\u5176\u6ee1\u8db3\u591a\u4e2a\u7406\u60f3\u539f\u5219\u800c\u6d41\u884c\u3002\u4f46\u5728LLM\u8fd9\u79cd\u968f\u673a\u63a8\u7406\u7cfb\u7edf\u4e2d\uff0c\u8fd9\u4e9b\u539f\u5219\u7684\u4fdd\u8bc1\u60c5\u51b5\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u8981\u7814\u7a76Shapley\u503c\u5728\u968f\u673a\u73af\u5883\u4e0b\u7684\u9002\u7528\u6027\u3002", "method": "\u5c06Shapley\u503c\u5e94\u7528\u4e8e\u57fa\u4e8eLLM\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u4e2d\u7684\u7279\u5f81\u5f52\u56e0\uff0c\u5206\u6790\u4e0d\u540c\u5b9e\u73b0\u53d8\u4f53\u4e0bShapley\u503c\u539f\u5219\u7684\u6ee1\u8db3\u60c5\u51b5\uff0c\u5e76\u7814\u7a76LLM\u7684\u968f\u673a\u6027\u5bf9\u8fd9\u4e9b\u4fdd\u8bc1\u7684\u5f71\u54cd\u3002", "result": "\u5c55\u793a\u4e86\u5728\u4e0d\u540c\u5b9e\u73b0\u53d8\u4f53\u4e0b\u80fd\u591f\u548c\u4e0d\u80fd\u4fdd\u8bc1Shapley\u503c\u539f\u5219\u6ee1\u8db3\u7684\u60c5\u51b5\uff0c\u5206\u6790\u4e86LLM\u7684\u968f\u673a\u6027\u5982\u4f55\u5f71\u54cd\u8fd9\u4e9b\u4fdd\u8bc1\uff0c\u5e76\u7a81\u51fa\u4e86\u63a8\u7406\u901f\u5ea6\u3001\u4e0e\u7cbe\u786eShapley\u503c\u5f52\u56e0\u7684\u4e00\u81f4\u6027\u4ee5\u53ca\u539f\u5219\u8fbe\u6210\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u5728\u57fa\u4e8eLLM\u7684\u968f\u673a\u63a8\u7406\u7cfb\u7edf\u4e2d\u5e94\u7528Shapley\u503c\u8fdb\u884c\u7279\u5f81\u5f52\u56e0\u65f6\uff0c\u9700\u8981\u4ed4\u7ec6\u8003\u8651\u4e0d\u540c\u5b9e\u73b0\u65b9\u6cd5\u7684\u6743\u8861\uff0c\u56e0\u4e3aLLM\u7684\u968f\u673a\u6027\u4f1a\u5f71\u54cdShapley\u503c\u539f\u5219\u7684\u4fdd\u8bc1\uff0c\u9700\u8981\u5728\u89e3\u91ca\u6027\u3001\u51c6\u786e\u6027\u548c\u6548\u7387\u4e4b\u95f4\u505a\u51fa\u5e73\u8861\u3002"}}
{"id": "2511.01276", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01276", "abs": "https://arxiv.org/abs/2511.01276", "authors": ["Yiyao Ma", "Kai Chen", "Kexin Zheng", "Qi Dou"], "title": "Contact Map Transfer with Conditional Diffusion Model for Generalizable Dexterous Grasp Generation", "comment": null, "summary": "Dexterous grasp generation is a fundamental challenge in robotics, requiring\nboth grasp stability and adaptability across diverse objects and tasks.\nAnalytical methods ensure stable grasps but are inefficient and lack task\nadaptability, while generative approaches improve efficiency and task\nintegration but generalize poorly to unseen objects and tasks due to data\nlimitations. In this paper, we propose a transfer-based framework for dexterous\ngrasp generation, leveraging a conditional diffusion model to transfer\nhigh-quality grasps from shape templates to novel objects within the same\ncategory. Specifically, we reformulate the grasp transfer problem as the\ngeneration of an object contact map, incorporating object shape similarity and\ntask specifications into the diffusion process. To handle complex shape\nvariations, we introduce a dual mapping mechanism, capturing intricate\ngeometric relationship between shape templates and novel objects. Beyond the\ncontact map, we derive two additional object-centric maps, the part map and\ndirection map, to encode finer contact details for more stable grasps. We then\ndevelop a cascaded conditional diffusion model framework to jointly transfer\nthese three maps, ensuring their intra-consistency. Finally, we introduce a\nrobust grasp recovery mechanism, identifying reliable contact points and\noptimizing grasp configurations efficiently. Extensive experiments demonstrate\nthe superiority of our proposed method. Our approach effectively balances grasp\nquality, generation efficiency, and generalization performance across various\ntasks. Project homepage: https://cmtdiffusion.github.io/", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u6269\u6563\u6a21\u578b\u7684\u7075\u5de7\u6293\u53d6\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u9ad8\u8d28\u91cf\u6293\u53d6\u4ece\u5f62\u72b6\u6a21\u677f\u8f6c\u79fb\u5230\u540c\u7c7b\u65b0\u7269\u4f53\uff0c\u89e3\u51b3\u4e86\u6293\u53d6\u7a33\u5b9a\u6027\u548c\u4efb\u52a1\u9002\u5e94\u6027\u7684\u6311\u6218\u3002", "motivation": "\u7075\u5de7\u6293\u53d6\u751f\u6210\u9700\u8981\u5e73\u8861\u6293\u53d6\u7a33\u5b9a\u6027\u548c\u4efb\u52a1\u9002\u5e94\u6027\u3002\u5206\u6790\u65b9\u6cd5\u7a33\u5b9a\u4f46\u6548\u7387\u4f4e\u4e14\u7f3a\u4e4f\u4efb\u52a1\u9002\u5e94\u6027\uff0c\u751f\u6210\u65b9\u6cd5\u6548\u7387\u9ad8\u4f46\u6cdb\u5316\u80fd\u529b\u5dee\u3002\u9700\u8981\u4e00\u79cd\u80fd\u517c\u987e\u7a33\u5b9a\u6027\u548c\u6cdb\u5316\u80fd\u529b\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u6761\u4ef6\u6269\u6563\u6a21\u578b\u5c06\u6293\u53d6\u8f6c\u79fb\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u7269\u4f53\u63a5\u89e6\u56fe\u751f\u6210\uff0c\u5f15\u5165\u53cc\u6620\u5c04\u673a\u5236\u5904\u7406\u590d\u6742\u5f62\u72b6\u53d8\u5316\uff0c\u6784\u5efa\u63a5\u89e6\u56fe\u3001\u90e8\u4ef6\u56fe\u548c\u65b9\u5411\u56fe\u4e09\u4e2a\u7269\u4f53\u4e2d\u5fc3\u56fe\uff0c\u91c7\u7528\u7ea7\u8054\u6761\u4ef6\u6269\u6563\u6a21\u578b\u6846\u67b6\u8054\u5408\u8f6c\u79fb\u8fd9\u4e09\u4e2a\u56fe\uff0c\u5e76\u5f00\u53d1\u4e86\u9c81\u68d2\u7684\u6293\u53d6\u6062\u590d\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u6293\u53d6\u8d28\u91cf\u3001\u751f\u6210\u6548\u7387\u548c\u6cdb\u5316\u6027\u80fd\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0c\u80fd\u591f\u6709\u6548\u5e73\u8861\u8fd9\u4e9b\u5173\u952e\u6307\u6807\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u6293\u53d6\u8f6c\u79fb\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u7075\u5de7\u6293\u53d6\u751f\u6210\u4e2d\u7684\u7a33\u5b9a\u6027\u548c\u6cdb\u5316\u95ee\u9898\uff0c\u4e3a\u673a\u5668\u4eba\u6293\u53d6\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01320", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01320", "abs": "https://arxiv.org/abs/2511.01320", "authors": ["Ziqi Wang", "Hailiang Zhao", "Yuhao Yang", "Daojiang Hu", "Cheng Bao", "Mingyi Liu", "Kai Di", "Schahram Dustdar", "Zhongjie Wang", "Shuiguang Deng"], "title": "OmniFuser: Adaptive Multimodal Fusion for Service-Oriented Predictive Maintenance", "comment": null, "summary": "Accurate and timely prediction of tool conditions is critical for intelligent\nmanufacturing systems, where unplanned tool failures can lead to quality\ndegradation and production downtime. In modern industrial environments,\npredictive maintenance is increasingly implemented as an intelligent service\nthat integrates sensing, analysis, and decision support across production\nprocesses. To meet the demand for reliable and service-oriented operation, we\npresent OmniFuser, a multimodal learning framework for predictive maintenance\nof milling tools that leverages both visual and sensor data. It performs\nparallel feature extraction from high-resolution tool images and cutting-force\nsignals, capturing complementary spatiotemporal patterns across modalities. To\neffectively integrate heterogeneous features, OmniFuser employs a\ncontamination-free cross-modal fusion mechanism that disentangles shared and\nmodality-specific components, allowing for efficient cross-modal interaction.\nFurthermore, a recursive refinement pathway functions as an anchor mechanism,\nconsistently retaining residual information to stabilize fusion dynamics. The\nlearned representations can be encapsulated as reusable maintenance service\nmodules, supporting both tool-state classification (e.g., Sharp, Used, Dulled)\nand multi-step force signal forecasting. Experiments on real-world milling\ndatasets demonstrate that OmniFuser consistently outperforms state-of-the-art\nbaselines, providing a dependable foundation for building intelligent\nindustrial maintenance services.", "AI": {"tldr": "\u63d0\u51fa\u4e86OmniFuser\u591a\u6a21\u6001\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u89c6\u89c9\u548c\u4f20\u611f\u5668\u6570\u636e\u8fdb\u884c\u94e3\u524a\u5200\u5177\u9884\u6d4b\u6027\u7ef4\u62a4\uff0c\u5728\u5200\u5177\u72b6\u6001\u5206\u7c7b\u548c\u529b\u4fe1\u53f7\u9884\u6d4b\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u667a\u80fd\u5236\u9020\u7cfb\u7edf\u4e2d\u51c6\u786e\u53ca\u65f6\u7684\u5200\u5177\u72b6\u6001\u9884\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u975e\u8ba1\u5212\u6027\u5200\u5177\u6545\u969c\u4f1a\u5bfc\u81f4\u8d28\u91cf\u4e0b\u964d\u548c\u751f\u4ea7\u505c\u673a\u3002\u9700\u8981\u53ef\u9760\u7684\u670d\u52a1\u5bfc\u5411\u578b\u9884\u6d4b\u7ef4\u62a4\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5e76\u884c\u7279\u5f81\u63d0\u53d6\u4ece\u9ad8\u5206\u8fa8\u7387\u5200\u5177\u56fe\u50cf\u548c\u5207\u524a\u529b\u4fe1\u53f7\u4e2d\u6355\u83b7\u4e92\u8865\u7684\u65f6\u7a7a\u6a21\u5f0f\uff0c\u4f7f\u7528\u65e0\u6c61\u67d3\u8de8\u6a21\u6001\u878d\u5408\u673a\u5236\u5206\u79bb\u5171\u4eab\u548c\u6a21\u6001\u7279\u5b9a\u7ec4\u4ef6\uff0c\u5e76\u901a\u8fc7\u9012\u5f52\u7cbe\u70bc\u8def\u5f84\u4fdd\u7559\u6b8b\u5dee\u4fe1\u606f\u7a33\u5b9a\u878d\u5408\u52a8\u6001\u3002", "result": "\u5728\u771f\u5b9e\u94e3\u524a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cOmniFuser\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e3a\u6784\u5efa\u667a\u80fd\u5de5\u4e1a\u7ef4\u62a4\u670d\u52a1\u63d0\u4f9b\u4e86\u53ef\u9760\u57fa\u7840\u3002", "conclusion": "OmniFuser\u6846\u67b6\u80fd\u591f\u6709\u6548\u6574\u5408\u5f02\u6784\u591a\u6a21\u6001\u6570\u636e\uff0c\u5b66\u4e60\u5230\u7684\u8868\u793a\u53ef\u5c01\u88c5\u4e3a\u53ef\u91cd\u7528\u7ef4\u62a4\u670d\u52a1\u6a21\u5757\uff0c\u652f\u6301\u5200\u5177\u72b6\u6001\u5206\u7c7b\u548c\u591a\u6b65\u529b\u4fe1\u53f7\u9884\u6d4b\uff0c\u662f\u667a\u80fd\u5de5\u4e1a\u7ef4\u62a4\u670d\u52a1\u7684\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01329", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01329", "abs": "https://arxiv.org/abs/2511.01329", "authors": ["Ying Song", "Yijing Wang", "Hui Yang", "Weihan Jin", "Jun Xiong", "Congyi Zhou", "Jialin Zhu", "Xiang Gao", "Rong Chen", "HuaGuang Deng", "Ying Dai", "Fei Xiao", "Haihong Tang", "Bo Zheng", "KaiFu Zhang"], "title": "Unbiased Platform-Level Causal Estimation for Search Systems: A Competitive Isolation PSM-DID Framework", "comment": null, "summary": "Evaluating platform-level interventions in search-based two-sided\nmarketplaces is fundamentally challenged by systemic effects such as spillovers\nand network interference. While widely used for causal inference, the PSM\n(Propensity Score Matching) - DID (Difference-in-Differences) framework remains\nsusceptible to selection bias and cross-unit interference from unaccounted\nspillovers. In this paper, we introduced Competitive Isolation PSM-DID, a novel\ncausal framework that integrates propensity score matching with competitive\nisolation to enable platform-level effect measurement (e.g., order volume, GMV)\ninstead of item-level metrics in search systems.\n  Our approach provides theoretically guaranteed unbiased estimation under\nmutual exclusion conditions, with an open dataset released to support\nreproducible research on marketplace interference (github.com/xxxx). Extensive\nexperiments demonstrate significant reductions in interference effects and\nestimation variance compared to baseline methods. Successful deployment in a\nlarge-scale marketplace confirms the framework's practical utility for\nplatform-level causal inference.", "AI": {"tldr": "\u63d0\u51fa\u4e86Competitive Isolation PSM-DID\u6846\u67b6\uff0c\u7ed3\u5408\u503e\u5411\u5f97\u5206\u5339\u914d\u548c\u7ade\u4e89\u9694\u79bb\uff0c\u7528\u4e8e\u89e3\u51b3\u641c\u7d22\u578b\u53cc\u8fb9\u5e02\u573a\u4e2d\u5e73\u53f0\u7ea7\u5e72\u9884\u8bc4\u4f30\u7684\u7cfb\u7edf\u6027\u6548\u5e94\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfPSM-DID\u6846\u67b6\u5728\u641c\u7d22\u578b\u53cc\u8fb9\u5e02\u573a\u4e2d\u9762\u4e34\u9009\u62e9\u504f\u5dee\u548c\u8de8\u5355\u5143\u5e72\u6270\u95ee\u9898\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u6ea2\u51fa\u6548\u5e94\u548c\u7f51\u7edc\u5e72\u6270\u3002", "method": "\u5c06\u503e\u5411\u5f97\u5206\u5339\u914d\u4e0e\u7ade\u4e89\u9694\u79bb\u76f8\u7ed3\u5408\uff0c\u5728\u4e92\u65a5\u6761\u4ef6\u4e0b\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u7684\u65e0\u504f\u4f30\u8ba1\uff0c\u652f\u6301\u5e73\u53f0\u7ea7\u6307\u6807\uff08\u5982\u8ba2\u5355\u91cf\u3001GMV\uff09\u800c\u975e\u5546\u54c1\u7ea7\u6307\u6807\u7684\u6d4b\u91cf\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u663e\u8457\u964d\u4f4e\u4e86\u5e72\u6270\u6548\u5e94\u548c\u4f30\u8ba1\u65b9\u5dee\uff0c\u5728\u5927\u89c4\u6a21\u5e02\u573a\u5e73\u53f0\u6210\u529f\u90e8\u7f72\u9a8c\u8bc1\u4e86\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5e73\u53f0\u7ea7\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u53d1\u5e03\u4e86\u5f00\u6e90\u6570\u636e\u96c6\u652f\u6301\u53ef\u91cd\u590d\u7814\u7a76\u3002"}}
{"id": "2511.01294", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01294", "abs": "https://arxiv.org/abs/2511.01294", "authors": ["Jiawei Wang", "Dingyou Wang", "Jiaming Hu", "Qixuan Zhang", "Jingyi Yu", "Lan Xu"], "title": "Kinematify: Open-Vocabulary Synthesis of High-DoF Articulated Objects", "comment": null, "summary": "A deep understanding of kinematic structures and movable components is\nessential for enabling robots to manipulate objects and model their own\narticulated forms. Such understanding is captured through articulated objects,\nwhich are essential for tasks such as physical simulation, motion planning, and\npolicy learning. However, creating these models, particularly for complex\nsystems like robots or objects with high degrees of freedom (DoF), remains a\nsignificant challenge. Existing methods typically rely on motion sequences or\nstrong assumptions from hand-curated datasets, which hinders scalability. In\nthis paper, we introduce Kinematify, an automated framework that synthesizes\narticulated objects directly from arbitrary RGB images or text prompts. Our\nmethod addresses two core challenges: (i) inferring kinematic topologies for\nhigh-DoF objects and (ii) estimating joint parameters from static geometry. To\nachieve this, we combine MCTS search for structural inference with\ngeometry-driven optimization for joint reasoning, producing physically\nconsistent and functionally valid descriptions. We evaluate Kinematify on\ndiverse inputs from both synthetic and real-world environments, demonstrating\nimprovements in registration and kinematic topology accuracy over prior work.", "AI": {"tldr": "Kinematify\u662f\u4e00\u4e2a\u4eceRGB\u56fe\u50cf\u6216\u6587\u672c\u63d0\u793a\u81ea\u52a8\u5408\u6210\u94f0\u63a5\u7269\u4f53\u7684\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u9ad8\u81ea\u7531\u5ea6\u7269\u4f53\u8fd0\u52a8\u5b66\u62d3\u6251\u63a8\u65ad\u548c\u9759\u6001\u51e0\u4f55\u5173\u8282\u53c2\u6570\u4f30\u8ba1\u7684\u6311\u6218\u3002", "motivation": "\u94f0\u63a5\u7269\u4f53\u5efa\u6a21\u5bf9\u4e8e\u673a\u5668\u4eba\u64cd\u4f5c\u548c\u7269\u7406\u6a21\u62df\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u8fd0\u52a8\u5e8f\u5217\u6216\u624b\u5de5\u6570\u636e\u96c6\uff0c\u96be\u4ee5\u6269\u5c55\u5230\u590d\u6742\u7cfb\u7edf\u3002", "method": "\u7ed3\u5408MCTS\u641c\u7d22\u8fdb\u884c\u7ed3\u6784\u63a8\u65ad\u548c\u51e0\u4f55\u9a71\u52a8\u7684\u4f18\u5316\u8fdb\u884c\u5173\u8282\u63a8\u7406\uff0c\u751f\u6210\u7269\u7406\u4e00\u81f4\u4e14\u529f\u80fd\u6709\u6548\u7684\u63cf\u8ff0\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u591a\u6837\u5316\u8f93\u5165\u4e0a\u8bc4\u4f30\uff0c\u5728\u914d\u51c6\u548c\u8fd0\u52a8\u5b66\u62d3\u6251\u51c6\u786e\u6027\u65b9\u9762\u4f18\u4e8e\u5148\u524d\u5de5\u4f5c\u3002", "conclusion": "Kinematify\u80fd\u591f\u4ece\u9759\u6001\u8f93\u5165\u81ea\u52a8\u751f\u6210\u94f0\u63a5\u7269\u4f53\u6a21\u578b\uff0c\u4e3a\u673a\u5668\u4eba\u64cd\u4f5c\u548c\u7269\u7406\u6a21\u62df\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01363", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01363", "abs": "https://arxiv.org/abs/2511.01363", "authors": ["Giuseppe Riva", "Brenda K. Wiederhold", "Fabrizia Mantovani"], "title": "Automatic Minds: Cognitive Parallels Between Hypnotic States and Large Language Model Processing", "comment": "4 Tables", "summary": "The cognitive processes of the hypnotized mind and the computational\noperations of large language models (LLMs) share deep functional parallels.\nBoth systems generate sophisticated, contextually appropriate behavior through\nautomatic pattern-completion mechanisms operating with limited or unreliable\nexecutive oversight. This review examines this convergence across three\nprinciples: automaticity, in which responses emerge from associative rather\nthan deliberative processes; suppressed monitoring, leading to errors such as\nconfabulation in hypnosis and hallucination in LLMs; and heightened contextual\ndependency, where immediate cues (for example, the suggestion of a therapist or\nthe prompt of the user) override stable knowledge.\n  These mechanisms reveal an observer-relative meaning gap: both systems\nproduce coherent but ungrounded outputs that require an external interpreter to\nsupply meaning. Hypnosis and LLMs also exemplify functional agency - the\ncapacity for complex, goal-directed, context-sensitive behavior - without\nsubjective agency, the conscious awareness of intention and ownership that\ndefines human action. This distinction clarifies how purposive behavior can\nemerge without self-reflective consciousness, governed instead by structural\nand contextual dynamics. Finally, both domains illuminate the phenomenon of\nscheming: automatic, goal-directed pattern generation that unfolds without\nreflective awareness. Hypnosis provides an experimental model for understanding\nhow intention can become dissociated from conscious deliberation, offering\ninsights into the hidden motivational dynamics of artificial systems.\nRecognizing these parallels suggests that the future of reliable AI lies in\nhybrid architectures that integrate generative fluency with mechanisms of\nexecutive monitoring, an approach inspired by the complex, self-regulating\narchitecture of the human mind.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u50ac\u7720\u72b6\u6001\u4e0b\u7684\u8ba4\u77e5\u8fc7\u7a0b\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u4e4b\u95f4\u7684\u6df1\u5c42\u529f\u80fd\u76f8\u4f3c\u6027\uff0c\u5305\u62ec\u81ea\u52a8\u6027\u3001\u76d1\u63a7\u6291\u5236\u548c\u60c5\u5883\u4f9d\u8d56\u6027\u7b49\u673a\u5236\uff0c\u63ed\u793a\u4e86\u65e0\u4e3b\u89c2\u610f\u8bc6\u7684\u590d\u6742\u884c\u4e3a\u5982\u4f55\u4ea7\u751f\uff0c\u5e76\u63d0\u51fa\u4e86\u7ed3\u5408\u751f\u6210\u6d41\u7545\u6027\u548c\u6267\u884c\u76d1\u63a7\u7684\u6df7\u5408AI\u67b6\u6784\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u4eba\u7c7b\u50ac\u7720\u8ba4\u77e5\u4e0eAI\u7cfb\u7edf\u4e4b\u95f4\u7684\u529f\u80fd\u76f8\u4f3c\u6027\uff0c\u4ee5\u7406\u89e3\u65e0\u4e3b\u89c2\u610f\u8bc6\u4e0b\u590d\u6742\u884c\u4e3a\u7684\u4ea7\u751f\u673a\u5236\uff0c\u5e76\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u542f\u793a\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u4ece\u4e09\u4e2a\u6838\u5fc3\u539f\u5219\uff08\u81ea\u52a8\u6027\u3001\u76d1\u63a7\u6291\u5236\u3001\u60c5\u5883\u4f9d\u8d56\u6027\uff09\u7cfb\u7edf\u6027\u5730\u5bf9\u6bd4\u50ac\u7720\u8ba4\u77e5\u8fc7\u7a0b\u4e0eLLMs\u7684\u8ba1\u7b97\u64cd\u4f5c\u3002", "result": "\u53d1\u73b0\u4e24\u79cd\u7cfb\u7edf\u90fd\u8868\u73b0\u51fa\u89c2\u5bdf\u8005\u76f8\u5bf9\u7684\u610f\u4e49\u9e3f\u6c9f\u3001\u529f\u80fd\u6027\u4ee3\u7406\u800c\u975e\u4e3b\u89c2\u6027\u4ee3\u7406\uff0c\u4ee5\u53ca\u65e0\u53cd\u601d\u610f\u8bc6\u7684\u56fe\u5f0f\u5316\u884c\u4e3a\u6a21\u5f0f\u3002", "conclusion": "\u672a\u6765\u53ef\u9760AI\u7684\u53d1\u5c55\u65b9\u5411\u5e94\u8be5\u662f\u6574\u5408\u751f\u6210\u6d41\u7545\u6027\u548c\u6267\u884c\u76d1\u63a7\u673a\u5236\u7684\u6df7\u5408\u67b6\u6784\uff0c\u501f\u9274\u4eba\u7c7b\u5fc3\u667a\u7684\u590d\u6742\u81ea\u6211\u8c03\u8282\u7ed3\u6784\u3002"}}
{"id": "2511.01331", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01331", "abs": "https://arxiv.org/abs/2511.01331", "authors": ["Hongyin Zhang", "Shuo Zhang", "Junxi Jin", "Qixin Zeng", "Runze Li", "Donglin Wang"], "title": "RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models", "comment": null, "summary": "Vision-Language-Action (VLA) models have recently emerged as powerful\ngeneral-purpose policies for robotic manipulation, benefiting from large-scale\nmulti-modal pre-training. However, they often fail to generalize reliably in\nout-of-distribution deployments, where unavoidable disturbances such as\nobservation noise, sensor errors, or actuation perturbations become prevalent.\nWhile recent Reinforcement Learning (RL)-based post-training provides a\npractical means to adapt pre-trained VLA models, existing methods mainly\nemphasize reward maximization and overlook robustness to environmental\nuncertainty. In this work, we introduce RobustVLA, a lightweight online RL\npost-training method designed to explicitly enhance the resilience of VLA\nmodels. Through a systematic robustness analysis, we identify two key\nregularizations: Jacobian regularization, which mitigates sensitivity to\nobservation noise, and smoothness regularization, which stabilizes policies\nunder action perturbations. Extensive experiments across diverse robotic\nenvironments demonstrate that RobustVLA significantly outperforms prior\nstate-of-the-art methods in robustness and reliability. Our results highlight\nthe importance of principled robustness-aware RL post-training as a key step\ntoward improving the reliability and robustness of VLA models.", "AI": {"tldr": "RobustVLA\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u589e\u5f3a\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c(VLA)\u6a21\u578b\u5728\u73af\u5883\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684VLA\u6a21\u578b\u5728\u5206\u5e03\u5916\u90e8\u7f72\u65f6\uff0c\u5bf9\u89c2\u6d4b\u566a\u58f0\u3001\u4f20\u611f\u5668\u8bef\u5dee\u548c\u6267\u884c\u6270\u52a8\u7b49\u4e0d\u53ef\u907f\u514d\u7684\u5e72\u6270\u7f3a\u4e4f\u9c81\u68d2\u6027\u3002\u867d\u7136\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u53ef\u4ee5\u9002\u5e94\u9884\u8bad\u7ec3\u7684VLA\u6a21\u578b\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5956\u52b1\u6700\u5927\u5316\uff0c\u5ffd\u89c6\u4e86\u73af\u5883\u4e0d\u786e\u5b9a\u6027\u7684\u9c81\u68d2\u6027\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u9c81\u68d2\u6027\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u5173\u952e\u6b63\u5219\u5316\uff1a\u96c5\u53ef\u6bd4\u6b63\u5219\u5316\uff08\u51cf\u8f7b\u5bf9\u89c2\u6d4b\u566a\u58f0\u7684\u654f\u611f\u6027\uff09\u548c\u5e73\u6ed1\u6027\u6b63\u5219\u5316\uff08\u5728\u52a8\u4f5c\u6270\u52a8\u4e0b\u7a33\u5b9a\u7b56\u7565\uff09\u3002", "result": "\u5728\u591a\u79cd\u673a\u5668\u4eba\u73af\u5883\u4e2d\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cRobustVLA\u5728\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u539f\u5219\u6027\u7684\u9c81\u68d2\u6027\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u662f\u63d0\u9ad8VLA\u6a21\u578b\u53ef\u9760\u6027\u548c\u9c81\u68d2\u6027\u7684\u5173\u952e\u6b65\u9aa4\u3002"}}
{"id": "2511.01375", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01375", "abs": "https://arxiv.org/abs/2511.01375", "authors": ["Hamin Koo", "Minseon Kim", "Jaehyung Kim"], "title": "Align to Misalign: Automatic LLM Jailbreak with Meta-Optimized LLM Judges", "comment": "under review, 28 pages", "summary": "Identifying the vulnerabilities of large language models (LLMs) is crucial\nfor improving their safety by addressing inherent weaknesses. Jailbreaks, in\nwhich adversaries bypass safeguards with crafted input prompts, play a central\nrole in red-teaming by probing LLMs to elicit unintended or unsafe behaviors.\nRecent optimization-based jailbreak approaches iteratively refine attack\nprompts by leveraging LLMs. However, they often rely heavily on either binary\nattack success rate (ASR) signals, which are sparse, or manually crafted\nscoring templates, which introduce human bias and uncertainty in the scoring\noutcomes. To address these limitations, we introduce AMIS (Align to MISalign),\na meta-optimization framework that jointly evolves jailbreak prompts and\nscoring templates through a bi-level structure. In the inner loop, prompts are\nrefined using fine-grained and dense feedback using a fixed scoring template.\nIn the outer loop, the template is optimized using an ASR alignment score,\ngradually evolving to better reflect true attack outcomes across queries. This\nco-optimization process yields progressively stronger jailbreak prompts and\nmore calibrated scoring signals. Evaluations on AdvBench and JBB-Behaviors\ndemonstrate that AMIS achieves state-of-the-art performance, including 88.0%\nASR on Claude-3.5-Haiku and 100.0% ASR on Claude-4-Sonnet, outperforming\nexisting baselines by substantial margins.", "AI": {"tldr": "AMIS\u662f\u4e00\u4e2a\u5143\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u5c42\u7ed3\u6784\u8054\u5408\u6f14\u5316\u8d8a\u72f1\u63d0\u793a\u548c\u8bc4\u5206\u6a21\u677f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u7a00\u758f\u4e8c\u5143\u4fe1\u53f7\u6216\u4eba\u5de5\u8bc4\u5206\u6a21\u677f\u7684\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u8d8a\u72f1\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u7a00\u758f\u7684\u4e8c\u5143\u653b\u51fb\u6210\u529f\u7387\u4fe1\u53f7\uff0c\u8981\u4e48\u4f7f\u7528\u5f15\u5165\u4eba\u4e3a\u504f\u89c1\u548c\u4e0d\u786e\u5b9a\u6027\u7684\u624b\u52a8\u8bc4\u5206\u6a21\u677f\uff0c\u9650\u5236\u4e86\u8d8a\u72f1\u6548\u679c\u548c\u8bc4\u4f30\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u53cc\u5c42\u4f18\u5316\u7ed3\u6784\uff1a\u5185\u5c42\u5faa\u73af\u4f7f\u7528\u56fa\u5b9a\u8bc4\u5206\u6a21\u677f\u901a\u8fc7\u7ec6\u7c92\u5ea6\u53cd\u9988\u4f18\u5316\u63d0\u793a\uff0c\u5916\u5c42\u5faa\u73af\u4f7f\u7528ASR\u5bf9\u9f50\u5206\u6570\u4f18\u5316\u8bc4\u5206\u6a21\u677f\uff0c\u5b9e\u73b0\u63d0\u793a\u548c\u6a21\u677f\u7684\u534f\u540c\u6f14\u5316\u3002", "result": "\u5728AdvBench\u548cJBB-Behaviors\u8bc4\u4f30\u4e2d\uff0cAMIS\u5728Claude-3.5-Haiku\u4e0a\u8fbe\u523088.0% ASR\uff0c\u5728Claude-4-Sonnet\u4e0a\u8fbe\u5230100.0% ASR\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "AMIS\u6846\u67b6\u901a\u8fc7\u8054\u5408\u4f18\u5316\u63d0\u793a\u548c\u8bc4\u5206\u6a21\u677f\uff0c\u80fd\u591f\u751f\u6210\u66f4\u5f3a\u7684\u8d8a\u72f1\u63d0\u793a\u5e76\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u8bc4\u5206\u4fe1\u53f7\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u6d4b\u8bd5\u80fd\u529b\u3002"}}
{"id": "2511.01334", "categories": ["cs.RO", "cs.AI", "cs.HC", "68T45"], "pdf": "https://arxiv.org/pdf/2511.01334", "abs": "https://arxiv.org/abs/2511.01334", "authors": ["Ling Niu", "Xiaoji Zheng", "Han Wang", "Chen Zheng", "Ziyuan Yang", "Bokui Chen", "Jiangtao Gong"], "title": "Embodied Cognition Augmented End2End Autonomous Driving", "comment": "24 pages,4 pages", "summary": "In recent years, vision-based end-to-end autonomous driving has emerged as a\nnew paradigm. However, popular end-to-end approaches typically rely on visual\nfeature extraction networks trained under label supervision. This limited\nsupervision framework restricts the generality and applicability of driving\nmodels. In this paper, we propose a novel paradigm termed $E^{3}AD$, which\nadvocates for comparative learning between visual feature extraction networks\nand the general EEG large model, in order to learn latent human driving\ncognition for enhancing end-to-end planning. In this work, we collected a\ncognitive dataset for the mentioned contrastive learning process. Subsequently,\nwe investigated the methods and potential mechanisms for enhancing end-to-end\nplanning with human driving cognition, using popular driving models as\nbaselines on publicly available autonomous driving datasets. Both open-loop and\nclosed-loop tests are conducted for a comprehensive evaluation of planning\nperformance. Experimental results demonstrate that the $E^{3}AD$ paradigm\nsignificantly enhances the end-to-end planning performance of baseline models.\nAblation studies further validate the contribution of driving cognition and the\neffectiveness of comparative learning process. To the best of our knowledge,\nthis is the first work to integrate human driving cognition for improving\nend-to-end autonomous driving planning. It represents an initial attempt to\nincorporate embodied cognitive data into end-to-end autonomous driving,\nproviding valuable insights for future brain-inspired autonomous driving\nsystems. Our code will be made available at Github", "AI": {"tldr": "\u63d0\u51faE\u00b3AD\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u89c6\u89c9\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4e0eEEG\u5927\u6a21\u578b\u7684\u5bf9\u6bd4\u5b66\u4e60\uff0c\u5b66\u4e60\u4eba\u7c7b\u9a7e\u9a76\u8ba4\u77e5\u6765\u589e\u5f3a\u7aef\u5230\u7aef\u89c4\u5212\u6027\u80fd", "motivation": "\u73b0\u6709\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u65b9\u6cd5\u4f9d\u8d56\u6807\u7b7e\u76d1\u7763\u8bad\u7ec3\u7684\u89c6\u89c9\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\uff0c\u8fd9\u79cd\u6709\u9650\u76d1\u7763\u6846\u67b6\u9650\u5236\u4e86\u9a7e\u9a76\u6a21\u578b\u7684\u901a\u7528\u6027\u548c\u9002\u7528\u6027", "method": "\u6536\u96c6\u8ba4\u77e5\u6570\u636e\u96c6\u8fdb\u884c\u5bf9\u6bd4\u5b66\u4e60\uff0c\u7814\u7a76\u5229\u7528\u4eba\u7c7b\u9a7e\u9a76\u8ba4\u77e5\u589e\u5f3a\u7aef\u5230\u7aef\u89c4\u5212\u7684\u65b9\u6cd5\u548c\u673a\u5236\uff0c\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u6d41\u884c\u9a7e\u9a76\u6a21\u578b\u4f5c\u4e3a\u57fa\u7ebf", "result": "E\u00b3AD\u8303\u5f0f\u663e\u8457\u63d0\u5347\u4e86\u57fa\u7ebf\u6a21\u578b\u7684\u7aef\u5230\u7aef\u89c4\u5212\u6027\u80fd\uff0c\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u9a7e\u9a76\u8ba4\u77e5\u7684\u8d21\u732e\u548c\u5bf9\u6bd4\u5b66\u4e60\u8fc7\u7a0b\u7684\u6709\u6548\u6027", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5c06\u4eba\u7c7b\u9a7e\u9a76\u8ba4\u77e5\u6574\u5408\u5230\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u89c4\u5212\u7684\u5de5\u4f5c\uff0c\u4e3a\u672a\u6765\u8111\u542f\u53d1\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3"}}
{"id": "2511.01396", "categories": ["cs.AI", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.01396", "abs": "https://arxiv.org/abs/2511.01396", "authors": ["Cl\u00e9ment Yvernes", "Emilie Devijver", "Ad\u00e8le H. Ribeiro", "Marianne Clausel--Lesourd", "\u00c9ric Gaussier"], "title": "Relaxing partition admissibility in Cluster-DAGs: a causal calculus with arbitrary variable clustering", "comment": "Accepted at The Thirty-ninth Annual Conference on Neural Information\n  Processing Systems (NeurIPS2025)", "summary": "Cluster DAGs (C-DAGs) provide an abstraction of causal graphs in which nodes\nrepresent clusters of variables, and edges encode both cluster-level causal\nrelationships and dependencies arisen from unobserved confounding. C-DAGs\ndefine an equivalence class of acyclic causal graphs that agree on\ncluster-level relationships, enabling causal reasoning at a higher level of\nabstraction. However, when the chosen clustering induces cycles in the\nresulting C-DAG, the partition is deemed inadmissible under conventional C-DAG\nsemantics. In this work, we extend the C-DAG framework to support arbitrary\nvariable clusterings by relaxing the partition admissibility constraint,\nthereby allowing cyclic C-DAG representations. We extend the notions of\nd-separation and causal calculus to this setting, significantly broadening the\nscope of causal reasoning across clusters and enabling the application of\nC-DAGs in previously intractable scenarios. Our calculus is both sound and\natomically complete with respect to the do-calculus: all valid interventional\nqueries at the cluster level can be derived using our rules, each corresponding\nto a primitive do-calculus step.", "AI": {"tldr": "\u6269\u5c55C-DAG\u6846\u67b6\u4ee5\u652f\u6301\u4efb\u610f\u53d8\u91cf\u805a\u7c7b\uff0c\u5141\u8bb8\u5faa\u73afC-DAG\u8868\u793a\uff0c\u5e76\u6269\u5c55d-\u5206\u79bb\u548c\u56e0\u679c\u6f14\u7b97\u6982\u5ff5\uff0c\u4f7f\u56e0\u679c\u63a8\u7406\u5728\u96c6\u7fa4\u7ea7\u522b\u66f4\u5e7f\u6cdb\u5e94\u7528\u3002", "motivation": "\u4f20\u7edfC-DAG\u8981\u6c42\u805a\u7c7b\u4ea7\u751f\u65e0\u73af\u56fe\uff0c\u9650\u5236\u4e86\u5176\u5e94\u7528\u8303\u56f4\u3002\u5f53\u9009\u62e9\u7684\u805a\u7c7b\u5bfc\u81f4\u5faa\u73af\u65f6\uff0c\u8be5\u5206\u533a\u5728\u4f20\u7edfC-DAG\u8bed\u4e49\u4e0b\u88ab\u89c6\u4e3a\u4e0d\u53ef\u63a5\u53d7\u3002", "method": "\u901a\u8fc7\u653e\u5bbd\u5206\u533a\u53ef\u63a5\u53d7\u6027\u7ea6\u675f\uff0c\u5141\u8bb8\u5faa\u73afC-DAG\u8868\u793a\uff0c\u5e76\u6269\u5c55d-\u5206\u79bb\u548c\u56e0\u679c\u6f14\u7b97\u6982\u5ff5\u5230\u8fd9\u4e2a\u8bbe\u7f6e\u4e2d\u3002", "result": "\u65b0\u6f14\u7b97\u76f8\u5bf9\u4e8edo-\u6f14\u7b97\u65e2\u662f\u53ef\u9760\u7684\u53c8\u662f\u539f\u5b50\u5b8c\u5907\u7684\uff1a\u6240\u6709\u6709\u6548\u7684\u96c6\u7fa4\u7ea7\u522b\u5e72\u9884\u67e5\u8be2\u90fd\u53ef\u4ee5\u4f7f\u7528\u6211\u4eec\u7684\u89c4\u5219\u63a8\u5bfc\uff0c\u6bcf\u4e2a\u89c4\u5219\u5bf9\u5e94\u4e00\u4e2a\u539f\u59cbdo-\u6f14\u7b97\u6b65\u9aa4\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u663e\u8457\u62d3\u5bbd\u4e86\u8de8\u96c6\u7fa4\u56e0\u679c\u63a8\u7406\u7684\u8303\u56f4\uff0c\u4f7fC-DAG\u80fd\u591f\u5728\u5148\u524d\u96be\u4ee5\u5904\u7406\u7684\u573a\u666f\u4e2d\u5e94\u7528\u3002"}}
{"id": "2511.01346", "categories": ["cs.RO", "physics.bio-ph"], "pdf": "https://arxiv.org/pdf/2511.01346", "abs": "https://arxiv.org/abs/2511.01346", "authors": ["Shun Yoshida", "Qingchuan Song", "Bastian E. Rapp", "Thomas Speck", "Falk J. Tauber"], "title": "Thermo-responsive closing and reopening artificial Venus Flytrap utilizing shape memory elastomers", "comment": "Conference Proceedings Paper Living Machines 2025", "summary": "Despite their often perceived static and slow nature, some plants can move\nfaster than the blink of an eye. The rapid snap closure motion of the Venus\nflytrap (Dionaea muscipula) has long captivated the interest of researchers and\nengineers alike, serving as a model for plant-inspired soft machines and\nrobots. The translation of the fast snapping closure has inspired the\ndevelopment of various artificial Venus flytrap (AVF) systems. However,\ntranslating both the closing and reopening motion of D. muscipula into an\nautonomous plant inspired soft machine has yet to be achieved. In this study,\nwe present an AVF that autonomously closes and reopens, utilizing novel\nthermo-responsive UV-curable shape memory materials for soft robotic systems.\nThe life-sized thermo-responsive AVF exhibits closing and reopening motions\ntriggered in a naturally occurring temperature range. The doubly curved trap\nlobes, built from shape memory polymers, close at 38{\\deg}C, while reopening\ninitiates around 45{\\deg}C, employing shape memory elastomer strips as\nantagonistic actuators to facilitate lobe reopening. This work represents the\nfirst demonstration of thermo-responsive closing and reopening in an AVF with\nprogrammed sequential motion in response to increasing temperature. This\napproach marks the next step toward autonomously bidirectional moving soft\nmachines/robots.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u80fd\u591f\u81ea\u4e3b\u95ed\u5408\u548c\u91cd\u65b0\u6253\u5f00\u7684\u4eff\u751f\u6355\u8747\u8349\u8f6f\u4f53\u673a\u5668\u4eba\uff0c\u4f7f\u7528\u70ed\u54cd\u5e94\u5f62\u72b6\u8bb0\u5fc6\u6750\u6599\uff0c\u5728\u81ea\u7136\u6e29\u5ea6\u8303\u56f4\u5185\u5b9e\u73b0\u53cc\u5411\u8fd0\u52a8\u3002", "motivation": "\u867d\u7136\u6355\u8747\u8349\u7684\u5feb\u901f\u95ed\u5408\u8fd0\u52a8\u5df2\u542f\u53d1\u591a\u79cd\u4eba\u5de5\u7cfb\u7edf\uff0c\u4f46\u5b9e\u73b0\u81ea\u4e3b\u95ed\u5408\u548c\u91cd\u65b0\u6253\u5f00\u7684\u53cc\u5411\u8fd0\u52a8\u4ecd\u662f\u6311\u6218\u3002", "method": "\u91c7\u7528\u65b0\u578b\u70ed\u54cd\u5e94UV\u56fa\u5316\u5f62\u72b6\u8bb0\u5fc6\u6750\u6599\uff0c\u6784\u5efa\u53cc\u66f2\u9762\u6355\u8747\u8349\u53f6\u7247\uff0c\u4f7f\u7528\u5f62\u72b6\u8bb0\u5fc6\u805a\u5408\u7269\u5b9e\u73b038\u00b0C\u95ed\u5408\uff0c\u5f62\u72b6\u8bb0\u5fc6\u5f39\u6027\u4f53\u6761\u5e26\u572845\u00b0C\u65f6\u4f5c\u4e3a\u62ee\u6297\u9a71\u52a8\u5668\u4fc3\u8fdb\u53f6\u7247\u91cd\u65b0\u6253\u5f00\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u70ed\u54cd\u5e94\u95ed\u5408\u548c\u91cd\u65b0\u6253\u5f00\uff0c\u5728\u81ea\u7136\u6e29\u5ea6\u8303\u56f4\u5185\u5b8c\u6210\u7a0b\u5e8f\u5316\u987a\u5e8f\u8fd0\u52a8\uff0c\u8fd9\u662f\u9996\u4e2a\u5c55\u793a\u53cc\u5411\u70ed\u54cd\u5e94\u8fd0\u52a8\u7684\u4eff\u751f\u6355\u8747\u8349\u7cfb\u7edf\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u6807\u5fd7\u7740\u5411\u81ea\u4e3b\u53cc\u5411\u79fb\u52a8\u8f6f\u4f53\u673a\u5668\u4eba\u7684\u91cd\u8981\u8fdb\u5c55\uff0c\u4e3a\u690d\u7269\u542f\u53d1\u7684\u8f6f\u4f53\u673a\u5668\u4eba\u6280\u672f\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2511.01415", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01415", "abs": "https://arxiv.org/abs/2511.01415", "authors": ["Amrapali Pednekar", "\u00c1lvaro Garrido-P\u00e9rez", "Yara Khaluf", "Pieter Simoens"], "title": "Modulation of temporal decision-making in a deep reinforcement learning agent under the dual-task paradigm", "comment": "Accepted at CogInterp workshop @ NeurIPS 2025", "summary": "This study explores the interference in temporal processing within a\ndual-task paradigm from an artificial intelligence (AI) perspective. In this\ncontext, the dual-task setup is implemented as a simplified version of the\nOvercooked environment with two variations, single task (T) and dual task\n(T+N). Both variations involve an embedded time production task, but the dual\ntask (T+N) additionally involves a concurrent number comparison task. Two deep\nreinforcement learning (DRL) agents were separately trained for each of these\ntasks. These agents exhibited emergent behavior consistent with human timing\nresearch. Specifically, the dual task (T+N) agent exhibited significant\noverproduction of time relative to its single task (T) counterpart. This result\nwas consistent across four target durations. Preliminary analysis of neural\ndynamics in the agents' LSTM layers did not reveal any clear evidence of a\ndedicated or intrinsic timer. Hence, further investigation is needed to better\nunderstand the underlying time-keeping mechanisms of the agents and to provide\ninsights into the observed behavioral patterns. This study is a small step\ntowards exploring parallels between emergent DRL behavior and behavior observed\nin biological systems in order to facilitate a better understanding of both.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4eceAI\u89d2\u5ea6\u63a2\u7d22\u53cc\u4efb\u52a1\u8303\u5f0f\u4e2d\u7684\u65f6\u95f4\u5904\u7406\u5e72\u6270\uff0c\u53d1\u73b0\u53cc\u4efb\u52a1DRL\u667a\u80fd\u4f53\u76f8\u5bf9\u4e8e\u5355\u4efb\u52a1\u667a\u80fd\u4f53\u663e\u8457\u9ad8\u4f30\u65f6\u95f4\uff0c\u4f46\u672a\u53d1\u73b0\u660e\u786e\u7684\u5185\u90e8\u8ba1\u65f6\u673a\u5236\u3002", "motivation": "\u63a2\u7d22\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u5728\u53cc\u4efb\u52a1\u8303\u5f0f\u4e2d\u7684\u65f6\u95f4\u5904\u7406\u884c\u4e3a\uff0c\u4e0e\u4eba\u7c7b\u8ba1\u65f6\u7814\u7a76\u8fdb\u884c\u6bd4\u8f83\uff0c\u4ee5\u4fc3\u8fdb\u5bf9\u751f\u7269\u7cfb\u7edf\u548cAI\u7cfb\u7edf\u7684\u66f4\u597d\u7406\u89e3\u3002", "method": "\u4f7f\u7528\u7b80\u5316\u7684Overcooked\u73af\u5883\uff0c\u5206\u522b\u8bad\u7ec3\u5355\u4efb\u52a1(T)\u548c\u53cc\u4efb\u52a1(T+N)\u7684DRL\u667a\u80fd\u4f53\uff0c\u53cc\u4efb\u52a1\u989d\u5916\u5305\u542b\u6570\u5b57\u6bd4\u8f83\u4efb\u52a1\uff0c\u5206\u6790\u667a\u80fd\u4f53\u7684\u65f6\u95f4\u4ea7\u751f\u884c\u4e3a\u548cLSTM\u5c42\u795e\u7ecf\u52a8\u529b\u5b66\u3002", "result": "\u53cc\u4efb\u52a1\u667a\u80fd\u4f53\u76f8\u5bf9\u4e8e\u5355\u4efb\u52a1\u667a\u80fd\u4f53\u663e\u8457\u9ad8\u4f30\u65f6\u95f4\uff0c\u8fd9\u4e00\u7ed3\u679c\u5728\u56db\u4e2a\u76ee\u6807\u65f6\u957f\u4e0a\u4e00\u81f4\uff1bLSTM\u5c42\u5206\u6790\u672a\u53d1\u73b0\u660e\u786e\u7684\u4e13\u7528\u8ba1\u65f6\u5668\u8bc1\u636e\u3002", "conclusion": "\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u667a\u80fd\u4f53\u7684\u6f5c\u5728\u8ba1\u65f6\u673a\u5236\uff0c\u8fd9\u662f\u63a2\u7d22DRL\u884c\u4e3a\u4e0e\u751f\u7269\u7cfb\u7edf\u884c\u4e3a\u76f8\u4f3c\u6027\u7684\u521d\u6b65\u5c1d\u8bd5\u3002"}}
{"id": "2511.01347", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01347", "abs": "https://arxiv.org/abs/2511.01347", "authors": ["Riddhi Das", "Joscha Teichmann", "Thomas Speck", "Falk J. Tauber"], "title": "Design and development of an electronics-free earthworm robot", "comment": "Conference Proceedings Paper Living Machines 2025", "summary": "Soft robotic systems have gained widespread attention due to their inherent\nflexibility, adaptability, and safety, making them well-suited for varied\napplications. Among bioinspired designs, earthworm locomotion has been\nextensively studied for its efficient peristaltic motion, enabling movement in\nconfined and unstructured environments. Existing earthworm-inspired robots\nprimarily utilize pneumatic actuation due to its high force-to-weight ratio and\nease of implementation. However, these systems often rely on bulky,\npower-intensive electronic control units, limiting their practicality. In this\nwork, we present an electronics-free, earthworm-inspired pneumatic robot\nutilizing a modified Pneumatic Logic Gate (PLG) design. By integrating\npreconfigured PLG units with bellow actuators, we achieved a plug-and-play\nstyle modular system capable of peristaltic locomotion without external\nelectronic components. The proposed design reduces system complexity while\nmaintaining efficient actuation. We characterize the bellow actuators under\ndifferent operating conditions and evaluate the robots locomotion performance.\nOur findings demonstrate that the modified PLG-based control system effectively\ngenerates peristaltic wave propagation, achieving autonomous motion with\nminimal deviation. This study serves as a proof of concept for the development\nof electronics-free, peristaltic soft robots. The proposed system has potential\nfor applications in hazardous environments, where untethered, adaptable\nlocomotion is critical. Future work will focus on further optimizing the robot\ndesign and exploring untethered operation using onboard compressed air sources.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u7535\u5b50\u5668\u4ef6\u7684\u4eff\u86af\u8693\u6c14\u52a8\u673a\u5668\u4eba\uff0c\u4f7f\u7528\u6539\u8fdb\u7684\u6c14\u52a8\u903b\u8f91\u95e8\u8bbe\u8ba1\u5b9e\u73b0\u8815\u52a8\u8fd0\u52a8\uff0c\u65e0\u9700\u5916\u90e8\u7535\u5b50\u63a7\u5236\u5355\u5143", "motivation": "\u73b0\u6709\u4eff\u86af\u8693\u673a\u5668\u4eba\u4e3b\u8981\u4f9d\u8d56\u7b28\u91cd\u3001\u9ad8\u529f\u8017\u7684\u7535\u5b50\u63a7\u5236\u5355\u5143\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u65e0\u7535\u5b50\u5668\u4ef6\u7684\u63a7\u5236\u7cfb\u7edf\uff0c\u964d\u4f4e\u7cfb\u7edf\u590d\u6742\u6027", "method": "\u5c06\u9884\u914d\u7f6e\u7684\u6c14\u52a8\u903b\u8f91\u95e8\u5355\u5143\u4e0e\u6ce2\u7eb9\u7ba1\u6267\u884c\u5668\u96c6\u6210\uff0c\u6784\u5efa\u5373\u63d2\u5373\u7528\u5f0f\u6a21\u5757\u5316\u7cfb\u7edf\uff0c\u5b9e\u73b0\u65e0\u5916\u90e8\u7535\u5b50\u7ec4\u4ef6\u7684\u8815\u52a8\u8fd0\u52a8", "result": "\u6539\u8fdb\u7684\u6c14\u52a8\u903b\u8f91\u95e8\u63a7\u5236\u7cfb\u7edf\u6709\u6548\u4ea7\u751f\u8815\u52a8\u6ce2\u4f20\u64ad\uff0c\u5b9e\u73b0\u81ea\u4e3b\u8fd0\u52a8\u4e14\u504f\u5dee\u6700\u5c0f\u3002\u6ce2\u7eb9\u7ba1\u6267\u884c\u5668\u5728\u4e0d\u540c\u5de5\u51b5\u4e0b\u6027\u80fd\u5f97\u5230\u8868\u5f81", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5f00\u53d1\u65e0\u7535\u5b50\u5668\u4ef6\u7684\u8815\u52a8\u8f6f\u4f53\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u6982\u5ff5\u9a8c\u8bc1\uff0c\u5728\u5371\u9669\u73af\u5883\u4e2d\u5177\u6709\u5e94\u7528\u6f5c\u529b\uff0c\u672a\u6765\u5c06\u4f18\u5316\u8bbe\u8ba1\u5e76\u63a2\u7d22\u4f7f\u7528\u673a\u8f7d\u538b\u7f29\u7a7a\u6c14\u6e90\u7684\u65e0\u7ebf\u64cd\u4f5c"}}
{"id": "2511.01425", "categories": ["cs.AI", "cs.CV", "I.2.6; I.2.10"], "pdf": "https://arxiv.org/pdf/2511.01425", "abs": "https://arxiv.org/abs/2511.01425", "authors": ["Yuhang Huang", "Zekai Lin", "Fan Zhong", "Lei Liu"], "title": "Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis", "comment": "12 pages, 3 figures. Under review at the Conference on Computer\n  Vision and Pattern Recognition (CVPR) 2026", "summary": "Explanations for AI models in high-stakes domains like medicine often lack\nverifiability, which can hinder trust. To address this, we propose an\ninteractive agent that produces explanations through an auditable sequence of\nactions. The agent learns a policy to strategically seek external visual\nevidence to support its diagnostic reasoning. This policy is optimized using\nreinforcement learning, resulting in a model that is both efficient and\ngeneralizable. Our experiments show that this action-based reasoning process\nsignificantly improves calibrated accuracy, reducing the Brier score by 18\\%\ncompared to a non-interactive baseline. To validate the faithfulness of the\nagent's explanations, we introduce a causal intervention method. By masking the\nvisual evidence the agent chooses to use, we observe a measurable degradation\nin its performance ($\\Delta$Brier=+0.029), confirming that the evidence is\nintegral to its decision-making process. Our work provides a practical\nframework for building AI systems with verifiable and faithful reasoning\ncapabilities.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u53ef\u5ba1\u8ba1\u884c\u52a8\u5e8f\u5217\u751f\u6210\u89e3\u91ca\u7684\u4ea4\u4e92\u5f0fAI\u4ee3\u7406\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u7b56\u7565\u6765\u5bfb\u6c42\u5916\u90e8\u89c6\u89c9\u8bc1\u636e\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6821\u51c6\u51c6\u786e\u6027\u548c\u89e3\u91ca\u7684\u53ef\u9a8c\u8bc1\u6027\u3002", "motivation": "\u5728\u533b\u7597\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u4e2d\uff0cAI\u6a21\u578b\u7684\u89e3\u91ca\u5f80\u5f80\u7f3a\u4e4f\u53ef\u9a8c\u8bc1\u6027\uff0c\u8fd9\u4f1a\u963b\u788d\u4fe1\u4efb\u7684\u5efa\u7acb\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u4ee3\u7406\uff0c\u5b66\u4e60\u7b56\u7565\u6765\u6218\u7565\u6027\u5730\u5bfb\u6c42\u5916\u90e8\u89c6\u89c9\u8bc1\u636e\u652f\u6301\u8bca\u65ad\u63a8\u7406\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u8be5\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6821\u51c6\u51c6\u786e\u6027\uff0cBrier\u5206\u6570\u6bd4\u975e\u4ea4\u4e92\u57fa\u7ebf\u964d\u4f4e\u4e8618%\u3002\u901a\u8fc7\u56e0\u679c\u5e72\u9884\u9a8c\u8bc1\u4e86\u89e3\u91ca\u7684\u5fe0\u5b9e\u6027\uff0c\u906e\u853d\u4ee3\u7406\u9009\u62e9\u7684\u89c6\u89c9\u8bc1\u636e\u4f1a\u5bfc\u81f4\u6027\u80fd\u660e\u663e\u4e0b\u964d\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u6784\u5efa\u5177\u6709\u53ef\u9a8c\u8bc1\u548c\u5fe0\u5b9e\u63a8\u7406\u80fd\u529b\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\u3002"}}
{"id": "2511.01350", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01350", "abs": "https://arxiv.org/abs/2511.01350", "authors": ["Maartje H. M. Wermelink", "Renate Sachse", "Sebastian Kruppert", "Thomas Speck", "Falk J. Tauber"], "title": "Model to Model: Understanding the Venus Flytrap Snapping Mechanism and Transferring it to a 3D-printed Bistable Soft Robotic Demonstrator", "comment": "Conference Proceedings Paper Living machines 2025", "summary": "The Venus flytrap (Dionaea muscipula) does not only serve as the textbook\nmodel for a carnivorous plant, but also has long intrigued both botanists and\nengineers with its rapidly closing leaf trap. The trap closure is triggered by\ntwo consecutive touches of a potential prey, after which the lobes rapidly\nswitch from their concave open-state to their convex close-state and catch the\nprey within 100-500 ms after being triggered. This transformation from concave\nto convex is initiated by changes in turgor pressure and the release of stored\nelastic energy from prestresses in the concave state, which accelerate this\nmovement, leading to inversion of the lobes bi-axial curvature. Possessing two\nlow-energy states, the leaves can be characterized as bistable systems. With\nour research, we seek to deepen the understanding of Venus flytrap motion\nmechanics and apply its principles to the design of an artificial bistable lobe\nactuator. We identified geometrical characteristics, such as dimensional ratios\nand the thickness gradient in the lobe, and transferred these to two 3D-printed\nbistable actuator models. One actuator parallels the simulated geometry of a\nVenus flytrap leaf, the other is a lobe model designed with CAD. Both models\ndisplay concave-convex bi-stability and snap close. These demonstrators are the\nfirst step in the development of an artificial Venus flytrap that mimics the\nmechanical behavior of the biological model and can be used as a soft fast\ngripper.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u6355\u8747\u8349\u7684\u5feb\u901f\u95ed\u5408\u673a\u5236\uff0c\u5e76\u5c06\u5176\u53cc\u7a33\u6001\u7279\u6027\u5e94\u7528\u4e8e\u4eba\u5de5\u6267\u884c\u5668\u7684\u8bbe\u8ba1\uff0c\u5f00\u53d1\u4e86\u4e24\u79cd3D\u6253\u5370\u7684\u53cc\u7a33\u6001\u6267\u884c\u5668\u6a21\u578b\u3002", "motivation": "\u6df1\u5165\u4e86\u89e3\u6355\u8747\u8349\u7684\u8fd0\u52a8\u529b\u5b66\u673a\u5236\uff0c\u5e76\u5c06\u5176\u539f\u7406\u5e94\u7528\u4e8e\u4eba\u5de5\u53cc\u7a33\u6001\u53f6\u7247\u6267\u884c\u5668\u7684\u8bbe\u8ba1\uff0c\u5f00\u53d1\u80fd\u591f\u6a21\u62df\u751f\u7269\u6a21\u578b\u673a\u68b0\u884c\u4e3a\u7684\u8f6f\u5feb\u901f\u6293\u53d6\u5668\u3002", "method": "\u8bc6\u522b\u6355\u8747\u8349\u53f6\u7247\u7684\u51e0\u4f55\u7279\u5f81\uff08\u5982\u5c3a\u5bf8\u6bd4\u4f8b\u548c\u539a\u5ea6\u68af\u5ea6\uff09\uff0c\u5e76\u5c06\u5176\u8f6c\u5316\u4e3a\u4e24\u79cd3D\u6253\u5370\u7684\u53cc\u7a33\u6001\u6267\u884c\u5668\u6a21\u578b\uff1a\u4e00\u79cd\u6a21\u62df\u6355\u8747\u8349\u53f6\u7247\u51e0\u4f55\u5f62\u72b6\uff0c\u53e6\u4e00\u79cd\u4f7f\u7528CAD\u8bbe\u8ba1\u7684\u53f6\u7247\u6a21\u578b\u3002", "result": "\u4e24\u79cd\u6a21\u578b\u90fd\u8868\u73b0\u51fa\u51f9-\u51f8\u53cc\u7a33\u6001\u7279\u6027\u5e76\u80fd\u591f\u5feb\u901f\u95ed\u5408\uff0c\u8fd9\u662f\u5f00\u53d1\u4eba\u5de5\u6355\u8747\u8349\u7684\u7b2c\u4e00\u6b65\u3002", "conclusion": "\u6210\u529f\u5c06\u6355\u8747\u8349\u7684\u53cc\u7a33\u6001\u673a\u5236\u5e94\u7528\u4e8e\u4eba\u5de5\u6267\u884c\u5668\u8bbe\u8ba1\uff0c\u4e3a\u5f00\u53d1\u6a21\u62df\u751f\u7269\u673a\u68b0\u884c\u4e3a\u7684\u8f6f\u5feb\u901f\u6293\u53d6\u5668\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.01444", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01444", "abs": "https://arxiv.org/abs/2511.01444", "authors": ["Huiting Huang", "Tieliang Gong", "Kai He", "Jialun Wu", "Erik Cambria", "Mengling Feng"], "title": "Robust Multimodal Sentiment Analysis via Double Information Bottleneck", "comment": null, "summary": "Multimodal sentiment analysis has received significant attention across\ndiverse research domains. Despite advancements in algorithm design, existing\napproaches suffer from two critical limitations: insufficient learning of\nnoise-contaminated unimodal data, leading to corrupted cross-modal\ninteractions, and inadequate fusion of multimodal representations, resulting in\ndiscarding discriminative unimodal information while retaining multimodal\nredundant information. To address these challenges, this paper proposes a\nDouble Information Bottleneck (DIB) strategy to obtain a powerful, unified\ncompact multimodal representation. Implemented within the framework of low-rank\nRenyi's entropy functional, DIB offers enhanced robustness against diverse\nnoise sources and computational tractability for high-dimensional data, as\ncompared to the conventional Shannon entropy-based methods. The DIB comprises\ntwo key modules: 1) learning a sufficient and compressed representation of\nindividual unimodal data by maximizing the task-relevant information and\ndiscarding the superfluous information, and 2) ensuring the discriminative\nability of multimodal representation through a novel attention bottleneck\nfusion mechanism. Consequently, DIB yields a multimodal representation that\neffectively filters out noisy information from unimodal data while capturing\ninter-modal complementarity. Extensive experiments on CMU-MOSI, CMU-MOSEI,\nCH-SIMS, and MVSA-Single validate the effectiveness of our method. The model\nachieves 47.4% accuracy under the Acc-7 metric on CMU-MOSI and 81.63% F1-score\non CH-SIMS, outperforming the second-best baseline by 1.19%. Under noise, it\nshows only 0.36% and 0.29% performance degradation on CMU-MOSI and CMU-MOSEI\nrespectively.", "AI": {"tldr": "\u63d0\u51fa\u53cc\u4fe1\u606f\u74f6\u9888(DIB)\u7b56\u7565\u89e3\u51b3\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u4e2d\u7684\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u566a\u58f0\u6c61\u67d3\u7684\u5355\u6a21\u6001\u6570\u636e\u5b66\u4e60\u548c\u591a\u6a21\u6001\u8868\u793a\u878d\u5408\u4e0d\u8db3\u3002DIB\u901a\u8fc7\u6700\u5927\u5316\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\u5e76\u4e22\u5f03\u5197\u4f59\u4fe1\u606f\uff0c\u83b7\u5f97\u7edf\u4e00\u7d27\u51d1\u7684\u591a\u6a21\u6001\u8868\u793a\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u5c40\u9650\uff1a\u5bf9\u566a\u58f0\u6c61\u67d3\u7684\u5355\u6a21\u6001\u6570\u636e\u5b66\u4e60\u4e0d\u8db3\u5bfc\u81f4\u8de8\u6a21\u6001\u4ea4\u4e92\u53d7\u635f\uff0c\u4ee5\u53ca\u591a\u6a21\u6001\u8868\u793a\u878d\u5408\u4e0d\u5145\u5206\u5bfc\u81f4\u4e22\u5f03\u5224\u522b\u6027\u5355\u6a21\u6001\u4fe1\u606f\u800c\u4fdd\u7559\u5197\u4f59\u4fe1\u606f\u3002", "method": "\u57fa\u4e8e\u4f4e\u79e9Renyi\u71b5\u51fd\u6570\u6846\u67b6\u5b9e\u73b0\u53cc\u4fe1\u606f\u74f6\u9888\u7b56\u7565\uff0c\u5305\u542b\u4e24\u4e2a\u6a21\u5757\uff1a1)\u5b66\u4e60\u5355\u6a21\u6001\u6570\u636e\u7684\u5145\u5206\u538b\u7f29\u8868\u793a\uff0c2)\u901a\u8fc7\u65b0\u9896\u7684\u6ce8\u610f\u529b\u74f6\u9888\u878d\u5408\u673a\u5236\u786e\u4fdd\u591a\u6a21\u6001\u8868\u793a\u7684\u5224\u522b\u80fd\u529b\u3002", "result": "\u5728CMU-MOSI\u3001CMU-MOSEI\u3001CH-SIMS\u548cMVSA-Single\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6709\u6548\u6027\u3002\u5728CMU-MOSI\u4e0aAcc-7\u8fbe\u523047.4%\uff0cCH-SIMS\u4e0aF1-score\u8fbe\u523081.63%\uff0c\u6bd4\u6b21\u4f18\u57fa\u7ebf\u63d0\u53471.19%\u3002\u5728\u566a\u58f0\u4e0b\u6027\u80fd\u4e0b\u964d\u4ec50.36%\u548c0.29%\u3002", "conclusion": "DIB\u7b56\u7565\u80fd\u591f\u6709\u6548\u8fc7\u6ee4\u5355\u6a21\u6001\u6570\u636e\u4e2d\u7684\u566a\u58f0\u4fe1\u606f\uff0c\u540c\u65f6\u6355\u6349\u6a21\u6001\u95f4\u4e92\u8865\u6027\uff0c\u83b7\u5f97\u5f3a\u5927\u7edf\u4e00\u7684\u591a\u6a21\u6001\u8868\u793a\uff0c\u76f8\u6bd4\u4f20\u7edf\u57fa\u4e8e\u9999\u519c\u71b5\u7684\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\u548c\u8ba1\u7b97\u53ef\u884c\u6027\u3002"}}
{"id": "2511.01369", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01369", "abs": "https://arxiv.org/abs/2511.01369", "authors": ["Luis Diener", "Jens Kalkkuhl", "Markus Enzweiler"], "title": "Lateral Velocity Model for Vehicle Parking Applications", "comment": "This manuscript has been submitted to Vehicle System Dynamics for\n  possible publication", "summary": "Automated parking requires accurate localization for quick and precise\nmaneuvering in tight spaces. While the longitudinal velocity can be measured\nusing wheel encoders, the estimation of the lateral velocity remains a key\nchallenge due to the absence of dedicated sensors in consumer-grade vehicles.\nExisting approaches often rely on simplified vehicle models, such as the\nzero-slip model, which assumes no lateral velocity at the rear axle. It is well\nestablished that this assumption does not hold during low-speed driving and\nresearchers thus introduce additional heuristics to account for differences. In\nthis work, we analyze real-world data from parking scenarios and identify a\nsystematic deviation from the zero-slip assumption. We provide explanations for\nthe observed effects and then propose a lateral velocity model that better\ncaptures the lateral dynamics of the vehicle during parking. The model improves\nestimation accuracy, while relying on only two parameters, making it\nwell-suited for integration into consumer-grade applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u4fa7\u5411\u901f\u5ea6\u6a21\u578b\uff0c\u7528\u4e8e\u5728\u81ea\u52a8\u6cca\u8f66\u573a\u666f\u4e2d\u66f4\u51c6\u786e\u5730\u4f30\u8ba1\u8f66\u8f86\u4fa7\u5411\u901f\u5ea6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u96f6\u6ed1\u79fb\u6a21\u578b\u5728\u4f4e\u901f\u884c\u9a76\u65f6\u4e0d\u51c6\u786e\u7684\u95ee\u9898\u3002", "motivation": "\u81ea\u52a8\u6cca\u8f66\u9700\u8981\u7cbe\u786e\u7684\u5b9a\u4f4d\uff0c\u4f46\u6d88\u8d39\u7ea7\u8f66\u8f86\u7f3a\u4e4f\u4e13\u7528\u4f20\u611f\u5668\u6765\u6d4b\u91cf\u4fa7\u5411\u901f\u5ea6\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u96f6\u6ed1\u79fb\u5047\u8bbe\uff0c\u8fd9\u5728\u4f4e\u901f\u884c\u9a76\u65f6\u4e0d\u6210\u7acb\uff0c\u5bfc\u81f4\u4f30\u8ba1\u4e0d\u51c6\u786e\u3002", "method": "\u5206\u6790\u771f\u5b9e\u6cca\u8f66\u573a\u666f\u6570\u636e\uff0c\u8bc6\u522b\u96f6\u6ed1\u79fb\u5047\u8bbe\u7684\u7cfb\u7edf\u6027\u504f\u5dee\uff0c\u63d0\u51fa\u4e00\u4e2a\u4ec5\u9700\u4e24\u4e2a\u53c2\u6570\u7684\u4fa7\u5411\u901f\u5ea6\u6a21\u578b\u6765\u66f4\u597d\u5730\u6355\u6349\u6cca\u8f66\u8fc7\u7a0b\u4e2d\u7684\u8f66\u8f86\u4fa7\u5411\u52a8\u529b\u5b66\u3002", "result": "\u65b0\u6a21\u578b\u63d0\u9ad8\u4e86\u4fa7\u5411\u901f\u5ea6\u4f30\u8ba1\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4ec5\u4f9d\u8d56\u4e24\u4e2a\u53c2\u6570\uff0c\u9002\u5408\u96c6\u6210\u5230\u6d88\u8d39\u7ea7\u5e94\u7528\u4e2d\u3002", "conclusion": "\u63d0\u51fa\u7684\u4fa7\u5411\u901f\u5ea6\u6a21\u578b\u5728\u6cca\u8f66\u573a\u666f\u4e2d\u6bd4\u4f20\u7edf\u96f6\u6ed1\u79fb\u6a21\u578b\u66f4\u51c6\u786e\uff0c\u4e3a\u6d88\u8d39\u7ea7\u8f66\u8f86\u7684\u81ea\u52a8\u6cca\u8f66\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01445", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01445", "abs": "https://arxiv.org/abs/2511.01445", "authors": ["ChengZhang Yu", "YingRu He", "Hongyan Cheng", "nuo Cheng", "Zhixing Liu", "Dongxu Mu", "Zhangrui Shen", "Zhanpeng Jin"], "title": "From Passive to Proactive: A Multi-Agent System with Dynamic Task Orchestration for Intelligent Medical Pre-Consultation", "comment": "14pages, 7 figures, 7 tables", "summary": "Global healthcare systems face critical challenges from increasing patient\nvolumes and limited consultation times, with primary care visits averaging\nunder 5 minutes in many countries. While pre-consultation processes\nencompassing triage and structured history-taking offer potential solutions,\nthey remain limited by passive interaction paradigms and context management\nchallenges in existing AI systems. This study introduces a hierarchical\nmulti-agent framework that transforms passive medical AI systems into proactive\ninquiry agents through autonomous task orchestration. We developed an\neight-agent architecture with centralized control mechanisms that decomposes\npre-consultation into four primary tasks: Triage ($T_1$), History of Present\nIllness collection ($T_2$), Past History collection ($T_3$), and Chief\nComplaint generation ($T_4$), with $T_1$--$T_3$ further divided into 13\ndomain-specific subtasks. Evaluated on 1,372 validated electronic health\nrecords from a Chinese medical platform across multiple foundation models\n(GPT-OSS 20B, Qwen3-8B, Phi4-14B), the framework achieved 87.0% accuracy for\nprimary department triage and 80.5% for secondary department classification,\nwith task completion rates reaching 98.2% using agent-driven scheduling versus\n93.1% with sequential processing. Clinical quality scores from 18 physicians\naveraged 4.56 for Chief Complaints, 4.48 for History of Present Illness, and\n4.69 for Past History on a 5-point scale, with consultations completed within\n12.7 rounds for $T_2$ and 16.9 rounds for $T_3$. The model-agnostic\narchitecture maintained high performance across different foundation models\nwhile preserving data privacy through local deployment, demonstrating the\npotential for autonomous AI systems to enhance pre-consultation efficiency and\nquality in clinical settings.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u5c42\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u88ab\u52a8\u533b\u7597AI\u7cfb\u7edf\u8f6c\u53d8\u4e3a\u4e3b\u52a8\u95ee\u8bca\u4ee3\u7406\uff0c\u901a\u8fc7\u81ea\u4e3b\u4efb\u52a1\u7f16\u6392\u63d0\u9ad8\u9884\u8bca\u6548\u7387\u548c\u4e34\u5e8a\u8d28\u91cf\u3002", "motivation": "\u5168\u7403\u533b\u7597\u7cfb\u7edf\u9762\u4e34\u60a3\u8005\u6570\u91cf\u589e\u52a0\u548c\u5c31\u8bca\u65f6\u95f4\u6709\u9650\u7684\u6311\u6218\uff0c\u73b0\u6709AI\u7cfb\u7edf\u53d7\u9650\u4e8e\u88ab\u52a8\u4ea4\u4e92\u6a21\u5f0f\u548c\u4e0a\u4e0b\u6587\u7ba1\u7406\u95ee\u9898\uff0c\u9700\u8981\u66f4\u4e3b\u52a8\u7684\u9884\u8bca\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u4e86\u516b\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5c06\u9884\u8bca\u8fc7\u7a0b\u5206\u89e3\u4e3a\u5206\u8bca\u3001\u73b0\u75c5\u53f2\u6536\u96c6\u3001\u65e2\u5f80\u53f2\u6536\u96c6\u548c\u4e3b\u8bc9\u751f\u6210\u56db\u4e2a\u4e3b\u8981\u4efb\u52a1\uff0c\u8fdb\u4e00\u6b65\u7ec6\u5206\u4e3a13\u4e2a\u9886\u57df\u7279\u5b9a\u5b50\u4efb\u52a1\uff0c\u91c7\u7528\u96c6\u4e2d\u63a7\u5236\u673a\u5236\u8fdb\u884c\u81ea\u4e3b\u4efb\u52a1\u7f16\u6392\u3002", "result": "\u57281,372\u4efd\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e0a\u8bc4\u4f30\uff0c\u5206\u8bca\u51c6\u786e\u7387\u8fbe87.0%\uff0c\u4efb\u52a1\u5b8c\u6210\u738798.2%\uff0c\u4e34\u5e8a\u8d28\u91cf\u8bc4\u5206\u5e73\u57474.56-4.69\uff085\u5206\u5236\uff09\uff0c\u54a8\u8be2\u8f6e\u6b21\u63a7\u5236\u572812.7-16.9\u8f6e\u5185\u3002", "conclusion": "\u8be5\u6a21\u578b\u65e0\u5173\u67b6\u6784\u5728\u4e0d\u540c\u57fa\u7840\u6a21\u578b\u4e0a\u4fdd\u6301\u9ad8\u6027\u80fd\uff0c\u901a\u8fc7\u672c\u5730\u90e8\u7f72\u4fdd\u62a4\u6570\u636e\u9690\u79c1\uff0c\u5c55\u793a\u4e86\u81ea\u4e3bAI\u7cfb\u7edf\u5728\u4e34\u5e8a\u9884\u8bca\u4e2d\u63d0\u5347\u6548\u7387\u548c\u8d28\u91cf\u7684\u80fd\u529b\u3002"}}
{"id": "2511.01379", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01379", "abs": "https://arxiv.org/abs/2511.01379", "authors": ["Kun Hu", "Menggang Li", "Zhiwen Jin", "Chaoquan Tang", "Eryi Hu", "Gongbo Zhou"], "title": "CM-LIUW-Odometry: Robust and High-Precision LiDAR-Inertial-UWB-Wheel Odometry for Extreme Degradation Coal Mine Tunnels", "comment": "Accepted by IROS 2025", "summary": "Simultaneous Localization and Mapping (SLAM) in large-scale, complex, and\nGPS-denied underground coal mine environments presents significant challenges.\nSensors must contend with abnormal operating conditions: GPS unavailability\nimpedes scene reconstruction and absolute geographic referencing, uneven or\nslippery terrain degrades wheel odometer accuracy, and long, feature-poor\ntunnels reduce LiDAR effectiveness. To address these issues, we propose\nCoalMine-LiDAR-IMU-UWB-Wheel-Odometry (CM-LIUW-Odometry), a multimodal SLAM\nframework based on the Iterated Error-State Kalman Filter (IESKF). First,\nLiDAR-inertial odometry is tightly fused with UWB absolute positioning\nconstraints to align the SLAM system with a global coordinate. Next, wheel\nodometer is integrated through tight coupling, enhanced by nonholonomic\nconstraints (NHC) and vehicle lever arm compensation, to address performance\ndegradation in areas beyond UWB measurement range. Finally, an adaptive motion\nmode switching mechanism dynamically adjusts the robot's motion mode based on\nUWB measurement range and environmental degradation levels. Experimental\nresults validate that our method achieves superior accuracy and robustness in\nreal-world underground coal mine scenarios, outperforming state-of-the-art\napproaches. We open source our code of this work on Github to benefit the\nrobotics community.", "AI": {"tldr": "\u63d0\u51faCM-LIUW-Odometry\u591a\u6a21\u6001SLAM\u6846\u67b6\uff0c\u878d\u5408LiDAR\u3001IMU\u3001UWB\u548c\u8f6e\u5f0f\u91cc\u7a0b\u8ba1\uff0c\u89e3\u51b3\u5730\u4e0b\u7164\u77ffGPS\u7f3a\u5931\u73af\u5883\u4e2d\u7684\u5b9a\u4f4d\u4e0e\u5efa\u56fe\u6311\u6218\u3002", "motivation": "\u5730\u4e0b\u7164\u77ff\u73af\u5883GPS\u4e0d\u53ef\u7528\u3001\u5730\u5f62\u4e0d\u5e73\u5bfc\u81f4\u8f6e\u5f0f\u91cc\u7a0b\u8ba1\u7cbe\u5ea6\u4e0b\u964d\u3001\u957f\u96a7\u9053\u7279\u5f81\u7a00\u5c11\u964d\u4f4eLiDAR\u6548\u679c\uff0c\u9700\u8981\u9c81\u68d2\u7684\u591a\u4f20\u611f\u5668\u878d\u5408\u65b9\u6848\u3002", "method": "\u57fa\u4e8eIESKF\uff0c\u7d27\u5bc6\u878d\u5408LiDAR-IMU\u91cc\u7a0b\u8ba1\u4e0eUWB\u7edd\u5bf9\u5b9a\u4f4d\u7ea6\u675f\uff0c\u96c6\u6210\u8f6e\u5f0f\u91cc\u7a0b\u8ba1\u5e76\u52a0\u5165\u975e\u5b8c\u6574\u7ea6\u675f\u548c\u8f66\u8f86\u6760\u6746\u81c2\u8865\u507f\uff0c\u91c7\u7528\u81ea\u9002\u5e94\u8fd0\u52a8\u6a21\u5f0f\u5207\u6362\u673a\u5236\u3002", "result": "\u5728\u771f\u5b9e\u5730\u4e0b\u7164\u77ff\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u591a\u6a21\u6001SLAM\u6846\u67b6\u5728\u5730\u4e0b\u7164\u77ff\u7b49\u6076\u52a3\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u4f9b\u673a\u5668\u4eba\u793e\u533a\u4f7f\u7528\u3002"}}
{"id": "2511.01527", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01527", "abs": "https://arxiv.org/abs/2511.01527", "authors": ["Hanwen Xu", "Xuyao Huang", "Yuzhe Liu", "Kai Yu", "Zhijie Deng"], "title": "TPS-Bench: Evaluating AI Agents' Tool Planning \\& Scheduling Abilities in Compounding Tasks", "comment": null, "summary": "Large language model (LLM) agents have exhibited strong problem-solving\ncompetence across domains like research and coding. Yet, it remains\nunderexplored whether LLM agents can tackle compounding real-world problems\nthat require a diverse set of tools to complete. Given a broad, heterogeneous\ntool repository, LLM agents must not only select appropriate tools based on\ntask planning analysis but also strategically schedule the execution order to\nensure efficiency. This paper introduces TPS-Bench to benchmark the ability of\nLLM agents in solving such problems that demand Tool Planning and Scheduling.\nTPS-Bench collects 200 compounding tasks of two difficulty levels, based on a\ntool repository containing hundreds of model context protocol (MCP) tools. In\nparticular, each task is composed of multiple subtasks, such as web search, map\nnavigation, calendar checking, etc., and each subtask can be completed by a\nbasic tool. Our evaluation emphasizes both task completion rate and efficiency.\nThe empirical studies on popular closed-source and open-source LLMs indicate\nthat most models can perform reasonable tool planning, but differ in\nscheduling. For example, GLM-4.5 achieves an outperforming task completion rate\nof 64.72% with extensive sequential tool calls, hence suffering from\nsignificantly long execution time. By contrast, GPT-4o prioritizes parallel\ntool calls but achieves only a 45.08% completion rate. Considering\nreinforcement learning (RL) can be a viable way to improve the scheduling\nefficiency without compromising performance, we perform an initial study on\nQwen3-1.7B and witness a 14% reduction in execution time alongside a 6% gain in\ntask completion rate based on rarely 100 RL training samples. Our code is\navailable https://github.com/hanwenxu1/mcp-agent.", "AI": {"tldr": "TPS-Bench\u662f\u4e00\u4e2a\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u5728\u5de5\u5177\u89c4\u5212\u4e0e\u8c03\u5ea6\u65b9\u9762\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b200\u4e2a\u590d\u5408\u4efb\u52a1\u548c\u6570\u767e\u4e2aMCP\u5de5\u5177\u3002\u7814\u7a76\u53d1\u73b0\u5927\u591a\u6570\u6a21\u578b\u80fd\u5408\u7406\u89c4\u5212\u5de5\u5177\u4f7f\u7528\uff0c\u4f46\u5728\u8c03\u5ea6\u6548\u7387\u4e0a\u5dee\u5f02\u663e\u8457\uff0c\u5f3a\u5316\u5b66\u4e60\u53ef\u4ee5\u63d0\u5347\u8c03\u5ea6\u6548\u7387\u3002", "motivation": "\u63a2\u7d22LLM\u667a\u80fd\u4f53\u662f\u5426\u80fd\u89e3\u51b3\u9700\u8981\u591a\u79cd\u5de5\u5177\u534f\u540c\u5de5\u4f5c\u7684\u590d\u5408\u73b0\u5b9e\u95ee\u9898\uff0c\u8fd9\u4e9b\u4efb\u52a1\u4e0d\u4ec5\u9700\u8981\u9009\u62e9\u5408\u9002\u7684\u5de5\u5177\uff0c\u8fd8\u9700\u8981\u9ad8\u6548\u5730\u5b89\u6392\u6267\u884c\u987a\u5e8f\u3002", "method": "\u6784\u5efaTPS-Bench\u57fa\u51c6\uff0c\u5305\u542b200\u4e2a\u590d\u5408\u4efb\u52a1\u548c\u6570\u767e\u4e2aMCP\u5de5\u5177\uff0c\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u7684\u5de5\u5177\u89c4\u5212\u4e0e\u8c03\u5ea6\u80fd\u529b\uff0c\u5e76\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u6539\u8fdb\u8c03\u5ea6\u6548\u7387\u3002", "result": "GLM-4.5\u8fbe\u523064.72%\u7684\u4efb\u52a1\u5b8c\u6210\u7387\u4f46\u6267\u884c\u65f6\u95f4\u957f\uff0cGPT-4o\u4ec545.08%\u5b8c\u6210\u7387\u4f46\u4f18\u5148\u5e76\u884c\u8c03\u7528\u5de5\u5177\u3002\u5f3a\u5316\u5b66\u4e60\u5728Qwen3-1.7B\u4e0a\u4f7f\u6267\u884c\u65f6\u95f4\u51cf\u5c1114%\uff0c\u5b8c\u6210\u7387\u63d0\u53476%\u3002", "conclusion": "LLM\u667a\u80fd\u4f53\u5728\u5de5\u5177\u89c4\u5212\u65b9\u9762\u8868\u73b0\u5408\u7406\uff0c\u4f46\u5728\u8c03\u5ea6\u6548\u7387\u4e0a\u5b58\u5728\u5dee\u5f02\uff0c\u5f3a\u5316\u5b66\u4e60\u662f\u63d0\u5347\u8c03\u5ea6\u6548\u7387\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2511.01383", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01383", "abs": "https://arxiv.org/abs/2511.01383", "authors": ["Landson Guo", "Andres M. Diaz Aguilar", "William Talbot", "Turcan Tuna", "Marco Hutter", "Cesar Cadena"], "title": "CaRLi-V: Camera-RADAR-LiDAR Point-Wise 3D Velocity Estimation", "comment": null, "summary": "Accurate point-wise velocity estimation in 3D is crucial for robot\ninteraction with non-rigid, dynamic agents, such as humans, enabling robust\nperformance in path planning, collision avoidance, and object manipulation in\ndynamic environments. To this end, this paper proposes a novel RADAR, LiDAR,\nand camera fusion pipeline for point-wise 3D velocity estimation named CaRLi-V.\nThis pipeline leverages raw RADAR measurements to create a novel RADAR\nrepresentation, the velocity cube, which densely represents radial velocities\nwithin the RADAR's field-of-view. By combining the velocity cube for radial\nvelocity extraction, optical flow for tangential velocity estimation, and LiDAR\nfor point-wise range measurements through a closed-form solution, our approach\ncan produce 3D velocity estimates for a dense array of points. Developed as an\nopen-source ROS2 package, CaRLi-V has been field-tested against a custom\ndataset and proven to produce low velocity error metrics relative to ground\ntruth, enabling point-wise velocity estimation for robotic applications.", "AI": {"tldr": "\u63d0\u51fa\u540d\u4e3aCaRLi-V\u7684\u65b0\u578b\u591a\u4f20\u611f\u5668\u878d\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408RADAR\u3001LiDAR\u548c\u76f8\u673a\u6570\u636e\uff0c\u5b9e\u73b0\u5bc6\u96c6\u70b9\u4e91\u76843D\u901f\u5ea6\u4f30\u8ba1\uff0c\u7279\u522b\u9002\u7528\u4e8e\u673a\u5668\u4eba\u4e0e\u975e\u521a\u6027\u52a8\u6001\u7269\u4f53\uff08\u5982\u4eba\u7c7b\uff09\u7684\u4ea4\u4e92\u3002", "motivation": "\u5728\u52a8\u6001\u73af\u5883\u4e2d\uff0c\u51c6\u786e\u76843D\u70b9\u7ea7\u901f\u5ea6\u4f30\u8ba1\u5bf9\u4e8e\u673a\u5668\u4eba\u7684\u8def\u5f84\u89c4\u5212\u3001\u78b0\u649e\u907f\u514d\u548c\u7269\u4f53\u64cd\u4f5c\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u4e0e\u975e\u521a\u6027\u52a8\u6001\u4ee3\u7406\uff08\u5982\u4eba\u7c7b\uff09\u4ea4\u4e92\u65f6\u3002", "method": "\u4f7f\u7528\u539f\u59cbRADAR\u6d4b\u91cf\u521b\u5efa\u901f\u5ea6\u7acb\u65b9\u4f53\u8868\u793a\u5f84\u5411\u901f\u5ea6\uff0c\u7ed3\u5408\u5149\u6d41\u4f30\u8ba1\u5207\u5411\u901f\u5ea6\uff0c\u901a\u8fc7LiDAR\u83b7\u53d6\u70b9\u7ea7\u8ddd\u79bb\u6d4b\u91cf\uff0c\u91c7\u7528\u95ed\u5f0f\u89e3\u878d\u5408\u8fd9\u4e9b\u4fe1\u606f\u751f\u6210\u5bc6\u96c63D\u901f\u5ea6\u4f30\u8ba1\u3002", "result": "\u5728\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u663e\u793a\uff0c\u76f8\u5bf9\u4e8e\u771f\u5b9e\u503c\u5177\u6709\u8f83\u4f4e\u7684\u901f\u5ea6\u8bef\u5dee\u6307\u6807\uff0c\u80fd\u591f\u4e3a\u673a\u5668\u4eba\u5e94\u7528\u63d0\u4f9b\u70b9\u7ea7\u901f\u5ea6\u4f30\u8ba1\u3002", "conclusion": "CaRLi-V\u4f5c\u4e3a\u5f00\u6e90ROS2\u5305\uff0c\u901a\u8fc7\u591a\u4f20\u611f\u5668\u878d\u5408\u6709\u6548\u89e3\u51b3\u4e863D\u70b9\u7ea7\u901f\u5ea6\u4f30\u8ba1\u95ee\u9898\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2511.01550", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01550", "abs": "https://arxiv.org/abs/2511.01550", "authors": ["Ujjwal Sharma", "Stevan Rudinac", "Ana Mi\u0107kovi\u0107", "Willemijn van Dolen", "Marcel Worring"], "title": "Analyzing Sustainability Messaging in Large-Scale Corporate Social Media", "comment": null, "summary": "In this work, we introduce a multimodal analysis pipeline that leverages\nlarge foundation models in vision and language to analyze corporate social\nmedia content, with a focus on sustainability-related communication. Addressing\nthe challenges of evolving, multimodal, and often ambiguous corporate messaging\non platforms such as X (formerly Twitter), we employ an ensemble of large\nlanguage models (LLMs) to annotate a large corpus of corporate tweets on their\ntopical alignment with the 17 Sustainable Development Goals (SDGs). This\napproach avoids the need for costly, task-specific annotations and explores the\npotential of such models as ad-hoc annotators for social media data that can\nefficiently capture both explicit and implicit references to sustainability\nthemes in a scalable manner. Complementing this textual analysis, we utilize\nvision-language models (VLMs), within a visual understanding framework that\nuses semantic clusters to uncover patterns in visual sustainability\ncommunication. This integrated approach reveals sectoral differences in SDG\nengagement, temporal trends, and associations between corporate messaging,\nenvironmental, social, governance (ESG) risks, and consumer engagement. Our\nmethods-automatic label generation and semantic visual clustering-are broadly\napplicable to other domains and offer a flexible framework for large-scale\nsocial media analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u591a\u6a21\u6001\u5206\u6790\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u57fa\u7840\u6a21\u578b\u5206\u6790\u4f01\u4e1a\u793e\u4ea4\u5a92\u4f53\u5185\u5bb9\u4e2d\u7684\u53ef\u6301\u7eed\u53d1\u5c55\u6c9f\u901a\uff0c\u7ed3\u5408\u6587\u672c\u548c\u89c6\u89c9\u5206\u6790\u63ed\u793a\u884c\u4e1a\u5dee\u5f02\u3001\u65f6\u95f4\u8d8b\u52bf\u4ee5\u53ca\u4e0eESG\u98ce\u9669\u548c\u7528\u6237\u53c2\u4e0e\u5ea6\u7684\u5173\u8054\u3002", "motivation": "\u89e3\u51b3\u4f01\u4e1a\u793e\u4ea4\u5a92\u4f53\u5185\u5bb9\u7684\u591a\u6a21\u6001\u3001\u6a21\u7cca\u6027\u548c\u52a8\u6001\u53d8\u5316\u5e26\u6765\u7684\u5206\u6790\u6311\u6218\uff0c\u7279\u522b\u662f\u53ef\u6301\u7eed\u53d1\u5c55\u76f8\u5173\u6c9f\u901a\u7684\u8bc6\u522b\u548c\u8bc4\u4f30\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u96c6\u6210\u81ea\u52a8\u6807\u6ce8\u4f01\u4e1a\u63a8\u6587\u4e0e17\u4e2a\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807(SDG)\u7684\u4e3b\u9898\u5bf9\u9f50\uff0c\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLM)\u901a\u8fc7\u8bed\u4e49\u805a\u7c7b\u5206\u6790\u89c6\u89c9\u53ef\u6301\u7eed\u53d1\u5c55\u6c9f\u901a\u6a21\u5f0f\u3002", "result": "\u63ed\u793a\u4e86\u4e0d\u540c\u884c\u4e1a\u5728SDG\u53c2\u4e0e\u5ea6\u4e0a\u7684\u5dee\u5f02\u3001\u65f6\u95f4\u8d8b\u52bf\uff0c\u4ee5\u53ca\u4f01\u4e1a\u4fe1\u606f\u4f20\u9012\u4e0eESG\u98ce\u9669\u3001\u6d88\u8d39\u8005\u53c2\u4e0e\u5ea6\u4e4b\u95f4\u7684\u5173\u8054\u3002", "conclusion": "\u63d0\u51fa\u7684\u81ea\u52a8\u6807\u7b7e\u751f\u6210\u548c\u8bed\u4e49\u89c6\u89c9\u805a\u7c7b\u65b9\u6cd5\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u793e\u4ea4\u5a92\u4f53\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u6846\u67b6\u3002"}}
{"id": "2511.01407", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01407", "abs": "https://arxiv.org/abs/2511.01407", "authors": ["Paolo Rabino", "Gabriele Tiboni", "Tatiana Tommasi"], "title": "FoldPath: End-to-End Object-Centric Motion Generation via Modulated Implicit Paths", "comment": "Accepted at 2025 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2025)", "summary": "Object-Centric Motion Generation (OCMG) is instrumental in advancing\nautomated manufacturing processes, particularly in domains requiring\nhigh-precision expert robotic motions, such as spray painting and welding. To\nrealize effective automation, robust algorithms are essential for generating\nextended, object-aware trajectories across intricate 3D geometries. However,\ncontemporary OCMG techniques are either based on ad-hoc heuristics or employ\nlearning-based pipelines that are still reliant on sensitive post-processing\nsteps to generate executable paths. We introduce FoldPath, a novel, end-to-end,\nneural field based method for OCMG. Unlike prior deep learning approaches that\npredict discrete sequences of end-effector waypoints, FoldPath learns the robot\nmotion as a continuous function, thus implicitly encoding smooth output paths.\nThis paradigm shift eliminates the need for brittle post-processing steps that\nconcatenate and order the predicted discrete waypoints. Particularly, our\napproach demonstrates superior predictive performance compared to recently\nproposed learning-based methods, and attains generalization capabilities even\nin real industrial settings, where only a limited amount of 70 expert samples\nare provided. We validate FoldPath through comprehensive experiments in a\nrealistic simulation environment and introduce new, rigorous metrics designed\nto comprehensively evaluate long-horizon robotic paths, thus advancing the OCMG\ntask towards practical maturity.", "AI": {"tldr": "FoldPath\u662f\u4e00\u79cd\u65b0\u9896\u7684\u7aef\u5230\u7aef\u795e\u7ecf\u573a\u65b9\u6cd5\uff0c\u7528\u4e8e\u7269\u4f53\u4e2d\u5fc3\u8fd0\u52a8\u751f\u6210(OCMG)\u3002\u5b83\u901a\u8fc7\u5c06\u673a\u5668\u4eba\u8fd0\u52a8\u5b66\u4e60\u4e3a\u8fde\u7eed\u51fd\u6570\u6765\u751f\u6210\u5e73\u6ed1\u8def\u5f84\uff0c\u65e0\u9700\u540e\u5904\u7406\u6b65\u9aa4\uff0c\u5728\u6709\u9650\u6837\u672c\u4e0b\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524dOCMG\u6280\u672f\u8981\u4e48\u57fa\u4e8e\u4e34\u65f6\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u8981\u4e48\u4f9d\u8d56\u5b66\u4e60\u578b\u7ba1\u9053\u4f46\u4ecd\u9700\u654f\u611f\u7684\u540e\u5904\u7406\u6b65\u9aa4\u6765\u751f\u6210\u53ef\u6267\u884c\u8def\u5f84\u3002\u9700\u8981\u66f4\u7a33\u5065\u7684\u7b97\u6cd5\u6765\u4e3a\u590d\u67423D\u51e0\u4f55\u4f53\u751f\u6210\u6269\u5c55\u7684\u3001\u7269\u4f53\u611f\u77e5\u7684\u8f68\u8ff9\u3002", "method": "FoldPath\u91c7\u7528\u795e\u7ecf\u573a\u65b9\u6cd5\uff0c\u5c06\u673a\u5668\u4eba\u8fd0\u52a8\u5b66\u4e60\u4e3a\u8fde\u7eed\u51fd\u6570\uff0c\u800c\u4e0d\u662f\u9884\u6d4b\u79bb\u6563\u7684\u672b\u7aef\u6267\u884c\u5668\u8def\u5f84\u70b9\u3002\u8fd9\u79cd\u8303\u5f0f\u8f6c\u53d8\u6d88\u9664\u4e86\u8fde\u63a5\u548c\u6392\u5e8f\u9884\u6d4b\u79bb\u6563\u8def\u5f84\u70b9\u7684\u8106\u5f31\u540e\u5904\u7406\u6b65\u9aa4\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u9884\u6d4b\u6027\u80fd\u4e0a\u4f18\u4e8e\u6700\u8fd1\u63d0\u51fa\u7684\u5b66\u4e60\u578b\u65b9\u6cd5\uff0c\u5728\u771f\u5b9e\u5de5\u4e1a\u73af\u5883\u4e2d\u4ec5\u4f7f\u752870\u4e2a\u4e13\u5bb6\u6837\u672c\u5c31\u5c55\u73b0\u51fa\u6cdb\u5316\u80fd\u529b\u3002\u901a\u8fc7\u5728\u771f\u5b9e\u6a21\u62df\u73af\u5883\u4e2d\u7684\u5168\u9762\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "FoldPath\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u4e25\u683c\u6307\u6807\u6765\u5168\u9762\u8bc4\u4f30\u957f\u65f6\u57df\u673a\u5668\u4eba\u8def\u5f84\uff0c\u5c06OCMG\u4efb\u52a1\u63a8\u5411\u5b9e\u9645\u6210\u719f\u5e94\u7528\uff0c\u4e3a\u81ea\u52a8\u5316\u5236\u9020\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01581", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01581", "abs": "https://arxiv.org/abs/2511.01581", "authors": ["Chengzhang Yu", "Zening Lu", "Chenyang Zheng", "Chiyue Wang", "Yiming Zhang", "Zhanpeng Jin"], "title": "ExplicitLM: Decoupling Knowledge from Parameters via Explicit Memory Banks", "comment": "12pages, 4figures", "summary": "Large language models suffer from knowledge staleness and lack of\ninterpretability due to implicit knowledge storage across entangled network\nparameters, preventing targeted updates and reasoning transparency. We propose\nExplicitLM, a novel architecture featuring a million-scale external memory bank\nstoring human-readable knowledge as token sequences, enabling direct inspection\nand modification. We design a differentiable two-stage retrieval mechanism with\nefficient coarse-grained filtering via product key decomposition (reducing\ncomplexity from $\\mathcal{O}(N \\cdot |I|)$ to $\\mathcal{O}(\\sqrt{N} \\cdot\n|I|)$) and fine-grained Gumbel-Softmax matching for end-to-end training.\nInspired by dual-system cognitive theory, we partition knowledge into frozen\nexplicit facts (20%) and learnable implicit patterns (80%), maintained through\nExponential Moving Average updates for stability. ExplicitLM achieves up to\n43.67% improvement on knowledge-intensive tasks versus standard Transformers,\nwith 3.62$\\times$ gains in low-data regimes (10k samples). Analysis shows\nstrong correlations between memory retrieval and performance, with correct\npredictions achieving 49% higher hit rates. Unlike RAG systems with frozen\nretrieval, our jointly optimized architecture demonstrates that interpretable,\nupdatable models can maintain competitive performance while providing\nunprecedented knowledge transparency.", "AI": {"tldr": "ExplicitLM\u662f\u4e00\u79cd\u65b0\u9896\u7684\u67b6\u6784\uff0c\u901a\u8fc7\u767e\u4e07\u89c4\u6a21\u7684\u5916\u90e8\u8bb0\u5fc6\u5e93\u5b58\u50a8\u4eba\u7c7b\u53ef\u8bfb\u7684\u77e5\u8bc6\u4f5c\u4e3a\u6807\u8bb0\u5e8f\u5217\uff0c\u5b9e\u73b0\u76f4\u63a5\u68c0\u67e5\u548c\u4fee\u6539\uff0c\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u9648\u65e7\u6027\u548c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u95ee\u9898\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7531\u4e8e\u77e5\u8bc6\u5728\u7ea0\u7f20\u7684\u7f51\u7edc\u53c2\u6570\u4e2d\u9690\u5f0f\u5b58\u50a8\uff0c\u5b58\u5728\u77e5\u8bc6\u9648\u65e7\u548c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u7684\u95ee\u9898\uff0c\u963b\u788d\u4e86\u9488\u5bf9\u6027\u66f4\u65b0\u548c\u63a8\u7406\u900f\u660e\u6027\u3002", "method": "\u8bbe\u8ba1\u53ef\u5fae\u5206\u7684\u4e24\u9636\u6bb5\u68c0\u7d22\u673a\u5236\uff1a\u901a\u8fc7\u4ea7\u54c1\u952e\u5206\u89e3\u8fdb\u884c\u9ad8\u6548\u7c97\u7c92\u5ea6\u8fc7\u6ee4\uff08\u5c06\u590d\u6742\u5ea6\u4eceO(N\u00b7|I|)\u964d\u4f4e\u5230O(\u221aN\u00b7|I|)\uff09\uff0c\u4ee5\u53ca\u7528\u4e8e\u7aef\u5230\u7aef\u8bad\u7ec3\u7684\u7ec6\u7c92\u5ea6Gumbel-Softmax\u5339\u914d\u3002\u53d7\u53cc\u7cfb\u7edf\u8ba4\u77e5\u7406\u8bba\u542f\u53d1\uff0c\u5c06\u77e5\u8bc6\u5212\u5206\u4e3a\u51bb\u7ed3\u7684\u663e\u5f0f\u4e8b\u5b9e\uff0820%\uff09\u548c\u53ef\u5b66\u4e60\u7684\u9690\u5f0f\u6a21\u5f0f\uff0880%\uff09\uff0c\u901a\u8fc7\u6307\u6570\u79fb\u52a8\u5e73\u5747\u66f4\u65b0\u4fdd\u6301\u7a33\u5b9a\u6027\u3002", "result": "\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u6bd4\u6807\u51c6Transformer\u63d0\u5347\u9ad8\u8fbe43.67%\uff0c\u5728\u4f4e\u6570\u636e\u573a\u666f\uff081\u4e07\u4e2a\u6837\u672c\uff09\u4e0b\u83b7\u5f973.62\u500d\u7684\u589e\u76ca\u3002\u5206\u6790\u663e\u793a\u5185\u5b58\u68c0\u7d22\u4e0e\u6027\u80fd\u4e4b\u95f4\u5b58\u5728\u5f3a\u76f8\u5173\u6027\uff0c\u6b63\u786e\u9884\u6d4b\u7684\u547d\u4e2d\u7387\u9ad8\u51fa49%\u3002", "conclusion": "\u4e0e\u4f7f\u7528\u51bb\u7ed3\u68c0\u7d22\u7684RAG\u7cfb\u7edf\u4e0d\u540c\uff0c\u8054\u5408\u4f18\u5316\u7684\u67b6\u6784\u8868\u660e\uff0c\u53ef\u89e3\u91ca\u3001\u53ef\u66f4\u65b0\u7684\u6a21\u578b\u53ef\u4ee5\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u540c\u65f6\u63d0\u4f9b\u524d\u6240\u672a\u6709\u7684\u77e5\u8bc6\u900f\u660e\u5ea6\u3002"}}
{"id": "2511.01437", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01437", "abs": "https://arxiv.org/abs/2511.01437", "authors": ["Elian Neppel", "Shamistan Karimov", "Ashutosh Mishra", "Gustavo Hernan Diaz Huenupan", "Hazal Gozbasi", "Kentaro Uno", "Shreya Santra", "Kazuya Yoshida"], "title": "Designing for Distributed Heterogeneous Modularity: On Software Architecture and Deployment of MoonBots", "comment": "6 pages, 8 figures. Accepted at ISPARO 2025", "summary": "This paper presents the software architecture and deployment strategy behind\nthe MoonBot platform: a modular space robotic system composed of heterogeneous\ncomponents distributed across multiple computers, networks and ultimately\ncelestial bodies. We introduce a principled approach to distributed,\nheterogeneous modularity, extending modular robotics beyond physical\nreconfiguration to software, communication and orchestration. We detail the\narchitecture of our system that integrates component-based design, a\ndata-oriented communication model using ROS2 and Zenoh, and a deployment\norchestrator capable of managing complex multi-module assemblies. These\nabstractions enable dynamic reconfiguration, decentralized control, and\nseamless collaboration between numerous operators and modules. At the heart of\nthis system lies our open-source Motion Stack software, validated by months of\nfield deployment with self-assembling robots, inter-robot cooperation, and\nremote operation. Our architecture tackles the significant hurdles of modular\nrobotics by significantly reducing integration and maintenance overhead, while\nremaining scalable and robust. Although tested with space in mind, we propose\ngeneralizable patterns for designing robotic systems that must scale across\ntime, hardware, teams and operational environments.", "AI": {"tldr": "MoonBot\u5e73\u53f0\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u7a7a\u95f4\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u91c7\u7528\u5206\u5e03\u5f0f\u5f02\u6784\u67b6\u6784\uff0c\u901a\u8fc7ROS2\u548cZenoh\u5b9e\u73b0\u6570\u636e\u5bfc\u5411\u901a\u4fe1\uff0c\u652f\u6301\u52a8\u6001\u91cd\u6784\u548c\u53bb\u4e2d\u5fc3\u5316\u63a7\u5236\uff0c\u5df2\u5728\u81ea\u7ec4\u88c5\u673a\u5668\u4eba\u548c\u8fdc\u7a0b\u64cd\u4f5c\u4e2d\u9a8c\u8bc1\u3002", "motivation": "\u89e3\u51b3\u6a21\u5757\u5316\u673a\u5668\u4eba\u7cfb\u7edf\u5728\u96c6\u6210\u548c\u7ef4\u62a4\u65b9\u9762\u7684\u91cd\u5927\u6311\u6218\uff0c\u4e3a\u8de8\u65f6\u95f4\u3001\u786c\u4ef6\u3001\u56e2\u961f\u548c\u64cd\u4f5c\u73af\u5883\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u53ef\u63a8\u5e7f\u7684\u6a21\u5f0f\u3002", "method": "\u91c7\u7528\u7ec4\u4ef6\u5316\u8bbe\u8ba1\u3001\u57fa\u4e8eROS2\u548cZenoh\u7684\u6570\u636e\u5bfc\u5411\u901a\u4fe1\u6a21\u578b\uff0c\u4ee5\u53ca\u80fd\u591f\u7ba1\u7406\u590d\u6742\u591a\u6a21\u5757\u7ec4\u4ef6\u7684\u90e8\u7f72\u7f16\u6392\u5668\uff0c\u5b9e\u73b0\u5206\u5e03\u5f0f\u5f02\u6784\u6a21\u5757\u5316\u3002", "result": "\u7ecf\u8fc7\u6570\u6708\u7684\u73b0\u573a\u90e8\u7f72\u9a8c\u8bc1\uff0c\u7cfb\u7edf\u663e\u8457\u964d\u4f4e\u4e86\u96c6\u6210\u548c\u7ef4\u62a4\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\uff0c\u6210\u529f\u5e94\u7528\u4e8e\u81ea\u7ec4\u88c5\u673a\u5668\u4eba\u3001\u673a\u5668\u4eba\u95f4\u534f\u4f5c\u548c\u8fdc\u7a0b\u64cd\u4f5c\u3002", "conclusion": "\u8be5\u67b6\u6784\u4e0d\u4ec5\u9488\u5bf9\u592a\u7a7a\u5e94\u7528\uff0c\u8fd8\u4e3a\u5fc5\u987b\u8de8\u8d8a\u65f6\u95f4\u3001\u786c\u4ef6\u3001\u56e2\u961f\u548c\u64cd\u4f5c\u73af\u5883\u6269\u5c55\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u63d0\u4f9b\u4e86\u901a\u7528\u8bbe\u8ba1\u6a21\u5f0f\u3002"}}
{"id": "2511.01639", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01639", "abs": "https://arxiv.org/abs/2511.01639", "authors": ["Sicheng Wang", "Shuhao Chen", "Jingran Zhou", "Chengyi Tu"], "title": "IVGAE-TAMA-BO: A novel temporal dynamic variational graph model for link prediction in global food trade networks with momentum structural memory and Bayesian optimization", "comment": "26pages,6figures", "summary": "Global food trade plays a crucial role in ensuring food security and\nmaintaining supply chain stability. However, its network structure evolves\ndynamically under the influence of geopolitical, economic, and environmental\nfactors, making it challenging to model and predict future trade links.\nEffectively capturing temporal patterns in food trade networks is therefore\nessential for improving the accuracy and robustness of link prediction. This\nstudy introduces IVGAE-TAMA-BO, a novel dynamic graph neural network designed\nto model evolving trade structures and predict future links in global food\ntrade networks. To the best of our knowledge, this is the first work to apply\ndynamic graph neural networks to this domain, significantly enhancing\npredictive performance. Building upon the original IVGAE framework, the\nproposed model incorporates a Trade-Aware Momentum Aggregator (TAMA) to capture\nthe temporal evolution of trade networks, jointly modeling short-term\nfluctuations and long-term structural dependencies. A momentum-based structural\nmemory mechanism further improves predictive stability and performance. In\naddition, Bayesian optimization is used to automatically tune key\nhyperparameters, enhancing generalization across diverse trade scenarios.\nExtensive experiments on five crop-specific datasets demonstrate that\nIVGAE-TAMA substantially outperforms the static IVGAE and other dynamic\nbaselines by effectively modeling temporal dependencies, while Bayesian\noptimization further boosts performance in IVGAE-TAMA-BO. These results\nhighlight the proposed framework as a robust and scalable solution for\nstructural prediction in global trade networks, with strong potential for\napplications in food security monitoring and policy decision support.", "AI": {"tldr": "\u63d0\u51fa\u4e86IVGAE-TAMA-BO\u52a8\u6001\u56fe\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u5168\u7403\u7cae\u98df\u8d38\u6613\u7f51\u7edc\u4e2d\u7684\u672a\u6765\u94fe\u63a5\uff0c\u901a\u8fc7\u65f6\u95f4\u611f\u77e5\u52a8\u91cf\u805a\u5408\u5668\u548c\u8d1d\u53f6\u65af\u4f18\u5316\u663e\u8457\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u5168\u7403\u7cae\u98df\u8d38\u6613\u7f51\u7edc\u5728\u653f\u6cbb\u3001\u7ecf\u6d4e\u548c\u73af\u5883\u56e0\u7d20\u5f71\u54cd\u4e0b\u52a8\u6001\u6f14\u53d8\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u6355\u6349\u65f6\u95f4\u6a21\u5f0f\uff0c\u9700\u8981\u66f4\u51c6\u786e\u7684\u94fe\u63a5\u9884\u6d4b\u65b9\u6cd5\u6765\u4fdd\u969c\u7cae\u98df\u5b89\u5168\u548c\u4f9b\u5e94\u94fe\u7a33\u5b9a\u3002", "method": "\u5728IVGAE\u6846\u67b6\u57fa\u7840\u4e0a\uff0c\u5f15\u5165\u8d38\u6613\u611f\u77e5\u52a8\u91cf\u805a\u5408\u5668(TAMA)\u6355\u6349\u8d38\u6613\u7f51\u7edc\u7684\u65f6\u95f4\u6f14\u5316\uff0c\u8054\u5408\u5efa\u6a21\u77ed\u671f\u6ce2\u52a8\u548c\u957f\u671f\u7ed3\u6784\u4f9d\u8d56\uff0c\u5e76\u4f7f\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u81ea\u52a8\u8c03\u53c2\u3002", "result": "\u5728\u4e94\u4e2a\u4f5c\u7269\u7279\u5b9a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cIVGAE-TAMA\u663e\u8457\u4f18\u4e8e\u9759\u6001IVGAE\u548c\u5176\u4ed6\u52a8\u6001\u57fa\u7ebf\u6a21\u578b\uff0c\u8d1d\u53f6\u65af\u4f18\u5316\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86IVGAE-TAMA-BO\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5168\u7403\u8d38\u6613\u7f51\u7edc\u7ed3\u6784\u9884\u6d4b\u63d0\u4f9b\u4e86\u7a33\u5065\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u7cae\u98df\u5b89\u5168\u76d1\u6d4b\u548c\u653f\u7b56\u51b3\u7b56\u652f\u6301\u65b9\u9762\u5177\u6709\u91cd\u8981\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.01472", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01472", "abs": "https://arxiv.org/abs/2511.01472", "authors": ["Sarthak Mishra", "Rishabh Dev Yadav", "Avirup Das", "Saksham Gupta", "Wei Pan", "Spandan Roy"], "title": "AERMANI-VLM: Structured Prompting and Reasoning for Aerial Manipulation with Vision Language Models", "comment": null, "summary": "The rapid progress of vision--language models (VLMs) has sparked growing\ninterest in robotic control, where natural language can express the operation\ngoals while visual feedback links perception to action. However, directly\ndeploying VLM-driven policies on aerial manipulators remains unsafe and\nunreliable since the generated actions are often inconsistent,\nhallucination-prone, and dynamically infeasible for flight. In this work, we\npresent AERMANI-VLM, the first framework to adapt pretrained VLMs for aerial\nmanipulation by separating high-level reasoning from low-level control, without\nany task-specific fine-tuning. Our framework encodes natural language\ninstructions, task context, and safety constraints into a structured prompt\nthat guides the model to generate a step-by-step reasoning trace in natural\nlanguage. This reasoning output is used to select from a predefined library of\ndiscrete, flight-safe skills, ensuring interpretable and temporally consistent\nexecution. By decoupling symbolic reasoning from physical action, AERMANI-VLM\nmitigates hallucinated commands and prevents unsafe behavior, enabling robust\ntask completion. We validate the framework in both simulation and hardware on\ndiverse multi-step pick-and-place tasks, demonstrating strong generalization to\npreviously unseen commands, objects, and environments.", "AI": {"tldr": "AERMANI-VLM\u6846\u67b6\u901a\u8fc7\u5c06\u9ad8\u5c42\u63a8\u7406\u4e0e\u5e95\u5c42\u63a7\u5236\u5206\u79bb\uff0c\u5c06\u9884\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u5730\u5e94\u7528\u4e8e\u7a7a\u4e2d\u673a\u68b0\u81c2\u64cd\u4f5c\uff0c\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u3002", "motivation": "\u76f4\u63a5\u90e8\u7f72\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u7b56\u7565\u5230\u7a7a\u4e2d\u673a\u68b0\u81c2\u4e0a\u4e0d\u5b89\u5168\u4e14\u4e0d\u53ef\u9760\uff0c\u56e0\u4e3a\u751f\u6210\u7684\u52a8\u4f5c\u5f80\u5f80\u4e0d\u4e00\u81f4\u3001\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\uff0c\u4e14\u5bf9\u98de\u884c\u6765\u8bf4\u52a8\u6001\u4e0d\u53ef\u884c\u3002", "method": "\u4f7f\u7528\u7ed3\u6784\u5316\u63d0\u793a\u7f16\u7801\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u3001\u4efb\u52a1\u4e0a\u4e0b\u6587\u548c\u5b89\u5168\u7ea6\u675f\uff0c\u5f15\u5bfc\u6a21\u578b\u751f\u6210\u9010\u6b65\u63a8\u7406\u8f68\u8ff9\uff0c\u7136\u540e\u4ece\u9884\u5b9a\u4e49\u7684\u5b89\u5168\u6280\u80fd\u5e93\u4e2d\u9009\u62e9\u79bb\u6563\u52a8\u4f5c\u3002", "result": "\u5728\u4eff\u771f\u548c\u786c\u4ef6\u4e0a\u7684\u591a\u6837\u5316\u591a\u6b65\u9aa4\u62fe\u653e\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u5bf9\u672a\u89c1\u547d\u4ee4\u3001\u7269\u4f53\u548c\u73af\u5883\u7684\u5f3a\u5927\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u89e3\u8026\u7b26\u53f7\u63a8\u7406\u548c\u7269\u7406\u52a8\u4f5c\uff0cAERMANI-VLM\u51cf\u8f7b\u4e86\u5e7b\u89c9\u547d\u4ee4\u5e76\u9632\u6b62\u4e0d\u5b89\u5168\u884c\u4e3a\uff0c\u5b9e\u73b0\u4e86\u7a33\u5065\u7684\u4efb\u52a1\u5b8c\u6210\u3002"}}
{"id": "2511.01668", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01668", "abs": "https://arxiv.org/abs/2511.01668", "authors": ["Yueqing Xi", "Yifan Bai", "Huasen Luo", "Weiliang Wen", "Hui Liu", "Haoliang Li"], "title": "Hybrid Retrieval-Augmented Generation Agent for Trustworthy Legal Question Answering in Judicial Forensics", "comment": null, "summary": "As artificial intelligence permeates judicial forensics, ensuring the\nveracity and traceability of legal question answering (QA) has become critical.\nConventional large language models (LLMs) are prone to hallucination, risking\nmisleading guidance in legal consultation, while static knowledge bases\nstruggle to keep pace with frequently updated statutes and case law. We present\na hybrid legal QA agent tailored for judicial settings that integrates\nretrieval-augmented generation (RAG) with multi-model ensembling to deliver\nreliable, auditable, and continuously updatable counsel. The system prioritizes\nretrieval over generation: when a trusted legal repository yields relevant\nevidence, answers are produced via RAG; otherwise, multiple LLMs generate\ncandidates that are scored by a specialized selector, with the top-ranked\nanswer returned. High-quality outputs then undergo human review before being\nwritten back to the repository, enabling dynamic knowledge evolution and\nprovenance tracking. Experiments on the Law\\_QA dataset show that our hybrid\napproach significantly outperforms both a single-model baseline and a vanilla\nRAG pipeline on F1, ROUGE-L, and an LLM-as-a-Judge metric. Ablations confirm\nthe complementary contributions of retrieval prioritization, model ensembling,\nand the human-in-the-loop update mechanism. The proposed system demonstrably\nreduces hallucination while improving answer quality and legal compliance,\nadvancing the practical landing of media forensics technologies in judicial\nscenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u591a\u6a21\u578b\u96c6\u6210\u7684\u6df7\u5408\u6cd5\u5f8b\u95ee\u7b54\u4ee3\u7406\uff0c\u901a\u8fc7\u68c0\u7d22\u4f18\u5148\u7b56\u7565\u3001\u6a21\u578b\u96c6\u6210\u548c\u4eba\u5de5\u5ba1\u6838\u673a\u5236\uff0c\u663e\u8457\u51cf\u5c11\u5e7b\u89c9\u5e76\u63d0\u9ad8\u6cd5\u5f8b\u5408\u89c4\u6027\u3002", "motivation": "\u4f20\u7edf\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u95ee\u7b54\u4e2d\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\uff0c\u53ef\u80fd\u8bef\u5bfc\u6cd5\u5f8b\u54a8\u8be2\uff1b\u9759\u6001\u77e5\u8bc6\u5e93\u96be\u4ee5\u8ddf\u4e0a\u9891\u7e41\u66f4\u65b0\u7684\u6cd5\u89c4\u548c\u5224\u4f8b\uff0c\u9700\u8981\u786e\u4fdd\u6cd5\u5f8b\u95ee\u7b54\u7684\u771f\u5b9e\u6027\u548c\u53ef\u8ffd\u6eaf\u6027\u3002", "method": "\u91c7\u7528\u68c0\u7d22\u4f18\u5148\u7b56\u7565\uff1a\u5f53\u53ef\u4fe1\u6cd5\u5f8b\u77e5\u8bc6\u5e93\u68c0\u7d22\u5230\u76f8\u5173\u8bc1\u636e\u65f6\u4f7f\u7528RAG\u751f\u6210\u7b54\u6848\uff0c\u5426\u5219\u901a\u8fc7\u591a\u4e2aLLM\u751f\u6210\u5019\u9009\u7b54\u6848\u5e76\u7531\u4e13\u95e8\u9009\u62e9\u5668\u8bc4\u5206\u8fd4\u56de\u6700\u4f73\u7b54\u6848\u3002\u9ad8\u8d28\u91cf\u8f93\u51fa\u7ecf\u8fc7\u4eba\u5de5\u5ba1\u6838\u540e\u5199\u56de\u77e5\u8bc6\u5e93\uff0c\u5b9e\u73b0\u52a8\u6001\u77e5\u8bc6\u6f14\u8fdb\u548c\u6eaf\u6e90\u8ddf\u8e2a\u3002", "result": "\u5728Law_QA\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6df7\u5408\u65b9\u6cd5\u5728F1\u3001ROUGE-L\u548cLLM-as-a-Judge\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u5355\u6a21\u578b\u57fa\u7ebf\u548c\u666e\u901aRAG\u6d41\u7a0b\u3002\u6d88\u878d\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u68c0\u7d22\u4f18\u5148\u3001\u6a21\u578b\u96c6\u6210\u548c\u4eba\u5de5\u66f4\u65b0\u673a\u5236\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u663e\u8457\u51cf\u5c11\u4e86\u5e7b\u89c9\uff0c\u63d0\u9ad8\u4e86\u7b54\u6848\u8d28\u91cf\u548c\u6cd5\u5f8b\u5408\u89c4\u6027\uff0c\u63a8\u52a8\u4e86\u5a92\u4f53\u53d6\u8bc1\u6280\u672f\u5728\u53f8\u6cd5\u573a\u666f\u4e2d\u7684\u5b9e\u9645\u843d\u5730\u5e94\u7528\u3002"}}
{"id": "2511.01476", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01476", "abs": "https://arxiv.org/abs/2511.01476", "authors": ["Cankut Bora Tuncer", "Marc Toussaint", "Ozgur S. Oguz"], "title": "MO-SeGMan: Rearrangement Planning Framework for Multi Objective Sequential and Guided Manipulation in Constrained Environments", "comment": "8 pages, 8 figures, website:https://sites.google.com/view/mo-segman/", "summary": "In this work, we introduce MO-SeGMan, a Multi-Objective Sequential and Guided\nManipulation planner for highly constrained rearrangement problems. MO-SeGMan\ngenerates object placement sequences that minimize both replanning per object\nand robot travel distance while preserving critical dependency structures with\na lazy evaluation method. To address highly cluttered, non-monotone scenarios,\nwe propose a Selective Guided Forward Search (SGFS) that efficiently relocates\nonly critical obstacles and to feasible relocation points. Furthermore, we\nadopt a refinement method for adaptive subgoal selection to eliminate\nunnecessary pick-and-place actions, thereby improving overall solution quality.\nExtensive evaluations on nine benchmark rearrangement tasks demonstrate that\nMO-SeGMan generates feasible motion plans in all cases, consistently achieving\nfaster solution times and superior solution quality compared to the baselines.\nThese results highlight the robustness and scalability of the proposed\nframework for complex rearrangement planning problems.", "AI": {"tldr": "MO-SeGMan\u662f\u4e00\u4e2a\u591a\u76ee\u6807\u987a\u5e8f\u5f15\u5bfc\u64cd\u4f5c\u89c4\u5212\u5668\uff0c\u7528\u4e8e\u89e3\u51b3\u9ad8\u5ea6\u53d7\u9650\u7684\u91cd\u6392\u95ee\u9898\u3002\u5b83\u901a\u8fc7\u6700\u5c0f\u5316\u91cd\u89c4\u5212\u6b21\u6570\u548c\u673a\u5668\u4eba\u79fb\u52a8\u8ddd\u79bb\uff0c\u540c\u65f6\u4fdd\u6301\u5173\u952e\u4f9d\u8d56\u7ed3\u6784\uff0c\u5728\u590d\u6742\u573a\u666f\u4e2d\u9ad8\u6548\u751f\u6210\u53ef\u884c\u7684\u8fd0\u52a8\u89c4\u5212\u3002", "motivation": "\u89e3\u51b3\u9ad8\u5ea6\u53d7\u9650\u3001\u975e\u5355\u8c03\u7684\u91cd\u6392\u89c4\u5212\u95ee\u9898\uff0c\u8fd9\u4e9b\u573a\u666f\u901a\u5e38\u5b58\u5728\u5927\u91cf\u969c\u788d\u7269\u548c\u590d\u6742\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u9ad8\u6548\u5904\u7406\u3002", "method": "\u91c7\u7528\u9009\u62e9\u6027\u5f15\u5bfc\u524d\u5411\u641c\u7d22(SGFS)\u6765\u91cd\u65b0\u5b9a\u4f4d\u5173\u952e\u969c\u788d\u7269\uff0c\u4f7f\u7528\u60f0\u6027\u8bc4\u4f30\u65b9\u6cd5\u4fdd\u6301\u4f9d\u8d56\u7ed3\u6784\uff0c\u5e76\u901a\u8fc7\u81ea\u9002\u5e94\u5b50\u76ee\u6807\u9009\u62e9\u7684\u7cbe\u5316\u65b9\u6cd5\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u62fe\u653e\u52a8\u4f5c\u3002", "result": "\u57289\u4e2a\u57fa\u51c6\u91cd\u6392\u4efb\u52a1\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cMO-SeGMan\u5728\u6240\u6709\u60c5\u51b5\u4e0b\u90fd\u80fd\u751f\u6210\u53ef\u884c\u7684\u8fd0\u52a8\u89c4\u5212\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f97\u66f4\u5feb\u7684\u6c42\u89e3\u65f6\u95f4\u548c\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u3002", "conclusion": "MO-SeGMan\u6846\u67b6\u5728\u590d\u6742\u91cd\u6392\u89c4\u5212\u95ee\u9898\u4e2d\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u9ad8\u5ea6\u53d7\u9650\u573a\u666f\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01824", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01824", "abs": "https://arxiv.org/abs/2511.01824", "authors": ["Yuetai Li", "Huseyin A Inan", "Xiang Yue", "Wei-Ning Chen", "Lukas Wutschitz", "Janardhan Kulkarni", "Radha Poovendran", "Robert Sim", "Saravan Rajmohan"], "title": "Simulating Environments with Reasoning Models for Agent Training", "comment": null, "summary": "LLM agents excel in compact environments requiring deep reasoning but remain\nbrittle when operating in broader, more complex contexts that demand robustness\nacross diverse tools and schemas. Building bespoke environments for training is\nheavy, brittle, and limits progress. In this paper, we demonstrate that LLMs\ncan simulate realistic environment feedback without access to actual testbed\ndata or APIs. Inspired by this capability, we propose two frameworks:\nSimia-SFT, a pipeline that synthesizes SFT data by amplifying small seed sets\ninto diverse trajectories in an environment-agnostic manner, and Simia-RL, a\nframework that enables RL training without real environment implementations\nthrough LLM-simulated feedback. Fine-tuning open models yields consistent\nimprovements across multiple benchmarks, surpassing GPT-4o and approaching\no4-mini on $\\tau^2$-Bench. Together, Simia-SFT and Simia-RL enable scalable\nagent training without environment engineering, replacing heavy and brittle\nimplementations with flexible LLM-based simulation.", "AI": {"tldr": "LLM\u4ee3\u7406\u5728\u590d\u6742\u73af\u5883\u4e2d\u8868\u73b0\u8106\u5f31\uff0c\u672c\u6587\u63d0\u51faSimia-SFT\u548cSimia-RL\u6846\u67b6\uff0c\u901a\u8fc7LLM\u6a21\u62df\u73af\u5883\u53cd\u9988\u5b9e\u73b0\u65e0\u9700\u771f\u5b9e\u73af\u5883\u6570\u636e\u7684\u53ef\u6269\u5c55\u4ee3\u7406\u8bad\u7ec3\u3002", "motivation": "LLM\u4ee3\u7406\u5728\u9700\u8981\u8de8\u591a\u79cd\u5de5\u5177\u548c\u6a21\u5f0f\u7684\u590d\u6742\u73af\u5883\u4e2d\u8868\u73b0\u8106\u5f31\uff0c\u800c\u6784\u5efa\u5b9a\u5236\u8bad\u7ec3\u73af\u5883\u6210\u672c\u9ad8\u4e14\u9650\u5236\u8fdb\u5c55\u3002", "method": "\u63d0\u51fa\u4e24\u4e2a\u6846\u67b6\uff1aSimia-SFT\u901a\u8fc7\u6269\u589e\u5c0f\u89c4\u6a21\u79cd\u5b50\u6570\u636e\u751f\u6210\u591a\u6837\u5316\u8f68\u8ff9\u7684SFT\u6570\u636e\uff1bSimia-RL\u901a\u8fc7LLM\u6a21\u62df\u53cd\u9988\u5b9e\u73b0\u65e0\u9700\u771f\u5b9e\u73af\u5883\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u3002", "result": "\u5fae\u8c03\u5f00\u6e90\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e00\u81f4\u6539\u8fdb\uff0c\u5728\u03c4\u00b2-Bench\u4e0a\u8d85\u8d8aGPT-4o\u5e76\u63a5\u8fd1o4-mini\u6027\u80fd\u3002", "conclusion": "Simia-SFT\u548cSimia-RL\u80fd\u591f\u5b9e\u73b0\u65e0\u9700\u73af\u5883\u5de5\u7a0b\u7684\u53ef\u6269\u5c55\u4ee3\u7406\u8bad\u7ec3\uff0c\u7528\u7075\u6d3b\u7684LLM\u6a21\u62df\u66ff\u4ee3\u7e41\u91cd\u8106\u5f31\u7684\u73af\u5883\u5b9e\u73b0\u3002"}}
{"id": "2511.01493", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01493", "abs": "https://arxiv.org/abs/2511.01493", "authors": ["Wei Huang", "Jiaxin Li", "Zang Wan", "Huijun Di", "Wei Liang", "Zhu Yang"], "title": "Floor Plan-Guided Visual Navigation Incorporating Depth and Directional Cues", "comment": null, "summary": "Guiding an agent to a specific target in indoor environments based solely on\nRGB inputs and a floor plan is a promising yet challenging problem. Although\nexisting methods have made significant progress, two challenges remain\nunresolved. First, the modality gap between egocentric RGB observations and the\nfloor plan hinders the integration of visual and spatial information for both\nlocal obstacle avoidance and global planning. Second, accurate localization is\ncritical for navigation performance, but remains challenging at deployment in\nunseen environments due to the lack of explicit geometric alignment between RGB\ninputs and floor plans. We propose a novel diffusion-based policy, denoted as\nGlocDiff, which integrates global path planning from the floor plan with local\ndepth-aware features derived from RGB observations. The floor plan offers\nexplicit global guidance, while the depth features provide implicit geometric\ncues, collectively enabling precise prediction of optimal navigation directions\nand robust obstacle avoidance. Moreover, GlocDiff introduces noise perturbation\nduring training to enhance robustness against pose estimation errors, and we\nfind that combining this with a relatively stable VO module during inference\nresults in significantly improved navigation performance. Extensive experiments\non the FloNa benchmark demonstrate GlocDiff's efficiency and effectiveness in\nachieving superior navigation performance, and the success of real-world\ndeployments also highlights its potential for widespread practical\napplications.", "AI": {"tldr": "\u63d0\u51faGlocDiff\uff0c\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u5bfc\u822a\u7b56\u7565\uff0c\u7ed3\u5408\u697c\u5c42\u5e73\u9762\u56fe\u7684\u5168\u5c40\u8def\u5f84\u89c4\u5212\u548cRGB\u89c2\u6d4b\u7684\u5c40\u90e8\u6df1\u5ea6\u7279\u5f81\uff0c\u89e3\u51b3\u5ba4\u5185\u5bfc\u822a\u4e2d\u89c6\u89c9\u4e0e\u7a7a\u95f4\u4fe1\u606f\u878d\u5408\u7684\u6311\u6218\u3002", "motivation": "\u89e3\u51b3\u5ba4\u5185\u5bfc\u822a\u4e2d\u7684\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1aRGB\u89c2\u6d4b\u4e0e\u697c\u5c42\u5e73\u9762\u56fe\u4e4b\u95f4\u7684\u6a21\u6001\u5dee\u8ddd\u963b\u788d\u89c6\u89c9\u548c\u7a7a\u95f4\u4fe1\u606f\u878d\u5408\uff1b\u5728\u672a\u89c1\u73af\u5883\u4e2d\u7531\u4e8e\u7f3a\u4e4f\u663e\u5f0f\u51e0\u4f55\u5bf9\u9f50\u800c\u96be\u4ee5\u5b9e\u73b0\u7cbe\u786e\u5b9a\u4f4d\u3002", "method": "\u4f7f\u7528\u6269\u6563\u6a21\u578b\u6574\u5408\u5168\u5c40\u8def\u5f84\u89c4\u5212\uff08\u6765\u81ea\u697c\u5c42\u5e73\u9762\u56fe\uff09\u548c\u5c40\u90e8\u6df1\u5ea6\u611f\u77e5\u7279\u5f81\uff08\u6765\u81eaRGB\u89c2\u6d4b\uff09\uff0c\u5728\u8bad\u7ec3\u4e2d\u5f15\u5165\u566a\u58f0\u6270\u52a8\u589e\u5f3a\u5bf9\u59ff\u6001\u4f30\u8ba1\u8bef\u5dee\u7684\u9c81\u68d2\u6027\uff0c\u63a8\u7406\u65f6\u7ed3\u5408\u76f8\u5bf9\u7a33\u5b9a\u7684VO\u6a21\u5757\u3002", "result": "\u5728FloNa\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u5bfc\u822a\u6027\u80fd\uff0c\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u9a8c\u8bc1\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "GlocDiff\u901a\u8fc7\u878d\u5408\u5168\u5c40\u5f15\u5bfc\u548c\u5c40\u90e8\u51e0\u4f55\u7ebf\u7d22\uff0c\u5b9e\u73b0\u4e86\u7cbe\u786e\u7684\u5bfc\u822a\u65b9\u5411\u9884\u6d4b\u548c\u9c81\u68d2\u7684\u969c\u788d\u7269\u89c4\u907f\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5b9e\u9645\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2511.01520", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01520", "abs": "https://arxiv.org/abs/2511.01520", "authors": ["Shipeng Lyu", "Lijie Sheng", "Fangyuan Wang", "Wenyao Zhang", "Weiwei Lin", "Zhenzhong Jia", "David Navarro-Alarcon", "Guodong Guo"], "title": "Phy-Tac: Toward Human-Like Grasping via Physics-Conditioned Tactile Goals", "comment": "9 papges, 10 figures, 3 tables", "summary": "Humans naturally grasp objects with minimal level required force for\nstability, whereas robots often rely on rigid, over-squeezing control. To\nnarrow this gap, we propose a human-inspired physics-conditioned tactile method\n(Phy-Tac) for force-optimal stable grasping (FOSG) that unifies pose selection,\ntactile prediction, and force regulation. A physics-based pose selector first\nidentifies feasible contact regions with optimal force distribution based on\nsurface geometry. Then, a physics-conditioned latent diffusion model (Phy-LDM)\npredicts the tactile imprint under FOSG target. Last, a latent-space LQR\ncontroller drives the gripper toward this tactile imprint with minimal\nactuation, preventing unnecessary compression. Trained on a physics-conditioned\ntactile dataset covering diverse objects and contact conditions, the proposed\nPhy-LDM achieves superior tactile prediction accuracy, while the Phy-Tac\noutperforms fixed-force and GraspNet-based baselines in grasp stability and\nforce efficiency. Experiments on classical robotic platforms demonstrate\nforce-efficient and adaptive manipulation that bridges the gap between robotic\nand human grasping.", "AI": {"tldr": "\u63d0\u51faPhy-Tac\u65b9\u6cd5\uff0c\u901a\u8fc7\u7269\u7406\u6761\u4ef6\u89e6\u89c9\u6280\u672f\u5b9e\u73b0\u529b\u6700\u4f18\u7a33\u5b9a\u6293\u53d6\uff0c\u7ed3\u5408\u59ff\u6001\u9009\u62e9\u3001\u89e6\u89c9\u9884\u6d4b\u548c\u529b\u8c03\u8282\uff0c\u4f7f\u673a\u5668\u4eba\u80fd\u50cf\u4eba\u7c7b\u4e00\u6837\u7528\u6700\u5c0f\u529b\u7a33\u5b9a\u6293\u53d6\u7269\u4f53\u3002", "motivation": "\u4eba\u7c7b\u80fd\u81ea\u7136\u4f7f\u7528\u6700\u5c0f\u5fc5\u8981\u529b\u7a33\u5b9a\u6293\u53d6\u7269\u4f53\uff0c\u800c\u673a\u5668\u4eba\u901a\u5e38\u4f9d\u8d56\u521a\u6027\u3001\u8fc7\u5ea6\u6324\u538b\u7684\u63a7\u5236\u65b9\u5f0f\uff0c\u9700\u8981\u7f29\u5c0f\u8fd9\u79cd\u5dee\u8ddd\u3002", "method": "1) \u57fa\u4e8e\u7269\u7406\u7684\u59ff\u6001\u9009\u62e9\u5668\u8bc6\u522b\u6700\u4f18\u529b\u5206\u5e03\u7684\u53ef\u884c\u63a5\u89e6\u533a\u57df\uff1b2) \u7269\u7406\u6761\u4ef6\u6f5c\u5728\u6269\u6563\u6a21\u578b\u9884\u6d4b\u76ee\u6807\u89e6\u89c9\u5370\u8bb0\uff1b3) \u6f5c\u5728\u7a7a\u95f4LQR\u63a7\u5236\u5668\u9a71\u52a8\u5939\u722a\u4ee5\u6700\u5c0f\u9a71\u52a8\u529b\u8fbe\u5230\u76ee\u6807\u89e6\u89c9\u5370\u8bb0\u3002", "result": "\u5728\u591a\u6837\u5316\u7269\u4f53\u548c\u63a5\u89e6\u6761\u4ef6\u4e0b\u8bad\u7ec3\u7684Phy-LDM\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u89e6\u89c9\u9884\u6d4b\u7cbe\u5ea6\uff0cPhy-Tac\u5728\u6293\u53d6\u7a33\u5b9a\u6027\u548c\u529b\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u56fa\u5b9a\u529b\u548cGraspNet\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u529b\u9ad8\u6548\u548c\u81ea\u9002\u5e94\u64cd\u4f5c\uff0c\u7f29\u5c0f\u4e86\u673a\u5668\u4eba\u4e0e\u4eba\u7c7b\u6293\u53d6\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2511.01594", "categories": ["cs.RO", "cs.CV", "I.2.9; I.2.11; I.2.6; I.4.8"], "pdf": "https://arxiv.org/pdf/2511.01594", "abs": "https://arxiv.org/abs/2511.01594", "authors": ["Renjun Gao", "Peiyan Zhong"], "title": "MARS: Multi-Agent Robotic System with Multimodal Large Language Models for Assistive Intelligence", "comment": "3 figures, 1 table; under review at Multimedia Systems (Springer)", "summary": "Multimodal large language models (MLLMs) have shown remarkable capabilities\nin cross-modal understanding and reasoning, offering new opportunities for\nintelligent assistive systems, yet existing systems still struggle with\nrisk-aware planning, user personalization, and grounding language plans into\nexecutable skills in cluttered homes. We introduce MARS - a Multi-Agent Robotic\nSystem powered by MLLMs for assistive intelligence and designed for smart home\nrobots supporting people with disabilities. The system integrates four agents:\na visual perception agent for extracting semantic and spatial features from\nenvironment images, a risk assessment agent for identifying and prioritizing\nhazards, a planning agent for generating executable action sequences, and an\nevaluation agent for iterative optimization. By combining multimodal perception\nwith hierarchical multi-agent decision-making, the framework enables adaptive,\nrisk-aware, and personalized assistance in dynamic indoor environments.\nExperiments on multiple datasets demonstrate the superior overall performance\nof the proposed system in risk-aware planning and coordinated multi-agent\nexecution compared with state-of-the-art multimodal models. The proposed\napproach also highlights the potential of collaborative AI for practical\nassistive scenarios and provides a generalizable methodology for deploying\nMLLM-enabled multi-agent systems in real-world environments.", "AI": {"tldr": "MARS\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u4e13\u4e3a\u667a\u80fd\u5bb6\u5c45\u673a\u5668\u4eba\u8bbe\u8ba1\uff0c\u4e3a\u6b8b\u969c\u4eba\u58eb\u63d0\u4f9b\u98ce\u9669\u611f\u77e5\u3001\u4e2a\u6027\u5316\u7684\u8f85\u52a9\u670d\u52a1\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edf\u5728\u98ce\u9669\u611f\u77e5\u89c4\u5212\u3001\u7528\u6237\u4e2a\u6027\u5316\u4ee5\u53ca\u5c06\u8bed\u8a00\u8ba1\u5212\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u6280\u80fd\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u7279\u522b\u662f\u5728\u6742\u4e71\u7684\u5bb6\u5ead\u73af\u5883\u4e2d\u3002", "method": "\u7cfb\u7edf\u96c6\u6210\u56db\u4e2a\u667a\u80fd\u4f53\uff1a\u89c6\u89c9\u611f\u77e5\u667a\u80fd\u4f53\u63d0\u53d6\u73af\u5883\u8bed\u4e49\u548c\u7a7a\u95f4\u7279\u5f81\uff0c\u98ce\u9669\u8bc4\u4f30\u667a\u80fd\u4f53\u8bc6\u522b\u548c\u4f18\u5148\u5904\u7406\u5371\u9669\uff0c\u89c4\u5212\u667a\u80fd\u4f53\u751f\u6210\u53ef\u6267\u884c\u52a8\u4f5c\u5e8f\u5217\uff0c\u8bc4\u4f30\u667a\u80fd\u4f53\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u5728\u98ce\u9669\u611f\u77e5\u89c4\u5212\u548c\u534f\u8c03\u591a\u667a\u80fd\u4f53\u6267\u884c\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u591a\u6a21\u6001\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u534f\u4f5cAI\u5728\u5b9e\u9645\u8f85\u52a9\u573a\u666f\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u4e3a\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u90e8\u7f72\u57fa\u4e8eMLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u63a8\u5e7f\u7684\u65b9\u6cd5\u8bba\u3002"}}
{"id": "2511.01718", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01718", "abs": "https://arxiv.org/abs/2511.01718", "authors": ["Jiayi Chen", "Wenxuan Song", "Pengxiang Ding", "Ziyang Zhou", "Han Zhao", "Feilong Tang", "Donglin Wang", "Haoang Li"], "title": "Unified Diffusion VLA: Vision-Language-Action Model via Joint Discrete Denoising Diffusion Process", "comment": null, "summary": "Vision-language-action (VLA) models aim to understand natural language\ninstructions and visual observations and to execute corresponding actions as an\nembodied agent. Recent work integrates future images into the\nunderstanding-acting loop, yielding unified VLAs that jointly understand,\ngenerate, and act -- reading text and images and producing future images and\nactions. However, these models either rely on external experts for modality\nunification or treat image generation and action prediction as separate\nprocesses, limiting the benefits of direct synergy between these tasks. Our\ncore philosophy is to optimize generation and action jointly through a\nsynchronous denoising process, where the iterative refinement enables actions\nto evolve from initialization, under constant and sufficient visual guidance.\nWe ground this philosophy in our proposed Unified Diffusion VLA and Joint\nDiscrete Denoising Diffusion Process (JD3P), which is a joint diffusion process\nthat integrates multiple modalities into a single denoising trajectory to serve\nas the key mechanism enabling understanding, generation, and acting to be\nintrinsically synergistic. Our model and theory are built on a unified\ntokenized space of all modalities and a hybrid attention mechanism. We further\npropose a two-stage training pipeline and several inference-time techniques\nthat optimize performance and efficiency. Our approach achieves\nstate-of-the-art performance on benchmarks such as CALVIN, LIBERO, and\nSimplerEnv with 4$\\times$ faster inference than autoregressive methods, and we\ndemonstrate its effectiveness through in-depth analysis and real-world\nevaluations. Our project page is available at\nhttps://irpn-eai.github.io/UD-VLA.github.io/.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u6269\u6563\u89c6\u89c9\u8bed\u8a00\u52a8\u4f5c\u6a21\u578b\uff0c\u901a\u8fc7\u8054\u5408\u53bb\u566a\u8fc7\u7a0b\u540c\u6b65\u4f18\u5316\u56fe\u50cf\u751f\u6210\u548c\u52a8\u4f5c\u9884\u6d4b\uff0c\u5b9e\u73b0\u7406\u89e3\u3001\u751f\u6210\u548c\u884c\u52a8\u7684\u5185\u5728\u534f\u540c\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u52a8\u4f5c\u6a21\u578b\u8981\u4e48\u4f9d\u8d56\u5916\u90e8\u4e13\u5bb6\u8fdb\u884c\u6a21\u6001\u7edf\u4e00\uff0c\u8981\u4e48\u5c06\u56fe\u50cf\u751f\u6210\u548c\u52a8\u4f5c\u9884\u6d4b\u4f5c\u4e3a\u72ec\u7acb\u8fc7\u7a0b\u5904\u7406\uff0c\u9650\u5236\u4e86\u8fd9\u4e9b\u4efb\u52a1\u4e4b\u95f4\u7684\u76f4\u63a5\u534f\u540c\u6548\u76ca\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u6269\u6563VLA\u548c\u8054\u5408\u79bb\u6563\u53bb\u566a\u6269\u6563\u8fc7\u7a0b\uff0c\u901a\u8fc7\u5355\u4e00\u53bb\u566a\u8f68\u8ff9\u6574\u5408\u591a\u6a21\u6001\uff0c\u4f7f\u7528\u7edf\u4e00\u6807\u8bb0\u7a7a\u95f4\u548c\u6df7\u5408\u6ce8\u610f\u529b\u673a\u5236\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\u548c\u63a8\u7406\u65f6\u4f18\u5316\u6280\u672f\u3002", "result": "\u5728CALVIN\u3001LIBERO\u548cSimplerEnv\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u63a8\u7406\u901f\u5ea6\u6bd4\u81ea\u56de\u5f52\u65b9\u6cd5\u5feb4\u500d\uff0c\u5e76\u901a\u8fc7\u6df1\u5165\u5206\u6790\u548c\u771f\u5b9e\u4e16\u754c\u8bc4\u4f30\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u8054\u5408\u53bb\u566a\u8fc7\u7a0b\u540c\u6b65\u4f18\u5316\u751f\u6210\u548c\u52a8\u4f5c\uff0c\u5b9e\u73b0\u4e86\u7406\u89e3\u3001\u751f\u6210\u548c\u884c\u52a8\u7684\u5185\u5728\u534f\u540c\uff0c\u4e3a\u89c6\u89c9\u8bed\u8a00\u52a8\u4f5c\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u7edf\u4e00\u6846\u67b6\u3002"}}
{"id": "2511.01770", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01770", "abs": "https://arxiv.org/abs/2511.01770", "authors": ["Liudi Yang", "Yang Bai", "Yuhao Wang", "Ibrahim Alsarraj", "Gitta Kutyniok", "Zhanchi Wang", "Ke Wu"], "title": "Lightweight Learning from Actuation-Space Demonstrations via Flow Matching for Whole-Body Soft Robotic Grasping", "comment": null, "summary": "Robotic grasping under uncertainty remains a fundamental challenge due to its\nuncertain and contact-rich nature. Traditional rigid robotic hands, with\nlimited degrees of freedom and compliance, rely on complex model-based and\nheavy feedback controllers to manage such interactions. Soft robots, by\ncontrast, exhibit embodied mechanical intelligence: their underactuated\nstructures and passive flexibility of their whole body, naturally accommodate\nuncertain contacts and enable adaptive behaviors. To harness this capability,\nwe propose a lightweight actuation-space learning framework that infers\ndistributional control representations for whole-body soft robotic grasping,\ndirectly from deterministic demonstrations using a flow matching model\n(Rectified Flow),without requiring dense sensing or heavy control loops. Using\nonly 30 demonstrations (less than 8% of the reachable workspace), the learned\npolicy achieves a 97.5% grasp success rate across the whole workspace,\ngeneralizes to grasped-object size variations of +-33%, and maintains stable\nperformance when the robot's dynamic response is directly adjusted by scaling\nthe execution time from 20% to 200%. These results demonstrate that\nactuation-space learning, by leveraging its passive redundant DOFs and\nflexibility, converts the body's mechanics into functional control intelligence\nand substantially reduces the burden on central controllers for this\nuncertain-rich task.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d41\u5339\u914d\u6a21\u578b\u7684\u8f7b\u91cf\u7ea7\u9a71\u52a8\u7a7a\u95f4\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u8f6f\u4f53\u673a\u5668\u4eba\u6293\u53d6\uff0c\u4ec5\u9700\u5c11\u91cf\u6f14\u793a\u5373\u53ef\u5b9e\u73b0\u9ad8\u6210\u529f\u7387\u6293\u53d6\uff0c\u5e76\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u521a\u6027\u673a\u5668\u4eba\u624b\u5728\u4e0d\u786e\u5b9a\u548c\u63a5\u89e6\u4e30\u5bcc\u7684\u6293\u53d6\u4efb\u52a1\u4e2d\u4f9d\u8d56\u590d\u6742\u7684\u6a21\u578b\u548c\u53cd\u9988\u63a7\u5236\uff0c\u800c\u8f6f\u4f53\u673a\u5668\u4eba\u5177\u6709\u673a\u68b0\u667a\u80fd\u7279\u6027\uff0c\u80fd\u591f\u81ea\u7136\u9002\u5e94\u4e0d\u786e\u5b9a\u63a5\u89e6\u3002", "method": "\u4f7f\u7528\u6d41\u5339\u914d\u6a21\u578b\u4ece\u786e\u5b9a\u6027\u6f14\u793a\u4e2d\u5b66\u4e60\u5206\u5e03\u63a7\u5236\u8868\u793a\uff0c\u65e0\u9700\u5bc6\u96c6\u4f20\u611f\u6216\u590d\u6742\u63a7\u5236\u56de\u8def\uff0c\u4ec5\u970030\u4e2a\u6f14\u793a\u6837\u672c\u3002", "result": "\u5b66\u4e60\u7b56\u7565\u5728\u6574\u4e2a\u5de5\u4f5c\u7a7a\u95f4\u5185\u8fbe\u523097.5%\u7684\u6293\u53d6\u6210\u529f\u7387\uff0c\u5bf9\u6293\u53d6\u7269\u4f53\u5c3a\u5bf8\u53d8\u5316\u00b133%\u5177\u6709\u6cdb\u5316\u80fd\u529b\uff0c\u4e14\u572820%-200%\u6267\u884c\u65f6\u95f4\u8303\u56f4\u5185\u4fdd\u6301\u7a33\u5b9a\u6027\u80fd\u3002", "conclusion": "\u9a71\u52a8\u7a7a\u95f4\u5b66\u4e60\u901a\u8fc7\u5229\u7528\u8f6f\u4f53\u673a\u5668\u4eba\u7684\u88ab\u52a8\u5197\u4f59\u81ea\u7531\u5ea6\u548c\u7075\u6d3b\u6027\uff0c\u5c06\u673a\u68b0\u7279\u6027\u8f6c\u5316\u4e3a\u529f\u80fd\u63a7\u5236\u667a\u80fd\uff0c\u663e\u8457\u51cf\u8f7b\u4e86\u4e2d\u592e\u63a7\u5236\u5668\u7684\u8d1f\u62c5\u3002"}}
{"id": "2511.01791", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01791", "abs": "https://arxiv.org/abs/2511.01791", "authors": ["Feng Chen", "Zhuxiu Xu", "Tianzhe Chu", "Xunzhe Zhou", "Li Sun", "Zewen Wu", "Shenghua Gao", "Zhongyu Li", "Yanchao Yang", "Yi Ma"], "title": "GenDexHand: Generative Simulation for Dexterous Hands", "comment": null, "summary": "Data scarcity remains a fundamental bottleneck for embodied intelligence.\nExisting approaches use large language models (LLMs) to automate gripper-based\nsimulation generation, but they transfer poorly to dexterous manipulation,\nwhich demands more specialized environment design. Meanwhile, dexterous\nmanipulation tasks are inherently more difficult due to their higher degrees of\nfreedom. Massively generating feasible and trainable dexterous hand tasks\nremains an open challenge. To this end, we present GenDexHand, a generative\nsimulation pipeline that autonomously produces diverse robotic tasks and\nenvironments for dexterous manipulation. GenDexHand introduces a closed-loop\nrefinement process that adjusts object placements and scales based on\nvision-language model (VLM) feedback, substantially improving the average\nquality of generated environments. Each task is further decomposed into\nsub-tasks to enable sequential reinforcement learning, reducing training time\nand increasing success rates. Our work provides a viable path toward scalable\ntraining of diverse dexterous hand behaviors in embodied intelligence by\noffering a simulation-based solution to synthetic data generation. Our website:\nhttps://winniechen2002.github.io/GenDexHand/.", "AI": {"tldr": "GenDexHand\u662f\u4e00\u4e2a\u751f\u6210\u5f0f\u4eff\u771f\u6d41\u6c34\u7ebf\uff0c\u80fd\u591f\u81ea\u4e3b\u751f\u6210\u591a\u6837\u5316\u7684\u7075\u5de7\u624b\u64cd\u4f5c\u4efb\u52a1\u548c\u73af\u5883\uff0c\u901a\u8fc7\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u53cd\u9988\u7684\u95ed\u73af\u4f18\u5316\u8fc7\u7a0b\u63d0\u9ad8\u73af\u5883\u8d28\u91cf\uff0c\u5e76\u901a\u8fc7\u4efb\u52a1\u5206\u89e3\u5b9e\u73b0\u5e8f\u5217\u5f3a\u5316\u5b66\u4e60\u3002", "motivation": "\u89e3\u51b3\u7075\u5de7\u64cd\u4f5c\u4e2d\u6570\u636e\u7a00\u7f3a\u7684\u6839\u672c\u74f6\u9888\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u7075\u5de7\u64cd\u4f5c\u4e2d\u8fc1\u79fb\u6548\u679c\u5dee\uff0c\u9700\u8981\u66f4\u4e13\u4e1a\u7684\u73af\u5883\u8bbe\u8ba1\uff0c\u4e14\u7075\u5de7\u64cd\u4f5c\u4efb\u52a1\u56e0\u5176\u66f4\u9ad8\u7684\u81ea\u7531\u5ea6\u800c\u66f4\u52a0\u56f0\u96be\u3002", "method": "\u5f15\u5165\u95ed\u73af\u4f18\u5316\u8fc7\u7a0b\uff0c\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u53cd\u9988\u8c03\u6574\u7269\u4f53\u4f4d\u7f6e\u548c\u5c3a\u5bf8\uff1b\u5c06\u4efb\u52a1\u5206\u89e3\u4e3a\u5b50\u4efb\u52a1\u4ee5\u5b9e\u73b0\u5e8f\u5217\u5f3a\u5316\u5b66\u4e60\uff1b\u63d0\u4f9b\u751f\u6210\u5f0f\u4eff\u771f\u6d41\u6c34\u7ebf\u3002", "result": "\u663e\u8457\u63d0\u9ad8\u4e86\u751f\u6210\u73af\u5883\u7684\u5e73\u5747\u8d28\u91cf\uff1b\u51cf\u5c11\u4e86\u8bad\u7ec3\u65f6\u95f4\u5e76\u63d0\u9ad8\u4e86\u6210\u529f\u7387\u3002", "conclusion": "\u4e3a\u5177\u8eab\u667a\u80fd\u4e2d\u591a\u6837\u5316\u7075\u5de7\u624b\u884c\u4e3a\u7684\u53ef\u6269\u5c55\u8bad\u7ec3\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\uff0c\u901a\u8fc7\u57fa\u4e8e\u4eff\u771f\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01797", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01797", "abs": "https://arxiv.org/abs/2511.01797", "authors": ["Javier Ballesteros-Jerez", "Jesus Mart\u00ednez-G\u00f3mez", "Ismael Garc\u00eda-Varea", "Luis Orozco-Barbosa", "Manuel Castillo-Cara"], "title": "Hybrid Neural Network-Based Indoor Localisation System for Mobile Robots Using CSI Data in a Robotics Simulator", "comment": "13 pages, 7 figures. Conference paper (ROBOVIS 2025)", "summary": "We present a hybrid neural network model for inferring the position of mobile\nrobots using Channel State Information (CSI) data from a Massive MIMO system.\nBy leveraging an existing CSI dataset, our approach integrates a Convolutional\nNeural Network (CNN) with a Multilayer Perceptron (MLP) to form a Hybrid Neural\nNetwork (HyNN) that estimates 2D robot positions. CSI readings are converted\ninto synthetic images using the TINTO tool. The localisation solution is\nintegrated with a robotics simulator, and the Robot Operating System (ROS),\nwhich facilitates its evaluation through heterogeneous test cases, and the\nadoption of state estimators like Kalman filters. Our contributions illustrate\nthe potential of our HyNN model in achieving precise indoor localisation and\nnavigation for mobile robots in complex environments. The study follows, and\nproposes, a generalisable procedure applicable beyond the specific use case\nstudied, making it adaptable to different scenarios and datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u795e\u7ecf\u7f51\u7edc(HyNN)\u7684\u79fb\u52a8\u673a\u5668\u4eba\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u7684CSI\u6570\u636e\uff0c\u901a\u8fc7CNN\u548cMLP\u7ed3\u5408\u4f30\u8ba12D\u673a\u5668\u4eba\u4f4d\u7f6e\u3002", "motivation": "\u89e3\u51b3\u590d\u6742\u73af\u5883\u4e2d\u79fb\u52a8\u673a\u5668\u4eba\u7684\u7cbe\u786e\u5ba4\u5185\u5b9a\u4f4d\u548c\u5bfc\u822a\u95ee\u9898\uff0c\u5229\u7528\u73b0\u6709CSI\u6570\u636e\u96c6\u5f00\u53d1\u901a\u7528\u6027\u5f3a\u7684\u5b9a\u4f4d\u65b9\u6848\u3002", "method": "\u4f7f\u7528TINTO\u5de5\u5177\u5c06CSI\u8bfb\u6570\u8f6c\u6362\u4e3a\u5408\u6210\u56fe\u50cf\uff0c\u6784\u5efaCNN\u4e0eMLP\u7ed3\u5408\u7684\u6df7\u5408\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u5e76\u4e0e\u673a\u5668\u4eba\u4eff\u771f\u5668\u548cROS\u7cfb\u7edf\u96c6\u6210\u3002", "result": "\u5b9e\u73b0\u4e86\u79fb\u52a8\u673a\u5668\u4eba\u7684\u7cbe\u786e\u5ba4\u5185\u5b9a\u4f4d\uff0c\u6a21\u578b\u5728\u590d\u6742\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u5b9a\u4f4d\u6027\u80fd\u3002", "conclusion": "HyNN\u6a21\u578b\u5728\u5ba4\u5185\u5b9a\u4f4d\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u63d0\u51fa\u7684\u901a\u7528\u5316\u6d41\u7a0b\u53ef\u9002\u5e94\u4e0d\u540c\u573a\u666f\u548c\u6570\u636e\u96c6\u3002"}}
