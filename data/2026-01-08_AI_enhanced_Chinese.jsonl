{"id": "2601.03552", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2601.03552", "abs": "https://arxiv.org/abs/2601.03552", "authors": ["Lujia Bo", "Mingxuan Chen", "Youduo Chen", "Xiaofan Gui", "Jiang Bian", "Chunyan Wang", "Yi Liu"], "title": "From Risk Perception to Behavior Large Language Models-Based Simulation of Pandemic Prevention Behaviors", "comment": null, "summary": "Individual prevention behaviors are a primary line of defense during the early stages of novel infectious disease outbreaks, yet their adoption is heterogeneous and difficult to forecast-especially when empirical data are scarce and epidemic-policy contexts evolve rapidly. To address this gap, we develop an LLM-based prevention-behavior simulation framework that couples (i) a static module for behavior-intensity prediction under a specified external context and (ii) a dynamic module that updates residents' perceived risk over time and propagates these updates into behavior evolution. The model is implemented via structured prompt engineering in a first-person perspective and is evaluated against two rounds of survey data from Beijing residents (R1: December 2020; R2: August 2021) under progressively realistic data-availability settings: zero-shot, few-shot, and cross-context transfer. Using Kolmogorov-Smirnov tests to compare simulated and observed behavior distributions (p > 0.001 as the validity criterion), the framework demonstrates robust performance and improves with limited reference examples; reported predictive accuracy increases from 72.7% (zero-shot) to 81.8% (few-shot), and remains high at 77.8% under transfer to novel contexts. We further apply the framework to simulate behavior changes during China's December 2022 policy relaxation and to stress-test behavioral responses across 120 systematically varied epidemic conditions (R0, CFR, and control-measure tiers). Results indicate broad behavioral loosening under relaxation but a distinctive counter-trend increase in drain-related disinfection, highlighting how low-cost, low-friction behaviors may persist or intensify even when external constraints recede-raising a potential environmental tradeoff.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u9884\u9632\u884c\u4e3a\u6a21\u62df\u6846\u67b6\uff0c\u901a\u8fc7\u9759\u6001\u6a21\u5757\u9884\u6d4b\u884c\u4e3a\u5f3a\u5ea6\uff0c\u52a8\u6001\u6a21\u5757\u66f4\u65b0\u98ce\u9669\u611f\u77e5\uff0c\u5728\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u548c\u8de8\u60c5\u5883\u8fc1\u79fb\u8bbe\u7f6e\u4e0b\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\uff0c\u5e76\u5e94\u7528\u4e8e\u653f\u7b56\u653e\u677e\u60c5\u666f\u6a21\u62df\u3002", "motivation": "\u5728\u65b0\u578b\u4f20\u67d3\u75c5\u7206\u53d1\u521d\u671f\uff0c\u4e2a\u4f53\u9884\u9632\u884c\u4e3a\u662f\u4e3b\u8981\u9632\u7ebf\uff0c\u4f46\u5176\u91c7\u7eb3\u5b58\u5728\u5f02\u8d28\u6027\u4e14\u96be\u4ee5\u9884\u6d4b\uff0c\u5c24\u5176\u662f\u5728\u7ecf\u9a8c\u6570\u636e\u7a00\u7f3a\u3001\u6d41\u884c\u75c5\u653f\u7b56\u73af\u5883\u5feb\u901f\u6f14\u53d8\u7684\u60c5\u51b5\u4e0b\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u51c6\u786e\u9884\u6d4b\u884c\u4e3a\u53d8\u5316\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8eLLM\u7684\u9884\u9632\u884c\u4e3a\u6a21\u62df\u6846\u67b6\uff0c\u5305\u542b\uff1a(1)\u9759\u6001\u6a21\u5757\uff1a\u5728\u6307\u5b9a\u5916\u90e8\u60c5\u5883\u4e0b\u9884\u6d4b\u884c\u4e3a\u5f3a\u5ea6\uff1b(2)\u52a8\u6001\u6a21\u5757\uff1a\u968f\u65f6\u95f4\u66f4\u65b0\u5c45\u6c11\u611f\u77e5\u98ce\u9669\u5e76\u4f20\u64ad\u5230\u884c\u4e3a\u6f14\u5316\u3002\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\u5de5\u7a0b\u4ee5\u7b2c\u4e00\u4eba\u79f0\u89c6\u89d2\u5b9e\u73b0\uff0c\u4f7f\u7528\u5317\u4eac\u5c45\u6c11\u4e24\u8f6e\u8c03\u67e5\u6570\u636e\uff082020\u5e7412\u6708\u548c2021\u5e748\u6708\uff09\u5728\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u548c\u8de8\u60c5\u5883\u8fc1\u79fb\u8bbe\u7f6e\u4e0b\u8bc4\u4f30\u3002", "result": "\u4f7f\u7528Kolmogorov-Smirnov\u68c0\u9a8c\u6bd4\u8f83\u6a21\u62df\u4e0e\u89c2\u5bdf\u884c\u4e3a\u5206\u5e03\uff08p>0.001\u4e3a\u6709\u6548\u6027\u6807\u51c6\uff09\uff0c\u6846\u67b6\u8868\u73b0\u51fa\u7a33\u5065\u6027\u80fd\u4e14\u968f\u53c2\u8003\u793a\u4f8b\u589e\u52a0\u800c\u6539\u8fdb\uff1a\u9884\u6d4b\u51c6\u786e\u7387\u4ece\u96f6\u6837\u672c\u768472.7%\u63d0\u9ad8\u5230\u5c11\u6837\u672c\u768481.8%\uff0c\u8de8\u60c5\u5883\u8fc1\u79fb\u4e0b\u4ecd\u4fdd\u630177.8%\u7684\u9ad8\u6c34\u5e73\u3002\u5e94\u7528\u4e8e\u4e2d\u56fd2022\u5e7412\u6708\u653f\u7b56\u653e\u677e\u60c5\u666f\u6a21\u62df\u548c120\u79cd\u7cfb\u7edf\u53d8\u5316\u6d41\u884c\u75c5\u6761\u4ef6\u538b\u529b\u6d4b\u8bd5\uff0c\u7ed3\u679c\u663e\u793a\u653f\u7b56\u653e\u677e\u4e0b\u884c\u4e3a\u666e\u904d\u5bbd\u677e\uff0c\u4f46\u6392\u6c34\u76f8\u5173\u6d88\u6bd2\u884c\u4e3a\u51fa\u73b0\u53cd\u8d8b\u52bf\u589e\u52a0\u3002", "conclusion": "LLM-based\u9884\u9632\u884c\u4e3a\u6a21\u62df\u6846\u67b6\u80fd\u6709\u6548\u9884\u6d4b\u4f20\u67d3\u75c5\u9632\u63a7\u4e2d\u7684\u4e2a\u4f53\u884c\u4e3a\u53d8\u5316\uff0c\u5373\u4f7f\u5728\u6570\u636e\u7a00\u7f3a\u548c\u60c5\u5883\u5feb\u901f\u6f14\u53d8\u4e0b\u4e5f\u8868\u73b0\u826f\u597d\u3002\u7814\u7a76\u53d1\u73b0\u4f4e\u6210\u672c\u3001\u4f4e\u6469\u64e6\u884c\u4e3a\u5728\u5916\u90e8\u7ea6\u675f\u51cf\u5f31\u65f6\u53ef\u80fd\u6301\u7eed\u6216\u5f3a\u5316\uff0c\u63ed\u793a\u4e86\u6f5c\u5728\u7684\u73af\u5883\u6743\u8861\u3002"}}
{"id": "2601.03859", "categories": ["cs.SI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.03859", "abs": "https://arxiv.org/abs/2601.03859", "authors": ["Stanis\u0142aw St\u0119pie\u0144", "Michalina Janik", "Mateusz Nurek", "Akrati Saxena", "Rados\u0142aw Michalski"], "title": "Fairness in Opinion Dynamics", "comment": null, "summary": "Ways in which people's opinions change are, without a doubt, subject to a rich tapestry of differing influences. Factors that affect how one arrives at an opinion reflect how they have been shaped by their environment throughout their lives, education, material status, what belief systems are they subscribed to, and what socio-economic minorities are they a part of. This already complex system is further expanded by the ever-changing nature of one's social network. It is therefore no surprise that many models have a tendency to perform best for the majority of the population and discriminating those people who are members of various marginalized groups . This bias and the study of how to counter it are subject to a rapidly developing field of Fairness in Social Network Analysis (SNA). The focus of this work is to look into how a state-of-the-art model discriminates certain minority groups and whether it is possible to reliably predict for whom it will perform worse. Moreover, is such prediction possible based solely on one's demographic or topological features? To this end, the NetSense dataset, together with a state-of-the-art CoDiNG model for opinion prediction have been employed. Our work explores how three classifier models (Demography-Based, Topology-Based, and Hybrid) perform when assessing for whom this algorithm will provide inaccurate predictions. Finally, through a comprehensive analysis of these experimental results, we identify four key patterns of algorithmic bias. Our findings suggest that no single paradigm provides the best results and that there is a real need for context-aware strategies in fairness-oriented social network analysis. We conclude that a multi-faceted approach, incorporating both individual attributes and network structures, is essential for reducing algorithmic bias and promoting inclusive decision-making.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u793e\u4f1a\u7f51\u7edc\u5206\u6790\u4e2d\u610f\u89c1\u9884\u6d4b\u6a21\u578b\u7684\u7b97\u6cd5\u504f\u89c1\u95ee\u9898\uff0c\u7279\u522b\u662f\u9488\u5bf9\u8fb9\u7f18\u5316\u7fa4\u4f53\u7684\u6b67\u89c6\u73b0\u8c61\uff0c\u5e76\u6d4b\u8bd5\u4e86\u57fa\u4e8e\u4eba\u53e3\u7edf\u8ba1\u3001\u62d3\u6251\u7ed3\u6784\u548c\u6df7\u5408\u7279\u5f81\u7684\u5206\u7c7b\u5668\u6765\u9884\u6d4b\u6a21\u578b\u6027\u80fd\u5dee\u5f02\u3002", "motivation": "\u793e\u4f1a\u7f51\u7edc\u5206\u6790\u4e2d\u7684\u610f\u89c1\u9884\u6d4b\u6a21\u578b\u5f80\u5f80\u5bf9\u591a\u6570\u7fa4\u4f53\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5bf9\u8fb9\u7f18\u5316\u7fa4\u4f53\u5b58\u5728\u6b67\u89c6\u3002\u73b0\u6709\u516c\u5e73\u6027\u7814\u7a76\u9700\u8981\u63a2\u7d22\u5982\u4f55\u8bc6\u522b\u6a21\u578b\u5bf9\u54ea\u4e9b\u4eba\u7fa4\u8868\u73b0\u4e0d\u4f73\uff0c\u4ee5\u53ca\u4ec5\u57fa\u4e8e\u4eba\u53e3\u7edf\u8ba1\u6216\u62d3\u6251\u7279\u5f81\u80fd\u5426\u53ef\u9760\u9884\u6d4b\u8fd9\u79cd\u6027\u80fd\u5dee\u5f02\u3002", "method": "\u4f7f\u7528NetSense\u6570\u636e\u96c6\u548c\u5148\u8fdb\u7684CoDiNG\u610f\u89c1\u9884\u6d4b\u6a21\u578b\uff0c\u6784\u5efa\u4e09\u79cd\u5206\u7c7b\u5668\uff1a\u57fa\u4e8e\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u3001\u57fa\u4e8e\u62d3\u6251\u7279\u5f81\u3001\u4ee5\u53ca\u6df7\u5408\u7279\u5f81\u5206\u7c7b\u5668\uff0c\u7528\u4e8e\u9884\u6d4b\u6a21\u578b\u5bf9\u54ea\u4e9b\u7528\u6237\u4f1a\u4ea7\u751f\u4e0d\u51c6\u786e\u7684\u9884\u6d4b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6ca1\u6709\u5355\u4e00\u8303\u5f0f\u80fd\u63d0\u4f9b\u6700\u4f73\u7ed3\u679c\uff0c\u9700\u8981\u60c5\u5883\u611f\u77e5\u7b56\u7565\u3002\u901a\u8fc7\u7efc\u5408\u5206\u6790\u8bc6\u522b\u51fa\u56db\u79cd\u5173\u952e\u7684\u7b97\u6cd5\u504f\u89c1\u6a21\u5f0f\uff0c\u8868\u660e\u9700\u8981\u7ed3\u5408\u4e2a\u4f53\u5c5e\u6027\u548c\u7f51\u7edc\u7ed3\u6784\u7684\u591a\u65b9\u9762\u65b9\u6cd5\u3002", "conclusion": "\u51cf\u5c11\u7b97\u6cd5\u504f\u89c1\u548c\u4fc3\u8fdb\u5305\u5bb9\u6027\u51b3\u7b56\u9700\u8981\u91c7\u7528\u591a\u65b9\u9762\u7684\u7efc\u5408\u65b9\u6cd5\uff0c\u540c\u65f6\u8003\u8651\u4e2a\u4f53\u5c5e\u6027\u548c\u7f51\u7edc\u7ed3\u6784\u7279\u5f81\uff0c\u5728\u516c\u5e73\u5bfc\u5411\u7684\u793e\u4f1a\u7f51\u7edc\u5206\u6790\u4e2d\u5b9e\u65bd\u60c5\u5883\u611f\u77e5\u7b56\u7565\u3002"}}
{"id": "2601.04134", "categories": ["cs.SI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.04134", "abs": "https://arxiv.org/abs/2601.04134", "authors": ["Eaman Jahani", "Blas Kolic", "Manuel Tonneau", "Hause Lin", "Daniel Barkoczi", "Edwin Ikhuoria", "Victor Orozco", "Samuel Fraiberger"], "title": "Celebrity messages reduce online hate and limit its spread", "comment": "16 pages, 5 figures", "summary": "Online hate spreads rapidly, yet little is known about whether preventive and scalable strategies can curb it. We conducted the largest randomized controlled trial of hate speech prevention to date: a 20-week messaging campaign on X in Nigeria targeting ethnic hate. 73,136 users who had previously engaged with hate speech were randomly assigned to receive prosocial video messages from Nigerian celebrities. The campaign reduced hate content by 2.5% to 5.5% during treatment, with about 75% of the reduction persisting over the following four months. Reaching a larger share of a user's audience reduced amplification of that user's hate posts among both treated and untreated users, cutting hate reposts by over 50% for the most exposed accounts. Scalable messaging can limit online hate without removing content.", "AI": {"tldr": "\u5728\u5c3c\u65e5\u5229\u4e9a\u9488\u5bf9\u79cd\u65cf\u4ec7\u6068\u8a00\u8bba\u7684\u5927\u89c4\u6a21\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u663e\u793a\uff0c\u901a\u8fc7\u540d\u4eba\u53d1\u9001\u7684\u4eb2\u793e\u4f1a\u89c6\u9891\u4fe1\u606f\u80fd\u5c06\u4ec7\u6068\u5185\u5bb9\u51cf\u5c112.5%-5.5%\uff0c\u4e1475%\u7684\u6548\u679c\u80fd\u6301\u7eed4\u4e2a\u6708", "motivation": "\u5728\u7ebf\u4ec7\u6068\u8a00\u8bba\u4f20\u64ad\u8fc5\u901f\uff0c\u4f46\u7f3a\u4e4f\u5173\u4e8e\u9884\u9632\u6027\u548c\u53ef\u6269\u5c55\u7b56\u7565\u6709\u6548\u6027\u7684\u5b9e\u8bc1\u7814\u7a76\u3002\u7814\u7a76\u8005\u5e0c\u671b\u4e86\u89e3\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u975e\u5185\u5bb9\u5220\u9664\u7684\u65b9\u5f0f\u6709\u6548\u904f\u5236\u4ec7\u6068\u8a00\u8bba\u4f20\u64ad", "method": "\u5728\u5c3c\u65e5\u5229\u4e9aX\u5e73\u53f0\u8fdb\u884c\u4e3a\u671f20\u5468\u7684\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\uff0c\u9488\u5bf973,136\u540d\u66fe\u53c2\u4e0e\u4ec7\u6068\u8a00\u8bba\u7684\u7528\u6237\uff0c\u968f\u673a\u5206\u914d\u63a5\u6536\u5c3c\u65e5\u5229\u4e9a\u540d\u4eba\u53d1\u9001\u7684\u4eb2\u793e\u4f1a\u89c6\u9891\u4fe1\u606f", "result": "\u5e72\u9884\u671f\u95f4\u4ec7\u6068\u5185\u5bb9\u51cf\u5c112.5%-5.5%\uff0c\u7ea675%\u7684\u51cf\u5c11\u6548\u679c\u5728\u540e\u7eed4\u4e2a\u6708\u6301\u7eed\uff1b\u5f53\u4fe1\u606f\u8986\u76d6\u7528\u6237\u66f4\u591a\u53d7\u4f17\u65f6\uff0c\u4ec7\u6068\u8f6c\u53d1\u51cf\u5c11\u8d85\u8fc750%", "conclusion": "\u53ef\u6269\u5c55\u7684\u4fe1\u606f\u4f20\u9012\u7b56\u7565\u80fd\u591f\u5728\u4e0d\u5220\u9664\u5185\u5bb9\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u9650\u5236\u5728\u7ebf\u4ec7\u6068\u8a00\u8bba\u4f20\u64ad\uff0c\u4e3a\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u5e72\u9884\u65b9\u6848"}}
{"id": "2601.03428", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2601.03428", "abs": "https://arxiv.org/abs/2601.03428", "authors": ["Patrik Guggenberger", "Nihal Mehta", "Nikita Pavlov"], "title": "Minimax regret treatment rules with finite samples when a quantile is the object of interest", "comment": null, "summary": "Consider a setup in which a decision maker is informed about the population by a finite sample and based on that sample has to decide whether or not to apply a certain treatment. We work out finite sample minimax regret treatment rules under various sampling schemes when outcomes are restricted onto the unit interval. In contrast to Stoye (2009) where the focus is on maximization of expected utility the focus here is instead on a particular quantile of the outcome distribution. We find that in the case where the sample consists of a fixed number of untreated and a fixed number of treated units, any treatment rule is minimax regret optimal. The same is true in the case of random treatment assignment in the sample with any assignment probability and in the case of testing an innovation when the known quantile of the untreated population equals 1/2. However if the known quantile exceeds 1/2 then never treating is the unique optimal rule and if it is smaller than 1/2 always treating is optimal. We also consider the case where a covariate is included.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u6709\u9650\u6837\u672c\u4e0b\u57fa\u4e8e\u7279\u5b9a\u5206\u4f4d\u6570\uff08\u800c\u975e\u671f\u671b\u6548\u7528\uff09\u7684\u6781\u5c0f\u5316\u6781\u5927\u540e\u6094\u6cbb\u7597\u89c4\u5219\uff0c\u53d1\u73b0\u5728\u4e0d\u540c\u62bd\u6837\u65b9\u6848\u4e0b\uff0c\u5f53\u5df2\u77e5\u672a\u6cbb\u7597\u7fa4\u4f53\u7684\u5206\u4f4d\u6570\u7b49\u4e8e1/2\u65f6\uff0c\u4efb\u4f55\u6cbb\u7597\u89c4\u5219\u90fd\u662f\u6700\u4f18\u7684\uff1b\u5206\u4f4d\u6570\u5927\u4e8e1/2\u65f6\u4ece\u4e0d\u6cbb\u7597\u6700\u4f18\uff0c\u5c0f\u4e8e1/2\u65f6\u603b\u662f\u6cbb\u7597\u6700\u4f18\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\uff08\u5982Stoye 2009\uff09\u4e3b\u8981\u5173\u6ce8\u671f\u671b\u6548\u7528\u7684\u6700\u5927\u5316\uff0c\u4f46\u5b9e\u9645\u51b3\u7b56\u4e2d\u51b3\u7b56\u8005\u53ef\u80fd\u66f4\u5173\u5fc3\u7ed3\u679c\u5206\u5e03\u7684\u7279\u5b9a\u5206\u4f4d\u6570\uff08\u5982\u4e2d\u4f4d\u6570\u6216\u4e0b\u5206\u4f4d\u6570\uff09\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u57fa\u4e8e\u5206\u4f4d\u6570\u76ee\u6807\u7684\u6709\u9650\u6837\u672c\u6781\u5c0f\u5316\u6781\u5927\u540e\u6094\u6cbb\u7597\u89c4\u5219\uff0c\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u6781\u5c0f\u5316\u6781\u5927\u540e\u6094\u6846\u67b6\uff0c\u5206\u6790\u4e0d\u540c\u62bd\u6837\u65b9\u6848\u4e0b\u7684\u6700\u4f18\u6cbb\u7597\u89c4\u5219\uff1a1\uff09\u56fa\u5b9a\u6570\u91cf\u7684\u672a\u6cbb\u7597\u548c\u6cbb\u7597\u5355\u4f4d\u6837\u672c\uff1b2\uff09\u968f\u673a\u6cbb\u7597\u5206\u914d\u6837\u672c\uff1b3\uff09\u5305\u542b\u534f\u53d8\u91cf\u7684\u60c5\u51b5\u3002\u5047\u8bbe\u7ed3\u679c\u9650\u5236\u5728\u5355\u4f4d\u533a\u95f4\u5185\uff0c\u5173\u6ce8\u7279\u5b9a\u5206\u4f4d\u6570\u800c\u975e\u671f\u671b\u6548\u7528\u3002", "result": "1\uff09\u5728\u56fa\u5b9a\u6570\u91cf\u672a\u6cbb\u7597\u548c\u6cbb\u7597\u5355\u4f4d\u7684\u6837\u672c\u4e2d\uff0c\u4efb\u4f55\u6cbb\u7597\u89c4\u5219\u90fd\u662f\u6781\u5c0f\u5316\u6781\u5927\u540e\u6094\u6700\u4f18\u7684\uff1b2\uff09\u5728\u968f\u673a\u6cbb\u7597\u5206\u914d\u6837\u672c\u4e2d\uff0c\u5f53\u5df2\u77e5\u672a\u6cbb\u7597\u7fa4\u4f53\u7684\u5206\u4f4d\u6570\u7b49\u4e8e1/2\u65f6\uff0c\u4efb\u4f55\u89c4\u5219\u90fd\u6700\u4f18\uff1b3\uff09\u5f53\u5df2\u77e5\u5206\u4f4d\u6570\u5927\u4e8e1/2\u65f6\uff0c\u4ece\u4e0d\u6cbb\u7597\u662f\u552f\u4e00\u6700\u4f18\u89c4\u5219\uff1b\u5c0f\u4e8e1/2\u65f6\uff0c\u603b\u662f\u6cbb\u7597\u6700\u4f18\uff1b4\uff09\u5305\u542b\u534f\u53d8\u91cf\u7684\u60c5\u51b5\u4e5f\u8fdb\u884c\u4e86\u5206\u6790\u3002", "conclusion": "\u57fa\u4e8e\u5206\u4f4d\u6570\u7684\u51b3\u7b56\u4e0e\u57fa\u4e8e\u671f\u671b\u6548\u7528\u7684\u51b3\u7b56\u5b58\u5728\u672c\u8d28\u5dee\u5f02\u3002\u5f53\u5df2\u77e5\u672a\u6cbb\u7597\u7fa4\u4f53\u7684\u5206\u4f4d\u6570\u6070\u597d\u4e3a1/2\u65f6\uff0c\u51b3\u7b56\u8005\u9762\u4e34\"\u65e0\u5dee\u5f02\"\u60c5\u51b5\uff0c\u4efb\u4f55\u6cbb\u7597\u89c4\u5219\u90fd\u540c\u6837\u597d\u3002\u8fd9\u4e00\u53d1\u73b0\u5bf9\u5b9e\u9645\u653f\u7b56\u5236\u5b9a\u6709\u91cd\u8981\u542f\u793a\uff0c\u7279\u522b\u662f\u5728\u98ce\u9669\u89c4\u907f\u6216\u5173\u6ce8\u5206\u5e03\u5c3e\u90e8\u7684\u51b3\u7b56\u573a\u666f\u4e2d\u3002"}}
{"id": "2601.03994", "categories": ["stat.AP", "stat.CO", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.03994", "abs": "https://arxiv.org/abs/2601.03994", "authors": ["David Randahl", "Anders Hjort", "Jonathan P. Williams"], "title": "pintervals: an R package for model-agnostic prediction intervals", "comment": null, "summary": "The \\pkg{pintervals} package aims to provide a unified framework for constructing prediction intervals and calibrating predictions in a model-agnostic setting using set-aside calibration data. It comprises routines to construct conformal as well as parametric and bootstrapped prediction intervals from any model that outputs point predictions. Several R packages and functions already exist for constructing prediction intervals, but they often focus on specific modeling frameworks or types of predictions, or require manual customization for different models or applications. By providing a consistent interface for a variety of prediction interval construction approaches (all model-agnostic), \\pkg{pintervals} allows researchers to apply and compare them across different modeling frameworks and applications.", "AI": {"tldr": "pintervals\u5305\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u6784\u5efa\u9884\u6d4b\u533a\u95f4\u548c\u6821\u51c6\u9884\u6d4b\uff0c\u652f\u6301\u591a\u79cd\u6a21\u578b\u65e0\u5173\u7684\u9884\u6d4b\u533a\u95f4\u6784\u5efa\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684R\u5305\u548c\u51fd\u6570\u901a\u5e38\u4e13\u6ce8\u4e8e\u7279\u5b9a\u7684\u5efa\u6a21\u6846\u67b6\u6216\u9884\u6d4b\u7c7b\u578b\uff0c\u6216\u8005\u9700\u8981\u9488\u5bf9\u4e0d\u540c\u6a21\u578b\u6216\u5e94\u7528\u8fdb\u884c\u624b\u52a8\u5b9a\u5236\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u6a21\u578b\u65e0\u5173\u9884\u6d4b\u533a\u95f4\u6784\u5efa\u5de5\u5177\u3002", "method": "\u4f7f\u7528\u9884\u7559\u7684\u6821\u51c6\u6570\u636e\uff0c\u63d0\u4f9b\u4e00\u81f4\u7684\u63a5\u53e3\u6765\u6784\u5efa\u591a\u79cd\u9884\u6d4b\u533a\u95f4\uff1a\u5305\u62ecconformal\u9884\u6d4b\u533a\u95f4\u3001\u53c2\u6570\u5316\u9884\u6d4b\u533a\u95f4\u548cbootstrap\u9884\u6d4b\u533a\u95f4\uff0c\u652f\u6301\u4efb\u4f55\u8f93\u51fa\u70b9\u9884\u6d4b\u7684\u6a21\u578b\u3002", "result": "\u5f00\u53d1\u4e86pintervals\u5305\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u5de5\u5177\uff0c\u53ef\u4ee5\u5728\u4e0d\u540c\u7684\u5efa\u6a21\u6846\u67b6\u548c\u5e94\u7528\u4e2d\u5e94\u7528\u548c\u6bd4\u8f83\u591a\u79cd\u9884\u6d4b\u533a\u95f4\u6784\u5efa\u65b9\u6cd5\u3002", "conclusion": "pintervals\u5305\u586b\u8865\u4e86R\u751f\u6001\u7cfb\u7edf\u4e2d\u6a21\u578b\u65e0\u5173\u9884\u6d4b\u533a\u95f4\u6784\u5efa\u5de5\u5177\u7684\u7a7a\u767d\uff0c\u4e3a\u7edf\u8ba1\u5efa\u6a21\u548c\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u7075\u6d3b\u3001\u7edf\u4e00\u7684\u9884\u6d4b\u533a\u95f4\u6784\u5efa\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.03976", "categories": ["cs.ET", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.03976", "abs": "https://arxiv.org/abs/2601.03976", "authors": ["Gorka Nieto", "Idoia de la Iglesia", "Cristina Perfecto", "Unai Lopez-Novoa"], "title": "On-Device Deep Reinforcement Learning for Decentralized Task Offloading Performance trade-offs in the training process", "comment": "Submitted to IEEE Transactions on Cognitive Communications and Networking", "summary": "Allowing less capable devices to offload computational tasks to more powerful devices or servers enables the development of new applications that may not run correctly on the device itself. Deciding where and why to run each of those applications is a complex task. Therefore, different approaches have been adopted to make offloading decisions. In this work, we propose a decentralized Deep Reinforcement Learning (DRL) agent to address the selection of computing locations. Unlike most existing work, we analyze it in a real testbed composed of various edge devices running the agent to determine where to execute each task. These devices are connected to a Multi-Access Edge Computing (MEC) server and a Cloud server through 5G communications. We evaluate not only the agent's performance in meeting task requirements but also the implications of running this type of agent locally, assessing the trade-offs of training locally versus remotely in terms of latency and energy consumption.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u53bb\u4e2d\u5fc3\u5316\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u8ba1\u7b97\u5378\u8f7d\u51b3\u7b56\u65b9\u6848\uff0c\u5e76\u5728\u771f\u5b9e5G\u8fb9\u7f18\u8ba1\u7b97\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u6027\u80fd\u4e0e\u80fd\u8017\u6743\u8861", "motivation": "\u73b0\u6709\u8ba1\u7b97\u5378\u8f7d\u51b3\u7b56\u65b9\u6cd5\u590d\u6742\u4e14\u7f3a\u4e4f\u771f\u5b9e\u73af\u5883\u9a8c\u8bc1\uff0c\u9700\u8981\u5728\u771f\u5b9e\u8fb9\u7f18\u8bbe\u5907\u4e0a\u8bc4\u4f30DRL\u4ee3\u7406\u7684\u6027\u80fd\u4e0e\u672c\u5730\u8fd0\u884c\u4ee3\u4ef7", "method": "\u91c7\u7528\u53bb\u4e2d\u5fc3\u5316\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\uff0c\u5728\u771f\u5b9e5G MEC\u6d4b\u8bd5\u5e73\u53f0\uff08\u5305\u542b\u591a\u79cd\u8fb9\u7f18\u8bbe\u5907\u3001MEC\u670d\u52a1\u5668\u548c\u4e91\u670d\u52a1\u5668\uff09\u4e0a\u5b9e\u73b0\u4efb\u52a1\u6267\u884c\u4f4d\u7f6e\u9009\u62e9", "result": "\u8bc4\u4f30\u4e86\u4ee3\u7406\u5728\u6ee1\u8db3\u4efb\u52a1\u9700\u6c42\u65b9\u9762\u7684\u6027\u80fd\uff0c\u5e76\u5206\u6790\u4e86\u672c\u5730\u8fd0\u884cDRL\u4ee3\u7406\u7684\u5ef6\u8fdf\u548c\u80fd\u8017\u6743\u8861\uff0c\u6bd4\u8f83\u4e86\u672c\u5730\u8bad\u7ec3\u4e0e\u8fdc\u7a0b\u8bad\u7ec3\u7684\u4f18\u52a3", "conclusion": "\u53bb\u4e2d\u5fc3\u5316DRL\u65b9\u6cd5\u5728\u771f\u5b9e\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e2d\u53ef\u884c\uff0c\u4f46\u9700\u8981\u8003\u8651\u672c\u5730\u8fd0\u884c\u4ee3\u7406\u7684\u8ba1\u7b97\u5f00\u9500\u4e0e\u6027\u80fd\u4e4b\u95f4\u7684\u5e73\u8861"}}
{"id": "2601.03458", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03458", "abs": "https://arxiv.org/abs/2601.03458", "authors": ["Aron Gohr", "Marie-Amelie Lawn", "Kevin Gao", "Inigo Serjeant", "Stephen Heslip"], "title": "Automated Feedback Generation for Undergraduate Mathematics: Development and Evaluation of an AI Teaching Assistant", "comment": null, "summary": "Intelligent tutoring systems have long enabled automated immediate feedback on student work when it is presented in a tightly structured format and when problems are very constrained, but reliably assessing free-form mathematical reasoning remains challenging.\n  We present a system that processes free-form natural language input, handles a wide range of edge cases, and comments competently not only on the technical correctness of submitted proofs, but also on style and presentation issues. We discuss the advantages and disadvantages of various approaches to the evaluation of such a system, and show that by the metrics we evaluate, the quality of the feedback generated is comparable to that produced by human experts when assessing early undergraduate homework. We stress-test our system with a small set of more advanced and unusual questions, and report both significant gaps and encouraging successes in that more challenging setting.\n  Our system uses large language models in a modular workflow. The workflow configuration is human-readable and editable without programming knowledge, and allows some intermediate steps to be precomputed or injected by the instructor.\n  A version of our tool is deployed on the Imperial mathematics homework platform Lambdafeedback. We report also on the integration of our tool into this platform.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\uff0c\u80fd\u591f\u5904\u7406\u81ea\u7531\u5f62\u5f0f\u7684\u6570\u5b66\u8bc1\u660e\uff0c\u63d0\u4f9b\u6280\u672f\u6b63\u786e\u6027\u548c\u5199\u4f5c\u98ce\u683c\u53cd\u9988\uff0c\u8d28\u91cf\u63a5\u8fd1\u4eba\u7c7b\u4e13\u5bb6\u6c34\u5e73", "motivation": "\u4f20\u7edf\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u53ea\u80fd\u5904\u7406\u7ed3\u6784\u5316\u3001\u53d7\u9650\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u53ef\u9760\u8bc4\u4f30\u81ea\u7531\u5f62\u5f0f\u7684\u6570\u5b66\u63a8\u7406\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u5904\u7406\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u3001\u5e94\u5bf9\u5404\u79cd\u8fb9\u7f18\u60c5\u51b5\u7684\u7cfb\u7edf", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u6a21\u5757\u5316\u5de5\u4f5c\u6d41\uff0c\u914d\u7f6e\u53ef\u8bfb\u4e14\u65e0\u9700\u7f16\u7a0b\u77e5\u8bc6\u5373\u53ef\u7f16\u8f91\uff0c\u5141\u8bb8\u6559\u5e08\u9884\u8ba1\u7b97\u6216\u6ce8\u5165\u4e2d\u95f4\u6b65\u9aa4", "result": "\u7cfb\u7edf\u53cd\u9988\u8d28\u91cf\u5728\u8bc4\u4f30\u6307\u6807\u4e0a\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u76f8\u5f53\uff0c\u5df2\u90e8\u7f72\u5728Imperial\u6570\u5b66\u4f5c\u4e1a\u5e73\u53f0Lambdafeedback\u4e0a\uff0c\u5bf9\u9ad8\u7ea7\u95ee\u9898\u65e2\u6709\u6210\u529f\u4e5f\u6709\u5dee\u8ddd", "conclusion": "\u8be5\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u8bc4\u4f30\u81ea\u7531\u5f62\u5f0f\u6570\u5b66\u8bc1\u660e\uff0c\u63d0\u4f9b\u6280\u672f\u6b63\u786e\u6027\u548c\u98ce\u683c\u53cd\u9988\uff0c\u4e3a\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u5728\u66f4\u5e7f\u6cdb\u6570\u5b66\u6559\u80b2\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84"}}
{"id": "2601.03306", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03306", "abs": "https://arxiv.org/abs/2601.03306", "authors": ["Jingbin Liu", "Xuechun Wang"], "title": "Mastering the Game of Go with Self-play Experience Replay", "comment": "13 pages, 5 figures", "summary": "The game of Go has long served as a benchmark for artificial intelligence, demanding sophisticated strategic reasoning and long-term planning. Previous approaches such as AlphaGo and its successors, have predominantly relied on model-based Monte-Carlo Tree Search (MCTS). In this work, we present QZero, a novel model-free reinforcement learning algorithm that forgoes search during training and learns a Nash equilibrium policy through self-play and off-policy experience replay. Built upon entropy-regularized Q-learning, QZero utilizes a single Q-value network to unify policy evaluation and improvement. Starting tabula rasa without human data and trained for 5 months with modest compute resources (7 GPUs), QZero achieved a performance level comparable to that of AlphaGo. This demonstrates, for the first time, the efficiency of using model-free reinforcement learning to master the game of Go, as well as the feasibility of off-policy reinforcement learning in solving large-scale and complex environments.", "AI": {"tldr": "QZero\u662f\u4e00\u79cd\u65e0\u9700\u641c\u7d22\u7684\u6a21\u578b\u65e0\u5173\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u81ea\u535a\u5f08\u548c\u79bb\u7b56\u7565\u7ecf\u9a8c\u56de\u653e\u5b66\u4e60\u7eb3\u4ec0\u5747\u8861\u7b56\u7565\uff0c\u5728\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u4e0b\u8fbe\u5230AlphaGo\u6c34\u5e73", "motivation": "\u56f4\u68cb\u957f\u671f\u4ee5\u6765\u4f5c\u4e3a\u4eba\u5de5\u667a\u80fd\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u9700\u8981\u590d\u6742\u7684\u6218\u7565\u63a8\u7406\u548c\u957f\u671f\u89c4\u5212\u3002\u5148\u524d\u65b9\u6cd5\u5982AlphaGo\u4e3b\u8981\u4f9d\u8d56\u57fa\u4e8e\u6a21\u578b\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u6a21\u578b\u65e0\u5173\u5f3a\u5316\u5b66\u4e60\u5728\u56f4\u68cb\u4e2d\u7684\u6709\u6548\u6027", "method": "\u57fa\u4e8e\u71b5\u6b63\u5219\u5316Q\u5b66\u4e60\uff0c\u4f7f\u7528\u5355\u4e2aQ\u503c\u7f51\u7edc\u7edf\u4e00\u7b56\u7565\u8bc4\u4f30\u548c\u6539\u8fdb\uff0c\u901a\u8fc7\u81ea\u535a\u5f08\u548c\u79bb\u7b56\u7565\u7ecf\u9a8c\u56de\u653e\u5b66\u4e60\uff0c\u65e0\u9700\u641c\u7d22\u8bad\u7ec3\uff0c\u4ece\u96f6\u5f00\u59cb\u65e0\u9700\u4eba\u7c7b\u6570\u636e", "result": "\u4f7f\u7528\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\uff087\u4e2aGPU\u8bad\u7ec35\u4e2a\u6708\uff09\u8fbe\u5230\u4e0eAlphaGo\u76f8\u5f53\u7684\u6027\u80fd\u6c34\u5e73\uff0c\u9996\u6b21\u8bc1\u660e\u6a21\u578b\u65e0\u5173\u5f3a\u5316\u5b66\u4e60\u5728\u56f4\u68cb\u4e2d\u7684\u6709\u6548\u6027", "conclusion": "\u9996\u6b21\u8bc1\u660e\u6a21\u578b\u65e0\u5173\u5f3a\u5316\u5b66\u4e60\u53ef\u4ee5\u638c\u63e1\u56f4\u68cb\u6e38\u620f\uff0c\u5c55\u793a\u4e86\u79bb\u7b56\u7565\u5f3a\u5316\u5b66\u4e60\u5728\u89e3\u51b3\u5927\u89c4\u6a21\u590d\u6742\u73af\u5883\u4e2d\u7684\u53ef\u884c\u6027"}}
{"id": "2601.03469", "categories": ["econ.EM", "cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.03469", "abs": "https://arxiv.org/abs/2601.03469", "authors": ["Nadav Kunievsky", "Pedro Pertusi"], "title": "Content vs. Form: What Drives the Writing Score Gap Across Socioeconomic Backgrounds? A Generated Panel Approach", "comment": null, "summary": "Students from different socioeconomic backgrounds exhibit persistent gaps in test scores, gaps that can translate into unequal educational and labor-market outcomes later in life. In many assessments, performance reflects not only what students know, but also how effectively they can communicate that knowledge. This distinction is especially salient in writing assessments, where scores jointly reward the substance of students' ideas and the way those ideas are expressed. As a result, observed score gaps may conflate differences in underlying content with differences in expressive skill. A central question, therefore, is how much of the socioeconomic-status (SES) gap in scores is driven by differences in what students say versus how they say it. We study this question using a large corpus of persuasive essays written by U.S. middle- and high-school students. We introduce a new measurement strategy that separates content from style by leveraging large language models to generate multiple stylistic variants of each essay. These rewrites preserve the underlying arguments while systematically altering surface expression, creating a \"generated panel\" that introduces controlled within-essay variation in style. This approach allows us to decompose SES gaps in writing scores into contributions from content and style. We find an SES gap of 0.67 points on a 1-6 scale. Approximately 69% of the gap is attributable to differences in essay content quality, Style differences account for 26% of the gap, and differences in evaluation standards across SES groups account for the remaining 5%. These patterns seems stable across demographic subgroups and writing tasks. More broadly, our approach shows how large language models can be used to generate controlled variation in observational data, enabling researchers to isolate and quantify the contributions of otherwise entangled factors.", "AI": {"tldr": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u540c\u4e00\u5185\u5bb9\u7684\u4e0d\u540c\u98ce\u683c\u53d8\u4f53\uff0c\u5206\u89e3\u5199\u4f5c\u8bc4\u5206\u4e2d\u7684\u793e\u4f1a\u7ecf\u6d4e\u5730\u4f4d\u5dee\u8ddd\uff0c\u53d1\u73b069%\u6e90\u4e8e\u5185\u5bb9\u8d28\u91cf\u5dee\u5f02\uff0c26%\u6e90\u4e8e\u8868\u8fbe\u98ce\u683c\u5dee\u5f02\uff0c5%\u6e90\u4e8e\u8bc4\u5206\u6807\u51c6\u5dee\u5f02", "motivation": "\u793e\u4f1a\u7ecf\u6d4e\u5730\u4f4d\uff08SES\uff09\u5dee\u8ddd\u5728\u6d4b\u8bd5\u6210\u7ee9\u4e2d\u6301\u7eed\u5b58\u5728\uff0c\u53ef\u80fd\u5f71\u54cd\u6559\u80b2\u548c\u5c31\u4e1a\u7ed3\u679c\u3002\u5199\u4f5c\u8bc4\u4f30\u4e2d\uff0c\u5206\u6570\u540c\u65f6\u53cd\u6620\u5185\u5bb9\u8d28\u91cf\u548c\u8868\u8fbe\u65b9\u5f0f\uff0c\u9700\u8981\u533a\u5206\u8fd9\u4e24\u8005\u5bf9SES\u5dee\u8ddd\u7684\u8d21\u732e\u7a0b\u5ea6", "method": "\u4f7f\u7528\u7f8e\u56fd\u4e2d\u5b66\u751f\u8bf4\u670d\u6027\u8bae\u8bba\u6587\u8bed\u6599\u5e93\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3a\u6bcf\u7bc7\u8bba\u6587\u751f\u6210\u591a\u4e2a\u98ce\u683c\u53d8\u4f53\uff0c\u4fdd\u6301\u8bba\u70b9\u5185\u5bb9\u4e0d\u53d8\u4f46\u6539\u53d8\u8868\u9762\u8868\u8fbe\uff0c\u521b\u5efa\"\u751f\u6210\u9762\u677f\"\u4ee5\u5f15\u5165\u53d7\u63a7\u7684\u98ce\u683c\u53d8\u5316", "result": "\u53d1\u73b0SES\u5dee\u8ddd\u4e3a0.67\u5206\uff081-6\u5206\u5236\uff09\uff0c\u5176\u4e2d69%\u6e90\u4e8e\u8bba\u6587\u5185\u5bb9\u8d28\u91cf\u5dee\u5f02\uff0c26%\u6e90\u4e8e\u98ce\u683c\u5dee\u5f02\uff0c5%\u6e90\u4e8e\u4e0d\u540cSES\u7fa4\u4f53\u95f4\u7684\u8bc4\u5206\u6807\u51c6\u5dee\u5f02\u3002\u8fd9\u4e9b\u6a21\u5f0f\u5728\u4e0d\u540c\u4eba\u53e3\u4e9a\u7fa4\u548c\u5199\u4f5c\u4efb\u52a1\u4e2d\u4fdd\u6301\u7a33\u5b9a", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u7528\u4e8e\u5728\u89c2\u5bdf\u6570\u636e\u4e2d\u751f\u6210\u53d7\u63a7\u53d8\u5316\uff0c\u5e2e\u52a9\u7814\u7a76\u8005\u5206\u79bb\u548c\u91cf\u5316\u539f\u672c\u7ea0\u7f20\u7684\u56e0\u7d20\u3002\u5199\u4f5c\u8bc4\u4f30\u4e2d\u7684SES\u5dee\u8ddd\u4e3b\u8981\u6e90\u4e8e\u5185\u5bb9\u8d28\u91cf\u5dee\u5f02\u800c\u975e\u8868\u8fbe\u98ce\u683c"}}
{"id": "2601.03482", "categories": ["cs.AI", "cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.03482", "abs": "https://arxiv.org/abs/2601.03482", "authors": ["Stefan Konigorski", "Johannes E. Vedder", "Babajide Alamu Owoyele", "\u0130brahim \u00d6zkan"], "title": "Personalization of Large Foundation Models for Health Interventions", "comment": "Accepted to the AAAI 2026 Workshop on Personalization in the Era of Large Foundation Models (PerFM)", "summary": "Large foundation models (LFMs) transform healthcare AI in prevention, diagnostics, and treatment. However, whether LFMs can provide truly personalized treatment recommendations remains an open question. Recent research has revealed multiple challenges for personalization, including the fundamental generalizability paradox: models achieving high accuracy in one clinical study perform at chance level in others, demonstrating that personalization and external validity exist in tension. This exemplifies broader contradictions in AI-driven healthcare: the privacy-performance paradox, scale-specificity paradox, and the automation-empathy paradox. As another challenge, the degree of causal understanding required for personalized recommendations, as opposed to mere predictive capacities of LFMs, remains an open question. N-of-1 trials -- crossover self-experiments and the gold standard for individual causal inference in personalized medicine -- resolve these tensions by providing within-person causal evidence while preserving privacy through local experimentation. Despite their impressive capabilities, this paper argues that LFMs cannot replace N-of-1 trials. We argue that LFMs and N-of-1 trials are complementary: LFMs excel at rapid hypothesis generation from population patterns using multimodal data, while N-of-1 trials excel at causal validation for a given individual. We propose a hybrid framework that combines the strengths of both to enable personalization and navigate the identified paradoxes: LFMs generate ranked intervention candidates with uncertainty estimates, which trigger subsequent N-of-1 trials. Clarifying the boundary between prediction and causation and explicitly addressing the paradoxical tensions are essential for responsible AI integration in personalized medicine.", "AI": {"tldr": "\u5927\u578b\u57fa\u7840\u6a21\u578b\u5728\u533b\u7597AI\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u65e0\u6cd5\u66ff\u4ee3N-of-1\u8bd5\u9a8c\u8fdb\u884c\u4e2a\u6027\u5316\u6cbb\u7597\u63a8\u8350\uff0c\u4e24\u8005\u5e94\u4e92\u8865\u7ed3\u5408", "motivation": "\u63a2\u8ba8\u5927\u578b\u57fa\u7840\u6a21\u578b\u80fd\u5426\u63d0\u4f9b\u771f\u6b63\u4e2a\u6027\u5316\u7684\u6cbb\u7597\u63a8\u8350\uff0c\u89e3\u51b3\u533b\u7597AI\u4e2d\u7684\u666e\u904d\u6027\u6096\u8bba\u3001\u9690\u79c1-\u6027\u80fd\u6096\u8bba\u3001\u89c4\u6a21-\u7279\u5f02\u6027\u6096\u8bba\u548c\u81ea\u52a8\u5316-\u5171\u60c5\u6096\u8bba\u7b49\u77db\u76fe", "method": "\u63d0\u51fa\u6df7\u5408\u6846\u67b6\uff1a\u5927\u578b\u57fa\u7840\u6a21\u578b\u5229\u7528\u591a\u6a21\u6001\u6570\u636e\u4ece\u7fa4\u4f53\u6a21\u5f0f\u4e2d\u5feb\u901f\u751f\u6210\u5047\u8bbe\u548c\u5e72\u9884\u5019\u9009\u6392\u540d\uff0cN-of-1\u8bd5\u9a8c\uff08\u4ea4\u53c9\u81ea\u6211\u5b9e\u9a8c\uff09\u8fdb\u884c\u4e2a\u4f53\u56e0\u679c\u9a8c\u8bc1", "result": "\u5927\u578b\u57fa\u7840\u6a21\u578b\u65e0\u6cd5\u66ff\u4ee3N-of-1\u8bd5\u9a8c\uff0c\u4f46\u4e24\u8005\u53ef\u4ee5\u4e92\u8865\u3002\u6df7\u5408\u6846\u67b6\u7ed3\u5408\u4e86\u5927\u578b\u57fa\u7840\u6a21\u578b\u7684\u9884\u6d4b\u80fd\u529b\u548cN-of-1\u8bd5\u9a8c\u7684\u56e0\u679c\u63a8\u65ad\u4f18\u52bf", "conclusion": "\u660e\u786e\u9884\u6d4b\u4e0e\u56e0\u679c\u4e4b\u95f4\u7684\u754c\u9650\uff0c\u89e3\u51b3\u533b\u7597AI\u4e2d\u7684\u6096\u8bba\u6027\u5f20\u529b\uff0c\u5bf9\u4e8e\u8d1f\u8d23\u4efb\u5730\u5c06AI\u6574\u5408\u5230\u4e2a\u6027\u5316\u533b\u7597\u4e2d\u81f3\u5173\u91cd\u8981\u3002\u5927\u578b\u57fa\u7840\u6a21\u578b\u548cN-of-1\u8bd5\u9a8c\u5e94\u534f\u540c\u5de5\u4f5c\u4ee5\u5b9e\u73b0\u771f\u6b63\u7684\u4e2a\u6027\u5316\u6cbb\u7597"}}
{"id": "2601.03693", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03693", "abs": "https://arxiv.org/abs/2601.03693", "authors": ["Junaid Qadir", "Muhammad Adil Attique", "Saleha Shoaib", "Syed Ibrahim Ghaznavi"], "title": "Can AI Chatbots Provide Coaching in Engineering? Beyond Information Processing Toward Mastery", "comment": "accepted at IEEE EDUCON 2026", "summary": "Engineering education faces a double disruption: traditional apprenticeship models that cultivated judgment and tacit skill are eroding, just as generative AI emerges as an informal coaching partner. This convergence rekindles long-standing questions in the philosophy of AI and cognition about the limits of computation, the nature of embodied rationality, and the distinction between information processing and wisdom. Building on this rich intellectual tradition, this paper examines whether AI chatbots can provide coaching that fosters mastery rather than merely delivering information. We synthesize critical perspectives from decades of scholarship on expertise, tacit knowledge, and human-machine interaction, situating them within the context of contemporary AI-driven education. Empirically, we report findings from a mixed-methods study (N = 75 students, N = 7 faculty) exploring the use of a coaching chatbot in engineering education. Results reveal a consistent boundary: participants accept AI for technical problem solving (convergent tasks; M = 3.84 on a 1-5 Likert scale) but remain skeptical of its capacity for moral, emotional, and contextual judgment (divergent tasks). Faculty express stronger concerns over risk (M = 4.71 vs. M = 4.14, p = 0.003), and privacy emerges as a key requirement, with 64-71 percent of participants demanding strict confidentiality. Our findings suggest that while generative AI can democratize access to cognitive and procedural support, it cannot replicate the embodied, value-laden dimensions of human mentorship. We propose a multiplex coaching framework that integrates human wisdom within expert-in-the-loop models, preserving the depth of apprenticeship while leveraging AI scalability to enrich the next generation of engineering education.", "AI": {"tldr": "AI\u804a\u5929\u673a\u5668\u4eba\u80fd\u5728\u5de5\u7a0b\u6559\u80b2\u4e2d\u63d0\u4f9b\u6280\u672f\u6307\u5bfc\uff0c\u4f46\u5728\u9053\u5fb7\u3001\u60c5\u611f\u548c\u60c5\u5883\u5224\u65ad\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u7ed3\u5408\u4eba\u7c7b\u5bfc\u5e08\u7684\u667a\u6167\u5f62\u6210\u6df7\u5408\u6307\u5bfc\u6846\u67b6\u3002", "motivation": "\u5de5\u7a0b\u6559\u80b2\u9762\u4e34\u53cc\u91cd\u51b2\u51fb\uff1a\u4f20\u7edf\u5b66\u5f92\u5236\u6a21\u5f0f\u6b63\u5728\u8870\u843d\uff0c\u800c\u751f\u6210\u5f0fAI\u4f5c\u4e3a\u975e\u6b63\u5f0f\u6307\u5bfc\u4f19\u4f34\u51fa\u73b0\u3002\u8fd9\u5f15\u53d1\u4e86\u5173\u4e8eAI\u8ba1\u7b97\u6781\u9650\u3001\u5177\u8eab\u7406\u6027\u672c\u8d28\u4ee5\u53ca\u4fe1\u606f\u5904\u7406\u4e0e\u667a\u6167\u533a\u522b\u7684\u54f2\u5b66\u95ee\u9898\u3002", "method": "\u7efc\u5408\u6570\u5341\u5e74\u5173\u4e8e\u4e13\u4e1a\u77e5\u8bc6\u3001\u9690\u6027\u77e5\u8bc6\u548c\u4eba\u673a\u4ea4\u4e92\u7684\u5b66\u672f\u89c2\u70b9\uff0c\u5e76\u5728\u5f53\u4ee3AI\u9a71\u52a8\u6559\u80b2\u80cc\u666f\u4e0b\u8fdb\u884c\u5b9a\u4f4d\u3002\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\uff0875\u540d\u5b66\u751f\uff0c7\u540d\u6559\u5e08\uff09\u63a2\u7d22\u6307\u5bfc\u804a\u5929\u673a\u5668\u4eba\u5728\u5de5\u7a0b\u6559\u80b2\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u53c2\u4e0e\u8005\u63a5\u53d7AI\u7528\u4e8e\u6280\u672f\u95ee\u9898\u89e3\u51b3\uff08\u6536\u655b\u6027\u4efb\u52a1\uff0c\u5e73\u5747\u8bc4\u52063.84/5\uff09\uff0c\u4f46\u5bf9\u5176\u9053\u5fb7\u3001\u60c5\u611f\u548c\u60c5\u5883\u5224\u65ad\u80fd\u529b\uff08\u53d1\u6563\u6027\u4efb\u52a1\uff09\u6301\u6000\u7591\u6001\u5ea6\u3002\u6559\u5e08\u5bf9\u98ce\u9669\u62c5\u5fe7\u66f4\u5f3a\uff0c64-71%\u53c2\u4e0e\u8005\u8981\u6c42\u4e25\u683c\u4fdd\u5bc6\u6027\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u53ef\u4ee5\u6c11\u4e3b\u5316\u8ba4\u77e5\u548c\u7a0b\u5e8f\u652f\u6301\uff0c\u4f46\u65e0\u6cd5\u590d\u5236\u4eba\u7c7b\u5bfc\u5e08\u7684\u5177\u8eab\u3001\u4ef7\u503c\u5bfc\u5411\u7ef4\u5ea6\u3002\u63d0\u51fa\u6574\u5408\u4eba\u7c7b\u667a\u6167\u7684\u4e13\u5bb6\u5728\u73af\u6a21\u578b\u7684\u591a\u91cd\u6307\u5bfc\u6846\u67b6\uff0c\u5728\u4fdd\u6301\u5b66\u5f92\u5236\u6df1\u5ea6\u7684\u540c\u65f6\u5229\u7528AI\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2601.03335", "categories": ["cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.03335", "abs": "https://arxiv.org/abs/2601.03335", "authors": ["Akarsh Kumar", "Ryan Bahlous-Boldi", "Prafull Sharma", "Phillip Isola", "Sebastian Risi", "Yujin Tang", "David Ha"], "title": "Digital Red Queen: Adversarial Program Evolution in Core War with LLMs", "comment": "14 pages, 13 figures", "summary": "Large language models (LLMs) are increasingly being used to evolve solutions to problems in many domains, in a process inspired by biological evolution. However, unlike biological evolution, most LLM-evolution frameworks are formulated as static optimization problems, overlooking the open-ended adversarial dynamics that characterize real-world evolutionary processes. Here, we study Digital Red Queen (DRQ), a simple self-play algorithm that embraces these so-called \"Red Queen\" dynamics via continual adaptation to a changing objective. DRQ uses an LLM to evolve assembly-like programs, called warriors, which compete against each other for control of a virtual machine in the game of Core War, a Turing-complete environment studied in artificial life and connected to cybersecurity. In each round of DRQ, the model evolves a new warrior to defeat all previous ones, producing a sequence of adapted warriors. Over many rounds, we observe that warriors become increasingly general (relative to a set of held-out human warriors). Interestingly, warriors also become less behaviorally diverse across independent runs, indicating a convergence pressure toward a general-purpose behavioral strategy, much like convergent evolution in nature. This result highlights a potential value of shifting from static objectives to dynamic Red Queen objectives. Our work positions Core War as a rich, controllable sandbox for studying adversarial adaptation in artificial systems and for evaluating LLM-based evolution methods. More broadly, the simplicity and effectiveness of DRQ suggest that similarly minimal self-play approaches could prove useful in other more practical multi-agent adversarial domains, like real-world cybersecurity or combating drug resistance.", "AI": {"tldr": "\u63d0\u51faDigital Red Queen\u7b97\u6cd5\uff0c\u5229\u7528LLM\u5728Core War\u6e38\u620f\u4e2d\u901a\u8fc7\u81ea\u6211\u5bf9\u6297\u6f14\u5316\u7a0b\u5e8f\uff0c\u5b9e\u73b0\u6301\u7eed\u9002\u5e94\u52a8\u6001\u76ee\u6807\uff0c\u76f8\u6bd4\u9759\u6001\u4f18\u5316\u80fd\u4ea7\u751f\u66f4\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570LLM\u6f14\u5316\u6846\u67b6\u91c7\u7528\u9759\u6001\u4f18\u5316\u65b9\u6cd5\uff0c\u5ffd\u7565\u4e86\u73b0\u5b9e\u4e16\u754c\u4e2d\u5f00\u653e\u5f0f\u7684\u5bf9\u6297\u6027\u6f14\u5316\u52a8\u6001\uff08\"\u7ea2\u7687\u540e\"\u6548\u5e94\uff09\u3002\u9700\u8981\u7814\u7a76\u5982\u4f55\u5c06\u8fd9\u79cd\u52a8\u6001\u5bf9\u6297\u8fc7\u7a0b\u7eb3\u5165LLM\u6f14\u5316\u6846\u67b6\u3002", "method": "\u63d0\u51faDigital Red Queen\u7b97\u6cd5\uff1a\u5728Core War\u6e38\u620f\u4e2d\uff0c\u8ba9LLM\u6f14\u5316\u6c47\u7f16\u5f0f\u7a0b\u5e8f\uff08warriors\uff09\uff0c\u6bcf\u8f6e\u751f\u6210\u65b0\u7a0b\u5e8f\u4ee5\u51fb\u8d25\u4e4b\u524d\u6240\u6709\u7a0b\u5e8f\uff0c\u5f62\u6210\u8fde\u7eed\u7684\u9002\u5e94\u5e8f\u5217\u3002Core War\u662f\u4e00\u4e2a\u56fe\u7075\u5b8c\u5907\u7684\u865a\u62df\u73af\u5883\u3002", "result": "\u6f14\u5316\u51fa\u7684\u7a0b\u5e8f\u8d8a\u6765\u8d8a\u901a\u7528\uff08\u76f8\u5bf9\u4e8e\u4eba\u7c7b\u7f16\u5199\u7684\u7a0b\u5e8f\u96c6\uff09\u3002\u6709\u8da3\u7684\u662f\uff0c\u72ec\u7acb\u8fd0\u884c\u4e2d\u7a0b\u5e8f\u7684\u884c\u4e3a\u591a\u6837\u6027\u51cf\u5c11\uff0c\u8868\u660e\u5411\u901a\u7528\u884c\u4e3a\u7b56\u7565\u7684\u6536\u655b\u538b\u529b\uff0c\u7c7b\u4f3c\u4e8e\u81ea\u7136\u754c\u7684\u8d8b\u540c\u6f14\u5316\u3002", "conclusion": "\u4ece\u9759\u6001\u76ee\u6807\u8f6c\u5411\u52a8\u6001\u7ea2\u7687\u540e\u76ee\u6807\u5177\u6709\u6f5c\u5728\u4ef7\u503c\u3002Core War\u53ef\u4f5c\u4e3a\u7814\u7a76\u5bf9\u6297\u6027\u9002\u5e94\u7684\u53ef\u63a7\u6c99\u76d2\u73af\u5883\u3002\u8fd9\u79cd\u7b80\u5355\u7684\u81ea\u6211\u5bf9\u6297\u65b9\u6cd5\u53ef\u5e94\u7528\u4e8e\u66f4\u5b9e\u9645\u7684\u5bf9\u6297\u9886\u57df\uff0c\u5982\u7f51\u7edc\u5b89\u5168\u6216\u6297\u836f\u6027\u7814\u7a76\u3002"}}
{"id": "2601.03598", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2601.03598", "abs": "https://arxiv.org/abs/2601.03598", "authors": ["Fu Ouyang", "Thomas T. Yang", "Wenying Yao"], "title": "Uncovering Sparse Financial Networks with Information Criteria", "comment": null, "summary": "Empirical measures of financial connectedness based on Forecast Error Variance Decompositions (FEVDs) often yield dense network structures that obscure true transmission channels and complicate the identification of systemic risk. This paper proposes a novel information-criterion-based approach to uncover sparse, economically meaningful financial networks. By reformulating FEVD-based connectedness as a regression problem, we develop a model selection framework that consistently recovers the active set of spillover channels. We extend this method to generalized FEVDs to accommodate correlated shocks and introduce a data-driven procedure for tuning the penalty parameter using pseudo-out-of-sample forecast performance. Monte Carlo simulations demonstrate the approach's effectiveness with finite samples and its robustness to approximately sparse networks and heavy-tailed errors. Applications to global stock markets, S&P 500 sectoral indices, and commodity futures highlight the prevalence of sparse networks in empirical settings.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4fe1\u606f\u51c6\u5219\u7684\u7a00\u758f\u91d1\u878d\u7f51\u7edc\u8bc6\u522b\u65b9\u6cd5\uff0c\u901a\u8fc7FEVD\u56de\u5f52\u91cd\u6784\u548c\u6a21\u578b\u9009\u62e9\u6846\u67b6\uff0c\u6709\u6548\u8bc6\u522b\u7cfb\u7edf\u6027\u98ce\u9669\u4f20\u64ad\u901a\u9053", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u9884\u6d4b\u8bef\u5dee\u65b9\u5dee\u5206\u89e3\u7684\u91d1\u878d\u5173\u8054\u6027\u5ea6\u91cf\u901a\u5e38\u4ea7\u751f\u5bc6\u96c6\u7f51\u7edc\u7ed3\u6784\uff0c\u8fd9\u63a9\u76d6\u4e86\u771f\u5b9e\u7684\u4f20\u64ad\u901a\u9053\uff0c\u4f7f\u7cfb\u7edf\u6027\u98ce\u9669\u8bc6\u522b\u53d8\u5f97\u590d\u6742", "method": "\u5c06FEVD\u5173\u8054\u6027\u91cd\u6784\u4e3a\u56de\u5f52\u95ee\u9898\uff0c\u5efa\u7acb\u6a21\u578b\u9009\u62e9\u6846\u67b6\u4ee5\u4e00\u81f4\u6062\u590d\u6d3b\u8dc3\u7684\u6ea2\u51fa\u901a\u9053\uff1b\u6269\u5c55\u5230\u5e7f\u4e49FEVD\u4ee5\u5904\u7406\u76f8\u5173\u51b2\u51fb\uff1b\u63d0\u51fa\u57fa\u4e8e\u4f2a\u6837\u672c\u5916\u9884\u6d4b\u6027\u80fd\u7684\u6570\u636e\u9a71\u52a8\u60e9\u7f5a\u53c2\u6570\u9009\u62e9\u65b9\u6cd5", "result": "\u8499\u7279\u5361\u6d1b\u6a21\u62df\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u6709\u9650\u6837\u672c\u4e0b\u6709\u6548\uff0c\u5bf9\u8fd1\u4f3c\u7a00\u758f\u7f51\u7edc\u548c\u539a\u5c3e\u8bef\u5dee\u5177\u6709\u9c81\u68d2\u6027\uff1b\u5e94\u7528\u4e8e\u5168\u7403\u80a1\u5e02\u3001\u6807\u666e500\u884c\u4e1a\u6307\u6570\u548c\u5927\u5b97\u5546\u54c1\u671f\u8d27\uff0c\u8bc1\u5b9e\u4e86\u7a00\u758f\u7f51\u7edc\u5728\u5b9e\u8bc1\u4e2d\u7684\u666e\u904d\u6027", "conclusion": "\u63d0\u51fa\u7684\u4fe1\u606f\u51c6\u5219\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u8bc6\u522b\u7a00\u758f\u7684\u3001\u7ecf\u6d4e\u610f\u4e49\u660e\u786e\u7684\u91d1\u878d\u7f51\u7edc\uff0c\u4e3a\u7cfb\u7edf\u6027\u98ce\u9669\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u6e05\u6670\u7684\u4f20\u64ad\u901a\u9053\u8bc6\u522b\u5de5\u5177"}}
{"id": "2601.03709", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03709", "abs": "https://arxiv.org/abs/2601.03709", "authors": ["Sarah Spiekermann-Hoff", "Marc Langheinrich", "Johannes Hoff", "Christiane Wendehorst", "J\u00fcrgen Pfeffer", "Thomas Fuchs", "Armin Grunwald"], "title": "The Power of 10: New Rules for the Digital World", "comment": "to be published in Communications of the ACM (submitted 26 June 2025, revised 29 August 2025, accepted 3 November 2025)", "summary": "As artificial intelligence rapidly advances, society is increasingly captivated by promises of superhuman machines and seamless digital futures. Yet these visions often obscure mounting social, ethical, and psychological concerns tied to pervasive digital technologies - from surveillance to mental health crises. This article argues that a guiding ethos is urgently needed to navigate these transformations. Inspired by the lasting influence of the biblical Ten Commandments, a European interdisciplinary group has proposed \"Ten Rules for the Digital World\" - a novel ethical framework to help individuals and societies make prudent, human-centered decisions in the age of \"supercharged\" technology.", "AI": {"tldr": "\u6b27\u6d32\u8de8\u5b66\u79d1\u56e2\u961f\u63d0\u51fa\"\u6570\u5b57\u4e16\u754c\u5341\u8beb\"\uff0c\u4f5c\u4e3a\u5e94\u5bf9AI\u6280\u672f\u5feb\u901f\u53d1\u5c55\u7684\u4f26\u7406\u6846\u67b6\uff0c\u65e8\u5728\u5f15\u5bfc\u4e2a\u4eba\u548c\u793e\u4f1a\u5728\"\u8d85\u7ea7\u6280\u672f\"\u65f6\u4ee3\u505a\u51fa\u660e\u667a\u3001\u4ee5\u4eba\u4e3a\u672c\u7684\u51b3\u7b56\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u5feb\u901f\u53d1\u5c55\uff0c\u793e\u4f1a\u8fc7\u5ea6\u5173\u6ce8\u8d85\u4eba\u673a\u5668\u548c\u65e0\u7f1d\u6570\u5b57\u672a\u6765\u7684\u627f\u8bfa\uff0c\u5374\u5ffd\u89c6\u4e86\u65e5\u76ca\u589e\u957f\u7684\u793e\u4f1a\u3001\u4f26\u7406\u548c\u5fc3\u7406\u95ee\u9898\uff0c\u5982\u76d1\u63a7\u548c\u5fc3\u7406\u5065\u5eb7\u5371\u673a\u3002\u8feb\u5207\u9700\u8981\u6307\u5bfc\u539f\u5219\u6765\u5e94\u5bf9\u8fd9\u4e9b\u6280\u672f\u53d8\u9769\u3002", "method": "\u501f\u9274\u5723\u7ecf\u5341\u8beb\u7684\u6301\u4e45\u5f71\u54cd\u529b\uff0c\u6b27\u6d32\u8de8\u5b66\u79d1\u56e2\u961f\u63d0\u51fa\u4e86\"\u6570\u5b57\u4e16\u754c\u5341\u8beb\"\uff0c\u8fd9\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u4f26\u7406\u6846\u67b6\uff0c\u65e8\u5728\u5e2e\u52a9\u4e2a\u4eba\u548c\u793e\u4f1a\u5728\u6280\u672f\"\u8d85\u7ea7\u5145\u7535\"\u65f6\u4ee3\u505a\u51fa\u8c28\u614e\u3001\u4ee5\u4eba\u4e3a\u672c\u7684\u51b3\u7b56\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5177\u4f53\u7684\u4f26\u7406\u6846\u67b6\u2014\u2014\"\u6570\u5b57\u4e16\u754c\u5341\u8beb\"\uff0c\u4e3a\u5e94\u5bf9\u6570\u5b57\u6280\u672f\u5e26\u6765\u7684\u793e\u4f1a\u3001\u4f26\u7406\u548c\u5fc3\u7406\u6311\u6218\u63d0\u4f9b\u4e86\u6307\u5bfc\u539f\u5219\u3002", "conclusion": "\u5728\u4eba\u5de5\u667a\u80fd\u548c\u6570\u5b57\u6280\u672f\u5feb\u901f\u53d1\u5c55\u7684\u65f6\u4ee3\uff0c\u8feb\u5207\u9700\u8981\u5efa\u7acb\u50cf\"\u6570\u5b57\u4e16\u754c\u5341\u8beb\"\u8fd9\u6837\u7684\u4f26\u7406\u6846\u67b6\uff0c\u4ee5\u786e\u4fdd\u6280\u672f\u53d1\u5c55\u7b26\u5408\u4eba\u7c7b\u4ef7\u503c\u89c2\uff0c\u5e2e\u52a9\u793e\u4f1a\u505a\u51fa\u660e\u667a\u3001\u4ee5\u4eba\u4e3a\u672c\u7684\u51b3\u7b56\u3002"}}
{"id": "2601.03359", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03359", "abs": "https://arxiv.org/abs/2601.03359", "authors": ["Alberto Purpura", "Li Wang", "Sahil Badyal", "Eugenio Beaufrand", "Adam Faulkner"], "title": "Enhancing LLM Instruction Following: An Evaluation-Driven Multi-Agentic Workflow for Prompt Instructions Optimization", "comment": null, "summary": "Large Language Models (LLMs) often generate substantively relevant content but fail to adhere to formal constraints, leading to outputs that are conceptually correct but procedurally flawed. Traditional prompt refinement approaches focus on rephrasing the description of the primary task an LLM has to perform, neglecting the granular constraints that function as acceptance criteria for its response. We propose a novel multi-agentic workflow that decouples optimization of the primary task description from its constraints, using quantitative scores as feedback to iteratively rewrite and improve them. Our evaluation demonstrates this method produces revised prompts that yield significantly higher compliance scores from models like Llama 3.1 8B and Mixtral-8x 7B.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff0c\u5c06\u4e3b\u4efb\u52a1\u63cf\u8ff0\u4f18\u5316\u4e0e\u7ea6\u675f\u6761\u4ef6\u89e3\u8026\uff0c\u901a\u8fc7\u5b9a\u91cf\u8bc4\u5206\u53cd\u9988\u8fed\u4ee3\u6539\u8fdb\u63d0\u793a\uff0c\u663e\u8457\u63d0\u5347LLM\u8f93\u51fa\u5bf9\u5f62\u5f0f\u7ea6\u675f\u7684\u9075\u5faa\u5ea6", "motivation": "LLM\u7ecf\u5e38\u751f\u6210\u5185\u5bb9\u76f8\u5173\u4f46\u4e0d\u7b26\u5408\u5f62\u5f0f\u7ea6\u675f\u7684\u8f93\u51fa\uff0c\u4f20\u7edf\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u53ea\u5173\u6ce8\u4e3b\u4efb\u52a1\u63cf\u8ff0\u7684\u91cd\u8ff0\uff0c\u5ffd\u7565\u4e86\u4f5c\u4e3a\u54cd\u5e94\u9a8c\u6536\u6807\u51c6\u7684\u7ec6\u7c92\u5ea6\u7ea6\u675f\u6761\u4ef6", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff0c\u5c06\u4e3b\u4efb\u52a1\u63cf\u8ff0\u4f18\u5316\u4e0e\u7ea6\u675f\u6761\u4ef6\u89e3\u8026\uff0c\u4f7f\u7528\u5b9a\u91cf\u8bc4\u5206\u4f5c\u4e3a\u53cd\u9988\uff0c\u8fed\u4ee3\u91cd\u5199\u548c\u6539\u8fdb\u63d0\u793a", "result": "\u8be5\u65b9\u6cd5\u751f\u6210\u7684\u4fee\u8ba2\u63d0\u793a\u5728Llama 3.1 8B\u548cMixtral-8x 7B\u7b49\u6a21\u578b\u4e0a\u4ea7\u751f\u663e\u8457\u66f4\u9ad8\u7684\u5408\u89c4\u6027\u8bc4\u5206", "conclusion": "\u89e3\u8026\u4efb\u52a1\u63cf\u8ff0\u4e0e\u7ea6\u675f\u6761\u4ef6\u7684\u591a\u667a\u80fd\u4f53\u4f18\u5316\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347LLM\u8f93\u51fa\u5bf9\u5f62\u5f0f\u7ea6\u675f\u7684\u9075\u5faa\u5ea6\uff0c\u4f18\u4e8e\u4f20\u7edf\u63d0\u793a\u4f18\u5316\u65b9\u6cd5"}}
{"id": "2601.03750", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2601.03750", "abs": "https://arxiv.org/abs/2601.03750", "authors": ["Marcia Schafgans", "Victoria Zinde-Walsh"], "title": "Multivariate kernel regression in vector and product metric spaces", "comment": "80 pages, 18 figures, Journal of Econometrics, January 2026", "summary": "This paper derives limit properties of nonparametric kernel regression estimators without requiring existence of density for regressors in $\\mathbb{R}^{q}.$ In functional regression limit properties are established for multivariate functional regression. The rate and asymptotic normality for the Nadaraya-Watson (NW) estimator is established for distributions of regressors in $\\mathbb{R}^{q}$ that allow for mass points, factor structure, multicollinearity and nonlinear dependence, as well as fractal distribution; when bounded density exists we provide statistical guarantees for the standard rate and the asymptotic normality without requiring smoothness. We demonstrate faster convergence associated with dimension reducing types of singularity, such as a fractal distribution or a factor structure in the regressors. The paper extends asymptotic normality of kernel functional regression to multivariate regression over a product of any number of metric spaces. Finite sample evidence confirms rate improvement due to singularity in regression over $\\mathbb{R}^{q}.$ For functional regression the simulations underline the importance of accounting for multiple functional regressors. We demonstrate the applicability and advantages of the NW estimator in our empirical study, which reexamines the job training program evaluation based on the LaLonde data.", "AI": {"tldr": "\u8bba\u6587\u63a8\u5bfc\u4e86\u975e\u53c2\u6570\u6838\u56de\u5f52\u4f30\u8ba1\u91cf\u7684\u6781\u9650\u6027\u8d28\uff0c\u65e0\u9700\u5047\u8bbe\u56de\u5f52\u53d8\u91cf\u5bc6\u5ea6\u5b58\u5728\uff0c\u9002\u7528\u4e8e\u5177\u6709\u8d28\u91cf\u70b9\u3001\u56e0\u5b50\u7ed3\u6784\u3001\u591a\u91cd\u5171\u7ebf\u6027\u548c\u5206\u5f62\u5206\u5e03\u7684\u60c5\u51b5\uff0c\u5e76\u8bc1\u660e\u4e86\u5947\u5f02\u6027\u80fd\u5e26\u6765\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u4f20\u7edf\u975e\u53c2\u6570\u6838\u56de\u5f52\u4f30\u8ba1\u901a\u5e38\u8981\u6c42\u56de\u5f52\u53d8\u91cf\u5177\u6709\u5bc6\u5ea6\u51fd\u6570\uff0c\u8fd9\u9650\u5236\u4e86\u5728\u73b0\u5b9e\u6570\u636e\u4e2d\u7684\u5e94\u7528\uff0c\u56e0\u4e3a\u5b9e\u9645\u6570\u636e\u5e38\u5305\u542b\u8d28\u91cf\u70b9\u3001\u56e0\u5b50\u7ed3\u6784\u3001\u591a\u91cd\u5171\u7ebf\u6027\u6216\u5206\u5f62\u5206\u5e03\u7b49\u7279\u5f81\u3002\u672c\u6587\u65e8\u5728\u653e\u5bbd\u8fd9\u4e00\u9650\u5236\uff0c\u5efa\u7acb\u66f4\u4e00\u822c\u6761\u4ef6\u4e0b\u7684\u6781\u9650\u6027\u8d28\u3002", "method": "\u4f7f\u7528Nadaraya-Watson\u6838\u56de\u5f52\u4f30\u8ba1\u91cf\uff0c\u5728\u56de\u5f52\u53d8\u91cf\u5206\u5e03\u5141\u8bb8\u8d28\u91cf\u70b9\u3001\u56e0\u5b50\u7ed3\u6784\u3001\u591a\u91cd\u5171\u7ebf\u6027\u548c\u5206\u5f62\u5206\u5e03\u7684\u6761\u4ef6\u4e0b\uff0c\u63a8\u5bfc\u4f30\u8ba1\u91cf\u7684\u6781\u9650\u6027\u8d28\u3002\u5c06\u51fd\u6570\u56de\u5f52\u7684\u6e10\u8fd1\u6b63\u6001\u6027\u6269\u5c55\u5230\u4efb\u610f\u591a\u4e2a\u5ea6\u91cf\u7a7a\u95f4\u4e58\u79ef\u4e0a\u7684\u591a\u5143\u56de\u5f52\u3002", "result": "\u5efa\u7acb\u4e86\u56de\u5f52\u53d8\u91cf\u5728\u211d^q\u4e2d\u5206\u5e03\u5141\u8bb8\u5947\u5f02\u60c5\u51b5\u4e0b\u7684\u6536\u655b\u901f\u7387\u548c\u6e10\u8fd1\u6b63\u6001\u6027\uff1b\u8bc1\u660e\u4e86\u7ef4\u5ea6\u964d\u4f4e\u578b\u5947\u5f02\u6027\uff08\u5982\u5206\u5f62\u5206\u5e03\u6216\u56e0\u5b50\u7ed3\u6784\uff09\u80fd\u5e26\u6765\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\uff1b\u5c06\u51fd\u6570\u56de\u5f52\u7684\u6e10\u8fd1\u6b63\u6001\u6027\u6269\u5c55\u5230\u591a\u5143\u60c5\u51b5\uff1b\u5b9e\u8bc1\u7814\u7a76\u9a8c\u8bc1\u4e86\u5947\u5f02\u6027\u80fd\u6539\u5584\u6536\u655b\u901f\u7387\u3002", "conclusion": "\u672c\u6587\u653e\u5bbd\u4e86\u975e\u53c2\u6570\u6838\u56de\u5f52\u5bf9\u56de\u5f52\u53d8\u91cf\u5bc6\u5ea6\u7684\u8981\u6c42\uff0c\u5efa\u7acb\u4e86\u66f4\u4e00\u822c\u6761\u4ef6\u4e0b\u7684\u6781\u9650\u7406\u8bba\uff0c\u8bc1\u660e\u4e86\u5947\u5f02\u6027\u80fd\u52a0\u901f\u6536\u655b\uff0c\u6269\u5c55\u4e86\u51fd\u6570\u56de\u5f52\u7684\u6e10\u8fd1\u6b63\u6001\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u5c55\u793a\u4e86NW\u4f30\u8ba1\u91cf\u5728LaLonde\u6570\u636e\u4e2d\u7684\u9002\u7528\u6027\u548c\u4f18\u52bf\u3002"}}
{"id": "2601.03788", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03788", "abs": "https://arxiv.org/abs/2601.03788", "authors": ["Anamaria Mojica-Hanke", "Thomas Goger", "Svenja W\u00f6lfel", "Brian Valerius", "Steffen Herbold"], "title": "Criminal Liability of Generative Artificial Intelligence Providers for User-Generated Child Sexual Abuse Material", "comment": "Accepted at the International Conference on AI Engineering", "summary": "The development of more powerful Generative Artificial Intelligence (GenAI) has expanded its capabilities and the variety of outputs. This has introduced significant legal challenges, including gray areas in various legal systems, such as the assessment of criminal liability for those responsible for these models. Therefore, we conducted a multidisciplinary study utilizing the statutory interpretation of relevant German laws, which, in conjunction with scenarios, provides a perspective on the different properties of GenAI in the context of Child Sexual Abuse Material (CSAM) generation. We found that generating CSAM with GenAI may have criminal and legal consequences not only for the user committing the primary offense but also for individuals responsible for the models, such as independent software developers, researchers, and company representatives. Additionally, the assessment of criminal liability may be affected by contextual and technical factors, including the type of generated image, content moderation policies, and the model's intended purpose. Based on our findings, we discussed the implications for different roles, as well as the requirements when developing such systems.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u751f\u6210\u513f\u7ae5\u6027\u8650\u5f85\u6750\u6599(CSAM)\u53ef\u80fd\u5f15\u53d1\u591a\u65b9\u5211\u4e8b\u8d23\u4efb\uff0c\u5305\u62ec\u7528\u6237\u3001\u5f00\u53d1\u8005\u3001\u7814\u7a76\u4eba\u5458\u548c\u516c\u53f8\u4ee3\u8868\uff0c\u8d23\u4efb\u8bc4\u4f30\u53d7\u56fe\u50cf\u7c7b\u578b\u3001\u5185\u5bb9\u5ba1\u6838\u653f\u7b56\u548c\u6280\u672f\u56e0\u7d20\u5f71\u54cd\u3002", "motivation": "\u751f\u6210\u5f0fAI\u80fd\u529b\u7684\u589e\u5f3a\u5e26\u6765\u4e86\u65b0\u7684\u6cd5\u5f8b\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u513f\u7ae5\u6027\u8650\u5f85\u6750\u6599\u751f\u6210\u65b9\u9762\u5b58\u5728\u6cd5\u5f8b\u7070\u8272\u5730\u5e26\uff0c\u9700\u8981\u660e\u786e\u76f8\u5173\u8d23\u4efb\u65b9\u7684\u5211\u4e8b\u8d23\u4efb\u3002", "method": "\u91c7\u7528\u591a\u5b66\u79d1\u7814\u7a76\u65b9\u6cd5\uff0c\u7ed3\u5408\u5fb7\u56fd\u76f8\u5173\u6cd5\u5f8b\u7684\u6cd5\u5b9a\u89e3\u91ca\u548c\u5177\u4f53\u573a\u666f\u5206\u6790\uff0c\u63a2\u8ba8\u751f\u6210\u5f0fAI\u5728CSAM\u751f\u6210\u80cc\u666f\u4e0b\u7684\u4e0d\u540c\u5c5e\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u751f\u6210CSAM\u4e0d\u4ec5\u7528\u6237\u53ef\u80fd\u6784\u6210\u4e3b\u8981\u72af\u7f6a\uff0c\u72ec\u7acb\u8f6f\u4ef6\u5f00\u53d1\u8005\u3001\u7814\u7a76\u4eba\u5458\u548c\u516c\u53f8\u4ee3\u8868\u7b49\u6a21\u578b\u8d23\u4efb\u65b9\u4e5f\u53ef\u80fd\u9762\u4e34\u5211\u4e8b\u548c\u6cd5\u5f8b\u8d23\u4efb\u3002\u8d23\u4efb\u8bc4\u4f30\u53d7\u751f\u6210\u56fe\u50cf\u7c7b\u578b\u3001\u5185\u5bb9\u5ba1\u6838\u653f\u7b56\u548c\u6a21\u578b\u9884\u671f\u7528\u9014\u7b49\u56e0\u7d20\u5f71\u54cd\u3002", "conclusion": "\u7814\u7a76\u8ba8\u8bba\u4e86\u4e0d\u540c\u89d2\u8272\u7684\u6cd5\u5f8b\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u5f00\u53d1\u6b64\u7c7b\u7cfb\u7edf\u65f6\u7684\u8981\u6c42\uff0c\u5f3a\u8c03\u4e86\u5728\u751f\u6210\u5f0fAI\u53d1\u5c55\u4e2d\u9700\u8981\u660e\u786e\u6cd5\u5f8b\u8d23\u4efb\u6846\u67b6\u3002"}}
{"id": "2601.03389", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03389", "abs": "https://arxiv.org/abs/2601.03389", "authors": ["Michael Petrowski", "Milica Ga\u0161i\u0107"], "title": "Exploration Through Introspection: A Self-Aware Reward Model", "comment": "Accepted at AAAI-26 ToM4AI Workshop", "summary": "Understanding how artificial agents model internal mental states is central to advancing Theory of Mind in AI. Evidence points to a unified system for self- and other-awareness. We explore this self-awareness by having reinforcement learning agents infer their own internal states in gridworld environments. Specifically, we introduce an introspective exploration component that is inspired by biological pain as a learning signal by utilizing a hidden Markov model to infer \"pain-belief\" from online observations. This signal is integrated into a subjective reward function to study how self-awareness affects the agent's learning abilities. Further, we use this computational framework to investigate the difference in performance between normal and chronic pain perception models. Results show that introspective agents in general significantly outperform standard baseline agents and can replicate complex human-like behaviors.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5185\u7701\u63a2\u7d22\u7684\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u63a8\u65ad\"\u75bc\u75db\u4fe1\u5ff5\"\u4f5c\u4e3a\u5b66\u4e60\u4fe1\u53f7\uff0c\u7814\u7a76\u81ea\u6211\u610f\u8bc6\u5982\u4f55\u5f71\u54cd\u667a\u80fd\u4f53\u7684\u5b66\u4e60\u80fd\u529b\uff0c\u5e76\u6bd4\u8f83\u6b63\u5e38\u4e0e\u6162\u6027\u75bc\u75db\u611f\u77e5\u6a21\u578b\u7684\u6027\u80fd\u5dee\u5f02\u3002", "motivation": "\u7406\u89e3\u4eba\u5de5\u667a\u80fd\u5982\u4f55\u5efa\u6a21\u5185\u90e8\u5fc3\u7406\u72b6\u6001\u5bf9\u4e8e\u63a8\u8fdbAI\u4e2d\u7684\u5fc3\u667a\u7406\u8bba\u81f3\u5173\u91cd\u8981\u3002\u8bc1\u636e\u8868\u660e\u81ea\u6211\u8ba4\u77e5\u548c\u4ed6\u4eba\u8ba4\u77e5\u5b58\u5728\u7edf\u4e00\u7cfb\u7edf\uff0c\u672c\u7814\u7a76\u901a\u8fc7\u8ba9\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u5728\u7f51\u683c\u4e16\u754c\u4e2d\u63a8\u65ad\u81ea\u8eab\u5185\u90e8\u72b6\u6001\u6765\u63a2\u7d22\u8fd9\u79cd\u81ea\u6211\u610f\u8bc6\u3002", "method": "\u5f15\u5165\u53d7\u751f\u7269\u75bc\u75db\u542f\u53d1\u7684\u5185\u7701\u63a2\u7d22\u7ec4\u4ef6\uff0c\u4f7f\u7528\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u4ece\u5728\u7ebf\u89c2\u5bdf\u4e2d\u63a8\u65ad\"\u75bc\u75db\u4fe1\u5ff5\"\uff0c\u5c06\u8be5\u4fe1\u53f7\u6574\u5408\u5230\u4e3b\u89c2\u5956\u52b1\u51fd\u6570\u4e2d\uff0c\u6784\u5efa\u8ba1\u7b97\u6846\u67b6\u6bd4\u8f83\u6b63\u5e38\u4e0e\u6162\u6027\u75bc\u75db\u611f\u77e5\u6a21\u578b\u7684\u6027\u80fd\u5dee\u5f02\u3002", "result": "\u5185\u7701\u667a\u80fd\u4f53\u603b\u4f53\u4e0a\u663e\u8457\u4f18\u4e8e\u6807\u51c6\u57fa\u7ebf\u667a\u80fd\u4f53\uff0c\u80fd\u591f\u590d\u73b0\u590d\u6742\u7684\u4eba\u7c7b\u7c7b\u4f3c\u884c\u4e3a\uff0c\u5c55\u793a\u4e86\u81ea\u6211\u610f\u8bc6\u5bf9\u667a\u80fd\u4f53\u5b66\u4e60\u80fd\u529b\u7684\u79ef\u6781\u5f71\u54cd\u3002", "conclusion": "\u901a\u8fc7\u8ba1\u7b97\u6846\u67b6\u7814\u7a76\u81ea\u6211\u610f\u8bc6\u5728AI\u4e2d\u7684\u4f5c\u7528\u662f\u53ef\u884c\u7684\uff0c\u5185\u7701\u63a2\u7d22\u673a\u5236\u80fd\u6709\u6548\u63d0\u5347\u667a\u80fd\u4f53\u6027\u80fd\uff0c\u4e3a\u7406\u89e3AI\u4e2d\u7684\u5fc3\u667a\u7406\u8bba\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u5e76\u53ef\u7528\u4e8e\u6a21\u62df\u548c\u7814\u7a76\u75bc\u75db\u611f\u77e5\u7b49\u590d\u6742\u5fc3\u7406\u73b0\u8c61\u3002"}}
{"id": "2601.03983", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2601.03983", "abs": "https://arxiv.org/abs/2601.03983", "authors": ["Christophe Hurlin", "Quentin Lajaunie", "Yoann Pull"], "title": "Reverse Stress Testing Geopolitical Risk in Corporate Credit Portfolios: A Formal and Operational Framework", "comment": null, "summary": "This paper proposes a formal framework for reverse stress testing geopolitical risk in corporate credit portfolios. A joint macro-financial scenario vector, augmented with an explicit geopolitical risk factor, is mapped into stressed probabilities of default and losses given default. These stresses are then propagated to portfolio tail losses through a latent factor structure and translated into a stressed CET1 ratio, jointly accounting for capital depletion and risk-weighted asset dynamics. Reverse stress testing is formulated as a constrained maximum likelihood problem over the scenario space. This yields a geopolitical point reverse stress test, or design point, defined as the most probable scenario that breaches a prescribed capital adequacy constraint under a reference distribution. The framework further characterises neighbourhoods and near optimal sets of reverse stress scenarios, allowing for sensitivity analysis and governance oriented interpretation. The approach is compatible with internal rating based models and supports implementation at the exposure or sector level.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7528\u4e8e\u4f01\u4e1a\u4fe1\u8d37\u7ec4\u5408\u5730\u7f18\u653f\u6cbb\u98ce\u9669\u53cd\u5411\u538b\u529b\u6d4b\u8bd5\u7684\u6b63\u5f0f\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5927\u4f3c\u7136\u65b9\u6cd5\u627e\u5230\u6700\u53ef\u80fd\u8fdd\u53cd\u8d44\u672c\u5145\u8db3\u7387\u7ea6\u675f\u7684\u5730\u7f18\u653f\u6cbb\u98ce\u9669\u60c5\u666f\u3002", "motivation": "\u4f20\u7edf\u538b\u529b\u6d4b\u8bd5\u901a\u5e38\u4ece\u9884\u8bbe\u60c5\u666f\u51fa\u53d1\uff0c\u800c\u53cd\u5411\u538b\u529b\u6d4b\u8bd5\u9700\u8981\u627e\u5230\u5bfc\u81f4\u7279\u5b9a\u4e0d\u5229\u7ed3\u679c\u7684\u6700\u53ef\u80fd\u60c5\u666f\u3002\u672c\u6587\u65e8\u5728\u5efa\u7acb\u4e00\u4e2a\u6b63\u5f0f\u6846\u67b6\uff0c\u4e13\u95e8\u9488\u5bf9\u5730\u7f18\u653f\u6cbb\u98ce\u9669\u5bf9\u4f01\u4e1a\u4fe1\u8d37\u7ec4\u5408\u7684\u5f71\u54cd\u8fdb\u884c\u53cd\u5411\u538b\u529b\u6d4b\u8bd5\u3002", "method": "\u6784\u5efa\u5305\u542b\u663e\u5f0f\u5730\u7f18\u653f\u6cbb\u98ce\u9669\u56e0\u5b50\u7684\u8054\u5408\u5b8f\u89c2\u91d1\u878d\u60c5\u666f\u5411\u91cf\uff0c\u6620\u5c04\u5230\u8fdd\u7ea6\u6982\u7387\u548c\u8fdd\u7ea6\u635f\u5931\u7387\u7684\u538b\u529b\u503c\u3002\u901a\u8fc7\u6f5c\u5728\u56e0\u5b50\u7ed3\u6784\u5c06\u538b\u529b\u4f20\u64ad\u5230\u7ec4\u5408\u5c3e\u90e8\u635f\u5931\uff0c\u5e76\u8f6c\u5316\u4e3a\u538b\u529b\u4e0b\u7684CET1\u6bd4\u7387\u3002\u5c06\u53cd\u5411\u538b\u529b\u6d4b\u8bd5\u8868\u8ff0\u4e3a\u60c5\u666f\u7a7a\u95f4\u4e0a\u7684\u7ea6\u675f\u6700\u5927\u4f3c\u7136\u95ee\u9898\uff0c\u627e\u5230\u6700\u53ef\u80fd\u8fdd\u53cd\u8d44\u672c\u5145\u8db3\u7387\u7ea6\u675f\u7684\u60c5\u666f\uff08\u8bbe\u8ba1\u70b9\uff09\u3002", "result": "\u6846\u67b6\u80fd\u591f\u8bc6\u522b\u5730\u7f18\u653f\u6cbb\u98ce\u9669\u53cd\u5411\u538b\u529b\u6d4b\u8bd5\u7684\u8bbe\u8ba1\u70b9\uff0c\u5e76\u8fdb\u4e00\u6b65\u63cf\u8ff0\u53cd\u5411\u538b\u529b\u60c5\u666f\u7684\u90bb\u57df\u548c\u8fd1\u4f3c\u6700\u4f18\u96c6\uff0c\u652f\u6301\u654f\u611f\u6027\u5206\u6790\u548c\u6cbb\u7406\u5bfc\u5411\u7684\u89e3\u91ca\u3002\u8be5\u65b9\u6cd5\u4e0e\u5185\u90e8\u8bc4\u7ea7\u6a21\u578b\u517c\u5bb9\uff0c\u53ef\u5728\u655e\u53e3\u6216\u884c\u4e1a\u5c42\u9762\u5b9e\u65bd\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4f01\u4e1a\u4fe1\u8d37\u7ec4\u5408\u7684\u5730\u7f18\u653f\u6cbb\u98ce\u9669\u53cd\u5411\u538b\u529b\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u65b9\u6cd5\uff0c\u80fd\u591f\u8bc6\u522b\u6700\u53ef\u80fd\u8fdd\u53cd\u8d44\u672c\u7ea6\u675f\u7684\u60c5\u666f\uff0c\u652f\u6301\u98ce\u9669\u7ba1\u7406\u548c\u76d1\u7ba1\u5408\u89c4\u51b3\u7b56\u3002"}}
{"id": "2601.04094", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.04094", "abs": "https://arxiv.org/abs/2601.04094", "authors": ["Tom Deckenbrunnen", "Alessio Buscemi", "Marco Almada", "Alfredo Capozucca", "German Castignani"], "title": "The Bathtub of European AI Governance: Identifying Technical Sandboxes as the Micro-Foundation of Regulatory Learning", "comment": null, "summary": "The EU AI Act adopts a horizontal and adaptive approach to govern AI technologies characterised by rapid development and unpredictable emerging capabilities. To maintain relevance, the Act embeds provisions for regulatory learning. However, these provisions operate within a complex network of actors and mechanisms that lack a clearly defined technical basis for scalable information flow. This paper addresses this gap by establishing a theoretical model of regulatory learning space defined by the AI Act, decomposed into micro, meso, and macro levels. Drawing from this functional perspective of this model, we situate the diverse stakeholders - ranging from the EU Commission at the macro level to AI developers at the micro level - within the transitions of enforcement (macro-micro) and evidence aggregation (micro-macro). We identify AI Technical Sandboxes as the essential engine for evidence generation at the micro level, providing the necessary data to drive scalable learning across all levels of the model. By providing an extensive discussion of the requirements and challenges for AITSes to serve as this micro-level evidence generator, we aim to bridge the gap between legislative commands and technical operationalisation, thereby enabling a structured discourse between technical and legal experts.", "AI": {"tldr": "\u6b27\u76dfAI\u6cd5\u6848\u91c7\u7528\u6a2a\u5411\u9002\u5e94\u6027\u76d1\u7ba1\u6846\u67b6\uff0c\u4f46\u7f3a\u4e4f\u53ef\u6269\u5c55\u4fe1\u606f\u6d41\u52a8\u7684\u6280\u672f\u57fa\u7840\u3002\u672c\u6587\u5efa\u7acb\u76d1\u7ba1\u5b66\u4e60\u7a7a\u95f4\u7406\u8bba\u6a21\u578b\uff0c\u5c06AI\u6280\u672f\u6c99\u76d2\u5b9a\u4f4d\u4e3a\u5fae\u89c2\u8bc1\u636e\u751f\u6210\u5f15\u64ce\uff0c\u8fde\u63a5\u7acb\u6cd5\u6307\u4ee4\u4e0e\u6280\u672f\u5b9e\u65bd\u3002", "motivation": "\u6b27\u76dfAI\u6cd5\u6848\u867d\u7136\u5305\u542b\u76d1\u7ba1\u5b66\u4e60\u6761\u6b3e\uff0c\u4f46\u7f3a\u4e4f\u6e05\u6670\u7684\u6280\u672f\u57fa\u7840\u6765\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u4fe1\u606f\u6d41\u52a8\u3002\u73b0\u6709\u76d1\u7ba1\u673a\u5236\u5728\u590d\u6742\u53c2\u4e0e\u8005\u7f51\u7edc\u4e2d\u8fd0\u4f5c\uff0c\u9700\u8981\u7406\u8bba\u6a21\u578b\u6765\u7406\u89e3\u76d1\u7ba1\u5b66\u4e60\u7a7a\u95f4\u7684\u7ed3\u6784\u548c\u529f\u80fd\u3002", "method": "\u5efa\u7acb\u76d1\u7ba1\u5b66\u4e60\u7a7a\u95f4\u7406\u8bba\u6a21\u578b\uff0c\u5206\u89e3\u4e3a\u5fae\u89c2\u3001\u4e2d\u89c2\u548c\u5b8f\u89c2\u4e09\u4e2a\u5c42\u6b21\u3002\u4ece\u529f\u80fd\u89c6\u89d2\u5206\u6790\u5404\u5229\u76ca\u76f8\u5173\u8005\uff08\u4ece\u6b27\u76df\u59d4\u5458\u4f1a\u5230AI\u5f00\u53d1\u8005\uff09\u5728\u6267\u6cd5\uff08\u5b8f\u89c2-\u5fae\u89c2\uff09\u548c\u8bc1\u636e\u805a\u5408\uff08\u5fae\u89c2-\u5b8f\u89c2\uff09\u8f6c\u6362\u4e2d\u7684\u4f4d\u7f6e\u3002\u5c06AI\u6280\u672f\u6c99\u76d2\u5b9a\u4f4d\u4e3a\u5fae\u89c2\u8bc1\u636e\u751f\u6210\u5f15\u64ce\u3002", "result": "\u63d0\u51fa\u4e86\u4e09\u5c42\u76d1\u7ba1\u5b66\u4e60\u7a7a\u95f4\u6a21\u578b\uff0c\u660e\u786e\u4e86AI\u6280\u672f\u6c99\u76d2\u4f5c\u4e3a\u5fae\u89c2\u8bc1\u636e\u751f\u6210\u7684\u5173\u952e\u4f5c\u7528\u3002\u8be5\u6a21\u578b\u4e3a\u6280\u672f\u4e13\u5bb6\u548c\u6cd5\u5f8b\u4e13\u5bb6\u4e4b\u95f4\u7684\u7ed3\u6784\u5316\u5bf9\u8bdd\u63d0\u4f9b\u4e86\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u5f25\u5408\u7acb\u6cd5\u6307\u4ee4\u4e0e\u6280\u672f\u5b9e\u65bd\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "\u901a\u8fc7\u5efa\u7acb\u76d1\u7ba1\u5b66\u4e60\u7a7a\u95f4\u7406\u8bba\u6a21\u578b\uff0c\u672c\u6587\u4e3a\u6b27\u76dfAI\u6cd5\u6848\u7684\u53ef\u64cd\u4f5c\u6027\u63d0\u4f9b\u4e86\u6280\u672f\u57fa\u7840\u3002AI\u6280\u672f\u6c99\u76d2\u4f5c\u4e3a\u8bc1\u636e\u751f\u6210\u5f15\u64ce\uff0c\u80fd\u591f\u9a71\u52a8\u8de8\u5c42\u6b21\u7684\u89c4\u6a21\u5316\u5b66\u4e60\uff0c\u5b9e\u73b0\u76d1\u7ba1\u6846\u67b6\u7684\u9002\u5e94\u6027\u6f14\u8fdb\u3002"}}
{"id": "2601.03470", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03470", "abs": "https://arxiv.org/abs/2601.03470", "authors": ["Michael C. Darling", "Alan H. Hesu", "Michael A. Mardikes", "Brian C. McGuigan", "Reed M. Milewicz"], "title": "Toward Maturity-Based Certification of Embodied AI: Quantifying Trustworthiness Through Measurement Mechanisms", "comment": "5 pages, Accepted to AAAI-26 Bridge Program B10: Making Embodied AI Reliable with Testing and Formal Verification", "summary": "We propose a maturity-based framework for certifying embodied AI systems through explicit measurement mechanisms. We argue that certifiable embodied AI requires structured assessment frameworks, quantitative scoring mechanisms, and methods for navigating multi-objective trade-offs inherent in trustworthiness evaluation. We demonstrate this approach using uncertainty quantification as an exemplar measurement mechanism and illustrate feasibility through an Uncrewed Aircraft System (UAS) detection case study.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6210\u719f\u5ea6\u7684\u8ba4\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u660e\u786e\u6d4b\u91cf\u673a\u5236\u6765\u8ba4\u8bc1\u5177\u8eabAI\u7cfb\u7edf", "motivation": "\u9700\u8981\u7ed3\u6784\u5316\u8bc4\u4f30\u6846\u67b6\u3001\u91cf\u5316\u8bc4\u5206\u673a\u5236\u4ee5\u53ca\u5904\u7406\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u4e2d\u591a\u76ee\u6807\u6743\u8861\u7684\u65b9\u6cd5\u6765\u8ba4\u8bc1\u5177\u8eabAI\u7cfb\u7edf", "method": "\u4f7f\u7528\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4f5c\u4e3a\u793a\u4f8b\u6d4b\u91cf\u673a\u5236\uff0c\u901a\u8fc7\u65e0\u4eba\u673a\u7cfb\u7edf\u68c0\u6d4b\u6848\u4f8b\u7814\u7a76\u6765\u5c55\u793a\u53ef\u884c\u6027", "result": "\u5c55\u793a\u4e86\u57fa\u4e8e\u6210\u719f\u5ea6\u7684\u8ba4\u8bc1\u6846\u67b6\u5728\u5177\u8eabAI\u7cfb\u7edf\u4e2d\u7684\u53ef\u884c\u6027", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u5177\u8eabAI\u7cfb\u7edf\u8ba4\u8bc1\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u8bc4\u4f30\u3001\u91cf\u5316\u6d4b\u91cf\u548c\u6743\u8861\u5bfc\u822a\u7684\u65b9\u6cd5"}}
{"id": "2601.04087", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2601.04087", "abs": "https://arxiv.org/abs/2601.04087", "authors": ["Matteo Barigozzi", "Diego Fresoli", "Esther Ruiz"], "title": "Mean Square Errors of factors extracted using principal components, linear projections, and Kalman filter", "comment": null, "summary": "Factor extraction from systems of variables with a large cross-sectional dimension, $N$, is often based on either Principal Components (PC)-based procedures, or Kalman filter (KF)-based procedures. Measuring the uncertainty of the extracted factors is important when, for example, they have a direct interpretation and/or they are used to summarized the information in a large number of potential predictors. In this paper, we compare the finite $N$ mean square errors (MSEs) of PC and KF factors extracted under different structures of the idiosyncratic cross-correlations. We show that the MSEs of PC-based factors, implicitly based on treating the true underlying factors as deterministic, are larger than the corresponding MSEs of KF factors, obtained by treating the true factors as either serially independent or autocorrelated random variables. We also study and compare the MSEs of PC and KF factors estimated when the idiosyncratic components are wrongly considered as if they were cross-sectionally homoscedastic and/or uncorrelated. The relevance of the results for the construction of confidence intervals for the factors are illustrated with simulated data.", "AI": {"tldr": "\u6bd4\u8f83\u4e3b\u6210\u5206\u5206\u6790(PC)\u548c\u5361\u5c14\u66fc\u6ee4\u6ce2(KF)\u4e24\u79cd\u56e0\u5b50\u63d0\u53d6\u65b9\u6cd5\u5728\u6709\u9650\u6837\u672c\u4e0b\u7684\u5747\u65b9\u8bef\u5dee(MSE)\uff0c\u53d1\u73b0KF\u65b9\u6cd5\u901a\u5e38\u6bd4PC\u65b9\u6cd5\u5177\u6709\u66f4\u5c0f\u7684MSE\uff0c\u7279\u522b\u662f\u5728\u8003\u8651\u56e0\u5b50\u968f\u673a\u6027\u65f6\u3002", "motivation": "\u5f53\u4ece\u9ad8\u7ef4\u53d8\u91cf\u7cfb\u7edf\u4e2d\u63d0\u53d6\u56e0\u5b50\u65f6\uff0c\u9700\u8981\u8bc4\u4f30\u63d0\u53d6\u56e0\u5b50\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u7279\u522b\u662f\u5f53\u8fd9\u4e9b\u56e0\u5b50\u5177\u6709\u76f4\u63a5\u89e3\u91ca\u610f\u4e49\u6216\u7528\u4e8e\u6c47\u603b\u5927\u91cf\u9884\u6d4b\u53d8\u91cf\u4fe1\u606f\u65f6\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9PC\u548cKF\u65b9\u6cd5\u5728\u6709\u9650\u6837\u672c\u4e0bMSE\u6027\u80fd\u7684\u7cfb\u7edf\u6bd4\u8f83\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u6a21\u62df\u7814\u7a76\uff0c\u6bd4\u8f83PC\u548cKF\u56e0\u5b50\u5728\u4e0d\u540c\u5f02\u8d28\u6027\u6a2a\u622a\u9762\u76f8\u5173\u7ed3\u6784\u4e0b\u7684\u6709\u9650\u6837\u672cMSE\u3002\u8003\u8651\u56e0\u5b50\u4f5c\u4e3a\u786e\u5b9a\u6027\u53d8\u91cf(PC\u65b9\u6cd5)\u548c\u968f\u673a\u53d8\u91cf(KF\u65b9\u6cd5)\u7684\u4e0d\u540c\u5904\u7406\u65b9\u5f0f\uff0c\u5e76\u5206\u6790\u5f53\u9519\u8bef\u5047\u8bbe\u5f02\u8d28\u6027\u6210\u5206\u5177\u6709\u540c\u65b9\u5dee\u548c/\u6216\u4e0d\u76f8\u5173\u65f6\u7684MSE\u8868\u73b0\u3002", "result": "PC\u65b9\u6cd5\u57fa\u4e8e\u786e\u5b9a\u6027\u56e0\u5b50\u5047\u8bbe\u7684MSE\u5927\u4e8eKF\u65b9\u6cd5\u57fa\u4e8e\u968f\u673a\u56e0\u5b50\u5047\u8bbe\u7684MSE\u3002\u5f53\u9519\u8bef\u5047\u8bbe\u5f02\u8d28\u6027\u6210\u5206\u5177\u6709\u540c\u65b9\u5dee\u6216\u4e0d\u76f8\u5173\u65f6\uff0c\u4e24\u79cd\u65b9\u6cd5\u7684MSE\u8868\u73b0\u4e5f\u4e0d\u540c\u3002\u6a21\u62df\u6570\u636e\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u7ed3\u679c\u5bf9\u6784\u5efa\u56e0\u5b50\u7f6e\u4fe1\u533a\u95f4\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u5728\u5904\u7406\u9ad8\u7ef4\u53d8\u91cf\u7cfb\u7edf\u7684\u56e0\u5b50\u63d0\u53d6\u65f6\uff0cKF\u65b9\u6cd5\u901a\u5e38\u6bd4PC\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684MSE\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u8003\u8651\u56e0\u5b50\u968f\u673a\u6027\u65f6\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u6784\u5efa\u56e0\u5b50\u7f6e\u4fe1\u533a\u95f4\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\uff0c\u5bf9\u5b9e\u9645\u5e94\u7528\u4e2d\u56e0\u5b50\u63d0\u53d6\u65b9\u6cd5\u7684\u9009\u62e9\u5177\u6709\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2601.04107", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.04107", "abs": "https://arxiv.org/abs/2601.04107", "authors": ["Ruiyi Guo", "Bodong Zhang"], "title": "From Abstract Threats to Institutional Realities: A Comparative Semantic Network Analysis of AI Securitisation in the US, EU, and China", "comment": "Submitted to the 2026 ACM Conference on Fairness, Accountability, and Transparency (ACM FAccT)", "summary": "Artificial intelligence governance exhibits a striking paradox: while major jurisdictions converge rhetorically around concepts such as safety, risk, and accountability, their regulatory frameworks remain fundamentally divergent and mutually unintelligible. This paper argues that this fragmentation cannot be explained solely by geopolitical rivalry, institutional complexity, or instrument selection. Instead, it stems from how AI is constituted as an object of governance through distinct institutional logics. Integrating securitisation theory with the concept of the dispositif, we demonstrate that jurisdictions govern ontologically different objects under the same vocabulary. Using semantic network analysis of official policy texts from the European Union, the United States, and China (2023-2025), we trace how concepts like safety are embedded within divergent semantic architectures. Our findings reveal that the EU juridifies AI as a certifiable product through legal-bureaucratic logic; the US operationalises AI as an optimisable system through market-liberal logic; and China governs AI as socio-technical infrastructure through holistic state logic. We introduce the concept of structural incommensurability to describe this condition of ontological divergence masked by terminological convergence. This reframing challenges ethics-by-principles approaches to global AI governance, suggesting that coordination failures arise not from disagreement over values but from the absence of a shared reference object.", "AI": {"tldr": "AI\u6cbb\u7406\u5b58\u5728\u6096\u8bba\uff1a\u4e3b\u8981\u53f8\u6cd5\u7ba1\u8f96\u533a\u5728\u5b89\u5168\u3001\u98ce\u9669\u3001\u95ee\u8d23\u7b49\u6982\u5ff5\u4e0a\u8a00\u8f9e\u8d8b\u540c\uff0c\u4f46\u76d1\u7ba1\u6846\u67b6\u5374\u6839\u672c\u5206\u6b67\u4e14\u4e92\u4e0d\u7406\u89e3\u3002\u8fd9\u79cd\u788e\u7247\u5316\u6e90\u4e8eAI\u5982\u4f55\u901a\u8fc7\u4e0d\u540c\u7684\u5236\u5ea6\u903b\u8f91\u88ab\u6784\u5efa\u4e3a\u6cbb\u7406\u5bf9\u8c61\uff0c\u5bfc\u81f4\u4e0d\u540c\u53f8\u6cd5\u7ba1\u8f96\u533a\u5728\u76f8\u540c\u8bcd\u6c47\u4e0b\u6cbb\u7406\u7740\u672c\u4f53\u8bba\u4e0a\u4e0d\u540c\u7684\u5bf9\u8c61\u3002", "motivation": "\u89e3\u91ca\u4e3a\u4ec0\u4e48\u4e3b\u8981\u53f8\u6cd5\u7ba1\u8f96\u533a\uff08\u6b27\u76df\u3001\u7f8e\u56fd\u3001\u4e2d\u56fd\uff09\u5728AI\u6cbb\u7406\u4e0a\u8a00\u8f9e\u8d8b\u540c\u4f46\u5b9e\u9645\u76d1\u7ba1\u6846\u67b6\u5374\u5b58\u5728\u6839\u672c\u5206\u6b67\u3002\u6311\u6218\u4f20\u7edf\u89c2\u70b9\uff0c\u8ba4\u4e3a\u8fd9\u79cd\u5206\u6b67\u4e0d\u80fd\u4ec5\u7528\u5730\u7f18\u653f\u6cbb\u7ade\u4e89\u3001\u5236\u5ea6\u590d\u6742\u6027\u6216\u5de5\u5177\u9009\u62e9\u6765\u89e3\u91ca\u3002", "method": "\u6574\u5408\u5b89\u5168\u5316\u7406\u8bba\u548c\"dispositif\"\u6982\u5ff5\uff0c\u4f7f\u7528\u8bed\u4e49\u7f51\u7edc\u5206\u6790\u5bf9\u6b27\u76df\u3001\u7f8e\u56fd\u3001\u4e2d\u56fd\uff082023-2025\u5e74\uff09\u7684\u5b98\u65b9\u653f\u7b56\u6587\u672c\u8fdb\u884c\u5206\u6790\uff0c\u8ffd\u8e2a\"\u5b89\u5168\"\u7b49\u6982\u5ff5\u5982\u4f55\u5d4c\u5165\u4e0d\u540c\u7684\u8bed\u4e49\u67b6\u6784\u4e2d\u3002", "result": "\u53d1\u73b0\u6b27\u76df\u901a\u8fc7\u6cd5\u5f8b-\u5b98\u50da\u903b\u8f91\u5c06AI\u53f8\u6cd5\u5316\u4e3a\u53ef\u8ba4\u8bc1\u7684\u4ea7\u54c1\uff1b\u7f8e\u56fd\u901a\u8fc7\u5e02\u573a-\u81ea\u7531\u903b\u8f91\u5c06AI\u64cd\u4f5c\u5316\u4e3a\u53ef\u4f18\u5316\u7684\u7cfb\u7edf\uff1b\u4e2d\u56fd\u901a\u8fc7\u6574\u4f53\u56fd\u5bb6\u903b\u8f91\u5c06AI\u6cbb\u7406\u4e3a\u793e\u4f1a\u6280\u672f\u57fa\u7840\u8bbe\u65bd\u3002\u5f15\u5165\u4e86\"\u7ed3\u6784\u6027\u4e0d\u53ef\u901a\u7ea6\u6027\"\u6982\u5ff5\u6765\u63cf\u8ff0\u8fd9\u79cd\u672c\u4f53\u8bba\u5206\u6b67\u88ab\u672f\u8bed\u8d8b\u540c\u6240\u63a9\u76d6\u7684\u72b6\u51b5\u3002", "conclusion": "\u8fd9\u79cd\u91cd\u6784\u6311\u6218\u4e86\u57fa\u4e8e\u539f\u5219\u7684\u4f26\u7406\u65b9\u6cd5\u5bf9\u5168\u7403AI\u6cbb\u7406\u7684\u9002\u7528\u6027\uff0c\u8868\u660e\u534f\u8c03\u5931\u8d25\u4e0d\u662f\u6e90\u4e8e\u4ef7\u503c\u89c2\u5206\u6b67\uff0c\u800c\u662f\u6e90\u4e8e\u7f3a\u4e4f\u5171\u4eab\u7684\u53c2\u8003\u5bf9\u8c61\u3002\u4e0d\u540c\u53f8\u6cd5\u7ba1\u8f96\u533a\u5b9e\u9645\u4e0a\u5728\u6cbb\u7406\u7740\u4e0d\u540c\u7684\"AI\"\u5bf9\u8c61\u3002"}}
{"id": "2601.03475", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03475", "abs": "https://arxiv.org/abs/2601.03475", "authors": ["Ruiqi Deng", "Geoffrey Martin", "Tony Wang", "Gongbo Zhang", "Yi Liu", "Chunhua Weng", "Yanshan Wang", "Justin F Rousseau", "Yifan Peng"], "title": "CPGPrompt: Translating Clinical Guidelines into LLM-Executable Decision Support", "comment": null, "summary": "Clinical practice guidelines (CPGs) provide evidence-based recommendations for patient care; however, integrating them into Artificial Intelligence (AI) remains challenging. Previous approaches, such as rule-based systems, face significant limitations, including poor interpretability, inconsistent adherence to guidelines, and narrow domain applicability. To address this, we develop and validate CPGPrompt, an auto-prompting system that converts narrative clinical guidelines into large language models (LLMs).\n  Our framework translates CPGs into structured decision trees and utilizes an LLM to dynamically navigate them for patient case evaluation. Synthetic vignettes were generated across three domains (headache, lower back pain, and prostate cancer) and distributed into four categories to test different decision scenarios. System performance was assessed on both binary specialty-referral decisions and fine-grained pathway-classification tasks.\n  The binary specialty referral classification achieved consistently strong performance across all domains (F1: 0.85-1.00), with high recall (1.00 $\\pm$ 0.00). In contrast, multi-class pathway assignment showed reduced performance, with domain-specific variations: headache (F1: 0.47), lower back pain (F1: 0.72), and prostate cancer (F1: 0.77). Domain-specific performance differences reflected the structure of each guideline. The headache guideline highlighted challenges with negation handling. The lower back pain guideline required temporal reasoning. In contrast, prostate cancer pathways benefited from quantifiable laboratory tests, resulting in more reliable decision-making.", "AI": {"tldr": "CPGPrompt\uff1a\u4e00\u4e2a\u81ea\u52a8\u63d0\u793a\u7cfb\u7edf\uff0c\u5c06\u53d9\u8ff0\u6027\u4e34\u5e8a\u6307\u5357\u8f6c\u5316\u4e3aLLM\u53ef\u7528\u7684\u7ed3\u6784\u5316\u51b3\u7b56\u6811\uff0c\u7528\u4e8e\u60a3\u8005\u75c5\u4f8b\u8bc4\u4f30\uff0c\u5728\u4e13\u79d1\u8f6c\u8bca\u51b3\u7b56\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u591a\u7c7b\u8def\u5f84\u5206\u914d\u4e0a\u8868\u73b0\u6709\u5dee\u5f02\u3002", "motivation": "\u4e34\u5e8a\u5b9e\u8df5\u6307\u5357\uff08CPGs\uff09\u4e3a\u60a3\u8005\u62a4\u7406\u63d0\u4f9b\u5faa\u8bc1\u5efa\u8bae\uff0c\u4f46\u5c06\u5176\u6574\u5408\u5230\u4eba\u5de5\u667a\u80fd\u4e2d\u9762\u4e34\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\uff08\u5982\u57fa\u4e8e\u89c4\u5219\u7684\u7cfb\u7edf\uff09\u5b58\u5728\u53ef\u89e3\u91ca\u6027\u5dee\u3001\u6307\u5357\u4f9d\u4ece\u6027\u4e0d\u4e00\u81f4\u3001\u9886\u57df\u9002\u7528\u6027\u7a84\u7b49\u9650\u5236\u3002", "method": "\u5f00\u53d1CPGPrompt\u7cfb\u7edf\uff0c\u5c06CPGs\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u51b3\u7b56\u6811\uff0c\u5229\u7528LLM\u52a8\u6001\u5bfc\u822a\u51b3\u7b56\u6811\u8fdb\u884c\u60a3\u8005\u75c5\u4f8b\u8bc4\u4f30\u3002\u5728\u4e09\u4e2a\u9886\u57df\uff08\u5934\u75db\u3001\u8170\u75db\u3001\u524d\u5217\u817a\u764c\uff09\u751f\u6210\u5408\u6210\u75c5\u4f8b\uff0c\u6d4b\u8bd5\u4e0d\u540c\u51b3\u7b56\u573a\u666f\u3002", "result": "\u4e8c\u5143\u4e13\u79d1\u8f6c\u8bca\u5206\u7c7b\u5728\u6240\u6709\u9886\u57df\u8868\u73b0\u4e00\u81f4\u5f3a\u52b2\uff08F1\uff1a0.85-1.00\uff09\uff0c\u53ec\u56de\u7387\u9ad8\uff081.00\u00b10.00\uff09\u3002\u591a\u7c7b\u8def\u5f84\u5206\u914d\u8868\u73b0\u964d\u4f4e\uff0c\u5b58\u5728\u9886\u57df\u5dee\u5f02\uff1a\u5934\u75db\uff08F1\uff1a0.47\uff09\u3001\u8170\u75db\uff08F1\uff1a0.72\uff09\u3001\u524d\u5217\u817a\u764c\uff08F1\uff1a0.77\uff09\u3002", "conclusion": "CPGPrompt\u5728\u5c06\u53d9\u8ff0\u6027\u4e34\u5e8a\u6307\u5357\u8f6c\u5316\u4e3aLLM\u53ef\u64cd\u4f5c\u683c\u5f0f\u65b9\u9762\u6709\u6548\uff0c\u7279\u522b\u9002\u5408\u4e8c\u5143\u51b3\u7b56\u4efb\u52a1\u3002\u6027\u80fd\u5dee\u5f02\u53cd\u6620\u4e86\u4e0d\u540c\u6307\u5357\u7684\u7ed3\u6784\u7279\u70b9\uff0c\u4e3a\u672a\u6765\u6539\u8fdb\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2601.04101", "categories": ["econ.EM", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.04101", "abs": "https://arxiv.org/abs/2601.04101", "authors": ["Junnan He", "Jean-Marc Robin"], "title": "Ridge Estimation of High Dimensional Two-Way Fixed Effect Regression", "comment": null, "summary": "We study a ridge estimator for the high-dimensional two-way fixed effect regression model with a sparse bipartite network. We develop concentration inequalities showing that when the ridge parameters increase as the log of the network size, the bias, and the variance-covariance matrix of the vector of estimated fixed effects converge to deterministic equivalents that depend only on the expected network. We provide simulations and an application using administrative data on wages for worker-firm matches.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u9ad8\u7ef4\u53cc\u5411\u56fa\u5b9a\u6548\u5e94\u56de\u5f52\u6a21\u578b\u4e2d\u7684\u5cad\u4f30\u8ba1\u5668\uff0c\u8be5\u6a21\u578b\u5177\u6709\u7a00\u758f\u4e8c\u5206\u7f51\u7edc\u7ed3\u6784\u3002\u5f53\u5cad\u53c2\u6570\u968f\u7f51\u7edc\u89c4\u6a21\u5bf9\u6570\u589e\u957f\u65f6\uff0c\u4f30\u8ba1\u56fa\u5b9a\u6548\u5e94\u7684\u504f\u5dee\u548c\u65b9\u5dee\u534f\u65b9\u5dee\u77e9\u9635\u6536\u655b\u5230\u4ec5\u4f9d\u8d56\u4e8e\u671f\u671b\u7f51\u7edc\u7684\u786e\u5b9a\u6027\u7b49\u4ef7\u5f62\u5f0f\u3002", "motivation": "\u5728\u5177\u6709\u7a00\u758f\u4e8c\u5206\u7f51\u7edc\u7ed3\u6784\u7684\u9ad8\u7ef4\u53cc\u5411\u56fa\u5b9a\u6548\u5e94\u56de\u5f52\u6a21\u578b\u4e2d\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u4f30\u8ba1\u65b9\u6cd5\u3002\u4f20\u7edf\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u7f51\u7edc\u65f6\u9762\u4e34\u8ba1\u7b97\u548c\u7edf\u8ba1\u6311\u6218\uff0c\u5cad\u4f30\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u6b63\u5219\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5cad\u4f30\u8ba1\u5668\u5904\u7406\u9ad8\u7ef4\u53cc\u5411\u56fa\u5b9a\u6548\u5e94\u56de\u5f52\u6a21\u578b\uff0c\u7814\u7a76\u5f53\u5cad\u53c2\u6570\u968f\u7f51\u7edc\u89c4\u6a21\u5bf9\u6570\u589e\u957f\u65f6\u7684\u6e10\u8fd1\u6027\u8d28\u3002\u5f00\u53d1\u6d53\u5ea6\u4e0d\u7b49\u5f0f\u5206\u6790\u4f30\u8ba1\u91cf\u7684\u6536\u655b\u884c\u4e3a\u3002", "result": "\u5f53\u5cad\u53c2\u6570\u968f\u7f51\u7edc\u89c4\u6a21\u5bf9\u6570\u589e\u957f\u65f6\uff0c\u56fa\u5b9a\u6548\u5e94\u5411\u91cf\u7684\u504f\u5dee\u548c\u65b9\u5dee\u534f\u65b9\u5dee\u77e9\u9635\u6536\u655b\u5230\u4ec5\u4f9d\u8d56\u4e8e\u671f\u671b\u7f51\u7edc\u7684\u786e\u5b9a\u6027\u7b49\u4ef7\u5f62\u5f0f\u3002\u901a\u8fc7\u6a21\u62df\u548c\u5b9e\u9645\u5de5\u8d44\u6570\u636e\u5e94\u7528\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u3002", "conclusion": "\u5cad\u4f30\u8ba1\u5668\u4e3a\u9ad8\u7ef4\u7a00\u758f\u4e8c\u5206\u7f51\u7edc\u4e2d\u7684\u53cc\u5411\u56fa\u5b9a\u6548\u5e94\u56de\u5f52\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u5176\u6e10\u8fd1\u6027\u8d28\u826f\u597d\uff0c\u504f\u5dee\u548c\u65b9\u5dee\u534f\u65b9\u5dee\u77e9\u9635\u6536\u655b\u5230\u786e\u5b9a\u6027\u7b49\u4ef7\u5f62\u5f0f\uff0c\u4ec5\u4f9d\u8d56\u4e8e\u671f\u671b\u7f51\u7edc\u7ed3\u6784\u3002"}}
{"id": "2601.04175", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.04175", "abs": "https://arxiv.org/abs/2601.04175", "authors": ["Noam Kolt", "Nicholas Caputo", "Jack Boeglin", "Cullen O'Keefe", "Rishi Bommasani", "Stephen Casper", "Mariano-Florentino Cu\u00e9llar", "Noah Feldman", "Iason Gabriel", "Gillian K. Hadfield", "Lewis Hammond", "Peter Henderson", "Atoosa Kasirzadeh", "Seth Lazar", "Anka Reuel", "Kevin L. Wei", "Jonathan Zittrain"], "title": "Legal Alignment for Safe and Ethical AI", "comment": null, "summary": "Alignment of artificial intelligence (AI) encompasses the normative problem of specifying how AI systems should act and the technical problem of ensuring AI systems comply with those specifications. To date, AI alignment has generally overlooked an important source of knowledge and practice for grappling with these problems: law. In this paper, we aim to fill this gap by exploring how legal rules, principles, and methods can be leveraged to address problems of alignment and inform the design of AI systems that operate safely and ethically. This emerging field -- legal alignment -- focuses on three research directions: (1) designing AI systems to comply with the content of legal rules developed through legitimate institutions and processes, (2) adapting methods from legal interpretation to guide how AI systems reason and make decisions, and (3) harnessing legal concepts as a structural blueprint for confronting challenges of reliability, trust, and cooperation in AI systems. These research directions present new conceptual, empirical, and institutional questions, which include examining the specific set of laws that particular AI systems should follow, creating evaluations to assess their legal compliance in real-world settings, and developing governance frameworks to support the implementation of legal alignment in practice. Tackling these questions requires expertise across law, computer science, and other disciplines, offering these communities the opportunity to collaborate in designing AI for the better.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u6cd5\u5f8b\u5bf9\u9f50\"\u65b0\u9886\u57df\uff0c\u63a2\u8ba8\u5982\u4f55\u5229\u7528\u6cd5\u5f8b\u89c4\u5219\u3001\u539f\u5219\u548c\u65b9\u6cd5\u89e3\u51b3AI\u5bf9\u9f50\u95ee\u9898\uff0c\u786e\u4fddAI\u7cfb\u7edf\u5b89\u5168\u3001\u7b26\u5408\u4f26\u7406\u5730\u8fd0\u884c\u3002", "motivation": "\u5f53\u524dAI\u5bf9\u9f50\u7814\u7a76\u5ffd\u89c6\u4e86\u6cd5\u5f8b\u8fd9\u4e00\u91cd\u8981\u77e5\u8bc6\u6765\u6e90\u548c\u5b9e\u8df5\u7ecf\u9a8c\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5229\u7528\u6cd5\u5f8b\u8d44\u6e90\u89e3\u51b3AI\u7cfb\u7edf\u7684\u89c4\u8303\u5236\u5b9a\u548c\u6280\u672f\u5b9e\u73b0\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u6cd5\u5f8b\u5bf9\u9f50\u7684\u4e09\u4e2a\u7814\u7a76\u65b9\u5411\uff1a1) \u8bbe\u8ba1AI\u7cfb\u7edf\u9075\u5b88\u5408\u6cd5\u673a\u6784\u5236\u5b9a\u7684\u6cd5\u5f8b\u89c4\u5219\u5185\u5bb9\uff1b2) \u91c7\u7528\u6cd5\u5f8b\u89e3\u91ca\u65b9\u6cd5\u6307\u5bfcAI\u7cfb\u7edf\u7684\u63a8\u7406\u548c\u51b3\u7b56\uff1b3) \u5229\u7528\u6cd5\u5f8b\u6982\u5ff5\u4f5c\u4e3a\u5e94\u5bf9AI\u7cfb\u7edf\u53ef\u9760\u6027\u3001\u4fe1\u4efb\u548c\u5408\u4f5c\u6311\u6218\u7684\u7ed3\u6784\u84dd\u56fe\u3002", "result": "\u5efa\u7acb\u4e86\u6cd5\u5f8b\u5bf9\u9f50\u7684\u7814\u7a76\u6846\u67b6\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u6982\u5ff5\u6027\u3001\u7ecf\u9a8c\u6027\u548c\u5236\u5ea6\u6027\u95ee\u9898\uff0c\u5305\u62ec\u786e\u5b9aAI\u7cfb\u7edf\u5e94\u9075\u5faa\u7684\u5177\u4f53\u6cd5\u5f8b\u3001\u521b\u5efa\u8bc4\u4f30\u6cd5\u5f8b\u5408\u89c4\u6027\u7684\u65b9\u6cd5\u3001\u5f00\u53d1\u652f\u6301\u5b9e\u8df5\u5b9e\u65bd\u7684\u6cbb\u7406\u6846\u67b6\u3002", "conclusion": "\u6cd5\u5f8b\u5bf9\u9f50\u4e3a\u8de8\u5b66\u79d1\u5408\u4f5c\u63d0\u4f9b\u4e86\u65b0\u673a\u9047\uff0c\u9700\u8981\u6cd5\u5f8b\u3001\u8ba1\u7b97\u673a\u79d1\u5b66\u7b49\u9886\u57df\u7684\u4e13\u5bb6\u5171\u540c\u534f\u4f5c\uff0c\u8bbe\u8ba1\u66f4\u5b89\u5168\u3001\u66f4\u7b26\u5408\u4f26\u7406\u7684AI\u7cfb\u7edf\u3002"}}
{"id": "2601.03509", "categories": ["cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.03509", "abs": "https://arxiv.org/abs/2601.03509", "authors": ["Haochen Shi", "Xingdi Yuan", "Bang Liu"], "title": "Evolving Programmatic Skill Networks", "comment": null, "summary": "We study continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills. We introduce the Programmatic Skill Network (PSN), a framework in which skills are executable symbolic programs forming a compositional network that evolves through experience. PSN defines three core mechanisms instantiated via large language models: (1)REFLECT for structured fault localization over skill compositions, (2) progressive optimization with maturity-aware update gating that stabilizes reliable skills while maintaining plasticity for uncertain ones, and (3) canonical structural refactoring under rollback validation that maintains network compactness. We further show that PSN's learning dynamics exhibit structural parallels to neural network training. Experiments on MineDojo and Crafter demonstrate robust skill reuse, rapid adaptation, and strong generalization across open-ended task distributions.\\footnote{We plan to open-source the code.", "AI": {"tldr": "PSN\u6846\u67b6\u901a\u8fc7\u7b26\u53f7\u7a0b\u5e8f\u7f51\u7edc\u5b9e\u73b0\u6301\u7eed\u6280\u80fd\u5b66\u4e60\uff0c\u5229\u7528LLM\u8fdb\u884c\u6545\u969c\u5b9a\u4f4d\u3001\u6e10\u8fdb\u4f18\u5316\u548c\u7ed3\u6784\u91cd\u6784\uff0c\u5728\u5f00\u653e\u73af\u5883\u4e2d\u5c55\u793a\u5f3a\u5927\u6cdb\u5316\u80fd\u529b", "motivation": "\u89e3\u51b3\u5f00\u653e\u73af\u5883\u4e2d\u7684\u6301\u7eed\u6280\u80fd\u83b7\u53d6\u95ee\u9898\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u6784\u5efa\u3001\u7cbe\u70bc\u548c\u91cd\u7528\u4e0d\u65ad\u6269\u5c55\u7684\u53ef\u6267\u884c\u6280\u80fd\u5e93\uff0c\u5b9e\u73b0\u957f\u671f\u5b66\u4e60\u80fd\u529b", "method": "\u63d0\u51fa\u7a0b\u5e8f\u5316\u6280\u80fd\u7f51\u7edc(PSN)\uff0c\u5c06\u6280\u80fd\u8868\u793a\u4e3a\u53ef\u6267\u884c\u7b26\u53f7\u7a0b\u5e8f\uff0c\u901a\u8fc7LLM\u5b9e\u73b0\u4e09\u79cd\u6838\u5fc3\u673a\u5236\uff1aREFLECT\u6545\u969c\u5b9a\u4f4d\u3001\u6e10\u8fdb\u4f18\u5316\u4e0e\u6210\u719f\u5ea6\u611f\u77e5\u66f4\u65b0\u95e8\u63a7\u3001\u89c4\u8303\u7ed3\u6784\u91cd\u6784\u4e0e\u56de\u6eda\u9a8c\u8bc1", "result": "\u5728MineDojo\u548cCrafter\u73af\u5883\u4e2d\u5c55\u793a\u51fa\u5f3a\u5927\u7684\u6280\u80fd\u91cd\u7528\u3001\u5feb\u901f\u9002\u5e94\u80fd\u529b\u548c\u8de8\u5f00\u653e\u4efb\u52a1\u5206\u5e03\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u5b66\u4e60\u52a8\u6001\u4e0e\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u5177\u6709\u7ed3\u6784\u76f8\u4f3c\u6027", "conclusion": "PSN\u6846\u67b6\u4e3a\u5f00\u653e\u73af\u5883\u4e2d\u7684\u6301\u7eed\u6280\u80fd\u5b66\u4e60\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u7b26\u53f7\u7a0b\u5e8f\u7f51\u7edc\u5b9e\u73b0\u7a33\u5b9a\u5b66\u4e60\u4e0e\u6cdb\u5316\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b"}}
{"id": "2601.03523", "categories": ["cs.AI", "cs.DS"], "pdf": "https://arxiv.org/pdf/2601.03523", "abs": "https://arxiv.org/abs/2601.03523", "authors": ["Kengo Nakamura", "Masaaki Nishino", "Norihito Yasuda"], "title": "Variance Computation for Weighted Model Counting with Knowledge Compilation Approach", "comment": "25 pages; accepted for AAAI 2026 main track", "summary": "One of the most important queries in knowledge compilation is weighted model counting (WMC), which has been applied to probabilistic inference on various models, such as Bayesian networks. In practical situations on inference tasks, the model's parameters have uncertainty because they are often learned from data, and thus we want to compute the degree of uncertainty in the inference outcome. One possible approach is to regard the inference outcome as a random variable by introducing distributions for the parameters and evaluate the variance of the outcome. Unfortunately, the tractability of computing such a variance is hardly known. Motivated by this, we consider the problem of computing the variance of WMC and investigate this problem's tractability. First, we derive a polynomial time algorithm to evaluate the WMC variance when the input is given as a structured d-DNNF. Second, we prove the hardness of this problem for structured DNNFs, d-DNNFs, and FBDDs, which is intriguing because the latter two allow polynomial time WMC algorithms. Finally, we show an application that measures the uncertainty in the inference of Bayesian networks. We empirically show that our algorithm can evaluate the variance of the marginal probability on real-world Bayesian networks and analyze the impact of the variances of parameters on the variance of the marginal.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u52a0\u6743\u6a21\u578b\u8ba1\u6570(WMC)\u65b9\u5dee\u7684\u8ba1\u7b97\u95ee\u9898\uff0c\u9488\u5bf9\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u573a\u666f\uff0c\u63d0\u51fa\u4e86\u5728\u7ed3\u6784\u5316d-DNNF\u4e0a\u8ba1\u7b97\u65b9\u5dee\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u8be5\u95ee\u9898\u5728\u7ed3\u6784\u5316DNNF\u3001d-DNNF\u548cFBDD\u4e0a\u7684\u8ba1\u7b97\u56f0\u96be\u6027\u3002", "motivation": "\u5728\u5b9e\u9645\u63a8\u7406\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u53c2\u6570\u901a\u5e38\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u5f97\u5230\uff0c\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\u3002\u4e3a\u4e86\u8bc4\u4f30\u63a8\u7406\u7ed3\u679c\u7684\u4e0d\u786e\u5b9a\u6027\u7a0b\u5ea6\uff0c\u9700\u8981\u5c06\u63a8\u7406\u7ed3\u679c\u89c6\u4e3a\u968f\u673a\u53d8\u91cf\u5e76\u8ba1\u7b97\u5176\u65b9\u5dee\u3002\u7136\u800c\uff0c\u8ba1\u7b97\u8fd9\u79cd\u65b9\u5dee\u7684\u53ef\u5904\u7406\u6027\u5c1a\u672a\u660e\u786e\u3002", "method": "1. \u4e3a\u7ed3\u6784\u5316d-DNNF\u63a8\u5bfc\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u6765\u8ba1\u7b97WMC\u65b9\u5dee\uff1b2. \u8bc1\u660e\u4e86\u8be5\u95ee\u9898\u5728\u7ed3\u6784\u5316DNNF\u3001d-DNNF\u548cFBDD\u4e0a\u7684\u8ba1\u7b97\u56f0\u96be\u6027\uff1b3. \u5c06\u65b9\u6cd5\u5e94\u7528\u4e8e\u8d1d\u53f6\u65af\u7f51\u7edc\u63a8\u7406\u7684\u4e0d\u786e\u5b9a\u6027\u6d4b\u91cf\u3002", "result": "1. \u6210\u529f\u5f00\u53d1\u4e86\u5728\u7ed3\u6784\u5316d-DNNF\u4e0a\u8ba1\u7b97WMC\u65b9\u5dee\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff1b2. \u8bc1\u660e\u4e86\u8be5\u95ee\u9898\u5728\u7ed3\u6784\u5316DNNF\u3001d-DNNF\u548cFBDD\u4e0a\u662f\u56f0\u96be\u7684\uff0c\u8fd9\u5f88\u6709\u8da3\uff0c\u56e0\u4e3a\u540e\u4e24\u8005\u5141\u8bb8\u591a\u9879\u5f0f\u65f6\u95f4\u7684WMC\u8ba1\u7b97\uff1b3. \u5728\u771f\u5b9e\u4e16\u754c\u8d1d\u53f6\u65af\u7f51\u7edc\u4e0a\u6210\u529f\u8bc4\u4f30\u4e86\u8fb9\u9645\u6982\u7387\u7684\u65b9\u5dee\uff0c\u5e76\u5206\u6790\u4e86\u53c2\u6570\u65b9\u5dee\u5bf9\u8fb9\u9645\u65b9\u5dee\u7684\u5f71\u54cd\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86WMC\u65b9\u5dee\u8ba1\u7b97\u7684\u53ef\u5904\u7406\u6027\u95ee\u9898\uff0c\u4e3a\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u6982\u7387\u63a8\u7406\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u5de5\u5177\u3002\u867d\u7136\u5728\u67d0\u4e9b\u8868\u793a\u5f62\u5f0f\u4e0b\u8be5\u95ee\u9898\u662f\u56f0\u96be\u7684\uff0c\u4f46\u5728\u7ed3\u6784\u5316d-DNNF\u4e0a\u5b58\u5728\u9ad8\u6548\u7b97\u6cd5\uff0c\u53ef\u7528\u4e8e\u5b9e\u9645\u8d1d\u53f6\u65af\u7f51\u7edc\u63a8\u7406\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002"}}
{"id": "2601.03537", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.03537", "abs": "https://arxiv.org/abs/2601.03537", "authors": ["Di Wu", "Yanyan Zhao", "Xin Lu", "Mingzhe Li", "Bing Qin"], "title": "STAR-S: Improving Safety Alignment through Self-Taught Reasoning on Safety Rules", "comment": "19 pages,4 figures", "summary": "Defending against jailbreak attacks is crucial for the safe deployment of Large Language Models (LLMs). Recent research has attempted to improve safety by training models to reason over safety rules before responding. However, a key issue lies in determining what form of safety reasoning effectively defends against jailbreak attacks, which is difficult to explicitly design or directly obtain. To address this, we propose \\textbf{STAR-S} (\\textbf{S}elf-\\textbf{TA}ught \\textbf{R}easoning based on \\textbf{S}afety rules), a framework that integrates the learning of safety rule reasoning into a self-taught loop. The core of STAR-S involves eliciting reasoning and reflection guided by safety rules, then leveraging fine-tuning to enhance safety reasoning. Repeating this process creates a synergistic cycle. Improvements in the model's reasoning and interpretation of safety rules allow it to produce better reasoning data under safety rule prompts, which is then utilized for further training. Experiments show that STAR-S effectively defends against jailbreak attacks, outperforming baselines. Code is available at: https://github.com/pikepokenew/STAR_S.git.", "AI": {"tldr": "STAR-S\u6846\u67b6\u901a\u8fc7\u81ea\u5b66\u4e60\u5faa\u73af\u589e\u5f3aLLM\u7684\u5b89\u5168\u89c4\u5219\u63a8\u7406\u80fd\u529b\uff0c\u6709\u6548\u9632\u5fa1\u8d8a\u72f1\u653b\u51fb", "motivation": "\u5f53\u524dLLM\u5b89\u5168\u9632\u5fa1\u9762\u4e34\u6311\u6218\uff1a\u867d\u7136\u5df2\u6709\u7814\u7a76\u5c1d\u8bd5\u901a\u8fc7\u8bad\u7ec3\u6a21\u578b\u5728\u54cd\u5e94\u524d\u8fdb\u884c\u5b89\u5168\u89c4\u5219\u63a8\u7406\u6765\u63d0\u5347\u5b89\u5168\u6027\uff0c\u4f46\u96be\u4ee5\u660e\u786e\u8bbe\u8ba1\u6216\u76f4\u63a5\u83b7\u53d6\u6709\u6548\u7684\u5b89\u5168\u63a8\u7406\u5f62\u5f0f\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u81ea\u52a8\u5b66\u4e60\u6709\u6548\u7684\u5b89\u5168\u63a8\u7406\u673a\u5236\u3002", "method": "\u63d0\u51faSTAR-S\u6846\u67b6\uff0c\u5c06\u5b89\u5168\u89c4\u5219\u63a8\u7406\u5b66\u4e60\u96c6\u6210\u5230\u81ea\u5b66\u4e60\u5faa\u73af\u4e2d\u3002\u6838\u5fc3\u5305\u62ec\uff1a1) \u5728\u5b89\u5168\u89c4\u5219\u6307\u5bfc\u4e0b\u5f15\u53d1\u63a8\u7406\u548c\u53cd\u601d\uff1b2) \u901a\u8fc7\u5fae\u8c03\u589e\u5f3a\u5b89\u5168\u63a8\u7406\u80fd\u529b\uff1b3) \u91cd\u590d\u6b64\u8fc7\u7a0b\u5f62\u6210\u534f\u540c\u5faa\u73af\u3002\u6a21\u578b\u63a8\u7406\u548c\u5b89\u5168\u89c4\u5219\u89e3\u91ca\u80fd\u529b\u7684\u63d0\u5347\u4f7f\u5176\u80fd\u4ea7\u751f\u66f4\u597d\u7684\u63a8\u7406\u6570\u636e\uff0c\u7528\u4e8e\u8fdb\u4e00\u6b65\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSTAR-S\u80fd\u6709\u6548\u9632\u5fa1\u8d8a\u72f1\u653b\u51fb\uff0c\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "STAR-S\u6846\u67b6\u901a\u8fc7\u81ea\u5b66\u4e60\u5faa\u73af\u589e\u5f3aLLM\u7684\u5b89\u5168\u89c4\u5219\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u9632\u5fa1\u8d8a\u72f1\u653b\u51fb\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.03550", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03550", "abs": "https://arxiv.org/abs/2601.03550", "authors": ["Zhizhang Fu", "Yuancheng Gu", "Chenkai Hu", "Hanmeng Liu", "Yue Zhang"], "title": "ReEfBench: Quantifying the Reasoning Efficiency of LLMs", "comment": null, "summary": "Test-time scaling has enabled Large Language Models (LLMs) to tackle complex reasoning, yet the limitations of current Chain-of-Thought (CoT) evaluation obscures whether performance gains stem from genuine reasoning or mere verbosity. To address this, (1) we propose a novel neuro-symbolic framework for the non-intrusive, comprehensive process-centric evaluation of reasoning. (2) Through this lens, we identify four distinct behavioral prototypes and diagnose the failure modes. (3) We examine the impact of inference mode, training strategy, and model scale. Our analysis reveals that extended token generation is not a prerequisite for deep reasoning. Furthermore, we reveal critical constraints: mixing long and short CoT data in training risks in premature saturation and collapse, while distillation into smaller models captures behavioral length but fails to replicate logical efficacy due to intrinsic capacity limits.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\u8bc4\u4f30LLM\u63a8\u7406\u8fc7\u7a0b\uff0c\u53d1\u73b0\u63a8\u7406\u6df1\u5ea6\u4e0d\u4f9d\u8d56\u751f\u6210\u957f\u5ea6\uff0c\u6df7\u5408\u8bad\u7ec3\u6570\u636e\u4f1a\u5bfc\u81f4\u8fc7\u65e9\u9971\u548c\uff0c\u5c0f\u6a21\u578b\u84b8\u998f\u65e0\u6cd5\u590d\u5236\u903b\u8f91\u6548\u80fd\u3002", "motivation": "\u5f53\u524dCoT\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff0c\u65e0\u6cd5\u533a\u5206\u6027\u80fd\u63d0\u5347\u662f\u6765\u81ea\u771f\u5b9e\u63a8\u7406\u8fd8\u662f\u4ec5\u4ec5\u589e\u52a0\u8f93\u51fa\u957f\u5ea6\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8fc7\u7a0b\u4e2d\u5fc3\u5316\u8bc4\u4f30\u6846\u67b6\u6765\u7406\u89e3LLM\u63a8\u7406\u673a\u5236\u3002", "method": "\u63d0\u51fa\u975e\u4fb5\u5165\u5f0f\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\u8fdb\u884c\u63a8\u7406\u8fc7\u7a0b\u8bc4\u4f30\uff0c\u8bc6\u522b\u56db\u79cd\u884c\u4e3a\u539f\u578b\uff0c\u5206\u6790\u63a8\u7406\u6a21\u5f0f\u3001\u8bad\u7ec3\u7b56\u7565\u548c\u6a21\u578b\u89c4\u6a21\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u751f\u6210\u957ftoken\u4e0d\u662f\u6df1\u5ea6\u63a8\u7406\u7684\u5fc5\u8981\u6761\u4ef6\uff1b\u6df7\u5408\u957f\u77edCoT\u8bad\u7ec3\u6570\u636e\u4f1a\u5bfc\u81f4\u8fc7\u65e9\u9971\u548c\u548c\u5d29\u6e83\uff1b\u5c0f\u6a21\u578b\u84b8\u998f\u80fd\u590d\u5236\u884c\u4e3a\u957f\u5ea6\u4f46\u65e0\u6cd5\u8fbe\u5230\u903b\u8f91\u6548\u80fd\u3002", "conclusion": "\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u7406\u89e3LLM\u63a8\u7406\uff0c\u751f\u6210\u957f\u5ea6\u4e0d\u7b49\u4e8e\u63a8\u7406\u8d28\u91cf\uff0c\u8bad\u7ec3\u6570\u636e\u6df7\u5408\u548c\u6a21\u578b\u5bb9\u91cf\u9650\u5236\u662f\u5f71\u54cd\u63a8\u7406\u80fd\u529b\u7684\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2601.03555", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03555", "abs": "https://arxiv.org/abs/2601.03555", "authors": ["Yuxuan Jiang", "Francis Ferraro"], "title": "SCRIBE: Structured Mid-Level Supervision for Tool-Using Language Models", "comment": null, "summary": "Training reliable tool-augmented agents remains a significant challenge, largely due to the difficulty of credit assignment in multi-step reasoning. While process-level reward models offer a promising direction, existing LLM-based judges often produce noisy and inconsistent signals because they lack fine-grained, task-specific rubrics to distinguish high-level planning from low-level execution. In this work, we introduce SCRIBE (Skill-Conditioned Reward with Intermediate Behavioral Evaluation), a reinforcement learning framework that intervenes at a novel mid-level abstraction. SCRIBE grounds reward modeling in a curated library of skill prototypes, transforming open-ended LLM evaluation into a constrained verification problem. By routing each subgoal to a corresponding prototype, the reward model is equipped with precise, structured rubrics that substantially reduce reward variance.\n  Experimental results show that SCRIBE achieves state-of-the-art performance across a range of reasoning and tool-use benchmarks. In particular, it improves the AIME25 accuracy of a Qwen3-4B model from 43.3% to 63.3%, and significantly increases success rates in complex multi-turn tool interactions.\n  Further analysis of training dynamics reveals a co-evolution across abstraction levels, where mastery of mid-level skills consistently precedes the emergence of effective high-level planning behaviors. Finally, we demonstrate that SCRIBE is additive to low-level tool optimizations, providing a scalable and complementary pathway toward more autonomous and reliable tool-using agents.", "AI": {"tldr": "SCRIBE\uff1a\u57fa\u4e8e\u6280\u80fd\u539f\u578b\u5e93\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4e2d\u95f4\u884c\u4e3a\u8bc4\u4f30\u51cf\u5c11\u5956\u52b1\u65b9\u5dee\uff0c\u63d0\u5347\u5de5\u5177\u589e\u5f3a\u4ee3\u7406\u7684\u591a\u6b65\u63a8\u7406\u80fd\u529b", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u5956\u52b1\u6a21\u578b\u5728\u5de5\u5177\u589e\u5f3a\u4ee3\u7406\u8bad\u7ec3\u4e2d\u4ea7\u751f\u566a\u58f0\u548c\u4e0d\u4e00\u81f4\u7684\u4fe1\u53f7\uff0c\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u3001\u4efb\u52a1\u7279\u5b9a\u7684\u8bc4\u4f30\u6807\u51c6\u6765\u533a\u5206\u9ad8\u5c42\u89c4\u5212\u4e0e\u4f4e\u5c42\u6267\u884c", "method": "\u5f15\u5165SCRIBE\u6846\u67b6\uff0c\u5728\u4e2d\u95f4\u62bd\u8c61\u5c42\u8fdb\u884c\u5e72\u9884\uff0c\u57fa\u4e8e\u6280\u80fd\u539f\u578b\u5e93\u8fdb\u884c\u5956\u52b1\u5efa\u6a21\uff0c\u5c06\u5f00\u653e\u5f0fLLM\u8bc4\u4f30\u8f6c\u5316\u4e3a\u7ea6\u675f\u9a8c\u8bc1\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u5b50\u76ee\u6807\u8def\u7531\u5230\u76f8\u5e94\u539f\u578b\u6765\u63d0\u4f9b\u7ed3\u6784\u5316\u8bc4\u4f30\u6807\u51c6", "result": "\u5728\u591a\u4e2a\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5c06Qwen3-4B\u6a21\u578b\u7684AIME25\u51c6\u786e\u7387\u4ece43.3%\u63d0\u5347\u81f363.3%\uff0c\u663e\u8457\u63d0\u9ad8\u590d\u6742\u591a\u8f6e\u5de5\u5177\u4ea4\u4e92\u7684\u6210\u529f\u7387", "conclusion": "SCRIBE\u5c55\u793a\u4e86\u8de8\u62bd\u8c61\u5c42\u7684\u534f\u540c\u6f14\u5316\uff0c\u4e2d\u5c42\u7ea7\u6280\u80fd\u638c\u63e1\u5148\u4e8e\u6709\u6548\u9ad8\u5c42\u89c4\u5212\u884c\u4e3a\u7684\u51fa\u73b0\uff0c\u4e14\u4e0e\u4f4e\u5c42\u5de5\u5177\u4f18\u5316\u4e92\u8865\uff0c\u4e3a\u66f4\u81ea\u4e3b\u53ef\u9760\u7684\u5de5\u5177\u4f7f\u7528\u4ee3\u7406\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u8def\u5f84"}}
{"id": "2601.03595", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.03595", "abs": "https://arxiv.org/abs/2601.03595", "authors": ["Yi Fang", "Wenjie Wang", "Mingfeng Xue", "Boyi Deng", "Fengli Xu", "Dayiheng Liu", "Fuli Feng"], "title": "Controllable LLM Reasoning via Sparse Autoencoder-Based Steering", "comment": "Under Review", "summary": "Large Reasoning Models (LRMs) exhibit human-like cognitive reasoning strategies (e.g. backtracking, cross-verification) during reasoning process, which improves their performance on complex tasks. Currently, reasoning strategies are autonomously selected by LRMs themselves. However, such autonomous selection often produces inefficient or even erroneous reasoning paths. To make reasoning more reliable and flexible, it is important to develop methods for controlling reasoning strategies. Existing methods struggle to control fine-grained reasoning strategies due to conceptual entanglement in LRMs' hidden states. To address this, we leverage Sparse Autoencoders (SAEs) to decompose strategy-entangled hidden states into a disentangled feature space. To identify the few strategy-specific features from the vast pool of SAE features, we propose SAE-Steering, an efficient two-stage feature identification pipeline. SAE-Steering first recalls features that amplify the logits of strategy-specific keywords, filtering out over 99\\% of features, and then ranks the remaining features by their control effectiveness. Using the identified strategy-specific features as control vectors, SAE-Steering outperforms existing methods by over 15\\% in control effectiveness. Furthermore, controlling reasoning strategies can redirect LRMs from erroneous paths to correct ones, achieving a 7\\% absolute accuracy improvement.", "AI": {"tldr": "SAE-Steering\uff1a\u5229\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5206\u89e3LRM\u9690\u85cf\u72b6\u6001\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u7279\u5f81\u8bc6\u522b\u6d41\u7a0b\u63a7\u5236\u63a8\u7406\u7b56\u7565\uff0c\u63d0\u5347\u63a7\u5236\u6548\u679c\u548c\u4efb\u52a1\u51c6\u786e\u6027", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u81ea\u4e3b\u9009\u62e9\u63a8\u7406\u7b56\u7565\u5e38\u5bfc\u81f4\u4f4e\u6548\u6216\u9519\u8bef\u8def\u5f84\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u63a7\u5236\u7ec6\u7c92\u5ea6\u63a8\u7406\u7b56\u7565\uff0c\u56e0\u4e3a\u9690\u85cf\u72b6\u6001\u4e2d\u5b58\u5728\u6982\u5ff5\u7ea0\u7f20\u95ee\u9898", "method": "\u4f7f\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5206\u89e3\u7b56\u7565\u7ea0\u7f20\u7684\u9690\u85cf\u72b6\u6001\u4e3a\u89e3\u8026\u7279\u5f81\u7a7a\u95f4\uff1b\u63d0\u51faSAE-Steering\u4e24\u9636\u6bb5\u7279\u5f81\u8bc6\u522b\u6d41\u7a0b\uff1a\u5148\u901a\u8fc7\u7b56\u7565\u5173\u952e\u8bcdlogits\u653e\u5927\u53ec\u56de\u7279\u5f81\uff08\u8fc7\u6ee499%\u4ee5\u4e0a\uff09\uff0c\u518d\u6309\u63a7\u5236\u6548\u679c\u6392\u5e8f\uff1b\u7528\u8bc6\u522b\u51fa\u7684\u7b56\u7565\u7279\u5b9a\u7279\u5f81\u4f5c\u4e3a\u63a7\u5236\u5411\u91cf", "result": "SAE-Steering\u5728\u63a7\u5236\u6548\u679c\u4e0a\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u5347\u8d85\u8fc715%\uff1b\u63a7\u5236\u63a8\u7406\u7b56\u7565\u53ef\u5c06LRM\u4ece\u9519\u8bef\u8def\u5f84\u91cd\u5b9a\u5411\u5230\u6b63\u786e\u8def\u5f84\uff0c\u5b9e\u73b07%\u7684\u7edd\u5bf9\u51c6\u786e\u7387\u63d0\u5347", "conclusion": "\u901a\u8fc7\u89e3\u8026\u9690\u85cf\u72b6\u6001\u5e76\u8bc6\u522b\u7b56\u7565\u7279\u5b9a\u7279\u5f81\uff0cSAE-Steering\u80fd\u6709\u6548\u63a7\u5236\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u7b56\u7565\uff0c\u63d0\u9ad8\u63a8\u7406\u53ef\u9760\u6027\u548c\u7075\u6d3b\u6027"}}
{"id": "2601.03604", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03604", "abs": "https://arxiv.org/abs/2601.03604", "authors": ["Chuanliu Fan", "Zicheng Ma", "Huanran Meng", "Aijia Zhang", "Wenjie Du", "Jun Zhang", "Yi Qin Gao", "Ziqiang Cao", "Guohong Fu"], "title": "Interleaved Tool-Call Reasoning for Protein Function Understanding", "comment": null, "summary": "Recent advances in large language models (LLMs) have highlighted the effectiveness of chain-of-thought reasoning in symbolic domains such as mathematics and programming. However, our study shows that directly transferring such text-based reasoning paradigms to protein function understanding is ineffective: reinforcement learning mainly amplifies superficial keyword patterns while failing to introduce new biological knowledge, resulting in limited generalization. We argue that protein function prediction is a knowledge-intensive scientific task that fundamentally relies on external biological priors and computational tools rather than purely internal reasoning. To address this gap, we propose PFUA, a tool-augmented protein reasoning agent that unifies problem decomposition, tool invocation, and grounded answer generation. Instead of relying on long unconstrained reasoning traces, PFUA integrates domain-specific tools to produce verifiable intermediate evidence. Experiments on four benchmarks demonstrate that PFUA consistently outperforms text-only reasoning models with an average performance improvement of 103%.", "AI": {"tldr": "PFUA\u662f\u4e00\u4e2a\u5de5\u5177\u589e\u5f3a\u7684\u86cb\u767d\u8d28\u63a8\u7406\u4ee3\u7406\uff0c\u901a\u8fc7\u6574\u5408\u9886\u57df\u7279\u5b9a\u5de5\u5177\u800c\u975e\u7eaf\u6587\u672c\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u86cb\u767d\u8d28\u529f\u80fd\u9884\u6d4b\u6027\u80fd", "motivation": "\u7814\u7a76\u53d1\u73b0\u76f4\u63a5\u5c06\u6587\u672c\u63a8\u7406\u8303\u5f0f\uff08\u5982\u601d\u7ef4\u94fe\uff09\u8fc1\u79fb\u5230\u86cb\u767d\u8d28\u529f\u80fd\u7406\u89e3\u9886\u57df\u6548\u679c\u4e0d\u4f73\uff0c\u56e0\u4e3a\u86cb\u767d\u8d28\u529f\u80fd\u9884\u6d4b\u662f\u77e5\u8bc6\u5bc6\u96c6\u578b\u7684\u79d1\u5b66\u4efb\u52a1\uff0c\u9700\u8981\u5916\u90e8\u751f\u7269\u5b66\u5148\u9a8c\u77e5\u8bc6\u548c\u8ba1\u7b97\u5de5\u5177\u800c\u975e\u7eaf\u5185\u90e8\u63a8\u7406", "method": "\u63d0\u51faPFUA\u5de5\u5177\u589e\u5f3a\u7684\u86cb\u767d\u8d28\u63a8\u7406\u4ee3\u7406\uff0c\u7edf\u4e00\u95ee\u9898\u5206\u89e3\u3001\u5de5\u5177\u8c03\u7528\u548c\u57fa\u4e8e\u8bc1\u636e\u7684\u7b54\u6848\u751f\u6210\uff0c\u901a\u8fc7\u6574\u5408\u9886\u57df\u7279\u5b9a\u5de5\u5177\u4ea7\u751f\u53ef\u9a8c\u8bc1\u7684\u4e2d\u95f4\u8bc1\u636e", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPFUA\u6301\u7eed\u4f18\u4e8e\u7eaf\u6587\u672c\u63a8\u7406\u6a21\u578b\uff0c\u5e73\u5747\u6027\u80fd\u63d0\u5347103%", "conclusion": "\u86cb\u767d\u8d28\u529f\u80fd\u9884\u6d4b\u9700\u8981\u6574\u5408\u9886\u57df\u5de5\u5177\u800c\u975e\u7eaf\u6587\u672c\u63a8\u7406\uff0cPFUA\u901a\u8fc7\u5de5\u5177\u589e\u5f3a\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u8fd9\u4e00\u6311\u6218"}}
{"id": "2601.03624", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03624", "abs": "https://arxiv.org/abs/2601.03624", "authors": ["Zoran Milosevic", "Fethi Rabhi"], "title": "Architecting Agentic Communities using Design Patterns", "comment": "supplementary material accompanying this paper is also attached .. its title is \"Complete Agentic AI Design Patterns Catalogue\"", "summary": "The rapid evolution of Large Language Models (LLM) and subsequent Agentic AI technologies requires systematic architectural guidance for building sophisticated, production-grade systems. This paper presents an approach for architecting such systems using design patterns derived from enterprise distributed systems standards, formal methods, and industry practice. We classify these patterns into three tiers: LLM Agents (task-specific automation), Agentic AI (adaptive goal-seekers), and Agentic Communities (organizational frameworks where AI agents and human participants coordinate through formal roles, protocols, and governance structures). We focus on Agentic Communities - coordination frameworks encompassing LLM Agents, Agentic AI entities, and humans - most relevant for enterprise and industrial applications. Drawing on established coordination principles from distributed systems, we ground these patterns in a formal framework that specifies collaboration agreements where AI agents and humans fill roles within governed ecosystems. This approach provides both practical guidance and formal verification capabilities, enabling expression of organizational, legal, and ethical rules through accountability mechanisms that ensure operational and verifiable governance of inter-agent communication, negotiation, and intent modeling. We validate this framework through a clinical trial matching case study. Our goal is to provide actionable guidance to practitioners while maintaining the formal rigor essential for enterprise deployment in dynamic, multi-agent ecosystems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u57fa\u4e8e\u4f01\u4e1a\u5206\u5e03\u5f0f\u7cfb\u7edf\u6807\u51c6\u3001\u5f62\u5f0f\u5316\u65b9\u6cd5\u548c\u884c\u4e1a\u5b9e\u8df5\u7684AI\u667a\u80fd\u4f53\u7cfb\u7edf\u67b6\u6784\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u5206\u4e3aLLM\u667a\u80fd\u4f53\u3001Agentic AI\u548c\u667a\u80fd\u4f53\u793e\u533a\u4e09\u4e2a\u5c42\u6b21\uff0c\u91cd\u70b9\u5173\u6ce8\u667a\u80fd\u4f53\u793e\u533a\u4f5c\u4e3a\u4f01\u4e1a\u5e94\u7528\u7684\u6838\u5fc3\u534f\u8c03\u6846\u67b6\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u548c\u667a\u80fd\u4f53AI\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u67b6\u6784\u6307\u5bfc\u6765\u6784\u5efa\u590d\u6742\u7684\u751f\u4ea7\u7ea7\u7cfb\u7edf\u3002\u5f53\u524d\u7f3a\u4e4f\u57fa\u4e8e\u4f01\u4e1a\u5206\u5e03\u5f0f\u7cfb\u7edf\u6807\u51c6\u548c\u5f62\u5f0f\u5316\u65b9\u6cd5\u7684\u7cfb\u7edf\u6027\u67b6\u6784\u6a21\u5f0f\u3002", "method": "\u4ece\u4f01\u4e1a\u5206\u5e03\u5f0f\u7cfb\u7edf\u6807\u51c6\u3001\u5f62\u5f0f\u5316\u65b9\u6cd5\u548c\u884c\u4e1a\u5b9e\u8df5\u4e2d\u63d0\u53d6\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u5206\u4e3a\u4e09\u4e2a\u5c42\u6b21\uff1aLLM\u667a\u80fd\u4f53\uff08\u4efb\u52a1\u7279\u5b9a\u81ea\u52a8\u5316\uff09\u3001Agentic AI\uff08\u81ea\u9002\u5e94\u76ee\u6807\u5bfb\u6c42\u8005\uff09\u548c\u667a\u80fd\u4f53\u793e\u533a\uff08\u7ec4\u7ec7\u6846\u67b6\uff09\u3002\u91cd\u70b9\u5173\u6ce8\u667a\u80fd\u4f53\u793e\u533a\uff0c\u5efa\u7acb\u5f62\u5f0f\u5316\u6846\u67b6\u6765\u89c4\u8303AI\u667a\u80fd\u4f53\u4e0e\u4eba\u7c7b\u5728\u6cbb\u7406\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u89d2\u8272\u534f\u4f5c\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u5b9e\u7528\u6307\u5bfc\u548c\u5f62\u5f0f\u5316\u9a8c\u8bc1\u80fd\u529b\u7684\u6846\u67b6\uff0c\u80fd\u591f\u901a\u8fc7\u95ee\u8d23\u673a\u5236\u8868\u8fbe\u7ec4\u7ec7\u3001\u6cd5\u5f8b\u548c\u4f26\u7406\u89c4\u5219\uff0c\u786e\u4fdd\u667a\u80fd\u4f53\u95f4\u901a\u4fe1\u3001\u534f\u5546\u548c\u610f\u56fe\u5efa\u6a21\u7684\u53ef\u64cd\u4f5c\u548c\u53ef\u9a8c\u8bc1\u6cbb\u7406\u3002\u901a\u8fc7\u4e34\u5e8a\u8bd5\u9a8c\u5339\u914d\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4f01\u4e1a\u90e8\u7f72\u5728\u52a8\u6001\u591a\u667a\u80fd\u4f53\u751f\u6001\u7cfb\u7edf\u4e2d\u6240\u5fc5\u9700\u7684\u5f62\u5f0f\u5316\u4e25\u8c28\u6027\uff0c\u4e3a\u6784\u5efa\u590d\u6742\u7684\u751f\u4ea7\u7ea7AI\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u67b6\u6784\u65b9\u6cd5\u3002"}}
{"id": "2601.03662", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03662", "abs": "https://arxiv.org/abs/2601.03662", "authors": ["Su-Hyeon Kim", "Hyundong Jin", "Yejin Lee", "Yo-Sub Han"], "title": "How Does the Thinking Step Influence Model Safety? An Entropy-based Safety Reminder for LRMs", "comment": null, "summary": "Large Reasoning Models (LRMs) achieve remarkable success through explicit thinking steps, yet the thinking steps introduce a novel risk by potentially amplifying unsafe behaviors. Despite this vulnerability, conventional defense mechanisms remain ineffective as they overlook the unique reasoning dynamics of LRMs. In this work, we find that the emergence of safe-reminding phrases within thinking steps plays a pivotal role in ensuring LRM safety. Motivated by this finding, we propose SafeRemind, a decoding-time defense method that dynamically injects safe-reminding phrases into thinking steps. By leveraging entropy triggers to intervene at decision-locking points, SafeRemind redirects potentially harmful trajectories toward safer outcomes without requiring any parameter updates. Extensive evaluations across five LRMs and six benchmarks demonstrate that SafeRemind substantially enhances safety, achieving improvements of up to 45.5%p while preserving core reasoning utility.", "AI": {"tldr": "SafeRemind\uff1a\u4e00\u79cd\u901a\u8fc7\u5728\u63a8\u7406\u6b65\u9aa4\u4e2d\u52a8\u6001\u6ce8\u5165\u5b89\u5168\u63d0\u9192\u77ed\u8bed\u6765\u589e\u5f3a\u5927\u578b\u63a8\u7406\u6a21\u578b\u5b89\u5168\u6027\u7684\u89e3\u7801\u65f6\u9632\u5fa1\u65b9\u6cd5", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u901a\u8fc7\u663e\u5f0f\u63a8\u7406\u6b65\u9aa4\u53d6\u5f97\u663e\u8457\u6210\u529f\uff0c\u4f46\u8fd9\u4e9b\u6b65\u9aa4\u53ef\u80fd\u653e\u5927\u4e0d\u5b89\u5168\u884c\u4e3a\u3002\u4f20\u7edf\u9632\u5fa1\u673a\u5236\u56e0\u5ffd\u89c6LRM\u72ec\u7279\u7684\u63a8\u7406\u52a8\u6001\u800c\u65e0\u6548\uff0c\u7814\u7a76\u53d1\u73b0\u63a8\u7406\u6b65\u9aa4\u4e2d\u51fa\u73b0\u7684\u5b89\u5168\u63d0\u9192\u77ed\u8bed\u5bf9\u786e\u4fddLRM\u5b89\u5168\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51faSafeRemind\u89e3\u7801\u65f6\u9632\u5fa1\u65b9\u6cd5\uff0c\u5229\u7528\u71b5\u89e6\u53d1\u5668\u5728\u51b3\u7b56\u9501\u5b9a\u70b9\u8fdb\u884c\u5e72\u9884\uff0c\u52a8\u6001\u5c06\u5b89\u5168\u63d0\u9192\u77ed\u8bed\u6ce8\u5165\u63a8\u7406\u6b65\u9aa4\uff0c\u65e0\u9700\u53c2\u6570\u66f4\u65b0\u5373\u53ef\u5c06\u6f5c\u5728\u6709\u5bb3\u8f68\u8ff9\u91cd\u5b9a\u5411\u5230\u66f4\u5b89\u5168\u7684\u7ed3\u679c\u3002", "result": "\u57285\u4e2aLRM\u548c6\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cSafeRemind\u663e\u8457\u589e\u5f3a\u5b89\u5168\u6027\uff0c\u63d0\u5347\u5e45\u5ea6\u9ad8\u8fbe45.5\u4e2a\u767e\u5206\u70b9\uff0c\u540c\u65f6\u4fdd\u6301\u6838\u5fc3\u63a8\u7406\u6548\u7528\u3002", "conclusion": "SafeRemind\u901a\u8fc7\u5229\u7528\u63a8\u7406\u6b65\u9aa4\u4e2d\u7684\u5b89\u5168\u63d0\u9192\u77ed\u8bed\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u5b9e\u7528\u7684LRM\u5b89\u5168\u9632\u5fa1\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u63d0\u5347\u5b89\u5168\u6027\u3002"}}
{"id": "2601.03672", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.03672", "abs": "https://arxiv.org/abs/2601.03672", "authors": ["Chen Zhang", "Kepu Zhang", "Jiatong Zhang", "Xiao Zhang", "Jun Xu"], "title": "Sandwich Reasoning: An Answer-Reasoning-Answer Approach for Low-Latency Query Correction", "comment": null, "summary": "Query correction is a critical entry point in modern search pipelines, demanding high accuracy strictly within real-time latency constraints. Chain-of-Thought (CoT) reasoning improves accuracy but incurs prohibitive latency for real-time query correction. A potential solution is to output an answer before reasoning to reduce latency; however, under autoregressive decoding, the early answer is independent of subsequent reasoning, preventing the model from leveraging its reasoning capability to improve accuracy. To address this issue, we propose Sandwich Reasoning (SandwichR), a novel approach that explicitly aligns a fast initial answer with post-hoc reasoning, enabling low-latency query correction without sacrificing reasoning-aware accuracy. SandwichR follows an Answer-Reasoning-Answer paradigm, producing an initial correction, an explicit reasoning process, and a final refined correction. To align the initial answer with post-reasoning insights, we design a consistency-aware reinforcement learning (RL) strategy: a dedicated consistency reward enforces alignment between the initial and final corrections, while margin-based rejection sampling prioritizes borderline samples where reasoning drives the most impactful corrective gains. Additionally, we construct a high-quality query correction dataset, addressing the lack of specialized benchmarks for complex query correction. Experimental results demonstrate that SandwichR achieves SOTA accuracy comparable to standard CoT while delivering a 40-70% latency reduction, resolving the latency-accuracy trade-off in online search.", "AI": {"tldr": "SandwichR\u63d0\u51fa\u4e00\u79cd\u4e09\u660e\u6cbb\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u7b54\u6848-\u63a8\u7406-\u7b54\u6848\u8303\u5f0f\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u67e5\u8be2\u7ea0\u6b63\uff0c\u5728\u4fdd\u6301CoT\u63a8\u7406\u51c6\u786e\u6027\u7684\u540c\u65f6\u51cf\u5c1140-70%\u5ef6\u8fdf\u3002", "motivation": "\u73b0\u4ee3\u641c\u7d22\u7ba1\u9053\u4e2d\u7684\u67e5\u8be2\u7ea0\u6b63\u9700\u8981\u5728\u5b9e\u65f6\u5ef6\u8fdf\u7ea6\u675f\u4e0b\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u3002CoT\u63a8\u7406\u867d\u7136\u80fd\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u4f46\u5ef6\u8fdf\u8fc7\u9ad8\u65e0\u6cd5\u6ee1\u8db3\u5b9e\u65f6\u9700\u6c42\u3002\u63d0\u524d\u8f93\u51fa\u7b54\u6848\u867d\u7136\u80fd\u51cf\u5c11\u5ef6\u8fdf\uff0c\u4f46\u7b54\u6848\u65e0\u6cd5\u53d7\u76ca\u4e8e\u540e\u7eed\u63a8\u7406\u8fc7\u7a0b\uff0c\u5bfc\u81f4\u51c6\u786e\u6027\u4e0b\u964d\u3002", "method": "\u63d0\u51faSandwichR\u65b9\u6cd5\uff0c\u91c7\u7528\u7b54\u6848-\u63a8\u7406-\u7b54\u6848\u8303\u5f0f\uff1a\u9996\u5148\u751f\u6210\u521d\u59cb\u7ea0\u6b63\uff0c\u7136\u540e\u8fdb\u884c\u663e\u5f0f\u63a8\u7406\u8fc7\u7a0b\uff0c\u6700\u540e\u751f\u6210\u6700\u7ec8\u7cbe\u70bc\u7ea0\u6b63\u3002\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u4e00\u81f4\u6027\u7684\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u5305\u62ec\u4e00\u81f4\u6027\u5956\u52b1\u673a\u5236\u548c\u57fa\u4e8e\u8fb9\u754c\u7684\u62d2\u7edd\u91c7\u6837\uff0c\u786e\u4fdd\u521d\u59cb\u7b54\u6848\u4e0e\u63a8\u7406\u540e\u89c1\u89e3\u5bf9\u9f50\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSandwichR\u5728\u4fdd\u6301\u4e0e\u6807\u51c6CoT\u76f8\u5f53\u7684\u6700\u5148\u8fdb\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e8640-70%\u7684\u5ef6\u8fdf\u51cf\u5c11\uff0c\u89e3\u51b3\u4e86\u5728\u7ebf\u641c\u7d22\u4e2d\u7684\u5ef6\u8fdf-\u51c6\u786e\u6027\u6743\u8861\u95ee\u9898\u3002", "conclusion": "SandwichR\u901a\u8fc7\u5c06\u5feb\u901f\u521d\u59cb\u7b54\u6848\u4e0e\u4e8b\u540e\u63a8\u7406\u5bf9\u9f50\uff0c\u5b9e\u73b0\u4e86\u4f4e\u5ef6\u8fdf\u67e5\u8be2\u7ea0\u6b63\u800c\u4e0d\u727a\u7272\u63a8\u7406\u611f\u77e5\u7684\u51c6\u786e\u6027\uff0c\u89e3\u51b3\u4e86CoT\u63a8\u7406\u5728\u5b9e\u65f6\u5e94\u7528\u4e2d\u7684\u5ef6\u8fdf\u74f6\u9888\u95ee\u9898\u3002"}}
{"id": "2601.03687", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03687", "abs": "https://arxiv.org/abs/2601.03687", "authors": ["Yonatan Vernik", "Alexander Tuisov", "David Izhaki", "Hana Weitman", "Gal A. Kaminka", "Alexander Shleyfman"], "title": "Personalized Medication Planning via Direct Domain Modeling and LLM-Generated Heuristics", "comment": null, "summary": "Personalized medication planning involves selecting medications and determining a dosing schedule to achieve medical goals specific to each individual patient. Previous work successfully demonstrated that automated planners, using general domain-independent heuristics, are able to generate personalized treatments, when the domain and problems are modeled using a general domain description language (\\pddlp). Unfortunately, this process was limited in practice to consider no more than seven medications. In clinical terms, this is a non-starter. In this paper, we explore the use of automatically-generated domain- and problem-specific heuristics to be used with general search, as a method of scaling up medication planning to levels allowing closer work with clinicians. Specifically, we specify the domain programmatically (specifying an initial state and a successor generation procedure), and use an LLM to generate a problem specific heuristic that can be used by a fixed search algorithm (GBFS). The results indicate dramatic improvements in coverage and planning time, scaling up the number of medications to at least 28, and bringing medication planning one step closer to practical applications.", "AI": {"tldr": "\u4f7f\u7528LLM\u751f\u6210\u9886\u57df\u7279\u5b9a\u542f\u53d1\u5f0f\u51fd\u6570\uff0c\u663e\u8457\u63d0\u5347\u4e2a\u6027\u5316\u7528\u836f\u89c4\u5212\u7684\u53ef\u6269\u5c55\u6027\uff0c\u4ece\u6700\u591a7\u79cd\u836f\u7269\u6269\u5c55\u5230\u81f3\u5c1128\u79cd", "motivation": "\u73b0\u6709\u57fa\u4e8e\u901a\u7528\u9886\u57df\u63cf\u8ff0\u8bed\u8a00\u7684\u81ea\u52a8\u5316\u7528\u836f\u89c4\u5212\u65b9\u6cd5\u6700\u591a\u53ea\u80fd\u5904\u74067\u79cd\u836f\u7269\uff0c\u8fd9\u5728\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u8fdc\u8fdc\u4e0d\u591f\uff0c\u9700\u8981\u63d0\u5347\u53ef\u6269\u5c55\u6027\u4ee5\u63a5\u8fd1\u5b9e\u9645\u5e94\u7528", "method": "\u901a\u8fc7\u7f16\u7a0b\u65b9\u5f0f\u5b9a\u4e49\u9886\u57df\uff08\u6307\u5b9a\u521d\u59cb\u72b6\u6001\u548c\u72b6\u6001\u8f6c\u79fb\u8fc7\u7a0b\uff09\uff0c\u4f7f\u7528LLM\u751f\u6210\u9488\u5bf9\u5177\u4f53\u95ee\u9898\u7684\u542f\u53d1\u5f0f\u51fd\u6570\uff0c\u7ed3\u5408GBFS\u641c\u7d22\u7b97\u6cd5\u8fdb\u884c\u7528\u836f\u89c4\u5212", "result": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u8986\u76d6\u7387\u548c\u89c4\u5212\u65f6\u95f4\uff0c\u80fd\u591f\u5904\u7406\u81f3\u5c1128\u79cd\u836f\u7269\u7684\u89c4\u5212\u95ee\u9898\uff0c\u4f7f\u7528\u836f\u89c4\u5212\u66f4\u63a5\u8fd1\u5b9e\u9645\u4e34\u5e8a\u5e94\u7528", "conclusion": "\u81ea\u52a8\u751f\u6210\u7684\u9886\u57df\u7279\u5b9a\u542f\u53d1\u5f0f\u51fd\u6570\u80fd\u591f\u6709\u6548\u6269\u5c55\u7528\u836f\u89c4\u5212\u7cfb\u7edf\u7684\u89c4\u6a21\uff0c\u4e3a\u4e34\u5e8a\u5b9e\u8df5\u5e94\u7528\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65"}}
{"id": "2601.03769", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03769", "abs": "https://arxiv.org/abs/2601.03769", "authors": ["Zihang Li", "Yuhang Wang", "Yikun Zong", "Wenhan Yu", "Xiaokun Yuan", "Runhan Jiang", "Zirui Liu", "Tong Yang", "Arthur Jiang"], "title": "EntroCoT: Enhancing Chain-of-Thought via Adaptive Entropy-Guided Segmentation", "comment": null, "summary": "Chain-of-Thought (CoT) prompting has significantly enhanced the mathematical reasoning capabilities of Large Language Models. We find existing fine-tuning datasets frequently suffer from the \"answer right but reasoning wrong\" probelm, where correct final answers are derived from hallucinated, redundant, or logically invalid intermediate steps. This paper proposes EntroCoT, a unified framework for automatically identifying and refining low-quality CoT supervision traces. EntroCoT first proposes an entropy-based mechanism to segment the reasoning trace into multiple steps at uncertain junctures, and then introduces a Monte Carlo rollout-based mechanism to evaluate the marginal contribution of each step. By accurately filtering deceptive reasoning samples, EntroCoT constructs a high-quality dataset where every intermediate step in each reasoning trace facilitates the final answer. Extensive experiments on mathematical benchmarks demonstrate that fine-tuning on the subset constructed by EntroCoT consistently outperforms the baseslines of full-dataset supervision.", "AI": {"tldr": "EntroCoT\uff1a\u901a\u8fc7\u71b5\u57fa\u5206\u5272\u548c\u8499\u7279\u5361\u6d1b\u8bc4\u4f30\u81ea\u52a8\u8bc6\u522b\u548c\u7cbe\u70bc\u4f4e\u8d28\u91cf\u601d\u7ef4\u94fe\u76d1\u7763\u6570\u636e\uff0c\u6784\u5efa\u9ad8\u8d28\u91cf\u6570\u5b66\u63a8\u7406\u6570\u636e\u96c6", "motivation": "\u73b0\u6709\u5fae\u8c03\u6570\u636e\u96c6\u5b58\u5728\"\u7b54\u6848\u6b63\u786e\u4f46\u63a8\u7406\u9519\u8bef\"\u95ee\u9898\uff0c\u5373\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u4f46\u4e2d\u95f4\u6b65\u9aa4\u5b58\u5728\u5e7b\u89c9\u3001\u5197\u4f59\u6216\u903b\u8f91\u9519\u8bef\uff0c\u8fd9\u5f71\u54cd\u4e86\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u8d28\u91cf", "method": "1. \u57fa\u4e8e\u71b5\u7684\u673a\u5236\u5728\u4e0d\u786e\u5b9a\u8282\u70b9\u5206\u5272\u63a8\u7406\u8f68\u8ff9\uff1b2. \u8499\u7279\u5361\u6d1brollout\u673a\u5236\u8bc4\u4f30\u6bcf\u4e2a\u6b65\u9aa4\u7684\u8fb9\u9645\u8d21\u732e\uff1b3. \u51c6\u786e\u8fc7\u6ee4\u6b3a\u9a97\u6027\u63a8\u7406\u6837\u672c\uff0c\u6784\u5efa\u9ad8\u8d28\u91cf\u6570\u636e\u96c6", "result": "\u5728\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528EntroCoT\u6784\u5efa\u7684\u5b50\u96c6\u8fdb\u884c\u5fae\u8c03\u59cb\u7ec8\u4f18\u4e8e\u5168\u6570\u636e\u96c6\u76d1\u7763\u7684\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "EntroCoT\u80fd\u6709\u6548\u8bc6\u522b\u548c\u7cbe\u70bc\u4f4e\u8d28\u91cf\u601d\u7ef4\u94fe\u76d1\u7763\u6570\u636e\uff0c\u6784\u5efa\u9ad8\u8d28\u91cf\u63a8\u7406\u6570\u636e\u96c6\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b"}}
{"id": "2601.03822", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03822", "abs": "https://arxiv.org/abs/2601.03822", "authors": ["Muyang Zhao", "Qi Qi", "Hao Sun"], "title": "ROI-Reasoning: Rational Optimization for Inference via Pre-Computation Meta-Cognition", "comment": null, "summary": "Large language models (LLMs) can achieve strong reasoning performance with sufficient computation, but they do not inherently know how much computation a task requires. We study budgeted inference-time reasoning for multiple tasks under a strict global token constraint and formalize it as a Ordered Stochastic Multiple-Choice Knapsack Problem(OS-MCKP). This perspective highlights a meta-cognitive requirement -- anticipating task difficulty, estimating return over investment (ROI), and allocating computation strategically. We propose ROI-Reasoning, a two-stage framework that endows LLMs with intrinsic, budget-aware rationality. In the first stage, Meta-Cognitive Fine-Tuning teaches models to predict reasoning cost and expected utility before generation, enabling explicit solve-or-skip decisions. Next, Rationality-Aware Reinforcement Learning optimizes sequential decision making under a hard token budget, allowing models to learn long-horizon allocation strategies. Across budgeted mathematical reasoning benchmarks, ROI-Reasoning consistently improves overall score while substantially reducing regret under tight computation budgets.", "AI": {"tldr": "ROI-Reasoning\uff1a\u4e00\u4e2a\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e25\u683c\u5168\u5c40token\u7ea6\u675f\u4e0b\u8fdb\u884c\u9884\u7b97\u63a8\u7406\uff0c\u901a\u8fc7\u5143\u8ba4\u77e5\u5fae\u8c03\u548c\u7406\u6027\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u8ba1\u7b97\u8d44\u6e90\u5206\u914d", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5177\u5907\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u65e0\u6cd5\u81ea\u52a8\u5224\u65ad\u4e0d\u540c\u4efb\u52a1\u6240\u9700\u7684\u8ba1\u7b97\u91cf\u3002\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5f80\u5f80\u9762\u4e34\u4e25\u683c\u7684\u5168\u5c40token\u9884\u7b97\u7ea6\u675f\uff0c\u9700\u8981\u6a21\u578b\u80fd\u591f\u667a\u80fd\u5730\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\uff0c\u5728\u6709\u9650\u9884\u7b97\u4e0b\u6700\u5927\u5316\u6574\u4f53\u6027\u80fd\u3002", "method": "\u63d0\u51faROI-Reasoning\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1) \u5143\u8ba4\u77e5\u5fae\u8c03\uff1a\u8bad\u7ec3\u6a21\u578b\u5728\u751f\u6210\u524d\u9884\u6d4b\u63a8\u7406\u6210\u672c\u548c\u9884\u671f\u6548\u7528\uff0c\u505a\u51fa\u660e\u786e\u7684\u89e3\u51b3\u6216\u8df3\u8fc7\u51b3\u7b56\uff1b2) \u7406\u6027\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\uff1a\u5728\u786ctoken\u9884\u7b97\u4e0b\u4f18\u5316\u5e8f\u5217\u51b3\u7b56\uff0c\u5b66\u4e60\u957f\u671f\u5206\u914d\u7b56\u7565\u3002\u5c06\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u6709\u5e8f\u968f\u673a\u591a\u9009\u62e9\u80cc\u5305\u95ee\u9898\u3002", "result": "\u5728\u9884\u7b97\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cROI-Reasoning\u5728\u4e25\u683c\u8ba1\u7b97\u9884\u7b97\u4e0b\u6301\u7eed\u63d0\u9ad8\u6574\u4f53\u5f97\u5206\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u9057\u61be\uff08regret\uff09\u3002", "conclusion": "ROI-Reasoning\u6846\u67b6\u8d4b\u4e88\u5927\u8bed\u8a00\u6a21\u578b\u5185\u5728\u7684\u9884\u7b97\u611f\u77e5\u7406\u6027\u80fd\u529b\uff0c\u4f7f\u5176\u80fd\u591f\u5728\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u4e0b\u667a\u80fd\u5206\u914d\u63a8\u7406\u9884\u7b97\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2601.03840", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.03840", "abs": "https://arxiv.org/abs/2601.03840", "authors": ["Racquel Dennison", "Jesse Heyninck", "Thomas Meyer"], "title": "Defeasible Conditionals using Answer Set Programming", "comment": "In Proceedings ICLP 2025, arXiv:2601.00047", "summary": "Defeasible entailment is concerned with drawing plausible conclusions from incomplete information. A foundational framework for modelling defeasible entailment is the KLM framework. Introduced by Kraus, Lehmann, and Magidor, the KLM framework outlines several key properties for defeasible entailment. One of the most prominent algorithms within this framework is Rational Closure (RC). This paper presents a declarative definition for computing RC using Answer Set Programming (ASP). Our approach enables the automatic construction of the minimal ranked model from a given knowledge base and supports entailment checking for specified queries. We formally prove the correctness of our ASP encoding and conduct empirical evaluations to compare the performance of our implementation with that of existing imperative implementations, specifically the InfOCF solver. The results demonstrate that our ASP-based approach adheres to RC's theoretical foundations and offers improved computational efficiency.", "AI": {"tldr": "\u4f7f\u7528\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u4e3a\u7406\u6027\u95ed\u5305\uff08RC\uff09\u63d0\u4f9b\u58f0\u660e\u5f0f\u5b9a\u4e49\uff0c\u5b9e\u73b0\u4ece\u77e5\u8bc6\u5e93\u81ea\u52a8\u6784\u5efa\u6700\u5c0f\u6392\u540d\u6a21\u578b\u5e76\u652f\u6301\u67e5\u8be2\u8574\u6db5\u68c0\u67e5\uff0c\u8bc1\u660e\u7f16\u7801\u6b63\u786e\u6027\u4e14\u8ba1\u7b97\u6548\u7387\u4f18\u4e8e\u73b0\u6709\u5b9e\u73b0\u3002", "motivation": "\u53ef\u5e9f\u6b62\u8574\u6db5\u7528\u4e8e\u4ece\u4e0d\u5b8c\u6574\u4fe1\u606f\u4e2d\u5f97\u51fa\u5408\u7406\u7ed3\u8bba\uff0cKLM\u6846\u67b6\u662f\u5176\u57fa\u7840\u6a21\u578b\uff0c\u7406\u6027\u95ed\u5305\uff08RC\uff09\u662f\u8be5\u6846\u67b6\u4e2d\u6700\u7a81\u51fa\u7684\u7b97\u6cd5\u4e4b\u4e00\u3002\u73b0\u6709\u5b9e\u73b0\u591a\u4e3a\u547d\u4ee4\u5f0f\u65b9\u6cd5\uff0c\u9700\u8981\u66f4\u58f0\u660e\u5f0f\u3001\u81ea\u52a8\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u4e3a\u7406\u6027\u95ed\u5305\u63d0\u4f9b\u58f0\u660e\u5f0f\u5b9a\u4e49\uff0c\u901a\u8fc7ASP\u7f16\u7801\u81ea\u52a8\u4ece\u7ed9\u5b9a\u77e5\u8bc6\u5e93\u6784\u5efa\u6700\u5c0f\u6392\u540d\u6a21\u578b\uff0c\u652f\u6301\u6307\u5b9a\u67e5\u8be2\u7684\u8574\u6db5\u68c0\u67e5\uff0c\u5e76\u5f62\u5f0f\u5316\u8bc1\u660e\u7f16\u7801\u7684\u6b63\u786e\u6027\u3002", "result": "ASP\u65b9\u6cd5\u80fd\u591f\u6b63\u786e\u5b9e\u73b0\u7406\u6027\u95ed\u5305\u7684\u7406\u8bba\u57fa\u7840\uff0c\u4e0e\u73b0\u6709\u547d\u4ee4\u5f0f\u5b9e\u73b0\uff08\u7279\u522b\u662fInfOCF\u6c42\u89e3\u5668\uff09\u76f8\u6bd4\uff0c\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u8868\u73b0\u51fa\u6539\u8fdb\u3002\u7ecf\u9a8c\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "ASP\u4e3a\u7406\u6027\u95ed\u5305\u63d0\u4f9b\u4e86\u4e00\u79cd\u58f0\u660e\u5f0f\u3001\u81ea\u52a8\u5316\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u7b26\u5408\u7406\u8bba\u8981\u6c42\uff0c\u800c\u4e14\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u547d\u4ee4\u5f0f\u5b9e\u73b0\uff0c\u4e3a\u53ef\u5e9f\u6b62\u63a8\u7406\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2601.03844", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03844", "abs": "https://arxiv.org/abs/2601.03844", "authors": ["Agostino Dovier", "Talissa Dreossi", "Andrea Formisano", "Benedetta Strizzolo"], "title": "XAI-LAW: A Logic Programming Tool for Modeling, Explaining, and Learning Legal Decisions", "comment": "In Proceedings ICLP 2025, arXiv:2601.00047", "summary": "We propose an approach to model articles of the Italian Criminal Code (ICC), using Answer Set Programming (ASP), and to semi-automatically learn legal rules from examples based on prior judicial decisions. The developed tool is intended to support legal experts during the criminal trial phase by providing reasoning and possible legal outcomes. The methodology involves analyzing and encoding articles of the ICC in ASP, including \"crimes against the person\" and property offenses. The resulting model is validated on a set of previous verdicts and refined as necessary. During the encoding process, contradictions may arise; these are properly handled by the system, which also generates possible decisions for new cases and provides explanations through a tool that leverages the \"supportedness\" of stable models. The automatic explainability offered by the tool can also be used to clarify the logic behind judicial decisions, making the decision-making process more interpretable. Furthermore, the tool integrates an inductive logic programming system for ASP, which is employed to generalize legal rules from case examples.", "AI": {"tldr": "\u4f7f\u7528ASP\u5bf9\u610f\u5927\u5229\u5211\u6cd5\u5178\u5efa\u6a21\uff0c\u901a\u8fc7\u534a\u81ea\u52a8\u5b66\u4e60\u53f8\u6cd5\u5224\u4f8b\u751f\u6210\u6cd5\u5f8b\u89c4\u5219\uff0c\u652f\u6301\u5211\u4e8b\u5ba1\u5224\u63a8\u7406\u548c\u89e3\u91ca", "motivation": "\u4e3a\u6cd5\u5f8b\u4e13\u5bb6\u5728\u5211\u4e8b\u5ba1\u5224\u9636\u6bb5\u63d0\u4f9b\u63a8\u7406\u652f\u6301\u548c\u53ef\u80fd\u7684\u5224\u51b3\u7ed3\u679c\uff0c\u63d0\u9ad8\u53f8\u6cd5\u51b3\u7b56\u7684\u53ef\u89e3\u91ca\u6027", "method": "\u4f7f\u7528\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u5bf9\u610f\u5927\u5229\u5211\u6cd5\u5178\u6761\u6b3e\u8fdb\u884c\u7f16\u7801\u5efa\u6a21\uff0c\u5305\u62ec\"\u4eba\u8eab\u72af\u7f6a\"\u548c\u8d22\u4ea7\u72af\u7f6a\uff1b\u5229\u7528\u57fa\u4e8e\u7a33\u5b9a\u6a21\u578b\"\u652f\u6301\u6027\"\u7684\u5de5\u5177\u5904\u7406\u77db\u76fe\u5e76\u751f\u6210\u89e3\u91ca\uff1b\u96c6\u6210\u5f52\u7eb3\u903b\u8f91\u7f16\u7a0b\u7cfb\u7edf\u4ece\u6848\u4f8b\u4e2d\u5f52\u7eb3\u6cd5\u5f8b\u89c4\u5219", "result": "\u5f00\u53d1\u51fa\u652f\u6301\u6cd5\u5f8b\u63a8\u7406\u7684\u5de5\u5177\uff0c\u80fd\u591f\u57fa\u4e8e\u5148\u524d\u5224\u51b3\u9a8c\u8bc1\u6a21\u578b\uff0c\u4e3a\u65b0\u6848\u4ef6\u751f\u6210\u53ef\u80fd\u7684\u51b3\u7b56\u5e76\u63d0\u4f9b\u89e3\u91ca\uff0c\u63d0\u9ad8\u51b3\u7b56\u8fc7\u7a0b\u7684\u900f\u660e\u5ea6", "conclusion": "ASP\u65b9\u6cd5\u80fd\u6709\u6548\u5efa\u6a21\u5211\u6cd5\u5178\u5e76\u5b66\u4e60\u6cd5\u5f8b\u89c4\u5219\uff0c\u5de5\u5177\u63d0\u4f9b\u7684\u81ea\u52a8\u89e3\u91ca\u6027\u6709\u52a9\u4e8e\u9610\u660e\u53f8\u6cd5\u51b3\u7b56\u903b\u8f91\uff0c\u4f7f\u51b3\u7b56\u8fc7\u7a0b\u66f4\u52a0\u53ef\u89e3\u91ca"}}
{"id": "2601.03845", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.03845", "abs": "https://arxiv.org/abs/2601.03845", "authors": ["Akihiro Takemura", "Masayuki Otani", "Katsumi Inoue"], "title": "Formally Explaining Decision Tree Models with Answer Set Programming", "comment": "In Proceedings ICLP 2025, arXiv:2601.00047", "summary": "Decision tree models, including random forests and gradient-boosted decision trees, are widely used in machine learning due to their high predictive performance.  However, their complex structures often make them difficult to interpret, especially in safety-critical applications where model decisions require formal justification.  Recent work has demonstrated that logical and abductive explanations can be derived through automated reasoning techniques.  In this paper, we propose a method for generating various types of explanations, namely, sufficient, contrastive, majority, and tree-specific explanations, using Answer Set Programming (ASP).  Compared to SAT-based approaches, our ASP-based method offers greater flexibility in encoding user preferences and supports enumeration of all possible explanations.  We empirically evaluate the approach on a diverse set of datasets and demonstrate its effectiveness and limitations compared to existing methods.", "AI": {"tldr": "\u4f7f\u7528\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u4e3a\u51b3\u7b56\u6811\u6a21\u578b\u751f\u6210\u591a\u79cd\u89e3\u91ca\u7c7b\u578b\uff0c\u76f8\u6bd4SAT\u65b9\u6cd5\u66f4\u7075\u6d3b\u4e14\u652f\u6301\u679a\u4e3e\u6240\u6709\u53ef\u80fd\u89e3\u91ca", "motivation": "\u51b3\u7b56\u6811\u6a21\u578b\uff08\u5982\u968f\u673a\u68ee\u6797\u548c\u68af\u5ea6\u63d0\u5347\u6811\uff09\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u590d\u6742\u7ed3\u6784\u96be\u4ee5\u89e3\u91ca\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u6b63\u5f0f\u51b3\u7b56\u4f9d\u636e\u7684\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u3002\u73b0\u6709\u5de5\u4f5c\u8868\u660e\u53ef\u4ee5\u901a\u8fc7\u81ea\u52a8\u63a8\u7406\u6280\u672f\u63a8\u5bfc\u903b\u8f91\u548c\u6eaf\u56e0\u89e3\u91ca\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u591a\u79cd\u89e3\u91ca\u7c7b\u578b\uff1a\u5145\u5206\u89e3\u91ca\u3001\u5bf9\u6bd4\u89e3\u91ca\u3001\u591a\u6570\u89e3\u91ca\u548c\u6811\u7279\u5b9a\u89e3\u91ca\u3002\u76f8\u6bd4\u57fa\u4e8eSAT\u7684\u65b9\u6cd5\uff0cASP\u65b9\u6cd5\u5728\u7f16\u7801\u7528\u6237\u504f\u597d\u65b9\u9762\u66f4\u7075\u6d3b\uff0c\u5e76\u652f\u6301\u679a\u4e3e\u6240\u6709\u53ef\u80fd\u7684\u89e3\u91ca\u3002", "result": "\u5728\u591a\u6837\u5316\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u5c40\u9650\u6027\u3002", "conclusion": "ASP\u65b9\u6cd5\u4e3a\u51b3\u7b56\u6811\u6a21\u578b\u89e3\u91ca\u63d0\u4f9b\u4e86\u7075\u6d3b\u4e14\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u751f\u6210\u591a\u79cd\u7c7b\u578b\u7684\u89e3\u91ca\u5e76\u652f\u6301\u7528\u6237\u504f\u597d\u7f16\u7801\uff0c\u4f46\u5728\u67d0\u4e9b\u65b9\u9762\u4ecd\u5b58\u5728\u5c40\u9650\u6027\u3002"}}
{"id": "2601.03847", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03847", "abs": "https://arxiv.org/abs/2601.03847", "authors": ["Ly Ly Trieu", "Tran Cao Son"], "title": "xDNN(ASP): Explanation Generation System for Deep Neural Networks powered by Answer Set Programming", "comment": "In Proceedings ICLP 2025, arXiv:2601.00047", "summary": "Explainable artificial intelligence (xAI) has gained significant attention in recent years. Among other things, explainablility for deep neural networks has been a topic of intensive research due to the meteoric rise in prominence of deep neural networks and their \"black-box\" nature. xAI approaches can be characterized along different dimensions such as their scope (global versus local explanations) or underlying methodologies (statistic-based versus rule-based strategies). Methods generating global explanations aim to provide reasoning process applicable to all possible output classes while local explanation methods focus only on a single, specific class. SHAP (SHapley Additive exPlanations), a well-known statistical technique, identifies important features of a network. Deep neural network rule extraction method constructs IF-THEN rules that link input conditions to a class. Another approach focuses on generating counterfactuals which help explain how small changes to an input can affect the model's predictions. However, these techniques primarily focus on the input-output relationship and thus neglect the structure of the network in explanation generation.   In this work, we propose xDNN(ASP), an explanation generation system for deep neural networks that provides global explanations. Given a neural network model and its training data, xDNN(ASP) extracts a logic program under answer set semantics that-in the ideal case-represents the trained model, i.e., answer sets of the extracted program correspond one-to-one to input-output pairs of the network. We demonstrate experimentally, using two synthetic datasets, that not only the extracted logic program maintains a high-level of accuracy in the prediction task, but it also provides valuable information for the understanding of the model such as the importance of features as well as the impact of hidden nodes on the prediction. The latter can be used as a guide for reducing the number of nodes used in hidden layers, i.e., providing a means for optimizing the network.", "AI": {"tldr": "xDNN(ASP) \u662f\u4e00\u4e2a\u57fa\u4e8e\u7b54\u6848\u96c6\u8bed\u4e49\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5168\u5c40\u89e3\u91ca\u7cfb\u7edf\uff0c\u901a\u8fc7\u63d0\u53d6\u903b\u8f91\u7a0b\u5e8f\u6765\u7406\u89e3\u6a21\u578b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u53ef\u89e3\u91caAI\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u8f93\u5165\u8f93\u51fa\u5173\u7cfb\uff0c\u5ffd\u89c6\u4e86\u795e\u7ecf\u7f51\u7edc\u5185\u90e8\u7ed3\u6784\u5728\u89e3\u91ca\u751f\u6210\u4e2d\u7684\u4f5c\u7528\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u63d0\u4f9b\u5168\u5c40\u89e3\u91ca\u5e76\u8003\u8651\u7f51\u7edc\u7ed3\u6784\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faxDNN(ASP)\u7cfb\u7edf\uff0c\u7ed9\u5b9a\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u548c\u8bad\u7ec3\u6570\u636e\uff0c\u63d0\u53d6\u57fa\u4e8e\u7b54\u6848\u96c6\u8bed\u4e49\u7684\u903b\u8f91\u7a0b\u5e8f\uff0c\u4f7f\u7a0b\u5e8f\u7b54\u6848\u96c6\u4e0e\u7f51\u7edc\u8f93\u5165\u8f93\u51fa\u5bf9\u4e00\u4e00\u5bf9\u5e94\u3002", "result": "\u5728\u4e24\u4e2a\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u63d0\u53d6\u7684\u903b\u8f91\u7a0b\u5e8f\u4e0d\u4ec5\u4fdd\u6301\u9ad8\u9884\u6d4b\u7cbe\u5ea6\uff0c\u8fd8\u63d0\u4f9b\u4e86\u7279\u5f81\u91cd\u8981\u6027\u548c\u9690\u85cf\u8282\u70b9\u5bf9\u9884\u6d4b\u5f71\u54cd\u7b49\u6709\u4ef7\u503c\u4fe1\u606f\u3002", "conclusion": "xDNN(ASP)\u80fd\u591f\u751f\u6210\u5168\u5c40\u89e3\u91ca\uff0c\u5e2e\u52a9\u7406\u89e3\u6a21\u578b\u51b3\u7b56\uff0c\u540c\u65f6\u4e3a\u7f51\u7edc\u4f18\u5316\uff08\u5982\u51cf\u5c11\u9690\u85cf\u8282\u70b9\uff09\u63d0\u4f9b\u6307\u5bfc\uff0c\u5f25\u8865\u4e86\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6\u7f51\u7edc\u7ed3\u6784\u7684\u4e0d\u8db3\u3002"}}
{"id": "2601.03850", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03850", "abs": "https://arxiv.org/abs/2601.03850", "authors": ["Veronika Semmelrock", "Gerhard Friedrich"], "title": "Investigating the Grounding Bottleneck for a Large-Scale Configuration Problem: Existing Tools and Constraint-Aware Guessing", "comment": "In Proceedings ICLP 2025, arXiv:2601.00047", "summary": "Answer set programming (ASP) aims to realize the AI vision: The user specifies the problem, and the computer solves it. Indeed, ASP has made this vision true in many application domains. However, will current ASP solving techniques scale up for large configuration problems? As a benchmark for such problems, we investigated the configuration of electronic systems, which may comprise more than 30,000 components. We show the potential and limits of current ASP technology, focusing on methods that address the so-called grounding bottleneck, i.e., the sharp increase of memory demands in the size of the problem instances. To push the limits, we investigated the incremental solving approach, which proved effective in practice. However, even in the incremental approach, memory demands impose significant limits. Based on an analysis of grounding, we developed the method constraint-aware guessing, which significantly reduced the memory need.", "AI": {"tldr": "ASP\u6280\u672f\u5728\u5927\u89c4\u6a21\u914d\u7f6e\u95ee\u9898\uff08\u59823\u4e07+\u7ec4\u4ef6\u7535\u5b50\u7cfb\u7edf\uff09\u4e2d\u9762\u4e34\u5185\u5b58\u74f6\u9888\uff0c\u901a\u8fc7\u589e\u91cf\u6c42\u89e3\u548c\u7ea6\u675f\u611f\u77e5\u731c\u6d4b\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u5185\u5b58\u9700\u6c42", "motivation": "\u7814\u7a76\u5f53\u524dASP\u6280\u672f\u5728\u5927\u89c4\u6a21\u914d\u7f6e\u95ee\u9898\u4e2d\u7684\u53ef\u6269\u5c55\u6027\uff0c\u7279\u522b\u662f\u9488\u5bf9\u8d85\u8fc73\u4e07\u4e2a\u7ec4\u4ef6\u7684\u7535\u5b50\u7cfb\u7edf\u914d\u7f6e\uff0c\u89e3\u51b3ASP\u6c42\u89e3\u4e2d\u7684\u5185\u5b58\u74f6\u9888\u95ee\u9898", "method": "1. \u5206\u6790ASP\u4e2d\u7684\u57fa\u7840\u5316\u74f6\u9888\u95ee\u9898\uff1b2. \u91c7\u7528\u589e\u91cf\u6c42\u89e3\u65b9\u6cd5\uff1b3. \u5f00\u53d1\u7ea6\u675f\u611f\u77e5\u731c\u6d4b\u65b9\u6cd5\uff0c\u57fa\u4e8e\u57fa\u7840\u5316\u5206\u6790\u51cf\u5c11\u5185\u5b58\u9700\u6c42", "result": "\u589e\u91cf\u6c42\u89e3\u5728\u5b9e\u8df5\u4e2d\u6709\u6548\uff0c\u4f46\u4ecd\u6709\u5185\u5b58\u9650\u5236\uff1b\u7ea6\u675f\u611f\u77e5\u731c\u6d4b\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u5185\u5b58\u9700\u6c42\uff0c\u63d0\u5347\u4e86ASP\u5728\u5927\u89c4\u6a21\u914d\u7f6e\u95ee\u9898\u4e2d\u7684\u53ef\u6269\u5c55\u6027", "conclusion": "ASP\u6280\u672f\u5728\u5927\u89c4\u6a21\u914d\u7f6e\u95ee\u9898\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u4e13\u95e8\u7684\u65b9\u6cd5\uff08\u5982\u7ea6\u675f\u611f\u77e5\u731c\u6d4b\uff09\u6765\u89e3\u51b3\u5185\u5b58\u74f6\u9888\uff0c\u624d\u80fd\u6709\u6548\u6269\u5c55\u5230\u8d85\u5927\u89c4\u6a21\u95ee\u9898\u5b9e\u4f8b"}}
{"id": "2601.03905", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.03905", "abs": "https://arxiv.org/abs/2601.03905", "authors": ["Cheng Qian", "Emre Can Acikgoz", "Bingxuan Li", "Xiusi Chen", "Yuji Zhang", "Bingxiang He", "Qinyu Luo", "Dilek Hakkani-T\u00fcr", "Gokhan Tur", "Yunzhu Li", "Heng Ji", "Heng Ji"], "title": "Current Agents Fail to Leverage World Model as Tool for Foresight", "comment": "36 Pages, 13 Figures, 17 Tables", "summary": "Agents built on vision-language models increasingly face tasks that demand anticipating future states rather than relying on short-horizon reasoning. Generative world models offer a promising remedy: agents could use them as external simulators to foresee outcomes before acting. This paper empirically examines whether current agents can leverage such world models as tools to enhance their cognition. Across diverse agentic and visual question answering tasks, we observe that some agents rarely invoke simulation (fewer than 1%), frequently misuse predicted rollouts (approximately 15%), and often exhibit inconsistent or even degraded performance (up to 5%) when simulation is available or enforced. Attribution analysis further indicates that the primary bottleneck lies in the agents' capacity to decide when to simulate, how to interpret predicted outcomes, and how to integrate foresight into downstream reasoning. These findings underscore the need for mechanisms that foster calibrated, strategic interaction with world models, paving the way toward more reliable anticipatory cognition in future agent systems.", "AI": {"tldr": "\u5f53\u524d\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u5728\u5229\u7528\u751f\u6210\u4e16\u754c\u6a21\u578b\u8fdb\u884c\u524d\u77bb\u6027\u63a8\u7406\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u4e3b\u8981\u8868\u73b0\u4e3a\u5f88\u5c11\u8c03\u7528\u6a21\u62df\u3001\u8bef\u7528\u9884\u6d4b\u7ed3\u679c\uff0c\u751a\u81f3\u6027\u80fd\u4e0b\u964d", "motivation": "\u968f\u7740\u667a\u80fd\u4f53\u9762\u4e34\u66f4\u591a\u9700\u8981\u9884\u6d4b\u672a\u6765\u72b6\u6001\u7684\u4efb\u52a1\uff0c\u751f\u6210\u4e16\u754c\u6a21\u578b\u7406\u8bba\u4e0a\u53ef\u4ee5\u4f5c\u4e3a\u5916\u90e8\u6a21\u62df\u5668\u5e2e\u52a9\u667a\u80fd\u4f53\u9884\u89c1\u7ed3\u679c\u3002\u672c\u6587\u65e8\u5728\u5b9e\u8bc1\u68c0\u9a8c\u5f53\u524d\u667a\u80fd\u4f53\u662f\u5426\u80fd\u6709\u6548\u5229\u7528\u4e16\u754c\u6a21\u578b\u4f5c\u4e3a\u5de5\u5177\u6765\u589e\u5f3a\u5176\u8ba4\u77e5\u80fd\u529b", "method": "\u901a\u8fc7\u5728\u5404\u79cd\u667a\u80fd\u4f53\u4efb\u52a1\u548c\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u89c2\u5bdf\u667a\u80fd\u4f53\u5982\u4f55\u4f7f\u7528\u4e16\u754c\u6a21\u578b\u8fdb\u884c\u6a21\u62df\uff0c\u5305\u62ec\u8c03\u7528\u9891\u7387\u3001\u7ed3\u679c\u4f7f\u7528\u65b9\u5f0f\u7b49\uff0c\u5e76\u8fdb\u884c\u5f52\u56e0\u5206\u6790", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u667a\u80fd\u4f53\u5f88\u5c11\u8c03\u7528\u6a21\u62df\uff08\u5c11\u4e8e1%\uff09\uff1b2\uff09\u7ecf\u5e38\u8bef\u7528\u9884\u6d4b\u7ed3\u679c\uff08\u7ea615%\uff09\uff1b3\uff09\u5f53\u6a21\u62df\u53ef\u7528\u6216\u88ab\u5f3a\u5236\u4f7f\u7528\u65f6\uff0c\u6027\u80fd\u8868\u73b0\u4e0d\u4e00\u81f4\u751a\u81f3\u4e0b\u964d\uff08\u6700\u591a5%\uff09\u3002\u5f52\u56e0\u5206\u6790\u8868\u660e\u4e3b\u8981\u74f6\u9888\u5728\u4e8e\u667a\u80fd\u4f53\u51b3\u5b9a\u4f55\u65f6\u6a21\u62df\u3001\u5982\u4f55\u89e3\u91ca\u9884\u6d4b\u7ed3\u679c\u4ee5\u53ca\u5982\u4f55\u5c06\u9884\u89c1\u6574\u5408\u5230\u4e0b\u6e38\u63a8\u7406\u7684\u80fd\u529b", "conclusion": "\u5f53\u524d\u667a\u80fd\u4f53\u96be\u4ee5\u6709\u6548\u5229\u7528\u4e16\u754c\u6a21\u578b\u8fdb\u884c\u524d\u77bb\u6027\u8ba4\u77e5\uff0c\u9700\u8981\u5f00\u53d1\u4fc3\u8fdb\u6821\u51c6\u3001\u6218\u7565\u6027\u4ea4\u4e92\u7684\u673a\u5236\uff0c\u4e3a\u672a\u6765\u667a\u80fd\u4f53\u7cfb\u7edf\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u524d\u77bb\u6027\u8ba4\u77e5\u94fa\u5e73\u9053\u8def"}}
{"id": "2601.03948", "categories": ["cs.AI", "q-fin.TR"], "pdf": "https://arxiv.org/pdf/2601.03948", "abs": "https://arxiv.org/abs/2601.03948", "authors": ["Rui Sun", "Yifan Sun", "Sheng Xu", "Li Zhao", "Jing Li", "Daxin Jiang", "Chen Hua", "Zuo Bai"], "title": "Trade-R1: Bridging Verifiable Rewards to Stochastic Environments via Process-Level Reasoning Verification", "comment": null, "summary": "Reinforcement Learning (RL) has enabled Large Language Models (LLMs) to achieve remarkable reasoning in domains like mathematics and coding, where verifiable rewards provide clear signals. However, extending this paradigm to financial decision is challenged by the market's stochastic nature: rewards are verifiable but inherently noisy, causing standard RL to degenerate into reward hacking. To address this, we propose Trade-R1, a model training framework that bridges verifiable rewards to stochastic environments via process-level reasoning verification. Our key innovation is a verification method that transforms the problem of evaluating reasoning over lengthy financial documents into a structured Retrieval-Augmented Generation (RAG) task. We construct a triangular consistency metric, assessing pairwise alignment between retrieved evidence, reasoning chains, and decisions to serve as a validity filter for noisy market returns. We explore two reward integration strategies: Fixed-effect Semantic Reward (FSR) for stable alignment signals, and Dynamic-effect Semantic Reward (DSR) for coupled magnitude optimization. Experiments on different country asset selection demonstrate that our paradigm reduces reward hacking, with DSR achieving superior cross-market generalization while maintaining the highest reasoning consistency.", "AI": {"tldr": "Trade-R1\u6846\u67b6\u901a\u8fc7\u8fc7\u7a0b\u7ea7\u63a8\u7406\u9a8c\u8bc1\u5c06\u53ef\u9a8c\u8bc1\u5956\u52b1\u4e0e\u968f\u673a\u91d1\u878d\u73af\u5883\u8fde\u63a5\uff0c\u89e3\u51b3\u6807\u51c6RL\u5728\u91d1\u878d\u51b3\u7b56\u4e2d\u7684\u5956\u52b1\u9ed1\u5ba2\u95ee\u9898\uff0c\u4f7f\u7528\u7ed3\u6784\u5316RAG\u4efb\u52a1\u8bc4\u4f30\u63a8\u7406\u8d28\u91cf\uff0c\u901a\u8fc7\u4e09\u89d2\u4e00\u81f4\u6027\u6307\u6807\u8fc7\u6ee4\u566a\u58f0\u5e02\u573a\u56de\u62a5\u3002", "motivation": "RL\u5728\u6570\u5b66\u548c\u7f16\u7a0b\u7b49\u53ef\u9a8c\u8bc1\u5956\u52b1\u9886\u57df\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u6269\u5c55\u5230\u91d1\u878d\u51b3\u7b56\u65f6\u9762\u4e34\u6311\u6218\uff1a\u5e02\u573a\u5177\u6709\u968f\u673a\u6027\uff0c\u5956\u52b1\u867d\u7136\u53ef\u9a8c\u8bc1\u4f46\u566a\u58f0\u4e25\u91cd\uff0c\u5bfc\u81f4\u6807\u51c6RL\u9000\u5316\u4e3a\u5956\u52b1\u9ed1\u5ba2\u884c\u4e3a\u3002", "method": "\u63d0\u51faTrade-R1\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u8fc7\u7a0b\u7ea7\u63a8\u7406\u9a8c\u8bc1\u8fde\u63a5\u53ef\u9a8c\u8bc1\u5956\u52b1\u4e0e\u968f\u673a\u73af\u5883\u3002\u6838\u5fc3\u521b\u65b0\u662f\u5c06\u957f\u7bc7\u91d1\u878d\u6587\u6863\u7684\u63a8\u7406\u8bc4\u4f30\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316RAG\u4efb\u52a1\uff0c\u6784\u5efa\u4e09\u89d2\u4e00\u81f4\u6027\u6307\u6807\uff08\u68c0\u7d22\u8bc1\u636e\u3001\u63a8\u7406\u94fe\u3001\u51b3\u7b56\u4e4b\u95f4\u7684\u4e24\u4e24\u5bf9\u9f50\uff09\uff0c\u4f5c\u4e3a\u566a\u58f0\u5e02\u573a\u56de\u62a5\u7684\u6709\u6548\u6027\u8fc7\u6ee4\u5668\u3002\u63a2\u7d22\u4e24\u79cd\u5956\u52b1\u6574\u5408\u7b56\u7565\uff1a\u56fa\u5b9a\u6548\u5e94\u8bed\u4e49\u5956\u52b1\uff08FSR\uff09\u7528\u4e8e\u7a33\u5b9a\u5bf9\u9f50\u4fe1\u53f7\uff0c\u52a8\u6001\u6548\u5e94\u8bed\u4e49\u5956\u52b1\uff08DSR\uff09\u7528\u4e8e\u8026\u5408\u5e45\u5ea6\u4f18\u5316\u3002", "result": "\u5728\u4e0d\u540c\u56fd\u5bb6\u8d44\u4ea7\u9009\u62e9\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u8303\u5f0f\u51cf\u5c11\u4e86\u5956\u52b1\u9ed1\u5ba2\u73b0\u8c61\uff0cDSR\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u8de8\u5e02\u573a\u6cdb\u5316\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6700\u9ad8\u7684\u63a8\u7406\u4e00\u81f4\u6027\u3002", "conclusion": "Trade-R1\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u91d1\u878d\u51b3\u7b56\u4e2dRL\u7684\u5956\u52b1\u9ed1\u5ba2\u95ee\u9898\uff0c\u901a\u8fc7\u8fc7\u7a0b\u7ea7\u63a8\u7406\u9a8c\u8bc1\u548c\u7ed3\u6784\u5316RAG\u8bc4\u4f30\uff0c\u5c06\u53ef\u9a8c\u8bc1\u5956\u52b1\u4e0e\u968f\u673a\u5e02\u573a\u73af\u5883\u6709\u6548\u8fde\u63a5\uff0c\u4e3a\u91d1\u878d\u9886\u57df\u7684RL\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2601.03969", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.03969", "abs": "https://arxiv.org/abs/2601.03969", "authors": ["Wei Wu", "Liyi Chen", "Congxi Xiao", "Tianfu Wang", "Qimeng Wang", "Chengqiang Lu", "Yan Gao", "Yi Wu", "Yao Hu", "Hui Xiong"], "title": "Anti-Length Shift: Dynamic Outlier Truncation for Training Efficient Reasoning Models", "comment": null, "summary": "Large reasoning models enhanced by reinforcement learning with verifiable rewards have achieved significant performance gains by extending their chain-of-thought. However, this paradigm incurs substantial deployment costs as models often exhibit excessive verbosity on simple queries. Existing efficient reasoning methods relying on explicit length penalties often introduce optimization conflicts and leave the generative mechanisms driving overthinking largely unexamined. In this paper, we identify a phenomenon termed length shift where models increasingly generate unnecessary reasoning on trivial inputs during training. To address this, we introduce Dynamic Outlier Truncation (DOT), a training-time intervention that selectively suppresses redundant tokens. This method targets only the extreme tail of response lengths within fully correct rollout groups while preserving long-horizon reasoning capabilities for complex problems. To complement this intervention and ensure stable convergence, we further incorporate auxiliary KL regularization and predictive dynamic sampling. Experimental results across multiple model scales demonstrate that our approach significantly pushes the efficiency-performance Pareto frontier outward. Notably, on the AIME-24, our method reduces inference token usage by 78% while simultaneously increasing accuracy compared to the initial policy and surpassing state-of-the-art efficient reasoning methods.", "AI": {"tldr": "\u63d0\u51faDOT\u65b9\u6cd5\u89e3\u51b3\u5927\u6a21\u578b\u5728\u7b80\u5355\u95ee\u9898\u4e0a\u8fc7\u5ea6\u63a8\u7406\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u52a8\u6001\u622a\u65ad\u5197\u4f59token\u51cf\u5c1178%\u63a8\u7406token\u4f7f\u7528\uff0c\u540c\u65f6\u63d0\u5347\u51c6\u786e\u7387", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u589e\u5f3a\u7684\u5927\u63a8\u7406\u6a21\u578b\u5728\u7b80\u5355\u67e5\u8be2\u4e0a\u4f1a\u4ea7\u751f\u8fc7\u5ea6\u5197\u957f\u7684\u63a8\u7406\uff0c\u5bfc\u81f4\u90e8\u7f72\u6210\u672c\u9ad8\u6602\u3002\u73b0\u6709\u57fa\u4e8e\u957f\u5ea6\u60e9\u7f5a\u7684\u65b9\u6cd5\u5b58\u5728\u4f18\u5316\u51b2\u7a81\uff0c\u4e14\u672a\u6df1\u5165\u63a2\u7a76\u8fc7\u5ea6\u63a8\u7406\u7684\u751f\u6210\u673a\u5236\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u5f02\u5e38\u622a\u65ad(DOT)\uff1a\u5728\u8bad\u7ec3\u65f6\u9009\u62e9\u6027\u6291\u5236\u5197\u4f59token\uff0c\u4ec5\u9488\u5bf9\u5b8c\u5168\u6b63\u786erollout\u7ec4\u4e2d\u7684\u6781\u7aef\u957f\u5ea6\u5c3e\u90e8\u8fdb\u884c\u622a\u65ad\u3002\u540c\u65f6\u7ed3\u5408\u8f85\u52a9KL\u6b63\u5219\u5316\u548c\u9884\u6d4b\u6027\u52a8\u6001\u91c7\u6837\u786e\u4fdd\u7a33\u5b9a\u6536\u655b\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u89c4\u6a21\u4e0a\u663e\u8457\u63a8\u8fdb\u4e86\u6548\u7387-\u6027\u80fd\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u3002\u5728AIME-24\u4e0a\uff0c\u76f8\u6bd4\u521d\u59cb\u7b56\u7565\u51cf\u5c1178%\u63a8\u7406token\u4f7f\u7528\uff0c\u540c\u65f6\u63d0\u5347\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u73b0\u6709\u9ad8\u6548\u63a8\u7406\u65b9\u6cd5\u3002", "conclusion": "DOT\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5927\u6a21\u578b\u5728\u7b80\u5355\u95ee\u9898\u4e0a\u7684\u8fc7\u5ea6\u63a8\u7406\u95ee\u9898\uff0c\u901a\u8fc7\u8bad\u7ec3\u65f6\u5e72\u9884\u5b9e\u73b0\u4e86\u63a8\u7406\u6548\u7387\u4e0e\u6027\u80fd\u7684\u53cc\u91cd\u63d0\u5347\uff0c\u4e3a\u9ad8\u6548\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.04035", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04035", "abs": "https://arxiv.org/abs/2601.04035", "authors": ["Yilin Cao", "Yufeng Zhong", "Zhixiong Zeng", "Liming Zheng", "Jing Huang", "Haibo Qiu", "Peng Shi", "Wenji Mao", "Wan Guanglu"], "title": "MobileDreamer: Generative Sketch World Model for GUI Agent", "comment": null, "summary": "Mobile GUI agents have shown strong potential in real-world automation and practical applications. However, most existing agents remain reactive, making decisions mainly from current screen, which limits their performance on long-horizon tasks. Building a world model from repeated interactions enables forecasting action outcomes and supports better decision making for mobile GUI agents. This is challenging because the model must predict post-action states with spatial awareness while remaining efficient enough for practical deployment. In this paper, we propose MobileDreamer, an efficient world-model-based lookahead framework to equip the GUI agents based on the future imagination provided by the world model. It consists of textual sketch world model and rollout imagination for GUI agent. Textual sketch world model forecasts post-action states through a learning process to transform digital images into key task-related sketches, and designs a novel order-invariant learning strategy to preserve the spatial information of GUI elements. The rollout imagination strategy for GUI agent optimizes the action-selection process by leveraging the prediction capability of world model. Experiments on Android World show that MobileDreamer achieves state-of-the-art performance and improves task success by 5.25%. World model evaluations further verify that our textual sketch modeling accurately forecasts key GUI elements.", "AI": {"tldr": "MobileDreamer\uff1a\u57fa\u4e8e\u4e16\u754c\u6a21\u578b\u7684\u79fb\u52a8GUI\u667a\u80fd\u4f53\u524d\u77bb\u6846\u67b6\uff0c\u901a\u8fc7\u6587\u672c\u8349\u56fe\u4e16\u754c\u6a21\u578b\u9884\u6d4b\u52a8\u4f5c\u540e\u72b6\u6001\uff0c\u63d0\u5347\u957f\u65f6\u7a0b\u4efb\u52a1\u6027\u80fd", "motivation": "\u73b0\u6709\u79fb\u52a8GUI\u667a\u80fd\u4f53\u591a\u4e3a\u53cd\u5e94\u5f0f\uff0c\u4ec5\u57fa\u4e8e\u5f53\u524d\u5c4f\u5e55\u51b3\u7b56\uff0c\u9650\u5236\u4e86\u957f\u65f6\u7a0b\u4efb\u52a1\u8868\u73b0\u3002\u6784\u5efa\u4e16\u754c\u6a21\u578b\u53ef\u901a\u8fc7\u9884\u6d4b\u52a8\u4f5c\u7ed3\u679c\u652f\u6301\u66f4\u597d\u51b3\u7b56\uff0c\u4f46\u9700\u5e73\u8861\u7a7a\u95f4\u611f\u77e5\u9884\u6d4b\u6548\u7387\u4e0e\u5b9e\u7528\u90e8\u7f72\u9700\u6c42\u3002", "method": "\u63d0\u51faMobileDreamer\u6846\u67b6\uff1a1) \u6587\u672c\u8349\u56fe\u4e16\u754c\u6a21\u578b\uff1a\u5c06\u6570\u5b57\u56fe\u50cf\u8f6c\u6362\u4e3a\u5173\u952e\u4efb\u52a1\u76f8\u5173\u8349\u56fe\uff0c\u91c7\u7528\u987a\u5e8f\u4e0d\u53d8\u5b66\u4e60\u7b56\u7565\u4fdd\u6301GUI\u5143\u7d20\u7a7a\u95f4\u4fe1\u606f\uff1b2) \u524d\u77bb\u63a8\u6f14\u7b56\u7565\uff1a\u5229\u7528\u4e16\u754c\u6a21\u578b\u9884\u6d4b\u80fd\u529b\u4f18\u5316\u52a8\u4f5c\u9009\u62e9\u8fc7\u7a0b", "result": "\u5728Android World\u5b9e\u9a8c\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u4efb\u52a1\u6210\u529f\u7387\u63d0\u53475.25%\u3002\u4e16\u754c\u6a21\u578b\u8bc4\u4f30\u9a8c\u8bc1\u6587\u672c\u8349\u56fe\u5efa\u6a21\u80fd\u51c6\u786e\u9884\u6d4b\u5173\u952eGUI\u5143\u7d20", "conclusion": "MobileDreamer\u901a\u8fc7\u9ad8\u6548\u7684\u4e16\u754c\u6a21\u578b\u524d\u77bb\u6846\u67b6\u663e\u8457\u63d0\u5347\u79fb\u52a8GUI\u667a\u80fd\u4f53\u5728\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8e\u4e16\u754c\u6a21\u578b\u7684\u60f3\u8c61\u673a\u5236\u5bf9GUI\u81ea\u52a8\u5316\u4efb\u52a1\u7684\u6709\u6548\u6027"}}
{"id": "2601.04060", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04060", "abs": "https://arxiv.org/abs/2601.04060", "authors": ["Jinwei Su", "Qizhen Lan", "Zeyu Wang", "Yinghui Xia", "Hairu Wen", "Yiqun Duan", "Xi Xiao", "Tianyu Shi", "Yang Jingsong", "Lewei He"], "title": "ComfySearch: Autonomous Exploration and Reasoning for ComfyUI Workflows", "comment": null, "summary": "AI-generated content has progressed from monolithic models to modular workflows, especially on platforms like ComfyUI, allowing users to customize complex creative pipelines. However, the large number of components in ComfyUI and the difficulty of maintaining long-horizon structural consistency under strict graph constraints frequently lead to low pass rates and workflows of limited quality. To tackle these limitations, we present ComfySearch, an agentic framework that can effectively explore the component space and generate functional ComfyUI pipelines via validation-guided workflow construction. Experiments demonstrate that ComfySearch substantially outperforms existing methods on complex and creative tasks, achieving higher executability (pass) rates, higher solution rates, and stronger generalization.", "AI": {"tldr": "ComfySearch\u662f\u4e00\u4e2a\u57fa\u4e8e\u4ee3\u7406\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728ComfyUI\u5e73\u53f0\u4e0a\u63a2\u7d22\u7ec4\u4ef6\u7a7a\u95f4\u5e76\u751f\u6210\u529f\u80fd\u6027\u7684\u5de5\u4f5c\u6d41\uff0c\u901a\u8fc7\u9a8c\u8bc1\u5f15\u5bfc\u7684\u5de5\u4f5c\u6d41\u6784\u5efa\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u590d\u6742\u521b\u610f\u4efb\u52a1\u4e2d\u7684\u4f4e\u901a\u8fc7\u7387\u95ee\u9898\u3002", "motivation": "ComfyUI\u5e73\u53f0\u4e0a\u7684AI\u751f\u6210\u5185\u5bb9\u5df2\u4ece\u5355\u4e00\u6a21\u578b\u53d1\u5c55\u4e3a\u6a21\u5757\u5316\u5de5\u4f5c\u6d41\uff0c\u4f46\u5927\u91cf\u7ec4\u4ef6\u548c\u4e25\u683c\u7684\u56fe\u7ea6\u675f\u5bfc\u81f4\u957f\u65f6\u7a0b\u7ed3\u6784\u4e00\u81f4\u6027\u96be\u4ee5\u4fdd\u6301\uff0c\u4f7f\u5f97\u5de5\u4f5c\u6d41\u901a\u8fc7\u7387\u4f4e\u4e14\u8d28\u91cf\u6709\u9650\u3002", "method": "\u63d0\u51fa\u4e86ComfySearch\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u9a8c\u8bc1\u5f15\u5bfc\u7684\u5de5\u4f5c\u6d41\u6784\u5efa\u6765\u6709\u6548\u63a2\u7d22\u7ec4\u4ef6\u7a7a\u95f4\uff0c\u751f\u6210\u529f\u80fd\u6027\u7684ComfyUI\u7ba1\u9053\u3002", "result": "\u5b9e\u9a8c\u8868\u660eComfySearch\u5728\u590d\u6742\u521b\u610f\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u53ef\u6267\u884c\u6027\uff08\u901a\u8fc7\uff09\u7387\u3001\u66f4\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\u7387\u548c\u66f4\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "ComfySearch\u901a\u8fc7\u9a8c\u8bc1\u5f15\u5bfc\u7684\u4ee3\u7406\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86ComfyUI\u5de5\u4f5c\u6d41\u6784\u5efa\u4e2d\u7684\u6311\u6218\uff0c\u4e3a\u6a21\u5757\u5316AI\u5185\u5bb9\u751f\u6210\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u548c\u9ad8\u8d28\u91cf\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.04170", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04170", "abs": "https://arxiv.org/abs/2601.04170", "authors": ["Abhishek Rath"], "title": "Agent Drift: Quantifying Behavioral Degradation in Multi-Agent LLM Systems Over Extended Interactions", "comment": null, "summary": "Multi-agent Large Language Model (LLM) systems have emerged as powerful architectures for complex task decomposition and collaborative problem-solving. However, their long-term behavioral stability remains largely unexamined. This study introduces the concept of agent drift, defined as the progressive degradation of agent behavior, decision quality, and inter-agent coherence over extended interaction sequences. We present a comprehensive theoretical framework for understanding drift phenomena, proposing three distinct manifestations: semantic drift (progressive deviation from original intent), coordination drift (breakdown in multi-agent consensus mechanisms), and behavioral drift (emergence of unintended strategies).\n  We introduce the Agent Stability Index (ASI), a novel composite metric framework for quantifying drift across twelve dimensions, including response consistency, tool usage patterns, reasoning pathway stability, and inter-agent agreement rates. Through simulation-based analysis and theoretical modeling, we demonstrate how unchecked agent drift can lead to substantial reductions in task completion accuracy and increased human intervention requirements.\n  We propose three mitigation strategies: episodic memory consolidation, drift-aware routing protocols, and adaptive behavioral anchoring. Theoretical analysis suggests these approaches can significantly reduce drift-related errors while maintaining system throughput. This work establishes a foundational methodology for monitoring, measuring, and mitigating agent drift in production agentic AI systems, with direct implications for enterprise deployment reliability and AI safety research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\"\u667a\u80fd\u4f53\u6f02\u79fb\"\u6982\u5ff5\uff0c\u5373\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u5728\u957f\u671f\u8fd0\u884c\u4e2d\u884c\u4e3a\u3001\u51b3\u7b56\u8d28\u91cf\u548c\u534f\u4f5c\u4e00\u81f4\u6027\u7684\u6e10\u8fdb\u9000\u5316\uff0c\u5e76\u5f00\u53d1\u4e86\u91cf\u5316\u6f02\u79fb\u7684ASI\u6307\u6807\u6846\u67b6\u548c\u4e09\u79cd\u7f13\u89e3\u7b56\u7565\u3002", "motivation": "\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u5df2\u6210\u4e3a\u590d\u6742\u4efb\u52a1\u5206\u89e3\u548c\u534f\u4f5c\u89e3\u51b3\u7684\u6709\u529b\u67b6\u6784\uff0c\u4f46\u5176\u957f\u671f\u884c\u4e3a\u7a33\u5b9a\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u9700\u8981\u7406\u89e3\u667a\u80fd\u4f53\u5728\u957f\u65f6\u95f4\u4ea4\u4e92\u5e8f\u5217\u4e2d\u884c\u4e3a\u9000\u5316\u7684\u73b0\u8c61\u53ca\u5176\u5bf9\u7cfb\u7edf\u53ef\u9760\u6027\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u667a\u80fd\u4f53\u6f02\u79fb\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5305\u62ec\u8bed\u4e49\u6f02\u79fb\u3001\u534f\u8c03\u6f02\u79fb\u548c\u884c\u4e3a\u6f02\u79fb\u4e09\u79cd\u8868\u73b0\u5f62\u5f0f\u3002\u5f00\u53d1\u4e86\u667a\u80fd\u4f53\u7a33\u5b9a\u6027\u6307\u6570\uff08ASI\uff09\u8fd9\u4e00\u590d\u5408\u5ea6\u91cf\u6846\u67b6\uff0c\u5305\u542b12\u4e2a\u7ef4\u5ea6\u6765\u91cf\u5316\u6f02\u79fb\u3002\u901a\u8fc7\u4eff\u771f\u5206\u6790\u548c\u7406\u8bba\u5efa\u6a21\u9a8c\u8bc1\u6f02\u79fb\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e09\u79cd\u7f13\u89e3\u7b56\u7565\uff1a\u60c5\u666f\u8bb0\u5fc6\u6574\u5408\u3001\u6f02\u79fb\u611f\u77e5\u8def\u7531\u534f\u8bae\u548c\u81ea\u9002\u5e94\u884c\u4e3a\u951a\u5b9a\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u672a\u53d7\u63a7\u5236\u7684\u667a\u80fd\u4f53\u6f02\u79fb\u4f1a\u5bfc\u81f4\u4efb\u52a1\u5b8c\u6210\u51c6\u786e\u7387\u663e\u8457\u4e0b\u964d\u548c\u4eba\u5de5\u5e72\u9884\u9700\u6c42\u589e\u52a0\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u63d0\u51fa\u7684\u7f13\u89e3\u7b56\u7565\u80fd\u591f\u663e\u8457\u51cf\u5c11\u6f02\u79fb\u76f8\u5173\u9519\u8bef\uff0c\u540c\u65f6\u4fdd\u6301\u7cfb\u7edf\u541e\u5410\u91cf\u3002", "conclusion": "\u672c\u7814\u7a76\u5efa\u7acb\u4e86\u76d1\u6d4b\u3001\u6d4b\u91cf\u548c\u7f13\u89e3\u751f\u4ea7\u6027\u667a\u80fdAI\u7cfb\u7edf\u4e2d\u667a\u80fd\u4f53\u6f02\u79fb\u7684\u57fa\u7840\u65b9\u6cd5\u8bba\uff0c\u5bf9\u4f01\u4e1a\u90e8\u7f72\u53ef\u9760\u6027\u548cAI\u5b89\u5168\u7814\u7a76\u5177\u6709\u76f4\u63a5\u610f\u4e49\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u957f\u671f\u7a33\u5b9a\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u8df5\u6307\u5bfc\u3002"}}
