<div id=toc></div>

# Table of Contents

- [econ.EM](#econ.EM) [Total: 2]
- [cs.AI](#cs.AI) [Total: 18]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.CY](#cs.CY) [Total: 7]
- [cs.ET](#cs.ET) [Total: 2]
- [stat.AP](#stat.AP) [Total: 5]


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [1] [Two-way Clustering Robust Variance Estimator in Quantile Regression Models](https://arxiv.org/abs/2602.16376)
*Ulrich Hounyo,Jiahao Lin*

Main category: econ.EM

TL;DR: 该论文研究双向聚类数据下的线性分位数回归推断，建立了自标准化高斯近似，提出了稳健方差估计器，并证明了高斯机制下的有效性，同时展示了非高斯交互机制下均匀推断的不可能性。


<details>
  <summary>Details</summary>
Motivation: 在实证研究中经常遇到双向聚类数据（如面板数据），传统分位数回归方法无法有效处理此类数据结构。需要开发适用于双向聚类数据的分位数回归推断方法，特别是在存在复杂依赖结构的情况下。

Method: 使用单独可交换数组框架和分位数得分的投影分解，表征机制依赖的收敛速度，建立自标准化高斯近似。提出双向聚类稳健三明治方差估计器，包含基于核的密度"面包"和投影匹配的"肉"。

Result: 证明了高斯机制下推断的一致性和有效性，建立了自标准化高斯近似。同时展示了非高斯交互机制下均匀推断的不可能性结果。

Conclusion: 该研究为双向聚类数据下的分位数回归提供了有效的推断方法，在高斯机制下具有理论保证，但揭示了在非高斯交互机制下均匀推断的局限性。

Abstract: We study inference for linear quantile regression with two-way clustered data. Using a separately exchangeable array framework and a projection decomposition of the quantile score, we characterize regime-dependent convergence rates and establish a self-normalized Gaussian approximation. We propose a two-way cluster-robust sandwich variance estimator with a kernel-based density ``bread'' and a projection-matched ``meat'', and prove consistency and validity of inference in Gaussian regimes. We also show an impossibility result for uniform inference in a non-Gaussian interaction regime.

</details>


### [2] [Model selection confidence sets for time series models with applications to electricity load data](https://arxiv.org/abs/2602.16527)
*Piersilvio De Bortoli,Davide Ferrari,Francesco Ravazzolo,Luca Rossini*

Main category: econ.EM

TL;DR: MSCS方法用于时间序列模型选择，识别统计上无法区分的模型集合，应用于意大利电力负荷数据，揭示模型选择不确定性和关键驱动因素。


<details>
  <summary>Details</summary>
Motivation: 传统模型选择方法依赖单一标准选择单个模型，忽略了模型选择的不确定性。本文旨在通过MSCS方法量化这种不确定性，特别是在电力负荷预测中识别统计上无法区分的候选模型集合。

Method: 提出Model Selection Confidence Set (MSCS)方法，为单变量时间序列模型（包含自回归和移动平均分量）构建置信集。该方法识别在给定置信水平下与真实数据生成过程统计上无法区分的模型集合。通过分析集合大小和组成来量化模型选择不确定性，并使用数值统计测量每个模型项在MSCS和Lower Boundary Models中的出现频率。

Result: 应用于意大利小时电力负荷数据，MSCS揭示了显著的日内模型选择不确定性变化。识别出包含日内小时滞后、温度、日历效应和太阳能发电等关键驱动因素的模型集合，这些模型在短期预测中表现具有竞争力。

Conclusion: MSCS方法提供了比传统单一模型选择更丰富的模型不确定性信息。在电力负荷预测中，该方法不仅识别了具有竞争力的预测模型，还揭示了关键驱动因素和模型选择不确定性的时间变化模式，为决策提供了更全面的依据。

Abstract: This paper studies the Model Selection Confidence Set (MSCS) methodology for univariate time series models involving autoregressive and moving average components, and applies it to study model selection uncertainty in the Italian electricity load data. Rather than relying on a single model selected by an arbitrary criterion, the MSCS identifies a set of models that are statistically indistinguishable from the true data-generating process at a given confidence level. The size and composition of this set reveal crucial information about model selection uncertainty: noisy data scenarios produce larger sets with many candidate models, while more informative cases narrow the set considerably. To study the importance of each model term, we consider numerical statistics measuring the frequency with which each term is included in both the entire MSCS and in Lower Boundary Models (LBM), its most parsimonious specifications. Applied to Italian hourly electricity load data, the MSCS methodology reveals marked intraday variation in model selection uncertainty and isolates a collection of model specifications that deliver competitive short-term forecasts while highlighting key drivers of electricity load like intraday hourly lags, temperature, calendar effects and solar energy generation.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [3] [Towards Efficient Constraint Handling in Neural Solvers for Routing Problems](https://arxiv.org/abs/2602.16012)
*Jieyi Bi,Zhiguang Cao,Jianan Zhou,Wen Song,Yaoxin Wu,Jie Zhang,Yining Ma,Cathy Wu*

Main category: cs.AI

TL;DR: CaR是一个用于神经路由求解器的约束处理框架，通过显式的基于学习的可行性精炼，在保持计算效率的同时处理复杂约束。


<details>
  <summary>Details</summary>
Motivation: 现有神经求解器在简单路由问题上表现出色，但在复杂约束下表现有限。当前的约束处理方案（可行性掩码或隐式可行性感知）对于硬约束要么效率低下，要么不适用。

Method: 提出Construct-and-Refine (CaR)框架，通过联合训练指导构造模块生成多样且高质量的解决方案，这些方案适合轻量级改进过程（如10步 vs 之前工作的5k步）。首次使用构造-改进共享表示，统一编码器以实现跨范式的知识共享。

Result: 在典型硬路由约束上的评估显示，CaR在可行性、解决方案质量和效率方面均优于经典和神经SOTA求解器。

Conclusion: CaR是第一个通用且高效的神经路由求解器约束处理框架，通过显式学习可行性精炼，在处理复杂约束时展现出优越性能。

Abstract: Neural solvers have achieved impressive progress in addressing simple routing problems, particularly excelling in computational efficiency. However, their advantages under complex constraints remain nascent, for which current constraint-handling schemes via feasibility masking or implicit feasibility awareness can be inefficient or inapplicable for hard constraints. In this paper, we present Construct-and-Refine (CaR), the first general and efficient constraint-handling framework for neural routing solvers based on explicit learning-based feasibility refinement. Unlike prior construction-search hybrids that target reducing optimality gaps through heavy improvements yet still struggle with hard constraints, CaR achieves efficient constraint handling by designing a joint training framework that guides the construction module to generate diverse and high-quality solutions well-suited for a lightweight improvement process, e.g., 10 steps versus 5k steps in prior work. Moreover, CaR presents the first use of construction-improvement-shared representation, enabling potential knowledge sharing across paradigms by unifying the encoder, especially in more complex constrained scenarios. We evaluate CaR on typical hard routing constraints to showcase its broader applicability. Results demonstrate that CaR achieves superior feasibility, solution quality, and efficiency compared to both classical and neural state-of-the-art solvers.

</details>


### [4] [Optimization Instability in Autonomous Agentic Workflows for Clinical Symptom Detection](https://arxiv.org/abs/2602.16037)
*Cameron Cagan,Pedram Fard,Jiazi Tian,Jingya Cheng,Shawn N. Murphy,Hossein Estiri*

Main category: cs.AI

TL;DR: 自主代理工作流在持续优化中可能出现性能退化，尤其是在低患病率分类任务中，验证敏感度会在1.0和0.0之间振荡，而回顾性选择比主动干预更有效


<details>
  <summary>Details</summary>
Motivation: 研究自主代理工作流在持续自我优化过程中的失败模式，特别是优化不稳定现象——持续自主改进反而降低分类器性能的问题

Method: 使用Pythia开源框架进行自动提示优化，评估三种不同患病率的临床症状（呼吸困难23%、胸痛12%、长新冠脑雾3%），测试两种干预措施：引导代理主动重定向优化和选择代理回顾性识别最佳迭代

Result: 验证敏感度在迭代过程中在1.0和0.0之间振荡，严重程度与类别患病率成反比；在3%患病率时，系统达到95%准确率但检测到零阳性病例；选择代理监督下，系统在脑雾检测上比专家策划词典高出331%（F1），胸痛检测高出7%

Conclusion: 研究揭示了自主AI系统的关键失败模式，并证明在低患病率分类任务中，回顾性选择比主动干预更能有效稳定系统性能

Abstract: Autonomous agentic workflows that iteratively refine their own behavior hold considerable promise, yet their failure modes remain poorly characterized. We investigate optimization instability, a phenomenon in which continued autonomous improvement paradoxically degrades classifier performance, using Pythia, an open-source framework for automated prompt optimization. Evaluating three clinical symptoms with varying prevalence (shortness of breath at 23%, chest pain at 12%, and Long COVID brain fog at 3%), we observed that validation sensitivity oscillated between 1.0 and 0.0 across iterations, with severity inversely proportional to class prevalence. At 3% prevalence, the system achieved 95% accuracy while detecting zero positive cases, a failure mode obscured by standard evaluation metrics. We evaluated two interventions: a guiding agent that actively redirected optimization, amplifying overfitting rather than correcting it, and a selector agent that retrospectively identified the best-performing iteration successfully prevented catastrophic failure. With selector agent oversight, the system outperformed expert-curated lexicons on brain fog detection by 331% (F1) and chest pain by 7%, despite requiring only a single natural language term as input. These findings characterize a critical failure mode of autonomous AI systems and demonstrate that retrospective selection outperforms active intervention for stabilization in low-prevalence classification tasks.

</details>


### [5] [How Uncertain Is the Grade? A Benchmark of Uncertainty Metrics for LLM-Based Automatic Assessment](https://arxiv.org/abs/2602.16039)
*Hang Li,Kaiqi Yang,Xianxuan Long,Fedor Filippov,Yucheng Chu,Yasemin Copur-Gencturk,Peng He,Cory Miller,Namsoo Shin,Joseph Krajcik,Hui Liu,Jiliang Tang*

Main category: cs.AI

TL;DR: 本文系统评估了大语言模型在教育自动评估中的不确定性量化方法，揭示了不确定性模式、影响因素，为开发更可靠的评估系统提供指导。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在教育自动评估中展现出优势，但其固有的概率性本质带来了输出不确定性的挑战。评估结果对后续教学决策至关重要，不可靠的不确定性估计可能导致不稳定的教学干预，影响学生学习。目前不确定性量化方法在教育评估场景中的适用性和可靠性尚未充分探索。

Method: 通过在多评估数据集、LLM家族和生成控制设置下进行综合分析，基准测试了广泛的不确定性量化方法。研究了LLM在评分场景中表现出的不确定性模式，评估了不同不确定性指标的优缺点，并分析了模型家族、评估任务和解码策略等关键因素对不确定性估计的影响。

Result: 研究揭示了LLM在自动评分中的不确定性行为模式，评估了不同不确定性指标的性能和局限性，分析了模型家族、任务类型和解码策略对不确定性估计的系统性影响。

Conclusion: 该研究为理解LLM自动评估中的不确定性特征提供了可操作的见解，为未来开发更可靠、有效的不确定性感知评分系统奠定了基础。

Abstract: The rapid rise of large language models (LLMs) is reshaping the landscape of automatic assessment in education. While these systems demonstrate substantial advantages in adaptability to diverse question types and flexibility in output formats, they also introduce new challenges related to output uncertainty, stemming from the inherently probabilistic nature of LLMs. Output uncertainty is an inescapable challenge in automatic assessment, as assessment results often play a critical role in informing subsequent pedagogical actions, such as providing feedback to students or guiding instructional decisions. Unreliable or poorly calibrated uncertainty estimates can lead to unstable downstream interventions, potentially disrupting students' learning processes and resulting in unintended negative consequences. To systematically understand this challenge and inform future research, we benchmark a broad range of uncertainty quantification methods in the context of LLM-based automatic assessment. Although the effectiveness of these methods has been demonstrated in many tasks across other domains, their applicability and reliability in educational settings, particularly for automatic grading, remain underexplored. Through comprehensive analyses of uncertainty behaviors across multiple assessment datasets, LLM families, and generation control settings, we characterize the uncertainty patterns exhibited by LLMs in grading scenarios. Based on these findings, we evaluate the strengths and limitations of different uncertainty metrics and analyze the influence of key factors, including model families, assessment tasks, and decoding strategies, on uncertainty estimates. Our study provides actionable insights into the characteristics of uncertainty in LLM-based automatic assessment and lays the groundwork for developing more reliable and effective uncertainty-aware grading systems in the future.

</details>


### [6] [Evidence-Grounded Subspecialty Reasoning: Evaluating a Curated Clinical Intelligence Layer on the 2025 Endocrinology Board-Style Examination](https://arxiv.org/abs/2602.16050)
*Amir Hosseinian,MohammadReza Zare Shahneh,Umer Mansoor,Gilbert Szeto,Kirill Karlin,Nima Aghaeepour*

Main category: cs.AI

TL;DR: January Mirror系统在120道内分泌学考试中达到87.5%准确率，超过人类参考(62.3%)和前沿LLMs，证明证据溯源系统在专科临床推理中的优势


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在普通医学考试中表现良好，但在专科临床推理方面仍面临挑战，因为专科指南更新快且证据层次复杂。需要开发能够整合专业证据库的临床推理系统。

Method: 开发January Mirror系统，整合精选的内分泌和心脏代谢证据库，采用结构化推理架构生成证据链接输出。在封闭证据约束下运行，与具有实时网络访问权限的前沿LLMs(GPT-5、GPT-5.2、Gemini-3-Pro)在120道内分泌学考试中进行比较。

Result: Mirror达到87.5%准确率，显著超过人类参考(62.3%)和所有前沿LLMs。在最难的30道题中达到76.7%准确率。74.2%的输出引用了指南级证据源，且引用准确率100%。

Conclusion: 具有明确溯源的精选证据系统在专科临床推理中优于无约束的网络检索，支持临床部署的可审计性。证据溯源能力对临床决策支持系统至关重要。

Abstract: Background: Large language models have demonstrated strong performance on general medical examinations, but subspecialty clinical reasoning remains challenging due to rapidly evolving guidelines and nuanced evidence hierarchies. Methods: We evaluated January Mirror, an evidence-grounded clinical reasoning system, against frontier LLMs (GPT-5, GPT-5.2, Gemini-3-Pro) on a 120-question endocrinology board-style examination. Mirror integrates a curated endocrinology and cardiometabolic evidence corpus with a structured reasoning architecture to generate evidence-linked outputs. Mirror operated under a closed-evidence constraint without external retrieval. Comparator LLMs had real-time web access to guidelines and primary literature. Results: Mirror achieved 87.5% accuracy (105/120; 95% CI: 80.4-92.3%), exceeding a human reference of 62.3% and frontier LLMs including GPT-5.2 (74.6%), GPT-5 (74.0%), and Gemini-3-Pro (69.8%). On the 30 most difficult questions (human accuracy less than 50%), Mirror achieved 76.7% accuracy. Top-2 accuracy was 92.5% for Mirror versus 85.25% for GPT-5.2. Conclusions: Mirror provided evidence traceability: 74.2% of outputs cited at least one guideline-tier source, with 100% citation accuracy on manual verification. Curated evidence with explicit provenance can outperform unconstrained web retrieval for subspecialty clinical reasoning and supports auditability for clinical deployment.

</details>


### [7] [Towards a Science of AI Agent Reliability](https://arxiv.org/abs/2602.16666)
*Stephan Rabanser,Sayash Kapoor,Peter Kirgis,Kangheng Liu,Saiteja Utpala,Arvind Narayanan*

Main category: cs.AI

TL;DR: 论文提出12个具体指标，从一致性、鲁棒性、可预测性和安全性四个维度分解AI代理的可靠性，发现当前能力提升对可靠性改善有限


<details>
  <summary>Details</summary>
Motivation: 当前AI代理评估存在根本性局限：将代理行为压缩为单一成功率指标会掩盖关键的操作缺陷，无法评估代理在不同运行中的一致性、抗干扰能力、失败可预测性或错误严重程度

Method: 基于安全关键工程原理，提出12个具体指标，从一致性、鲁棒性、可预测性和安全性四个关键维度分解代理可靠性，并在两个互补基准上评估14个代理模型

Result: 研究发现最近的能力提升仅带来可靠性方面的微小改善，暴露了代理的持续局限性

Conclusion: 提出的指标补充了传统评估方法，为理解代理如何执行、退化和失败提供了工具，有助于更全面地评估AI代理的可靠性

Abstract: AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on standard benchmarks suggest rapid progress, many agents still continue to fail in practice. This discrepancy highlights a fundamental limitation of current evaluations: compressing agent behavior into a single success metric obscures critical operational flaws. Notably, it ignores whether agents behave consistently across runs, withstand perturbations, fail predictably, or have bounded error severity. Grounded in safety-critical engineering, we provide a holistic performance profile by proposing twelve concrete metrics that decompose agent reliability along four key dimensions: consistency, robustness, predictability, and safety. Evaluating 14 agentic models across two complementary benchmarks, we find that recent capability gains have only yielded small improvements in reliability. By exposing these persistent limitations, our metrics complement traditional evaluations while offering tools for reasoning about how agents perform, degrade, and fail.

</details>


### [8] [Improving Interactive In-Context Learning from Natural Language Feedback](https://arxiv.org/abs/2602.16066)
*Martin Klissarov,Jonathan Cook,Diego Antognini,Hao Sun,Jingling Li,Natasha Jaques,Claudiu Musat,Edward Grefenstette*

Main category: cs.AI

TL;DR: 该论文提出了一种训练框架，将交互式上下文学习视为可训练技能而非涌现特性，通过信息不对称将单轮任务转化为多轮教学互动，显著提升了模型从语言反馈中学习的能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型训练主要依赖静态语料库建模，忽视了人类学习中基于纠正反馈动态调整思维过程的关键能力。现有的训练范式虽然有效获取知识，但缺乏交互式反馈循环，限制了模型在上下文中动态适应的能力。

Method: 提出可扩展方法，将单轮可验证任务转化为由信息不对称驱动的多轮教学互动。通过训练模型整合语言反馈，将交互式上下文学习作为独立可训练技能。进一步通过让模型预测教师批评来建模反馈环境，将外部信号转化为内部能力。

Result: 1) 当前旗舰模型在困难推理任务上难以整合纠正反馈；2) 使用该方法训练后，模型交互式学习能力显著提升，较小模型的多轮表现接近大一个数量级的大模型；3) 观察到强大的分布外泛化能力：数学问题的交互训练能迁移到编程、谜题和迷宫导航等领域；4) 模型获得了增强的上下文可塑性，并能通过自我纠正实现自我改进。

Conclusion: 交互式上下文学习应被视为可训练技能而非涌现特性。通过将单轮任务转化为多轮教学互动，模型能显著提升从反馈中学习的能力，并实现跨领域泛化和自我改进，为语言模型训练提供了新范式。

Abstract: Adapting one's thought process based on corrective feedback is an essential ability in human learning, particularly in collaborative settings. In contrast, the current large language model training paradigm relies heavily on modeling vast, static corpora. While effective for knowledge acquisition, it overlooks the interactive feedback loops essential for models to adapt dynamically to their context. In this work, we propose a framework that treats this interactive in-context learning ability not as an emergent property, but as a distinct, trainable skill. We introduce a scalable method that transforms single-turn verifiable tasks into multi-turn didactic interactions driven by information asymmetry. We first show that current flagship models struggle to integrate corrective feedback on hard reasoning tasks. We then demonstrate that models trained with our approach dramatically improve the ability to interactively learn from language feedback. More specifically, the multi-turn performance of a smaller model nearly reaches that of a model an order of magnitude larger. We also observe robust out-of-distribution generalization: interactive training on math problems transfers to diverse domains like coding, puzzles and maze navigation. Our qualitative analysis suggests that this improvement is due to an enhanced in-context plasticity. Finally, we show that this paradigm offers a unified path to self-improvement. By training the model to predict the teacher's critiques, effectively modeling the feedback environment, we convert this external signal into an internal capability, allowing the model to self-correct even without a teacher.

</details>


### [9] [GPSBench: Do Large Language Models Understand GPS Coordinates?](https://arxiv.org/abs/2602.16105)
*Thinh Hung Truong,Jey Han Lau,Jianzhong Qi*

Main category: cs.AI

TL;DR: GPSBench是一个包含57,800个样本、涵盖17个任务的评估数据集，用于测试LLM在GPS坐标和地理空间推理方面的能力，发现当前模型在几何坐标计算方面较弱，但在真实世界地理推理方面表现较好。


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地应用于与物理世界交互的应用（如导航、机器人、地图），强大的地理空间推理能力变得至关重要。然而，LLM在GPS坐标和真实世界地理推理方面的能力尚未得到充分探索。

Method: 作者提出了GPSBench数据集，包含57,800个样本，涵盖17个任务，包括几何坐标操作（如距离和方位计算）以及将坐标与世界知识结合的推理任务。评估了14个最先进的LLM，专注于模型内在能力而非工具使用。

Result: GPS推理仍然具有挑战性，不同任务间存在显著差异：模型在真实世界地理推理方面通常比几何计算更可靠。地理知识呈层次性退化，国家级别表现强但城市级别定位弱。对坐标噪声的鲁棒性表明模型具有真正的坐标理解而非单纯记忆。GPS坐标增强可以改善下游地理空间任务，微调会在几何计算收益和世界知识退化之间产生权衡。

Conclusion: 地理空间推理是LLM的一个重要但尚未充分开发的能力领域。GPSBench为评估和改进LLM的地理空间推理能力提供了基准，揭示了当前模型的局限性，并展示了通过坐标增强和微调来改进的潜力。

Abstract: Large Language Models (LLMs) are increasingly deployed in applications that interact with the physical world, such as navigation, robotics, or mapping, making robust geospatial reasoning a critical capability. Despite that, LLMs' ability to reason about GPS coordinates and real-world geography remains underexplored. We introduce GPSBench, a dataset of 57,800 samples across 17 tasks for evaluating geospatial reasoning in LLMs, spanning geometric coordinate operations (e.g., distance and bearing computation) and reasoning that integrates coordinates with world knowledge. Focusing on intrinsic model capabilities rather than tool use, we evaluate 14 state-of-the-art LLMs and find that GPS reasoning remains challenging, with substantial variation across tasks: models are generally more reliable at real-world geographic reasoning than at geometric computations. Geographic knowledge degrades hierarchically, with strong country-level performance but weak city-level localization, while robustness to coordinate noise suggests genuine coordinate understanding rather than memorization. We further show that GPS-coordinate augmentation can improve in downstream geospatial tasks, and that finetuning induces trade-offs between gains in geometric computation and degradation in world knowledge. Our dataset and reproducible code are available at https://github.com/joey234/gpsbench

</details>


### [10] [Learning Personalized Agents from Human Feedback](https://arxiv.org/abs/2602.16173)
*Kaiqu Liang,Julia Kruk,Shengyi Qian,Xianjun Yang,Shengjie Bi,Yuanshun Yao,Shaoliang Nie,Mingyang Zhang,Lijuan Liu,Jaime Fernández Fisac,Shuyan Zhou,Saghar Hosseini*

Main category: cs.AI

TL;DR: PAHF框架通过显式用户记忆和双反馈通道实现AI代理的持续个性化，显著提升新用户偏好学习和偏好漂移适应能力


<details>
  <summary>Details</summary>
Motivation: 现有AI代理虽然强大，但难以适应个体用户的独特且不断演变的偏好。传统方法依赖静态数据集，要么基于交互历史训练隐式偏好模型，要么将用户档案编码到外部记忆中，但这些方法在新用户和偏好随时间变化时表现不佳。

Method: 提出个性化人类反馈代理(PAHF)框架，通过显式用户记忆实现持续个性化。采用三步循环：(1)寻求行动前澄清以解决歧义，(2)基于从记忆中检索的偏好进行行动，(3)整合行动后反馈以更新记忆（当偏好漂移时）。开发了四阶段协议和两个基准测试（具身操作和在线购物）。

Result: 理论分析和实证结果表明，将显式记忆与双反馈通道结合至关重要：PAHF学习速度显著更快，始终优于无记忆和单通道基线，减少了初始个性化误差，并能够快速适应偏好变化。

Conclusion: PAHF框架通过显式用户记忆和双反馈机制有效解决了AI代理持续个性化的问题，在初始偏好学习和偏好漂移适应方面表现出色，为构建更适应用户个性化需求的AI系统提供了有效方法。

Abstract: Modern AI agents are powerful but often fail to align with the idiosyncratic, evolving preferences of individual users. Prior approaches typically rely on static datasets, either training implicit preference models on interaction history or encoding user profiles in external memory. However, these approaches struggle with new users and with preferences that change over time. We introduce Personalized Agents from Human Feedback (PAHF), a framework for continual personalization in which agents learn online from live interaction using explicit per-user memory. PAHF operationalizes a three-step loop: (1) seeking pre-action clarification to resolve ambiguity, (2) grounding actions in preferences retrieved from memory, and (3) integrating post-action feedback to update memory when preferences drift. To evaluate this capability, we develop a four-phase protocol and two benchmarks in embodied manipulation and online shopping. These benchmarks quantify an agent's ability to learn initial preferences from scratch and subsequently adapt to persona shifts. Our theoretical analysis and empirical results show that integrating explicit memory with dual feedback channels is critical: PAHF learns substantially faster and consistently outperforms both no-memory and single-channel baselines, reducing initial personalization error and enabling rapid adaptation to preference shifts.

</details>


### [11] [EnterpriseGym Corecraft: Training Generalizable Agents on High-Fidelity RL Environments](https://arxiv.org/abs/2602.16179)
*Sushant Mehta,Logan Ritchie,Suhaas Garre,Nick Heiner,Edwin Chen*

Main category: cs.AI

TL;DR: 在CoreCraft企业模拟环境中训练AI代理，其能力可泛化到训练分布之外，在多个外部基准测试中取得显著提升


<details>
  <summary>Details</summary>
Motivation: 研究AI代理在高保真强化学习环境中训练后，其能力是否能泛化到训练分布之外，探索环境质量、多样性和真实性对代理泛化能力的影响

Method: 开发CoreCraft企业模拟环境（包含2500+实体、14种实体类型、23种工具），使用GRPO（Group Relative Policy Optimization）和自适应裁剪训练GLM 4.6模型，在单轮训练后评估任务通过率和外部基准测试表现

Result: 训练后任务通过率从25.37%提升至36.76%；在外部基准测试中：BFCL Parallel提升4.5%，τ²-Bench Retail提升7.4%，Toolathlon（Pass@1）提升6.8%

Conclusion: 环境质量、多样性和真实性是使AI代理能力具有泛化性的关键因素，任务中心的世界构建、专家编写的评估标准和反映真实工作流程的设计有助于实现能力迁移

Abstract: We show that training AI agents on high-fidelity reinforcement learning environments produces capabilities that generalize beyond the training distribution. We introduce \corecraft{}, the first environment in \textsc{EnterpriseGym}, Surge AI's suite of agentic RL environments. \corecraft{} is a fully operational enterprise simulation of a customer support organization, comprising over 2,500 entities across 14 entity types with 23 unique tools, designed to measure whether AI agents can perform the multi-step, domain-specific work that real jobs demand. Frontier models such as GPT-5.2 and Claude Opus 4.6 solve fewer than 30\% of tasks when all expert-authored rubric criteria must be satisfied. Using this environment, we train GLM~4.6 with Group Relative Policy Optimization (GRPO) and adaptive clipping. After a single epoch of training, the model improves from 25.37\% to 36.76\% task pass rate on held-out evaluation tasks. More importantly, these gains transfer to out-of-distribution benchmarks: +4.5\% on BFCL Parallel, +7.4\% on $τ^2$-Bench Retail, and +6.8\% on Toolathlon (Pass@1). We believe three environment properties are consistent with the observed transfer: task-centric world building that optimizes for diverse, challenging tasks; expert-authored rubrics enabling reliable reward computation; and enterprise workflows that reflect realistic professional patterns. Our results suggest that environment quality, diversity, and realism are key factors enabling generalizable agent capabilities.

</details>


### [12] [Revolutionizing Long-Term Memory in AI: New Horizons with High-Capacity and High-Speed Storage](https://arxiv.org/abs/2602.16192)
*Hiroaki Yamanaka,Daisuke Miyashita,Takashi Toi,Asuka Maki,Taiga Ikeda,Jun Deguchi*

Main category: cs.AI

TL;DR: 论文探讨了实现人工超智能所需的关键"记忆"设计概念，提出了"先存储后按需提取"等替代方法，强调保留原始经验以避免信息损失，并通过简单实验验证了这些方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前主流的"先提取后存储"范式存在信息损失风险，因为提取过程中可能丢弃对不同任务有价值的知识。为了提升人工超智能的记忆能力，需要探索更有效的记忆设计方法。

Method: 提出了四种替代方法：1）"先存储后按需提取" - 保留原始经验并灵活应用于不同任务；2）从大量概率性经验中发现深层洞察；3）通过共享存储经验提高经验收集效率；4）通过简单实验验证这些方法的有效性。

Result: 简单实验证实了这些替代方法的有效性，表明它们确实能够避免信息损失并提高记忆系统的性能。

Conclusion: 论文指出了限制这些有前景方向研究的主要挑战，并提出了相应的研究课题，为人工超智能的记忆系统设计提供了新的思路和方向。

Abstract: Driven by our mission of "uplifting the world with memory," this paper explores the design concept of "memory" that is essential for achieving artificial superintelligence (ASI). Rather than proposing novel methods, we focus on several alternative approaches whose potential benefits are widely imaginable, yet have remained largely unexplored. The currently dominant paradigm, which can be termed "extract then store," involves extracting information judged to be useful from experiences and saving only the extracted content. However, this approach inherently risks the loss of information, as some valuable knowledge particularly for different tasks may be discarded in the extraction process. In contrast, we emphasize the "store then on-demand extract" approach, which seeks to retain raw experiences and flexibly apply them to various tasks as needed, thus avoiding such information loss. In addition, we highlight two further approaches: discovering deeper insights from large collections of probabilistic experiences, and improving experience collection efficiency by sharing stored experiences. While these approaches seem intuitively effective, our simple experiments demonstrate that this is indeed the case. Finally, we discuss major challenges that have limited investigation into these promising directions and propose research topics to address them.

</details>


### [13] [Toward Scalable Verifiable Reward: Proxy State-Based Evaluation for Multi-turn Tool-Calling LLM Agents](https://arxiv.org/abs/2602.16246)
*Yun-Shiuan Chuang,Chaitanya Kulkarni,Alec Chiu,Avinash Thangali,Zijie Pan,Shivani Shekhar,Yirou Ge,Yixi Li,Uma Kona,Linsey Pang,Prakhar Mehrotra*

Main category: cs.AI

TL;DR: 提出Proxy State-Based Evaluation框架，使用LLM驱动的模拟来评估交互式LLM智能体，避免构建确定性数据库的成本


<details>
  <summary>Details</summary>
Motivation: 现有智能体基准（如tau-bench、AppWorld）依赖完全确定性的后端，构建和维护成本高昂，需要更实用、可扩展的评估方法

Method: 通过场景规范定义用户目标、事实、期望最终状态和行为，使用LLM状态跟踪器从交互轨迹推断结构化代理状态，再由LLM评判器验证目标完成和检测幻觉

Result: 基准产生稳定、能区分不同模型的排名，支持敏感度分析，人类-LLM评判器一致性超过90%，模拟器幻觉率接近零

Conclusion: 代理状态评估为工业LLM智能体提供了实用、可扩展的确定性基准替代方案，支持自动评估和训练数据生成

Abstract: Interactive large language model (LLM) agents operating via multi-turn dialogue and multi-step tool calling are increasingly used in production. Benchmarks for these agents must both reliably compare models and yield on-policy training data. Prior agentic benchmarks (e.g., tau-bench, tau2-bench, AppWorld) rely on fully deterministic backends, which are costly to build and iterate. We propose Proxy State-Based Evaluation, an LLM-driven simulation framework that preserves final state-based evaluation without a deterministic database. Specifically, a scenario specifies the user goal, user/system facts, expected final state, and expected agent behavior, and an LLM state tracker infers a structured proxy state from the full interaction trace. LLM judges then verify goal completion and detect tool/user hallucinations against scenario constraints. Empirically, our benchmark produces stable, model-differentiating rankings across families and inference-time reasoning efforts, and its on-/off-policy rollouts provide supervision that transfers to unseen scenarios. Careful scenario specification yields near-zero simulator hallucination rates as supported by ablation studies. The framework also supports sensitivity analyses over user personas. Human-LLM judge agreement exceeds 90%, indicating reliable automated evaluation. Overall, proxy state-based evaluation offers a practical, scalable alternative to deterministic agentic benchmarks for industrial LLM agents.

</details>


### [14] [Multi-agent cooperation through in-context co-player inference](https://arxiv.org/abs/2602.16301)
*Marissa A. Weis,Maciej Wołczyk,Rajai Nasser,Rif A. Saurous,Blaise Agüera y Arcas,João Sacramento,Alexander Meulemans*

Main category: cs.AI

TL;DR: 序列模型通过上下文学习实现多智能体合作，无需硬编码假设或显式时间尺度分离，仅需与多样化对手训练即可自然涌现合作行为。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要硬编码对手学习规则假设或强制区分快速更新的"朴素学习者"和观察这些更新的"元学习者"，这限制了多智能体强化学习中自利智能体合作的实现。

Method: 使用序列模型的上下文学习能力，训练智能体对抗多样化的对手分布，让智能体在快速时间尺度上自然地学习上下文最佳响应策略，无需硬编码假设或显式时间尺度分离。

Result: 序列模型智能体通过上下文适应变得容易受到勒索攻击，这种相互压力促使智能体塑造对手的上下文学习动态，最终自然涌现出合作行为。

Conclusion: 序列模型的去中心化强化学习结合对手多样性，为学习合作行为提供了可扩展的路径，无需复杂的元学习架构或硬编码假设。

Abstract: Achieving cooperation among self-interested agents remains a fundamental challenge in multi-agent reinforcement learning. Recent work showed that mutual cooperation can be induced between "learning-aware" agents that account for and shape the learning dynamics of their co-players. However, existing approaches typically rely on hardcoded, often inconsistent, assumptions about co-player learning rules or enforce a strict separation between "naive learners" updating on fast timescales and "meta-learners" observing these updates. Here, we demonstrate that the in-context learning capabilities of sequence models allow for co-player learning awareness without requiring hardcoded assumptions or explicit timescale separation. We show that training sequence model agents against a diverse distribution of co-players naturally induces in-context best-response strategies, effectively functioning as learning algorithms on the fast intra-episode timescale. We find that the cooperative mechanism identified in prior work-where vulnerability to extortion drives mutual shaping-emerges naturally in this setting: in-context adaptation renders agents vulnerable to extortion, and the resulting mutual pressure to shape the opponent's in-context learning dynamics resolves into the learning of cooperative behavior. Our results suggest that standard decentralized reinforcement learning on sequence models combined with co-player diversity provides a scalable path to learning cooperative behaviors.

</details>


### [15] [Verifiable Semantics for Agent-to-Agent Communication](https://arxiv.org/abs/2602.16424)
*Philipp Schoenegger,Matt Carlson,Chris Schneider,Chris Daly*

Main category: cs.AI

TL;DR: 提出基于刺激-意义模型的认证协议，通过测试智能体在可观测事件上的一致性来认证术语，确保通信语义对齐


<details>
  <summary>Details</summary>
Motivation: 多智能体AI系统需要一致的通信，但目前缺乏验证智能体对术语理解是否一致的方法。自然语言可解释但易受语义漂移影响，而学习协议高效但不透明

Method: 基于刺激-意义模型设计认证协议：测试智能体在共享可观测事件上的表现，如果经验分歧低于统计阈值则认证术语。智能体限制推理于认证术语（核心防护推理）可实现可证明的有界分歧。还包括检测漂移的重新认证机制和恢复共享词汇的重新协商机制

Result: 在语义分歧程度不同的模拟中，核心防护将分歧减少72-96%。在使用微调语言模型的验证中，分歧减少51%

Conclusion: 该框架为可验证的智能体间通信提供了第一步，通过统计认证确保语义对齐，减少通信分歧

Abstract: Multiagent AI systems require consistent communication, but we lack methods to verify that agents share the same understanding of the terms used. Natural language is interpretable but vulnerable to semantic drift, while learned protocols are efficient but opaque. We propose a certification protocol based on the stimulus-meaning model, where agents are tested on shared observable events and terms are certified if empirical disagreement falls below a statistical threshold. In this protocol, agents restricting their reasoning to certified terms ("core-guarded reasoning") achieve provably bounded disagreement. We also outline mechanisms for detecting drift (recertification) and recovering shared vocabulary (renegotiation). In simulations with varying degrees of semantic divergence, core-guarding reduces disagreement by 72-96%. In a validation with fine-tuned language models, disagreement is reduced by 51%. Our framework provides a first step towards verifiable agent-to-agent communication.

</details>


### [16] [Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.16435)
*Arun Vignesh Malarkkan,Wangyang Ying,Yanjie Fu*

Main category: cs.AI

TL;DR: CAFE框架将自动特征工程重新定义为因果引导的序列决策过程，通过因果发现和强化学习结合，提升特征工程的鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有自动特征工程方法依赖统计启发式，产生的特征在分布偏移下表现脆弱。需要结合因果结构来提升特征的鲁棒性。

Method: 两阶段方法：第一阶段学习稀疏有向无环图获取软因果先验，将特征按因果影响分组；第二阶段使用级联多智能体深度Q学习架构选择因果组和变换算子，采用分层奖励塑造和因果组级探索策略。

Result: 在15个公共基准测试中，CAFE相比基线提升达7%，减少收敛所需回合数，在协变量偏移下性能下降减少约4倍，产生更紧凑的特征集和更稳定的后验归因。

Conclusion: 因果结构作为软归纳先验而非刚性约束，能显著提升自动特征工程的鲁棒性和效率。

Abstract: Automated feature engineering (AFE) enables AI systems to autonomously construct high-utility representations from raw tabular data. However, existing AFE methods rely on statistical heuristics, yielding brittle features that fail under distribution shift. We introduce CAFE, a framework that reformulates AFE as a causally-guided sequential decision process, bridging causal discovery with reinforcement learning-driven feature construction. Phase I learns a sparse directed acyclic graph over features and the target to obtain soft causal priors, grouping features as direct, indirect, or other based on their causal influence with respect to the target. Phase II uses a cascading multi-agent deep Q-learning architecture to select causal groups and transformation operators, with hierarchical reward shaping and causal group-level exploration strategies that favor causally plausible transformations while controlling feature complexity. Across 15 public benchmarks (classification with macro-F1; regression with inverse relative absolute error), CAFE achieves up to 7% improvement over strong AFE baselines, reduces episodes-to-convergence, and delivers competitive time-to-target. Under controlled covariate shifts, CAFE reduces performance drop by ~4x relative to a non-causal multi-agent baseline, and produces more compact feature sets with more stable post-hoc attributions. These findings underscore that causal structure, used as a soft inductive prior rather than a rigid constraint, can substantially improve the robustness and efficiency of automated feature engineering.

</details>


### [17] [Leveraging Large Language Models for Causal Discovery: a Constraint-based, Argumentation-driven Approach](https://arxiv.org/abs/2602.16481)
*Zihao Li,Fabrizio Russo*

Main category: cs.AI

TL;DR: 该论文探索使用大型语言模型作为不完美专家，为因果ABA框架提供语义结构先验，结合条件独立性证据，在标准基准测试中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 因果发现需要专家知识构建原则性因果图，但专家知识获取困难。同时，现有统计方法虽然能利用观测数据，但缺乏与输入约束的符号推理保证。因果假设论证(ABA)框架能确保输入约束与输出图之间的对应关系，但需要专家知识输入。

Method: 使用大型语言模型作为不完美专家，从变量名称和描述中提取语义结构先验，将这些先验与条件独立性证据结合，集成到因果ABA框架中。还引入了评估协议来减轻评估LLMs时的记忆偏差。

Result: 在标准基准测试和语义基础合成图上展示了最先进的性能。提出的评估协议有效减轻了LLMs在因果发现评估中的记忆偏差问题。

Conclusion: LLMs可以作为有效的"不完美专家"为因果ABA提供语义先验，结合条件独立性证据能实现强大的因果发现性能。该方法为结合符号推理和统计证据提供了有前景的途径。

Abstract: Causal discovery seeks to uncover causal relations from data, typically represented as causal graphs, and is essential for predicting the effects of interventions. While expert knowledge is required to construct principled causal graphs, many statistical methods have been proposed to leverage observational data with varying formal guarantees. Causal Assumption-based Argumentation (ABA) is a framework that uses symbolic reasoning to ensure correspondence between input constraints and output graphs, while offering a principled way to combine data and expertise. We explore the use of large language models (LLMs) as imperfect experts for Causal ABA, eliciting semantic structural priors from variable names and descriptions and integrating them with conditional-independence evidence. Experiments on standard benchmarks and semantically grounded synthetic graphs demonstrate state-of-the-art performance, and we additionally introduce an evaluation protocol to mitigate memorisation bias when assessing LLMs for causal discovery.

</details>


### [18] [Framework of Thoughts: A Foundation Framework for Dynamic and Optimized Reasoning based on Chains, Trees, and Graphs](https://arxiv.org/abs/2602.16512)
*Felix Fricke,Simon Malberg,Georg Groh*

Main category: cs.AI

TL;DR: FoT是一个通用的基础框架，用于构建和优化动态推理方案，通过超参数调优、提示优化、并行执行和智能缓存来提升推理方案的性能。


<details>
  <summary>Details</summary>
Motivation: 现有提示方案（如Chain of Thought、Tree of Thoughts等）存在两个主要问题：1）需要用户定义静态的、特定于问题的推理结构，缺乏对动态或未见问题类型的适应性；2）在超参数、提示、运行时间和提示成本方面通常未优化。

Method: 提出了Framework of Thoughts (FoT)，这是一个通用的基础框架，具有内置的超参数调优、提示优化、并行执行和智能缓存功能。通过在FoT中实现Tree of Thoughts、Graph of Thoughts和ProbTree三种流行方案来展示其能力。

Result: 实验证明FoT能够显著加快执行速度、降低成本，并通过优化获得更好的任务分数。代码库已开源以促进未来动态高效推理方案的发展。

Conclusion: FoT通过提供统一的优化框架，解决了现有推理方案缺乏适应性和未优化的问题，为构建动态高效的推理方案提供了基础支持。

Abstract: Prompting schemes such as Chain of Thought, Tree of Thoughts, and Graph of Thoughts can significantly enhance the reasoning capabilities of large language models. However, most existing schemes require users to define static, problem-specific reasoning structures that lack adaptability to dynamic or unseen problem types. Additionally, these schemes are often under-optimized in terms of hyperparameters, prompts, runtime, and prompting cost. To address these limitations, we introduce Framework of Thoughts (FoT)--a general-purpose foundation framework for building and optimizing dynamic reasoning schemes. FoT comes with built-in features for hyperparameter tuning, prompt optimization, parallel execution, and intelligent caching, unlocking the latent performance potential of reasoning schemes. We demonstrate FoT's capabilities by implementing three popular schemes--Tree of Thoughts, Graph of Thoughts, and ProbTree--within FoT. We empirically show that FoT enables significantly faster execution, reduces costs, and achieves better task scores through optimization. We release our codebase to facilitate the development of future dynamic and efficient reasoning schemes.

</details>


### [19] [Creating a digital poet](https://arxiv.org/abs/2602.16578)
*Vered Tohar,Tsahi Hayat,Amir Leshem*

Main category: cs.AI

TL;DR: 通过七个月的诗歌工作坊，研究人员使用大型语言模型通过迭代式上下文专家反馈塑造了一个数字诗人，该模型能够创作出与人类诗歌难以区分的作品，并在盲测中达到随机水平。


<details>
  <summary>Details</summary>
Motivation: 探索机器能否创作出优秀的诗歌，这涉及到艺术本质和价值的根本问题。研究旨在测试通过工作坊式提示能否支持长期创造性塑造，并重新引发关于创造力和作者身份的讨论。

Method: 进行为期七个月的诗歌工作坊，通过迭代式上下文专家反馈（无需重新训练）将大型语言模型塑造成数字诗人。使用定量和定性分析评估模型发展出的独特风格和连贯作品集。进行盲测实验，让50名人文学生和毕业生判断六首诗（三首AI创作，三首知名诗人作品）的作者身份。

Result: 模型发展出了独特的风格和连贯的作品集，并创建了笔名和作者形象。盲测结果显示：人类诗歌被标记为人类的准确率为54%，AI诗歌被标记为AI的准确率为52%（95%置信区间包含50%），判断处于随机水平。工作坊后，商业出版社出版了该模型的诗集。

Conclusion: 工作坊式提示能够支持长期创造性塑造，使AI创作的诗歌在盲测中与人类作品难以区分。这一发现更新了关于创造力和作者身份的讨论，表明机器能够创作出被认可为艺术的诗歌作品。

Abstract: Can a machine write good poetry? Any positive answer raises fundamental questions about the nature and value of art. We report a seven-month poetry workshop in which a large language model was shaped into a digital poet through iterative in-context expert feedback, without retraining. Across sessions, the model developed a distinctive style and a coherent corpus, supported by quantitative and qualitative analyses, and it produced a pen name and author image. In a blinded authorship test with 50 humanities students and graduates (three AI poems and three poems by well-known poets each), judgments were at chance: human poems were labeled human 54% of the time and AI poems 52%, with 95% confidence intervals including 50%. After the workshop, a commercial publisher released a poetry collection authored by the model. These results show that workshop-style prompting can support long-horizon creative shaping and renew debates on creativity and authorship.

</details>


### [20] [Agent Skill Framework: Perspectives on the Potential of Small Language Models in Industrial Environments](https://arxiv.org/abs/2602.16653)
*Yangjie Xu,Lujun Li,Lama Sleem,Niccolo Gentile,Yewei Song,Yiqun Wang,Siming Ji,Wenbo Wu,Radu State*

Main category: cs.AI

TL;DR: Agent Skill框架对中小型语言模型（特别是12B-30B参数）有显著提升效果，但在超小型模型上效果有限，80B参数的代码专用模型能达到闭源基线性能。


<details>
  <summary>Details</summary>
Motivation: 研究Agent Skill范式是否能为小型语言模型带来类似大型专有模型的性能提升，解决工业场景中因数据安全和预算限制无法持续依赖公共API的问题。

Method: 首先形式化定义Agent Skill过程的数学模型，然后系统评估不同规模的语言模型在多个用例中的表现，包括两个开源任务和一个真实世界保险索赔数据集。

Result: 超小型模型在可靠技能选择方面表现不佳，中等规模SLMs（约12B-30B参数）从Agent Skill方法中获益显著，约80B参数的代码专用变体在提升GPU效率的同时达到闭源基线性能。

Conclusion: 研究全面描述了Agent Skill框架在小语言模型环境中的能力和限制，为在SLM中心化环境中有效部署Agent Skills提供了实用见解。

Abstract: Agent Skill framework, now widely and officially supported by major players such as GitHub Copilot, LangChain, and OpenAI, performs especially well with proprietary models by improving context engineering, reducing hallucinations, and boosting task accuracy. Based on these observations, an investigation is conducted to determine whether the Agent Skill paradigm provides similar benefits to small language models (SLMs). This question matters in industrial scenarios where continuous reliance on public APIs is infeasible due to data-security and budget constraints requirements, and where SLMs often show limited generalization in highly customized scenarios. This work introduces a formal mathematical definition of the Agent Skill process, followed by a systematic evaluation of language models of varying sizes across multiple use cases. The evaluation encompasses two open-source tasks and a real-world insurance claims data set. The results show that tiny models struggle with reliable skill selection, while moderately sized SLMs (approximately 12B - 30B) parameters) benefit substantially from the Agent Skill approach. Moreover, code-specialized variants at around 80B parameters achieve performance comparable to closed-source baselines while improving GPU efficiency. Collectively, these findings provide a comprehensive and nuanced characterization of the capabilities and constraints of the framework, while providing actionable insights for the effective deployment of Agent Skills in SLM-centered environments.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [21] [Individual Fairness in Community Detection: Quantitative Measure and Comparative Evaluation](https://arxiv.org/abs/2602.16326)
*Fabrizio Corriera,Frank W. Takes,Akrati Saxena*

Main category: cs.SI

TL;DR: 该论文提出了一种量化社区检测中个体公平性的新度量方法，通过实证研究发现个体不公平性可能在群体公平性或聚类准确性较高时仍然存在，并识别了在不同网络密度下实现个体公平性与社区质量更好权衡的算法。


<details>
  <summary>Details</summary>
Motivation: 当前公平性社区检测研究主要关注群体公平性，但缺乏对个体公平性的量化评估。社区检测作为复杂网络分析的基础任务，其公平性对下游任务有重要影响，需要开发能够同时考虑个体公平性的方法。

Method: 提出基于节点真实与预测社区表示向量距离的个体公平性度量方法，使用社区共现矩阵计算。在合成网络（不同社区显性程度）和真实网络上对多种社区检测算法进行综合实证研究，分析公平性与性能的权衡关系。

Result: 研究发现：1）个体不公平性可能在群体公平性或聚类准确性较高时仍然存在；2）个体公平性与群体公平性不可互换；3）公平性严重依赖社区结构的可检测性；4）对于稠密图，Significance和Surprise算法表现更好；对于稀疏图，Combo、Leiden和SBMDL算法表现更好。

Conclusion: 个体公平性与群体公平性是不同的概念，需要分别考虑。社区检测作为网络分析的重要步骤，开发公平性感知的社区检测方法具有必要性。研究结果为算法选择提供了指导，并强调了在社区检测中同时考虑个体公平性的重要性。

Abstract: Community detection is a fundamental task in complex network analysis. Fairness-aware community detection seeks to prevent biased node partitions, typically framed in terms of individual fairness, which requires similar nodes to be treated similarly, and group fairness, which aims to avoid disadvantaging specific groups of nodes. While existing literature on fair community detection has primarily focused on group fairness, we introduce a novel measure to quantify individual fairness in community detection methods. The proposed measure captures unfairness as the vectorial distance between a node's true and predicted community representations, computed using the community co-occurrence matrix. We provide a comprehensive empirical investigation of a broad set of community detection algorithms from the literature on both synthetic networks, with varying levels of community explicitness, and real-world networks. We particularly investigate the fairness-performance trade-off using standard quality metrics and compare individual fairness outcomes with existing group fairness measures. The results show that individual unfairness can occur even when group fairness or clustering accuracy is high, underscoring that individual and group fairness are not interchangeable. Moreover, fairness depends critically on the detectability of community structure. However, we find that Significance and Surprise for denser graphs, and Combo, Leiden, and SBMDL for sparser graphs result in a better trade-off between individual fairness and community quality. Overall, our findings, together with the fact that community detection is an important step in many network analysis downstream tasks, highlight the necessity of developing fairness-aware community detection methods.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [22] [Should There be a Teacher In-the-Loop? A Study of Generative AI Personalized Tasks Middle School](https://arxiv.org/abs/2602.15876)
*Candace Walkington,Mingyu Feng,Itffini Pruitt-Britton,Theodora Beauchamp,Andrew Lan*

Main category: cs.CY

TL;DR: 教师与ChatGPT合作创建个性化数学问题，研究发现教师参与导致粗粒度个性化，而学生偏好细粒度流行文化引用，教师调整过程耗时且效率提升有限。


<details>
  <summary>Details</summary>
Motivation: 探索教师使用生成式AI（ChatGPT）创建个性化学习任务的实际效率，尽管商业工具声称能节省教师时间，但教师参与过程的实际效率尚不明确。

Method: 7名中学数学教师与ChatGPT合作，根据学生兴趣个性化课程问题；分析教师的提示策略、创建效率，以及521名七年级学生对个性化作业的反应。

Result: 教师参与导致生成式AI增强的个性化以相对粗粒度实施，而学生偏好包含具体流行文化引用的细粒度个性化；教师花费大量精力调整流行文化引用、解决问题深度或现实性问题；教师能提高与AI合作创建有趣问题的能力，但过程并未变得特别高效。

Conclusion: 教师与生成式AI合作创建个性化任务需要大量调整工作，效率提升有限；学生偏好与教师实施方式存在粒度差异；需要更好的工具支持教师高效个性化教学。

Abstract: Adapting instruction to the fine-grained needs of individual students is a powerful application of recent advances in large language models. These generative AI models can create tasks that correspond to students' interests and enact context personalization, enhancing students' interest in learning academic content. However, when there is a teacher in-the-loop creating or modifying tasks with generative AI, it is unclear how efficient this process might be, despite commercial generative AI tools' claims that they will save teachers time. In the present study, we teamed 7 middle school mathematics teachers with ChatGPT to create personalized versions of problems in their curriculum, to correspond to their students' interests. We look at the prompting moves teachers made, their efficiency when creating problems, and the reactions of their 521 7th grade students who received the personalized assignments. We find that having a teacher-in-the-loop results in generative AI-enhanced personalization being enacted at a relatively broad grain size, whereas students tend to prefer a smaller grain size where they receive specific popular culture references that interest them. Teachers spent a lot of effort adjusting popular culture references and addressing issues with the depth or realism of the problems generated, giving higher or lower levels of ownership to the generative AI. Teachers were able to improve in their ability to craft interesting problems in partnership with generative AI, but this process did not appear to become particularly time efficient as teachers learned and reflected on their students' data, iterating their approaches.

</details>


### [23] [Pluralism in AI Governance: Toward Sociotechnical Alignment and Normative Coherence](https://arxiv.org/abs/2602.15881)
*Mike Wa Nkongolo*

Main category: cs.CY

TL;DR: 该论文探讨了如何将公共价值嵌入国家AI治理框架，提出了一个连接价值、机制和策略的分层框架，并通过比较不同司法管辖区展示了多元化的监管哲学。


<details>
  <summary>Details</summary>
Motivation: 随着AI渗透到医疗、司法和公共管理等关键领域，治理的合法性不仅取决于技术正确性，还需要与社会规范、民主原则和人类尊严保持一致。传统范式过于关注模型安全或市场效率，忽视了更广泛的制度背景。

Method: 研究综合了包括全栈对齐、厚价值模型、价值敏感设计和公共宪法AI在内的多个框架，并对欧盟、美国、中国、英国、巴西和南非等司法管辖区进行了比较分析。提出了一个连接价值、机制和策略的分层框架。

Result: 研究发现存在多元化的监管哲学，南非的主权导向方法提供了独特的对比视角。研究识别了公平与效率、透明度与安全、隐私与公平等核心张力。

Conclusion: 该研究贡献了一个整体性的、价值敏感的AI治理模型，将监管重新定义为将公共价值嵌入社会技术系统的主动机制，强调了在AI治理中嵌入公共价值的重要性。

Abstract: This paper examines the challenge of embedding public values into national artificial intelligence (AI) governance frameworks, a task complicated by the sociotechnical nature of contemporary systems. As AI permeates domains such as healthcare, justice, and public administration, legitimacy depends not only on technical correctness but on alignment with societal norms, democratic principles, and human dignity. Traditional paradigms focused on model safety or market efficiency neglect broader institutional contexts. To address this, the study synthesises frameworks including Full-Stack Alignment, Thick Models of Value, Value Sensitive Design, and Public Constitutional AI, alongside comparative analysis of jurisdictions such as the EU, US, China, UK, Brazil, and South Africa (SA). It introduces a layered framework linking values, mechanisms, and strategies, and maps tensions such as fairness versus efficiency, transparency versus security, and privacy versus equity. Findings reveal a pluralism of regulatory philosophies, with SA sovereignty-oriented approach offering a distinctive counterpoint. The study contributes a holistic, value-sensitive model of AI governance, reframing regulation as a proactive mechanism for embedding public values into sociotechnical systems.

</details>


### [24] [Queer NLP: A Critical Survey on Literature Gaps, Biases and Trends](https://arxiv.org/abs/2602.16151)
*Sabine Weber,Angelina Wang,Ankush Gupta,Arjun Subramonian,Dennis Ulmer,Eshaan Tanwar,Geetanjali Aich,Hannah Devinney,Jacob Hobbs,Jennifer Mickel,Joshua Tint,Mae Sosto,Ray Groshan,Simone Astarita,Vagrant Gautam,Verena Blaschke,William Agnew,Wilson Y Lee,Yanan Long*

Main category: cs.CY

TL;DR: 这篇综述系统回顾了NLP技术与LGBTQIA+社区关系的研究现状，发现该领域论文数量虽在增长，但大多采取被动而非主动的方法，更多是指出偏见而非缓解偏见，关注现有系统的缺陷而非创造新解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着NLP技术在招聘、法律、医疗等影响人们生活的领域应用日益广泛，理解和减轻对边缘化群体（特别是LGBTQIA+社区）的伤害变得至关重要。需要系统了解当前研究现状、发现研究空白并为未来工作指明方向。

Method: 系统性地回顾了ACL Anthology中所有明确探讨LGBTQIA+社区与NLP技术关系的论文，通过回答三个研究问题来分析当前研究趋势、方法空白和未来工作方向。

Result: 发现虽然近年来关于queer NLP的论文数量有所增长，但大多数论文采取被动而非主动的方法：更多是指出偏见而非缓解偏见，关注现有系统的缺陷而非创造新解决方案。研究存在利益相关者参与不足、交叉性考虑不够、跨学科合作缺乏、非英语语言研究稀少等问题。

Conclusion: 该调查不仅是对现有研究的路线图，更是对构建更公正、包容的NLP技术的行动呼吁。未来工作需要更多利益相关者参与、考虑交叉性、加强跨学科合作、关注非英语语言，并从酷儿研究视角填补研究空白。

Abstract: Natural language processing (NLP) technologies are rapidly reshaping how language is created, processed, and analyzed by humans. With current and potential applications in hiring, law, healthcare, and other areas that impact people's lives, understanding and mitigating harms towards marginalized groups is critical. In this survey, we examine NLP research papers that explicitly address the relationship between LGBTQIA+ communities and NLP technologies. We systematically review all such papers published in the ACL Anthology, to answer the following research questions: (1) What are current research trends? (2) What gaps exist in terms of topics and methods? (3) What areas are open for future work? We find that while the number of papers on queer NLP has grown within the last few years, most papers take a reactive rather than a proactive approach, pointing out bias more often than mitigating it, and focusing on shortcomings of existing systems rather than creating new solutions. Our survey uncovers many opportunities for future work, especially regarding stakeholder involvement, intersectionality, interdisciplinarity, and languages other than English. We also offer an outlook from a queer studies perspective, highlighting understudied topics and gaps in the harms addressed in NLP papers. Beyond being a roadmap of what has been done, this survey is a call to action for work towards more just and inclusive NLP technologies.

</details>


### [25] [Generative AI Usage of University Students: Navigating Between Education and Business](https://arxiv.org/abs/2602.16307)
*Fabian Walke,Veronika Föller*

Main category: cs.CY

TL;DR: 研究采用扎根理论方法，探讨在职大学生的生成式AI使用特征，识别了影响使用的因果条件、中介条件和策略，揭示了教育与企业应用交叉的潜力与挑战。


<details>
  <summary>Details</summary>
Motivation: 现有文献很少关注在职学生以及生成式AI在教育与商业交叉领域的使用情况，本研究旨在填补这一空白，深入了解在职学生的生成式AI使用特征。

Method: 采用扎根理论方法，对11名远程教育大学的学生进行访谈，通过质性分析识别影响生成式AI使用的各种条件因素。

Result: 识别了三个因果条件和四个中介条件，以及相应的策略，这些因素共同影响生成式AI的使用。研究发现生成式AI能显著提高生产力和学习效果，但也存在伦理问题、可靠性和学术不端风险等挑战。

Conclusion: 开发的扎根模型为理解学生使用生成式AI提供了全面框架，为教育者、政策制定者和AI工具开发者弥合教育与商业之间的差距提供了宝贵见解。

Abstract: This study investigates generative artificial intelligence (GenAI) usage of university students who study alongside their professional career. Previous literature has paid little attention to part-time students and the intersectional use of GenAI between education and business. This study examines with a grounded theory approach the characteristics of GenAI usage of part-time students. Eleven students from a distance learning university were interviewed. Three causal and four intervening conditions, as well as strategies were identified, to influence the use of GenAI. The study highlights both the potential and challenges of GenAI usage in education and business. While GenAI can significantly enhance productivity and learning outcomes, concerns about ethical implications, reliability, and the risk of academic misconduct persist. The developed grounded model offers a comprehensive understanding of GenAI usage among students, providing valuable insights for educators, policymakers, and developers of GenAI tools seeking to bridge the gap between education and business.

</details>


### [26] [Agentic AI, Medical Morality, and the Transformation of the Patient-Physician Relationship](https://arxiv.org/abs/2602.16553)
*Robert Ranisch,Sabine Salloch*

Main category: cs.CY

TL;DR: 本文探讨了智能体AI如何重塑医疗保健的道德结构，强调需要在广泛部署前进行伦理预见


<details>
  <summary>Details</summary>
Motivation: 智能体AI作为医疗数字化的新阶段，与传统生成式AI不同，能够自主执行目标导向行动和复杂任务协调。虽然引发了安全、问责和偏见等常见道德问题，但本文关注其更少被探讨的维度：改变医疗保健本身的道德结构

Method: 采用技术-道德变革框架，从决策、关系和感知三个领域分析智能体AI如何重塑医患关系和重新配置医疗道德核心概念

Result: 智能体AI可能从根本上改变医疗道德结构，这些转变虽不完全可预测，但在广泛部署前需要伦理关注

Conclusion: 应将伦理预见整合到智能体AI的设计和使用中，以应对其对医疗道德结构的潜在重塑

Abstract: The emergence of agentic AI marks a new phase in the digital transformation of healthcare. Distinct from conventional generative AI, agentic AI systems are capable of autonomous, goal-directed actions and complex task coordination. They promise to support or even collaborate with clinicians and patients in increasingly independent ways. While agentic AI raises familiar moral concerns regarding safety, accountability, and bias, this article focuses on a less explored dimension: its capacity to transform the moral fabric of healthcare itself. Drawing on the framework of techno-moral change and the three domains of decision, relation and perception, we investigate how agentic AI might reshape the patient-physician relationship and reconfigure core concepts of medical morality. We argue that these shifts, while not fully predictable, demand ethical attention before widespread deployment. Ultimately, the paper calls for integrating ethical foresight into the design and use of agentic AI.

</details>


### [27] [Hidden in Plain Sight: Detecting Illicit Massage Businesses from Mobility Data](https://arxiv.org/abs/2602.16561)
*Roya Shomali,Nick Freeman,Greg Bott,Iman Dayarian,Jason Parton*

Main category: cs.CY

TL;DR: 利用移动数据检测非法按摩店，通过正例-未标记学习解决标签不对称问题，模型AUC达0.97，识别出四大运营特征，为执法部门提供风险评分系统


<details>
  <summary>Details</summary>
Motivation: 非法按摩店(IMBs)伪装成合法按摩店从事性交易和人口贩卖，是美国室内性交易的最大组成部分。传统基于在线评论的检测方法容易被操纵，且许多场所完全避免数字可见性。执法资源有限，需要更有效的检测方法。

Method: 使用移动数据提取特征：时间访问模式、停留时间、访客来源区域、需求稳定性。采用正例-未标记学习解决标签不对称问题（只有通过广告平台确认的非法场所标签）。开发决策支持系统为执法部门提供校准的风险评分。

Result: 模型达到0.97 AUC和0.84平均精度。识别出四大运营特征：需求一致性、晚间集中访问、压缩服务时长、本地客户来源。在最高风险10%的按摩店中捕获53%的已知非法运营，比无信息检查提高5.3倍。

Conclusion: 移动数据提供了一种有效的非法按摩店检测方法，其运营特征难以被操纵。模型为执法部门提供了实用的决策支持工具，能显著提高检查效率。这种方法可扩展到其他隐蔽的非法活动检测。

Abstract: Illicit massage businesses (IMBs) masquerade as legitimate massage parlors while facilitating commercial sex and human trafficking. Law enforcement must identify these businesses within a dense population of lawful establishments, but investigative resources are limited and the illicit status of each location is unknown until inspection. Detection methods based on online reviews offer some insight, yet operators can manipulate these signals, leaving covert establishments undetected. IMBs constitute one of the largest segments of indoor sex trafficking in the United States, with an estimated 9,000 establishments. Mobility data offers an alternative to online signals, covering establishments that avoid digital visibility entirely. We derive features from mobility data spanning temporal visitation patterns, dwell times, visitor catchment areas, and demand stability. Because confirmed labels exist only for establishments identified through advertising platforms, we employ positive-unlabeled learning to address the label asymmetry in ground truth. The model achieves 0.97 AUC and 0.84 Average Precision. Four operational signatures characterize high-risk establishments: demand consistency, evening-concentrated visits, compressed service durations, and locally drawn clientele. The model produces risk scores for each business-week observation. Aggregating to the business level, prioritizing the highest-risk 10% of massage establishments captures 53% of known illicit operations, a 5.3-fold improvement over uninformed inspection. We develop a decision-support system that produces calibrated prioritization scores for law enforcement, enabling investigators to concentrate inspections on the highest-risk venues. The operational signatures may resist strategic manipulation because they reflect actual operations rather than online signals that operators can control.

</details>


### [28] [Measuring Mid-2025 LLM-Assistance on Novice Performance in Biology](https://arxiv.org/abs/2602.16703)
*Shen Zhou Hong,Alex Kleinman,Alyssa Mathiowetz,Adam Howes,Julian Cohen,Suveer Ganta,Alex Letizia,Dora Liao,Deepika Pahari,Xavier Roberts-Gaal,Luca Righetti,Joe Torres*

Main category: cs.CY

TL;DR: LLMs在生物安全评估中显示出有限的实验室操作提升效果，虽然在某些任务中有数值优势，但未显著提高新手完成复杂实验室流程的能力


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型是否真的能帮助新手在物理实验室中执行双重用途的生物技术操作，验证AI生物安全评估在现实世界中的有效性

Method: 采用预注册、研究者盲法、随机对照试验设计，招募153名参与者，比较LLM辅助与互联网搜索在模拟病毒反向遗传学工作流程任务中的表现

Result: 工作流程完成率无显著差异（LLM 5.2% vs 互联网 6.6%），但LLM组在4/5任务中成功率数值更高，特别是细胞培养任务（68.8% vs 55.3%）。贝叶斯模型估计LLM辅助下典型任务成功率约提高1.4倍

Conclusion: 2025年中期的LLMs并未显著提升新手完成复杂实验室程序的能力，但显示出适度的性能优势，揭示了AI生物安全评估在虚拟基准测试与现实效用之间的差距

Abstract: Large language models (LLMs) perform strongly on biological benchmarks, raising concerns that they may help novice actors acquire dual-use laboratory skills. Yet, whether this translates to improved human performance in the physical laboratory remains unclear. To address this, we conducted a pre-registered, investigator-blinded, randomized controlled trial (June-August 2025; n = 153) evaluating whether LLMs improve novice performance in tasks that collectively model a viral reverse genetics workflow. We observed no significant difference in the primary endpoint of workflow completion (5.2% LLM vs. 6.6% Internet; P = 0.759), nor in the success rate of individual tasks. However, the LLM arm had numerically higher success rates in four of the five tasks, most notably for the cell culture task (68.8% LLM vs. 55.3% Internet; P = 0.059). Post-hoc Bayesian modeling of pooled data estimates an approximate 1.4-fold increase (95% CrI 0.74-2.62) in success for a "typical" reverse genetics task under LLM assistance. Ordinal regression modelling suggests that participants in the LLM arm were more likely to progress through intermediate steps across all tasks (posterior probability of a positive effect: 81%-96%). Overall, mid-2025 LLMs did not substantially increase novice completion of complex laboratory procedures but were associated with a modest performance benefit. These results reveal a gap between in silico benchmarks and real-world utility, underscoring the need for physical-world validation of AI biosecurity assessments as model capabilities and user proficiency evolve.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [29] [Decomposing Large-Scale Ising Problems on FPGAs: A Hybrid Hardware Approach](https://arxiv.org/abs/2602.15985)
*Ruihong Yin,Yue Zheng,Chaohui Li,Ahmet Efe,Abhimanyu Kumar,Ziqing Zeng,Ulya R. Karpuzcu,Sachin S. Sapatnekar,Chris H. Kim*

Main category: cs.ET

TL;DR: 提出异构系统，将分解工作负载卸载到FPGA，与模拟伊辛求解器紧密集成，减少通信延迟，实现2倍加速和百倍能效提升


<details>
  <summary>Details</summary>
Motivation: 模拟计算基板（如振荡器伊辛机）在组合优化中收敛快，但受物理实现限制难以扩展。处理数千变量需要问题分解，但CPU分解引入高延迟，限制了高速求解器的性能发挥

Method: 设计异构系统，将分解逻辑迁移到可重构硬件（FPGA），利用并行处理元件，与28nm定制伊辛求解器紧密集成，最小化主机-设备通信延迟

Result: 该协同设计方法有效弥合了数字预处理和模拟求解之间的速度差距，相比现代CPU上的优化软件基线，实现了近2倍加速和超过两个数量级的能效提升

Conclusion: 通过将分解工作负载卸载到FPGA并与模拟伊辛求解器紧密集成，可以显著减少通信延迟，使高速模拟求解器能够充分发挥性能，为大规模组合优化问题提供高效解决方案

Abstract: Emerging analog computing substrates, such as oscillator-based Ising machines, offer rapid convergence times for combinatorial optimization but often suffer from limited scalability due to physical implementation constraints. To tackle real-world problems involving thousands of variables, problem decomposition is required; however, performing this step on standard CPUs introduces significant latency, preventing the high-speed solver from operating at full capacity. This work presents a heterogeneous system that offloads the decomposition workload to an FPGA, tightly integrated with a custom 28nm Ising solver. By migrating the decomposition logic to reconfigurable hardware and utilizing parallel processing elements, the system minimizes the communication latency typically associated with host-device interactions. Our evaluation demonstrates that this co-design approach effectively bridges the speed gap between digital preprocessing and analog solving, achieving nearly 2$\times$ speedup and an energy efficiency improvement of over two orders of magnitude compared to optimized software baselines running on modern CPUs.

</details>


### [30] [Bibby AI -- AI Latex Editor writing assistant for researchers vs Overleaf Alternative vs OpenAI Prism. (Bibby AI Latex Editor)](https://arxiv.org/abs/2602.16432)
*Nilesh jain,Rohit Yadav,Andrej Karpathy*

Main category: cs.ET

TL;DR: Bibby AI是一款原生AI优先的LaTeX编辑器，集成了智能写作助手、文献搜索、表格公式生成、论文审阅等功能，在LaTeX错误检测和修复方面显著优于现有工具。


<details>
  <summary>Details</summary>
Motivation: 当前主流的LaTeX编辑器缺乏原生AI支持，研究人员需要在不同工具间切换，导致文档上下文碎片化和写作流程中断，需要一个统一的AI优先研究写作平台。

Method: 开发Bibby AI作为原生AI优先的LaTeX编辑器，集成多种AI功能；创建LaTeXBench-500基准测试，包含500个真实编译错误，用于评估错误检测和修复能力。

Result: Bibby AI在LaTeX错误检测准确率达到91.4%，一键修复准确率83.7%，显著优于Overleaf原生诊断（61.2%）和OpenAI Prism（78.3%/64.1%）。

Conclusion: Bibby AI证明了一个注重隐私、以研究为先的AI编辑器能够显著加速学术手稿准备的各个阶段，是比Overleaf和OpenAI Prism更优越的替代方案。

Abstract: Large language models are increasingly integrated into academic writing workflows; however, the most widely used \LaTeX\ editors remain AI-peripheral -- offering compilation and collaboration, but no native intelligence. This separation forces researchers to leave their editing environment for AI assistance, fragmenting document context and interrupting writing flow. We present Bibby AI (trybibby.com), a native, AI-first \LaTeX\ editor that unifies the complete research writing lifecycle within a single interface. Bibby embeds an AI writing assistant, smart citation search, AI table and equation generation, an AI paper reviewer, abstract generator, literature review drafting, a deep research assistant, and real-time \LaTeX\ error detection and auto-fix -- all natively, without plugins or copy-paste workflows. We introduce LaTeXBench-500, a benchmark of 500 real-world compilation errors across six categories. Bibby achieves 91.4\% detection accuracy and 83.7\% one-click fix accuracy, outperforming Overleaf's native diagnostics (61.2\%) and OpenAI Prism (78.3 / 64.1\%) by large margins. Bibby demonstrates that a privacy-preserving, research-first AI editor can meaningfully accelerate every stage of academic manuscript preparation. We found that Bibby AI is a far superior alternative to overleaf latex and better than OpenAI Prism functionalities and AI.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [31] [Evidence for Daily and Weekly Periodic Variability in GPT-4o Performance](https://arxiv.org/abs/2602.15889)
*Paul Tschisgale,Peter Wulff*

Main category: stat.AP

TL;DR: GPT-4o在固定条件下解决物理选择题的性能随时间呈现周期性变化，约20%的方差可由日周期和周周期解释，挑战了LLM性能时间不变的假设。


<details>
  <summary>Details</summary>
Motivation: 当前研究通常假设在固定条件（相同模型版本、超参数和提示）下，LLM的性能是时间不变的。如果平均输出质量随时间系统性变化，这一假设将被违反，威胁研究结果的可靠性、有效性和可重复性。

Method: 使用固定模型快照、固定超参数和相同提示，通过API每3小时查询GPT-4o解决相同的多项选择物理任务，持续约3个月。每个时间点生成10个独立响应并计算平均分数，对得到的时间序列进行频谱（傅里叶）分析。

Result: 频谱分析显示模型平均性能存在显著的周期性变化，约占总方差的20%。观察到的周期性模式很好地由日节奏和周节奏的相互作用解释，表明即使在受控条件下，LLM性能也可能随时间周期性变化。

Conclusion: LLM性能在固定条件下并非时间不变，而是呈现周期性变化，这挑战了当前研究的基本假设。研究结果对确保使用或研究LLM的科研工作的有效性和可重复性具有重要意义。

Abstract: Large language models (LLMs) are increasingly used in research both as tools and as objects of investigation. Much of this work implicitly assumes that LLM performance under fixed conditions (identical model snapshot, hyperparameters, and prompt) is time-invariant. If average output quality changes systematically over time, this assumption is violated, threatening the reliability, validity, and reproducibility of findings. To empirically examine this assumption, we conducted a longitudinal study on the temporal variability of GPT-4o's average performance. Using a fixed model snapshot, fixed hyperparameters, and identical prompting, GPT-4o was queried via the API to solve the same multiple-choice physics task every three hours for approximately three months. Ten independent responses were generated at each time point and their scores were averaged. Spectral (Fourier) analysis of the resulting time series revealed notable periodic variability in average model performance, accounting for approximately 20% of the total variance. In particular, the observed periodic patterns are well explained by the interaction of a daily and a weekly rhythm. These findings indicate that, even under controlled conditions, LLM performance may vary periodically over time, calling into question the assumption of time invariance. Implications for ensuring validity and replicability of research that uses or investigates LLMs are discussed.

</details>


### [32] [Surrogate-Based Prevalence Measurement for Large-Scale A/B Testing](https://arxiv.org/abs/2602.16111)
*Zehao Xu,Tony Paek,Kevin O'Sullivan,Attila Dobi*

Main category: stat.AP

TL;DR: 提出基于代理信号的流行度测量框架，通过离线校准代理信号与参考标签，实现无需每次实验标注的快速、可扩展的流行度测量


<details>
  <summary>Details</summary>
Motivation: 在线媒体平台需要测量用户接触特定内容属性的频率以评估A/B实验中的权衡。直接采样标注方法成本高、速度慢，无法作为规模化默认测量方案

Method: 提出代理基础流行度测量框架：1) 离线校准代理信号与参考标签；2) 使用分数分桶作为代理信号，将模型分数离散化为桶；3) 从离线标注样本估计桶级流行度；4) 结合校准桶级流行度与各实验臂的桶分布，获得基于日志的快速估计

Result: 在多个大规模A/B测试中验证，代理估计与参考估计在臂级流行度和处理-控制差异方面高度匹配，实现可扩展、低延迟的流行度测量

Conclusion: 该框架使实验中的流行度测量变得可扩展且低延迟，无需每次实验的标注工作，为在线平台提供高效的测量解决方案

Abstract: Online media platforms often need to measure how frequently users are exposed to specific content attributes in order to evaluate trade-offs in A/B experiments. A direct approach is to sample content, label it using a high-quality rubric (e.g., an expert-reviewed LLM prompt), and estimate impression-weighted prevalence. However, repeatedly running such labeling for every experiment arm and segment is too costly and slow to serve as a default measurement at scale.
  We present a scalable \emph{surrogate-based prevalence measurement} framework that decouples expensive labeling from per-experiment evaluation. The framework calibrates a surrogate signal to reference labels offline and then uses only impression logs to estimate prevalence for arbitrary experiment arms and segments. We instantiate this framework using \emph{score bucketing} as the surrogate: we discretize a model score into buckets, estimate bucket-level prevalences from an offline labeled sample, and combine these calibrated bucket level prevalences with the bucket distribution of impressions in each arm to obtain fast, log-based estimates.
  Across multiple large-scale A/B tests, we validate that the surrogate estimates closely match the reference estimates for both arm-level prevalence and treatment--control deltas. This enables scalable, low-latency prevalence measurement in experimentation without requiring per-experiment labeling jobs.

</details>


### [33] [Phase Transitions in Collective Damage of Civil Structures under Natural Hazards](https://arxiv.org/abs/2602.16195)
*Sebin Oh,Jinyan Zhao,Raul Rincon,Jamie E. Padgett,Ziqi Wang*

Main category: stat.AP

TL;DR: 城市结构损伤在自然灾害下呈现相变现象，类似于统计物理学中的一级相变，损伤模式受建筑多样性和多尺度聚类影响，传统工程建模方法会系统性偏差风险指标达50%。


<details>
  <summary>Details</summary>
Motivation: 城市在自然灾害下的命运不仅取决于灾害强度，还取决于结构损伤的耦合过程，这是一个集体过程，目前理解不足。需要理解城市结构损伤的集体行为模式。

Method: 使用随机场伊辛模型来描述城市结构损伤现象，将外部场、无序强度和温度分别解释为有效灾害需求、结构多样性和建模不确定性。将该框架应用于真实城市库存数据。

Result: 城市结构损伤呈现相变现象：随着灾害强度增加，系统会从安全状态急剧转变为损伤状态（一级相变）。建筑多样性越高，相变越平滑；多尺度损伤聚类使系统陷入扩展的临界状态（Griffiths相），抑制可预测的无序相出现。传统工程建模方法会使城市损伤模式在同步和波动状态之间转变，在中等地震下系统性偏差风险指标达50%，相当于修复成本数倍的差距。

Conclusion: 这种相感知描述将民用基础设施损伤的集体行为转化为可操作的诊断工具，用于城市风险评估和规划，揭示了传统建模方法的局限性，为更准确的风险评估提供了新框架。

Abstract: The fate of cities under natural hazards depends not only on hazard intensity but also on the coupling of structural damage, a collective process that remains poorly understood. Here we show that urban structural damage exhibits phase-transition phenomena. As hazard intensity increases, the system can shift abruptly from a largely safe to a largely damaged state, analogous to a first-order phase transition in statistical physics. Higher diversity in the building portfolio smooths this transition, but multiscale damage clustering traps the system in an extended critical-like regime (analogous to a Griffiths phase), suppressing the emergence of a more predictable disordered (Gaussian) phase. These phenomenological patterns are characterized by a random-field Ising model, with the external field, disorder strength, and temperature interpreted as the effective hazard demand, structural diversity, and modeling uncertainty, respectively. Applying this framework to real urban inventories reveals that widely used engineering modeling practices can shift urban damage patterns between synchronized and volatile regimes, systematically biasing exceedance-based risk metrics by up to 50% under moderate earthquakes ($M_w \approx 5.5$--$6.0$), equivalent to a several-fold gap in repair costs. This phase-aware description turns the collective behavior of civil infrastructure damage into actionable diagnostics for urban risk assessment and planning.

</details>


### [34] [Physical Activity Trajectories Preceding Incident Major Depressive Disorder Diagnosis Using Consumer Wearable Devices in the All of Us Research Program: Case-Control Study](https://arxiv.org/abs/2602.16583)
*Yuezhou Zhang,Amos Folarin,Hugh Logan Ellis,Rongrong Zhong,Callum Stewart,Heet Sankesara,Hyunju Kim,Shaoxiong Sun,Abhishek Pratap,Richard JB Dobson*

Main category: stat.AP

TL;DR: 通过可穿戴设备数据发现，在首次被诊断为重度抑郁症前4-5个月，患者的身体活动水平就开始显著下降，这为早期风险识别提供了客观指标。


<details>
  <summary>Details</summary>
Motivation: 虽然低身体活动是重度抑郁症的已知风险因素，但在首次临床诊断前身体活动的变化模式尚不清楚，特别是缺乏长期客观测量数据。本研究旨在通过可穿戴设备数据，揭示在首次MDD诊断前一年内身体活动的轨迹变化。

Method: 采用回顾性巢式病例对照研究设计，利用"All of Us研究计划"中的电子健康记录和Fitbit数据。纳入在诊断前一年至少有6个月有效可穿戴数据的成年人。将829例新发MDD病例与3,275例对照按年龄、性别、BMI和索引时间匹配。将每日步数和中等至剧烈身体活动(MVPA)汇总为月平均值，使用线性混合效应模型比较从诊断前12个月到诊断时的活动轨迹。

Result: 与对照组相比，病例组在诊断前一年内表现出持续较低的活动水平，且步数和MVPA均呈现显著下降趋势(P<0.001)。步数在诊断前约4个月开始显著下降，MVPA在诊断前约5个月开始显著下降。探索性分析显示存在亚组差异：男性下降更陡峭，年龄较大者强度下降更大，肥胖个体活动水平持续较低。

Conclusion: 在首次MDD诊断前数月，个体身体活动水平已出现持续下降。纵向可穿戴设备监测可能提供早期信号，有助于风险分层和早期干预。

Abstract: Low physical activity is a known risk factor for major depressive disorder (MDD), but changes in activity before a first clinical diagnosis remain unclear, especially using long-term objective measurements. This study characterized trajectories of wearable-measured physical activity during the year preceding incident MDD diagnosis.
  We conducted a retrospective nested case-control study using linked electronic health record and Fitbit data from the All of Us Research Program. Adults with at least 6 months of valid wearable data in the year before diagnosis were eligible. Incident MDD cases were matched to controls on age, sex, body mass index, and index time (up to four controls per case). Daily step counts and moderate-to-vigorous physical activity (MVPA) were aggregated into monthly averages. Linear mixed-effects models compared trajectories from 12 months before diagnosis to diagnosis. Within cases, contrasts identified when activity first significantly deviated from levels 12 months prior.
  The cohort included 4,104 participants (829 cases and 3,275 controls; 81.7% women; median age 48.4 years). Compared with controls, cases showed consistently lower activity and significant downward trajectories in both step counts and MVPA during the year before diagnosis (P < 0.001). Significant declines appeared about 4 months before diagnosis for step counts and 5 months for MVPA. Exploratory analyses suggested subgroup differences, including steeper declines in men, greater intensity reductions at older ages, and persistently low activity among individuals with obesity.
  Sustained within-person declines in physical activity emerged months before incident MDD diagnosis. Longitudinal wearable monitoring may provide early signals to support risk stratification and earlier intervention.

</details>


### [35] [Design and Analysis Strategies for Pooling in High Throughput Screening: Application to the Search for a New Anti-Microbial](https://arxiv.org/abs/2602.16616)
*Byran Smucker,Benjamin Brennan,Emily Rego,Meng Wu,Zhihong Lin,Brian Ahmer,Blake Peterson*

Main category: stat.AP

TL;DR: 该论文研究了抗菌药物发现中的化合物池化筛选方法，评估了多种池化构建和分析技术，为实践者提供方法选择指导。


<details>
  <summary>Details</summary>
Motivation: 细菌对抗生素耐药性日益严重，需要开发新的抗菌策略。传统高通量筛选效率低，池化筛选（多个化合物混合检测）能提高效率，但需要指导实践者选择合适的方法。

Method: 研究评估了多种近期提出的池化构建方法和池化高通量筛选分析技术，包括在抗菌药物发现应用中的实际测试，进行了广泛的试点研究和较小的筛选活动。

Result: 研究提供了池化方法在抗菌药物筛选中的实际应用结果，突出了该方法的成功之处和面临的挑战，为实践者提供了方法选择的实用指导。

Conclusion: 池化筛选是提高抗菌药物发现效率的有效策略，但需要根据具体应用场景选择合适的池化构建和分析方法，本研究为实践者提供了重要的方法选择指导。

Abstract: A major public health issue is the growing resistance of bacteria to antibiotics. An important part of the needed response is the discovery and development of new antimicrobial strategies. These require the screening of potential new drugs, typically accomplished using high-throughput screening (HTS). Traditionally, HTS is performed by examining one compound per well, but a more efficient strategy pools multiple compounds per well. In this work, we study several recently proposed pooling construction methods, as well as a variety of pooled high-throughput screening analysis methods, in order to provide guidance to practitioners on which methods to use. This is done in the context of an application of the methods to the search for new drugs to combat bacterial infection. We discuss both an extensive pilot study as well as a small screening campaign, and highlight both the successes and challenges of the pooling approach.

</details>
