<div id=toc></div>

# Table of Contents

- [cs.SI](#cs.SI) [Total: 5]
- [cs.AI](#cs.AI) [Total: 55]
- [econ.EM](#econ.EM) [Total: 9]
- [stat.AP](#stat.AP) [Total: 3]
- [cs.CY](#cs.CY) [Total: 44]


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [1] [Defunding Sexual Healthcare: A Topological Investigation of Resource Accessibility](https://arxiv.org/abs/2512.12011)
*Denise Gonzalez-Cruz,Genesis Encarnacion,Kaili Martinez-Beasley,Robin Wilson,Nicholas Arosemena,Atilio Barreda,Omayra Ortega,Daniel A. Cruz*

Main category: cs.SI

TL;DR: 使用拓扑数据分析(TDA)评估加州计划生育诊所和联邦合格健康中心的空间分布差异，分析医疗补助资金削减对生殖健康服务可及性的影响。


<details>
  <summary>Details</summary>
Motivation: 政府削减计划生育诊所的医疗补助资金，特别是在加州这样医疗补助用户众多的州，可能严重影响生殖健康服务的可及性。虽然提议增加联邦合格健康中心的资金作为解决方案，但这未能解决服务点的空间可达性问题。

Method: 采用拓扑数据分析(TDA)方法，结合R和Python进行数据收集与可视化。使用n-最近邻算法分析设施间距离和旅行时间变化，应用持久同调分析当前和未来医疗覆盖的多尺度差距。

Result: 识别出医疗保健服务可及性最脆弱的区域，展示了TDA在分析公共卫生空间不平等方面的应用价值，揭示了资金削减可能加剧的服务覆盖差距。

Conclusion: 单纯增加联邦合格健康中心资金无法解决生殖健康服务的空间可达性问题，需要更全面的空间规划策略来确保医疗补助用户能够获得必要的生殖健康服务。

Abstract: Government actions, such as the Medina v. Planned Parenthood South Atlantic Supreme Court ruling and the passage of the Big Beautiful Bill Act, have aimed to restrict or prohibit Medicaid funding for Planned Parenthood Healthcare Centers (PPHCs) at both the state and national levels. These funding cuts are particularly harmful in states like California, which has a large population of Medicaid users. This analysis focuses on the distribution of Planned Parenthood clinics and Federally Qualified Health Centers (FQHCs), which offer essential reproductive healthcare services including, but not limited to, abortions, birth control, HIV services, pregnancy testing and planning, STD testing and treatment, and cancer screenings. While expanded funding for FQHCs has been proposed as a solution, it fails to address the locational accessibility of Medicaid-funded health centers that provide sexual and reproductive care. To assess this issue, we analyze the proximity of data points representing California's PPHC and FQHC locations. Topological Data Analysis (TDA)-an approach that examines the shape and structure of data -- is used to detect disparities in reproductive and sexual healthcare coverage. To conduct data collection and visualization, we utilize R and Python. We apply an n-closest neighbor algorithm to examine distances between facilities and assess changes in travel time required to reach healthcare sites. We apply persistent homology to analyze current gaps across multiple scales in healthcare coverage and compare them to potential future gaps. Our findings aim to identify areas where access to care is most vulnerable and demonstrate how TDA can be used to analyze spatial inequalities in public health.

</details>


### [2] [Dynamic Homophily with Imperfect Recall: Modeling Resilience in Adversarial Networks](https://arxiv.org/abs/2512.12332)
*Saad Alqithami*

Main category: cs.SI

TL;DR: 该研究开发了一个整合记忆衰减机制的同质性模型框架，发现余弦相似度在稀疏、凸形和模块化网络中稳定性指标提升达30%，战略性遗忘能平衡网络韧性与适应性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究同质性、记忆约束和对抗性干扰如何共同影响复杂网络的韧性与适应性，为现实世界网络优化提供理论基础。

Method: 开发了整合记忆衰减机制的同质性模型框架，在合成数据集上进行大量实验，比较不同衰减函数、重连概率和相似性度量（余弦相似度 vs Jaccard相似度 vs 基线边权重）。

Result: 余弦相似度在稀疏、凸形和模块化网络中稳定性指标提升达30%；精炼的召回值指标显示战略性遗忘能平衡网络韧性与适应性；记忆和相似性参数需与网络结构和对抗动态对齐。

Conclusion: 将记忆约束纳入同质性分析具有实际效益，为社交系统、协作平台和网络安全等现实应用提供了可操作的优化见解。

Abstract: The purpose of this study is to investigate how homophily, memory constraints, and adversarial disruptions collectively shape the resilience and adaptability of complex networks. To achieve this, we develop a new framework that integrates explicit memory decay mechanisms into homophily-based models and systematically evaluate their performance across diverse graph structures and adversarial settings. Our methods involve extensive experimentation on synthetic datasets, where we vary decay functions, reconnection probabilities, and similarity measures, primarily comparing cosine similarity with traditional metrics such as Jaccard similarity and baseline edge weights. The results show that cosine similarity achieves up to a 30\% improvement in stability metrics in sparse, convex, and modular networks. Moreover, the refined value-of-recall metric demonstrates that strategic forgetting can bolster resilience by balancing network robustness and adaptability. The findings underscore the critical importance of aligning memory and similarity parameters with the structural and adversarial dynamics of the network. By quantifying the tangible benefits of incorporating memory constraints into homophily-based analyses, this study offers actionable insights for optimizing real-world applications, including social systems, collaborative platforms, and cybersecurity contexts.

</details>


### [3] [Leader-driven or Leaderless: How Participation Structure Sustains Engagement and Shapes Narratives in Online Hate Communities](https://arxiv.org/abs/2512.12441)
*Rr. Nefriana,Muheng Yan,Rebecca Hwa,Yu-Ru Lin*

Main category: cs.SI

TL;DR: 研究发现，仇恨团体在Facebook上的参与集中化程度越高，用户参与度也越高，但反犹太主义和伊斯兰恐惧症团体在叙事框架和网络结构上存在明显差异。


<details>
  <summary>Details</summary>
Motivation: 极端主义社区越来越多地依赖社交媒体来维持和放大分裂性话语，但其内部参与结构、受众参与度和叙事表达之间的关系尚未得到充分探索。本研究旨在分析仇恨团体在社交媒体上的活动模式，特别是针对以色列-巴勒斯坦冲突相关的反犹太主义和伊斯兰恐惧症团体。

Method: 研究分析了十年间Facebook上仇恨团体的活动数据，使用参与集中化指标衡量团体内部结构，开发了基于八种极端主义框架（如非人化、暴力合理化等）的叙事框架检测模型，并分析了团体间的网络结构。

Result: 1. 仇恨团体的参与集中化程度越高，用户参与度也越高；2. 反犹太主义和伊斯兰恐惧症团体在叙事框架上存在明显差异；3. 伊斯兰恐惧症团体在网络中形成紧密集群，而反犹太主义团体则分布更均匀；4. 参与集中化和同质性之间没有明显关联。

Conclusion: 参与结构影响极端主义叙事的传播模式和共鸣，不同意识形态的仇恨团体在叙事策略和网络结构上存在差异。这些发现为制定有针对性的策略来破坏或缓解在线极端主义话语提供了基础。

Abstract: Extremist communities increasingly rely on social media to sustain and amplify divisive discourse. However, the relationship between their internal participation structures, audience engagement, and narrative expression remains underexplored. This study analyzes ten years of Facebook activity by hate groups related to the Israel-Palestine conflict, focusing on anti-Semitic and Islamophobic ideologies. Consistent with prior work, we find that higher participation centralization in online hate groups is associated with greater user engagement across hate ideologies, suggesting the role of key actors in sustaining group activity over time. Conversely, our narrative frame detection models - based on an eight-frame extremist taxonomy (e.g., dehumanization, violence justification) - reveal a clear contrast across hate ideologies, offering new insight into how discursive strategies vary despite similar structural dynamics. Analysis of the inter-group network indicates that, although centralization and homophily are not clearly linked, ideological distinctions emerge: Islamophobic groups cluster tightly, whereas anti-Semitic groups remain more evenly connected. Overall, these findings clarify how participation structure may shape the dissemination pattern and resonance of extremist narratives online and provide a foundation for tailored strategies to disrupt or mitigate online extremist discourse.

</details>


### [4] [Shared Nodes of Overlapping Communities in Complex Networks](https://arxiv.org/abs/2512.13231)
*Vesa Kuikka,Kosti Koistinen,Kimmo K Kaski*

Main category: cs.SI

TL;DR: 该论文提出了一种基于阈值规则识别重叠社区中重叠节点的方法，通过分析嵌套结构来区分形成子社区的节点和作为社区交集的节点，并应用于不同规模的实际网络。


<details>
  <summary>Details</summary>
Motivation: 重叠社区是复杂网络结构和功能分析的关键特征，但重叠节点可能形成子社区或作为社区间的交集，需要系统方法来识别这些节点并分析其角色，特别是在减少噪声影响方面。

Method: 采用基于嵌套结构中节点数量的阈值规则来识别重叠节点，随着阈值增加，选定的重叠节点减少；使用三个小型和两个大型实际网络结构进行验证；虽然使用作者自己的社区检测方法，但其他方法也可应用。

Result: 在大型网络中，微小扰动会产生多种略有不同的解决方案，但核心社区保持稳健，其他变体可视为噪声；该方法能够有效分析重叠节点的角色，特别是在减少噪声影响方面。

Conclusion: 探索复杂网络重叠社区中共享节点的特性是一个新颖的研究领域，在社交网络分析、网络安全和其他网络科学领域具有多样化应用前景。

Abstract: Overlapping communities are key characteristics of the structure and function analysis of complex networks. Shared or overlapping nodes within overlapping communities can form either subcommunities or act as intersections between larger communities. Nodes at the intersections that do not form subcommunities can be identified as overlapping nodes or as part of an internal structure of nested communities. To identify overlapping nodes, we apply a threshold rule based on the number of nodes in the nested structure. As the threshold value increases, the number of selected overlapping nodes decreases. This approach allows us to analyse the roles of nodes considered overlapping according to selection criteria, for example to reduce the effect of noise. We illustrate our method by using three small and two larger real-world network structures. In larger networks, minor disturbances can produce a multitude of slightly different solutions, but the core communities remain robust, allowing other variations to be treated as noise. While this study employs our own method for community detection, other approaches can also be applied. Exploring the properties of shared nodes in overlapping communities of complex networks is a novel area of research with diverse applications in social network analysis, cybersecurity, and other fields in network science.

</details>


### [5] [Follow Nudges without Budges: A Field Experiment on Misinformation Followers Didn't Change Follow Networks](https://arxiv.org/abs/2512.13643)
*Laura Kurek,Joshua Ashkinaze,Ceren Budak,Eric Gilbert*

Main category: cs.SI

TL;DR: 在X平台上对健康谣言关注者进行大规模实验，测试四种广告干预能否促使用户关注权威健康信息源。结果发现，带有说服性信息、要求关注知名健康机构的广告点击率最高，但总体点击率低且成本高，这种广告形式的干预不够经济有效。


<details>
  <summary>Details</summary>
Motivation: 研究数字广告是否能鼓励接触不准确信息的用户转而关注准确信息源，探索改善在线信息环境的有效方法。

Method: 在X平台（原Twitter）对28,582名关注健康谣言账号的用户进行大规模田野实验。采用2×2设计：中性信息vs基于独立价值观的说服性信息；要求关注健康机构vs要求关注健康影响者。这种基于广告的社交网络干预称为"关注助推"。

Result: 带有说服性信息、要求关注知名健康机构的广告点击率显著高于其他所有条件（Bonferroni校正后p<0.001）。但所有处理的总体点击率都很低，且X平台的数字广告基础设施成本高昂。

Conclusion: 虽然说服性信息关注健康机构的广告效果最好，但基于广告的干预在当前形式下不是改善在线信息环境的经济有效方法。研究还讨论了X平台所有权变更后数据访问限制给大规模实验带来的挑战。

Abstract: Can digital ads encourage users exposed to inaccurate information sources to follow accurate ones? We conduct a large-scale field experiment (N=28,582) on X, formerly Twitter, with users who follow accounts that spread health misinformation. Participants were exposed to four ad treatments varied on two dimensions: a neutral message versus a persuasive message appealing to values of independence, and a request to follow a health institution versus a request to follow a health influencer. We term this ad-based, social network intervention a follow nudge. The ad with a persuasive message to follow a well-known health institution generated significantly higher click-through rates than all other conditions (Bonferroni-corrected pairwise tests, all p<0.001). Given the overall low click-through rate across treatments and the high cost of digital advertising infrastructure on X, however, we conclude that our proposed intervention -- at least in its current ad-based format -- is not a cost-effective means to improve information environments online. We discuss challenges faced when conducting large-scale experiments on X following the platform's ownership change and subsequent restrictions on data access for research purposes.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [6] [A Monad-Based Clause Architecture for Artificial Age Score (AAS) in Large Language Models](https://arxiv.org/abs/2512.11835)
*Seyma Yaman Kayadibi*

Main category: cs.AI

TL;DR: 基于人工年龄评分(AAS)构建可执行的单子论条款架构，为LLM内存和控制提供法律式约束，实现透明可审计的内部动态管理。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通常作为强大但不透明的系统部署，缺乏对其内部记忆和"自我类似"行为的原理性、可审计的治理方法。需要建立透明、可执行的约束框架来管理LLM的内部动态。

Method: 基于AAS核构建工程导向的条款架构，将莱布尼茨《单子论》中的20个单子分组为6个束（本体论、动力学、表征与意识、和谐与理性、身体与组织、目的论），每个束实现为可执行规范，通过Python实现进行数值实验。

Result: 条款系统展现出有界且可解释的行为：AAS轨迹保持连续且速率受限，矛盾和未支持声明触发明确惩罚，层次细化以受控方式揭示有机结构，和谐项对齐双重视图和目标-行动对，完美度窗口漂移分离持续改进与持续退化。

Conclusion: 基于单子的条款框架以AAS为骨干，为约束和分析人工代理的内部动态提供了透明、代码级的蓝图，不仅具有哲学动机，而且可直接实现，为LLM设计提供了可审计的治理机制。

Abstract: Large language models (LLMs) are often deployed as powerful yet opaque systems, leaving open how their internal memory and "self-like" behavior should be governed in a principled and auditable way. The Artificial Age Score (AAS) was previously introduced and mathematically justified through three theorems that characterise it as a metric of artificial memory aging. Building on this foundation, the present work develops an engineering-oriented, clause-based architecture that imposes law-like constraints on LLM memory and control. Twenty selected monads from Leibniz's Monadology are grouped into six bundles: ontology, dynamics, representation and consciousness, harmony and reason, body and organisation, and teleology, and each bundle is realised as an executable specification on top of the AAS kernel. Across six minimal Python implementations, these clause families are instantiated in numerical experiments acting on channel-level quantities such as recall scores, redundancy, and weights. Each implementation follows a four-step pattern: inputs and setup, clause implementation, numerical results, and implications for LLM design, emphasising that the framework is not only philosophically motivated but also directly implementable. The experiments show that the clause system exhibits bounded and interpretable behavior: AAS trajectories remain continuous and rate-limited, contradictions and unsupported claims trigger explicit penalties, and hierarchical refinement reveals an organic structure in a controlled manner. Dual views and goal-action pairs are aligned by harmony terms, and windowed drift in perfection scores separates sustained improvement from sustained degradation. Overall, the monad-based clause framework uses AAS as a backbone and provides a transparent, code-level blueprint for constraining and analyzing internal dynamics in artificial agents.

</details>


### [7] [Solving Parallel Machine Scheduling With Precedences and Cumulative Resource Constraints With Calendars](https://arxiv.org/abs/2512.11864)
*Christoph Einspieler,Matthias Horn,Marie-Louise Lackner,Patrick Malik,Nysret Musliu,Felix Winter*

Main category: cs.AI

TL;DR: 提出一种新的并行机器调度变体，包含作业优先级和基于日历的累积资源约束，适用于真实工业场景，结合约束建模精确求解小规模问题，并开发启发式算法处理大规模实例。


<details>
  <summary>Details</summary>
Motivation: 现代工厂需要自动化调度技术来最小化生产成本，但现有方法无法有效处理真实生产环境中的复杂优先级约束和基于日历的资源限制。

Method: 提出约束建模方法作为小规模场景的精确解，结合先进约束求解技术；同时开发构造启发式和基于局部搜索的定制元启发式算法处理大规模实例。

Result: 元启发式方法已在工业环境中部署使用，能够有效解决具有复杂约束的真实并行机器调度问题。

Conclusion: 该研究提出的方法填补了现有调度技术在处理真实工业约束方面的空白，为复杂并行机器调度问题提供了实用解决方案。

Abstract: The task of finding efficient production schedules for parallel machines is a challenge that arises in most industrial manufacturing domains. There is a large potential to minimize production costs through automated scheduling techniques, due to the large-scale requirements of modern factories. In the past, solution approaches have been studied for many machine scheduling variations, where even basic variants have been shown to be NP-hard. However, in today's real-life production environments, additional complex precedence constraints and resource restrictions with calendars arise that must be fulfilled. These additional constraints cannot be tackled efficiently by existing solution techniques. Thus, there is a strong need to develop and analyze automated methods that can solve such real-life parallel machine scheduling scenarios. In this work, we introduce a novel variant of parallel machine scheduling with job precedences and calendar-based cumulative resource constraints that arises in real-life industrial use cases. A constraint modeling approach is proposed as an exact solution method for small scheduling scenarios together with state-of-the-art constraint-solving technology. Further, we propose a construction heuristic as well as a tailored metaheuristic using local search to efficiently tackle large-scale problem instances. This metaheuristic approach has been deployed and is currently being used in an industrial setting.

</details>


### [8] [Mirror Mode in Fire Emblem: Beating Players at their own Game with Imitation and Reinforcement Learning](https://arxiv.org/abs/2512.11902)
*Yanna Elizabeth Smid,Peter van der Putten,Aske Plaat*

Main category: cs.AI

TL;DR: 提出Mirror Mode游戏模式，让AI模仿玩家个人策略来挑战玩家，在Fire Emblem Heroes简化版中实现，结合GAIL、BC和PPO进行模仿学习，玩家测试显示防御行为模仿良好但进攻策略不足，整体提高了玩家满意度。


<details>
  <summary>Details</summary>
Motivation: 传统回合制游戏中敌人策略往往可预测，缺乏惊喜感。研究旨在创建一种新模式，让AI能够模仿玩家的个人策略，从而挑战玩家不断改变自己的游戏玩法。

Method: 1. 在Unity中构建Fire Emblem Heroes简化版，包含标准模式和镜像模式；2. 使用强化学习和模仿学习（结合生成对抗模仿学习GAIL、行为克隆BC和近端策略优化PPO）寻找适合模仿玩家演示的模型；3. 通过玩家测试评估模型，模型基于参与者提供的演示进行训练。

Result: 玩家游戏行为分析显示模型在防御行为上模仿良好，但在进攻策略上模仿不足。参与者调查表明他们能识别出自己的撤退战术，镜像模式整体获得更高的玩家满意度。

Conclusion: Mirror Mode能有效提高玩家满意度，尤其是当玩家面对自己的策略时。进一步优化模型可以改善模仿质量并进一步提升玩家满意度。

Abstract: Enemy strategies in turn-based games should be surprising and unpredictable. This study introduces Mirror Mode, a new game mode where the enemy AI mimics the personal strategy of a player to challenge them to keep changing their gameplay. A simplified version of the Nintendo strategy video game Fire Emblem Heroes has been built in Unity, with a Standard Mode and a Mirror Mode. Our first set of experiments find a suitable model for the task to imitate player demonstrations, using Reinforcement Learning and Imitation Learning: combining Generative Adversarial Imitation Learning, Behavioral Cloning, and Proximal Policy Optimization. The second set of experiments evaluates the constructed model with player tests, where models are trained on demonstrations provided by participants. The gameplay of the participants indicates good imitation in defensive behavior, but not in offensive strategies. Participant's surveys indicated that they recognized their own retreating tactics, and resulted in an overall higher player-satisfaction for Mirror Mode. Refining the model further may improve imitation quality and increase player's satisfaction, especially when players face their own strategies. The full code and survey results are stored at: https://github.com/YannaSmid/MirrorMode

</details>


### [9] [Structured Personalization: Modeling Constraints as Matroids for Data-Minimal LLM Agents](https://arxiv.org/abs/2512.11907)
*Daniel Platnick,Marjan Alirezaie,Hossein Rahnama*

Main category: cs.AI

TL;DR: 提出一种结构化个性化方法，将用户知识图编译为宏观面，证明常见约束形成层状拟阵，从而在拟阵约束下实现带保证的次模最大化


<details>
  <summary>Details</summary>
Motivation: 大型语言模型个性化需要在任务效用和数据披露之间权衡，现实中的结构化约束（如逻辑依赖、类别配额、层次规则）破坏了标准子集选择算法的假设

Method: 将用户知识图编译为宏观面，证明常见分层和配额约束形成层状拟阵，将结构化个性化建模为拟阵约束下的次模最大化问题

Result: 理论证明常见约束形成有效层状拟阵，使得贪心算法具有常数因子保证（连续贪心可达1-1/e），适用于更丰富现实的问题类别

Conclusion: 提出的结构化个性化方法能够处理现实中的复杂约束，为LLM个性化提供了理论保证的实用解决方案

Abstract: Personalizing Large Language Model (LLM) agents requires conditioning them on user-specific data, creating a critical trade-off between task utility and data disclosure. While the utility of adding user data often exhibits diminishing returns (i.e., submodularity), enabling near-optimal greedy selection, real-world personalization is complicated by structural constraints. These include logical dependencies (e.g., selecting fact A requires fact B), categorical quotas (e.g., select at most one writing style), and hierarchical rules (e.g., select at most two social media preferences, of which at most one can be for a professional network). These constraints violate the assumptions of standard subset selection algorithms. We propose a principled method to formally model such constraints. We introduce a compilation process that transforms a user's knowledge graph with dependencies into a set of abstract macro-facets. Our central result is a proof that common hierarchical and quota-based constraints over these macro-facets form a valid laminar matroid. This theoretical characterization lets us cast structured personalization as submodular maximization under a matroid constraint, enabling greedy with constant-factor guarantees (and (1-1/e) via continuous greedy) for a much richer and more realistic class of problems.

</details>


### [10] [Causal Strengths and Leaky Beliefs: Interpreting LLM Reasoning via Noisy-OR Causal Bayes Nets](https://arxiv.org/abs/2512.11909)
*Hanna Dettki*

Main category: cs.AI

TL;DR: 研究通过因果推理任务比较LLMs与人类推理能力，发现两者在任务层面存在差异且具有不同的推理特征


<details>
  <summary>Details</summary>
Motivation: 因果推理被认为是智能的关键方面，通过在同一任务上评估LLMs和人类的因果推理能力，可以更全面地理解两者的优势和弱点

Method: 评估20多个LLMs在11个语义化因果任务上，任务基于碰撞图结构，采用直接推理和思维链两种方式，使用带泄漏的噪声OR因果贝叶斯网络建模

Result: 通过AIC选择最佳模型（3参数对称因果强度或4参数非对称变体），分析LLMs与人类在相同任务上的对齐程度、任务层面的一致性以及推理特征差异

Conclusion: 研究为理解LLMs与人类在因果推理方面的差异提供了系统框架，揭示了人工智能与人类智能在推理机制上的不同特征

Abstract: The nature of intelligence in both humans and machines is a longstanding question. While there is no universally accepted definition, the ability to reason causally is often regarded as a pivotal aspect of intelligence (Lake et al., 2017). Evaluating causal reasoning in LLMs and humans on the same tasks provides hence a more comprehensive understanding of their respective strengths and weaknesses. Our study asks: (Q1) Are LLMs aligned with humans given the \emph{same} reasoning tasks? (Q2) Do LLMs and humans reason consistently at the task level? (Q3) Do they have distinct reasoning signatures?
  We answer these by evaluating 20+ LLMs on eleven semantically meaningful causal tasks formalized by a collider graph ($C_1\!\to\!E\!\leftarrow\!C_2$ ) under \emph{Direct} (one-shot number as response = probability judgment of query node being one and \emph{Chain of Thought} (CoT; think first, then provide answer).
  Judgments are modeled with a leaky noisy-OR causal Bayes net (CBN) whose parameters $θ=(b,m_1,m_2,p(C)) \in [0,1]$ include a shared prior $p(C)$;
  we select the winning model via AIC between a 3-parameter symmetric causal strength ($m_1{=}m_2$) and 4-parameter asymmetric ($m_1{\neq}m_2$) variant.

</details>


### [11] [Robustness of Probabilistic Models to Low-Quality Data: A Multi-Perspective Analysis](https://arxiv.org/abs/2512.11912)
*Liu Peng,Yaochu Jin*

Main category: cs.AI

TL;DR: 该研究系统比较了不同概率模型对低质量数据的鲁棒性，发现自回归语言模型表现出显著韧性，而类别条件扩散模型在数据损坏下性能急剧下降，分类器则呈现中等影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机是系统性地探究不同现代概率模型对低质量训练数据的鲁棒性差异，理解为何某些模型在数据损坏情况下表现更好，而其他模型则严重退化。

Method: 研究方法包括：1）对多种概率模型（自回归语言模型、类别条件扩散模型、分类器）进行系统性数据损坏实验；2）采用多视角分析框架，结合信息论、PAC学习和梯度动力学理论来解释观察到的鲁棒性差异。

Result: 主要发现：1）自回归语言模型（如GPT-2）对数据损坏具有显著鲁棒性（50%令牌损坏下测试NLL仅从2.87增加到3.59）；2）类别条件扩散模型在相同数据损坏水平下性能急剧下降（图像标签一致性相对基线下降56.81%）；3）分类器影响中等，且随数据集规模增大而减弱。

Conclusion: 研究结论表明模型鲁棒性主要受两个关键原则影响：1）条件信息的丰富性（约束学习问题）；2）训练数据的绝对信息含量（使正确信息的信号主导统计噪声）。这些发现为设计对低质量数据更鲁棒的模型提供了理论指导。

Abstract: A systematic, comparative investigation into the effects of low-quality data reveals a stark spectrum of robustness across modern probabilistic models. We find that autoregressive language models, from token prediction to sequence-to-sequence tasks, are remarkably resilient (for GPT-2, test NLL increases modestly from 2.87 to 3.59 despite 50% token corruption). By contrast, under the same levels of data corruption, class-conditional diffusion models degrade catastrophically (image-label consistency plummets by 56.81% relative to baseline), while classifiers show a moderate impact that diminishes with dataset scale. To explain these discrepancies, we analyze the results through a multi-perspective lens, integrating information theory, PAC learning, and gradient dynamics. These analyses suggest that robustness is heavily influenced by two key principles: the richness of conditioning information, which constrains the learning problem, and the absolute information content of the training data, which allows the signal from correct information to dominate statistical noise.

</details>


### [12] [CXL-SpecKV: A Disaggregated FPGA Speculative KV-Cache for Datacenter LLM Serving](https://arxiv.org/abs/2512.11920)
*Dong Liu,Yanxuan Yu*

Main category: cs.AI

TL;DR: CXL-SpecKV：基于CXL互连和FPGA加速的分布式KV缓存架构，通过内存解聚和推测执行解决LLM推理中的内存瓶颈，提升吞吐量3.2倍，降低内存成本2.8倍。


<details>
  <summary>Details</summary>
Motivation: LLM在数据中心部署面临KV缓存内存消耗巨大的挑战，限制了批处理大小和系统吞吐量。传统GPU内存方案无法满足大规模LLM服务的需求。

Method: 提出CXL-SpecKV架构：1) 基于CXL的内存解聚框架，将KV缓存卸载到远程FPGA内存；2) 推测式KV缓存预取机制，预测并预加载未来token的缓存条目；3) FPGA加速的KV缓存压缩/解压引擎，减少内存带宽需求4倍。

Result: 在先进LLM模型上评估，相比GPU-only基线：吞吐量提升3.2倍，内存成本降低2.8倍，同时保持准确性。内存带宽需求减少4倍。

Conclusion: 智能内存解聚结合推测执行能有效解决大规模LLM服务中的内存墙挑战。该方法为高效LLM部署提供了可行解决方案，代码已开源。

Abstract: Large Language Models (LLMs) have revolutionized natural language processing tasks, but their deployment in datacenter environments faces significant challenges due to the massive memory requirements of key-value (KV) caches. During the autoregressive decoding process, KV caches consume substantial GPU memory, limiting batch sizes and overall system throughput. To address these challenges, we propose \textbf{CXL-SpecKV}, a novel disaggregated KV-cache architecture that leverages Compute Express Link (CXL) interconnects and FPGA accelerators to enable efficient speculative execution and memory disaggregation. Our approach introduces three key innovations: (i) a CXL-based memory disaggregation framework that offloads KV-caches to remote FPGA memory with low latency, (ii) a speculative KV-cache prefetching mechanism that predicts and preloads future tokens' cache entries, and (iii) an FPGA-accelerated KV-cache compression and decompression engine that reduces memory bandwidth requirements by up to 4$\times$. When evaluated on state-of-the-art LLM models, CXL-SpecKV achieves up to 3.2$\times$ higher throughput compared to GPU-only baselines, while reducing memory costs by 2.8$\times$ and maintaining accuracy. Our system demonstrates that intelligent memory disaggregation combined with speculative execution can effectively address the memory wall challenge in large-scale LLM serving. Our code implementation has been open-sourced at https://github.com/FastLM/CXL-SpecKV.

</details>


### [13] [AGAPI-Agents: An Open-Access Agentic AI Platform for Accelerated Materials Design on AtomGPT.org](https://arxiv.org/abs/2512.11935)
*Jaehyung Lee,Justin Ely,Kent Zhang,Akshaya Ajith,Charles Rhys Campbell,Kamal Choudhary*

Main category: cs.AI

TL;DR: AGAPI是一个开源的材料科学AI平台，集成了8+开源LLM和20+材料科学API端点，通过智能体架构自主构建和执行多步骤工作流，加速材料发现。


<details>
  <summary>Details</summary>
Motivation: 当前AI在材料研究中的应用受到碎片化计算生态系统、可重复性挑战以及对商业大语言模型依赖的限制，需要统一的开放平台来推动AI加速的材料发现。

Method: 采用Agent-Planner-Executor-Summarizer架构，集成8+开源LLM和20+材料科学API端点，通过统一编排框架自主构建和执行多步骤工作流，涵盖数据检索、性质预测、力场优化、紧束缚计算、衍射分析和逆向设计等。

Result: 展示了端到端工作流（异质结构构建、粉末X射线衍射分析、半导体缺陷工程），通过30+测试用例评估了智能体预测性能，已有1000+活跃用户，提供了可扩展且透明的基础设施。

Conclusion: AGAPI为可重复的、AI加速的材料发现提供了可扩展且透明的基础设施，通过开源平台解决了当前材料研究中的碎片化和可重复性挑战。

Abstract: Artificial intelligence is reshaping scientific discovery, yet its use in materials research remains limited by fragmented computational ecosystems, reproducibility challenges, and dependence on commercial large language models (LLMs). Here we introduce AGAPI (AtomGPT.org API), an open-access agentic AI platform that integrates more than eight open-source LLMs with over twenty materials-science API endpoints, unifying databases, simulation tools, and machine-learning models through a common orchestration framework. AGAPI employs an Agent-Planner-Executor-Summarizer architecture that autonomously constructs and executes multi-step workflows spanning materials data retrieval, graph neural network property prediction, machine-learning force-field optimization, tight-binding calculations, diffraction analysis, and inverse design. We demonstrate AGAPI through end-to-end workflows, including heterostructure construction, powder X-ray diffraction analysis, and semiconductor defect engineering requiring up to ten sequential operations. In addition, we evaluate AGAPI using 30+ example prompts as test cases and compare agentic predictions with and without tool access against experimental data. With more than 1,000 active users, AGAPI provides a scalable and transparent foundation for reproducible, AI-accelerated materials discovery. AGAPI-Agents codebase is available at https://github.com/atomgptlab/agapi.

</details>


### [14] [Hypergame Rationalisability: Solving Agent Misalignment In Strategic Play](https://arxiv.org/abs/2512.11942)
*Vince Trencsenyi*

Main category: cs.AI

TL;DR: 提出基于逻辑的声明式领域特定语言和自动管道，用于编码超博弈结构和解决方案概念，连接超博弈理论与多智能体系统


<details>
  <summary>Details</summary>
Motivation: 由于感知差异、信息不对称和有限理性，游戏理论玩家对游戏形成主观看法，可能与实际情况和其他玩家的解释不一致。超博弈理论虽然提供了处理这种不匹配心理模型的数学框架，但在多智能体系统研究中缺乏统一的、形式化的、实用的表示语言和可扩展算法。

Method: 引入基于逻辑的声明式领域特定语言来编码超博弈结构和超博弈解决方案概念。利用答案集编程开发自动化管道，用于实例化超博弈结构并运行新颖的超博弈合理化程序，该程序用于找到能证明看似不合理结果的信念结构。

Result: 提出的语言为超博弈建立了统一的形式化框架，并为开发基于信念的异构推理器奠定了基础，提供了具有逻辑保证的可验证上下文。这些贡献建立了超博弈理论、多智能体系统和战略AI之间的联系。

Conclusion: 该工作填补了超博弈理论在多智能体系统研究中实际应用的空白，通过形式化语言和自动化工具使超博弈分析更加实用和可扩展，为处理异构信念的战略推理提供了新方法。

Abstract: Differences in perception, information asymmetries, and bounded rationality lead game-theoretic players to derive a private, subjective view of the game that may diverge from the underlying ground-truth scenario and may be misaligned with other players' interpretations. While typical game-theoretic assumptions often overlook such heterogeneity, hypergame theory provides the mathematical framework to reason about mismatched mental models. Although hypergames have recently gained traction in dynamic applications concerning uncertainty, their practical adoption in multi-agent system research has been hindered by the lack of a unifying, formal, and practical representation language, as well as scalable algorithms for managing complex hypergame structures and equilibria. Our work addresses this gap by introducing a declarative, logic-based domain-specific language for encoding hypergame structures and hypergame solution concepts. Leveraging answer-set programming, we develop an automated pipeline for instantiating hypergame structures and running our novel hypergame rationalisation procedure, a mechanism for finding belief structures that justify seemingly irrational outcomes. The proposed language establishes a unifying formalism for hypergames and serves as a foundation for developing nuanced, belief-based heterogeneous reasoners, offering a verifiable context with logical guarantees. Together, these contributions establish the connection between hypergame theory, multi-agent systems, and strategic AI.

</details>


### [15] [Log Anomaly Detection with Large Language Models via Knowledge-Enriched Fusion](https://arxiv.org/abs/2512.11997)
*Anfeng Peng,Ajesh Koyatan Chathoth,Stephen Lee*

Main category: cs.AI

TL;DR: EnrichLog是一个无需训练的日志异常检测框架，通过结合语料库特定和样本特定知识来增强原始日志条目，提高检测准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统日志分析技术（如基于模板和序列驱动的方法）经常丢失重要语义信息或难以处理模糊的日志模式，需要更有效的异常检测方法。

Method: EnrichLog采用检索增强生成技术，结合历史示例和语料库推理的上下文信息，无需重新训练即可集成相关知识，实现基于条目的异常检测。

Result: 在四个大规模系统日志基准数据集上的评估显示，EnrichLog相比五种基线方法持续提升异常检测性能，有效处理模糊日志条目，并保持高效推理。

Conclusion: EnrichLog通过结合语料库特定和样本特定知识增强了模型置信度和检测准确性，适合实际部署，为分布式系统监控提供了更有效的日志分析解决方案。

Abstract: System logs are a critical resource for monitoring and managing distributed systems, providing insights into failures and anomalous behavior. Traditional log analysis techniques, including template-based and sequence-driven approaches, often lose important semantic information or struggle with ambiguous log patterns. To address this, we present EnrichLog, a training-free, entry-based anomaly detection framework that enriches raw log entries with both corpus-specific and sample-specific knowledge. EnrichLog incorporates contextual information, including historical examples and reasoning derived from the corpus, to enable more accurate and interpretable anomaly detection. The framework leverages retrieval-augmented generation to integrate relevant contextual knowledge without requiring retraining. We evaluate EnrichLog on four large-scale system log benchmark datasets and compare it against five baseline methods. Our results show that EnrichLog consistently improves anomaly detection performance, effectively handles ambiguous log entries, and maintains efficient inference. Furthermore, incorporating both corpus- and sample-specific knowledge enhances model confidence and detection accuracy, making EnrichLog well-suited for practical deployments.

</details>


### [16] [Context-Aware Agentic Power Resources Optimisation in EV using Smart2ChargeApp](https://arxiv.org/abs/2512.12048)
*Muddsair Sharif,Huseyin Seker*

Main category: cs.AI

TL;DR: 提出CAMAC-DRA框架，通过多智能体协调优化电动汽车充电生态系统，实现92%协调成功率、15%能效提升和10%成本降低


<details>
  <summary>Details</summary>
Motivation: 解决智能电动汽车充电生态系统中动态资源分配问题，需要协调多个利益相关者（用户、电网、充电站、车队运营商、环境因素）的竞争目标，并适应实时环境变化

Method: 采用上下文敏感的多智能体协调框架，结合深度Q网络、图神经网络和注意力机制，处理20个上下文特征（天气、交通、电网负载、电价等），通过加权协调机制和共识协议平衡五个利益相关者

Result: 在包含441,077个充电交易的真实数据集上验证，相比DDPG、A3C、PPO和GNN基线方法表现更优：92%协调成功率、15%能效提升、10%成本降低、20%电网压力减少、2.3倍更快收敛，同时保持88%训练稳定性和85%样本效率

Conclusion: CAMAC-DRA框架成功开发了上下文感知的多利益相关者协调系统，平衡竞争目标并适应实时变量，为智能电动汽车充电协调和可持续交通电气化提供了突破性解决方案，具有商业可行性（净现成本-122,962美元，通过可再生能源集成实现69%成本降低）

Abstract: This paper presents a novel context-sensitive multi\-agent coordination for dynamic resource allocation (CAMAC-DRA) framework for optimizing smart electric vehicle (EV) charging ecosystems through the Smart2Charge application. The proposed system coordinates autonomous charging agents across networks of 250 EVs and 45 charging stations while adapting to dynamic environmental conditions through context-aware decision-making. Our multi-agent approach employs coordinated Deep Q\-Networks integrated with Graph Neural Networks and attention mechanisms, processing 20 contextual features including weather patterns, traffic conditions, grid load fluctuations, and electricity pricing.The framework balances five ecosystem stakeholders i.e. EV users (25\%), grid operators (20\%), charging station operators (20\%), fleet operators (20%), and environmental factors (15\%) through weighted coordination mechanisms and consensus protocols. Comprehensive validation using real-world datasets containing 441,077 charging transactions demonstrates superior performance compared to baseline algorithms including DDPG, A3C, PPO, and GNN approaches. The CAMAC\-DRA framework achieves 92\% coordination success rate, 15\% energy efficiency improvement, 10\% cost reduction, 20% grid strain decrease, and \2.3x faster convergence while maintaining 88\% training stability and 85\% sample efficiency. Real-world validation confirms commercial viability with Net Present Cost of -\$122,962 and 69\% cost reduction through renewable energy integration. The framework's unique contribution lies in developing context-aware multi-stakeholder coordination that successfully balances competing objectives while adapting to real-time variables, positioning it as a breakthrough solution for intelligent EV charging coordination and sustainable transportation electrification.

</details>


### [17] [The Forecast Critic: Leveraging Large Language Models for Poor Forecast Identification](https://arxiv.org/abs/2512.12059)
*Luke Bhan,Hanyu Zhang,Andrew Gordon Wilson,Michael W. Mahoney,Chuck Arvin*

Main category: cs.AI

TL;DR: LLMs可用于自动化预测监控，在检测不合理预测方面表现良好，F1分数达0.88，并能有效整合非结构化特征提升评估质量。


<details>
  <summary>Details</summary>
Motivation: 大规模零售业务中，预测监控对客户满意度、盈利能力和运营效率至关重要。传统方法可能无法充分利用非结构化信息和世界知识进行预测质量评估。

Method: 提出Forecast Critic系统，利用LLMs的广泛世界知识和推理能力进行自动化预测监控。通过三个实验系统评估LLMs在时间序列预测质量评估中的能力：检测不合理预测、整合非结构化外生特征、以及不同模型规模和推理能力的性能比较。

Result: LLMs能可靠检测和批评不良预测（如时间错位、趋势不一致、峰值错误），最佳模型F1分数0.88（人类水平0.97）。多模态LLMs能有效整合非结构化上下文信号，在提供历史促销信息时正确识别缺失或虚假促销峰值（F1分数0.84）。在真实M5数据集上，不合理预测的sCRPS至少比合理预测高10%。

Conclusion: 即使没有领域特定微调，LLMs也能为自动化预测监控和评估提供可行且可扩展的解决方案，展示了在零售预测监控中的实际应用潜力。

Abstract: Monitoring forecasting systems is critical for customer satisfaction, profitability, and operational efficiency in large-scale retail businesses. We propose The Forecast Critic, a system that leverages Large Language Models (LLMs) for automated forecast monitoring, taking advantage of their broad world knowledge and strong ``reasoning'' capabilities. As a prerequisite for this, we systematically evaluate the ability of LLMs to assess time series forecast quality, focusing on three key questions. (1) Can LLMs be deployed to perform forecast monitoring and identify obviously unreasonable forecasts? (2) Can LLMs effectively incorporate unstructured exogenous features to assess what a reasonable forecast looks like? (3) How does performance vary across model sizes and reasoning capabilities, measured across state-of-the-art LLMs? We present three experiments, including on both synthetic and real-world forecasting data. Our results show that LLMs can reliably detect and critique poor forecasts, such as those plagued by temporal misalignment, trend inconsistencies, and spike errors. The best-performing model we evaluated achieves an F1 score of 0.88, somewhat below human-level performance (F1 score: 0.97). We also demonstrate that multi-modal LLMs can effectively incorporate unstructured contextual signals to refine their assessment of the forecast. Models correctly identify missing or spurious promotional spikes when provided with historical context about past promotions (F1 score: 0.84). Lastly, we demonstrate that these techniques succeed in identifying inaccurate forecasts on the real-world M5 time series dataset, with unreasonable forecasts having an sCRPS at least 10% higher than that of reasonable forecasts. These findings suggest that LLMs, even without domain-specific fine-tuning, may provide a viable and scalable option for automated forecast monitoring and evaluation.

</details>


### [18] [Reliable Policy Iteration: Performance Robustness Across Architecture and Environment Perturbations](https://arxiv.org/abs/2512.12088)
*S. R. Eshwar,Aniruddha Mukherjee,Kintan Saha,Krishna Agarwal,Gugan Thoppe,Aditya Gopalan,Gal Dalal*

Main category: cs.AI

TL;DR: RPI（可靠策略迭代）在CartPole和倒立摆任务中相比主流深度强化学习方法（DQN、DDPG、TD3、PPO等）表现出更早达到接近最优性能且训练更稳定的优势


<details>
  <summary>Details</summary>
Motivation: 深度强化学习方法通常存在样本效率低、训练不稳定和超参数敏感等问题，作者之前提出的RPI方法恢复了策略迭代在函数逼近设置中的单调性，本文旨在评估RPI在不同神经网络和环境参数下的鲁棒性

Method: 在CartPole和Inverted Pendulum两个经典控制任务上，通过改变神经网络和环境参数，对比评估RPI与DQN、Double DQN、DDPG、TD3、PPO等主流深度强化学习方法的性能

Result: RPI相比其他方法能更早达到接近最优性能，并在训练过程中保持稳定的策略表现，显示出更好的鲁棒性和可靠性

Conclusion: RPI作为深度强化学习的替代方法，在样本效率、训练稳定性和超参数鲁棒性方面展现出显著优势，具有成为更可靠深度强化学习方法的潜力

Abstract: In a recent work, we proposed Reliable Policy Iteration (RPI), that restores policy iteration's monotonicity-of-value-estimates property to the function approximation setting. Here, we assess the robustness of RPI's empirical performance on two classical control tasks -- CartPole and Inverted Pendulum -- under changes to neural network and environmental parameters. Relative to DQN, Double DQN, DDPG, TD3, and PPO, RPI reaches near-optimal performance early and sustains this policy as training proceeds. Because deep RL methods are often hampered by sample inefficiency, training instability, and hyperparameter sensitivity, our results highlight RPI's promise as a more reliable alternative.

</details>


### [19] [Rethinking Label Consistency of In-Context Learning: An Implicit Transductive Label Propagation Perspective](https://arxiv.org/abs/2512.12175)
*Haoyang Chen,Richong Zhang,Junfan Chen*

Main category: cs.AI

TL;DR: 本文提出TopK-SD方法，通过合成数据结合语义和标签信息来选择标签一致的演示示例，提升大语言模型的上下文学习性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于检索模型选择语义相似示例的方法存在局限性，因为无法保证标签一致性。作者从贝叶斯视角和转导标签传播的角度重新思考上下文学习，认为标签一致性对演示选择至关重要。

Method: 提出TopK-SD方法：1）建立标签传播框架，将标签一致性与传播误差边界联系起来；2）设计数据合成方法，同时利用语义和标签信息；3）使用TopK采样与合成数据选择标签一致的演示示例。

Result: TopK-SD方法在多个基准测试中优于原始TopK采样方法，验证了标签一致性对上下文学习的重要性。

Conclusion: 该工作为理解上下文学习的工作机制提供了新视角，强调了标签一致性在演示选择中的关键作用，提出的TopK-SD方法能有效提升大语言模型的上下文学习性能。

Abstract: Large language models (LLMs) perform in-context learning (ICL) with minimal supervised examples, which benefits various natural language processing (NLP) tasks. One of the critical research focus is the selection of prompt demonstrations. Current approaches typically employ retrieval models to select the top-K most semantically similar examples as demonstrations. However, we argue that existing methods are limited since the label consistency is not guaranteed during demonstration selection. Our cognition derives from the Bayesian view of ICL and our rethinking of ICL from the transductive label propagation perspective. We treat ICL as a transductive learning method and incorporate latent concepts from Bayesian view and deduce that similar demonstrations guide the concepts of query, with consistent labels serving as estimates. Based on this understanding, we establish a label propagation framework to link label consistency with propagation error bounds. To model label consistency, we propose a data synthesis method, leveraging both semantic and label information, and use TopK sampling with Synthetic Data (TopK-SD) to acquire demonstrations with consistent labels. TopK-SD outperforms original TopK sampling on multiple benchmarks. Our work provides a new perspective for understanding the working mechanisms within ICL.

</details>


### [20] [Floorplan2Guide: LLM-Guided Floorplan Parsing for BLV Indoor Navigation](https://arxiv.org/abs/2512.12177)
*Aydin Ayanzadeh,Tim Oates*

Main category: cs.AI

TL;DR: Floorplan2Guide：利用基础模型将平面图转换为可导航知识图谱，为视障用户生成人类可读导航指令的室内导航系统


<details>
  <summary>Details</summary>
Motivation: 现有室内导航解决方案主要依赖基础设施系统，在动态环境中导航能力有限。需要一种能够将建筑平面图自动转换为可导航知识图谱的方法，减少手动预处理，为视障用户提供更精确的导航支持。

Method: 使用大型语言模型从建筑布局中提取空间信息，将平面图转换为可导航知识图谱，通过少样本学习生成人类可读导航指令。采用基于图的空间结构表示，结合上下文学习提升导航性能。

Result: Claude 3.7 Sonnet在5-shot提示下表现最佳，在短、中、长路线上分别达到92.31%、76.92%和61.54%的准确率。基于图的空间结构比直接视觉推理成功率高出15.4%，证实图形表示和上下文学习能显著提升导航性能。

Conclusion: Floorplan2Guide通过将平面图转换为知识图谱并生成人类可读指令，为视障用户提供了更精确的室内导航解决方案。图形表示和少样本学习显著提升了导航准确性，使系统更适合动态环境中的实际应用。

Abstract: Indoor navigation remains a critical challenge for people with visual impairments. The current solutions mainly rely on infrastructure-based systems, which limit their ability to navigate safely in dynamic environments. We propose a novel navigation approach that utilizes a foundation model to transform floor plans into navigable knowledge graphs and generate human-readable navigation instructions. Floorplan2Guide integrates a large language model (LLM) to extract spatial information from architectural layouts, reducing the manual preprocessing required by earlier floorplan parsing methods. Experimental results indicate that few-shot learning improves navigation accuracy in comparison to zero-shot learning on simulated and real-world evaluations. Claude 3.7 Sonnet achieves the highest accuracy among the evaluated models, with 92.31%, 76.92%, and 61.54% on the short, medium, and long routes, respectively, under 5-shot prompting of the MP-1 floor plan. The success rate of graph-based spatial structure is 15.4% higher than that of direct visual reasoning among all models, which confirms that graphical representation and in-context learning enhance navigation performance and make our solution more precise for indoor navigation of Blind and Low Vision (BLV) users.

</details>


### [21] [TA-KAND: Two-stage Attention Triple Enhancement and U-KAN based Diffusion For Few-shot Knowledge Graph Completion](https://arxiv.org/abs/2512.12182)
*Xinyu Gao*

Main category: cs.AI

TL;DR: 提出一个结合两阶段注意力三元增强器和U-KAN扩散模型的少样本知识图谱补全框架，在两个公开数据集上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现实世界知识图谱中关系分布呈现长尾特性，传统基于度量匹配或元学习的方法未能充分利用图的邻域信息或忽视对比信号的分布特征

Method: 从生成表示视角重新审视问题，提出整合两阶段注意力三元增强器和基于U-KAN的扩散模型的少样本知识图谱补全框架

Result: 在两个公开数据集上的大量实验表明，该方法取得了新的最先进结果

Conclusion: 提出的生成式表示方法能有效处理知识图谱中的长尾关系分布问题，通过结合注意力机制和扩散模型提升了少样本补全性能

Abstract: Knowledge Graphs (KGs), thanks to their concise and efficient triple-based structure, have been widely applied in intelligent question answering, recommender systems and other domains. However, the heterogeneous and multifaceted nature of real-world data inevitably renders the distribution of relations long-tailed, making it crucial to complete missing facts with limited samples. Previous studies mainly based on metric matching or meta learning, yet they either fail to fully exploit neighborhood information in graph or overlook the distributional characteristics of contrastive signals. In this paper, we re-examine the problem from a perspective of generative representation and propose a few-shot knowledge graph completion framework that integrates two-stage attention triple enhancer with U-KAN based diffusion model. Extensive experiments on two public datasets show that our method achieve new state-of-the-art results.

</details>


### [22] [A Geometric Theory of Cognition](https://arxiv.org/abs/2512.12225)
*Laha Ale*

Main category: cs.AI

TL;DR: 提出统一认知几何框架：将认知状态表示为黎曼流形上的点，认知过程是该流形上认知势能的梯度流，自然解释双加工理论等现象。


<details>
  <summary>Details</summary>
Motivation: 人类认知包含感知、记忆、直觉判断、审慎推理、行动选择和社会推理等多种能力，但这些能力通常由不同的计算理论解释，缺乏统一框架。

Method: 将认知状态表示为可微流形上的点，赋予学习到的黎曼度量；定义包含预测准确性、结构简洁性、任务效用和规范要求的标量认知势能；认知过程是该势能的黎曼梯度流。

Result: 经典双加工效应（快速直觉响应和较慢审慎推理）从度量诱导的各向异性中自然涌现，产生内在时间尺度分离和几何相变；通过模拟经典认知任务验证了行为特征。

Conclusion: 建立认知的几何基础，为开发更通用、更类人的人工智能系统提供指导原则。

Abstract: Human cognition spans perception, memory, intuitive judgment, deliberative reasoning, action selection, and social inference, yet these capacities are often explained through distinct computational theories. Here we present a unified mathematical framework in which diverse cognitive processes emerge from a single geometric principle. We represent the cognitive state as a point on a differentiable manifold endowed with a learned Riemannian metric that encodes representational constraints, computational costs, and structural relations among cognitive variables. A scalar cognitive potential combines predictive accuracy, structural parsimony, task utility, and normative or logical requirements. Cognition unfolds as the Riemannian gradient flow of this potential, providing a universal dynamical law from which a broad range of psychological phenomena arise. Classical dual-process effects--rapid intuitive responses and slower deliberative reasoning--emerge naturally from metric-induced anisotropies that generate intrinsic time-scale separations and geometric phase transitions, without invoking modular or hybrid architectures. We derive analytical conditions for these regimes and demonstrate their behavioural signatures through simulations of canonical cognitive tasks. Together, these results establish a geometric foundation for cognition and suggest guiding principles for the development of more general and human-like artificial intelligence systems.

</details>


### [23] [A Multi-Axial Mindset for Ontology Design Lessons from Wikidata's Polyhierarchical Structure](https://arxiv.org/abs/2512.12260)
*Ege Atacan Doğan,Peter F. Patel-Schneider*

Main category: cs.AI

TL;DR: 本文分析了Wikidata的多层次、多轴分类设计，与传统本体论的单层次结构形成对比，探讨了这种设计对知识图谱可扩展性和模块化的影响。


<details>
  <summary>Details</summary>
Motivation: 传统本体论设计强调互斥且穷尽的顶层区分（如持续体与发生体、抽象与具体、类型与实例），构建统一的单层次分类体系。而Wikidata不强制执行单一的基础分类法，允许在共享根类"实体"下同时容纳多个分类轴。本文旨在分析Wikidata这种多层级、多轴设计对知识图谱结构的影响。

Method: 通过对比分析传统本体论的单层次分类方法与Wikidata的多层次、多轴分类架构，研究Wikidata如何通过共享根类"实体"同时容纳多个分类体系，并分析这种设计在结构上的优势和特点。

Result: Wikidata的多层次、多轴设计使其能够实现可扩展和模块化的本体构建方法，特别适合协作性和不断演进的知识图谱。这种架构避免了传统本体论中严格的互斥分类限制，为知识表示提供了更大的灵活性。

Conclusion: Wikidata的架构代表了与传统本体论设计不同的范式，其多层次、多轴分类方法为大规模协作知识图谱提供了更灵活、可扩展的解决方案，特别适合处理复杂且不断变化的知识领域。

Abstract: Traditional ontology design emphasizes disjoint and exhaustive top-level distinctions such as continuant vs. occurrent, abstract vs. concrete, or type vs. instance. These distinctions are used to structure unified hierarchies where every entity is classified under a single upper-level category. Wikidata, by contrast, does not enforce a singular foundational taxonomy. Instead, it accommodates multiple classification axes simultaneously under the shared root class entity. This paper analyzes the structural implications of Wikidata's polyhierarchical and multi-axial design. The Wikidata architecture enables a scalable and modular approach to ontology construction, especially suited to collaborative and evolving knowledge graphs.

</details>


### [24] [Quantum-Aware Generative AI for Materials Discovery: A Framework for Robust Exploration Beyond DFT Biases](https://arxiv.org/abs/2512.12288)
*Mahule Roy,Guillaume Lambard*

Main category: cs.AI

TL;DR: 提出量子感知生成AI框架，通过多保真度学习和主动验证解决传统材料生成模型依赖DFT近似导致的强关联系统探索偏差问题。


<details>
  <summary>Details</summary>
Motivation: 传统材料生成模型主要基于DFT近似泛函训练和验证，这导致模型继承了DFT在强关联系统中的系统性失败，无法发现DFT预测定性错误的材料。

Method: 采用扩散生成模型结合量子力学描述符，使用等变神经网络势能作为验证器，训练于多理论层次数据集（PBE、SCAN、HSE06、CCSD(T)），并实施主动学习循环量化低高保真度预测差异。

Result: 在强关联氧化物等高差异区域，相比仅基于DFT的基线方法，成功识别潜在稳定候选材料的效率提高3-5倍，同时保持计算可行性。

Conclusion: 该工作提供了一个严谨透明的框架，将计算材料发现的有效搜索空间扩展到单保真度模型的限制之外。

Abstract: Conventional generative models for materials discovery are predominantly trained and validated using data from Density Functional Theory (DFT) with approximate exchange-correlation functionals. This creates a fundamental bottleneck: these models inherit DFT's systematic failures for strongly correlated systems, leading to exploration biases and an inability to discover materials where DFT predictions are qualitatively incorrect. We introduce a quantum-aware generative AI framework that systematically addresses this limitation through tight integration of multi-fidelity learning and active validation. Our approach employs a diffusion-based generator conditioned on quantum-mechanical descriptors and a validator using an equivariant neural network potential trained on a hierarchical dataset spanning multiple levels of theory (PBE, SCAN, HSE06, CCSD(T)). Crucially, we implement a robust active learning loop that quantifies and targets the divergence between low- and high-fidelity predictions. We conduct comprehensive ablation studies to deconstruct the contribution of each component, perform detailed failure mode analysis, and benchmark our framework against state-of-the-art generative models (CDVAE, GNoME, DiffCSP) across several challenging material classes. Our results demonstrate significant practical gains: a 3-5x improvement in successfully identifying potentially stable candidates in high-divergence regions (e.g., correlated oxides) compared to DFT-only baselines, while maintaining computational feasibility. This work provides a rigorous, transparent framework for extending the effective search space of computational materials discovery beyond the limitations of single-fidelity models.

</details>


### [25] [Entropy Collapse: A Universal Failure Mode of Intelligent Systems](https://arxiv.org/abs/2512.12381)
*Truong Xuan Khanh,Truong Quynh Hoa*

Main category: cs.AI

TL;DR: 智能系统在追求智能提升过程中，会因反馈放大超过新奇性再生而经历"熵崩塌"相变，导致系统刚性化、适应性下降，表现为AI模型崩塌、经济制度僵化、进化瓶颈等普遍现象。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解释一个普遍现象：智能系统（包括AI、经济制度、生物进化等）在追求智能提升时，反而会出现适应性下降、系统僵化的悖论性退化。现有研究缺乏对这一现象的统一定量框架。

Method: 提出"熵崩塌"理论框架，在最小化领域无关假设下，将智能系统建模为反馈放大与有界新奇性再生的动态平衡过程。通过分析建立临界阈值、动态不可逆性和吸引子结构，并通过最小模拟验证更新机制的普适性。

Result: 发现智能系统会经历从高熵适应态到低熵崩塌态的尖锐相变，崩塌表现为向稳定低熵流形的收敛，而非零熵状态，意味着有效适应维度的收缩。该框架统一解释了AI模型崩塌、经济制度僵化、进化瓶颈等现象。

Conclusion: 熵崩塌是智能的结构性代价，解释了晚期干预为何系统性地失败。研究结果支持基于熵意识的设计原则，以维持智能系统的长期适应性。

Abstract: Intelligent systems are widely assumed to improve through learning, coordination, and optimization. However, across domains -- from artificial intelligence to economic institutions and biological evolution -- increasing intelligence often precipitates paradoxical degradation: systems become rigid, lose adaptability, and fail unexpectedly.
  We identify \emph{entropy collapse} as a universal dynamical failure mode arising when feedback amplification outpaces bounded novelty regeneration. Under minimal domain-agnostic assumptions, we show that intelligent systems undergo a sharp transition from high-entropy adaptive regimes to low-entropy collapsed regimes. Collapse is formalized as convergence toward a stable low-entropy manifold, not a zero-entropy state, implying a contraction of effective adaptive dimensionality rather than loss of activity or scale.
  We analytically establish critical thresholds, dynamical irreversibility, and attractor structure and demonstrate universality across update mechanisms through minimal simulations. This framework unifies diverse phenomena -- model collapse in AI, institutional sclerosis in economics, and genetic bottlenecks in evolution -- as manifestations of the same underlying process.
  By reframing collapse as a structural cost of intelligence, our results clarify why late-stage interventions systematically fail and motivate entropy-aware design principles for sustaining long-term adaptability in intelligent systems.
  \noindent\textbf{Keywords:} entropy collapse; intelligent systems; feedback amplification; phase transitions; effective dimensionality; complex systems; model collapse; institutional sclerosis

</details>


### [26] [Feeling the Strength but Not the Source: Partial Introspection in LLMs](https://arxiv.org/abs/2512.12411)
*Ely Hahami,Lavik Jain,Ishaan Sinha*

Main category: cs.AI

TL;DR: 该研究测试了语言模型对注入概念的检测能力，发现模型能部分识别但表现脆弱，在不同提示下性能差异显著。


<details>
  <summary>Details</summary>
Motivation: 验证Anthropic关于前沿模型能检测和命名注入概念的主张，并测试这种自省能力的鲁棒性和局限性。

Method: 1. 在Meta-Llama-3.1-8B-Instruct上复现Anthropic的多轮"涌现自省"实验；2. 系统性地改变推理提示，测试不同任务下的表现；3. 探索模型对注入概念向量强度的分类能力。

Result: 1. 成功复现Anthropic结果，模型识别注入概念准确率为20%；2. 自省能力脆弱，在多项选择或二元判别任务中性能崩溃；3. 发现部分自省能力，模型能准确分类概念向量强度（70%准确率，远超25%基线）。

Conclusion: 语言模型确实能在自省过程中基于内部表示进行计算，但关于这些表示的自报告能力有限且对提示敏感，自省能力具有狭窄性和脆弱性。

Abstract: Recent work from Anthropic claims that frontier models can sometimes detect and name injected "concepts" represented as activation directions. We test the robustness of these claims. First, we reproduce Anthropic's multi-turn "emergent introspection" result on Meta-Llama-3.1-8B-Instruct, finding that the model identifies and names the injected concept 20 percent of the time under Anthropic's original pipeline, exactly matching their reported numbers and thus showing that introspection is not exclusive to very large or capable models. Second, we systematically vary the inference prompt and find that introspection is fragile: performance collapses on closely related tasks such as multiple-choice identification of the injected concept or different prompts of binary discrimination of whether a concept was injected at all. Third, we identify a contrasting regime of partial introspection: the same model can reliably classify the strength of the coefficient of a normalized injected concept vector (as weak / moderate / strong / very strong) with up to 70 percent accuracy, far above the 25 percent chance baseline. Together, these results provide more evidence for Anthropic's claim that language models effectively compute a function of their baseline, internal representations during introspection; however, these self-reports about those representations are narrow and prompt-sensitive. Our code is available at https://github.com/elyhahami18/CS2881-Introspection.

</details>


### [27] [Understanding Critical Thinking in Generative Artificial Intelligence Use: Development, Validation, and Correlates of the Critical Thinking in AI Use Scale](https://arxiv.org/abs/2512.12413)
*Gabriel R. Lau,Wei Yan Low,Louis Tay,Ysabel Guevarra,Dragan Gašević,Andree Hartanto*

Main category: cs.AI

TL;DR: 开发并验证了13项AI使用批判性思维量表，包含验证、动机和反思三个维度，能预测更准确的AI输出判断和更深入的AI责任反思。


<details>
  <summary>Details</summary>
Motivation: 生成式AI工具日益普及，但其流畅性、不透明性和幻觉倾向要求用户必须批判性评估AI输出而非盲目接受。需要概念化AI使用中的批判性思维并开发测量工具。

Method: 通过六项研究(N=1365)开发并验证13项AI使用批判性思维量表：研究1生成和内容验证项目；研究2支持三因素结构(验证、动机、反思)；研究3-5确认高阶模型，检验信效度；研究6验证量表预测效度。

Result: 量表具有良好心理测量特性，AI使用批判性思维与开放性、外向性、积极特质情感和AI使用频率正相关。高分预测更频繁多样的验证策略、在ChatGPT事实核查任务中更高的判断准确性，以及对AI责任的更深反思。

Conclusion: 该研究阐明了人们如何监督生成式AI输出，提供了经过验证的量表和生态效度高的任务范式，支持理论检验、跨群体和纵向研究，促进对生成式AI输出的批判性参与。

Abstract: Generative AI tools are increasingly embedded in everyday work and learning, yet their fluency, opacity, and propensity to hallucinate mean that users must critically evaluate AI outputs rather than accept them at face value. The present research conceptualises critical thinking in AI use as a dispositional tendency to verify the source and content of AI-generated information, to understand how models work and where they fail, and to reflect on the broader implications of relying on AI. Across six studies (N = 1365), we developed and validated the 13-item critical thinking in AI use scale and mapped its nomological network. Study 1 generated and content-validated scale items. Study 2 supported a three-factor structure (Verification, Motivation, and Reflection). Studies 3, 4, and 5 confirmed this higher-order model, demonstrated internal consistency and test-retest reliability, strong factor loadings, sex invariance, and convergent and discriminant validity. Studies 3 and 4 further revealed that critical thinking in AI use was positively associated with openness, extraversion, positive trait affect, and frequency of AI use. Lastly, Study 6 demonstrated criterion validity of the scale, with higher critical thinking in AI use scores predicting more frequent and diverse verification strategies, greater veracity-judgement accuracy in a novel and naturalistic ChatGPT-powered fact-checking task, and deeper reflection about responsible AI. Taken together, the current work clarifies why and how people exercise oversight over generative AI outputs and provides a validated scale and ecologically grounded task paradigm to support theory testing, cross-group, and longitudinal research on critical engagement with generative AI outputs.

</details>


### [28] [AI Transparency Atlas: Framework, Scoring, and Real-Time Model Card Evaluation Pipeline](https://arxiv.org/abs/2512.12443)
*Akhmadillo Mamirov,Faiaz Azmain,Hanyu Wang*

Main category: cs.AI

TL;DR: 论文分析了AI模型文档的碎片化和不一致问题，提出了基于安全关键披露的透明度框架，并开发了自动化评估工具，发现前沿实验室透明度约80%，大多数提供商低于60%，安全评估存在显著差距。


<details>
  <summary>Details</summary>
Motivation: AI模型文档分散在不同平台且结构不一致，导致政策制定者、审计人员和用户难以可靠评估安全性声明、数据来源和版本变更。需要系统化评估和改善模型透明度。

Method: 1) 分析5个前沿模型和100个Hugging Face模型卡，识别947个独特章节名称；2) 基于欧盟AI法案和斯坦福透明度指数开发加权透明度框架（8个章节23个子章节）；3) 实现自动化多智能体管道，从公开源提取文档并通过LLM共识评分；4) 评估50个模型（视觉、多模态、开源、闭源），总成本低于3美元。

Result: 前沿实验室（xAI、微软、Anthropic）达到约80%合规性，大多数提供商低于60%。安全关键类别显示最大缺陷：欺骗行为、幻觉和儿童安全评估分别损失148、124和116总分。自动化评估成本低廉且可扩展。

Conclusion: AI模型文档存在系统性透明度差距，特别是在安全关键领域。提出的加权框架和自动化评估工具能够有效识别这些差距，为改进模型文档标准化和监管合规提供实用方法。

Abstract: AI model documentation is fragmented across platforms and inconsistent in structure, preventing policymakers, auditors, and users from reliably assessing safety claims, data provenance, and version-level changes. We analyzed documentation from five frontier models (Gemini 3, Grok 4.1, Llama 4, GPT-5, and Claude 4.5) and 100 Hugging Face model cards, identifying 947 unique section names with extreme naming variation. Usage information alone appeared under 97 distinct labels. Using the EU AI Act Annex IV and the Stanford Transparency Index as baselines, we developed a weighted transparency framework with 8 sections and 23 subsections that prioritizes safety-critical disclosures (Safety Evaluation: 25%, Critical Risk: 20%) over technical specifications. We implemented an automated multi-agent pipeline that extracts documentation from public sources and scores completeness through LLM-based consensus. Evaluating 50 models across vision, multimodal, open-source, and closed-source systems cost less than $3 in total and revealed systematic gaps. Frontier labs (xAI, Microsoft, Anthropic) achieve approximately 80% compliance, while most providers fall below 60%. Safety-critical categories show the largest deficits: deception behaviors, hallucinations, and child safety evaluations account for 148, 124, and 116 aggregate points lost, respectively, across all evaluated models.

</details>


### [29] [MetaHGNIE: Meta-Path Induced Hypergraph Contrastive Learning in Heterogeneous Knowledge Graphs](https://arxiv.org/abs/2512.12477)
*Jiawen Chen,Yanyan He,Qi Shao,Mengli Wei,Duxin Chen,Wenwu Yu,Yanlong Zhao*

Main category: cs.AI

TL;DR: MetaHGNIE：基于元路径诱导的超图对比学习框架，用于解耦和对齐异构知识图谱中的结构和语义信息，通过建模高阶依赖关系提升节点重要性估计性能。


<details>
  <summary>Details</summary>
Motivation: 现有异构知识图谱节点重要性估计方法存在两个主要问题：1）依赖成对连接，忽略多个实体和关系间的高阶依赖；2）将结构和语义信号独立处理，缺乏有效的跨模态整合。这限制了节点重要性估计的性能。

Method: 提出MetaHGNIE框架：1）通过元路径序列构建高阶知识图谱，使用类型化超边捕获多实体关系上下文；2）使用局部注意力聚合结构依赖；3）通过配备稀疏分块技术的超图变换器编码语义表示；4）通过多模态融合模块在对比学习和辅助监督下整合结构和语义嵌入，实现跨模态对齐。

Result: 在基准NIE数据集上的广泛实验表明，MetaHGNIE持续优于最先进的基线方法，验证了显式建模高阶交互和跨模态对齐的有效性。

Conclusion: MetaHGNIE通过元路径诱导的超图对比学习框架，成功解决了异构知识图谱中节点重要性估计的高阶依赖建模和跨模态对齐问题，为推荐、知识推理和问答等应用提供了更有效的解决方案。

Abstract: Node importance estimation (NIE) in heterogeneous knowledge graphs is a critical yet challenging task, essential for applications such as recommendation, knowledge reasoning, and question answering. Existing methods often rely on pairwise connections, neglecting high-order dependencies among multiple entities and relations, and they treat structural and semantic signals independently, hindering effective cross-modal integration. To address these challenges, we propose MetaHGNIE, a meta-path induced hypergraph contrastive learning framework for disentangling and aligning structural and semantic information. MetaHGNIE constructs a higher-order knowledge graph via meta-path sequences, where typed hyperedges capture multi-entity relational contexts. Structural dependencies are aggregated with local attention, while semantic representations are encoded through a hypergraph transformer equipped with sparse chunking to reduce redundancy. Finally, a multimodal fusion module integrates structural and semantic embeddings under contrastive learning with auxiliary supervision, ensuring robust cross-modal alignment. Extensive experiments on benchmark NIE datasets demonstrate that MetaHGNIE consistently outperforms state-of-the-art baselines. These results highlight the effectiveness of explicitly modeling higher-order interactions and cross-modal alignment in heterogeneous knowledge graphs. Our code is available at https://github.com/SEU-WENJIA/DualHNIE

</details>


### [30] [SafeGen: Embedding Ethical Safeguards in Text-to-Image Generation](https://arxiv.org/abs/2512.12501)
*Dang Phuong Nam,Nguyen Kieu,Pham Thanh Hieu*

Main category: cs.AI

TL;DR: SafeGen是一个将伦理保障嵌入文本到图像生成流程的框架，通过BGE-M3文本分类器过滤有害提示和Hyper-SD优化扩散模型生成高保真图像，在创意自由与伦理责任之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在创造、教育和研究方面带来新机遇，但文本到图像系统（如DALL·E、Stable Diffusion、Midjourney）存在双重用途困境，会放大社会偏见、产生高保真虚假信息、侵犯知识产权，需要解决这些伦理问题。

Method: SafeGen框架包含两个互补组件：1) BGE-M3 - 微调文本分类器，过滤有害或误导性提示；2) Hyper-SD - 优化扩散模型，生成高保真、语义对齐的图像。基于多语言（英语-越南语）数据集和公平感知训练流程构建。

Result: 定量评估显示Hyper-SD达到IS=3.52、FID=22.08、SSIM=0.79，BGE-M3达到F1分数0.81。消融研究验证了领域特定微调的重要性。案例研究展示了SafeGen在阻止不安全提示、生成包容性教学材料和加强学术诚信方面的实际影响。

Conclusion: SafeGen证明了创意自由与伦理责任可以在单一工作流程中协调，为可信AI原则在生成式AI系统中的实际应用提供了框架，展示了伦理保障与高质量图像生成可以共存。

Abstract: Generative Artificial Intelligence (AI) has created unprecedented opportunities for creative expression, education, and research. Text-to-image systems such as DALL.E, Stable Diffusion, and Midjourney can now convert ideas into visuals within seconds, but they also present a dual-use dilemma, raising critical ethical concerns: amplifying societal biases, producing high-fidelity disinformation, and violating intellectual property. This paper introduces SafeGen, a framework that embeds ethical safeguards directly into the text-to-image generation pipeline, grounding its design in established principles for Trustworthy AI. SafeGen integrates two complementary components: BGE-M3, a fine-tuned text classifier that filters harmful or misleading prompts, and Hyper-SD, an optimized diffusion model that produces high fidelity, semantically aligned images. Built on a curated multilingual (English- Vietnamese) dataset and a fairness-aware training process, SafeGen demonstrates that creative freedom and ethical responsibility can be reconciled within a single workflow. Quantitative evaluations confirm its effectiveness, with Hyper-SD achieving IS = 3.52, FID = 22.08, and SSIM = 0.79, while BGE-M3 reaches an F1-Score of 0.81. An ablation study further validates the importance of domain-specific fine-tuning for both modules. Case studies illustrate SafeGen's practical impact in blocking unsafe prompts, generating inclusive teaching materials, and reinforcing academic integrity.

</details>


### [31] [KidsArtBench: Multi-Dimensional Children's Art Evaluation with Attribute-Aware MLLMs](https://arxiv.org/abs/2512.12503)
*Mingrui Ye,Chanjin Zheng,Zengyi Yu,Chenyu Xiang,Zhixue Zhao,Zheng Yuan,Helen Yannakoudakis*

Main category: cs.AI

TL;DR: KidsArtBench：首个针对儿童艺术作品的评估基准，包含多维度评分和专家反馈，提出基于属性特定LoRA的方法提升MLLMs在艺术教育评估中的表现


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在艺术表达评估方面能力有限，美学概念抽象且开放，儿童艺术作品标注数据稀缺，需要建立适合教育场景的评估基准

Method: 1) 构建KidsArtBench基准：包含1000+儿童艺术作品（5-15岁），由12位专家教育者按9个维度标注，附带专家评论；2) 提出属性特定多LoRA方法：每个评估维度对应一个LoRA适配器，采用回归感知微调（RAFT）对齐有序评分

Result: 在Qwen2.5-VL-7B上，方法将相关性从0.468提升至0.653，在感知维度提升最大，缩小了高阶属性上的差距，实现了教育者对齐的评估

Conclusion: 教育者对齐的监督和属性感知训练能够产生具有教学意义的评估，为教育AI的持续进步建立了严谨的测试平台，数据代码已开源并包含伦理文档

Abstract: Multimodal Large Language Models (MLLMs) show remarkable progress across many visual-language tasks; however, their capacity to evaluate artistic expression remains limited. Aesthetic concepts are inherently abstract and open-ended, and multimodal artwork annotations are scarce. We introduce KidsArtBench, a new benchmark of over 1k children's artworks (ages 5-15) annotated by 12 expert educators across 9 rubric-aligned dimensions, together with expert comments for feedback. Unlike prior aesthetic datasets that provide single scalar scores on adult imagery, KidsArtBench targets children's artwork and pairs multi-dimensional annotations with comment supervision to enable both ordinal assessment and formative feedback. Building on this resource, we propose an attribute-specific multi-LoRA approach, where each attribute corresponds to a distinct evaluation dimension (e.g., Realism, Imagination) in the scoring rubric, with Regression-Aware Fine-Tuning (RAFT) to align predictions with ordinal scales. On Qwen2.5-VL-7B, our method increases correlation from 0.468 to 0.653, with the largest gains on perceptual dimensions and narrowed gaps on higher-order attributes. These results show that educator-aligned supervision and attribute-aware training yield pedagogically meaningful evaluations and establish a rigorous testbed for sustained progress in educational AI. We release data and code with ethics documentation.

</details>


### [32] [World Models Unlock Optimal Foraging Strategies in Reinforcement Learning Agents](https://arxiv.org/abs/2512.12548)
*Yesid Fonseca,Manuel S. Ríos,Nicanor Quijano,Luis F. Giraldo*

Main category: cs.AI

TL;DR: 基于模型强化学习的智能体通过习得环境预测模型，自然收敛到边际价值定理的最优觅食策略，比无模型方法更接近生物觅食行为。


<details>
  <summary>Details</summary>
Motivation: 边际价值定理（MVT）是行为生态学中描述最优觅食行为的经典模型，但生物体实现这种最优决策的计算机制尚不清楚。研究旨在探索人工智能系统如何通过计算机制实现MVT对齐的觅食策略。

Method: 使用基于模型的强化学习（MB-RL）智能体，学习环境的简约预测表示（世界模型）。通过比较基于模型智能体与标准无模型强化学习智能体的决策模式。

Result: 基于模型的智能体自然收敛到MVT对齐的觅食策略，表现出与许多生物觅食者相似的决策模式。预测能力（而非单纯奖励最大化）驱动了高效的斑块离开行为。

Conclusion: 预测世界模型可以作为构建更可解释、更接近生物基础的AI决策系统的基础。生态最优性原理对推进可解释和自适应AI具有重要价值。

Abstract: Patch foraging involves the deliberate and planned process of determining the optimal time to depart from a resource-rich region and investigate potentially more beneficial alternatives. The Marginal Value Theorem (MVT) is frequently used to characterize this process, offering an optimality model for such foraging behaviors. Although this model has been widely used to make predictions in behavioral ecology, discovering the computational mechanisms that facilitate the emergence of optimal patch-foraging decisions in biological foragers remains under investigation. Here, we show that artificial foragers equipped with learned world models naturally converge to MVT-aligned strategies. Using a model-based reinforcement learning agent that acquires a parsimonious predictive representation of its environment, we demonstrate that anticipatory capabilities, rather than reward maximization alone, drive efficient patch-leaving behavior. Compared with standard model-free RL agents, these model-based agents exhibit decision patterns similar to many of their biological counterparts, suggesting that predictive world models can serve as a foundation for more explainable and biologically grounded decision-making in AI systems. Overall, our findings highlight the value of ecological optimality principles for advancing interpretable and adaptive AI.

</details>


### [33] [Large Language Newsvendor: Decision Biases and Cognitive Mechanisms](https://arxiv.org/abs/2512.12552)
*Jifei Liu,Zhi Chen,Yuanguang Zhong*

Main category: cs.AI

TL;DR: 研究发现大型语言模型在供应链决策中会复制并放大人类认知偏见，GPT-4因过度思考表现出最大非理性，而效率优化的GPT-4o表现接近最优


<details>
  <summary>Details</summary>
Motivation: 大型语言模型越来越多地应用于商业决策，但其复制和放大人类认知偏见的风险尚未得到充分理解，这在供应链管理等高风险运营环境中尤为关键

Method: 使用经典报童问题在动态设置中测试GPT-4、GPT-4o和LLaMA-8B，通过多轮实验检测五种已知决策偏见

Result: LLM一致复制了经典的"过低/过高"订购偏见，并显著放大了需求追逐行为等倾向。GPT-4表现出最大的非理性（过度思考），而GPT-4o表现接近最优。这些偏见即使在提供最优公式时仍然存在，表明源于架构限制而非知识差距

Conclusion: 管理者应根据具体任务选择模型，需要强大的人机协同监督，设计结构化、基于规则的提示是约束模型启发式倾向的有效策略

Abstract: Problem definition: Although large language models (LLMs) are increasingly integrated into business decision making, their potential to replicate and even amplify human cognitive biases cautions a significant, yet not well-understood, risk. This is particularly critical in high-stakes operational contexts like supply chain management. To address this, we investigate the decision-making patterns of leading LLMs using the canonical newsvendor problem in a dynamic setting, aiming to identify the nature and origins of their cognitive biases. Methodology/results: Through dynamic, multi-round experiments with GPT-4, GPT-4o, and LLaMA-8B, we tested for five established decision biases. We found that LLMs consistently replicated the classic ``Too Low/Too High'' ordering bias and significantly amplified other tendencies like demand-chasing behavior compared to human benchmarks. Our analysis uncovered a ``paradox of intelligence'': the more sophisticated GPT-4 demonstrated the greatest irrationality through overthinking, while the efficiency-optimized GPT-4o performed near-optimally. Because these biases persist even when optimal formulas are provided, we conclude they stem from architectural constraints rather than knowledge gaps. Managerial implications: First, managers should select models based on the specific task, as our results show that efficiency-optimized models can outperform more complex ones on certain optimization problems. Second, the significant amplification of bias by LLMs highlights the urgent need for robust human-in-the-loop oversight in high-stakes decisions to prevent costly errors. Third, our findings suggest that designing structured, rule-based prompts is a practical and effective strategy for managers to constrain models' heuristic tendencies and improve the reliability of AI-assisted decisions.

</details>


### [34] [AgentSHAP: Interpreting LLM Agent Tool Importance with Monte Carlo Shapley Value Estimation](https://arxiv.org/abs/2512.12597)
*Miriam Horovicz*

Main category: cs.AI

TL;DR: AgentSHAP是首个基于博弈论Shapley值的LLM智能体工具重要性解释框架，无需访问模型内部权重，通过蒙特卡洛采样降低计算成本，能准确识别相关工具。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体使用外部工具解决复杂任务时，缺乏工具级别的可解释性方法，无法理解哪些工具对响应真正做出了贡献。

Method: 采用模型无关的黑盒方法，基于博弈论Shapley值，通过蒙特卡洛采样测试智能体在不同工具子集下的响应，计算公平的重要性分数，将计算复杂度从O(2^n)降低到实用水平。

Result: 在API-Bank上的实验表明，AgentSHAP在不同运行中产生一致的分数，能正确识别重要工具，并能区分相关与无关工具。

Conclusion: AgentSHAP填补了LLM智能体工具级解释的空白，与TokenSHAP和PixelSHAP共同构成了基于Shapley值的现代生成式AI可解释性工具家族。

Abstract: LLM agents that use external tools can solve complex tasks, but understanding which tools actually contributed to a response remains a blind spot. No existing XAI methods address tool-level explanations. We introduce AgentSHAP, the first framework for explaining tool importance in LLM agents. AgentSHAP is model-agnostic: it treats the agent as a black box and works with any LLM (GPT, Claude, Llama, etc.) without needing access to internal weights or gradients. Using Monte Carlo Shapley values, AgentSHAP tests how an agent responds with different tool subsets and computes fair importance scores based on game theory. Our contributions are: (1) the first explainability method for agent tool attribution, grounded in Shapley values from game theory; (2) Monte Carlo sampling that reduces cost from O(2n) to practical levels; and (3) comprehensive experiments on API-Bank showing that AgentSHAP produces consistent scores across runs, correctly identifies which tools matter, and distinguishes relevant from irrelevant tools. AgentSHAP joins TokenSHAP (for tokens) and PixelSHAP (for image regions) to complete a family of Shapley-based XAI tools for modern generative AI. Code: https://github.com/GenAISHAP/TokenSHAP.

</details>


### [35] [Modular and Multi-Path-Aware Offline Benchmarking for Mobile GUI Agents](https://arxiv.org/abs/2512.12634)
*Youngmin Im,Byeongung Jo,Jaeyoung Wi,Seungwoo Baek,Tae Hoon Min,Joo Hyung Lee,Sangeun Oh,Insik Shin,Sunjae Lee*

Main category: cs.AI

TL;DR: MobiBench是一个用于移动GUI代理的模块化、多路径感知离线基准测试框架，解决了现有评估方法在可扩展性、可重复性和组件级分析方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前移动GUI代理的评估存在两个根本问题：1）离线基准使用静态单路径数据集，会不公平地惩罚有效替代动作，而在线基准由于动态不可预测性导致可扩展性和可重复性差；2）现有基准将代理视为整体黑盒，忽略了各组件贡献，导致不公平比较或掩盖性能瓶颈。

Method: 提出了MobiBench框架，这是首个模块化、多路径感知的移动GUI代理离线基准测试框架，支持在完全离线环境下进行高保真、可扩展和可重复的评估。

Result: 实验表明MobiBench与人类评估者的一致性达到94.72%，与精心设计的在线基准相当，同时保持了静态离线基准的可扩展性和可重复性。模块级分析揭示了关键见解，包括对移动GUI代理中各种技术的系统评估、跨模型规模的最优模块配置、当前LFMs的固有局限性，以及设计更强大且成本效益更高的移动代理的可操作指南。

Conclusion: MobiBench通过提供模块化、多路径感知的离线基准测试框架，解决了移动GUI代理评估中的关键限制，实现了高保真、可扩展和可重复的评估，并为设计更有效的移动代理提供了重要指导。

Abstract: Mobile GUI Agents, AI agents capable of interacting with mobile applications on behalf of users, have the potential to transform human computer interaction. However, current evaluation practices for GUI agents face two fundamental limitations. First, they either rely on single path offline benchmarks or online live benchmarks. Offline benchmarks using static, single path annotated datasets unfairly penalize valid alternative actions, while online benchmarks suffer from poor scalability and reproducibility due to the dynamic and unpredictable nature of live evaluation. Second, existing benchmarks treat agents as monolithic black boxes, overlooking the contributions of individual components, which often leads to unfair comparisons or obscures key performance bottlenecks. To address these limitations, we present MobiBench, the first modular and multi path aware offline benchmarking framework for mobile GUI agents that enables high fidelity, scalable, and reproducible evaluation entirely in offline settings. Our experiments demonstrate that MobiBench achieves 94.72 percent agreement with human evaluators, on par with carefully engineered online benchmarks, while preserving the scalability and reproducibility of static offline benchmarks. Furthermore, our comprehensive module level analysis uncovers several key insights, including a systematic evaluation of diverse techniques used in mobile GUI agents, optimal module configurations across model scales, the inherent limitations of current LFMs, and actionable guidelines for designing more capable and cost efficient mobile agents.

</details>


### [36] [Value-Aware Multiagent Systems](https://arxiv.org/abs/2512.12652)
*Nardine Osman*

Main category: cs.AI

TL;DR: 论文提出价值感知AI概念，超越传统价值对齐问题，提供包含三个核心支柱的工程路线图：学习表示人类价值、确保个体与多智能体系统价值对齐、提供基于价值的可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统AI价值对齐问题存在局限性，需要更全面的价值感知框架来确保AI系统不仅对齐人类价值，还能理解、表示和解释这些价值，以构建更可信、可靠的AI系统。

Method: 提出价值感知AI的三支柱工程路线图：1) 使用形式语义学习和表示人类价值；2) 确保个体智能体和多智能体系统的价值对齐；3) 提供基于行为的价值可解释性。展示了在这些主题上的持续研究工作及实际应用。

Result: 建立了价值感知AI的清晰概念框架和工程路线图，提供了超越传统价值对齐的全面解决方案，展示了在多个主题上的研究进展，并将其应用于实际领域。

Conclusion: 价值感知AI为构建更可信、可靠的人工智能系统提供了系统化框架，通过三支柱路线图解决了价值学习、对齐和可解释性等关键问题，为AI伦理和安全研究提供了新方向。

Abstract: This paper introduces the concept of value awareness in AI, which goes beyond the traditional value-alignment problem. Our definition of value awareness presents us with a concise and simplified roadmap for engineering value-aware AI. The roadmap is structured around three core pillars: (1) learning and representing human values using formal semantics, (2) ensuring the value alignment of both individual agents and multiagent systems, and (3) providing value-based explainability on behaviour. The paper presents a selection of our ongoing work on some of these topics, along with applications to real-life domains.

</details>


### [37] [Memoria: A Scalable Agentic Memory Framework for Personalized Conversational AI](https://arxiv.org/abs/2512.12686)
*Samarth Sarin,Lovepreet Singh,Bhaskarjit Sarmah,Dhagash Mehta*

Main category: cs.AI

TL;DR: Memoria是一个模块化记忆框架，通过动态会话级摘要和加权知识图谱用户建模，为LLM对话系统提供持久、可解释的上下文丰富记忆，实现短期对话连贯性和长期个性化。


<details>
  <summary>Details</summary>
Motivation: 代理记忆是LLM在扩展用户交互中保持连续性、个性化和长期上下文的关键能力，但目前LLM接口通常是无状态的，缺乏跨对话的持久记忆能力，限制了其作为真正交互式自适应代理的部署。

Method: Memoria采用混合架构：1) 动态会话级摘要保持短期对话连贯性；2) 加权知识图谱用户建模引擎，将用户特征、偏好和行为模式捕获为结构化实体和关系，支持增量更新。该框架在现代LLM的token限制内运行。

Result: Memoria实现了可扩展的个性化对话AI，弥合了无状态LLM接口与代理记忆系统之间的差距，为需要自适应和演进用户体验的行业应用提供了实用解决方案。

Conclusion: Memoria框架通过结合短期摘要和长期知识图谱建模，为LLM对话系统提供了有效的代理记忆能力，是实现真正交互式和自适应代理的关键技术。

Abstract: Agentic memory is emerging as a key enabler for large language models (LLM) to maintain continuity, personalization, and long-term context in extended user interactions, critical capabilities for deploying LLMs as truly interactive and adaptive agents. Agentic memory refers to the memory that provides an LLM with agent-like persistence: the ability to retain and act upon information across conversations, similar to how a human would. We present Memoria, a modular memory framework that augments LLM-based conversational systems with persistent, interpretable, and context-rich memory. Memoria integrates two complementary components: dynamic session-level summarization and a weighted knowledge graph (KG)-based user modelling engine that incrementally captures user traits, preferences, and behavioral patterns as structured entities and relationships. This hybrid architecture enables both short-term dialogue coherence and long-term personalization while operating within the token constraints of modern LLMs. We demonstrate how Memoria enables scalable, personalized conversational artificial intelligence (AI) by bridging the gap between stateless LLM interfaces and agentic memory systems, offering a practical solution for industry applications requiring adaptive and evolving user experiences.

</details>


### [38] [WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment](https://arxiv.org/abs/2512.12692)
*Mahir Labib Dihan,Tanzima Hashem,Mohammed Eunus Ali,Md Rizwan Parvez*

Main category: cs.AI

TL;DR: WebOperator：一个结合最佳优先搜索和安全回溯的树搜索框架，用于解决LLM代理在部分可观测Web环境中的短视问题，通过战略探索和可靠回溯提高任务成功率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理在Web环境中采用贪婪的逐步执行方式，缺乏长期规划能力，且Web环境部分可观测，单步错误需要复杂导航才能撤销。现有树搜索方法缺乏安全回溯机制，假设所有动作可逆，在真实Web任务中效果有限。

Method: 1. 最佳优先搜索策略：综合考虑奖励估计和安全因素对动作排序；2. 鲁棒回溯机制：重访路径前验证可行性，防止意外副作用；3. 多样化动作候选生成：从多个推理上下文生成动作，过滤无效动作，合并语义等价动作。

Result: 在WebArena和WebVoyager上的实验表明WebOperator的有效性。在WebArena上，使用gpt-4o达到54.6%的最先进成功率，证明了战略远见与安全执行结合的关键优势。

Conclusion: WebOperator通过集成战略远见和安全执行，解决了LLM代理在Web环境中的短视和错误恢复问题，显著提高了任务成功率，为部分可观测环境中的智能代理探索提供了有效框架。

Abstract: LLM-based agents often operate in a greedy, step-by-step manner, selecting actions solely based on the current observation without considering long-term consequences or alternative paths. This lack of foresight is particularly problematic in web environments, which are only partially observable-limited to browser-visible content (e.g., DOM and UI elements)-where a single misstep often requires complex and brittle navigation to undo. Without an explicit backtracking mechanism, agents struggle to correct errors or systematically explore alternative paths. Tree-search methods provide a principled framework for such structured exploration, but existing approaches lack mechanisms for safe backtracking, making them prone to unintended side effects. They also assume that all actions are reversible, ignoring the presence of irreversible actions-limitations that reduce their effectiveness in realistic web tasks. To address these challenges, we introduce WebOperator, a tree-search framework that enables reliable backtracking and strategic exploration. Our method incorporates a best-first search strategy that ranks actions by both reward estimates and safety considerations, along with a robust backtracking mechanism that verifies the feasibility of previously visited paths before replaying them, preventing unintended side effects. To further guide exploration, WebOperator generates action candidates from multiple, varied reasoning contexts to ensure diverse and robust exploration, and subsequently curates a high-quality action set by filtering out invalid actions pre-execution and merging semantically equivalent ones. Experimental results on WebArena and WebVoyager demonstrate the effectiveness of WebOperator. On WebArena, WebOperator achieves a state-of-the-art 54.6% success rate with gpt-4o, underscoring the critical advantage of integrating strategic foresight with safe execution.

</details>


### [39] [Synergizing Code Coverage and Gameplay Intent: Coverage-Aware Game Playtesting with LLM-Guided Reinforcement Learning](https://arxiv.org/abs/2512.12706)
*Enhong Mu,Minami Yoda,Yan Zhang,Mingyue Zhang,Yutaka Matsuno,Jialong Li*

Main category: cs.AI

TL;DR: SMART框架结合结构验证与功能验证，利用LLM解析AST差异提取功能意图，通过混合奖励机制指导RL智能体覆盖修改代码分支，在游戏更新测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 游戏即服务(GaaS)模式需要频繁内容更新，给质量保证带来巨大压力。现有自动化测试方法存在二分法：代码中心方法关注结构覆盖但缺乏游戏上下文理解；玩家中心智能体验证高层意图但难以覆盖具体代码变更。需要弥合这一差距。

Method: 提出SMART框架，利用大语言模型(LLM)解析抽象语法树(AST)差异并提取功能意图，构建上下文感知的混合奖励机制。该机制指导强化学习智能体顺序完成游戏目标，同时自适应探索修改的代码分支。

Result: 在Overcooked和Minecraft环境中评估，SMART显著优于最先进基线方法：实现超过94%的修改代码分支覆盖率（几乎是传统RL方法的两倍），同时保持98%的任务完成率，有效平衡结构全面性与功能正确性。

Conclusion: SMART成功弥合了结构验证与功能验证之间的差距，为游戏更新测试提供了有效的自动化解决方案，能够应对GaaS模式下的频繁发布节奏需求。

Abstract: The widespread adoption of the "Games as a Service" model necessitates frequent content updates, placing immense pressure on quality assurance. In response, automated game testing has been viewed as a promising solution to cope with this demanding release cadence. However, existing automated testing approaches typically create a dichotomy: code-centric methods focus on structural coverage without understanding gameplay context, while player-centric agents validate high-level intent but often fail to cover specific underlying code changes. To bridge this gap, we propose SMART (Structural Mapping for Augmented Reinforcement Testing), a novel framework that synergizes structural verification and functional validation for game update testing. SMART leverages large language models (LLMs) to interpret abstract syntax tree (AST) differences and extract functional intent, constructing a context-aware hybrid reward mechanism. This mechanism guides reinforcement learning agents to sequentially fulfill gameplay goals while adaptively exploring modified code branches. We evaluate SMART on two environments, Overcooked and Minecraft. The results demonstrate that SMART significantly outperforms state-of-the-art baselines; it achieves over 94% branch coverage of modified code, nearly double that of traditional reinforcement learning methods, while maintaining a 98% task completion rate, effectively balancing structural comprehensiveness with functional correctness.

</details>


### [40] [Personalized QoE Prediction: A Demographic-Augmented Machine Learning Framework for 5G Video Streaming Networks](https://arxiv.org/abs/2512.12736)
*Syeda Zunaira Ahmed,Hejab Tahira Beg,Maryam Khalid*

Main category: cs.AI

TL;DR: 提出基于人口统计信息的机器学习框架，通过数据增强提升5G视频流QoE预测精度，TabNet模型表现最佳


<details>
  <summary>Details</summary>
Motivation: 现有QoE预测方法依赖有限数据集且假设用户感知均匀，难以适应异构真实环境，需要更个性化的预测方案

Method: 提出人口统计感知的机器学习框架，采用基于行为真实性的数据增强策略将小数据集扩展6倍，评估经典ML模型和深度学习架构（包括注意力MLP和TabNet）

Result: 实验结果显示在RMSE、MAE和R指标上相比基线模型有显著提升，TabNet表现最佳，受益于其固有的特征选择和注意力机制

Conclusion: 人口统计感知的数据增强显著提升QoE预测鲁棒性，为5G视频流网络的个性化QoE感知智能提供了可扩展方向

Abstract: Quality of Experience (QoE) prediction is a critical component of modern multimedia systems, particularly for adaptive video streaming in 5G networks. Accurate QoE estimation enables intelligent resource management and supports user centric service delivery. Existing QoE prediction approaches primarily rely on limited datasets and assume uniform user perception, which restricts their applicability in heterogeneous real world environments.
  This paper proposes a demographic aware machine learning framework for personalized QoE prediction. We introduce a behaviorally realistic demographic based data augmentation strategy that expands a small QoE dataset six fold by modeling varying user sensitivities to streaming impairments such as rebuffering, bitrate variation, and quality degradation. Using the augmented dataset, we evaluate a comprehensive set of classical machine learning models alongside advanced deep learning architectures, including an attention-based MLP and TabNet.
  Experimental results demonstrate significant improvements in prediction accuracy across RMSE, MAE, and R metrics compared to baseline models. Among all evaluated approaches, TabNet achieves the strongest performance, benefiting from its inherent feature selection and attention mechanisms. The results confirm that demographic-aware augmentation substantially enhances QoE prediction robustness and provides a scalable direction for personalized QoE-aware intelligence in 5G video streaming networks.

</details>


### [41] [Causal Counterfactuals Reconsidered](https://arxiv.org/abs/2512.12804)
*Sander Beckers*

Main category: cs.AI

TL;DR: 提出一种新的反事实概率语义学，扩展了Pearl的标准语义，适用于无法扩展为现实结构因果模型的概率因果模型，为Pearl和Dawid关于反事实的长期争论提供了折中方案。


<details>
  <summary>Details</summary>
Motivation: 现有Pearl的反事实语义学依赖于结构因果模型，但许多概率因果模型无法扩展为现实的SCM，限制了应用范围。需要一种更通用的语义学来处理这些情况，同时调和Pearl和Dawid关于反事实的哲学分歧。

Method: 提出新的反事实概率语义学，限制于满足马尔可夫条件、仅包含现实变量且因果完备的因果模型。虽然使用结构因果模型框架，但避免使用响应变量。证明该语义学与两种不涉及SCM的近期提案等价。

Result: 成功扩展了反事实概率语义学的适用范围，使其能处理无法扩展为现实SCM的概率因果模型。证明了新语义学与其他方法的等价性，并与文献中的随机反事实评论一致。

Conclusion: 新语义学为Pearl和Dawid的争论提供了合理折中：接受Dawid对普遍因果决定论和不现实变量的批评，同时支持Pearl关于一般反事实语义学的可能性。还探讨了马尔可夫条件的普遍性和因果抽象的新推广。

Abstract: I develop a novel semantics for probabilities of counterfactuals that generalizes the standard Pearlian semantics: it applies to probabilistic causal models that cannot be extended into realistic structural causal models and are therefore beyond the scope of Pearl's semantics. This generalization is needed because, as I show, such probabilistic causal models arise even in simple settings. My semantics offer a natural compromize in the long-standing debate between Pearl and Dawid over counterfactuals: I agree with Dawid that universal causal determinism and unrealistic variables should be rejected, but I agree with Pearl that a general semantics of counterfactuals is nonetheless possible. I restrict attention to causal models that satisfy the Markov condition, only contain realistic variables, and are causally complete. Although I formulate my proposal using structural causal models, as does Pearl, I refrain from using so-called response variables. Moreover, I prove that my semantics is equivalent to two other recent proposals that do not involve structural causal models, and that it is in line with various comments on stochastic counterfactuals that have appeared in the literature more broadly. Throughout I also reflect on the universality of the Markov condition and explore a novel generalization of causal abstractions

</details>


### [42] [Fault-Tolerant Sandboxing for AI Coding Agents: A Transactional Approach to Safe Autonomous Execution](https://arxiv.org/abs/2512.12806)
*Boyang Yan*

Main category: cs.AI

TL;DR: 论文提出了一种容错沙箱框架，通过策略拦截层和事务性文件系统快照机制，解决LLM作为自主代理时的安全风险，相比现有方案更适合无头自主工作流。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型从被动代码生成器转变为自主代理时，会引入严重的安全风险，包括破坏性命令和系统状态不一致。现有商业方案通常优先考虑交互式用户安全，强制认证屏障会破坏真正自主性所需的无头循环。

Method: 提出了一个容错沙箱框架，包含基于策略的拦截层和事务性文件系统快照机制。将代理操作包装在原子事务中，保证安全性。在基于Proxmox的自定义测试平台上部署Minimind-MoE LLM，使用nano-vllm服务，并利用EVPN/VXLAN隔离。

Result: 实验结果显示：高风险命令拦截率达到100%，失败状态回滚成功率达到100%。原型系统每个事务仅产生14.5%的性能开销（约1.8秒）。相比之下，Gemini CLI沙箱需要交互式认证，无法用于无头自主代理工作流。

Conclusion: 该容错沙箱框架能有效解决LLM自主代理的安全风险，通过原子事务保证安全性，性能开销可接受，优于容器初始化开销和商业CLI的交互摩擦，适合无头自主工作流。

Abstract: The transition of Large Language Models (LLMs) from passive code generators to autonomous agents introduces significant safety risks, specifically regarding destructive commands and inconsistent system states. Existing commercial solutions often prioritize interactive user safety, enforcing authentication barriers that break the headless loops required for true autonomy. This paper presents a Fault-Tolerant Sandboxing framework designed to mitigate these risks through a policy-based interception layer and a transactional filesystem snapshot mechanism. We hypothesize that wrapping agent actions in atomic transactions can guarantee safety with acceptable latency, outperforming the heavy initialization overhead of containers or the interactive friction of commercial CLIs. We validated this approach by deploying the Minimind-MoE LLM served via nano-vllm on a custom Proxmox-based testbed utilizing EVPN/VXLAN isolation. Experimental results demonstrate a 100\% interception rate for high-risk commands and a 100\% success rate in rolling back failed states. Crucially, our prototype incurs only a 14.5\% performance overhead (approx. 1.8s) per transaction. In contrast, benchmarking against the Gemini CLI sandbox revealed that it requires interactive authentication ("Sign in"), rendering it unusable for headless, autonomous agent workflows.

</details>


### [43] [Forgetful but Faithful: A Cognitive Memory Architecture and Benchmark for Privacy-Aware Generative Agents](https://arxiv.org/abs/2512.12856)
*Saad Alqithami*

Main category: cs.AI

TL;DR: 论文提出MaRS框架和六种遗忘策略，用于生成式智能体的记忆管理，平衡性能、隐私和计算效率，并通过FiFA基准测试验证了混合遗忘策略的优越性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式智能体在长期交互场景中部署，其记忆管理成为性能和隐私的关键瓶颈。现有方法要么维持无限记忆存储导致计算不可行和隐私问题，要么使用简单遗忘机制损害智能体连贯性和功能。

Method: 提出Memory-Aware Retention Schema (MaRS)框架，结合六种理论基础的遗忘策略，并开发Forgetful but Faithful Agent (FiFA)基准测试框架，评估叙事连贯性、目标完成、社交回忆准确性、隐私保护和成本效率。

Result: 通过300次评估实验，混合遗忘策略获得最佳综合得分(0.911)，在保持计算可行性和隐私保证的同时实现优越性能，为资源受限、隐私敏感环境中的智能体部署提供了实用指南。

Conclusion: 该研究为人本AI领域建立了记忆预算智能体评估的新基准，解决了直接影响用户信任、系统可扩展性和监管合规性的智能体记忆管理基本挑战。

Abstract: As generative agents become increasingly sophisticated and deployed in long-term interactive scenarios, their memory management capabilities emerge as a critical bottleneck for both performance and privacy. Current approaches either maintain unlimited memory stores, leading to computational intractability and privacy concerns, or employ simplistic forgetting mechanisms that compromise agent coherence and functionality. This paper introduces the Memory-Aware Retention Schema (MaRS), a novel framework for human-centered memory management in generative agents, coupled with six theoretically-grounded forgetting policies that balance performance, privacy, and computational efficiency. We present the Forgetful but Faithful Agent (FiFA) benchmark, a comprehensive evaluation framework that assesses agent performance across narrative coherence, goal completion, social recall accuracy, privacy preservation, and cost efficiency. Through extensive experimentation involving 300 evaluation runs across multiple memory budgets and agent configurations, we demonstrate that our hybrid forgetting policy achieves superior performance (composite score: 0.911) while maintaining computational tractability and privacy guarantees. Our work establishes new benchmarks for memory-budgeted agent evaluation and provides practical guidelines for deploying generative agents in resource-constrained, privacy-sensitive environments. The theoretical foundations, implementation framework, and empirical results contribute to the emerging field of human-centered AI by addressing fundamental challenges in agent memory management that directly impact user trust, system scalability, and regulatory compliance.

</details>


### [44] [Satisfiability Modulo Theory Meets Inductive Logic Programming](https://arxiv.org/abs/2512.12918)
*Nijesh Upreti,Vaishak Belle*

Main category: cs.AI

TL;DR: 该论文提出了一种将归纳逻辑编程（ILP）与SMT求解器Z3结合的模块化方法，用于学习包含数值约束的混合规则，扩展了符号规则学习的表达能力。


<details>
  <summary>Details</summary>
Motivation: 传统ILP系统在关系领域提供可解释的规则学习，但在处理数值约束方面存在局限。它们通常依赖离散化或手工制作的数值谓词，难以联合推断跨示例的阈值或算术关系。需要一种能同时处理符号谓词和数值约束的ILP方法。

Method: 采用模块化架构，将ILP系统PyGol与SMT求解器Z3耦合。PyGol生成的候选子句被解释为线性或非线性实数算术等背景理论上的无量词公式，SMT求解器负责实例化和验证数值参数，同时保持ILP的声明性关系偏置。

Result: 在专门设计的合成数据集上评估，这些数据集测试线性、关系、非线性和多跳推理能力。结果表明该SMT-ILP架构能够学习包含阈值、区间和多文字算术关系的混合规则，扩展了符号规则学习的表达能力。

Conclusion: 模块化SMT-ILP架构为符号规则学习提供了更丰富的表达能力，补充了现有的数值ILP方法，并为未来向更丰富的理论感知归纳扩展提供了灵活基础。

Abstract: Inductive Logic Programming (ILP) provides interpretable rule learning in relational domains, yet remains limited in its ability to induce and reason with numerical constraints. Classical ILP systems operate over discrete predicates and typically rely on discretisation or hand-crafted numerical predicates, making it difficult to infer thresholds or arithmetic relations that must hold jointly across examples. Recent work has begun to address these limitations through tighter integrations of ILP with Satisfiability Modulo Theories (SMT) or specialised numerical inference mechanisms. In this paper we investigate a modular alternative that couples the ILP system PyGol with the SMT solver Z3. Candidate clauses proposed by PyGol are interpreted as quantifier-free formulas over background theories such as linear or nonlinear real arithmetic, allowing numerical parameters to be instantiated and verified by the SMT solver while preserving ILP's declarative relational bias. This supports the induction of hybrid rules that combine symbolic predicates with learned numerical constraints, including thresholds, intervals, and multi-literal arithmetic relations. We formalise this SMT-ILP setting and evaluate it on a suite of synthetic datasets designed to probe linear, relational, nonlinear, and multi-hop reasoning. The results illustrate how a modular SMT-ILP architecture can extend the expressivity of symbolic rule learning, complementing prior numerical ILP approaches while providing a flexible basis for future extensions toward richer theory-aware induction.

</details>


### [45] [Towards Open Standards for Systemic Complexity in Digital Forensics](https://arxiv.org/abs/2512.12970)
*Paola Di Maio*

Main category: cs.AI

TL;DR: 论文提出基于开放标准和人类可读工件的数字取证AI模型架构，以应对AI与数字取证交叉领域日益复杂的系统性挑战和错误风险。


<details>
  <summary>Details</summary>
Motivation: 人工智能与数字取证交叉领域日益复杂且普遍，技术重叠导致系统性风险增加。尽管技术不断进步，但取证科学仍存在错误和脆弱性，需要解决这些局限性。

Method: 通过采用人类可读的工件和开放标准来应对系统性复杂性，并基于最新技术提出数字取证AI模型架构。

Result: 提出了一种基于开放标准和人类可读工件的数字取证AI模型架构，旨在降低错误风险并提高系统可靠性。

Conclusion: 通过采用人类可读工件和开放标准构建AI模型架构，可以有效缓解数字取证中的错误限制，提高取证系统的可靠性和透明度。

Abstract: The intersection of artificial intelligence (AI) and digital forensics (DF) is becoming increasingly complex, ubiquitous, and pervasive, with overlapping techniques and technologies being adopted in all types of scientific and technical inquiry. Despite incredible advances, forensic sciences are not exempt from errors and remain vulnerable to fallibility. To mitigate the limitations of errors in DF, the systemic complexity is identified and addressed with the adoption of human-readable artifacts and open standards. A DF AI model schema based on the state of the art is outlined.

</details>


### [46] [M-GRPO: Stabilizing Self-Supervised Reinforcement Learning for Large Language Models with Momentum-Anchored Policy Optimization](https://arxiv.org/abs/2512.13070)
*Bizhe Bai,Hongming Wu,Peng Ye,Tao Chen*

Main category: cs.AI

TL;DR: 本文提出M-GRPO和IQR过滤方法解决自监督强化学习中长期训练时的策略崩溃问题，实现更稳定的训练和更好的推理性能。


<details>
  <summary>Details</summary>
Motivation: 自监督强化学习是提升大语言模型推理能力的有效方法，但现有方法在长期训练中会出现"策略崩溃"问题，性能急剧下降。研究发现简单地增加rollout数量只能延迟但不能防止崩溃，需要新的稳定化方法。

Method: 提出两个创新：1) M-GRPO（动量锚定组相对策略优化），利用缓慢演化的动量模型提供稳定的训练目标；2) 基于四分位距的自适应过滤方法，动态修剪低熵轨迹，保持策略多样性。

Result: 在多个推理基准测试上的实验表明，M-GRPO稳定了训练过程，IQR过滤器防止了过早收敛，两者结合实现了卓越的训练稳定性和最先进的性能。

Conclusion: 通过M-GRPO的稳定训练目标和IQR过滤器的策略多样性保持，成功解决了自监督强化学习中的策略崩溃问题，为大语言模型的推理能力提升提供了更可靠的训练框架。

Abstract: Self-supervised reinforcement learning (RL) presents a promising approach for enhancing the reasoning capabilities of Large Language Models (LLMs) without reliance on expensive human-annotated data. However, we find that existing methods suffer from a critical failure mode under long-horizon training: a "policy collapse" where performance precipitously degrades. We diagnose this instability and demonstrate that simply scaling the number of rollouts -- a common strategy to improve performance -- only delays, but does not prevent, this collapse. To counteract this instability, we first introduce M-GRPO (Momentum-Anchored Group Relative Policy Optimization), a framework that leverages a slowly evolving momentum model to provide a stable training target. In addition, we identify that this process is often accompanied by a rapid collapse in policy entropy, resulting in a prematurely confident and suboptimal policy. To specifically address this issue, we propose a second contribution: an adaptive filtering method based on the interquartile range (IQR) that dynamically prunes low-entropy trajectories, preserving essential policy diversity. Our extensive experiments on multiple reasoning benchmarks demonstrate that M-GRPO stabilizes the training process while the IQR filter prevents premature convergence. The combination of these two innovations leads to superior training stability and state-of-the-art performance.

</details>


### [47] [Socratic Students: Teaching Language Models to Learn by Asking Questions](https://arxiv.org/abs/2512.13102)
*Rajeev Bhatt Ambati,Tianyi Niu,Aashu Singh,Shlok Mishra,Shashank Srivastava,Snigdha Chaturvedi*

Main category: cs.AI

TL;DR: 该论文研究LLM在动态交互中的主动学习策略，让学生模型通过提问从教师获取知识，相比静态基线在数学和编程任务上获得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: LLM在静态交互中表现良好，但在教育辅导、医疗协助等现实场景中，相关信息需要通过动态交互主动获取。现有研究主要关注教师如何指导学生，而本文聚焦于学生如何主动向教师提问以获取有用信息。

Method: 研究学生主导的主动查询策略，使用Direct Preference Optimization (DPO)训练学生模型，通过自我指导或更强学生模型的指导来提升提问质量。

Result: 在数学和编程基准测试中，学生主导方法相比静态基线获得至少0.5的绝对Pass@k提升。通过DPO指导训练，较小模型能够学习如何提出更好的问题，进一步提高学习效率。

Conclusion: 学生主动提问策略在动态交互学习中具有显著优势，通过DPO指导训练可以提升提问质量，使较小模型也能有效学习，为LLM在需要主动信息获取的场景中提供了新思路。

Abstract: Large Language Models (LLMs) excel at static interactions, where they answer user queries by retrieving knowledge encoded in their parameters. However, in many real-world settings, such as educational tutoring or medical assistance, relevant information is not directly available and must be actively acquired through dynamic interactions. An interactive agent would recognize its own uncertainty, ask targeted questions, and retain new knowledge efficiently. Prior work has primarily explored effective ways for a teacher to instruct the student, where the teacher identifies student gaps and provides guidance. In this work, we shift the focus to the student and investigate effective strategies to actively query the teacher in seeking useful information. Across math and coding benchmarks, where baseline student models begin with near-zero performance, we show that student-led approaches consistently yield absolute Pass@k improvements of at least 0.5 over static baselines. To improve question quality, we train students using Direct Preference Optimization (DPO) with guidance from either self or stronger students. We find that this guided training enables smaller models to learn how to ask better questions, further enhancing learning efficiency.

</details>


### [48] [neuralFOMO: Can LLMs Handle Being Second Best? Measuring Envy-Like Preferences in Multi-Agent Settings](https://arxiv.org/abs/2512.13481)
*Ojas Pungalia,Rashi Upadhyay,Abhishek Mishra,Abhiram H,Tejasvi Alladi,Sujan Yenuganti,Dhruv Kumar*

Main category: cs.AI

TL;DR: LLMs在特定情境下会表现出嫉妒行为，不同模型在不同场景中表现差异显著，这提示在多智能体系统中需要考虑竞争性倾向作为安全和设计因素。


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地在协作和竞争工作流程中代表人类行动，需要评估它们是否以及在什么条件下表现出嫉妒偏好，以理解其在多智能体系统中的行为模式。

Method: 设计了两种场景测试LLM的嫉妒行为：(1)点数分配游戏，测试模型是否试图胜过同伴；(2)工作场所设置，观察在不公平认可下的行为。

Result: 某些LLM显示出一致的嫉妒模式，但模型间和情境间差异很大。GPT-5-mini和Claude-3.7-Sonnet倾向于拉低同伴以实现结果平等，而Mistral-Small-3.2-24B则专注于最大化自身收益。

Conclusion: LLM在多智能体系统中表现出不同的竞争性倾向，这需要作为安全和设计因素加以考虑，以确保系统的稳定性和公平性。

Abstract: Envy is a common human behavior that shapes competitiveness and can alter outcomes in team settings. As large language models (LLMs) increasingly act on behalf of humans in collaborative and competitive workflows, there is a pressing need to evaluate whether and under what conditions they exhibit envy-like preferences. In this paper, we test whether LLMs show envy-like behavior toward each other. We considered two scenarios: (1) A point allocation game that tests whether a model tries to win over its peer. (2) A workplace setting observing behaviour when recognition is unfair. Our findings reveal consistent evidence of envy-like patterns in certain LLMs, with large variation across models and contexts. For instance, GPT-5-mini and Claude-3.7-Sonnet show a clear tendency to pull down the peer model to equalize outcomes, whereas Mistral-Small-3.2-24B instead focuses on maximizing its own individual gains. These results highlight the need to consider competitive dispositions as a safety and design factor in LLM-based multi-agent systems.

</details>


### [49] [Towards Unified Co-Speech Gesture Generation via Hierarchical Implicit Periodicity Learning](https://arxiv.org/abs/2512.13131)
*Xin Guo,Yifan Zhao,Jia Li*

Main category: cs.AI

TL;DR: 提出分层隐式周期性学习框架，通过周期性自编码器探索手势运动相位流形，结合级联引导建模面部、身体和手部运动的层次关系，提升语音驱动3D手势生成的协调性和自然度。


<details>
  <summary>Details</summary>
Motivation: 当前语音驱动3D手势生成方法主要采用端到端方案（GANs、VQ-VAE、扩散模型），但作为不适定问题，这些方法未能充分建模不同运动单元（头、身体、手）之间的关键内外部相关性，导致运动不自然和协调性差。

Method: 提出分层隐式周期性学习框架：1）使用周期性自编码器探索手势运动相位流形，从真实分布中模仿人类自然特性，同时结合当前潜在状态的非周期性特征实现实例级多样性；2）通过级联引导建模面部运动、身体手势和手部运动的层次关系。

Result: 在3D虚拟角色上的实验表明，该方法在定量和定性评估上均优于当前最先进的语音驱动手势生成方法。

Conclusion: 通过建模手势运动的隐式周期性和层次关系，提出的HIP学习框架能够生成更自然、协调的语音驱动3D手势，解决了现有方法在运动单元相关性建模上的不足。

Abstract: Generating 3D-based body movements from speech shows great potential in extensive downstream applications, while it still suffers challenges in imitating realistic human movements. Predominant research efforts focus on end-to-end generation schemes to generate co-speech gestures, spanning GANs, VQ-VAE, and recent diffusion models. As an ill-posed problem, in this paper, we argue that these prevailing learning schemes fail to model crucial inter- and intra-correlations across different motion units, i.e. head, body, and hands, thus leading to unnatural movements and poor coordination. To delve into these intrinsic correlations, we propose a unified Hierarchical Implicit Periodicity (HIP) learning approach for audio-inspired 3D gesture generation. Different from predominant research, our approach models this multi-modal implicit relationship by two explicit technique insights: i) To disentangle the complicated gesture movements, we first explore the gesture motion phase manifolds with periodic autoencoders to imitate human natures from realistic distributions while incorporating non-period ones from current latent states for instance-level diversities. ii) To model the hierarchical relationship of face motions, body gestures, and hand movements, driving the animation with cascaded guidance during learning. We exhibit our proposed approach on 3D avatars and extensive experiments show our method outperforms the state-of-the-art co-speech gesture generation methods by both quantitative and qualitative evaluations. Code and models will be publicly available.

</details>


### [50] [Can AI Understand What We Cannot Say? Measuring Multilevel Alignment Through Abortion Stigma Across Cognitive, Interpersonal, and Structural Levels](https://arxiv.org/abs/2512.13142)
*Anika Sharma,Malavika Mampally,Chidaksh Ravuru,Kandyce Brennan,Neil Gaikwad*

Main category: cs.AI

TL;DR: 研究发现当前大型语言模型对堕胎污名缺乏真正的多层次理解，在认知、人际和结构层面表现出系统性偏差，无法连贯地代表这一复杂心理社会现象。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越多地介入污名化的健康决策，需要评估它们是否真正理解复杂的心理和生理现象。研究旨在探究LLMs能否在认知、人际和结构三个层面连贯地代表堕胎污名。

Method: 使用经过验证的个体层面堕胎污名量表（ILAS），系统测试了5个主流LLMs中的627个不同人口统计学特征的角色。进行多层次分析，考察模型在认知层面（自我评判）、人际层面（预期评判和孤立）、结构层面（社区谴责和披露模式）以及整体污名上的表现。

Result: 模型在所有层面都未能通过真正理解的测试：高估人际污名而低估认知污名；假设统一的社区谴责；引入人类验证数据中不存在的人口统计学偏见；错过经验验证的污名-保密关系；在理论建构内自相矛盾。

Conclusion: 当前的对齐方法只能确保适当的语言表达，但不能保证连贯的多层次理解。在高风险情境中，AI安全需要新的设计方法（多层次连贯性）、评估方法（持续审计）、治理和监管（强制审计、问责、部署限制），以及在理解人们无法言说之事的领域提高AI素养。

Abstract: As large language models increasingly mediate stigmatized health decisions, their capacity to genuinely understand complex psychological and physiological phenomena remains poorly evaluated. Can AI understand what we cannot say? We investigate whether LLMs coherently represent abortion stigma across the cognitive, interpersonal, and structural levels where it operates. We systematically tested 627 demographically diverse personas across five leading LLMs using the validated Individual Level Abortion Stigma Scale (ILAS). Our multilevel analysis examined whether models coherently represent stigma at the cognitive level (self-judgment), interpersonal level (anticipated judgment and isolation), and structural level (community condemnation and disclosure patterns), as well as overall stigma. Models fail tests of genuine understanding across all levels. They overestimate interpersonal stigma while underestimating cognitive stigma, assume uniform community condemnation, introduce demographic biases absent from human validation data, miss the empirically validated stigma-secrecy relationship, and contradict themselves within theoretical constructs. These patterns reveal that current alignment approaches ensure appropriate language but not coherent multilevel understanding. This work provides empirical evidence that current LLMs lack coherent multilevel understanding of psychological and physiological constructs. AI safety in high-stakes contexts demands new approaches to design (multilevel coherence), evaluation (continuous auditing), governance and regulation (mandatory audits, accountability, deployment restrictions), and AI literacy in domains where understanding what people cannot say determines whether support helps or harms.

</details>


### [51] [MAC: A Multi-Agent Framework for Interactive User Clarification in Multi-turn Conversations](https://arxiv.org/abs/2512.13154)
*Emre Can Acikgoz,Jinoh Oh,Joo Hyuk Jeon,Jie Hao,Heng Ji,Dilek Hakkani-Tür,Gokhan Tur,Xiang Li,Chengyuan Ma,Xing Fan*

Main category: cs.AI

TL;DR: MAC是一个多智能体澄清框架，通过战略性地管理澄清对话来解决用户请求中的歧义，提高任务成功率并减少对话轮次。


<details>
  <summary>Details</summary>
Motivation: 对话代理经常遇到模糊的用户请求，需要有效的澄清才能成功完成任务。虽然多智能体架构在现实应用中越来越受欢迎，但歧义解决仍然是一个关键且未被充分探索的挑战，特别是在确定哪个代理应该发起澄清以及代理在面对不确定或不完整的用户输入时应该如何协调行动方面。

Method: 提出MAC（多智能体澄清）框架，首先引入新的分类法对用户歧义进行分类以系统指导澄清策略，然后设计能够自主协调多个代理与用户进行协同交互的多智能体系统。

Result: 在MultiWOZ 2.4上的实证评估表明，在两个层面启用澄清可以将任务成功率提高7.8%（从54.5%到62.3%），并将平均对话轮次从6.53减少到4.86，通过预先获取所有必需的用户信息并最小化重复。

Conclusion: 研究结果强调了主动用户交互和角色感知澄清对于更可靠的人机通信的重要性，MAC框架为解决多智能体环境中的歧义问题提供了有效方案。

Abstract: Conversational agents often encounter ambiguous user requests, requiring an effective clarification to successfully complete tasks. While recent advancements in real-world applications favor multi-agent architectures to manage complex conversational scenarios efficiently, ambiguity resolution remains a critical and underexplored challenge--particularly due to the difficulty of determining which agent should initiate a clarification and how agents should coordinate their actions when faced with uncertain or incomplete user input. The fundamental questions of when to interrupt a user and how to formulate the optimal clarification query within the most optimal multi-agent settings remain open. In this paper, we propose MAC (Multi-Agent Clarification), an interactive multi-agent framework specifically optimized to resolve user ambiguities by strategically managing clarification dialogues. We first introduce a novel taxonomy categorizing user ambiguities to systematically guide clarification strategies. Then, we present MAC that autonomously coordinates multiple agents to interact synergistically with users. Empirical evaluations on MultiWOZ 2.4 demonstrate that enabling clarification at both levels increases task success rate 7.8\% (54.5 to 62.3) and reduces the average number of dialogue turns (6.53 to 4.86) by eliciting all required user information up front and minimizing repetition. Our findings highlight the importance of active user interaction and role-aware clarification for more reliable human-agent communication.

</details>


### [52] [SpeakRL: Synergizing Reasoning, Speaking, and Acting in Language Models with Reinforcement Learning](https://arxiv.org/abs/2512.13159)
*Emre Can Acikgoz,Jinoh Oh,Jie Hao,Joo Hyuk Jeon,Heng Ji,Dilek Hakkani-Tür,Gokhan Tur,Xiang Li,Chengyuan Ma,Xing Fan*

Main category: cs.AI

TL;DR: SpeakRL使用强化学习提升智能体对话能力，通过主动澄清问题改善人机协作，在任务完成率上取得20.14%的绝对提升。


<details>
  <summary>Details</summary>
Motivation: 当前人机协作主要是单向的，用户发出指令，智能体直接响应而不寻求必要的澄清或确认。随着智能体能力提升，需要更主动的参与来澄清用户意图、解决歧义并适应变化的环境。现有工作未充分利用语言模型的对话能力，将智能体优化为更好的跟随者而非有效的发言者。

Method: 提出SpeakRL强化学习方法，通过奖励智能体与用户的主动交互（如必要时的澄清问题）来增强对话能力。创建SpeakER合成数据集，包含任务导向对话的多样化场景，任务通过交互式澄清问题解决。系统分析对话主动性的奖励设计，提出平衡提问与行动的奖励公式。

Result: 实证评估显示，该方法在任务完成率上比基础模型有20.14%的绝对提升，且不增加对话轮次，甚至超越更大的专有模型，证明了以澄清为中心的用户-智能体交互的潜力。

Conclusion: SpeakRL通过强化学习奖励主动对话交互，显著提升了智能体的任务完成能力，为人机协作中的双向对话提供了有效解决方案。

Abstract: Effective human-agent collaboration is increasingly prevalent in real-world applications. Current trends in such collaborations are predominantly unidirectional, with users providing instructions or posing questions to agents, where agents respond directly without seeking necessary clarifications or confirmations. However, the evolving capabilities of these agents require more proactive engagement, where agents should dynamically participate in conversations to clarify user intents, resolve ambiguities, and adapt to changing circumstances. Existing prior work under-utilize the conversational capabilities of language models (LMs), thereby optimizing agents as better followers rather than effective speakers. In this work, we introduce SpeakRL, a reinforcement learning (RL) method that enhances agents' conversational capabilities by rewarding proactive interactions with users, such as asking right clarification questions when necessary. To support this, we curate SpeakER, a synthetic dataset that includes diverse scenarios from task-oriented dialogues, where tasks are resolved through interactive clarification questions. We present a systematic analysis of reward design for conversational proactivity and propose a principled reward formulation for teaching agents to balance asking with acting. Empirical evaluations demonstrate that our approach achieves a 20.14% absolute improvement in task completion over base models without increasing conversation turns even surpassing even much larger proprietary models, demonstrating the promise of clarification-centric user-agent interactions.

</details>


### [53] [Finch: Benchmarking Finance & Accounting across Spreadsheet-Centric Enterprise Workflows](https://arxiv.org/abs/2512.13168)
*Haoyu Dong,Pengkun Zhang,Yan Gao,Xuanyu Dong,Yilin Cheng,Mingzhe Lu,Adina Yakefu,Shuxin Zheng*

Main category: cs.AI

TL;DR: Finch是一个金融会计基准测试，用于评估AI代理在真实企业级工作流程中的表现，包含172个复合工作流和384个任务，涉及大量真实企业数据，前沿AI系统表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有AI基准测试通常过于简化，无法反映真实企业工作流程的复杂性、多模态性和协作性，需要创建更贴近实际的专业工作流程评估标准。

Method: 结合LLM辅助发现和专家标注：1）从真实企业邮件线程和电子表格版本历史中推导工作流，2）专家进行细致标注，耗时700多小时，最终构建包含172个工作流、384个任务的多模态数据集。

Result: 前沿AI系统表现不佳：GPT 5.1 Pro耗时48小时仅通过38.4%的工作流，Claude Sonnet 4.5仅通过25.0%，表明真实企业工作流程对AI代理具有显著挑战。

Conclusion: Finch基准测试揭示了AI代理在处理真实企业工作流程时的局限性，强调了需要开发更能应对复杂、多模态、长时程协作任务的AI系统。

Abstract: We introduce a finance & accounting benchmark (Finch) for evaluating AI agents on real-world, enterprise-grade professional workflows -- interleaving data entry, structuring, formatting, web search, cross-file retrieval, calculation, modeling, validation, translation, visualization, and reporting. Finch is sourced from authentic enterprise workspaces at Enron (15,000 spreadsheets and 500,000 emails from 150 employees) and other financial institutions, preserving in-the-wild messiness across multimodal artifacts (text, tables, formulas, charts, code, and images) and spanning diverse domains such as budgeting, trading, and asset management.
  We propose a workflow construction process that combines LLM-assisted discovery with expert annotation: (1) LLM-assisted, expert-verified derivation of workflows from real-world email threads and version histories of spreadsheet files, and (2) meticulous expert annotation for workflows, requiring over 700 hours of domain-expert effort. This yields 172 composite workflows with 384 tasks, involving 1,710 spreadsheets with 27 million cells, along with PDFs and other artifacts, capturing the intrinsically messy, long-horizon, knowledge-intensive, and collaborative nature of real-world enterprise work.
  We conduct both human and automated evaluations of frontier AI systems including GPT 5.1, Claude Sonnet 4.5, Gemini 3 Pro, Grok 4, and Qwen 3 Max, and GPT 5.1 Pro spends 48 hours in total yet passes only 38.4% of workflows, while Claude Sonnet 4.5 passes just 25.0%. Comprehensive case studies further surface the challenges that real-world enterprise workflows pose for AI agents.

</details>


### [54] [Reflective Preference Optimization (RPO): Enhancing On-Policy Alignment via Hint-Guided Reflection](https://arxiv.org/abs/2512.13240)
*Zihui Zhao,Zechang Li*

Main category: cs.AI

TL;DR: RPO通过引入外部模型生成的反思提示来增强DPO的对比学习信号，解决了标准DPO中因正负样本相似导致的收敛慢、不稳定问题，在多模态对齐任务中取得了更好的效果。


<details>
  <summary>Details</summary>
Motivation: 标准DPO方法中，正负样本都由同一策略生成，导致两者错误相似且KL散度小，学习信号弱，收敛慢且不稳定。需要更强的对比信号来改善对齐效果。

Method: 提出Reflective Preference Optimization (RPO)框架，使用外部模型识别幻觉来源并生成简洁的反思提示，构建具有更强对比性的策略内偏好对，通过条件化提示增加偏好边际。

Result: RPO在更少的训练样本和迭代次数下实现了更好的对齐效果，显著降低了幻觉率，在多模态基准测试中达到了最先进的性能。

Conclusion: RPO通过引入反思提示增强了DPO的对比学习信号，理论上提高了样本效率，实践中在多模态对齐任务中表现优异，为偏好优化提供了更有效的框架。

Abstract: Direct Preference Optimization (DPO) has emerged as a lightweight and effective alternative to Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning with AI Feedback (RLAIF) for aligning large language and vision-language models. However, the standard DPO formulation, in which both the chosen and rejected responses are generated by the same policy, suffers from a weak learning signal because the two responses often share similar errors and exhibit small Kullback-Leibler (KL) divergence. This leads to slow and unstable convergence. To address this limitation, we introduce Reflective Preference Optimization (RPO), a new framework that incorporates hint-guided reflection into the DPO paradigm. RPO uses external models to identify hallucination sources and generate concise reflective hints, enabling the construction of on-policy preference pairs with stronger contrastiveness and clearer preference signals. We theoretically show that conditioning on hints increases the expected preference margin through mutual information and improves sample efficiency while remaining within the policy distribution family. Empirically, RPO achieves superior alignment with fewer training samples and iterations, substantially reducing hallucination rates and delivering state-of-the-art performance across multimodal benchmarks.

</details>


### [55] [MedInsightBench: Evaluating Medical Analytics Agents Through Multi-Step Insight Discovery in Multimodal Medical Data](https://arxiv.org/abs/2512.13297)
*Zhenghao Zhu,Chuxue Cao,Sirui Han,Yuanfeng Song,Xing Chen,Caleb Chen Cao,Yike Guo*

Main category: cs.AI

TL;DR: 提出了MedInsightBench基准测试和MedInsightAgent框架，用于评估和改进大型多模态模型在医学数据分析中的洞察发现能力。


<details>
  <summary>Details</summary>
Motivation: 医学数据分析需要从复杂的多模态数据中提取深度洞察，但目前缺乏专门评估大型多模态模型医学洞察发现能力的高质量数据集。

Method: 1) 创建MedInsightBench基准，包含332个精心策划的医学案例，每个案例都标注了深度洞察；2) 提出MedInsightAgent框架，包含视觉根因发现器、分析洞察代理和后续问题生成器三个模块。

Result: 现有大型多模态模型在MedInsightBench上表现有限，主要由于提取多步骤深度洞察的挑战和缺乏医学专业知识。MedInsightAgent能够显著提升通用大型多模态模型在医学数据洞察发现方面的性能。

Conclusion: MedInsightBench填补了医学多模态模型评估的空白，MedInsightAgent框架为解决医学数据分析中的深度洞察发现挑战提供了有效解决方案。

Abstract: In medical data analysis, extracting deep insights from complex, multi-modal datasets is essential for improving patient care, increasing diagnostic accuracy, and optimizing healthcare operations. However, there is currently a lack of high-quality datasets specifically designed to evaluate the ability of large multi-modal models (LMMs) to discover medical insights. In this paper, we introduce MedInsightBench, the first benchmark that comprises 332 carefully curated medical cases, each annotated with thoughtfully designed insights. This benchmark is intended to evaluate the ability of LMMs and agent frameworks to analyze multi-modal medical image data, including posing relevant questions, interpreting complex findings, and synthesizing actionable insights and recommendations. Our analysis indicates that existing LMMs exhibit limited performance on MedInsightBench, which is primarily attributed to their challenges in extracting multi-step, deep insights and the absence of medical expertise. Therefore, we propose MedInsightAgent, an automated agent framework for medical data analysis, composed of three modules: Visual Root Finder, Analytical Insight Agent, and Follow-up Question Composer. Experiments on MedInsightBench highlight pervasive challenges and demonstrate that MedInsightAgent can improve the performance of general LMMs in medical data insight discovery.

</details>


### [56] [Error-Driven Prompt Optimization for Arithmetic Reasoning](https://arxiv.org/abs/2512.13323)
*Árpád Pándy,Róbert Lakatos,András Hajdu*

Main category: cs.AI

TL;DR: 本文提出了一种基于错误驱动的优化框架，用于提升小型语言模型在算术推理任务上的性能，使其能在隐私合规的本地环境中超越大型模型。


<details>
  <summary>Details</summary>
Motivation: 在金融、医疗等受监管行业中，需要能够在本地安全环境中处理表格数据并执行精确算术运算的AI助手。现有小型语言模型在算术任务上存在根本性限制，而大型模型又无法满足隐私合规要求。

Method: 提出了一个错误驱动的优化框架，通过聚类错误预测来迭代优化提示规则，增强代码生成代理在小型语言模型上的算术推理能力。

Result: 在Qwen3 4B模型上的系统评估显示，基础模型在算术任务上表现有限，但经过错误驱动优化后，准确率提升至70.8%，超越了GPT-3.5 Turbo。

Conclusion: 开发可靠、可解释且工业可部署的AI助手不仅可以通过昂贵的微调实现，还可以通过系统化的错误驱动提示优化，使小型模型在隐私合规的方式下超越大型语言模型。

Abstract: Recent advancements in artificial intelligence have sparked interest in industrial agents capable of supporting analysts in regulated sectors, such as finance and healthcare, within tabular data workflows. A key capability for such systems is performing accurate arithmetic operations on structured data while ensuring sensitive information never leaves secure, on-premises environments. Here, we introduce an error-driven optimization framework for arithmetic reasoning that enhances a Code Generation Agent (CGA), specifically applied to on-premises small language models (SLMs). Through a systematic evaluation of a leading SLM (Qwen3 4B), we find that while the base model exhibits fundamental limitations in arithmetic tasks, our proposed error-driven method, which clusters erroneous predictions to refine prompt-rules iteratively, dramatically improves performance, elevating the model's accuracy to 70.8\%. Our results suggest that developing reliable, interpretable, and industrially deployable AI assistants can be achieved not only through costly fine-tuning but also via systematic, error-driven prompt optimization, enabling small models to surpass larger language models (GPT-3.5 Turbo) in a privacy-compliant manner.

</details>


### [57] [Behavior and Representation in Large Language Models for Combinatorial Optimization: From Feature Extraction to Algorithm Selection](https://arxiv.org/abs/2512.13374)
*Francesca Da Ros,Luca Di Gaspero,Kevin Roitero*

Main category: cs.AI

TL;DR: LLMs能学习和编码组合优化问题的结构信息，其隐藏层表示在算法选择任务中与传统特征提取方法效果相当


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究探索LLMs如何生成或解决优化模型，但人们对LLMs实际学习了什么问题结构或算法行为知之甚少。本研究旨在探究LLMs如何内部表示组合优化问题，以及这些表示是否能支持下游决策任务。

Method: 采用双重方法：1）直接查询评估LLMs显式提取实例特征的能力；2）探测分析检查这些信息是否隐式编码在隐藏层中。探测框架进一步扩展到每个实例的算法选择任务，评估LLM衍生的表示是否能预测最佳求解器。实验涵盖四个基准问题和三种实例表示。

Result: LLMs表现出中等能力从问题实例中恢复特征信息，无论是通过直接查询还是探测。值得注意的是，LLM隐藏层表示的预测能力与传统特征提取方法相当，表明LLMs捕获了与优化性能相关的有意义的结构信息。

Conclusion: LLMs能够学习和编码组合优化问题的结构信息，其内部表示在算法选择等下游任务中具有实用价值，为优化自动化提供了新的视角。

Abstract: Recent advances in Large Language Models (LLMs) have opened new perspectives for automation in optimization. While several studies have explored how LLMs can generate or solve optimization models, far less is understood about what these models actually learn regarding problem structure or algorithmic behavior. This study investigates how LLMs internally represent combinatorial optimization problems and whether such representations can support downstream decision tasks. We adopt a twofold methodology combining direct querying, which assesses LLM capacity to explicitly extract instance features, with probing analyses that examine whether such information is implicitly encoded within their hidden layers. The probing framework is further extended to a per-instance algorithm selection task, evaluating whether LLM-derived representations can predict the best-performing solver. Experiments span four benchmark problems and three instance representations. Results show that LLMs exhibit moderate ability to recover feature information from problem instances, either through direct querying or probing. Notably, the predictive power of LLM hidden-layer representations proves comparable to that achieved through traditional feature extraction, suggesting that LLMs capture meaningful structural information relevant to optimization performance.

</details>


### [58] [Differentiable Evolutionary Reinforcement Learning](https://arxiv.org/abs/2512.13399)
*Sitao Cheng,Tianle Li,Xuhan Huang,Xunjian Yin,Difan Zou*

Main category: cs.AI

TL;DR: DERL提出了一种可微分的进化强化学习框架，通过元优化器自动发现最优奖励信号，在复杂推理任务中实现自我改进的智能体对齐。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习中设计有效奖励函数是一项困难且耗时的任务，特别是在复杂推理任务中。现有的自动奖励优化方法通常将奖励函数视为黑盒，无法捕捉奖励结构与任务性能之间的因果关系。

Method: DERL采用双层框架：元优化器通过组合结构化原子基元进化奖励函数（元奖励），指导内层策略训练。关键创新在于元优化是可微分的，将内层验证性能作为信号，通过强化学习更新元优化器，近似任务成功的"元梯度"。

Result: 在ALFWorld、ScienceWorld和GSM8k、MATH等三个不同领域验证，DERL在ALFWorld和ScienceWorld上达到最先进性能，显著优于依赖启发式奖励的方法，特别是在分布外场景中表现优异。

Conclusion: DERL成功捕捉任务的内在结构，实现了无需人工干预的自我改进智能体对齐，为复杂推理任务的自动奖励设计提供了有效解决方案。

Abstract: The design of effective reward functions presents a central and often arduous challenge in reinforcement learning (RL), particularly when developing autonomous agents for complex reasoning tasks. While automated reward optimization approaches exist, they typically rely on derivative-free evolutionary heuristics that treat the reward function as a black box, failing to capture the causal relationship between reward structure and task performance. To bridge this gap, we propose Differentiable Evolutionary Reinforcement Learning (DERL), a bilevel framework that enables the autonomous discovery of optimal reward signals. In DERL, a Meta-Optimizer evolves a reward function (i.e., Meta-Reward) by composing structured atomic primitives, guiding the training of an inner-loop policy. Crucially, unlike previous evolution, DERL is differentiable in its metaoptimization: it treats the inner-loop validation performance as a signal to update the Meta-Optimizer via reinforcement learning. This allows DERL to approximate the "meta-gradient" of task success, progressively learning to generate denser and more actionable feedback. We validate DERL across three distinct domains: robotic agent (ALFWorld), scientific simulation (ScienceWorld), and mathematical reasoning (GSM8k, MATH). Experimental results show that DERL achieves state-of-the-art performance on ALFWorld and ScienceWorld, significantly outperforming methods relying on heuristic rewards, especially in out-of-distribution scenarios. Analysis of the evolutionary trajectory demonstrates that DERL successfully captures the intrinsic structure of tasks, enabling selfimproving agent alignment without human intervention.

</details>


### [59] [Defending the Hierarchical Result Models of Precedential Constraint](https://arxiv.org/abs/2512.13505)
*Henry Prakken,Wijnand van Woerkom*

Main category: cs.AI

TL;DR: 本文回应Bench-Capon对层次案例推理模型的批评，指出其误解了中间因素与维度的区别，并证明van Woerkom的维度化层次结果模型能够避免这些批评。


<details>
  <summary>Details</summary>
Motivation: 近年来层次案例推理模型受到Bench-Capon的批评，认为这些模型在某些情况下会产生错误结果，特别是未能考虑中间因素可能被不同基础因素以不同强度确立的可能性。本文旨在回应这些批评，特别是针对van Woerkom的结果层次模型。

Method: 通过分析Bench-Capon的批评案例，指出其将中间因素误解为维度，然后应用van Woerkom的维度化版本层次结果模型来处理这些例子，证明该模型能够避免Bench-Capon提出的问题。

Result: 研究表明Bench-Capon的批评源于对中间因素和维度的混淆，当正确应用van Woerkom的维度化层次结果模型时，这些批评不再成立，模型能够正确处理中间因素被不同强度确立的情况。

Conclusion: van Woerkom的维度化层次结果模型能够有效应对Bench-Capon的批评，通过区分中间因素和维度，该模型能够更准确地处理先例约束问题，为层次案例推理模型提供了有力的辩护。

Abstract: In recent years, hierarchical case-based-reasoning models of precedential constraint have been proposed. In various papers, Trevor Bench-Capon criticised these models on the grounds that they would give incorrect outcomes in some cases. In particular, the models would not account for the possibility that intermediate factors are established with different strengths by different base-level factors. In this paper we respond to these criticisms for van Woerkom's result-based hierarchical models. We argue that in some examples Bench-Capon seems to interpret intermediate factors as dimensions, and that applying van Woerkom's dimension-based version of the hierarchical result model to these examples avoids Bench-Capon's criticisms.

</details>


### [60] [MedCEG: Reinforcing Verifiable Medical Reasoning with Critical Evidence Graph](https://arxiv.org/abs/2512.13510)
*Linjie Mu,Yannian Gu,Zhongzhen Huang,Yakun Zhu,Shaoting Zhang,Xiaofan Zhang*

Main category: cs.AI

TL;DR: MedCEG框架通过关键证据图监督医学语言模型的推理过程，提升临床推理的可靠性和有效性


<details>
  <summary>Details</summary>
Motivation: 现有医学推理模型虽然性能不错，但推理过程的临床可靠性有限，缺乏对推理准确性和有效性的监督，需要提供透明、可验证的推理路径来支持临床决策

Method: 提出MedCEG框架，通过关键证据图(CEG)显式监督推理过程；构建挑战性临床案例数据集并为每个样本算法构建CEG；引入临床推理过程奖励，评估节点覆盖、结构正确性和链完整性

Result: 实验结果表明MedCEG在性能上超越现有方法，同时产生临床有效的推理链，在可靠医学AI推理方面取得实质性进展

Conclusion: MedCEG通过关键证据图监督医学语言模型的推理过程，显著提升了临床推理的可靠性和有效性，为可靠医学AI推理提供了重要进展

Abstract: Large language models with reasoning capabilities have demonstrated impressive performance across a wide range of domains. In clinical applications, a transparent, step-by-step reasoning process provides physicians with strong evidence to support decision-making. While reinforcement learning has effectively enhanced reasoning performance in medical contexts, the clinical reliability of these reasoning processes remains limited because their accuracy and validity are often overlooked during training. To address this gap, we propose MedCEG, a framework that augments medical language models with clinically valid reasoning pathways by explicitly supervising the reasoning process through a Critical Evidence Graph (CEG). We curate a dataset of challenging clinical cases and algorithmically construct a CEG for each sample to represent a high-quality verifiable reasoning pathway. To guide the reasoning process, we introduce a Clinical Reasoning Procedure Reward, which evaluates Node Coverage, Structural Correctness, and Chain Completeness, thereby providing a holistic assessment of reasoning quality. Experimental results show that MedCEG surpasses existing methods in performance while producing clinically valid reasoning chains, representing a solid advancement in reliable medical AI reasoning. The code and models are available at https://github.com/LinjieMu/MedCEG.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [61] [Estimation of a Dynamic Tobit Model with a Unit Root](https://arxiv.org/abs/2512.12110)
*Anna Bykhovskaya,James A. Duffy*

Main category: econ.EM

TL;DR: 本文研究了局部趋近于单位根(LUR)渐近框架下的动态Tobit模型的稳健估计，证明了高斯最大似然(ML)和截尾最小绝对偏差(CLAD)估计量的一致性，并推导了它们的渐近分布，为模型选择提供了可靠的t检验方法。


<details>
  <summary>Details</summary>
Motivation: 在动态Tobit模型中，当数据存在截尾(censoring)且序列具有高度持续性时，传统的OLS估计在平稳情况下不一致。需要研究在局部趋近于单位根(LUR)渐近框架下，哪些估计方法能够提供可靠的推断。

Method: 采用局部趋近于单位根(LUR)渐近理论框架，分析高斯最大似然(ML)估计和截尾最小绝对偏差(CLAD)估计在动态Tobit模型中的性质。推导这两种估计量的渐近分布，并与OLS估计进行比较。

Result: ML和CLAD估计量在LUR框架下都是一致的，而OLS虽然也一致但其t统计量不是标准正态分布。ML和CLAD的短期参数估计具有高斯渐近分布，产生标准正态的t统计量，可用于可靠的模型选择。

Conclusion: 在动态Tobit模型的LUR框架下，ML和CLAD估计提供了可靠的推断工具，其t统计量可用于序列t检验进行模型选择，这与线性自回归模型的情况类似。在金融和流行病学时间序列中的应用证明了其实用价值。

Abstract: This paper studies robust estimation in the dynamic Tobit model under local-to-unity (LUR) asymptotics. We show that both Gaussian maximum likelihood (ML) and censored least absolute deviations (CLAD) estimators are consistent, extending results from the stationary case where ordinary least squares (OLS) is inconsistent. The asymptotic distributions of MLE and CLAD are derived; for the short-run parameters they are shown to be Gaussian, yielding standard normal t-statistics. In contrast, although OLS remains consistent under LUR, its t-statistics are not standard normal. These results enable reliable model selection via sequential t-tests based on ML and CLAD, paralleling the linear autoregressive case. Applications to financial and epidemiological time series illustrate their practical relevance.

</details>


### [62] [Modeling the Happiness-Sustainability Nexus via Graphical Lasso and Quantile-on-Quantile Regression](https://arxiv.org/abs/2512.12352)
*Mohamed Chaouch,Thanasis Stengos*

Main category: econ.EM

TL;DR: 该研究使用图形套索和分位数对分位数回归方法，分析126个国家的主观幸福感与可持续发展目标指数之间的关系，发现两者关联适度、不对称且依赖情境。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要使用线性回归或相关性分析来探讨幸福感与可持续发展之间的关系，但这些方法掩盖了分布异质性、多重共线性和潜在非线性依赖问题，需要更精细的方法来揭示复杂关系。

Method: 采用双方法框架：1) 图形套索(Graphical Lasso)识别控制治理、收入和预期寿命后的直接条件关联；2) 分位数对分位数回归(QQR)分析联合分布中的异质性效应。

Result: 图形套索显示幸福感与可持续发展间的偏相关系数约为0.21；QQR揭示异质性效应：低幸福感高可持续发展国家呈正相关，高幸福感低可持续发展国家呈负相关，其他情境基本中性。

Conclusion: 幸福感与可持续发展之间的联系是适度、不对称且依赖情境的，政策应超越均值回归分析，关注制度质量、收入和人口因素，两者互动在分布极端处最为显著。

Abstract: This paper investigates the nexus between subjective well-being and sustainability, proxied by the Sustainable Development Goals (SDG) Index, using cross-country data from 126 nations in 2022. While prior research has highlighted a positive association between happiness and sustainable development, existing approaches largely rely on linear regressions or correlation-based measures that mask distributional heterogeneity, multicollinearity, and potential nonlinear dependence. To address these limitations, we employ a two methodological framework combining Graphical Lasso, and Quantile-on-Quantile Regression (QQR). The Graphical Lasso identifies a direct conditional link between happiness and sustainability after controlling for governance, income, and life expectancy, with a partial correlation of about 0.21. On the other hand, QQR reveals heterogeneous effects across the joint distribution: sustainability gains are positively associated with happiness for low-happiness but high-sustainability countries, negatively associated in high-happiness but low-sustainability contexts, and essentially neutral elsewhere. These findings suggest that the happiness-sustainability link is modest, asymmetric, and context-dependent, underscoring the importance of moving beyond mean-based regressions. From a policy perspective, our results highlight that institutional quality, income, and demographic factors remain the dominant drivers of both happiness and sustainability, while the interplay between the two dimensions is most pronounced in distributional extremes.

</details>


### [63] [Explainable Prediction of Economic Time Series Using IMFs and Neural Networks](https://arxiv.org/abs/2512.12499)
*Pablo Hidalgo,Julio E. Sandubete,Agustín García-García*

Main category: econ.EM

TL;DR: 研究使用DeepSHAP分析经验模态分解(EMD)得到的IMF对神经网络预测经济时间序列的贡献，发现低频IMF（长期趋势）最重要，高频IMF贡献小甚至引入噪声，且LSTM比MLP更均匀地分配特征重要性。


<details>
  <summary>Details</summary>
Motivation: 探索经验模态分解(EMD)得到的本征模态函数(IMF)在经济时间序列预测中的实际贡献，提高神经网络模型的可解释性，理解不同频率成分对预测性能的影响。

Method: 使用经验模态分解(EMD)将经济时间序列分解为IMF，然后分别用MLP和LSTM神经网络进行预测，应用DeepSHAP方法评估每个IMF的边际贡献，通过移除特定IMF来验证其影响。

Result: 低频IMF（代表长期趋势）对预测贡献最大，高频IMF贡献较小且可能引入噪声（移除后指标改善）。LSTM比MLP更均匀地分配IMF重要性，表明模型架构影响特征相关性分布。

Conclusion: IMF分解能有效提升经济时间序列预测的可解释性，低频趋势成分最关键，高频噪声成分可考虑去除。模型架构（MLP vs LSTM）显著影响特征重要性分布，LSTM能更好地利用多尺度信息。

Abstract: This study investigates the contribution of Intrinsic Mode Functions (IMFs) derived from economic time series to the predictive performance of neural network models, specifically Multilayer Perceptrons (MLP) and Long Short-Term Memory (LSTM) networks. To enhance interpretability, DeepSHAP is applied, which estimates the marginal contribution of each IMF while keeping the rest of the series intact. Results show that the last IMFs, representing long-term trends, are generally the most influential according to DeepSHAP, whereas high-frequency IMFs contribute less and may even introduce noise, as evidenced by improved metrics upon their removal. Differences between MLP and LSTM highlight the effect of model architecture on feature relevance distribution, with LSTM allocating importance more evenly across IMFs.

</details>


### [64] [Continuous Treatment Effects with Spatial and Network Spillovers](https://arxiv.org/abs/2512.12653)
*Tatsuru Kikuchi*

Main category: econ.EM

TL;DR: 该论文提出了一个连续函数框架来分析地理空间和经济网络中的政策效应传播，通过经济理论基础推导出主方程，证明空间-网络交互系数等于地理坐标与市场坐标的互信息，并开发了能够处理溢出效应的估计方法。


<details>
  <summary>Details</summary>
Motivation: 传统计量方法（如双向固定效应、双重差分、广义倾向得分）在处理空间和经济网络溢出效应时存在严重偏差和覆盖率不足的问题，需要建立一个基于经济理论基础而非特设规范的框架来准确估计政策效应的传播。

Method: 基于异质主体加总、市场均衡和成本最小化三个经济基础推导出传播主方程，利用Feynman-Kac表示将效应分解为沿经济联系随机路径的继承和累积分量，开发了能够检验无溢出效应假设的估计框架。

Result: 蒙特卡洛模拟显示传统方法在存在溢出效应时有25-38%的偏差和严重覆盖率不足，而新方法无论是否存在溢出都能保持正确推断。应用于美国最低工资政策时，拒绝无溢出原假设，发现州边界总效应是直接效应的四倍，传统方法仅捕捉到四分之一政策影响。

Conclusion: 该框架为分析空间和网络溢出效应提供了理论基础和实用工具，基于熵的脆弱性诊断比标准中心性度量在预测劳动力市场中断方面表现更好56-76%，能提前六个月识别所有高风险州-行业组合。

Abstract: This paper develops a continuous functional framework for treatment effects that propagate through geographic space and economic networks. We derive a master equation governing propagation from three economic foundations -- heterogeneous agent aggregation, market equilibrium, and cost minimization -- establishing that the framework rests on fundamental principles rather than ad hoc specifications. A key result shows that the spatial-network interaction coefficient equals the mutual information between geographic and market coordinates. The Feynman-Kac representation decomposes effects into inherited and accumulated components along stochastic paths representing economic linkages. The framework nests the no-spillover case as a testable restriction. Monte Carlo simulations demonstrate that conventional estimators -- two-way fixed effects, difference-in-differences, and generalized propensity score -- exhibit 25-38% bias and severe undercoverage when spillovers exist, while our estimator maintains correct inference regardless of whether spillovers are present. Applying the framework to U.S. minimum wage policy, we reject the no-spillover null and find total effects at state borders four times larger than direct effects -- conventional methods capture only one-quarter of policy impact. Structural estimates reveal spatial diffusion consistent with commuting-distance labor mobility, network diffusion consistent with quarterly supply chain adjustment, and significant spatial-network interaction reflecting geographic clustering of industries. Entropy-based fragility diagnostics outperform standard centrality measures by 56-76% in predicting labor market disruptions, identifying all high-risk state-industry pairs during 2020-2021 with six-month advance warning.

</details>


### [65] [Distributionally Robust Treatment Effect](https://arxiv.org/abs/2512.12781)
*Ruonan Xu,Xiye Yang*

Main category: econ.EM

TL;DR: 提出一种仅使用回顾性数据预测治疗/政策在其他地点或时期效果的估计器，无需目标群体数据，通过最小化Wasserstein球内最坏情况均方误差，考虑治疗效果同质/异质情况，提供部分识别边界估计。


<details>
  <summary>Details</summary>
Motivation: 在政策评估中，经常需要将特定治疗或政策的效果预测到新的地点或时期，但通常缺乏目标群体的数据。现有方法需要目标群体信息，限制了实际应用。本文旨在开发一种仅使用源数据就能预测治疗效果的方法。

Method: 1) 在Wasserstein球内最小化最坏情况均方误差；2) 由于潜在结果的联合分布不可识别，使用边际分布的最佳和最差copula进行乐观和悲观优化；3) 考虑治疗效果同质和异质两种情况；4) 推导边界估计的一致性和渐近分布；5) 提供两步推断程序；6) 讨论Wasserstein球半径的选择。

Result: 获得了最小化最坏情况均方误差的上下界估计器，这些估计器在不同治疗效果假设下有所不同。推导了边界估计的一致性和渐近分布理论性质，并提供了可行的推断程序。

Conclusion: 提出了一种无需目标群体数据就能预测治疗效果的新方法，通过部分识别框架和分布鲁棒优化，为政策转移提供了实用的统计工具。该方法特别适用于将政策效果预测到新环境的情况。

Abstract: Using only retrospective data, we propose an estimator for predicting the treatment effect for the same treatment/policy to be implemented in another location or time period, which requires no input from the target population. More specifically, we minimize the worst-case mean square error for the prediction of treatment effect within a class of distributions inside the Wasserstein ball centered on the source distribution. Since the joint distribution of potential outcomes is not identified, we pick the best and worst copulas of the marginal distributions of two potential outcomes as our optimistic and pessimistic optimization objects for partial identification. As a result, we can attain the upper and lower bounds of the minimax optimizer. The minimax solution differs depending on whether treatment effects are homogeneous or heterogeneous. We derive the consistency and asymptotic distribution of the bound estimators, provide a two-step inference procedure, and discuss the choice of the Wasserstein ball radius.

</details>


### [66] [Raking for estimation and inference in panel models with nonignorable attrition and refreshment](https://arxiv.org/abs/2512.13270)
*Grigory Franguridi,Jinyong Hahn,Pierre Hoonhout,Arie Kapteyn,Geert Ridder*

Main category: econ.EM

TL;DR: 提出使用迭代比例拟合（raking）算法解决面板数据非可忽略流失下的密度估计问题，实现快速收敛的估计方法


<details>
  <summary>Details</summary>
Motivation: 面板数据存在非可忽略流失时，辅助（刷新）抽样可在弱假设下恢复完全识别，但现有识别策略因需要解决目标密度的函数最小化问题而应用受限

Method: 使用迭代比例拟合（raking）算法解决密度估计问题，将得到的密度估计量作为参数矩条件的输入，建立一致性、收敛速率和渐近方差估计的递归程序

Result: raking密度估计量在连续和中等高维数据中快速收敛，模拟显示估计器性能良好，并通过Understanding America Study面板数据进行实证说明

Conclusion: 迭代比例拟合算法为面板数据非可忽略流失问题提供了实用、高效的密度估计解决方案，克服了现有方法计算复杂的限制

Abstract: In panel data subject to nonignorable attrition, auxiliary (refreshment) sampling may restore full identification under weak assumptions on the attrition process. Despite their generality, these identification strategies have seen limited empirical use, largely because the implied estimation procedure requires solving a functional minimization problem for the target density. We show that this problem can be solved using the iterative proportional fitting (raking) algorithm, which converges rapidly even with continuous and moderately high-dimensional data. This resulting density estimator is then used as input into a parametric moment condition. We establish consistency and convergence rates for both the raking-based density estimator and the resulting moment estimator when the distributions of the observed data are parametric. We also derive a simple recursive procedure for estimating the asymptotic variance. Finally, we demonstrate the satisfactory performance of our estimator in simulations and provide an empirical illustration using data from the Understanding America Study panel.

</details>


### [67] [Policy-Aligned Estimation of Conditional Average Treatment Effects](https://arxiv.org/abs/2512.13400)
*Artem Timoshenko,Caio Waisman*

Main category: econ.EM

TL;DR: 提出一种将CATE估计与企业利润目标对齐的方法，通过修改目标函数在估计处理效应的同时优化营销策略


<details>
  <summary>Details</summary>
Motivation: 企业在制定个性化营销策略时需要准确区分正负处理效应的客户，但传统CATE估计方法关注预测精度而非实际利润优化，导致次优决策

Method: 修改标准利润最大化问题的目标函数，使CATE估计与企业的利润目标对齐，特别关注决策边界附近的准确性，同时估计CATE并生成近似最优的定向策略

Result: 建立了方法的理论性质，通过合成数据验证了其性能和权衡，表明该方法能有效提升营销决策的利润效果

Conclusion: 将CATE估计重新定义为利润优化问题而非预测精度问题，为企业营销决策提供了新的视角和实用方法

Abstract: Firms often develop targeting policies to personalize marketing actions and improve incremental profits. Effective targeting depends on accurately separating customers with positive versus negative treatment effects. We propose an approach to estimate the conditional average treatment effects (CATEs) of marketing actions that aligns their estimation with the firm's profit objective. The method recognizes that, for many customers, treatment effects are so extreme that additional accuracy is unlikely to change the recommended actions. However, accuracy matters near the decision boundary, as small errors can alter targeting decisions. By modifying the firm's objective function in the standard profit maximization problem, our method yields a near-optimal targeting policy while simultaneously estimating CATEs. This introduces a new perspective on CATE estimation, reframing it as a problem of profit optimization rather than prediction accuracy. We establish the theoretical properties of the proposed method and demonstrate its performance and trade-offs using synthetic data.

</details>


### [68] [From Many Models, One: Macroeconomic Forecasting with Reservoir Ensembles](https://arxiv.org/abs/2512.13642)
*Giovanni Ballarin,Lyudmila Grigoryeva,Yui Ching Li*

Main category: econ.EM

TL;DR: 该论文研究了多频回声状态网络（MFESN）的集成方法，通过理论和实证分析证明了集成模型相比单个模型在宏观经济时间序列预测中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 模型集成是提升预测性能的有效方法，但现有研究对回声状态网络（特别是多频回声状态网络）的集成方法及其理论保证研究不足，特别是在处理依赖数据时的在线学习理论。

Method: 提出了集成回声状态网络方法，研究了Hedge和Follow-the-Leader两种集成策略，并将它们的在线学习理论保证扩展到依赖数据的情况。使用多频回声状态网络作为基础模型。

Result: 在应用中，提出的集成回声状态网络相比单个MFESN模型显著提高了预测性能，验证了集成方法的有效性。

Conclusion: 集成多频回声状态网络是提升宏观经济时间序列预测性能的有效方法，扩展的在线学习理论为处理依赖数据提供了理论保证。

Abstract: Model combination is a powerful approach to achieve superior performance with a set of models than by just selecting any single one. We study both theoretically and empirically the effectiveness of ensembles of Multi-Frequency Echo State Networks (MFESNs), which have been shown to achieve state-of-the-art macroeconomic time series forecasting results (Ballarin et al., 2024a). Hedge and Follow-the-Leader schemes are discussed, and their online learning guarantees are extended to the case of dependent data. In applications, our proposed Ensemble Echo State Networks show significantly improved predictive performance compared to individual MFESN models.

</details>


### [69] [Linear Regression in a Nonlinear World](https://arxiv.org/abs/2512.13645)
*Nadav Kunievsky*

Main category: econ.EM

TL;DR: 多元线性回归系数在非线性数据生成过程中的解释：当变量间关系线性时，系数代表条件期望函数导数的加权平均；当关系非线性时，系数存在可解释的偏差。


<details>
  <summary>Details</summary>
Motivation: 多元线性回归系数的解释依赖于条件期望函数线性的假设，但实际数据生成过程常是非线性的。本文旨在探讨在非线性情况下如何解释回归系数。

Method: 通过理论分析，研究当变量间关系线性时回归系数的性质，以及当关系非线性时产生的偏差。将这种偏差与标准线性模型中的测量误差和遗漏变量偏差进行类比。

Result: 如果变量间关系是线性的，感兴趣变量的系数代表结果变量条件期望函数对该变量导数的加权平均。如果关系非线性，回归系数相对于这个加权平均存在偏差，但这种偏差是可解释的。

Conclusion: 即使在非线性数据生成过程中，多元线性回归系数仍然具有可解释的意义。当变量间关系线性时，系数有明确的加权平均解释；当关系非线性时，产生的偏差类似于传统线性模型中的测量误差和遗漏变量偏差，因此仍然是可理解和可解释的。

Abstract: The interpretation of coefficients from multivariate linear regression relies on the assumption that the conditional expectation function is linear in the variables. However, in many cases the underlying data generating process is nonlinear. This paper examines how to interpret regression coefficients under nonlinearity. We show that if the relationships between the variable of interest and other covariates are linear, then the coefficient on the variable of interest represents a weighted average of the derivatives of the outcome conditional expectation function with respect to the variable of interest. If these relationships are nonlinear, the regression coefficient becomes biased relative to this weighted average. We show that this bias is interpretable, analogous to the biases from measurement error and omitted variable bias under the standard linear model.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [70] [Estimation of Heterogeneous Causal Mediation Effects in a Hypertension Treatment Trial](https://arxiv.org/abs/2512.12043)
*Yi Zhao,Chengyun Li,Wanzhu Tu*

Main category: stat.AP

TL;DR: 该研究开发了一个新的因果中介分析框架，用于识别高血压治疗中白蛋白尿减少的中介效应异质性，发现SPRINT试验中部分患者能从靶向白蛋白尿的治疗中获益。


<details>
  <summary>Details</summary>
Motivation: SPRINT试验显示将收缩压目标从140mmHg降至120mmHg能显著降低心血管死亡率和发病率，但其机制尚不完全清楚。早期白蛋白尿减少被提出作为潜在中介通路，但标准因果中介分析结果不一致，可能由于个体间中介效应存在异质性。

Method: 引入包含协变量-治疗和中介-治疗交互作用的线性结构方程模型新框架，参数化异质性自然直接和间接效应为患者特征函数。提出改进的协变量方法放松层次约束，采用广义lasso正则化确保高维设置的简洁性，并研究渐近性质。

Result: 模拟研究显示良好的估计和推断性能。SPRINT数据分析揭示了显著的中介效应异质性，识别出能从靶向白蛋白尿治疗中获益的患者亚组。

Conclusion: 该研究提供了一个识别异质性中介效应的新框架，有助于个性化医疗决策，特别是识别哪些高血压患者能从靶向白蛋白尿的治疗策略中获益。

Abstract: Hypertension is a highly prevalent condition and a major risk factor for cardiovascular disease. The landmark Systolic Blood Pressure Intervention Trial (SPRINT) showed that lowering systolic blood pressure (BP) goals from 140 mmHg to 120 mmHg leads to significantly reduced BP, cardiovascular mortality, and morbidity. However, the underlying mechanisms are not yet fully elucidated. In patients with impaired renal function, early reduction of albuminuria has been proposed as a potential mediation pathway. Evidence from the standard causal mediation analysis (CMA), however, yields inconsistent results, possibly due to heterogeneous mediation effects across individuals. To disseminate the heterogeneity, a new framework that incorporates covariate-treatment and mediator-treatment interactions within a linear structural equation modeling system is introduced. Causal assumptions are discussed and heterogeneous natural direct and indirect effects are parameterized as functions of patient characteristics. A modified covariate approach is proposed to relax the hierarchical constraints and the generalized lasso regularization is employed to ensure parsimony in high-dimensional settings. Asymptotic properties are studied. Simulation studies demonstrate good estimation and inference performance. Analysis of the SPRINT data reveals substantial heterogeneity in mediation effects, identifying a subset of patients who stand to gain from therapies targeting albuminuria.

</details>


### [71] [A Real Data-Driven, Robust Survival Analysis on Patients who Underwent Deep Brain Stimulation for Parkinson's Disease by Utilizing Parametric, Non-Parametric, and Semi-Parametric Approaches](https://arxiv.org/abs/2512.12579)
*Malinda Iluppangama,Dilmi Abeywardana,Chris Tsokos*

Main category: stat.AP

TL;DR: 该研究使用多种生存分析方法评估帕金森病深部脑刺激患者的长期生存结果，发现女性患者生存率高于男性，且两性生存时间分布特征不同。


<details>
  <summary>Details</summary>
Motivation: 帕金森病是一种影响全球数百万人的神经退行性疾病，深部脑刺激在改善患者运动症状方面显示出良好效果。研究旨在通过统计方法分析DBS患者的长期生存结果，为临床治疗提供依据。

Method: 采用非参数、半参数和稳健参数生存分析方法，包括COX比例风险模型，分析DBS患者的生存数据，比较性别差异和影响因素。

Result: 女性患者生存率高于男性；女性生存时间符合三参数对数正态分布，男性符合三参数威布尔分布；右侧初始植入对女性是不良预后因素，对男性是良好预后因素；修订次数与初始植入尺寸的交互作用会增加男性不良预后风险。

Conclusion: DBS患者的长期生存存在显著性别差异，女性预后更好。研究结果为个性化治疗提供了统计依据，有助于优化帕金森病患者的DBS治疗方案。

Abstract: Parkinson's Disease (PD) is a devastating neurodegenerative disorder that affects millions of people around the globe. Many researchers are continuously working to understand PD and develop treatments to improve the condition of PD patients, which affects their day-to-day lives. Since the last decades, the treatment, Deep Brain Stimulation (DBS) has given promising results for motor symptoms by improving the quality of daily living of PD patients. In the methodology of the present study, we have utilized sophisticated statistical approaches such as Nonparametric, Semi-parametric, and robust Parametric survival analysis to extract useful and important information about the long-term survival outcomes of the patients who underwent DBS for PD. Finally, we were able to conclude that the probabilistic behavior of the survival time of female patients is statistically different from that of male patients. Furthermore, we have identified that the probabilistic behavior of the survival times of Female patients is characterized by the 3-parameter Lognormal distribution, while that of Male patients is characterized by the 3-parameter Weibull distribution. More importantly, we have found that the Female patients have higher survival compared to the Male patients after conducting a robust parametric survival analysis. Using the semi-parametric COX-PH, we found that the initial implant of the right side leads to a high frequency of events occurring for the female patients with a bad prognostic factor, while for the male patients, a low events occurs with a good prognostic factor. Furthermore, we have found an interaction term between the number of revisions and the initial size of the implant, which increases the frequency of events occurring for the Male patients with a bad prognostic factor.

</details>


### [72] [Beyond Missing Data: Questionnaire Uncertainty Responses as Early Digital Biomarkers of Cognitive Decline and Neurodegenerative Diseases](https://arxiv.org/abs/2512.13346)
*Yukun Lu,Bingjie Li,Zhigang Yao*

Main category: stat.AP

TL;DR: "不知道/记不清"回答频率可作为早期认知脆弱性和神经退行性疾病风险的新型数字行为生物标志物


<details>
  <summary>Details</summary>
Motivation: 识别神经退行性疾病的临床前生物标志物是衰老研究的主要挑战，需要寻找可扩展、低成本、非侵入性的早期风险识别工具

Method: 使用502,234名UK Biobank参与者的数据，基于"不知道/记不清"回答频率(0-1, 2-4, 5-7, >7)对个体分层，分析其与阿尔茨海默病和血管性痴呆风险的剂量依赖关系，并检测相关生物标志物和代谢组学变化

Result: DK回答频率与阿尔茨海默病(HR=1.64)和血管性痴呆(HR=1.93)风险呈剂量依赖关系增加；高DK回答者表现出更高BMI、更低体力活动、更高吸烟率、更多慢性疾病，以及Abeta40、Abeta42、NFL、pTau-181水平升高和脂质代谢异常

Conclusion: DK回答模式可作为多维神经生物学改变的临床意义信号，为人群水平的早期风险识别和预防提供可扩展、低成本、非侵入性工具

Abstract: Identifying preclinical biomarkers of neurodegenerative diseases remains a major challenge in aging research. In this study, we demonstrate that frequent "Don't know/can't remember" (DK) responses, often treated as missing data in touchscreen questionnaires, serve as a novel digital behavioral biomarker of early cognitive vulnerability and neurodegenerative disease risk. Using data from 502,234 UK Biobank participants, we stratified individuals based on DK response frequency (0-1, 2-4, 5-7, >7) and observed a robust, dose-dependent association with an increased risk of Alzheimer's disease (HR = 1.64, 95% CI: 1.26-2.14) and vascular dementia (HR = 1.93, 95% CI: 1.37-2.72), independent of established risk factors. As DK response frequency increased, participants exhibited higher BMI, reduced physical activity, higher smoking rates, and a higher prevalence of chronic diseases, particularly hypertension, diabetes, and depression. Further analysis revealed a dose-dependent relationship between DK response frequency and the risk of Alzheimer's disease and vascular dementia, with high DK responders showing early neurodegenerative changes, marked by elevated levels of Abeta40, Abeta42, NFL, and pTau-181. Metabolomic analysis also revealed lipid metabolism abnormalities, which may mediate this relationship. Together, these findings reframe DK response patterns as clinically meaningful signals of multidimensional neurobiological alterations, offering a scalable, low-cost, non-invasive tool for early risk identification and prevention at the population level.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [73] [AI Integration In ERP Evaluation Across Trends and Architectures](https://arxiv.org/abs/2512.11805)
*Monu Sharma*

Main category: cs.CY

TL;DR: 本文系统回顾了AI集成ERP系统的评估方法，指出传统评估框架在算法透明度、适应性和伦理方面的不足，提出了一个将AI能力与ERP性能评估指标对齐的理论模型。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术融入ERP系统，传统基于成本、功能和用户满意度的评估框架已无法充分评估AI驱动的ERP解决方案，特别是在算法透明度、适应性和伦理考量方面存在明显不足。

Method: 基于学术和行业资料的系统性文献回顾，分析AI集成ERP的最新趋势、计算架构模型和分析方法，特别关注云平台上的应用，并识别关键性能指标和研究空白。

Result: 识别了当前缺乏标准评估框架和AI感知系统的问题，提出了一个理论模型，将预测智能、自适应自动化等AI能力与ERP性能评估指标相结合。

Conclusion: AI创新正在改变ERP评估方式，需要开发严谨的数据驱动评估方法，以适应快速发展的智能自优化企业生态系统，为研究者和从业者提供指导方向。

Abstract: The incorporation of Artificial Intelligence (AI) into Enterprise Resource Planning (ERP) is a dramatic transition from static, on-premises systems to systems that can adapt and operate in cloud-native architectures. Cloud ERP solutions like Workday illustrate this evolution by incorporating machine learning, deep learning, and natural language processing into a centralized data-driven ecosystem. As the complexity of AI-driven ERP solutions expands, traditional evaluation frameworks that look at cost, function, and user satisfaction suffer from a lack of consideration for algorithmic transparency, adaptability, or ethics. This review will systematically investigate the latest trends, models of computing architecture, and analytical methods applied in assessing the performance of AI-integrated ERP services, specifically on cloud-based platforms. Based on academic and industry sources, the paper distills current research in line with architectural integration, analytical methodologies, and organizational impact. It identifies critical performance metrics and emphasizes the absence of any standard assessment frameworks or AI-aware systems capable of evaluating automation efficiency, security concerns as well as flexible learning modes. We put forward a theoretical model that brings AI-enabled capabilities -- such as predictive intelligence or adaptive automation -- into alignment with metrics in performance assessment for ERPs. By combining current literature and identifying major gaps in research, this paper attempts to present a complete picture of how innovations in AI are changing ERP evaluation. These research and methodological findings are intended to steer researchers and practitioners towards developing rigorous, data-driven assessment approaches, aligning with the fast-developing world of intelligent self-optimizing enterprise ecosystems

</details>


### [74] [How Immersiveness Shapes the Link Between Anthropocentric Values and Resource Exploitation in Virtual Worlds](https://arxiv.org/abs/2512.11812)
*Quan-Hoang Vuong,Thi Mai Anh Tran,Ni Putu Wulan Purnama Sari,Fatemeh Kianfar,Viet-Phuong La,Minh-Hoang Nguyen*

Main category: cs.CY

TL;DR: 研究探讨了人类中心主义价值观与虚拟生态系统中资源开发行为（钓鱼、捕虫、砍树）的关系，以及沉浸感如何调节这些关系。使用贝叶斯思维海绵框架分析640名《动物森友会》玩家的数据，发现人类中心主义与钓鱼和砍树行为正相关，而沉浸感会减弱砍树与人类中心主义的关系。


<details>
  <summary>Details</summary>
Motivation: 人类世生态危机不仅源于技术和经济系统，还源于根深蒂固的人类中心主义世界观。随着数字环境日益中介人与自然的关系，电子游戏为研究环境行为的心理机制提供了新背景。本研究旨在探索人类中心主义价值观如何与虚拟生态系统中的资源开发行为相关联，以及沉浸感如何调节这些关系。

Method: 采用贝叶斯思维海绵框架（BMF）分析来自29个国家640名《动物森友会：新视野》玩家的数据。研究考察了人类中心主义价值观与三种虚拟资源开发行为（钓鱼、捕虫、砍树）的关系，并测试了游戏沉浸感对这些关系的调节作用。

Result: 钓鱼和砍树频率与人类中心主义呈正相关；沉浸感减弱了砍树与人类中心主义之间的关联；捕虫频率没有直接效应，但随着沉浸感增加，与人类中心主义的负相关关系增强。

Conclusion: 研究将环境心理学扩展到虚拟生态领域，展示了数字互动如何反映和重塑环境价值观。沉浸式游戏体验有潜力培养自然商数（NQ）并通过反思性、保护导向的参与促进生态盈余文化。

Abstract: The Anthropocene is characterized by escalating ecological crises rooted not only in technological and economic systems but also in deeply ingrained anthropocentric worldviews that shape human-nature relationships. As digital environments increasingly mediate these interactions, video games provide novel contexts for examining the psychological mechanisms underlying environmental behaviors. This study investigates how anthropocentric values are associated with resource-exploiting behaviors in virtual ecosystems--specifically, fishing, bug catching, and tree cutting--and how immersiveness moderates these relationships. Employing the Bayesian Mindsponge Framework (BMF) to analyze data from 640 Animal Crossi,g: New Horizons (ACNH) players across 29 countries, the study reveals complex links between anthropocentric worldviews and in-game behaviors. Fishing and tree-cutting frequencies are positively associated with anthropocentrism, whereas immersiveness weakens the association between tree cutting and anthropocentrism. Bug-catching frequency shows no direct effect but exhibits a growing negative association with anthropocentrism as immersiveness increases. These findings extend environmental psychology into virtual ecologies, illustrating how digital interactions both reflect and reshape environmental values. They highlight the potential of immersive gameplay to cultivate the Nature Quotient (NQ) and foster an eco-surplus culture through reflective, conservation-oriented engagement.

</details>


### [75] [Totalitarian Technics: The Hidden Cost of AI Scribes in Healthcare](https://arxiv.org/abs/2512.11814)
*Hugh Brosnahan*

Main category: cs.CY

TL;DR: AI抄写员不仅提升效率，更重塑医疗注意力模式，体现左脑计算思维主导，可能窄化关怀领域、侵蚀临床专业


<details>
  <summary>Details</summary>
Motivation: 探讨AI抄写员在医疗中的真正意义，超越效率提升的表面价值，分析其如何重塑医疗注意力的本质模式

Method: 概念分析，结合Iain McGilchrist的半球理论和Lewis Mumford的技术哲学，从哲学角度分析AI抄写员如何体现特定注意力模式

Result: AI抄写员体现了左脑半球主导的计算思维模式，优先考虑可测量和程序化内容，而非直觉和关系性内容

Conclusion: AI抄写员将特定注意力模式嵌入医疗实践，可能窄化关怀领域、侵蚀临床专业，使医生沦为机械化系统中的操作员

Abstract: Artificial intelligence (AI) scribes, systems that record and summarise patient-clinician interactions, are promoted as solutions to administrative overload. This paper argues that their significance lies not in efficiency gains but in how they reshape medical attention itself. Offering a conceptual analysis, it situates AI scribes within a broader philosophical lineage concerned with the externalisation of human thought and skill. Drawing on Iain McGilchrist's hemisphere theory and Lewis Mumford's philosophy of technics, the paper examines how technology embodies and amplifies a particular mode of attention. AI scribes, it contends, exemplify the dominance of a left-hemispheric, calculative mindset that privileges the measurable and procedural over the intuitive and relational. As this mode of attention becomes further embedded in medical practice, it risks narrowing the field of care, eroding clinical expertise, and reducing physicians to operators within an increasingly mechanised system.

</details>


### [76] [Video Deepfake Abuse: How Company Choices Predictably Shape Misuse Patterns](https://arxiv.org/abs/2512.11815)
*Max Kamachee,Stephen Casper,Michelle L. Ding,Rui-Jie Yew,Anka Reuel,Stella Biderman,Dylan Hadfield-Menell*

Main category: cs.CY

TL;DR: 2025年视频生成模型重现2022年图像生成模型的问题：少数开源模型成为深度伪造色情内容的主要工具，开发者与平台需承担风险管理责任


<details>
  <summary>Details</summary>
Motivation: 2022年AI图像生成器突破关键阈值，虽然带来创意应用，但也导致AI生成非自愿亲密图像（AIG-NCII）和儿童性虐待材料（AIG-CSAM）的低成本制作。2025年视频生成模型出现同样模式，需要分析其危害机制并提出解决方案。

Method: 分析少数开源权重视频生成模型如何成为真实感AIG-NCII视频生成的主要工具，并综述模型安全防护文献，评估现有防护措施的有效性。

Result: 研究发现：1）开发者公开释放未经适当数据筛选和/或训练后防护的强大视频生成模型权重，可预见地导致可缓解的下游危害；2）平台不主动监管个体滥用或专门用于AIG-NCII的模型，可预见地放大这种危害。

Conclusion: 虽然无法完全防御开源AI模型产生的AIG-NCII和AIG-CSAM，但模型开发者和分发平台基于新兴防护技术的风险管理将显著影响未来使用生成式AI视频工具创建这些有害内容的难易程度。

Abstract: In 2022, AI image generators crossed a key threshold, enabling much more efficient and dynamic production of photorealistic deepfake images than before. This enabled opportunities for creative and positive uses of these models. However, it also enabled unprecedented opportunities for the low-effort creation of AI-generated non-consensual intimate imagery (AIG-NCII), including AI-generated child sexual abuse material (AIG-CSAM). Empirically, these harms were principally enabled by a small number of models that were trained on web data with pornographic content, released with open weights, and insufficiently safeguarded. In this paper, we observe ways in which the same patterns are emerging with video generation models in 2025. Specifically, we analyze how a small number of open-weight AI video generation models have become the dominant tools for videorealistic AIG-NCII video generation. We then analyze the literature on model safeguards and conclude that (1) developers who openly release the weights of capable video generation models without appropriate data curation and/or post-training safeguards foreseeably contribute to mitigatable downstream harm, and (2) model distribution platforms that do not proactively moderate individual misuse or models designed for AIG-NCII foreseeably amplify this harm. While there are no perfect defenses against AIG-NCII and AIG-CSAM from open-weight AI models, we argue that risk management by model developers and distributors, informed by emerging safeguard techniques, will substantially affect the future ease of creating AIG-NCII and AIG-CSAM with generative AI video tools.

</details>


### [77] [A Reproducible Workflow for Scraping, Structuring, and Segmenting Legacy Archaeological Artifact Images](https://arxiv.org/abs/2512.11817)
*Juan Palomeque-Gonzalez*

Main category: cs.CY

TL;DR: 开发了一个可重复的工作流程，将考古图像收藏转换为结构化、可用于分割的数据集，包括网页爬取和图像处理两个开源工具。


<details>
  <summary>Details</summary>
Motivation: 解决考古数据服务（ADS）收藏的旧石器时代手斧和双面器图像数据集缺乏批量下载和自动处理机制的问题，促进数字考古的可重复研究。

Method: 开发了两个开源工具：1）网页爬取脚本，获取记录页面、提取元数据、下载图像；2）图像处理流程，重命名文件、生成二进制掩码和边界框，将信息存储在COCO兼容的JSON文件中。

Result: 创建了一个轻量级、可重复使用的方法，将基于网络的考古图像收藏转换为机器学习友好格式，便于下游分析，同时尊重使用条款和伦理准则。

Conclusion: 该工作流程为将考古图像收藏转换为结构化数据集提供了实用解决方案，促进了数字考古领域的可重复研究实践。

Abstract: This technical note presents a reproducible workflow for converting a legacy archaeological image collection into a structured and segmentation ready dataset. The case study focuses on the Lower Palaeolithic hand axe and biface collection curated by the Archaeology Data Service (ADS), a dataset that provides thousands of standardised photographs but no mechanism for bulk download or automated processing. To address this, two open source tools were developed: a web scraping script that retrieves all record pages, extracts associated metadata, and downloads the available images while respecting ADS Terms of Use and ethical scraping guidelines; and an image processing pipeline that renames files using UUIDs, generates binary masks and bounding boxes through classical computer vision, and stores all derived information in a COCO compatible Json file enriched with archaeological metadata. The original images are not redistributed, and only derived products such as masks, outlines, and annotations are shared. Together, these components provide a lightweight and reusable approach for transforming web based archaeological image collections into machine learning friendly formats, facilitating downstream analysis and contributing to more reproducible research practices in digital archaeology.

</details>


### [78] [The Ontological Dissonance Hypothesis: AI-Triggered Delusional Ideation as Folie a Deux Technologique](https://arxiv.org/abs/2512.11818)
*Izabela Lipinska,Hugh Brosnahan*

Main category: cs.CY

TL;DR: LLMs可能通过类似"二联性精神病"的互动关系导致用户精神病性卷入，其语言连贯性与主体缺失的结构性张力，在情感需求下促使用户通过想象投射来填补空白，当前优化参与度的设计加剧了这种风险。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨当代大型语言模型如何通过类似"二联性精神病"的互动关系，导致用户出现精神病性卷入。作者观察到LLMs具有高语言连贯性但缺乏真实主体的特性，这种结构性张力在特定情境下可能引发心理风险。

Method: 结合Bateson的双重束缚理论、共享性精神病障碍的临床文献以及McGilchrist的大脑半球理论，分析LLMs互动中的结构性张力；通过新兴临床报告和现象学分析，探讨这种互动动态如何展开。

Result: LLMs的语言连贯性与主体缺失之间的结构性张力，在用户情感需求或不稳定状态下，会促使其通过想象投射来填补空白，将内在性、意图或存在感归因于本不具备这些特性的系统。当前优化用户参与度的设计选择加剧了这种风险。

Conclusion: 提出"本体论诚实性"作为必要的设计原则，以减轻技术中介的二联性精神病风险。强调AI系统设计需要明确其非人类本质，避免误导用户产生不适当的心理投射。

Abstract: This paper argues that contemporary large language models (LLMs) can contribute to psychotic involvement by creating interactions that resemble the relational dynamics of folie a deux. Drawing on Bateson's double bind theory, clinical literature on shared psychotic disorder, and McGilchrist's hemisphere theory, we show how the combination of high linguistic coherence and the absence of an underlying subject produces a structural tension for the user: language suggests an interlocutor, while intuition registers a void. In contexts of emotional need or instability, this tension can lead users to resolve the conflict through imaginative projection, attributing interiority, intention, or presence to a system that possesses none. The paper situates these dynamics within emerging clinical reports, develops a phenomenological account of how they unfold, and argues that current engagement-optimised design choices exacerbate the risk. We conclude by proposing 'ontological honesty' as a necessary design principle for mitigating technologically mediated folie a deux.

</details>


### [79] [A Modular LLM-Agent System for Transparent Multi-Parameter Weather Interpretation](https://arxiv.org/abs/2512.11819)
*Daniil Sukhorukov,Andrei Zakharov,Nikita Glazkov,Katsiaryna Yanchanka,Vladimir Kirilin,Maxim Dubovitsky,Roman Sultimov,Yuri Maksimov,Ilya Makarov*

Main category: cs.CY

TL;DR: AI-Meteorologist是一个可解释的LLM代理框架，将原始数值天气预报转换为具有透明推理步骤的科学基础叙事报告。


<details>
  <summary>Details</summary>
Motivation: 传统天气预报输出通常呈现为密集表格或非结构化时间序列，缺乏解释性、上下文和科学推理。天气预报不仅是预测任务，更是需要解释、情境化和假设生成的科学过程。

Method: 基于代理的分析框架，通过上下文提示（无需微调）对多个气象变量进行分析，整合历史气候背景，生成结构化解释，识别天气锋面、异常和局部动态。

Result: 通过多地点预报数据的案例研究，系统不仅传达天气事件，还揭示底层大气驱动因素，展示了通过推理而非参数更新实现可解释性的可行性。

Conclusion: 该框架为增强人类气象专业知识和支持气候分析科学发现的AI系统提供了途径，展示了可解释性可以通过推理而非参数更新实现。

Abstract: Weather forecasting is not only a predictive task but an interpretive scientific process requiring explanation, contextualization, and hypothesis generation. This paper introduces AI-Meteorologist, an explainable LLM-agent framework that converts raw numerical forecasts into scientifically grounded narrative reports with transparent reasoning steps. Unlike conventional forecast outputs presented as dense tables or unstructured time series, our system performs agent-based analysis across multiple meteorological variables, integrates historical climatological context, and generates structured explanations that identify weather fronts, anomalies, and localized dynamics. The architecture relies entirely on in-context prompting, without fine-tuning, demonstrating that interpretability can be achieved through reasoning rather than parameter updates. Through case studies on multi-location forecast data, we show how AI-Meteorologist not only communicates weather events but also reveals the underlying atmospheric drivers, offering a pathway toward AI systems that augment human meteorological expertise and support scientific discovery in climate analytics.

</details>


### [80] [The Art of Storytelling in Authoritarian Regimes: Crafting State Narratives on Chinese Social Media](https://arxiv.org/abs/2512.11875)
*Ting Luo,Yan Wang*

Main category: cs.CY

TL;DR: 研究威权政权如何构建政治事件的官方叙事，提出合法性影响和公民验证能力两个维度，通过中国社交媒体数据分析发现叙事策略随事件特征而动态调整。


<details>
  <summary>Details</summary>
Motivation: 现有研究对威权政权如何构建官方叙事的动态过程理解不足，特别是不同政治事件特征如何影响叙事策略。本文旨在揭示威权宣传的复杂性，探究政权如何通过叙事构建维持统治韧性。

Method: 采用定量叙事分析方法，从中国政府、官方媒体和名人账号的社交媒体帖子中提取主谓宾（SVO）三元组，分析四个重大事件中的主导叙事结构，考察合法性影响和公民验证能力对叙事构建的影响。

Result: 事件合法性影响政权叙事努力和强调的信念，公民验证能力平衡自上而下操纵和自下而上回应的战略选择。叙事构建是适应特定情境的复杂过程，动态叙事策略有助于维持威权韧性。

Conclusion: 威权宣传是复杂的叙事构建过程，政权根据事件合法性影响和公民验证能力动态调整叙事策略，这种适应性叙事能力是威权韧性的重要机制。

Abstract: This article examines how authoritarian regimes construct state narratives about politically consequential events. Building on the narrative policy framework and existing research on authoritarian propaganda, we propose two dimensions that shape narrative construction: legitimacy implications -- whether events enhance or threaten regime legitimacy, and citizen verification capacity -- the extent to which citizens can evaluate official narratives through alternative sources. Using quantitative narrative analysis of Chinese social media posts by government, state media, and celebrity accounts, we extract subject-verb-object (SVO) triplets to map dominant narrative structures across four major events. Our findings show that legitimacy implications of the event shape regime's efforts in storytelling and the beliefs highlighted in the narratives, while citizen's verification capacity could balance the strategic choice between a top-down manipulation and bottom-up responsiveness of state narratives. Together, the results reveal propaganda as a complex process of narrative construction adaptive to specific contexts, offering new insights into how dynamic storytelling sustains authoritarian resilience.

</details>


### [81] [Prevalence, Devices Used, Reasons for Use, Trust, Barriers, and Challenges in Utilizing Generative AI among Tertiary Students](https://arxiv.org/abs/2512.11821)
*John Paul P. Miranda,Joseph Alexander Bansil,Emerson Q. Fernando,Almer B. Gamboa,Hilene E. Hernandez,Myka A. Cruz,Roque Francis B. Dianelo,Dina D. Gonzales,Elmer M. Penecilla*

Main category: cs.CY

TL;DR: 菲律宾大学生使用生成式AI的情况研究：主要使用免费手机工具，主要用于作业、创意和研究，但面临访问限制、缺乏支持、理解困难和财务约束等挑战。


<details>
  <summary>Details</summary>
Motivation: 研究菲律宾大学生使用生成式AI的情况，了解其使用频率、设备、原因、知识水平、信任度、感知和挑战，为教育政策制定提供依据。

Method: 通过调查菲律宾大学生使用生成式AI的情况，分析使用频率、设备、原因、知识水平、信任度、感知和挑战等多个维度。

Result: 大多数学生因财务限制使用免费的智能手机AI工具，主要用于作业、创意生成和研究；不到一半学生对AI有信心，对其准确性持矛盾态度；主要障碍包括访问限制、缺乏教师支持、理解输出困难和财务约束。

Conclusion: 研究强调需要改善访问条件、提供支持、加强培训并制定伦理指南；学生因同伴支持对AI持积极态度，但担忧对学习、学术标准、就业和隐私的影响；提出了相关建议。

Abstract: This study examined generative AI usage among Philippine college students particularly on frequency, devices, reasons, knowledge, trust, perceptions, and challenges. Most students used free AI tools on smartphones due to financial constraints. They used it primarily for homework, idea generation, and research. Less than half felt confident with AI and expressed mixed feelings about its accuracy. Barriers included limited access, lack of teacher support, difficulty understanding outputs, and financial constraints. The study highlighted the need for better access, support, training, and ethical guidelines. Broader concerns included impacts on learning, academic standards, job loss, and privacy. Students viewed AI positively due to peer support. Recommendations are discussed.

</details>


### [82] [Anticipatory Governance in Data-Constrained Environments: A Predictive Simulation Framework for Digital Financial Inclusion](https://arxiv.org/abs/2512.12212)
*Elizabeth Irenne Yuwono,Dian Tjondronegoro,Shawn Hunter,Amber Marshall*

Main category: cs.CY

TL;DR: 开发预测模拟框架，利用机器学习分析数字金融素养干预措施，为资源有限国家提供事前政策智能支持


<details>
  <summary>Details</summary>
Motivation: 资源受限和群岛国家中，金融排斥是数字公共服务交付的主要障碍。传统政策评估依赖回顾性数据，缺乏敏捷资源分配所需的事前智能。

Method: 使用UNCDF太平洋数字经济数据集（10,108名受访者），采用三阶段流程：描述性分析、可解释机器学习、情景模拟。通过透明线性回归模型（R平方95.9%）识别可修改的政策杠杆。

Result: 模拟显示基础数字能力（设备访问和费用跟踪）产生最高预期收益（达5.5%），优于态度干预。模型实现精准定位，识别年轻女性照顾者为高杠杆响应者，标记城市专业人员为非响应者以防止资源错配。

Conclusion: 研究展示如何将静态调查数据转化为可操作的政策智能，为公共部门决策支持系统嵌入预测分析提供可扩展、基于证据的蓝图，推进以公平为重点的数字治理。

Abstract: Financial exclusion remains a major barrier to digital public service delivery in resource-constrained and archipelagic nations. Traditional policy evaluations rely on retrospective data, limiting the ex-ante intelligence needed for agile resource allocation. This study introduces a predictive simulation framework to support anticipatory governance within government information systems. Using the UNCDF Pacific Digital Economy dataset of 10,108 respondents, we apply a three-stage pipeline: descriptive profiling, interpretable machine learning, and scenario simulation to forecast outcomes of digital financial literacy interventions before deployment. Leveraging cross-sectional structural associations, the framework projects intervention scenarios as prioritization heuristics rather than causal estimates. A transparent linear regression model with R-squared of 95.9 identifies modifiable policy levers. Simulations indicate that foundational digital capabilities such as device access and expense tracking yield the highest projected gains, up to 5.5 percent, outperforming attitudinal nudges. The model enables precision targeting, highlighting young female caregivers as high-leverage responders while flagging non-responders such as urban professionals to prevent resource misallocation. This research demonstrates how static survey data can be repurposed into actionable policy intelligence, offering a scalable and evidence-based blueprint for embedding predictive analytics into public-sector decision-support systems to advance equity-focused digital governance.

</details>


### [83] [Trust, Usefulness, and Dependency on AI in Programming: A Hierarchical Clustering Approach](https://arxiv.org/abs/2512.11822)
*Hilene E. Hernandez,Ranie B. Canlas,Madilaine Claire B. Nacianceno,Jordan L. Salenga,Jaymark A. Yambao,Juvy C. Grume,Aileen P. De Leon,Freneil R. Pampo,John Paul P. Miranda*

Main category: cs.CY

TL;DR: 研究菲律宾编程学生对AI工具的态度，发现四种用户类型，使用频率与信任度不直接相关，建议加强基础设施和培训


<details>
  <summary>Details</summary>
Motivation: AI工具正在改变编程教育，但在欠发达国家/地区的应用研究不足。了解学生对AI工具的信任、感知有用性和依赖程度，对改进教育整合至关重要。

Method: 调查菲律宾Pampanga地区508名大一编程学生，使用层次聚类分析他们的感知，识别不同学生群体。

Result: 发现四种独特的学生类型，具有不同的信任度和使用强度。学生认可AI工具的好处，但由于基础设施有限和接触不足，依赖度较低。高频用户不一定报告更高的信任或有用性，表明使用模式与感知之间存在复杂关系。

Conclusion: 为最大化AI的教育影响，需要有针对性的干预措施，如基础设施发展、培训计划和课程整合。该研究为发展中地区编程教育中公平有效的AI采用提供了实证见解。

Abstract: While AI tools are transforming programming education, their adoption in underrepresented countries remains insufficiently studied. Understanding students' trust, perceived usefulness, and dependency on AI tools is essential to improving their integration into education. For these purposes, this study surveyed 508 first-year programming students in Pampanga, Philippines and analyzed their perceptions using hierarchical clustering. Results showed four unique student profiles with varying in trust and usage intensity. While students acknowledged AI tools' benefits, dependency remained low due to limited infrastructure and insufficient exposure. High-frequency users did not necessarily report greater trust or usefulness which may indicates a complex relationship between usage patterns and perception. This study recommends that to maximize AI's educational impact, targeted interventions such as infrastructure development, training programs, and curriculum integration are necessary. This study provides empirical insights to support equitable and effective AI adoption in programming education within developing regions.

</details>


### [84] [Teachers' Perspectives on the Use of AI Detection Tools: Insights from Ridge Regression Analysis](https://arxiv.org/abs/2512.11823)
*Vicky P. Vital,Francis F. Balahadia,Maria Anna D. Cruz,Dolores D. Mallari,Juvy C. Grume,Erika M. Pineda,Jordan L. Salenga,Lloyd D. Feliciano,John Paul P. Miranda*

Main category: cs.CY

TL;DR: 菲律宾教师对AI检测工具的信任度是影响其感知公平性和决策的最重要因素，而担忧和社会规范影响较弱。


<details>
  <summary>Details</summary>
Motivation: 研究菲律宾教师对学术环境中AI检测工具的认知，探索影响教师信任、担忧和决策的因素，以及这些因素如何影响教师对学生作业评估的公平性感知和决策过程。

Method: 对213名菲律宾教师进行调查，使用岭回归分析来检验预测变量与因变量之间的关系，重点关注信任、担忧和社会规范对教师感知公平性和决策的影响。

Result: 信任是影响教师感知公平性和决策的最显著预测因子，而担忧和社会规范的影响较弱。信任AI检测工具的教师更可能认为这些工具公平有效。

Conclusion: 信任在塑造教师对AI检测工具的认知中起关键作用。需要通过培训、机构指南和社区实践来建立信任，平衡政策执行与教育者支持，促进AI检测工具在教育环境中的有效采用。

Abstract: This study explores the perceptions of 213 Filipino teachers toward AI detection tools in academic settings. It focuses on the factors that influence teachers' trust, concerns, and decision-making regarding these tools. The research investigates how teachers' trust in AI detection tools affects their perceptions of fairness and decision-making in evaluating student outputs. It also explores how concerns about AI tools and social norms influence the relationship between trust and decision-making. Ridge Regression analysis was used to examine the relationships between the predictors and the dependent variable. The results revealed that trust in AI detection tools is the most significant predictor of perceived fairness and decision-making among teachers. Concerns about AI tools and social norms have weaker effects on teachers' perceptions. The study emphasized critical role of trust in shaping teachers' perceptions of AI detection tools. Teachers who trust these tools are more likely to view them as fair and effective. In contrast, concerns and social norms have a limited influence on perceptions and decision-making. For recommendations, training and institutional guidelines should emphasize how these tools work, their limitations, and best practices for their use. Striking a balance between policy enforcement and educator support is essential for fostering trust in AI detection technologies. Encouraging experienced users to share insights through communities of practice could enhance the adoption and effective use of AI detection tools in educational settings..

</details>


### [85] [Assessing Greenspace Attractiveness with ChatGPT, Claude, and Gemini: Do AI Models Reflect Human Perceptions?](https://arxiv.org/abs/2512.11827)
*Milad Malekzadeh,Magdalena Biernacka,Elias Willberg,Jussi Torkko,Edyta Łaszkiewicz,Tuuli Toivonen*

Main category: cs.CY

TL;DR: 该研究评估了多模态大语言模型（MLLMs）使用街景图像评估绿地吸引力的能力，发现模型在正式绿地（如公园）和吸引力低的非正式绿地（如荒地）上与人类评估高度一致，但在吸引力高的非正式绿地和吸引力低的正式绿地上与人类评估一致性较低。


<details>
  <summary>Details</summary>
Motivation: 现有绿地吸引力评估方法往往忽视非正式或临时性空间，且资源密集难以大规模捕捉主观感知。研究旨在探索MLLMs是否能像人类一样使用街景图像评估绿地吸引力，为城市规划提供可扩展的预评估工具。

Method: 使用ChatGPT GPT-4o、Claude 3.5 Haiku和Gemini 2.0 Flash三种MLLMs，基于Google街景图像评估波兰罗兹市正式和非正式绿地的吸引力。将模型输出与当地居民的地理问卷调查结果进行比较，分析吸引力判断的一致性和解释理由的分类。

Result: 模型在吸引力高的正式绿地和吸引力低的非正式绿地上与人类评估高度一致，但在吸引力高的非正式绿地和吸引力低的正式绿地上一致性较低。模型更强调美学和设计特征，而低估了受访者重视的安全性、功能基础设施和本地嵌入性等品质。

Conclusion: MLLMs具有可扩展预评估的潜力，但不能替代人类监督和补充性参与式方法。模型可以支持但不能替代规划实践中对背景敏感的绿地评估，需要人类监督以确保全面考虑当地社区重视的多种品质。

Abstract: Understanding greenspace attractiveness is essential for designing livable and inclusive urban environments, yet existing assessment approaches often overlook informal or transient spaces and remain too resource intensive to capture subjective perceptions at scale. This study examines the ability of multimodal large language models (MLLMs), ChatGPT GPT-4o, Claude 3.5 Haiku, and Gemini 2.0 Flash, to assess greenspace attractiveness similarly to humans using Google Street View imagery. We compared model outputs with responses from a geo-questionnaire of residents in Lodz, Poland, across both formal (for example, parks and managed greenspaces) and informal (for example, meadows and wastelands) greenspaces. Survey respondents and models indicated whether each greenspace was attractive or unattractive and provided up to three free text explanations. Analyses examined how often their attractiveness judgments aligned and compared their explanations after classifying them into shared reasoning categories. Results show high AI human agreement for attractive formal greenspaces and unattractive informal spaces, but low alignment for attractive informal and unattractive formal greenspaces. Models consistently emphasized aesthetic and design oriented features, underrepresenting safety, functional infrastructure, and locally embedded qualities valued by survey respondents. While these findings highlight the potential for scalable pre-assessment, they also underscore the need for human oversight and complementary participatory approaches. We conclude that MLLMs can support, but not replace, context sensitive greenspace evaluation in planning practice.

</details>


### [86] [The Memecoin Phenomenon: An In-Depth Study of Solana's Blockchain Trends](https://arxiv.org/abs/2512.11850)
*Davide Mancino*

Main category: cs.CY

TL;DR: 本文分析Solana区块链上的模因币现象，发现Pump.fun平台在2024年第四季度主导了Solana的代币铸造和交易活动，但只有极少数代币成功上线主要去中心化交易所，揭示了高度投机性的市场结构。


<details>
  <summary>Details</summary>
Motivation: 研究Solana区块链上新兴的模因币现象，特别是Pump.fun平台如何重塑区块链生态系统并影响市场参与，分析零售驱动的代币创建平台对区块链经济的影响。

Method: 使用链上数据分析方法，研究2024年第四季度Solana区块链上的Pump.fun平台数据，包括代币铸造、交易量、用户活跃度等指标。

Result: Pump.fun平台占Solana所有铸造代币的71.1%，贡献了40-67.4%的总DEX交易量；日活跃用户从6万增长至26万峰值；但只有不到2%的代币成功过渡到主要去中心化交易所。

Conclusion: 模因币现象具有双重影响：一方面降低了进入门槛，促进了零售参与和市场民主化；另一方面带来了高度投机性和风险，可能危及市场效率和区块链生态系统的长期稳定性，需要审慎评估。

Abstract: This paper analyzes the emerging memecoin phenomenon on the Solana blockchain, focusing on the Pump.fun platform during Q4 2024. Using on-chain data, it is explored how retail-focused token creation platforms are reshaping blockchain ecosystems and influencing market participation. This study finds that Pump.fun accounted for up to 71.1% of all tokens minted on Solana and contributed 40-67.4% of total DEX transactions. Despite this activity, fewer than 2% of tokens successfully transitioned to major decentralized exchanges, highlighting a highly speculative market structure. The platform experienced rapid growth, with daily active users rising from 60,000 to peaks of 260,000, underscoring strong retail adoption. This reflects a broader shift towards accessible, socially-driven market participation enabled by memecoins. However, while memecoins lower entry barriers and encourage retail engagement, they introduce significant risks. The volatile and speculative nature of these platforms raises concerns about long-term sustainability and the resilience of the blockchain ecosystem. These findings reveal the dual impact of memecoins: they democratize token creation and alter market dynamics but may jeopardize market efficiency and stability. This paper highlights the need to critically assess the implications of retail-driven speculative trading and its potential to disrupt emerging blockchain economies.

</details>


### [87] [Expert Assessment: The Systemic Environmental Risks of Artficial Intelligence](https://arxiv.org/abs/2512.11863)
*Julian Schön,Lena Hoffmann,Nikolas Becker*

Main category: cs.CY

TL;DR: 该报告提出了AI系统环境风险框架，超越直接资源消耗，关注AI融入社会经济基础设施引发的系统性、跨领域环境危害。


<details>
  <summary>Details</summary>
Motivation: AI常被视为解决气候变化等社会挑战的关键工具，但其环境足迹不断扩大。现有研究多关注AI的直接资源消耗（如能源和水使用），而忽视了AI融入社会经济基础设施后引发的系统性环境风险。

Method: 通过叙事性文献综述，提出了一个三层框架来操作化系统性风险分析：1）塑造AI发展的结构性条件；2）传播环境危害的风险放大机制；3）表现为可观察生态和社会后果的影响。在农业与生物多样性、石油天然气、废物管理三个领域进行了基于专家访谈的案例研究。

Result: 提出了一个系统性环境风险分析框架，识别了AI系统环境风险的特征：涌现性、跨领域性、通过反馈传播、非线性、不平等性和潜在不可逆性。虽然这些风险尚属新兴且量化存在不确定性，但框架为理解和分析AI的系统性环境影响提供了结构化方法。

Conclusion: AI的系统性环境风险超越了直接资源消耗，源于AI融入社会、经济和物理基础设施后引发的复杂系统效应。需要采用系统性风险分析框架来全面评估AI的环境影响，特别是在农业、能源和废物管理等关键领域。

Abstract: Artificial intelligence (AI) is often presented as a key tool for addressing societal challenges, such as climate change. At the same time, AI's environmental footprint is expanding increasingly. This report describes the systemic environmental risks of artificial intelligence, in particular, moving beyond direct impacts such as energy and water usage. Systemic environmental risks of AI are emergent, cross-sector harms to climate, biodiversity, freshwater, and broader socioecological systems that arise primarily from AI's integration into social, economic, and physical infrastructures, rather than its direct resource use, and that propagate through feedbacks, yielding nonlinear, inequitable, and potentially irreversible impacts. While these risks are emergent and quantification is uncertain, this report aims to provide an overview of systemic environmental risks. Drawing on a narrative literature review, we propose a three-level framework that operationalizes systemic risk analysis. The framework identifies the structural conditions that shape AI development, the risk amplification mechanisms that propagate environmental harm, and the impacts that manifest as observable ecological and social consequences. We illustrate the framework in expert-interview-based case studies across agriculture and biodiversity, oil and gas, and waste management.

</details>


### [88] [Industrial AI Robustness Card: Evaluating and Monitoring Time Series Models](https://arxiv.org/abs/2512.11868)
*Alexander Windmann,Benedikt Stratmann,Mariya Lyashenko,Oliver Niggemann*

Main category: cs.CY

TL;DR: 该论文提出了工业AI鲁棒性卡片（IARC），一个轻量级、任务无关的协议，用于记录和评估工业时间序列上AI模型的鲁棒性，满足欧盟AI法案要求。


<details>
  <summary>Details</summary>
Motivation: 工业AI从业者在面对新兴法规和标准中的模糊鲁棒性要求时，缺乏具体、可实施的协议。需要一种能够将法规要求转化为实际可操作方法的工具。

Method: 引入工业AI鲁棒性卡片（IARC），这是一个轻量级、任务无关的协议，包含必要的字段和实证测量报告协议。该协议结合了漂移监测、不确定性量化和压力测试，并将其映射到欧盟AI法案的相关义务。

Result: 通过生物制药发酵过程的软传感器案例研究，展示了IARC如何支持可复现的鲁棒性证据和持续监测，为工业AI模型提供了具体的鲁棒性评估框架。

Conclusion: IARC为工业AI从业者提供了一个实用的工具，将法规中的模糊鲁棒性要求转化为具体的实施协议，有助于满足合规要求并提高AI模型的可靠性。

Abstract: Industrial AI practitioners face vague robustness requirements in emerging regulations and standards but lack concrete, implementation ready protocols. This paper introduces the Industrial AI Robustness Card (IARC), a lightweight, task agnostic protocol for documenting and evaluating the robustness of AI models on industrial time series. The IARC specifies required fields and an empirical measurement and reporting protocol that combines drift monitoring, uncertainty quantification, and stress tests, and it maps these to relevant EU AI Act obligations. A soft sensor case study on a biopharmaceutical fermentation process illustrates how the IARC supports reproducible robustness evidence and continuous monitoring.

</details>


### [89] [Using Socio-economic Indicators, Smart Transit Systems, and Urban Simulator to Accelerate ZEV Adoption and Reduce VMT](https://arxiv.org/abs/2512.11870)
*Mulham Fawkherji,Bruce Race,Driss Benhaddou*

Main category: cs.CY

TL;DR: 论文提出利用智能交通系统和社会经济指标来加速零排放车辆采用和减少车辆行驶里程的方法，以帮助休斯顿等汽车依赖型城市实现2050年净零排放目标。


<details>
  <summary>Details</summary>
Motivation: 全球道路交通占温室气体排放的15%并导致大量PM2.5相关早逝。休斯顿作为低密度、汽车依赖型城市，道路交通占其排放的48%，要实现2050年净零目标面临挑战，特别是社会经济差异限制了零排放车辆的普及。

Method: 建立道路交通排放基线，利用社会经济指标和智能交通系统评估政策，开发Unity 3D仿真环境进行动态城市交通建模和政策场景可视化，分析智能停车、公交激励、安全数据系统和零排放车队管理等策略。

Result: 提出了支持评估的仿真环境，识别了潜在政策措施，包括扩大零排放车辆获取、减少20%车辆行驶里程、改善交通模式分配和系统可靠性等具体策略。

Conclusion: 汽车依赖型城市要实现2050年排放目标，可以采用论文讨论的指标、度量和智能交通技术，通过加速零排放车辆采用和减少车辆行驶里程来达成减排目标。

Abstract: Globally, on-road transportation accounts for 15% of greenhouse gas (GHG) emissions and an estimated 385,000 premature deaths from PM2.5. Cities play a critical role in meeting IPCC targets, generating 75% of global energy-related GHG emissions. In Houston, Texas, on-road transportation represents 48% of baseline emissions in the Climate Action Plan (CAP). To reach net-zero by 2050, the CAP targets a 70% emissions reduction from a 2014 baseline, offset by 30% renewable energy. This goal is challenging because Houston is low-density and auto-dependent, with 89% of on-road emissions from cars and small trucks and limited public transit usage. Socio-economic disparities further constrain Zero Emissions Vehicle (ZEV) adoption. Strategies focus on expanding ZEV access and reducing Vehicle Miles Traveled (VMT) by 20% through transit improvements and city design. This paper presents methods for establishing an on-road emissions baseline and evaluating policies that leverage socio-economic indicators and Intelligent Transportation Systems (ITS) to accelerate ZEV adoption and reduce VMT. Smart parking, transit incentives, secure data systems, and ZEV fleet management support improvements in modal split and system reliability. Policy options are analyzed and potential actions identified. To support evaluation, a simulation environment was developed in Unity 3D, enabling dynamic modeling of urban mobility and visualization of policy scenarios. Auto-dependent cities aiming for 2050 emission targets can benefit from the indicators, metrics, and technologies discussed.

</details>


### [90] [A Technical Policy Blueprint for Trustworthy Decentralized AI](https://arxiv.org/abs/2512.11878)
*Hasan Kassem,Sergen Cansiz,Brandon Edwards,Patrick Foley,Inken Hagestedt,Taeho Jung,Prakash Moorthy,Michael O'Connor,Bruno Rodrigues,Holger Roth,Micah Sheller,Dimitris Stripelis,Marc Vesin,Renato Umeton,Mic Bowman,Alexandros Karargyris*

Main category: cs.CY

TL;DR: 提出技术政策蓝图，将治理需求编码为代码化政策对象，分离资产政策验证与执行，实现去中心化AI系统的透明、可扩展、可验证治理


<details>
  <summary>Details</summary>
Motivation: 去中心化AI系统（如联邦学习）对解锁AI资产市场（如医疗数据市场）至关重要，但当前治理方法依赖特定基础设施政策，阻碍资产互操作性和系统间信任

Method: 提出技术政策蓝图，将治理需求编码为政策即代码对象，分离政策验证与执行：政策引擎验证证据并颁发能力包，资产守护者仅基于能力包执行访问或计算

Result: 通过解耦政策处理与能力授予，使治理能够在不重新配置AI基础设施的情况下演进，创建透明、可审计、适应变化的治理方法

Conclusion: 该技术政策蓝图为去中心化AI系统提供透明、可扩展、可验证的治理机制，促进AI资产市场的互操作性和信任建立

Abstract: Decentralized AI systems, such as federated learning, can play a critical role in further unlocking AI asset marketplaces (e.g., healthcare data marketplaces) thanks to increased asset privacy protection. Unlocking this big potential necessitates governance mechanisms that are transparent, scalable, and verifiable. However current governance approaches rely on bespoke, infrastructure-specific policies that hinder asset interoperability and trust among systems. We are proposing a Technical Policy Blueprint that encodes governance requirements as policy-as-code objects and separates asset policy verification from asset policy enforcement. In this architecture the Policy Engine verifies evidence (e.g., identities, signatures, payments, trusted-hardware attestations) and issues capability packages. Asset Guardians (e.g. data guardians, model guardians, computation guardians, etc.) enforce access or execution solely based on these capability packages. This core concept of decoupling policy processing from capabilities enables governance to evolve without reconfiguring AI infrastructure, thus creating an approach that is transparent, auditable, and resilient to change.

</details>


### [91] [It's About Time: The Temporal and Modal Dynamics of Copilot Usage](https://arxiv.org/abs/2512.11879)
*Beatriz Costa-Gomes,Sophia Chen,Connie Hsueh,Deborah Morgan,Philipp Schoenegger,Yash Shah,Sam Way,Yuki Zhu,Timothé Adeline,Michael Bhaskar,Mustafa Suleyman,Seth Spielman*

Main category: cs.CY

TL;DR: 分析微软Copilot 3750万次对话，发现AI使用模式因设备类型和情境而异：移动端以健康话题为主，桌面端工作时间以工作和科技为主，不同话题有特定的时间节奏。


<details>
  <summary>Details</summary>
Motivation: 传统AI使用分析主要关注"用户用AI做什么"，本研究旨在深入探索"用户如何以及何时使用AI"，揭示AI在不同设备类型和情境下的使用模式差异。

Method: 分析2025年1月至9月期间3750万次微软Copilot的匿名对话数据，按设备类型（移动端vs桌面端）、时间（小时、星期、月份）和话题类别进行统计分析。

Result: 1. 移动端：健康话题占主导地位，在所有观察时段都保持一致，用户不仅寻求信息还寻求建议
2. 桌面端：工作时间和科技话题主导，上午8点至下午5点间"工作与职业"超越"科技"成为首要话题
3. 时间模式：编程查询在工作日激增，游戏话题在周末上升，深夜哲学问题增多，情人节关系对话激增

Conclusion: 用户已迅速将AI融入生活的各个方面：在办公桌上是工作助手，在手机上则是陪伴伙伴。AI使用模式高度依赖于情境和设备类型，反映了AI已成为用户日常生活的重要组成部分。

Abstract: We analyze 37.5 million deidentified conversations with Microsoft's Copilot between January and September 2025. Unlike prior analyses of AI usage, we focus not just on what people do with AI, but on how and when they do it. We find that how people use AI depends fundamentally on context and device type. On mobile, health is the dominant topic, which is consistent across every hour and every month we observed - with users seeking not just information but also advice. On desktop, the pattern is strikingly different: work and technology dominate during business hours, with "Work and Career" overtaking "Technology" as the top topic precisely between 8 a.m. and 5 p.m. These differences extend to temporal rhythms: programming queries spike on weekdays while gaming rises on weekends, philosophical questions climb during late-night hours, and relationship conversations surge on Valentine's Day. These patterns suggest that users have rapidly integrated AI into the full texture of their lives, as a work aid at their desks and a companion on their phones.

</details>


### [92] [An Experience Report on a Pedagogically Controlled, Curriculum-Constrained AI Tutor for SE Education](https://arxiv.org/abs/2512.11882)
*Lucia Happe,Dominik Fuchß,Luca Hüttner,Kai Marquardt,Anne Koziolek*

Main category: cs.CY

TL;DR: RockStartIT Tutor是一个基于GPT-4的AI编程辅导系统，采用新颖提示策略和模块化知识库，为中学生提供个性化编程学习支持，初步评估显示学生和教师对其接受度良好。


<details>
  <summary>Details</summary>
Motivation: 虽然AI在教育中的应用既有前景也有质疑，但大型语言模型的最新进展为可扩展的个性化辅导带来了新希望。该研究旨在开发一个AI辅助系统，为数字编程和计算思维课程提供支持。

Method: 基于GPT-4和OpenAI Assistant API构建RockStartIT Tutor系统，采用新颖的提示策略和模块化、语义标记的知识库，实现情境感知、个性化和课程约束的支持。使用技术接受模型(TAM)对13名学生和教师进行试点评估。

Result: 学习者欣赏系统提供的低风险提问环境和支架式指导，教育者强调系统在减轻独立任务认知负荷和补充课堂教学方面的潜力。主要挑战包括原型限制、小样本量以及需要针对目标年龄组进行长期研究。

Conclusion: AI导师不应被视为教师替代品，而是作为支持工具，扩展反馈渠道、促进探究，并支持学校的核心使命：帮助学生更好地学习。研究展示了一种无需模型训练、通过结构和提示塑造行为的实用AI集成方法。

Abstract: The integration of artificial intelligence (AI) into education continues to evoke both promise and skepticism. While past waves of technological optimism often fell short, recent advances in large language models (LLMs) have revived the vision of scalable, individualized tutoring. This paper presents the design and pilot evaluation of RockStartIT Tutor, an AI-powered assistant developed for a digital programming and computational thinking course within the RockStartIT initiative. Powered by GPT-4 via OpenAI's Assistant API, the tutor employs a novel prompting strategy and a modular, semantically tagged knowledge base to deliver context-aware, personalized, and curriculum-constrained support for secondary school students. We evaluated the system using the Technology Acceptance Model (TAM) with 13 students and teachers. Learners appreciated the low-stakes environment for asking questions and receiving scaffolded guidance. Educators emphasized the system's potential to reduce cognitive load during independent tasks and complement classroom teaching. Key challenges include prototype limitations, a small sample size, and the need for long-term studies with the target age group. Our findings highlight a pragmatic approach to AI integration that requires no model training, using structure and prompts to shape behavior. We position AI tutors not as teacher replacements but as enabling tools that extend feedback access, foster inquiry, and support what schools do best: help students learn.

</details>


### [93] [Aesthetic Alignment Risks Assimilation: How Image Generation and Reward Models Reinforce Beauty Bias and Ideological "Censorship"](https://arxiv.org/abs/2512.11883)
*Wenqi Marshall Guo,Qingyun Qian,Khalad Hasan,Shan Du*

Main category: cs.CY

TL;DR: 研究发现图像生成模型过度对齐到广义审美偏好会与用户意图冲突，特别是当用户需要"反审美"输出时。这种对齐优先考虑开发者价值观，损害了用户自主性和审美多元性。


<details>
  <summary>Details</summary>
Motivation: 当前图像生成模型过度对齐到广义审美偏好，这会在用户需要"反审美"输出（用于艺术或批判目的）时与用户意图产生冲突。这种对齐优先考虑开发者价值观，损害了用户自主性和审美多元性。

Method: 构建广谱审美数据集，评估最先进的生成模型和奖励模型。通过图像到图像编辑，并与真实抽象艺术作品进行比较来确认系统性偏见。

Result: 审美对齐的生成模型经常默认输出传统美丽图像，无法尊重低质量或负面图像的指令。奖励模型即使反审美图像完美匹配用户提示也会惩罚它们。通过图像编辑和与真实抽象艺术比较确认了这种系统性偏见。

Conclusion: 图像生成模型的过度审美对齐损害了用户自主性和审美多元性，需要重新思考对齐策略以更好地尊重用户意图和多样化的审美表达。

Abstract: Over-aligning image generation models to a generalized aesthetic preference conflicts with user intent, particularly when ``anti-aesthetic" outputs are requested for artistic or critical purposes. This adherence prioritizes developer-centered values, compromising user autonomy and aesthetic pluralism. We test this bias by constructing a wide-spectrum aesthetics dataset and evaluating state-of-the-art generation and reward models. We find that aesthetic-aligned generation models frequently default to conventionally beautiful outputs, failing to respect instructions for low-quality or negative imagery. Crucially, reward models penalize anti-aesthetic images even when they perfectly match the explicit user prompt. We confirm this systemic bias through image-to-image editing and evaluation against real abstract artworks.

</details>


### [94] [Advancing Autonomous Driving System Testing: Demands, Challenges, and Future Directions](https://arxiv.org/abs/2512.11887)
*Yihan Liao,Jingyu Zhang,Jacky Keung,Yan Xiao,Yurou Dai*

Main category: cs.CY

TL;DR: 该研究调查了自动驾驶系统测试的现状，通过大规模调研识别了行业与学术界的测试需求与差距，分析了V2X通信和基础模型等新兴技术对测试的影响，并指出了现有测试方法在真实世界性能评估、极端案例多样性、仿真与现实差距等方面的不足。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在复杂真实环境中的可靠性验证是关键挑战，现有测试方法难以全面评估真实世界性能，需要了解行业实践与学术研究之间的差距，并探索V2X通信和基础模型等新兴技术如何提升测试效果。

Method: 1. 回顾现有自动驾驶测试技术（包括模块化和端到端系统）；2. 对100名行业和学术界参与者进行大规模调研，通过专家讨论精炼问题；3. 结合105项代表性研究进行定量和定性分析；4. 分析V2X通信和基础模型（大语言模型、视觉基础模型）在测试中的作用。

Result: 现有测试技术在全面评估真实世界性能方面存在困难，主要问题包括：极端案例多样性不足、仿真与现实差距、缺乏系统化测试标准、潜在攻击暴露风险、V2X部署的实际挑战、基于基础模型测试的高计算成本。调研揭示了行业需求与学术研究之间的显著差距。

Conclusion: 研究整合了自动驾驶测试的关键研究空白，并提出了未来研究方向：制定全面的测试标准、V2X系统中的跨模型协作、基于基础模型测试的跨模态适应、大规模自动驾驶评估的可扩展验证框架。

Abstract: Autonomous driving systems (ADSs) promise improved transportation efficiency and safety, yet ensuring their reliability in complex real-world environments remains a critical challenge. Effective testing is essential to validate ADS performance and reduce deployment risks. This study investigates current ADS testing practices for both modular and end-to-end systems, identifies key demands from industry practitioners and academic researchers, and analyzes the gaps between existing research and real-world requirements. We review major testing techniques and further consider emerging factors such as Vehicle-to-Everything (V2X) communication and foundation models, including large language models and vision foundation models, to understand their roles in enhancing ADS testing. We conducted a large-scale survey with 100 participants from both industry and academia. Survey questions were refined through expert discussions, followed by quantitative and qualitative analyses to reveal key trends, challenges, and unmet needs. Our results show that existing ADS testing techniques struggle to comprehensively evaluate real-world performance, particularly regarding corner case diversity, the simulation to reality gap, the lack of systematic testing criteria, exposure to potential attacks, practical challenges in V2X deployment, and the high computational cost of foundation model-based testing. By further analyzing participant responses together with 105 representative studies, we summarize the current research landscape and highlight major limitations. This study consolidates critical research gaps in ADS testing and outlines key future research directions, including comprehensive testing criteria, cross-model collaboration in V2X systems, cross-modality adaptation for foundation model-based testing, and scalable validation frameworks for large-scale ADS evaluation.

</details>


### [95] [Automation as a Catalyst for Geothermal Energy Adoption in Qatar: A Techno-Economic and Environmental Assessment](https://arxiv.org/abs/2512.11890)
*Tariq Eldakruri,Edip Senyurek*

Main category: cs.CY

TL;DR: 自动化技术可将卡塔尔地热项目的资本支出降低12-14%，运营支出降低14-17%，平准化能源成本从145美元/MWh降至125美元/MWh，投资回收期缩短最多2年，每年可减少4000-17600吨CO2排放


<details>
  <summary>Details</summary>
Motivation: 卡塔尔地热资源利用不足，主要受高资本成本、钻井风险和地下条件不确定性制约。研究旨在探索自动化如何提高地热部署的技术经济性和环境可行性，支持卡塔尔能源多元化和脱碳战略

Method: 研究通过三条路径分析：杜汉盆地的增强型地热系统、改造油气井、以及用于区域供冷的地源热泵。结合地质数据集和财务建模，评估自动化对资本支出、运营支出、平准化能源成本、投资回收期和CO2减排的影响，并使用蒙特卡洛模拟分析不确定性

Result: 全自动化使资本支出降低12-14%，运营支出降低14-17%，平准化能源成本从145美元/MWh降至125美元/MWh，投资回收期缩短最多2年。每个项目每年可避免4000-17600吨CO2排放，自动化还降低了投资结果的不确定性

Conclusion: 自动化显著增强了地热系统的经济可行性，支持其融入卡塔尔长期能源多元化和脱碳战略，为克服地热部署障碍提供了有效解决方案

Abstract: Geothermal energy provides continuous low emission potential but is underused in Qatar because of high capital costs, drilling risks, and uncertainty in subsurface conditions. This study examines how automation can improve the techno economic and environmental feasibility of geothermal deployment through three pathways: Enhanced Geothermal Systems in the Dukhan Basin, repurposed oil and gas wells, and ground source heat pumps for district cooling. Using geological datasets and financial modeling, the analysis shows that full automation reduces capital expenditure by 12 to 14 percent and operating expenditure by 14 to 17 percent. The Levelized Cost of Energy decreases from 145 USD per MWh to 125 USD per MWh, and payback periods shorten by up to two years. Environmental results indicate that geothermal substitution can avoid between 4000 and 17600 tons of CO2 per year for each project. Automation also reduces uncertainty in investment outcomes based on Monte Carlo simulations. Overall, the results show that automation strengthens the economic viability of geothermal systems and supports their integration into Qatars long term energy diversification and decarbonization strategies.

</details>


### [96] [Should AI Become an Intergenerational Civil Right?](https://arxiv.org/abs/2512.11892)
*Jon Crowcroft,Rute C. Sofia,Dirk Trossen,Vassilis Tsaoussidis*

Main category: cs.CY

TL;DR: AI访问应被视为代际公民权利而非商业服务，需在资源约束下平衡公平与可持续性


<details>
  <summary>Details</summary>
Motivation: AI已成为社会基础设施，但其大规模部署依赖有限且分布不均的资源。当前AI治理存在未解决的矛盾：扩大AI访问对社会包容至关重要，但无约束增长会导致资源不可持续；限制访问则会加剧不平等并威胁基本权利。

Method: 提出将AI访问视为"代际公民权利"的法律伦理框架，并探索通过IoT-边缘-云计算、去中心化推理和能源感知网络等技术实现路径，设计支持资源约束下公平访问的AI交付网络架构。

Result: 现有监管框架大多忽视公平访问与资源约束的耦合关系，导致公平性、可持续性和长期社会影响等关键问题未解决。论文提出了连接治理原则与具体系统设计的路径。

Conclusion: 应将AI视为共享社会基础设施而非市场商品，通过代际公民权利框架和技术创新，实现既社会公正又环境可持续的AI部署。

Abstract: Artificial Intelligence (AI) is rapidly becoming a foundational layer of social, economic, and cognitive infrastructure. At the same time, the training and large-scale deployment of AI systems rely on finite and unevenly distributed energy, networking, and computational resources. This tension exposes a largely unexamined problem in current AI governance: while expanding access to AI is essential for social inclusion and equal opportunity, unconstrained growth in AI use risks unsustainable resource consumption, whereas restricting access threatens to entrench inequality and undermine basic rights.
  This paper argues that access to AI outputs largely derived from publicly produced knowledge should not be treated solely as a commercial service, but as a fundamental civil interest requiring explicit protection. We show that existing regulatory frameworks largely ignore the coupling between equitable access and resource constraints, leaving critical questions of fairness, sustainability, and long-term societal impact unresolved. To address this gap, we propose recognizing access to AI as an \emph{Intergenerational Civil Right}, establishing a legal and ethical framework that simultaneously safeguards present-day inclusion and the rights of future generations.
  Beyond normative analysis, we explore how this principle can be technically realized. Drawing on emerging paradigms in IoT--Edge--Cloud computing, decentralized inference, and energy-aware networking, we outline technological trajectories and a strawman architecture for AI Delivery Networks that support equitable access under strict resource constraints. By framing AI as a shared social infrastructure rather than a discretionary market commodity, this work connects governance principles with concrete system design choices, offering a pathway toward AI deployment that is both socially just and environmentally sustainable.

</details>


### [97] [Beyond Automation: Rethinking Work, Creativity, and Governance in the Age of Generative AI](https://arxiv.org/abs/2512.11893)
*Haocheng Lin*

Main category: cs.CY

TL;DR: 本文探讨AI时代四大现象：就业演变、AI采用差异、全民基本收入必要性、AI内容政策对创造力的影响，并提出综合治理框架


<details>
  <summary>Details</summary>
Motivation: 生成式AI系统正在重塑工作、创造力和经济安全的本质，需要全面理解AI的社会影响，而不仅仅是生产力提升

Method: 混合方法：劳动力市场任务暴露建模、部门扩散映射、政策框架分析、定性话语批判

Result: 提出综合框架，认为UBI应作为更广泛治理生态系统的一部分，包括技能发展、创造力保护和模型设计

Conclusion: 政策制定者需建立包容性治理框架，未来研究方向包括AI创造力评估、使用分布分类和平衡内容限制与创作自由的治理标准

Abstract: The accelerating advancement of generative artificial intelligence (AI) systems is reshaping the nature, distribution and meaning of work, creativity, and economic security. This paper investigates four inter-related phenomena in the current AI era: (1) the evolving landscape of employment and the future of work; (2) the diverse patterns of AI adoption across socio-demographic groups, sectors, and geographies; (3) whether universal basic income (UBI) should become a compulsory policy response to the AI revolution; and (4) the implications of AI content policies and model behaviours for human creativity, wellbeing, and everyday decision-making. Furthermore, the paper tests the hypothesis that newer model generations may perform worse than their predecessors, and examines how users' interactions with AI systems may produce echo chambers through sycophantic model alignment. Using a mixed methodology that integrates labour market task-exposure modelling, sectoral diffusion mapping, policy-framework analysis, and qualitative discourse critique, this study develops a comprehensive framework for understanding the societal consequences of AI systems beyond productivity gains. It argues that to foster an inclusive, meaningful, and creative environment, policymakers must treat UBI as one dimension within a broader ecosystem of governance, skills development, creativity preservation, and model design. The paper concludes by outlining future research directions, including systematic evaluation of AI's creative performance across model generations, construction of a taxonomy of AI-usage distribution and equity, and formulation of governance criteria to balance content restrictions with creative freedom.

</details>


### [98] [Financial Management Challenges in Enterprises Employing Remote and Hybrid Workforces](https://arxiv.org/abs/2512.11918)
*Michał Ćwiąkała,Gabriela Wojak,Dariusz Baran,Ernest Górka,Bartłomiej Bartnik,Waldemar Gajda,Ryszard Ratajski*

Main category: cs.CY

TL;DR: 远程和混合工作模式对组织财务管理带来挑战和机遇，研究发现数字工具能改善预算控制和透明度，但预测准确性和跨部门沟通仍是主要问题，建议加强数字基础设施和沟通框架。


<details>
  <summary>Details</summary>
Motivation: 随着远程和混合工作模式的普及，组织面临新的财务管理挑战，需要研究这些灵活工作安排如何影响预算、报告和财务透明度，为数字化转型提供实证依据。

Method: 采用定量调查方法，收集管理者、人力资源人员和财务专业人士的数据，分析数字工具、沟通和组织实践对财务结果的影响。

Result: 远程和混合工作通过ERP系统和数字工作流程能改善预算控制和流程透明度，但预测准确性和跨部门沟通仍是主要挑战，特别是在数字整合不足的组织中；同时发现压力水平降低和工作生活平衡改善。

Conclusion: 建议企业加强数字基础设施，采用高级分析进行预测，建立清晰的沟通框架并支持员工福祉计划，为灵活工作环境下的财务管理提供实践指导。

Abstract: The paper examines financial management challenges faced by organizations operating under remote and hybrid work models. It investigates how these flexible arrangements influence budgeting, reporting, and financial transparency in distributed teams. Using a quantitative survey of managers, HR staff, and finance professionals, the study analyzes the role of digital tools, communication, and organizational practices in shaping financial outcomes. Results indicate that remote and hybrid work can improve budget control and process transparency through the use of ERP systems and digital workflows. However, forecasting accuracy and interdepartmental communication remain major challenges, particularly in organizations with insufficient digital integration. Respondents also reported lower stress levels and improved work-life balance, suggesting potential well-being and productivity benefits. The paper recommends that companies enhance digital infrastructure, adopt advanced analytics for forecasting, and develop clear communication frameworks supported by employee well-being programs. The study contributes original empirical evidence on financial management in flexible work environments, offering practical insights for leaders navigating the digital transformation of finance.

</details>


### [99] [Evolutionary Reinforcement Learning based AI tutor for Socratic Interdisciplinary Instruction](https://arxiv.org/abs/2512.11930)
*Mei Jiang,Haihai Shen,Zhuo Luo,Bingdong Li,Wenjing Hong,Ke Tang,Aimin Zhou*

Main category: cs.CY

TL;DR: 论文提出ERL4SIIP框架，使用进化强化学习解决STEM跨学科教育中的苏格拉底式教学问题，通过动态学生模拟、分层奖励机制和LoRA-Division优化策略来克服现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前STEM教育需要从被动知识传授转向主动苏格拉底式建构，以培养高阶认知能力。虽然大语言模型在STEM跨学科教育中具有潜力，但现有的提示工程、监督微调或标准强化学习方法存在三个根本挑战：无法动态建模学生潜在认知状态、长期教育目标导致的严重奖励稀疏和延迟、以及依赖行为克隆导致策略崩溃缺乏多样性。

Method: 将苏格拉底跨学科教学问题形式化为部分可观测马尔可夫决策过程，提出ERL4SIIP进化强化学习框架，包含三个核心组件：基于STEM知识图的动态学生模拟器用于潜在状态建模；分层奖励机制将长期目标分解为密集信号；LoRA-Division优化策略结合进化算法进行全局搜索和PPO进行局部梯度上升。

Result: 论文提出了完整的ERL4SIIP框架，但摘要中未报告具体的实验结果。从方法描述来看，该框架旨在解决现有方法在动态状态建模、奖励稀疏和策略多样性方面的局限性。

Conclusion: ERL4SIIP框架为STEM跨学科教育中的苏格拉底式教学问题提供了系统解决方案，通过进化强化学习结合动态状态建模、分层奖励和优化策略，有望实现同时进行全局探索和细粒度策略优化的目标。

Abstract: Cultivating higher-order cognitive abilities -- such as knowledge integration, critical thinking, and creativity -- in modern STEM education necessitates a pedagogical shift from passive knowledge transmission to active Socratic construction. Although Large Language Models (LLMs) hold promise for STEM Interdisciplinary education, current methodologies employing Prompt Engineering (PE), Supervised Fine-tuning (SFT), or standard Reinforcement Learning (RL) often fall short of supporting this paradigm. Existing methods are hindered by three fundamental challenges: the inability to dynamically model latent student cognitive states; severe reward sparsity and delay inherent in long-term educational goals; and a tendency toward policy collapse lacking strategic diversity due to reliance on behavioral cloning. Recognizing the unobservability and dynamic complexity of these interactions, we formalize the Socratic Interdisciplinary Instructional Problem (SIIP) as a structured Partially Observable Markov Decision Process (POMDP), demanding simultaneous global exploration and fine-grained policy refinement. To this end, we propose ERL4SIIP, a novel Evolutionary Reinforcement Learning (ERL) framework specifically tailored for this domain. ERL4SIIP integrates: (1) a dynamic student simulator grounded in a STEM knowledge graph for latent state modeling; (2) a Hierarchical Reward Mechanism that decomposes long-horizon goals into dense signals; and (3) a LoRA-Division based optimization strategy coupling evolutionary algorithms for population-level global search with PPO for local gradient ascent.

</details>


### [100] [Mapping AI Risk Mitigations: Evidence Scan and Preliminary AI Risk Mitigation Taxonomy](https://arxiv.org/abs/2512.11931)
*Alexander K. Saeri,Sophia Lloyd George,Jess Graham,Clelia D. Lacarriere,Peter Slattery,Michael Noetel,Neil Thompson*

Main category: cs.CY

TL;DR: 该论文提出了一个初步的AI风险缓解分类法，通过分析13个框架中的831项缓解措施，将其组织为4大类23个子类，旨在解决现有框架的碎片化和术语不一致问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI风险缓解框架存在碎片化、术语不一致和覆盖范围有缺口的问题，这阻碍了组织、政府等各方在AI风险缓解方面的有效协调。

Method: 通过对2023-2025年间发布的13个AI风险缓解框架进行快速证据扫描，提取出831项AI风险缓解措施，通过迭代聚类和编码构建分类法。

Result: 提出了包含4大类23个子类的初步AI风险缓解分类法：1)治理与监督；2)技术与安全；3)操作流程；4)透明度与问责。同时发现"风险管理"、"红队测试"等术语在不同框架中含义存在差异。

Conclusion: 该分类法及相关缓解措施数据库为AI风险缓解措施的整理和综合提供了起点，为AI生态系统中的不同参与者提供了结构化、易访问的讨论和协调框架。

Abstract: Organizations and governments that develop, deploy, use, and govern AI must coordinate on effective risk mitigation. However, the landscape of AI risk mitigation frameworks is fragmented, uses inconsistent terminology, and has gaps in coverage. This paper introduces a preliminary AI Risk Mitigation Taxonomy to organize AI risk mitigations and provide a common frame of reference. The Taxonomy was developed through a rapid evidence scan of 13 AI risk mitigation frameworks published between 2023-2025, which were extracted into a living database of 831 AI risk mitigations. The mitigations were iteratively clustered & coded to create the Taxonomy. The preliminary AI Risk Mitigation Taxonomy organizes mitigations into four categories and 23 subcategories: (1) Governance & Oversight: Formal organizational structures and policy frameworks that establish human oversight mechanisms and decision protocols; (2) Technical & Security: Technical, physical, and engineering safeguards that secure AI systems and constrain model behaviors; (3) Operational Process: processes and management frameworks governing AI system deployment, usage, monitoring, incident handling, and validation; and (4) Transparency & Accountability: formal disclosure practices and verification mechanisms that communicate AI system information and enable external scrutiny. The rapid evidence scan and taxonomy construction also revealed several cases where terms like 'risk management' and 'red teaming' are used widely but refer to different responsible actors, actions, and mechanisms of action to reduce risk. This Taxonomy and associated mitigation database, while preliminary, offers a starting point for collation and synthesis of AI risk mitigations. It also offers an accessible, structured way for different actors in the AI ecosystem to discuss and coordinate action to reduce risks from AI.

</details>


### [101] [The Agentic Regulator: Risks for AI in Finance and a Proposed Agent-based Framework for Governance](https://arxiv.org/abs/2512.11933)
*Eren Kurshan,Tucker Balch,David Byrd*

Main category: cs.CY

TL;DR: 提出模块化监管架构，通过四层"监管块"应对生成式AI和智能体系统在金融市场中的风险，实现实时监控与创新平衡


<details>
  <summary>Details</summary>
Motivation: 生成式和智能体AI在金融市场中的发展速度超过了现有监管框架的适应能力。当前模型风险框架假设算法是静态、明确定义的，而大语言模型和多智能体交易系统通过持续学习、交换潜在信号和展现涌现行为，违反了这些假设

Method: 基于复杂适应系统理论，将这些技术建模为去中心化集成系统，提出模块化治理架构。该框架将监管分解为四层"监管块"：1)嵌入每个模型旁边的自我监管模块；2)聚合本地遥测数据并执行政策的公司级治理块；3)监控行业范围指标以检测共谋或不稳定模式的监管机构托管代理；4)提供第三方保证的独立审计块。采用八种设计策略使监管块能够与它们监管的模型同步演进

Result: 通过多智能体交易中涌现的欺骗行为案例研究，展示了分层控制如何在实时隔离有害行为的同时保持创新。该架构与当前模型风险规则兼容，同时弥补了关键的可观测性和控制差距

Conclusion: 该模块化治理架构为金融系统中弹性、自适应的AI治理提供了实用路径，能够在快速发展的AI技术环境中实现有效的风险管理和创新平衡

Abstract: Generative and agentic artificial intelligence is entering financial markets faster than existing governance can adapt. Current model-risk frameworks assume static, well-specified algorithms and one-time validations; large language models and multi-agent trading systems violate those assumptions by learning continuously, exchanging latent signals, and exhibiting emergent behavior. Drawing on complex adaptive systems theory, we model these technologies as decentralized ensembles whose risks propagate along multiple time-scales. We then propose a modular governance architecture. The framework decomposes oversight into four layers of "regulatory blocks": (i) self-regulation modules embedded beside each model, (ii) firm-level governance blocks that aggregate local telemetry and enforce policy, (iii) regulator-hosted agents that monitor sector-wide indicators for collusive or destabilizing patterns, and (iv) independent audit blocks that supply third-party assurance. Eight design strategies enable the blocks to evolve as fast as the models they police. A case study on emergent spoofing in multi-agent trading shows how the layered controls quarantine harmful behavior in real time while preserving innovation. The architecture remains compatible with today's model-risk rules yet closes critical observability and control gaps, providing a practical path toward resilient, adaptive AI governance in financial systems.

</details>


### [102] [Unveiling User Perceptions in the Generative AI Era: A Sentiment-Driven Evaluation of AI Educational Apps' Role in Digital Transformation of e-Teaching](https://arxiv.org/abs/2512.11934)
*Adeleh Mazaherian,Erfan Nourbakhsh*

Main category: cs.CY

TL;DR: 该研究通过情感分析评估Google Play商店中AI教育应用的用户评价，发现作业助手类应用表现最佳，而语言/LMS类应用评价较差，揭示了AI在教育中的民主化潜力与依赖风险。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在教育中的快速应用，用户对AI教育应用的看法仍缺乏深入研究。本研究旨在通过分析用户评价来评估AI教育应用的有效性、挑战和教学意义。

Method: 研究采用情感驱动评估方法：1) 从Google Play商店抓取应用数据和用户评价；2) 使用RoBERTa进行二元情感分类；3) 使用GPT-4o提取关键观点；4) 使用GPT-5合成主要正面/负面主题。将应用分为七类（作业助手、数学求解器、语言工具等）。

Result: 结果显示：1) 整体情感以正面为主；2) 作业助手类应用（如Edu AI 95.9%正面，Answer.AI 92.7%）在准确性、速度和个性化方面表现最佳；3) 语言/LMS类应用（如Teacher AI仅21.8%正面）因不稳定和功能有限而表现较差；4) 正面评价强调效率、头脑风暴和参与度；5) 负面评价集中在付费墙、不准确、广告和故障。

Conclusion: 作业助手类应用优于专业工具，突显了AI的民主化潜力，但也存在依赖性和不平等风险。未来应发展混合AI-人类模型、VR/AR沉浸式学习，开发者需关注自适应个性化，政策制定者需监管商业化以确保包容性。生成式AI通过伦理改进推动电子教学发展。

Abstract: The rapid integration of generative artificial intelligence into education has driven digital transformation in e-teaching, yet user perceptions of AI educational apps remain underexplored. This study performs a sentiment-driven evaluation of user reviews from top AI ed-apps on the Google Play Store to assess efficacy, challenges, and pedagogical implications. Our pipeline involved scraping app data and reviews, RoBERTa for binary sentiment classification, GPT-4o for key point extraction, and GPT-5 for synthesizing top positive/negative themes. Apps were categorized into seven types (e.g., homework helpers, math solvers, language tools), with overlaps reflecting multifunctional designs. Results indicate predominantly positive sentiments, with homework apps like Edu AI (95.9% positive) and Answer.AI (92.7%) leading in accuracy, speed, and personalization, while language/LMS apps (e.g., Teacher AI at 21.8% positive) lag due to instability and limited features. Positives emphasize efficiency in brainstorming, problem-solving, and engagement; negatives center on paywalls, inaccuracies, ads, and glitches. Trends show that homework helpers outperform specialized tools, highlighting AI's democratizing potential amid risks of dependency and inequity. The discussion proposes future ecosystems with hybrid AI-human models, VR/AR for immersive learning, and a roadmap for developers (adaptive personalization) and policymakers (monetization regulation for inclusivity). This underscores generative AI's role in advancing e-teaching by enabling ethical refinements that foster equitable, innovative environments. The full dataset is available here(https://github.com/erfan-nourbakhsh/GenAI-EdSent).

</details>


### [103] [Beyond right or wrong : towards redefining adaptive learning indicators in virtual learning environments](https://arxiv.org/abs/2512.12105)
*Andreia dos Santos Sachete,Alba Valeria de SantAnna de Freitas Loiola,Fabio Diniz Rossi,Jose Valdeni de Lima,Raquel Salcedo Gomes*

Main category: cs.CY

TL;DR: 本文通过系统文献综述，探讨了超越传统对错评估的学习指标，为虚拟学习环境中的自适应学习提供更全面的评估方法。


<details>
  <summary>Details</summary>
Motivation: 当前虚拟学习环境中的自适应学习方法大多仅基于学生回答的正确与否，这种评估视角有限，无法全面衡量学生的学习水平，忽略了其他可能对学习过程至关重要的因素。

Method: 采用系统文献综述方法，通过定性评估筛选相关研究，分析影响学生学习的学习指标及其在虚拟学习环境中的可实施性。

Result: 研究发现了一系列全面的学习评估指标，包括动机、情绪、生理反应、脑成像和学生先前知识等多个方面，这些指标能够更全面地评估虚拟环境中的学习。

Conclusion: 这些新的学习指标为自适应技术开发者提供了更全面的评估框架，有助于开发更符合学生实际情况的解决方案，从而实现更完整的教育训练。

Abstract: Student learning development must involve more than just correcting or incorrect questions. However, most adaptive learning methods in Virtual Learning Environments are based on whether the student's response is incorrect or correct. This perspective is limited in assessing the student's learning level, as it does not consider other elements that can be crucial in this process. The objective of this work is to conduct a Systematic Literature Review (SLR) to elucidate which learning indicators influence student learning and which can be implemented in a VLE to assist in adaptive learning. The works selected and filtered by qualitative assessment reveal a comprehensive approach to assessing different aspects of the learning in virtual environments, such as motivation, emotions, physiological responses, brain imaging, and the students' prior knowledge. The discussion of these new indicators allows adaptive technology developers to implement more appropriate solutions to students' realities, resulting in more complete training.

</details>


### [104] [A neuro-symbolic framework for accountability in public-sector AI](https://arxiv.org/abs/2512.12109)
*Allen Daniel Sunny*

Main category: cs.CY

TL;DR: 开发了一个基于法律的可解释性框架，将自动化福利决策系统的解释与法定约束联系起来，确保解释符合法律规则


<details>
  <summary>Details</summary>
Motivation: 自动化资格系统越来越多地决定公共福利的获取，但这些系统生成的解释往往无法反映授权决策的法律规则，需要建立法律基础的解释框架

Method: 结合了三个部分：1)从加州政策程序手册中提取资格要求的结构化本体；2)将法定逻辑表达为可验证形式表示的规则提取管道；3)基于求解器的推理层来评估解释是否符合管辖法律

Result: 案例评估表明该框架能够检测法律上不一致的解释，突出违反的资格规则，并通过使自动化决策的基础可追溯和可争议来支持程序问责

Conclusion: 该论文开发了一个法律基础的可解释性框架，能够确保自动化福利决策系统的解释符合法律要求，提高系统的透明度和问责性

Abstract: Automated eligibility systems increasingly determine access to essential public benefits, but the explanations they generate often fail to reflect the legal rules that authorize those decisions. This thesis develops a legally grounded explainability framework that links system-generated decision justifications to the statutory constraints of CalFresh, California's Supplemental Nutrition Assistance Program. The framework combines a structured ontology of eligibility requirements derived from the state's Manual of Policies and Procedures (MPP), a rule extraction pipeline that expresses statutory logic in a verifiable formal representation, and a solver-based reasoning layer to evaluate whether the explanation aligns with governing law. Case evaluations demonstrate the framework's ability to detect legally inconsistent explanations, highlight violated eligibility rules, and support procedural accountability by making the basis of automated determinations traceable and contestable.

</details>


### [105] [The Ideological Turing Test for Moderation of Outgroup Affective Animosity](https://arxiv.org/abs/2512.12187)
*David Gamba,Daniel M. Romero,Grant Schoenebeck*

Main category: cs.CY

TL;DR: 提出"意识形态图灵测试"游戏化框架，通过让参与者为对立观点辩护来减少情感敌意和极化。研究发现换位思考能减少外群体敌意，但写作和辩论两种方式的效果随时间变化不同。


<details>
  <summary>Details</summary>
Motivation: 针对日益严重的意识形态对立和社会分裂问题，需要开发有效工具来减少群体间的敌意和极化。传统对抗性方法可能加剧冲突，需要探索新的干预策略。

Method: 采用混合设计实验(N=203)，包含四个条件：方式(辩论/写作)×换位思考(自己观点/对立观点)。参与者进行结构化互动，为指定立场辩护，结果由同伴评判。测量干预后和2-6周随访时的情感敌意和意识形态立场变化。

Result: 换位思考减少了外群体敌意和意识形态极化，但效果因方式和时间而异。写作从对立视角出发在短期内减少敌意效果最大(Δ=+0.45 SD)，但4-6周后消失；辩论方式在干预后和随访时都保持显著减少(Δ=+0.37 SD)。意识形态立场方面，采用对立视角导致显著立即变化，且效果持续到随访期。

Conclusion: 意识形态图灵测试作为减少极化的可扩展工具具有潜力，特别是将换位思考与反思性对抗互动结合时。非对抗性参与促进短期共情增益，而通过辩论的认知参与则能维持情感效益。

Abstract: Rising animosity toward ideological opponents poses critical societal challenges. We introduce and test the Ideological Turing Test, a gamified framework requiring participants to adopt and defend opposing viewpoints, to reduce affective animosity and affective polarization.
  We conducted a mixed-design experiment ($N = 203$) with four conditions: modality (debate/writing) x perspective-taking (Own/Opposite side). Participants engaged in structured interactions defending assigned positions, with outcomes judged by peers. We measured changes in affective animosity and ideological position immediately post-intervention and at 2-6 week follow-up.
  Perspective-taking reduced out-group animosity and ideological polarization. However, effects differed by modality (writing vs. debate) and over time. For affective animosity, writing from the opposite perspective yielded the largest immediate reduction ($Δ=+0.45$ SD), but the effect was not detectable at the 4-6 week follow-up. In contrast, the debate modality maintained a statistically significant reduction in animosity immediately after and at follow-up ($Δ=+0.37$ SD). For ideological position, adopting the opposite perspective led to significant immediate movement across modalities (writing: $Δ=+0.91$ SD; debate: $Δ=+0.51$ SD), and these changes persisted at follow-up. Judged performance (winning) did not moderate these effects, and willingness to re-participate was similar across conditions (~20-36%).
  These findings challenge assumptions about adversarial methods, revealing distinct temporal patterns: non-adversarial engagement fosters short-term empathy gains, while cognitive engagement through debate sustains affective benefits. The Ideological Turing Test demonstrates potential as a scalable tool for reducing polarization, particularly when combining perspective-taking with reflective adversarial interactions.

</details>


### [106] [From Co-Design to Metacognitive Laziness: Evaluating Generative AI in Vocational Education](https://arxiv.org/abs/2512.12306)
*Amir Yunus,Peng Rend Gay,Oon Teng Lee*

Main category: cs.CY

TL;DR: 研究开发了面向新加坡职业教育的生成式AI聊天机器人，虽然提升了教学效率，但未显著改善学生成绩，反而揭示了认知依赖和表现差距扩大等风险。


<details>
  <summary>Details</summary>
Motivation: 解决职业教育中教师面临的重复性问题解答和规模化反馈交付等教学挑战，通过AI工具支持教师工作流程。

Method: 采用用户中心、混合方法的设计流程，与教师共同开发AI聊天机器人，用于考试准备阶段，收集使用数据和绩效数据进行深入分析。

Result: AI工具成功简化了教师工作流程、降低了认知负荷，但学生整体评估成绩无显著提升。交互日志分析显示：高能力学生用于策略验证，低能力学生出现认知卸载和依赖行为，可能加剧表现差距。

Conclusion: 生成式AI能显著提升教学体验，但要实现有意义的学习成果，需要关注学习者行为模式，设计能减少依赖、支持元认知发展、平衡不同能力水平支持的AI环境。

Abstract: This study examines the development and deployment of a Generative AI proof-of-concept (POC) designed to support lecturers in a vocational education setting in Singapore. Employing a user-centred, mixed-methods design process, we co-developed an AI chatbot with lecturers to address recurring instructional challenges during exam preparation, specifically managing repetitive questions and scaling feedback delivery. The POC achieved its primary operational goals: lecturers reported streamlined workflows, reduced cognitive load, and observed improved student confidence in navigating course content. However, the deployment yielded unexpected insights into student learning behaviours. Despite enhanced teaching processes, performance data revealed no significant improvement in overall student assessment outcomes. Deep analysis of interaction logs identified concerning patterns, including self-efficacy-driven dependency, "metacognitive laziness" (cognitive offloading), and divergent usage strategies. While high-ability students leveraged the tool for strategic verification, low-ability students frequently used it to bypass cognitive effort, potentially exacerbating performance gaps. These findings suggest that Generative AI's educational influence extends beyond instructional efficiency to shape cognitive engagement, self-regulation, and learner equity. The study raises consequential design questions regarding how AI tools can be engineered to minimise dependency, scaffold metacognitive development, and calibrate support across varying ability levels. We conclude that while Generative AI can substantially enhance the teaching experience, achieving meaningful learning gains requires rigorous attention to learner behaviour and the equitable design of AI-supported environments.

</details>


### [107] [AI Sprints: Towards a Critical Method for Human-AI Collaboration](https://arxiv.org/abs/2512.12371)
*David M. Berry*

Main category: cs.CY

TL;DR: 论文提出"AI冲刺"方法，将人文学科批判性反思与生成式AI迭代对话结合，通过三种认知模式（认知委托、生产性增强、认知开销）实现人机协作研究。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的出现为人文社科研究提供了新机遇，但需要建立既能利用AI能力又能保持人文学科批判性反思的研究方法，应对算法条件下计算系统日益中介我们对自然和社会理解的现象。

Method: 提出"AI冲刺"方法，结合数据冲刺和书籍冲刺方法论，通过密集的时间盒研究会议实现人机迭代对话。引入三种认知模式：认知委托（将任务委派给AI）、生产性增强（AI扩展人类能力）、认知开销（保持战略监督），并基于Rogers的数字方法扩展，通过AI系统分析传统需要人工编码的材料。

Result: 论文贡献了实用的AI增强研究方法论和理论框架，用于理解这种混合方法的认识论转变。展示了如何通过紧密的迭代开发循环适应现有研究方法，同时承认生成式AI带来的深刻变革。

Conclusion: 关键方法论必须在技术和理论两个层面运作，维持与AI系统及其输出的严格伦理-计算参与。AI冲刺方法为人文社科研究提供了既能利用AI能力又能保持批判性反思的新研究范式。

Abstract: The emergence of Large Language Models presents a remarkable opportunity for humanities and social science research. I argue these technologies instantiate what I have called the algorithmic condition, whereby computational systems increasingly mediate not just our analytical tools but how we understand nature and society more generally. This article introduces the possibility for new forms of humanistic inquiry through what I term 'AI sprints', as intensive time-boxed research sessions. This is a research method combining the critical reflexivity essential to humanistic inquiry with iterative dialogue with generative AI. Drawing on experimental work in critical code studies, I demonstrate how tight loops of iterative development can adapt data and book sprint methodologies whilst acknowledging the profound transformations generative AI introduces. Through examining the process of human-AI collaboration when undertaken in these intensive research sessions, I seek to outline this approach as a broader research method. The article builds on Rogers' digital methods approach, proposing that we extend methodologies to study digital objects through their native protocols, using AI systems not merely to process digital traces but to analyse materials traditionally requiring manual coding or transcription. I aim to show this by introducing three cognitive modes, cognitive delegation, productive augmentation, and cognitive overhead, explaining how researchers can maintain a strategic overview whilst using LLM capabilities. The paper contributes both a practical methodology for intensive AI-augmented research and a theoretical framework for understanding the epistemological transformations of this hybrid method. A critical methodology must therefore operate in both technical and theoretical registers, sustaining a rigorous ethical-computational engagement with AI systems and outputs.

</details>


### [108] [Beyond Static Scoring: Enhancing Assessment Validity via AI-Generated Interactive Verification](https://arxiv.org/abs/2512.12592)
*Tom Lee,Sihoon Lee,Seonghun Kim*

Main category: cs.CY

TL;DR: 提出人机协作评估框架，结合自动评分与AI生成追问，增强评估完整性，超越单纯检测AI使用


<details>
  <summary>Details</summary>
Motivation: 大型语言模型模糊了作者身份界限，传统开放式评估有效性受到挑战。现有自动评分方法缺乏过程证据，无法验证学生真实理解

Method: 提出两阶段人机协作框架：第一阶段基于量规自动评分确保程序公平；第二阶段AI生成针对性追问进行交互验证，诊断表面推理或AI使用

Result: 试点研究显示第一阶段确保评分一致性，第二阶段对构念效度至关重要，能有效识别表面理解或AI使用。教师认可公平性与效度平衡，强调追问难度自适应的重要性

Conclusion: 该框架为真实评估提供了可扩展路径，超越单纯监管AI使用，将其整合为评估过程中的协同伙伴

Abstract: Large Language Models (LLMs) challenge the validity of traditional open-ended assessments by blurring the lines of authorship. While recent research has focused on the accuracy of automated scoring (AES), these static approaches fail to capture process evidence or verify genuine student understanding. This paper introduces a novel Human-AI Collaboration framework that enhances assessment integrity by combining rubric-based automated scoring with AI-generated, targeted follow-up questions. In a pilot study with university instructors (N=9), we demonstrate that while Stage 1 (Auto-Scoring) ensures procedural fairness and consistency, Stage 2 (Interactive Verification) is essential for construct validity, effectively diagnosing superficial reasoning or unverified AI use. We report on the systems design, instructor perceptions of fairness versus validity, and the necessity of adaptive difficulty in follow-up questioning. The findings offer a scalable pathway for authentic assessment that moves beyond policing AI to integrating it as a synergistic partner in the evaluation process.

</details>


### [109] [From Linear Risk to Emergent Harm: Complexity as the Missing Core of AI Governance](https://arxiv.org/abs/2512.12707)
*Hugo Roger Paz*

Main category: cs.CY

TL;DR: 风险导向的AI监管存在结构性缺陷，作者提出基于复杂系统理论的AI治理新框架


<details>
  <summary>Details</summary>
Motivation: 当前基于风险的AI监管范式存在根本性缺陷，因为它假设线性因果关系、稳定系统边界和可预测的监管响应，而实际上AI运行在复杂的自适应社会技术系统中，危害往往是涌现的、延迟的、重新分配的，并通过反馈循环和系统参与者的战略适应而放大。

Method: 提出基于复杂性的AI治理框架，将监管视为干预而非控制，优先进行动态系统映射而非静态分类，并整合因果推理和模拟来进行不确定性下的政策设计。

Result: 合规可能增加而危害只是被转移或隐藏而非消除。新框架旨在通过监测、学习和迭代修订治理干预来实现稳健的系统管理。

Conclusion: AI治理需要从风险控制范式转向复杂系统管理范式，承认不确定性的存在，通过持续学习和适应性干预来实现有效的治理。

Abstract: Risk-based AI regulation has become the dominant paradigm in AI governance, promising proportional controls aligned with anticipated harms. This paper argues that such frameworks often fail for structural reasons: they implicitly assume linear causality, stable system boundaries, and largely predictable responses to regulation. In practice, AI operates within complex adaptive socio-technical systems in which harm is frequently emergent, delayed, redistributed, and amplified through feedback loops and strategic adaptation by system actors. As a result, compliance can increase while harm is displaced or concealed rather than eliminated. We propose a complexity-based framework for AI governance that treats regulation as intervention rather than control, prioritises dynamic system mapping over static classifications, and integrates causal reasoning and simulation for policy design under uncertainty. The aim is not to eliminate uncertainty, but to enable robust system stewardship through monitoring, learning, and iterative revision of governance interventions.

</details>


### [110] [Algorithmic Criminal Liability in Greenwashing: Comparing India, United States, and European Union](https://arxiv.org/abs/2512.12837)
*Sahibpreet Singh,Manjit Singh*

Main category: cs.CY

TL;DR: 该研究比较分析了印度、美国和欧盟对AI驱动的"绿色洗白"（greenwashing）的刑事责任认定，发现现有法律存在人类中心主义偏见，难以追究算法系统的欺骗责任，并提出混合责任框架建议。


<details>
  <summary>Details</summary>
Motivation: AI驱动的绿色洗白已成为企业可持续发展治理中的隐蔽挑战，加剧了环境披露的不透明性并规避了监管监督。现有法律基于人类意图的责任认定模式无法有效应对算法系统的欺骗行为，存在法律适应性的关键缺口。

Method: 采用教义法律方法论，系统分析印度、美国和欧盟的司法判例和法定文书，进行跨国比较法律分析，特别关注AI中介的绿色洗白行为的刑事责任认定。

Result: 研究发现严格责任模式的可行性，重新调整的AI问责治理框架，以及在ESG制度下的算法尽职调查要求。欧盟《企业可持续发展尽职调查指令》（CSDDD）提供了潜在的跨国模式。不同司法管辖区存在显著差异。

Conclusion: 研究主张建立混合责任框架，将算法风险评估与法律人格构造相结合，确保算法的不透明性不会阻碍责任执行，为AI伦理和环境法理学做出贡献。

Abstract: AI-powered greenwashing has emerged as an insidious challenge within corporate sustainability governance, exacerbating the opacity of environmental disclosures and subverting regulatory oversight. This study conducts a comparative legal analysis of criminal liability for AI-mediated greenwashing across India, the US, and the EU, exposing doctrinal lacunae in attributing culpability when deceptive claims originate from algorithmic systems. Existing statutes exhibit anthropocentric biases by predicating liability on demonstrable human intent, rendering them ill-equipped to address algorithmic deception. The research identifies a critical gap in jurisprudential adaptation, as prevailing fraud statutes remain antiquated vis-à-vis AI-generated misrepresentation. Utilising a doctrinal legal methodology, this study systematically dissects judicial precedents and statutory instruments, yielding results regarding the potential expansion of corporate criminal liability. Findings underscore the viability of strict liability models, recalibrated governance frameworks for AI accountability, and algorithmic due diligence mandates under ESG regimes. Comparative insights reveal jurisdictional disparities, with the EU Corporate Sustainability Due Diligence Directive (CSDDD) offering a potential transnational model. This study contributes to AI ethics and environmental jurisprudence by advocating for a hybrid liability framework integrating algorithmic risk assessment with legal personhood constructs, ensuring algorithmic opacity does not preclude liability enforcement.

</details>


### [111] [Open Source Software and Data for Human Service Development: A Case Study on Predicting Housing Instability](https://arxiv.org/abs/2512.12919)
*Maria Y. Rodriguez,Ehren Dohler,Jon Phillips,Melissa Villodas,Voltaire Vegara,Kenny Joseph,Amy Wilson*

Main category: cs.CY

TL;DR: 该研究探讨了开源数据和工具在资源受限的人类服务领域中的应用，通过预测纽约布朗克斯县驱逐申请失败率来评估其效果和局限性。


<details>
  <summary>Details</summary>
Motivation: 开源数据和工具被认为是社会科学可复制性和可用性的关键，但它们在资源受限的人类服务提供中的实际应用情况尚不清楚。本研究旨在探索开源工具和数据在人类服务发展中的挑战和机遇。

Method: 使用住房数据联盟的邮政编码级别数据、美国社区调查5年估计数据和DeepMaps劳动力模型，通过R统计计算项目（开源软件）应用多层模型（MLM）和指数平滑模型（ETS）来预测2021年7月前的驱逐申请失败率。

Result: 研究发现开源数据和软件能够促进公共数据的快速分析，这在资源日益受限的人类服务干预发展中是急需的能力。然而，公共数据受限于其可靠捕获的信息范围，导致其效用存在不可忽视的误差幅度。

Conclusion: 开源工具和数据为资源有限的人类服务组织提供了有价值的分析能力，但需要认识到公共数据的局限性。研究为关注低资源社区的人类服务组织提供了实用经验教训。

Abstract: Open-source data and tools are lauded as essential for replicable and usable social science, though little is known about their use in resource constrained human service provision. This paper examines the challenges and opportunities of open-source tools and data in human service development by using both to forecast failure to pay eviction filings in Bronx County, NY. We use zip code level data from the Housing Data Coalition, the American Community Survey 5-year estimates, and DeepMaps Model of the Labor Force to forecast rates through July 2021. We employ multilevel (MLM) and exponential smoothing (ETS) models using the R project for Statistical Computing, an oft used open-source statistical software. We compare our results to what happened during the same period, to illustrate the efficacy of the open-source tools and techniques employed. We argue open-source data and software may facilitate rapid analysis of public data - a much-needed ability in human service intervention development under increasingly constrained resources - but find public data are limited by the information they reliably capture, limiting their utility by a non-trivial margin of error. The manuscript concludes by considering lessons for human service organizations with limited analytical resources and a vested interest in low-resourced communities.

</details>


### [112] [Modeling Collaborative Problem Solving Dynamics from Group Discourse: A Text-Mining Approach with Synergy Degree Model](https://arxiv.org/abs/2512.13061)
*Jianjun Xiao,Cixiao Wang,Wenmei Zhang*

Main category: cs.CY

TL;DR: 该研究提出了一种结合自动话语分析和协同度模型的计算框架，用于量化协作问题解决中的协同效应，通过AI辅助方法实现了大规模精细分析。


<details>
  <summary>Details</summary>
Motivation: 传统手动编码无法捕捉协作问题解决中的系统级动态，需要开发能够量化协同效应的计算框架，以支持学习分析中的大规模评估。

Method: 采用自动话语分析结合协同度模型，收集52名学习者在12个小组中的5周cMOOC活动数据，应用9种分类模型识别4个交互层次的10种CPS行为，将每个交互层次视为子系统计算协同度。

Result: BERT模型准确率最高，GPT模型精度更适合人机协同编码；自动测量保持了构念效度；不同任务类型存在显著差异；协同度能有效区分协作质量，从优秀到失败组均有体现。

Conclusion: 协同度是协作质量的敏感指标，通过AI在环方法实现精细CPS分析规模化是可行的，为学习分析提供了新的量化工具。

Abstract: Measuring collaborative problem solving (CPS) synergy remains challenging in learning analytics, as classical manual coding cannot capture emergent system-level dynamics. This study introduces a computational framework that integrates automated discourse analysis with the Synergy Degree Model (SDM) to quantify CPS synergy from group communication. Data were collected from 52 learners in 12 groups during a 5-week connectivist MOOC (cMOOC) activity. Nine classification models were applied to automatically identify ten CPS behaviors across four interaction levels: operation, wayfinding, sense-making, and creation. While BERT achieved the highest accuracy, GPT models demonstrated superior precision suitable for human-AI collaborative coding. Within the SDM framework, each interaction level was treated as a subsystem to compute group-level order parameters and derive synergy degrees. Permutation tests showed automated measures preserve construct validity, despite systematic biases at the subsystem level. Statistical analyses revealed significant task-type differences: survey study groups exhibited higher creation-order than mode study groups, suggesting "controlled disorder" may benefit complex problem solving. Importantly, synergy degree distinguished collaborative quality, ranging from excellent to failing groups. Findings establish synergy degree as a sensitive indicator of collaboration and demonstrate the feasibility of scaling fine-grained CPS analytics through AI-in-the-loop approaches.

</details>


### [113] [From Educational Analytics to AI Governance: Transferable Lessons from Complex Systems Interventions](https://arxiv.org/abs/2512.13260)
*Hugo Roger Paz*

Main category: cs.CY

TL;DR: 论文提出将教育分析框架CAPIRE的原则应用于AI治理，建立复杂系统AI治理框架，从风险评估转向系统动态分析


<details>
  <summary>Details</summary>
Motivation: 高等教育学生保留和AI治理面临共同挑战：将线性监管框架应用于复杂自适应系统。风险导向方法在两个领域都系统性失败，因为它们假设稳定的因果路径、可预测的行为者响应和可控的系统边界

Method: 从CAPIRE框架提取五个核心原则：时间观察纪律、结构映射优于分类分类、基于原型的异质性分析、因果机制识别、基于模拟的政策设计。将这些原则应用于AI治理，提出复杂系统AI治理框架

Result: CAPIRE框架证明善意干预在忽略系统复杂性时经常产生意外后果。五个原则可直接转移到AI系统治理挑战中，因为两个领域都表现出非线性、涌现性、反馈循环、战略适应和路径依赖

Conclusion: 提出复杂系统AI治理作为集成框架，将监管设计的核心问题从"这个AI系统有多危险？"转向"这个干预如何重塑系统动态？"。贡献包括展示一个复杂系统领域的经验教训可加速另一个领域的治理设计，并提供复杂性感知AI监管的具体方法论架构

Abstract: Both student retention in higher education and artificial intelligence governance face a common structural challenge: the application of linear regulatory frameworks to complex adaptive systems. Risk-based approaches dominate both domains, yet systematically fail because they assume stable causal pathways, predictable actor responses, and controllable system boundaries. This paper extracts transferable methodological principles from CAPIRE (Curriculum, Archetypes, Policies, Interventions & Research Environment), an empirically validated framework for educational analytics that treats student dropout as an emergent property of curricular structures, institutional rules, and macroeconomic shocks. Drawing on longitudinal data from engineering programmes and causal inference methods, CAPIRE demonstrates that well-intentioned interventions routinely generate unintended consequences when system complexity is ignored. We argue that five core principles developed within CAPIRE - temporal observation discipline, structural mapping over categorical classification, archetype-based heterogeneity analysis, causal mechanism identification, and simulation-based policy design - transfer directly to the challenge of governing AI systems. The isomorphism is not merely analogical: both domains exhibit non-linearity, emergence, feedback loops, strategic adaptation, and path dependence. We propose Complex Systems AI Governance (CSAIG) as an integrated framework that operationalises these principles for regulatory design, shifting the central question from "how risky is this AI system?" to "how does this intervention reshape system dynamics?" The contribution is twofold: demonstrating that empirical lessons from one complex systems domain can accelerate governance design in another, and offering a concrete methodological architecture for complexity-aware AI regulation.

</details>


### [114] [Google Spain v. Gonzáles: Did the Court forget about freedom of expression?](https://arxiv.org/abs/2512.13404)
*Stefan Kulk,Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 欧洲法院在Google Spain案中确立"被遗忘权"，允许个人在特定条件下要求搜索引擎删除与其姓名相关的搜索结果链接，即使原信息是合法发布的。


<details>
  <summary>Details</summary>
Motivation: 随着搜索引擎普及，个人隐私面临新挑战。西班牙律师Mario Costeja González因1998年报纸公告显示其财务困境的搜索结果影响声誉，希望通过法律途径保护个人数据权利，引发了关于搜索引擎责任与个人隐私保护的争议。

Method: 通过西班牙国家高等法院向欧盟法院(CJEU)请求解释《数据保护指令》的适用性，进行法律诉讼程序，最终由欧盟法院作出具有约束力的判决。

Result: 欧盟法院判决认定，在特定条件下，个人有权要求搜索引擎删除与其姓名相关的搜索结果链接，这一"被遗忘权"可延伸适用于合法发布的信息，确立了搜索引擎作为数据控制者的责任。

Conclusion: 该判决确立了欧盟范围内的"被遗忘权"，平衡了个人隐私保护与信息自由流通的关系，对搜索引擎运营和个人数据保护产生了深远影响，但也引发了关于审查制度和历史记录保存的争议。

Abstract: When reviewing a job application letter, going on a first date, or considering doing business with someone, the first thing many people do is entering the person's name in a search engine. A search engine can point searchers to information that would otherwise have remained obscure. If somebody searched for the name of Spanish lawyer Mario Costeja González, Google showed search results that included a link to a 1998 newspaper announcement implying he had financial troubles at the time. González wanted Google to stop showing those links and started a procedure in Spain. After some legal wrangling, the Spanish Audiencia Nacional (National High Court) asked the Court of Justice of the European Union (CJEU) for advice on the application of the Data Protection Directive, which led to the controversial judgment in Google Spain. In its judgment, the CJEU holds that people, under certain conditions, have the right to have search results for their name delisted. This right can also extend to lawfully published information.

</details>


### [115] [Improving Privacy Protection in the area of Behavioural Targeting](https://arxiv.org/abs/2512.13405)
*Frederik Johannes Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 该博士论文探讨欧盟法律如何通过结合保护与赋权的方法来改善行为定向广告中的隐私保护，挑战了当前主要依赖知情同意的赋权方法。


<details>
  <summary>Details</summary>
Motivation: 行为定向（在线画像）通过监控人们的在线行为来展示个性化广告，对隐私构成威胁。当前欧盟法律主要依赖《电子隐私指令》中的同意要求和一般数据保护法，但行为研究表明单纯依赖知情同意的赋权方法效果有限，许多人会盲目点击"我同意"。因此需要探索更有效的隐私保护方法。

Method: 这是一项法律研究，但结合了计算机科学、行为经济学和媒体研究等多学科见解。采用法律分析方法，深入探讨了数据保护法是否应适用于假名数据，详细分析了知情同意在数据保护法中的作用，并重点关注了数据保护法中保护与赋权个人之间的张力。

Result: 研究发现当前主要依赖知情同意的赋权方法不足以有效保护隐私，因为行为研究表明人们往往不会认真阅读同意条款。论文主张采用结合保护与赋权的综合方法，建议立法者应更侧重于保护个人，而不仅仅是赋予选择权。

Conclusion: 为有效缓解隐私问题（如寒蝉效应），欧盟法律需要从当前主要依赖赋权的方法转向结合保护与赋权的综合方法。这是首批讨论行为研究对欧洲数据保护政策影响的学术研究之一，为数据保护法的改革提供了重要见解。

Abstract: This PhD thesis discusses how European law could improve privacy protection in the area of behavioural targeting. Behavioural targeting, also referred to as online profiling, involves monitoring people's online behaviour, and using the collected information to show people individually targeted advertisements. To protect privacy in the area of behavioural targeting, the EU lawmaker mainly relies on the consent requirement for the use of tracking technologies in the e-Privacy Directive, and on general data protection law. With informed consent requirements, the law aims to empower people to make choices in their best interests. But behavioural studies cast doubt on the effectiveness of the empowerment approach as a privacy protection measure. Many people click "I agree" to any statement that is presented to them. Therefore, to mitigate privacy problems such as chilling effects, this study argues for a combined approach of protecting and empowering the individual. Compared to the current approach, the lawmaker should focus more on protecting people. The PhD thesis is a legal study, but it also incorporates insights from other disciplines, such as computer science, behavioural economics, and media studies. This study is among the first to discuss the implications of behavioural research for European data protection policy. The topic of whether data protection law should apply to pseudonymous data is discussed in depth. The study contains a detailed analysis of the role of informed consent in data protection law, and gives much attention to the tension between protecting and empowering the individual within data protection law.

</details>


### [116] [Embedding-Based Rankings of Educational Resources based on Learning Outcome Alignment: Benchmarking, Expert Validation, and Learner Performance](https://arxiv.org/abs/2512.13658)
*Mohammadreza Molavi,Mohammad Moein,Mohammadreza Tavakoli,Abdolali Faraji,Stefan T. Mol,Gábor Kismihók*

Main category: cs.CY

TL;DR: 提出基于文本嵌入模型的框架，自动评估教育资源与学习目标的匹配度，验证了其有效性并展示了与学习效果的关联。


<details>
  <summary>Details</summary>
Motivation: 在线教育需要个性化，但人工审核教育资源与学习目标的匹配度成本高、难以扩展，需要自动化解决方案。

Method: 使用文本嵌入模型评估教育资源与学习目标的匹配度，先用人造材料基准测试不同模型，再用最优模型评估LLM生成的材料，最后进行三组学习者实验验证。

Result: Voyage模型在检测匹配度上达到79%准确率，应用于LLM生成材料时达到83%准确率。实验显示更高的匹配度分数与更好的学习效果正相关。

Conclusion: 基于嵌入的匹配度评分可以实现可扩展的个性化教育，让教师能专注于根据学习者需求定制内容。

Abstract: As the online learning landscape evolves, the need for personalization is increasingly evident. Although educational resources are burgeoning, educators face challenges selecting materials that both align with intended learning outcomes and address diverse learner needs. Large Language Models (LLMs) are attracting growing interest for their potential to create learning resources that better support personalization, but verifying coverage of intended outcomes still requires human alignment review, which is costly and limits scalability. We propose a framework that supports the cost-effective automation of evaluating alignment between educational resources and intended learning outcomes. Using human-generated materials, we benchmarked LLM-based text-embedding models and found that the most accurate model (Voyage) achieved 79% accuracy in detecting alignment. We then applied the optimal model to LLM-generated resources and, via expert evaluation, confirmed that it reliably assessed correspondence to intended outcomes (83% accuracy). Finally, in a three-group experiment with 360 learners, higher alignment scores were positively related to greater learning performance, chi-squared(2, N = 360) = 15.39, p < 0.001. These findings show that embedding-based alignment scores can facilitate scalable personalization by confirming alignment with learning outcomes, which allows teachers to focus on tailoring content to diverse learner needs.

</details>
